{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleConvTT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4AT4gyNuDQaA",
        "Zcxk7OZMZiQU"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMKO6Hh9RrYcnwchSv+kGa9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WhiteTeaDragon/SingularValues/blob/main/TT/SimpleConvTT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "praf7vwRHu5P"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import regularizers\n",
        "import numpy as np\n",
        "import random as rn\n",
        "from tensorflow.python.framework import tensor_shape\n",
        "from tensorflow.python.keras.engine.input_spec import InputSpec\n",
        "import six\n",
        "import functools\n",
        "from tensorflow.python.ops import nn, nn_ops\n",
        "\n",
        "np.random.seed(1)   \n",
        "rn.seed(1)   \n",
        "tf.random.set_seed(1234)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AT4gyNuDQaA"
      },
      "source": [
        "### Проверка функции, превращающей тензорное разложение в ядро"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8De736fxe_G"
      },
      "source": [
        "def full_tt(K1, K2, K3):\n",
        "    \"\"\"Converts a TensorTrain into a regular tensor or matrix (tf.Tensor).\"\"\"\n",
        "    res = K1\n",
        "    K2_reshaped = tf.reshape(K2, (K2.shape[0], -1))\n",
        "    res = tf.matmul(res, K2_reshaped)\n",
        "    res = tf.reshape(res, (-1, K3.shape[0]))\n",
        "    res = tf.matmul(res, K3)\n",
        "    res = tf.reshape(res, (K1.shape[0],) + K2.shape[1:-1] + (K3.shape[-1],))\n",
        "    num_dims = len(K2.shape[1:-1])\n",
        "    return tf.transpose(res, list(range(1, num_dims + 1)) + [0, num_dims + 1])\n",
        "\n",
        "def simple_full_tt(K1, K2, K3):\n",
        "    kernel_shape = K2.shape[1:-1]\n",
        "    filters_shape = (K1.shape[0], K3.shape[-1])\n",
        "    res = np.zeros(kernel_shape + filters_shape)\n",
        "    if len(kernel_shape) == 2:\n",
        "        for a in range(kernel_shape[0]):\n",
        "            for b in range(kernel_shape[1]):\n",
        "                for i in range(filters_shape[0]):\n",
        "                    for j in range(filters_shape[1]):\n",
        "                        for alpha in range(K1.shape[1]):\n",
        "                            for beta in range(K2.shape[-1]):\n",
        "                                res[a, b, i, j] += K1[i, alpha] * K2[alpha, a, b, beta] * K3[beta, j]\n",
        "    elif len(kernel_shape) == 3:\n",
        "        for a in range(kernel_shape[0]):\n",
        "            for b in range(kernel_shape[1]):\n",
        "                for c in range(kernel_shape[2]):\n",
        "                    for i in range(filters_shape[0]):\n",
        "                        for j in range(filters_shape[1]):\n",
        "                            for alpha in range(K1.shape[1]):\n",
        "                                for beta in range(K2.shape[-1]):\n",
        "                                    res[a, b, c, i, j] += K1[i, alpha] * K2[alpha, a, b, c, beta] * K3[beta, j]\n",
        "    else:\n",
        "        raise ValueError(\"Only for 2D and 3D images.\")\n",
        "    return res"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee5KnbQ60Q6m"
      },
      "source": [
        "def check_funcs(rank, kernel_shape, filter_shape):\n",
        "    r1 = min(filter_shape[0], rank)\n",
        "    r2 = min(filter_shape[1], rank)\n",
        "    K1 = np.random.rand(*(filter_shape[0], r1))\n",
        "    K2 = np.random.rand(*((r1,) + kernel_shape + (r2,)))\n",
        "    K3 = np.random.rand(*(r2, filter_shape[1]))\n",
        "    clever_wrong = full_tt(K1, K2, K3)\n",
        "    simple_right = simple_full_tt(K1, K2, K3)\n",
        "    return np.allclose(clever_wrong, simple_right)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL76zZBw0-cN",
        "outputId": "a5aadfa5-b3e1-4883-94b5-59de6e57ae42"
      },
      "source": [
        "check_funcs(2, (2, 2), (2, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFhAZR1qDsH0",
        "outputId": "1e4737bd-02b5-450c-8426-8d53f7ea3e8f"
      },
      "source": [
        "check_funcs(2, (2, 2, 1), (2, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLMZGS2hDvbp",
        "outputId": "90ce43ac-0887-427a-ce5c-a65097073210"
      },
      "source": [
        "check_funcs(2, (2, 2, 2), (2, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWpcGgf627IK",
        "outputId": "8faec0b1-b0ce-4b6f-929b-d930d04217f1"
      },
      "source": [
        "check_funcs(4, (7, 7), (32, 32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8dTpq07DxzB",
        "outputId": "8f9f9b6f-22ac-4a0d-8b9a-6bb0c4d86646"
      },
      "source": [
        "check_funcs(4, (7, 7, 7), (32, 32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hggAxE9ZCzxW",
        "outputId": "2143a5f7-023e-450a-f92d-ebdf07f973c9"
      },
      "source": [
        "check_funcs(4, (7, 7), (16, 32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAJGqwRMD30K",
        "outputId": "7f59c4a1-2d17-4121-c754-1c8e86f97597"
      },
      "source": [
        "check_funcs(4, (5, 5, 5), (16, 32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqdcRao9_Wow",
        "outputId": "0c5d5821-2081-4168-dbfb-be71916709bc"
      },
      "source": [
        "check_funcs(2, (2, 1), (2, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xu6M4_K_Yn4",
        "outputId": "a0835ca7-50f8-4671-8842-5be700527a28"
      },
      "source": [
        "check_funcs(2, (2, 1), (1, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwmeKew9_bH6",
        "outputId": "dc007552-174f-4baa-8a47-4157c6f3f98d"
      },
      "source": [
        "check_funcs(2, (2, 2), (1, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKMDeM5N_ehF",
        "outputId": "a64f40d6-0127-4e1e-88f8-a9b92eb412f2"
      },
      "source": [
        "check_funcs(2, (2, 2), (2, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VafYm3spApBe",
        "outputId": "fdc8be22-13d3-49f5-a99d-4db6ac9e7179"
      },
      "source": [
        "check_funcs(17, (7, 7), (16, 32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIOsm1xkDbtG"
      },
      "source": [
        "### Свёрточный 2D слой с ТТ-разложением"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFkPELYHeWWk"
      },
      "source": [
        "def faster_memory(convolution_op, inputs, K1, K2, K3):\n",
        "    return convolution_op(inputs, full_tt(K1, K2, K3))\n",
        "\n",
        "def slower_without_memory(convolution_op, inputs, K1, K2, K3):\n",
        "    outputs = None\n",
        "    input_channels = K1.shape[0]\n",
        "    output_channels = K3.shape[1]\n",
        "    for j in range(output_channels):\n",
        "        j_outputs = None\n",
        "        for i in range(input_channels):\n",
        "            kernel = full_tt(K1[i:i + 1, :], K2, K3[:, j:j + 1])\n",
        "            if j_outputs == None:\n",
        "                j_outputs = convolution_op(inputs[:, :, :, i:i + 1], kernel)\n",
        "            else:\n",
        "                j_outputs += convolution_op(inputs[:, :, :, i:i + 1], kernel)\n",
        "        if outputs == None:\n",
        "            outputs = j_outputs\n",
        "        else:\n",
        "            outputs = tf.concat([outputs, j_outputs], -1)\n",
        "    return outputs"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvfRr94fi7Nr",
        "outputId": "86afe613-44c8-4278-cee0-a246033f044e"
      },
      "source": [
        "3 * 32 * 3 * 3"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "864"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFSLz-Y4i8Lk",
        "outputId": "208b4b46-4128-4779-cce2-4bd1f05db693"
      },
      "source": [
        "28 * 28"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwjwq1q3FtSB"
      },
      "source": [
        "class ConvDecomposed2D(tf.keras.layers.Conv2D):\n",
        "    def __init__(self,\n",
        "               filters,\n",
        "               kernel_size,\n",
        "               decomposition_rank,\n",
        "               use_memory=True,\n",
        "               use_memory_test = True,\n",
        "               strides=(1, 1),\n",
        "               padding='valid',\n",
        "               data_format=None,\n",
        "               dilation_rate=(1, 1),\n",
        "               activation=None,\n",
        "               use_bias=True,\n",
        "               kernel_initializer='glorot_uniform',\n",
        "               bias_initializer='zeros',\n",
        "               kernel_regularizer=None,\n",
        "               bias_regularizer=None,\n",
        "               activity_regularizer=None,\n",
        "               kernel_constraint=None,\n",
        "               bias_constraint=None,\n",
        "               **kwargs):\n",
        "        super(ConvDecomposed2D, self).__init__(\n",
        "               filters=filters,\n",
        "               kernel_size=kernel_size,\n",
        "               strides=strides,\n",
        "               padding=padding,\n",
        "               data_format=data_format,\n",
        "               dilation_rate=dilation_rate,\n",
        "               groups=1, # does not support groups!\n",
        "               activation=activation,\n",
        "               use_bias=use_bias,\n",
        "               kernel_initializer=kernel_initializer,\n",
        "               bias_initializer=bias_initializer,\n",
        "               kernel_regularizer=kernel_regularizer,\n",
        "               bias_regularizer=bias_regularizer,\n",
        "               activity_regularizer=activity_regularizer,\n",
        "               kernel_constraint=kernel_constraint,\n",
        "               bias_constraint=bias_constraint,\n",
        "               **kwargs)\n",
        "        self.decomposition_rank = decomposition_rank\n",
        "        self.K1 = None\n",
        "        self.K2 = None\n",
        "        self.K3 = None\n",
        "        self.bias = None\n",
        "        self._convolution_op = None\n",
        "        self.use_memory = use_memory # can be changed if we use too much memory in singular clipping anyway\n",
        "        self.use_memory_test = use_memory_test\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_shape = tf.TensorShape(input_shape).as_list()\n",
        "        if self.data_format == 'channels_last':\n",
        "            input_smth = input_shape[1:-1]\n",
        "        else:\n",
        "            input_smth = input_shape[2:]\n",
        "        input_shape = tensor_shape.TensorShape(input_shape)\n",
        "        input_channel = self._get_input_channel(input_shape)\n",
        "        r1 = min(input_channel, self.decomposition_rank)\n",
        "        r2 = min(self.filters, self.decomposition_rank)\n",
        "\n",
        "        if not self.use_memory:\n",
        "            big_kernel = input_channel * self.filters * self.kernel_size[0] * self.kernel_size[1]\n",
        "            padded_kernel = r1 * r2 * input_smth[0] * input_smth[1]\n",
        "            self.use_memory = (big_kernel < padded_kernel)\n",
        "    \n",
        "        self.K1 = self.add_weight(\n",
        "            name='K1',\n",
        "            shape=(input_channel, r1),\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "            trainable=True,\n",
        "            dtype=self.dtype)\n",
        "        self.K2 = self.add_weight(\n",
        "            name='K2',\n",
        "            shape=(r1,) + self.kernel_size + (r2,),\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "            trainable=True,\n",
        "            dtype=self.dtype)\n",
        "        self.K3 = self.add_weight(\n",
        "            name='K3',\n",
        "            shape=(r2, self.filters),\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "            trainable=True,\n",
        "            dtype=self.dtype)\n",
        "        \n",
        "        # the rest is copied from Conv build function\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "              name='bias',\n",
        "              shape=(self.filters,),\n",
        "              initializer=self.bias_initializer,\n",
        "              regularizer=self.bias_regularizer,\n",
        "              constraint=self.bias_constraint,\n",
        "              trainable=True,\n",
        "              dtype=self.dtype)\n",
        "        else:\n",
        "            self.bias = None\n",
        "        channel_axis = self._get_channel_axis()\n",
        "        self.input_spec = InputSpec(min_ndim=self.rank + 2,\n",
        "                                    axes={channel_axis: input_channel})\n",
        "    \n",
        "        # Convert Keras formats to TF native formats.\n",
        "        if self.padding == 'causal':\n",
        "            tf_padding = 'VALID'  # Causal padding handled in `call`.\n",
        "        elif isinstance(self.padding, six.string_types):\n",
        "            tf_padding = self.padding.upper()\n",
        "        else:\n",
        "            tf_padding = self.padding\n",
        "        tf_dilations = list(self.dilation_rate)\n",
        "        tf_strides = list(self.strides)\n",
        "    \n",
        "        tf_op_name = self.__class__.__name__\n",
        "        if tf_op_name == 'Conv1D':\n",
        "            tf_op_name = 'conv1d'  # Backwards compat.\n",
        "    \n",
        "        self._convolution_op = functools.partial(\n",
        "            nn_ops.convolution_v2,\n",
        "            strides=tf_strides,\n",
        "            padding=tf_padding,\n",
        "            dilations=tf_dilations,\n",
        "            data_format=self._tf_data_format,\n",
        "            name=tf_op_name)\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        if training and self.use_memory or not training and self.use_memory_test:\n",
        "            outputs = faster_memory(self._convolution_op, inputs, self.K1, self.K2, self.K3)\n",
        "        else:\n",
        "            outputs = slower_without_memory(self._convolution_op, inputs, self.K1, self.K2, self.K3)\n",
        "        if self.use_bias:\n",
        "            output_rank = outputs.shape.rank\n",
        "            if self.rank == 1 and self._channels_first:\n",
        "                # nn.bias_add does not accept a 1D input tensor.\n",
        "                bias = array_ops.reshape(self.bias, (1, self.filters, 1))\n",
        "                outputs += bias\n",
        "            else:\n",
        "                # Handle multiple batch dimensions.\n",
        "                if output_rank is not None and output_rank > 2 + self.rank:\n",
        "    \n",
        "                    def _apply_fn(o):\n",
        "                        return nn.bias_add(o, self.bias, data_format=self._tf_data_format)\n",
        "    \n",
        "                    outputs = nn_ops.squeeze_batch_dims(\n",
        "                      outputs, _apply_fn, inner_rank=self.rank + 1)\n",
        "                else:\n",
        "                    outputs = nn.bias_add(\n",
        "                      outputs, self.bias, data_format=self._tf_data_format)\n",
        "        if self.activation is not None:\n",
        "            return self.activation(outputs)\n",
        "        return outputs        "
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zcxk7OZMZiQU"
      },
      "source": [
        "### Проверка свёртки, занимающей меньше памяти"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwt0Dz9eZqqz"
      },
      "source": [
        "def check_funcs(rank, pic_size, kernel_shape, filter_shape):\n",
        "    r1 = min(filter_shape[0], rank)\n",
        "    r2 = min(filter_shape[1], rank)\n",
        "    inputs = np.random.rand(100, pic_size, pic_size, filter_shape[0])\n",
        "    K1 = np.random.rand(*(filter_shape[0], r1))\n",
        "    K2 = np.random.rand(*((r1,) + kernel_shape + (r2,)))\n",
        "    K3 = np.random.rand(*(r2, filter_shape[1]))\n",
        "    conv = ConvDecomposed2D(filter_shape[1], kernel_shape, rank,\n",
        "                            input_shape=(pic_size, pic_size, filter_shape[0]),\n",
        "                            data_format=\"channels_last\", activation='relu',\n",
        "                            padding='same')\n",
        "    conv.build(inputs.shape)\n",
        "    convolution_op = conv._convolution_op\n",
        "    simple_mem = faster_memory(convolution_op, inputs, K1, K2, K3)\n",
        "    slower_mem = slower_without_memory(convolution_op, inputs, K1, K2, K3)\n",
        "    return np.allclose(simple_mem, slower_mem)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wkgf745AceQ0",
        "outputId": "500e2517-56dc-4e05-fa5c-176bb8a68db9"
      },
      "source": [
        "check_funcs(10, 100, (1, 3), (32, 64))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3avRM0WeHU0",
        "outputId": "5c348d30-ef77-4900-e395-5df31694ff3e"
      },
      "source": [
        "check_funcs(1, 10, (3, 3), (5, 5))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSatFAHUVVZM"
      },
      "source": [
        "### Проверка работоспособности слоя на наборе данных из букв (одна из наших домашек)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfvhZ-l0rsUd"
      },
      "source": [
        "#### Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3tYiEG_VTGT",
        "outputId": "930f7122-ff2b-49c0-84ae-fc77b8a89db9"
      },
      "source": [
        "!wget http://yaroslavvb.com/upload/notMNIST/notMNIST_large.tar.gz\n",
        "!tar -xvf notMNIST_large.tar.gz >> /dev/null"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-21 10:31:57--  http://yaroslavvb.com/upload/notMNIST/notMNIST_large.tar.gz\n",
            "Resolving yaroslavvb.com (yaroslavvb.com)... 129.121.4.193\n",
            "Connecting to yaroslavvb.com (yaroslavvb.com)|129.121.4.193|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 247336696 (236M) [application/x-gzip]\n",
            "Saving to: ‘notMNIST_large.tar.gz’\n",
            "\n",
            "notMNIST_large.tar. 100%[===================>] 235.88M  71.6MB/s    in 3.5s    \n",
            "\n",
            "2021-05-21 10:32:00 (66.7 MB/s) - ‘notMNIST_large.tar.gz’ saved [247336696/247336696]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxgpV6QQVeQU"
      },
      "source": [
        "DATA_DIR = 'notMNIST_large/'"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo8NwEd7Vrcu"
      },
      "source": [
        "from glob import glob\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "for img_path in glob(f'{DATA_DIR}/**/*.png'):\n",
        "  try:\n",
        "    img = Image.open(img_path)\n",
        "  except:\n",
        "      os.remove(img_path)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "PAIaOAt4Vvji",
        "outputId": "27c69e76-4de6-4016-9afe-5c8853d6379b"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "plt.figure(figsize=(17,10))\n",
        "letter = 'A'\n",
        "img = cv2.imread(os.path.join(DATA_DIR, letter, os.listdir(f'{DATA_DIR}/{letter}/')[1]))\n",
        "plt.imshow(img)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc7a70e8f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1224x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v28-MI9WWPLn"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import image\n",
        "from keras.layers.core import Activation, Reshape, Dense, Flatten\n",
        "from keras.layers import Conv2D, MaxPool2D, InputLayer, BatchNormalization, Dropout, GlobalAveragePooling2D, GlobalMaxPool2D\n",
        "from keras.models import Model\n",
        "\n",
        "pic_size = 28\n",
        "n_classes = len(os.listdir(DATA_DIR))\n",
        "\n",
        "def build_model(decomposition_rank):\n",
        "    model = keras.Sequential([\n",
        "        ConvDecomposed2D(32, 3, decomposition_rank=decomposition_rank,\n",
        "                        input_shape=(pic_size, pic_size, 3),\n",
        "                            data_format=\"channels_last\", activation='relu',\n",
        "                            padding='same'),\n",
        "        keras.layers.MaxPooling2D(),\n",
        "        ConvDecomposed2D(32, 3, decomposition_rank=decomposition_rank,\n",
        "                        activation='relu', padding='same'),\n",
        "        keras.layers.MaxPooling2D(),\n",
        "        ConvDecomposed2D(16, 3, decomposition_rank=decomposition_rank,\n",
        "                        activation='relu', padding='same'),\n",
        "        keras.layers.MaxPooling2D(),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3EyzG5DWuER",
        "outputId": "622660b2-c708-4044-d797-3cbdeef52705"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Подсказка: train/val split удобно делать вот так https://stackoverflow.com/questions/53037510/can-flow-from-directory-get-train-and-validation-data-from-the-same-directory-in (самый залайканый ответ)\n",
        "\n",
        "\"\"\" Data generators initialization: for train and validation sets \"\"\"\n",
        "generator = ImageDataGenerator(validation_split=0.1, rescale=1./255)\n",
        "train_gen = generator.flow_from_directory(DATA_DIR,\n",
        "                                          target_size=(pic_size, pic_size),\n",
        "                                          class_mode='categorical',\n",
        "                                          subset='training', seed=1)\n",
        "val_gen = generator.flow_from_directory(DATA_DIR,\n",
        "                                        target_size=(pic_size, pic_size),\n",
        "                                        class_mode='categorical',\n",
        "                                        subset='validation', seed=1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 476205 images belonging to 10 classes.\n",
            "Found 52909 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmr9s-v4rJu8"
      },
      "source": [
        "#### Модель с обычными свёрточными слоями"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvWuVxCgjTTM",
        "outputId": "50df3909-9848-4a4c-d51a-a512876ce80c"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, 3, input_shape=(pic_size, pic_size, 3),\n",
        "                        data_format=\"channels_last\", activation='relu',\n",
        "                        padding='same'),\n",
        "    keras.layers.MaxPooling2D(),\n",
        "    keras.layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
        "    keras.layers.MaxPooling2D(),\n",
        "    keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
        "    keras.layers.MaxPooling2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(n_classes, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 16)          4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 144)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               18560     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 34,618\n",
            "Trainable params: 34,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzA9v2bEoWgE",
        "outputId": "adec3dd1-ce0a-4e26-deea-8cbb1fd1263a"
      },
      "source": [
        "step_size_train = (train_gen.n // train_gen.batch_size)\n",
        "step_size_valid = (val_gen.n // val_gen.batch_size)\n",
        "\n",
        "history2 = model.fit(train_gen, steps_per_epoch=step_size_train, epochs=2,\n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=step_size_valid)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "14881/14881 [==============================] - 151s 10ms/step - loss: 0.4498 - accuracy: 0.8662 - val_loss: 0.2711 - val_accuracy: 0.9167\n",
            "Epoch 2/2\n",
            "14881/14881 [==============================] - 150s 10ms/step - loss: 0.2821 - accuracy: 0.9135 - val_loss: 0.2310 - val_accuracy: 0.9290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRChluDlrVYz"
      },
      "source": [
        "#### decomposition_rank = 1 (with use_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUuo_lwPigPL",
        "outputId": "57135c69-3790-4fdb-97ec-9f075e14f45e"
      },
      "source": [
        "model1 = build_model(1) # the function was trivially changed for this"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_decomposed2d_29 (ConvDe (None, 28, 28, 32)        76        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_decomposed2d_30 (ConvDe (None, 14, 14, 32)        105       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv_decomposed2d_31 (ConvDe (None, 7, 7, 16)          73        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 3, 3, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 144)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               18560     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 20,104\n",
            "Trainable params: 20,104\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "lR4MyUYOburL",
        "outputId": "c7ece613-c227-45a5-91b2-e04c6904fd76"
      },
      "source": [
        "step_size_train = (train_gen.n // train_gen.batch_size)\n",
        "step_size_valid = (val_gen.n // val_gen.batch_size)\n",
        "\n",
        "history2 = model1.fit(train_gen, steps_per_epoch=step_size_train, epochs=2,\n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=step_size_valid)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            " 8742/14881 [================>.............] - ETA: 50:48 - loss: 0.8649 - accuracy: 0.7397"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-3a8f38c290a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m history2 = model1.fit(train_gen, steps_per_epoch=step_size_train, epochs=2,\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     validation_steps=step_size_valid)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIngu2bq9Pfg"
      },
      "source": [
        "Итог: придётся использовать дополнительную память."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l773vFkM9bCu"
      },
      "source": [
        "#### decomposition_rank = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAj3WXUl9kVU",
        "outputId": "11cc1670-bb3e-4333-fc83-9db75612dbd0"
      },
      "source": [
        "model1 = build_model(1)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_decomposed2d_35 (ConvDe (None, 28, 28, 32)        76        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_decomposed2d_36 (ConvDe (None, 14, 14, 32)        105       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv_decomposed2d_37 (ConvDe (None, 7, 7, 16)          73        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 3, 3, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 144)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               18560     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 20,104\n",
            "Trainable params: 20,104\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wlr03FR9mXL",
        "outputId": "9614c365-9e70-4ba3-c1a7-830a63ef684c"
      },
      "source": [
        "step_size_train = (train_gen.n // train_gen.batch_size)\n",
        "step_size_valid = (val_gen.n // val_gen.batch_size)\n",
        "\n",
        "history2 = model1.fit(train_gen, steps_per_epoch=step_size_train, epochs=2,\n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=step_size_valid)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "14881/14881 [==============================] - 240s 16ms/step - loss: 0.8630 - accuracy: 0.7283 - val_loss: 0.5215 - val_accuracy: 0.8399\n",
            "Epoch 2/2\n",
            "14881/14881 [==============================] - 172s 12ms/step - loss: 0.5716 - accuracy: 0.8235 - val_loss: 0.4917 - val_accuracy: 0.8486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3VcnSJ9rahO"
      },
      "source": [
        "#### decomposition_rank = 17"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhKMxgKSG0Jx",
        "outputId": "b52ddb63-698b-4fd0-a8dd-919827dcccc9"
      },
      "source": [
        "16 * 16 + 16 * 3 * 3 * 17 + 17 * 32 + 16 # bias"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3264"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxOR56Sji3XJ",
        "outputId": "0035c2eb-9f89-456b-b100-6a4c30c3aefb"
      },
      "source": [
        "model17 = build_model(17)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_decomposed2d_12 (ConvDe (None, 28, 28, 32)        1044      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_decomposed2d_13 (ConvDe (None, 14, 14, 32)        3721      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv_decomposed2d_14 (ConvDe (None, 7, 7, 16)          3264      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 3, 3, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 144)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               18560     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 27,879\n",
            "Trainable params: 27,879\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a5QMldUb09e",
        "outputId": "e5953394-4df7-4b79-c7a4-ffdd2d5ca98d"
      },
      "source": [
        "step_size_train = (train_gen.n // train_gen.batch_size)\n",
        "step_size_valid = (val_gen.n // val_gen.batch_size)\n",
        "\n",
        "history2 = model17.fit(train_gen, steps_per_epoch=step_size_train, epochs=2,\n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=step_size_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "14881/14881 [==============================] - 219s 15ms/step - loss: 0.4837 - accuracy: 0.8556 - val_loss: 0.2614 - val_accuracy: 0.9200\n",
            "Epoch 2/2\n",
            "14881/14881 [==============================] - 217s 15ms/step - loss: 0.2989 - accuracy: 0.9088 - val_loss: 0.2391 - val_accuracy: 0.9281\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
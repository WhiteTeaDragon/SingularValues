{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PerformanceExperimentsTT",
      "provenance": [],
      "collapsed_sections": [
        "Q2gf23x1rHE7",
        "FUSAJEF5zZCK",
        "EBFMbHvLIf5g",
        "npx7NtMb2D0_",
        "SYsweyOS3wPM",
        "Xq3bNGTuDGIm",
        "FO9ydg0YT2e2",
        "KgRj4CpUqu7P"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WhiteTeaDragon/SingularValues/blob/main/TT/PerformanceExperimentsTT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "praf7vwRHu5P"
      },
      "source": [
        "import functions\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWn7MN-iaAXi",
        "outputId": "010774e3-e2ad-4abb-8ce4-188feff674b5"
      },
      "source": [
        "import importlib\n",
        "importlib.reload(functions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'functions' from '/content/functions.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PBmtSgLffdr"
      },
      "source": [
        "Время на обучение у разных моделей может отличаться -- это происходит из-за того, что они обучались в разных сессиях Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwqz2XLi4WU7"
      },
      "source": [
        "def plot_final_graph(addition=\"\", third=True, ylim_loss=4, ylim_error=1):\n",
        "    history_no_clipping = pickle.load(open(addition + 'trainHistoryDict', \"rb\"))\n",
        "    history_05 = pickle.load(open(addition + 'trainHistoryDict_clip_05', \"rb\"))\n",
        "    if third:\n",
        "        history_1 = pickle.load(open(addition + 'trainHistoryDict_clip_1', \"rb\"))\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
        "    axs[0].grid(True)\n",
        "    axs[1].grid(True)\n",
        "    max_len = len(history_no_clipping['val_loss'])\n",
        "    axs[0].plot(history_no_clipping['val_loss'][4:max_len:5], label='no clipping')\n",
        "    axs[0].plot(history_05['val_loss'][4:max_len:5], label='0.5')\n",
        "    if third:\n",
        "        axs[0].plot(history_1['val_loss'][4:max_len:5], label='1')\n",
        "    axs[0].set_title('Loss')\n",
        "    axs[0].set_xlabel('Epochs')\n",
        "    axs[0].set_ylim(0, ylim_loss)\n",
        "    axs[1].plot(1 - np.array(history_no_clipping['val_acc'][4:max_len:5]), label='no clipping')\n",
        "    axs[1].plot(1 - np.array(history_05['val_acc'][4:max_len:5]), label='0.5')\n",
        "    if third:\n",
        "        axs[1].plot(1 - np.array(history_1['val_acc'][4:max_len:5]), label='1')\n",
        "    axs[1].set_title('Error')\n",
        "    axs[1].set_xlabel('Epochs')\n",
        "    axs[1].set_ylim(0, ylim_error)\n",
        "    axs[0].legend(loc='best')\n",
        "    axs[1].legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2gf23x1rHE7"
      },
      "source": [
        "### Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceD49furq4ux",
        "outputId": "2cb0048c-d10a-4cf3-b6e2-f7cb4c8e80ab"
      },
      "source": [
        "num_classes = 10\n",
        "\n",
        "# load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# if subtract pixel mean is enabled\n",
        "x_train_mean = np.mean(x_train, axis=0)\n",
        "x_train -= x_train_mean\n",
        "x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# convert class vectors to binary class matrices.\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUSAJEF5zZCK"
      },
      "source": [
        "### Without decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZVJDAmRzfzc"
      },
      "source": [
        "#### Model without clipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYSrjJb-1409",
        "outputId": "b18f0dc7-492b-4200-ff01-7fc9dd39afa0"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(input_shape)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 16)   2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 16)   0           activation[0][0]                 \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 16)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 16)   0           activation_2[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 16)   0           activation_4[0][0]               \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 16)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 16)   2320        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 16)   0           activation_6[0][0]               \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 16)   2320        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 32, 32, 16)   0           activation_8[0][0]               \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 16)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   4640        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 32)   544         activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 32)   0           conv2d_13[0][0]                  \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 32)   9248        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 32)   128         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 32)   0           activation_12[0][0]              \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 32)   9248        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 32)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 16, 16, 32)   0           activation_14[0][0]              \n",
            "                                                                 batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 32)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 32)   9248        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 32)   128         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 16, 16, 32)   0           activation_16[0][0]              \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 32)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 32)   9248        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 32)   128         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 32)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 32)   9248        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 16, 16, 32)   0           activation_18[0][0]              \n",
            "                                                                 batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 8, 64)     18496       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 64)     256         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8, 8, 64)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 8, 8, 64)     36928       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 8, 8, 64)     2112        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 8, 8, 64)     256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 8, 64)     0           conv2d_24[0][0]                  \n",
            "                                                                 batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 8, 64)     0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 8, 8, 64)     36928       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 8, 8, 64)     256         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 8, 8, 64)     0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 8, 8, 64)     36928       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 8, 8, 64)     256         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 8, 8, 64)     0           activation_22[0][0]              \n",
            "                                                                 batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 8, 8, 64)     0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 64)     36928       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 8, 8, 64)     256         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 8, 8, 64)     0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 64)     36928       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 8, 64)     0           activation_24[0][0]              \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 64)     0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 64)     36928       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 64)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 64)     36928       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 8, 8, 64)     0           activation_26[0][0]              \n",
            "                                                                 batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 64)     0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 64)     36928       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 64)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 64)     36928       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 8, 8, 64)     0           activation_28[0][0]              \n",
            "                                                                 batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 64)     0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 64)     0           activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 64)           0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           650         flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 470,218\n",
            "Trainable params: 467,946\n",
            "Non-trainable params: 2,272\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjID6DOf2F36",
        "outputId": "1efd5543-d1db-4765-ecc0-15b1005b7b44"
      },
      "source": [
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'simple_trainHistoryDict', steps_per_epoch=100,\n",
        "                       batch_size=100, epochs=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Epoch 1/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 41s 83ms/step - loss: 2.7917 - acc: 0.2219 - val_loss: 2.3573 - val_acc: 0.2291\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.22910, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.8881 - acc: 0.3917 - val_loss: 2.0455 - val_acc: 0.3656\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.22910 to 0.36560, saving model to /content/saved_models/cifar10_ResNet32v1_model.002.h5\n",
            "Epoch 3/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.7052 - acc: 0.4599 - val_loss: 2.1614 - val_acc: 0.3371\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.36560\n",
            "Epoch 4/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.6138 - acc: 0.5131 - val_loss: 1.8819 - val_acc: 0.4220\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.36560 to 0.42200, saving model to /content/saved_models/cifar10_ResNet32v1_model.004.h5\n",
            "Epoch 5/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.5030 - acc: 0.5427 - val_loss: 1.5544 - val_acc: 0.5389\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.42200 to 0.53890, saving model to /content/saved_models/cifar10_ResNet32v1_model.005.h5\n",
            "Epoch 6/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.4443 - acc: 0.5735 - val_loss: 2.3545 - val_acc: 0.3883\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.53890\n",
            "Epoch 7/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.3409 - acc: 0.6062 - val_loss: 1.8422 - val_acc: 0.4894\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.53890\n",
            "Epoch 8/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.2782 - acc: 0.6317 - val_loss: 2.1510 - val_acc: 0.4281\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.53890\n",
            "Epoch 9/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.2750 - acc: 0.6320 - val_loss: 2.0645 - val_acc: 0.4674\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.53890\n",
            "Epoch 10/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.2217 - acc: 0.6419 - val_loss: 1.6657 - val_acc: 0.5276\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.53890\n",
            "Epoch 11/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.1674 - acc: 0.6763 - val_loss: 1.5014 - val_acc: 0.5551\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.53890 to 0.55510, saving model to /content/saved_models/cifar10_ResNet32v1_model.011.h5\n",
            "Epoch 12/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.1179 - acc: 0.6789 - val_loss: 1.9582 - val_acc: 0.5055\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.55510\n",
            "Epoch 13/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.0905 - acc: 0.6958 - val_loss: 1.7686 - val_acc: 0.5308\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.55510\n",
            "Epoch 14/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.0857 - acc: 0.7006 - val_loss: 2.2155 - val_acc: 0.4995\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.55510\n",
            "Epoch 15/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.0401 - acc: 0.7178 - val_loss: 1.2924 - val_acc: 0.6301\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.55510 to 0.63010, saving model to /content/saved_models/cifar10_ResNet32v1_model.015.h5\n",
            "Epoch 16/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.0120 - acc: 0.7213 - val_loss: 1.0936 - val_acc: 0.6955\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.63010 to 0.69550, saving model to /content/saved_models/cifar10_ResNet32v1_model.016.h5\n",
            "Epoch 17/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.9839 - acc: 0.7299 - val_loss: 1.2644 - val_acc: 0.6521\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.69550\n",
            "Epoch 18/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9804 - acc: 0.7338 - val_loss: 1.4880 - val_acc: 0.5987\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.69550\n",
            "Epoch 19/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.9635 - acc: 0.7352 - val_loss: 1.5609 - val_acc: 0.5911\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.69550\n",
            "Epoch 20/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9496 - acc: 0.7411 - val_loss: 1.2798 - val_acc: 0.6422\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.69550\n",
            "Epoch 21/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.9427 - acc: 0.7443 - val_loss: 1.3395 - val_acc: 0.6167\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.69550\n",
            "Epoch 22/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.9248 - acc: 0.7502 - val_loss: 1.1253 - val_acc: 0.6956\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.69550 to 0.69560, saving model to /content/saved_models/cifar10_ResNet32v1_model.022.h5\n",
            "Epoch 23/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.9006 - acc: 0.7614 - val_loss: 1.3942 - val_acc: 0.6477\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.69560\n",
            "Epoch 24/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9245 - acc: 0.7488 - val_loss: 1.2264 - val_acc: 0.6819\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.69560\n",
            "Epoch 25/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8584 - acc: 0.7723 - val_loss: 2.2518 - val_acc: 0.5116\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.69560\n",
            "Epoch 26/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8688 - acc: 0.7654 - val_loss: 1.9974 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.69560\n",
            "Epoch 27/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8264 - acc: 0.7894 - val_loss: 1.0888 - val_acc: 0.7157\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.69560 to 0.71570, saving model to /content/saved_models/cifar10_ResNet32v1_model.027.h5\n",
            "Epoch 28/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8369 - acc: 0.7831 - val_loss: 1.0199 - val_acc: 0.7212\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.71570 to 0.72120, saving model to /content/saved_models/cifar10_ResNet32v1_model.028.h5\n",
            "Epoch 29/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8358 - acc: 0.7797 - val_loss: 1.1612 - val_acc: 0.6783\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.72120\n",
            "Epoch 30/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.8279 - acc: 0.7840 - val_loss: 1.5258 - val_acc: 0.6003\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.72120\n",
            "Epoch 31/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8344 - acc: 0.7854 - val_loss: 1.3518 - val_acc: 0.6287\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.72120\n",
            "Epoch 32/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8262 - acc: 0.7791 - val_loss: 1.2475 - val_acc: 0.6609\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.72120\n",
            "Epoch 33/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8167 - acc: 0.7864 - val_loss: 1.1745 - val_acc: 0.6987\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.72120\n",
            "Epoch 34/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7594 - acc: 0.8101 - val_loss: 0.9930 - val_acc: 0.7396\n",
            "\n",
            "Epoch 00034: val_acc improved from 0.72120 to 0.73960, saving model to /content/saved_models/cifar10_ResNet32v1_model.034.h5\n",
            "Epoch 35/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7827 - acc: 0.8033 - val_loss: 0.9648 - val_acc: 0.7471\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.73960 to 0.74710, saving model to /content/saved_models/cifar10_ResNet32v1_model.035.h5\n",
            "Epoch 36/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.7772 - acc: 0.7983 - val_loss: 1.2062 - val_acc: 0.6843\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.74710\n",
            "Epoch 37/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7632 - acc: 0.8054 - val_loss: 1.0416 - val_acc: 0.7114\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.74710\n",
            "Epoch 38/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.7672 - acc: 0.8077 - val_loss: 0.9819 - val_acc: 0.7333\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.74710\n",
            "Epoch 39/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7513 - acc: 0.8055 - val_loss: 1.0230 - val_acc: 0.7176\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.74710\n",
            "Epoch 40/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7381 - acc: 0.8110 - val_loss: 0.9133 - val_acc: 0.7546\n",
            "\n",
            "Epoch 00040: val_acc improved from 0.74710 to 0.75460, saving model to /content/saved_models/cifar10_ResNet32v1_model.040.h5\n",
            "Epoch 41/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7403 - acc: 0.8142 - val_loss: 1.0525 - val_acc: 0.7259\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.75460\n",
            "Epoch 42/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7462 - acc: 0.8073 - val_loss: 0.9765 - val_acc: 0.7513\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.75460\n",
            "Epoch 43/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7166 - acc: 0.8170 - val_loss: 1.1618 - val_acc: 0.6971\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.75460\n",
            "Epoch 44/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7271 - acc: 0.8185 - val_loss: 1.1486 - val_acc: 0.7115\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.75460\n",
            "Epoch 45/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6986 - acc: 0.8225 - val_loss: 1.0484 - val_acc: 0.7133\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.75460\n",
            "Epoch 46/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.7148 - acc: 0.8224 - val_loss: 0.9758 - val_acc: 0.7404\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.75460\n",
            "Epoch 47/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7076 - acc: 0.8225 - val_loss: 1.1730 - val_acc: 0.7137\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.75460\n",
            "Epoch 48/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6986 - acc: 0.8315 - val_loss: 0.9340 - val_acc: 0.7537\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.75460\n",
            "Epoch 49/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6911 - acc: 0.8283 - val_loss: 0.9484 - val_acc: 0.7501\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.75460\n",
            "Epoch 50/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6969 - acc: 0.8259 - val_loss: 1.1239 - val_acc: 0.6992\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.75460\n",
            "Epoch 51/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6651 - acc: 0.8352 - val_loss: 1.0633 - val_acc: 0.7376\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.75460\n",
            "Epoch 52/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6918 - acc: 0.8290 - val_loss: 1.7289 - val_acc: 0.5983\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.75460\n",
            "Epoch 53/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.7092 - acc: 0.8220 - val_loss: 0.9287 - val_acc: 0.7595\n",
            "\n",
            "Epoch 00053: val_acc improved from 0.75460 to 0.75950, saving model to /content/saved_models/cifar10_ResNet32v1_model.053.h5\n",
            "Epoch 54/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6614 - acc: 0.8382 - val_loss: 0.8823 - val_acc: 0.7569\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.75950\n",
            "Epoch 55/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6732 - acc: 0.8315 - val_loss: 0.9849 - val_acc: 0.7507\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.75950\n",
            "Epoch 56/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6568 - acc: 0.8379 - val_loss: 1.0759 - val_acc: 0.7228\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.75950\n",
            "Epoch 57/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6423 - acc: 0.8436 - val_loss: 0.7996 - val_acc: 0.7952\n",
            "\n",
            "Epoch 00057: val_acc improved from 0.75950 to 0.79520, saving model to /content/saved_models/cifar10_ResNet32v1_model.057.h5\n",
            "Epoch 58/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6656 - acc: 0.8365 - val_loss: 1.1049 - val_acc: 0.7299\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.79520\n",
            "Epoch 59/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6688 - acc: 0.8321 - val_loss: 1.1031 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.79520\n",
            "Epoch 60/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6562 - acc: 0.8358 - val_loss: 0.9279 - val_acc: 0.7509\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.79520\n",
            "Epoch 61/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6351 - acc: 0.8459 - val_loss: 0.8573 - val_acc: 0.7828\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.79520\n",
            "Epoch 62/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6722 - acc: 0.8383 - val_loss: 0.8526 - val_acc: 0.7857\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.79520\n",
            "Epoch 63/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6282 - acc: 0.8525 - val_loss: 1.1547 - val_acc: 0.7238\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.79520\n",
            "Epoch 64/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6216 - acc: 0.8509 - val_loss: 1.2750 - val_acc: 0.6902\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.79520\n",
            "Epoch 65/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6225 - acc: 0.8452 - val_loss: 0.9463 - val_acc: 0.7652\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.79520\n",
            "Epoch 66/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6105 - acc: 0.8559 - val_loss: 1.0440 - val_acc: 0.7389\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.79520\n",
            "Epoch 67/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6377 - acc: 0.8429 - val_loss: 0.9184 - val_acc: 0.7619\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.79520\n",
            "Epoch 68/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6319 - acc: 0.8482 - val_loss: 0.9735 - val_acc: 0.7557\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.79520\n",
            "Epoch 69/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6197 - acc: 0.8514 - val_loss: 0.9155 - val_acc: 0.7615\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.79520\n",
            "Epoch 70/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6120 - acc: 0.8591 - val_loss: 0.7543 - val_acc: 0.8140\n",
            "\n",
            "Epoch 00070: val_acc improved from 0.79520 to 0.81400, saving model to /content/saved_models/cifar10_ResNet32v1_model.070.h5\n",
            "Epoch 71/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5971 - acc: 0.8611 - val_loss: 0.8425 - val_acc: 0.7731\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.81400\n",
            "Epoch 72/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6074 - acc: 0.8568 - val_loss: 0.8468 - val_acc: 0.7850\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.81400\n",
            "Epoch 73/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5760 - acc: 0.8677 - val_loss: 0.8759 - val_acc: 0.7760\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.81400\n",
            "Epoch 74/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6146 - acc: 0.8532 - val_loss: 0.8554 - val_acc: 0.7742\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.81400\n",
            "Epoch 75/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6088 - acc: 0.8545 - val_loss: 0.8282 - val_acc: 0.7934\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.81400\n",
            "Epoch 76/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5966 - acc: 0.8554 - val_loss: 0.9090 - val_acc: 0.7688\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.81400\n",
            "Epoch 77/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5903 - acc: 0.8648 - val_loss: 0.7742 - val_acc: 0.8100\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.81400\n",
            "Epoch 78/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5912 - acc: 0.8579 - val_loss: 0.8025 - val_acc: 0.7937\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.81400\n",
            "Epoch 79/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5773 - acc: 0.8680 - val_loss: 0.9038 - val_acc: 0.7771\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.81400\n",
            "Epoch 80/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.5794 - acc: 0.8671 - val_loss: 1.0124 - val_acc: 0.7430\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.81400\n",
            "Epoch 81/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5986 - acc: 0.8608 - val_loss: 0.8916 - val_acc: 0.7776\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.81400\n",
            "Epoch 82/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5762 - acc: 0.8732 - val_loss: 0.7365 - val_acc: 0.8209\n",
            "\n",
            "Epoch 00082: val_acc improved from 0.81400 to 0.82090, saving model to /content/saved_models/cifar10_ResNet32v1_model.082.h5\n",
            "Epoch 83/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5882 - acc: 0.8599 - val_loss: 1.0098 - val_acc: 0.7403\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.82090\n",
            "Epoch 84/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5827 - acc: 0.8684 - val_loss: 0.9415 - val_acc: 0.7613\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.82090\n",
            "Epoch 85/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5644 - acc: 0.8680 - val_loss: 0.8748 - val_acc: 0.7851\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.82090\n",
            "Epoch 86/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5539 - acc: 0.8719 - val_loss: 0.9657 - val_acc: 0.7689\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.82090\n",
            "Epoch 87/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5804 - acc: 0.8656 - val_loss: 0.9822 - val_acc: 0.7619\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.82090\n",
            "Epoch 88/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5751 - acc: 0.8674 - val_loss: 0.9051 - val_acc: 0.7776\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.82090\n",
            "Epoch 89/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5549 - acc: 0.8748 - val_loss: 0.8442 - val_acc: 0.7955\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.82090\n",
            "Epoch 90/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5683 - acc: 0.8692 - val_loss: 1.1180 - val_acc: 0.7201\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.82090\n",
            "Epoch 91/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5652 - acc: 0.8732 - val_loss: 1.1057 - val_acc: 0.7166\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.82090\n",
            "Epoch 92/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5621 - acc: 0.8713 - val_loss: 0.9378 - val_acc: 0.7802\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.82090\n",
            "Epoch 93/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5689 - acc: 0.8691 - val_loss: 0.7497 - val_acc: 0.8035\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.82090\n",
            "Epoch 94/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5688 - acc: 0.8698 - val_loss: 1.3253 - val_acc: 0.7030\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.82090\n",
            "Epoch 95/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5558 - acc: 0.8699 - val_loss: 0.8225 - val_acc: 0.7998\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.82090\n",
            "Epoch 96/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5746 - acc: 0.8657 - val_loss: 1.3325 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.82090\n",
            "Epoch 97/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5341 - acc: 0.8841 - val_loss: 0.9161 - val_acc: 0.7655\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.82090\n",
            "Epoch 98/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5373 - acc: 0.8822 - val_loss: 1.0970 - val_acc: 0.7383\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.82090\n",
            "Epoch 99/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5248 - acc: 0.8869 - val_loss: 0.9046 - val_acc: 0.7894\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.82090\n",
            "Epoch 100/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5588 - acc: 0.8760 - val_loss: 1.0311 - val_acc: 0.7412\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.82090\n",
            "Epoch 101/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5630 - acc: 0.8715 - val_loss: 0.8098 - val_acc: 0.8020\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.82090\n",
            "Epoch 102/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5373 - acc: 0.8823 - val_loss: 0.7706 - val_acc: 0.8120\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.82090\n",
            "Epoch 103/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5653 - acc: 0.8721 - val_loss: 1.3472 - val_acc: 0.6967\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.82090\n",
            "Epoch 104/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5269 - acc: 0.8829 - val_loss: 0.8820 - val_acc: 0.7846\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.82090\n",
            "Epoch 105/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5453 - acc: 0.8758 - val_loss: 1.2220 - val_acc: 0.7181\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.82090\n",
            "Epoch 106/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5362 - acc: 0.8845 - val_loss: 0.8292 - val_acc: 0.7927\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.82090\n",
            "Epoch 107/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5491 - acc: 0.8788 - val_loss: 0.7816 - val_acc: 0.8091\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.82090\n",
            "Epoch 108/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5050 - acc: 0.8957 - val_loss: 0.9262 - val_acc: 0.7885\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.82090\n",
            "Epoch 109/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5302 - acc: 0.8863 - val_loss: 0.7075 - val_acc: 0.8296\n",
            "\n",
            "Epoch 00109: val_acc improved from 0.82090 to 0.82960, saving model to /content/saved_models/cifar10_ResNet32v1_model.109.h5\n",
            "Epoch 110/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5297 - acc: 0.8836 - val_loss: 0.7696 - val_acc: 0.8230\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.82960\n",
            "Epoch 111/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5269 - acc: 0.8808 - val_loss: 0.8664 - val_acc: 0.7837\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.82960\n",
            "Epoch 112/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5254 - acc: 0.8888 - val_loss: 0.7935 - val_acc: 0.8070\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.82960\n",
            "Epoch 113/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5228 - acc: 0.8916 - val_loss: 0.9615 - val_acc: 0.7609\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.82960\n",
            "Epoch 114/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5223 - acc: 0.8847 - val_loss: 0.8401 - val_acc: 0.7914\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.82960\n",
            "Epoch 115/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5179 - acc: 0.8894 - val_loss: 0.9835 - val_acc: 0.7684\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.82960\n",
            "Epoch 116/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5260 - acc: 0.8790 - val_loss: 0.9361 - val_acc: 0.7727\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.82960\n",
            "Epoch 117/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5447 - acc: 0.8812 - val_loss: 0.8277 - val_acc: 0.7964\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.82960\n",
            "Epoch 118/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5195 - acc: 0.8837 - val_loss: 0.8952 - val_acc: 0.7940\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.82960\n",
            "Epoch 119/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5145 - acc: 0.8891 - val_loss: 0.9242 - val_acc: 0.7765\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.82960\n",
            "Epoch 120/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5411 - acc: 0.8795 - val_loss: 0.8581 - val_acc: 0.7855\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.82960\n",
            "Epoch 121/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4897 - acc: 0.8982 - val_loss: 0.8325 - val_acc: 0.7953\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.82960\n",
            "Epoch 122/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5198 - acc: 0.8849 - val_loss: 0.9437 - val_acc: 0.7736\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.82960\n",
            "Epoch 123/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5209 - acc: 0.8873 - val_loss: 0.6966 - val_acc: 0.8291\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.82960\n",
            "Epoch 124/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4914 - acc: 0.8961 - val_loss: 0.8602 - val_acc: 0.7831\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.82960\n",
            "Epoch 125/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4789 - acc: 0.9040 - val_loss: 0.9890 - val_acc: 0.7588\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.82960\n",
            "Epoch 126/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5059 - acc: 0.8934 - val_loss: 1.1877 - val_acc: 0.7301\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.82960\n",
            "Epoch 127/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5032 - acc: 0.8927 - val_loss: 0.7272 - val_acc: 0.8276\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.82960\n",
            "Epoch 128/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5057 - acc: 0.8890 - val_loss: 0.8406 - val_acc: 0.7930\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.82960\n",
            "Epoch 129/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5083 - acc: 0.8893 - val_loss: 0.9669 - val_acc: 0.7580\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.82960\n",
            "Epoch 130/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5065 - acc: 0.8937 - val_loss: 0.9088 - val_acc: 0.7781\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.82960\n",
            "Epoch 131/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4956 - acc: 0.8935 - val_loss: 0.8971 - val_acc: 0.7866\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.82960\n",
            "Epoch 132/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5186 - acc: 0.8900 - val_loss: 1.0260 - val_acc: 0.7619\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.82960\n",
            "Epoch 133/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4906 - acc: 0.8940 - val_loss: 1.0400 - val_acc: 0.7622\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.82960\n",
            "Epoch 134/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.4809 - acc: 0.9007 - val_loss: 1.0715 - val_acc: 0.7609\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.82960\n",
            "Epoch 135/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4914 - acc: 0.8949 - val_loss: 0.7459 - val_acc: 0.8255\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.82960\n",
            "Epoch 136/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5035 - acc: 0.8890 - val_loss: 0.7743 - val_acc: 0.8150\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.82960\n",
            "Epoch 137/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4865 - acc: 0.9008 - val_loss: 0.7608 - val_acc: 0.8164\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.82960\n",
            "Epoch 138/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4812 - acc: 0.8983 - val_loss: 0.9314 - val_acc: 0.7780\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.82960\n",
            "Epoch 139/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5142 - acc: 0.8911 - val_loss: 0.8120 - val_acc: 0.8020\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.82960\n",
            "Epoch 140/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5089 - acc: 0.8908 - val_loss: 0.7798 - val_acc: 0.8084\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.82960\n",
            "Epoch 141/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4779 - acc: 0.9021 - val_loss: 0.9337 - val_acc: 0.7783\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.82960\n",
            "Epoch 142/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4869 - acc: 0.8981 - val_loss: 0.8430 - val_acc: 0.8041\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.82960\n",
            "Epoch 143/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4882 - acc: 0.8990 - val_loss: 0.8237 - val_acc: 0.8087\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.82960\n",
            "Epoch 144/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4785 - acc: 0.9018 - val_loss: 0.9233 - val_acc: 0.7832\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.82960\n",
            "Epoch 145/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4765 - acc: 0.9002 - val_loss: 1.1600 - val_acc: 0.7402\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.82960\n",
            "Epoch 146/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4901 - acc: 0.8928 - val_loss: 0.7021 - val_acc: 0.8317\n",
            "\n",
            "Epoch 00146: val_acc improved from 0.82960 to 0.83170, saving model to /content/saved_models/cifar10_ResNet32v1_model.146.h5\n",
            "Epoch 147/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4995 - acc: 0.8913 - val_loss: 0.7749 - val_acc: 0.8172\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.83170\n",
            "Epoch 148/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4732 - acc: 0.9042 - val_loss: 0.7311 - val_acc: 0.8245\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.83170\n",
            "Epoch 149/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4961 - acc: 0.8947 - val_loss: 0.8270 - val_acc: 0.8012\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.83170\n",
            "Epoch 150/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4734 - acc: 0.9026 - val_loss: 0.7302 - val_acc: 0.8274\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.83170\n",
            "Epoch 151/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4731 - acc: 0.9017 - val_loss: 0.8536 - val_acc: 0.7943\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.83170\n",
            "Epoch 152/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4983 - acc: 0.8927 - val_loss: 0.7299 - val_acc: 0.8291\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.83170\n",
            "Epoch 153/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4778 - acc: 0.9010 - val_loss: 0.8402 - val_acc: 0.7999\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.83170\n",
            "Epoch 154/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4681 - acc: 0.9032 - val_loss: 0.7196 - val_acc: 0.8288\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.83170\n",
            "Epoch 155/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4692 - acc: 0.9029 - val_loss: 0.8495 - val_acc: 0.8062\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.83170\n",
            "Epoch 156/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4677 - acc: 0.9046 - val_loss: 0.8068 - val_acc: 0.8127\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.83170\n",
            "Epoch 157/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4790 - acc: 0.8996 - val_loss: 0.9271 - val_acc: 0.7934\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.83170\n",
            "Epoch 158/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4873 - acc: 0.8995 - val_loss: 0.7201 - val_acc: 0.8386\n",
            "\n",
            "Epoch 00158: val_acc improved from 0.83170 to 0.83860, saving model to /content/saved_models/cifar10_ResNet32v1_model.158.h5\n",
            "Epoch 159/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4977 - acc: 0.8962 - val_loss: 0.7495 - val_acc: 0.8277\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.83860\n",
            "Epoch 160/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4959 - acc: 0.8978 - val_loss: 0.8236 - val_acc: 0.7985\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.83860\n",
            "Epoch 161/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4538 - acc: 0.9088 - val_loss: 0.8986 - val_acc: 0.7990\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.83860\n",
            "Epoch 162/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4625 - acc: 0.9080 - val_loss: 0.8518 - val_acc: 0.7915\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.83860\n",
            "Epoch 163/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4642 - acc: 0.9046 - val_loss: 0.9348 - val_acc: 0.7882\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.83860\n",
            "Epoch 164/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4658 - acc: 0.9070 - val_loss: 1.0637 - val_acc: 0.7704\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.83860\n",
            "Epoch 165/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4677 - acc: 0.9071 - val_loss: 0.8199 - val_acc: 0.8084\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.83860\n",
            "Epoch 166/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4765 - acc: 0.9042 - val_loss: 0.8807 - val_acc: 0.8067\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.83860\n",
            "Epoch 167/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4673 - acc: 0.9040 - val_loss: 0.7487 - val_acc: 0.8218\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.83860\n",
            "Epoch 168/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4513 - acc: 0.9088 - val_loss: 0.7737 - val_acc: 0.8245\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.83860\n",
            "Epoch 169/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4581 - acc: 0.9126 - val_loss: 0.7371 - val_acc: 0.8291\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.83860\n",
            "Epoch 170/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4495 - acc: 0.9091 - val_loss: 0.8816 - val_acc: 0.8043\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.83860\n",
            "Epoch 171/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4701 - acc: 0.9044 - val_loss: 0.6588 - val_acc: 0.8497\n",
            "\n",
            "Epoch 00171: val_acc improved from 0.83860 to 0.84970, saving model to /content/saved_models/cifar10_ResNet32v1_model.171.h5\n",
            "Epoch 172/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4610 - acc: 0.9040 - val_loss: 0.7604 - val_acc: 0.8282\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.84970\n",
            "Epoch 173/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4544 - acc: 0.9085 - val_loss: 0.8683 - val_acc: 0.8029\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.84970\n",
            "Epoch 174/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4669 - acc: 0.9134 - val_loss: 0.8301 - val_acc: 0.8103\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.84970\n",
            "Epoch 175/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4806 - acc: 0.9014 - val_loss: 0.7030 - val_acc: 0.8351\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.84970\n",
            "Epoch 176/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4697 - acc: 0.9025 - val_loss: 0.8812 - val_acc: 0.7968\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.84970\n",
            "Epoch 177/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4681 - acc: 0.9033 - val_loss: 0.8154 - val_acc: 0.8079\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.84970\n",
            "Epoch 178/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4693 - acc: 0.9051 - val_loss: 0.8587 - val_acc: 0.8034\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.84970\n",
            "Epoch 179/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4426 - acc: 0.9138 - val_loss: 0.9660 - val_acc: 0.7787\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.84970\n",
            "Epoch 180/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4440 - acc: 0.9144 - val_loss: 0.9526 - val_acc: 0.7892\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.84970\n",
            "Epoch 181/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4419 - acc: 0.9126 - val_loss: 0.7180 - val_acc: 0.8328\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.84970\n",
            "Epoch 182/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4610 - acc: 0.9087 - val_loss: 0.7263 - val_acc: 0.8292\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.84970\n",
            "Epoch 183/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4705 - acc: 0.9043 - val_loss: 0.8446 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.84970\n",
            "Epoch 184/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4466 - acc: 0.9106 - val_loss: 0.7262 - val_acc: 0.8328\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.84970\n",
            "Epoch 185/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4609 - acc: 0.9112 - val_loss: 0.6703 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00185: val_acc improved from 0.84970 to 0.85000, saving model to /content/saved_models/cifar10_ResNet32v1_model.185.h5\n",
            "Epoch 186/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4387 - acc: 0.9123 - val_loss: 0.8192 - val_acc: 0.8144\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.85000\n",
            "Epoch 187/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4553 - acc: 0.9111 - val_loss: 1.0692 - val_acc: 0.7623\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.85000\n",
            "Epoch 188/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4572 - acc: 0.9108 - val_loss: 0.8220 - val_acc: 0.8052\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.85000\n",
            "Epoch 189/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4495 - acc: 0.9137 - val_loss: 0.7167 - val_acc: 0.8391\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.85000\n",
            "Epoch 190/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4503 - acc: 0.9089 - val_loss: 0.8382 - val_acc: 0.8042\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.85000\n",
            "Epoch 191/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4474 - acc: 0.9151 - val_loss: 0.6204 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00191: val_acc improved from 0.85000 to 0.85810, saving model to /content/saved_models/cifar10_ResNet32v1_model.191.h5\n",
            "Epoch 192/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4498 - acc: 0.9143 - val_loss: 0.8123 - val_acc: 0.8079\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.85810\n",
            "Epoch 193/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4365 - acc: 0.9165 - val_loss: 0.6374 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00193: val_acc improved from 0.85810 to 0.86010, saving model to /content/saved_models/cifar10_ResNet32v1_model.193.h5\n",
            "Epoch 194/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4471 - acc: 0.9134 - val_loss: 0.6900 - val_acc: 0.8460\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.86010\n",
            "Epoch 195/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4484 - acc: 0.9120 - val_loss: 0.8432 - val_acc: 0.8099\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.86010\n",
            "Epoch 196/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4501 - acc: 0.9057 - val_loss: 0.7940 - val_acc: 0.8231\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.86010\n",
            "Epoch 197/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4460 - acc: 0.9086 - val_loss: 0.7361 - val_acc: 0.8226\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.86010\n",
            "Epoch 198/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4447 - acc: 0.9131 - val_loss: 0.7736 - val_acc: 0.8182\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.86010\n",
            "Epoch 199/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4606 - acc: 0.9075 - val_loss: 0.7063 - val_acc: 0.8369\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.86010\n",
            "Epoch 200/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4434 - acc: 0.9110 - val_loss: 0.7136 - val_acc: 0.8332\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.86010\n",
            "Epoch 201/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4494 - acc: 0.9067 - val_loss: 0.7989 - val_acc: 0.8190\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.86010\n",
            "Epoch 202/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4424 - acc: 0.9131 - val_loss: 0.7216 - val_acc: 0.8392\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.86010\n",
            "Epoch 203/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4397 - acc: 0.9100 - val_loss: 0.7417 - val_acc: 0.8380\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.86010\n",
            "Epoch 204/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4593 - acc: 0.9071 - val_loss: 0.7866 - val_acc: 0.8113\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.86010\n",
            "Epoch 205/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4590 - acc: 0.9113 - val_loss: 0.8348 - val_acc: 0.7975\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.86010\n",
            "Epoch 206/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4383 - acc: 0.9119 - val_loss: 1.0811 - val_acc: 0.7607\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.86010\n",
            "Epoch 207/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4593 - acc: 0.9031 - val_loss: 0.8669 - val_acc: 0.7993\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.86010\n",
            "Epoch 208/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4427 - acc: 0.9110 - val_loss: 0.7251 - val_acc: 0.8355\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.86010\n",
            "Epoch 209/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4531 - acc: 0.9112 - val_loss: 0.6023 - val_acc: 0.8655\n",
            "\n",
            "Epoch 00209: val_acc improved from 0.86010 to 0.86550, saving model to /content/saved_models/cifar10_ResNet32v1_model.209.h5\n",
            "Epoch 210/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4415 - acc: 0.9203 - val_loss: 0.6972 - val_acc: 0.8403\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.86550\n",
            "Epoch 211/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4659 - acc: 0.9029 - val_loss: 0.6098 - val_acc: 0.8633\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.86550\n",
            "Epoch 212/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4302 - acc: 0.9149 - val_loss: 0.7294 - val_acc: 0.8327\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.86550\n",
            "Epoch 213/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4279 - acc: 0.9198 - val_loss: 0.7086 - val_acc: 0.8465\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.86550\n",
            "Epoch 214/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4285 - acc: 0.9154 - val_loss: 0.7279 - val_acc: 0.8394\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.86550\n",
            "Epoch 215/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4193 - acc: 0.9224 - val_loss: 0.7462 - val_acc: 0.8335\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.86550\n",
            "Epoch 216/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4281 - acc: 0.9153 - val_loss: 0.7239 - val_acc: 0.8391\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.86550\n",
            "Epoch 217/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4456 - acc: 0.9100 - val_loss: 0.8837 - val_acc: 0.8055\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.86550\n",
            "Epoch 218/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4479 - acc: 0.9143 - val_loss: 0.7663 - val_acc: 0.8259\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.86550\n",
            "Epoch 219/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4367 - acc: 0.9168 - val_loss: 0.7876 - val_acc: 0.8261\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.86550\n",
            "Epoch 220/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4143 - acc: 0.9267 - val_loss: 0.6897 - val_acc: 0.8408\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.86550\n",
            "Epoch 221/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4466 - acc: 0.9133 - val_loss: 1.0710 - val_acc: 0.7682\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.86550\n",
            "Epoch 222/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4437 - acc: 0.9121 - val_loss: 1.0323 - val_acc: 0.7762\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.86550\n",
            "Epoch 223/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4357 - acc: 0.9167 - val_loss: 0.7241 - val_acc: 0.8345\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.86550\n",
            "Epoch 224/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4350 - acc: 0.9209 - val_loss: 1.1035 - val_acc: 0.7658\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.86550\n",
            "Epoch 225/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4199 - acc: 0.9222 - val_loss: 0.6989 - val_acc: 0.8348\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.86550\n",
            "Epoch 226/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4383 - acc: 0.9162 - val_loss: 0.9680 - val_acc: 0.7969\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.86550\n",
            "Epoch 227/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4209 - acc: 0.9233 - val_loss: 0.7857 - val_acc: 0.8209\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.86550\n",
            "Epoch 228/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4177 - acc: 0.9246 - val_loss: 0.8170 - val_acc: 0.8146\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.86550\n",
            "Epoch 229/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4326 - acc: 0.9155 - val_loss: 0.8537 - val_acc: 0.8159\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.86550\n",
            "Epoch 230/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4303 - acc: 0.9205 - val_loss: 0.6620 - val_acc: 0.8585\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.86550\n",
            "Epoch 231/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4255 - acc: 0.9204 - val_loss: 0.6730 - val_acc: 0.8485\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.86550\n",
            "Epoch 232/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4182 - acc: 0.9226 - val_loss: 0.9119 - val_acc: 0.7989\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.86550\n",
            "Epoch 233/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4563 - acc: 0.9088 - val_loss: 0.8876 - val_acc: 0.8038\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.86550\n",
            "Epoch 234/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4277 - acc: 0.9195 - val_loss: 0.8444 - val_acc: 0.8043\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.86550\n",
            "Epoch 235/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4420 - acc: 0.9117 - val_loss: 0.6828 - val_acc: 0.8419\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.86550\n",
            "Epoch 236/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4291 - acc: 0.9182 - val_loss: 1.0152 - val_acc: 0.7731\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.86550\n",
            "Epoch 237/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4258 - acc: 0.9204 - val_loss: 0.7825 - val_acc: 0.8184\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.86550\n",
            "Epoch 238/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4218 - acc: 0.9190 - val_loss: 0.8518 - val_acc: 0.8235\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.86550\n",
            "Epoch 239/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4398 - acc: 0.9141 - val_loss: 0.6856 - val_acc: 0.8474\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.86550\n",
            "Epoch 240/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4159 - acc: 0.9224 - val_loss: 0.6561 - val_acc: 0.8541\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.86550\n",
            "Epoch 241/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4400 - acc: 0.9137 - val_loss: 0.8374 - val_acc: 0.8102\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.86550\n",
            "Epoch 242/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4258 - acc: 0.9191 - val_loss: 0.6482 - val_acc: 0.8538\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.86550\n",
            "Epoch 243/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4199 - acc: 0.9204 - val_loss: 0.7434 - val_acc: 0.8358\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.86550\n",
            "Epoch 244/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4353 - acc: 0.9118 - val_loss: 0.8859 - val_acc: 0.7981\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.86550\n",
            "Epoch 245/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4211 - acc: 0.9212 - val_loss: 0.7258 - val_acc: 0.8387\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.86550\n",
            "Epoch 246/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4151 - acc: 0.9219 - val_loss: 0.7559 - val_acc: 0.8278\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.86550\n",
            "Epoch 247/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4248 - acc: 0.9230 - val_loss: 1.0486 - val_acc: 0.7895\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.86550\n",
            "Epoch 248/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4077 - acc: 0.9270 - val_loss: 0.7507 - val_acc: 0.8370\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.86550\n",
            "Epoch 249/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4250 - acc: 0.9222 - val_loss: 0.8364 - val_acc: 0.8136\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.86550\n",
            "Epoch 250/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4193 - acc: 0.9211 - val_loss: 0.6665 - val_acc: 0.8502\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.86550\n",
            "Epoch 251/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4284 - acc: 0.9177 - val_loss: 0.6926 - val_acc: 0.8426\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.86550\n",
            "Epoch 252/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4220 - acc: 0.9218 - val_loss: 0.7518 - val_acc: 0.8228\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.86550\n",
            "Epoch 253/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4452 - acc: 0.9135 - val_loss: 0.6986 - val_acc: 0.8528\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.86550\n",
            "Epoch 254/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4274 - acc: 0.9178 - val_loss: 0.7380 - val_acc: 0.8436\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.86550\n",
            "Epoch 255/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4267 - acc: 0.9178 - val_loss: 0.8221 - val_acc: 0.8115\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.86550\n",
            "Epoch 256/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4229 - acc: 0.9203 - val_loss: 0.7467 - val_acc: 0.8365\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.86550\n",
            "Epoch 257/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4163 - acc: 0.9224 - val_loss: 0.6297 - val_acc: 0.8641\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.86550\n",
            "Epoch 258/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4078 - acc: 0.9276 - val_loss: 0.9440 - val_acc: 0.7851\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.86550\n",
            "Epoch 259/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4297 - acc: 0.9146 - val_loss: 0.7340 - val_acc: 0.8426\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.86550\n",
            "Epoch 260/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4127 - acc: 0.9217 - val_loss: 0.8861 - val_acc: 0.8107\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.86550\n",
            "Epoch 261/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4294 - acc: 0.9183 - val_loss: 0.7869 - val_acc: 0.8248\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.86550\n",
            "Epoch 262/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4129 - acc: 0.9248 - val_loss: 0.8131 - val_acc: 0.8160\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.86550\n",
            "Epoch 263/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4113 - acc: 0.9243 - val_loss: 0.9338 - val_acc: 0.8025\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.86550\n",
            "Epoch 264/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4060 - acc: 0.9274 - val_loss: 0.6378 - val_acc: 0.8582\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.86550\n",
            "Epoch 265/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4265 - acc: 0.9205 - val_loss: 0.7049 - val_acc: 0.8459\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.86550\n",
            "Epoch 266/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4258 - acc: 0.9196 - val_loss: 0.9061 - val_acc: 0.7979\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.86550\n",
            "Epoch 267/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4216 - acc: 0.9210 - val_loss: 0.8370 - val_acc: 0.8155\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.86550\n",
            "Epoch 268/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4209 - acc: 0.9209 - val_loss: 0.9583 - val_acc: 0.7982\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.86550\n",
            "Epoch 269/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4204 - acc: 0.9198 - val_loss: 0.8543 - val_acc: 0.8028\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.86550\n",
            "Epoch 270/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4099 - acc: 0.9235 - val_loss: 0.8079 - val_acc: 0.8212\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.86550\n",
            "Epoch 271/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4248 - acc: 0.9201 - val_loss: 0.7229 - val_acc: 0.8410\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.86550\n",
            "Epoch 272/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4199 - acc: 0.9193 - val_loss: 0.6114 - val_acc: 0.8690\n",
            "\n",
            "Epoch 00272: val_acc improved from 0.86550 to 0.86900, saving model to /content/saved_models/cifar10_ResNet32v1_model.272.h5\n",
            "Epoch 273/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4211 - acc: 0.9191 - val_loss: 0.8919 - val_acc: 0.7899\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.86900\n",
            "Epoch 274/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4062 - acc: 0.9273 - val_loss: 0.6616 - val_acc: 0.8579\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.86900\n",
            "Epoch 275/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4137 - acc: 0.9248 - val_loss: 0.6413 - val_acc: 0.8604\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.86900\n",
            "Epoch 276/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4093 - acc: 0.9234 - val_loss: 0.7534 - val_acc: 0.8334\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.86900\n",
            "Epoch 277/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4209 - acc: 0.9231 - val_loss: 0.9096 - val_acc: 0.8024\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.86900\n",
            "Epoch 278/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4131 - acc: 0.9240 - val_loss: 0.7036 - val_acc: 0.8453\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.86900\n",
            "Epoch 279/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4039 - acc: 0.9259 - val_loss: 0.6245 - val_acc: 0.8635\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.86900\n",
            "Epoch 280/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4256 - acc: 0.9222 - val_loss: 0.6674 - val_acc: 0.8481\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.86900\n",
            "Epoch 281/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4053 - acc: 0.9273 - val_loss: 0.7677 - val_acc: 0.8260\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.86900\n",
            "Epoch 282/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4122 - acc: 0.9267 - val_loss: 0.7833 - val_acc: 0.8266\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.86900\n",
            "Epoch 283/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4147 - acc: 0.9209 - val_loss: 0.8242 - val_acc: 0.8152\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.86900\n",
            "Epoch 284/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4052 - acc: 0.9254 - val_loss: 0.6536 - val_acc: 0.8626\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.86900\n",
            "Epoch 285/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4244 - acc: 0.9199 - val_loss: 0.8916 - val_acc: 0.8071\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.86900\n",
            "Epoch 286/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4033 - acc: 0.9260 - val_loss: 0.6169 - val_acc: 0.8680\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.86900\n",
            "Epoch 287/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3905 - acc: 0.9354 - val_loss: 0.7379 - val_acc: 0.8289\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.86900\n",
            "Epoch 288/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4108 - acc: 0.9282 - val_loss: 0.7330 - val_acc: 0.8370\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.86900\n",
            "Epoch 289/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4220 - acc: 0.9227 - val_loss: 0.8740 - val_acc: 0.8187\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.86900\n",
            "Epoch 290/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3964 - acc: 0.9316 - val_loss: 0.8740 - val_acc: 0.8039\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.86900\n",
            "Epoch 291/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4302 - acc: 0.9166 - val_loss: 0.8048 - val_acc: 0.8341\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.86900\n",
            "Epoch 292/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4063 - acc: 0.9241 - val_loss: 0.6558 - val_acc: 0.8621\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.86900\n",
            "Epoch 293/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4190 - acc: 0.9212 - val_loss: 0.7952 - val_acc: 0.8353\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.86900\n",
            "Epoch 294/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4065 - acc: 0.9286 - val_loss: 0.9838 - val_acc: 0.7820\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.86900\n",
            "Epoch 295/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4098 - acc: 0.9282 - val_loss: 0.8247 - val_acc: 0.8179\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.86900\n",
            "Epoch 296/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4102 - acc: 0.9252 - val_loss: 0.6500 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.86900\n",
            "Epoch 297/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3929 - acc: 0.9299 - val_loss: 0.6600 - val_acc: 0.8557\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.86900\n",
            "Epoch 298/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4218 - acc: 0.9193 - val_loss: 0.6776 - val_acc: 0.8573\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.86900\n",
            "Epoch 299/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4293 - acc: 0.9166 - val_loss: 0.7496 - val_acc: 0.8328\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.86900\n",
            "Epoch 300/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3890 - acc: 0.9317 - val_loss: 0.7389 - val_acc: 0.8335\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.86900\n",
            "Epoch 301/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4018 - acc: 0.9297 - val_loss: 0.7384 - val_acc: 0.8349\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.86900\n",
            "Epoch 302/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4055 - acc: 0.9265 - val_loss: 0.7357 - val_acc: 0.8402\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.86900\n",
            "Epoch 303/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4211 - acc: 0.9225 - val_loss: 0.5812 - val_acc: 0.8761\n",
            "\n",
            "Epoch 00303: val_acc improved from 0.86900 to 0.87610, saving model to /content/saved_models/cifar10_ResNet32v1_model.303.h5\n",
            "Epoch 304/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3940 - acc: 0.9309 - val_loss: 0.6540 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.87610\n",
            "Epoch 305/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4045 - acc: 0.9252 - val_loss: 0.8987 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.87610\n",
            "Epoch 306/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4109 - acc: 0.9262 - val_loss: 0.9759 - val_acc: 0.7995\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.87610\n",
            "Epoch 307/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4194 - acc: 0.9228 - val_loss: 0.7730 - val_acc: 0.8303\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.87610\n",
            "Epoch 308/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4288 - acc: 0.9192 - val_loss: 0.8661 - val_acc: 0.8134\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.87610\n",
            "Epoch 309/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4032 - acc: 0.9238 - val_loss: 0.7824 - val_acc: 0.8243\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.87610\n",
            "Epoch 310/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4014 - acc: 0.9280 - val_loss: 0.6714 - val_acc: 0.8483\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.87610\n",
            "Epoch 311/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3916 - acc: 0.9319 - val_loss: 0.6655 - val_acc: 0.8570\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.87610\n",
            "Epoch 312/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4062 - acc: 0.9296 - val_loss: 0.7274 - val_acc: 0.8394\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.87610\n",
            "Epoch 313/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3995 - acc: 0.9283 - val_loss: 0.8081 - val_acc: 0.8247\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.87610\n",
            "Epoch 314/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4084 - acc: 0.9260 - val_loss: 0.6616 - val_acc: 0.8569\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.87610\n",
            "Epoch 315/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4286 - acc: 0.9202 - val_loss: 0.6767 - val_acc: 0.8519\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.87610\n",
            "Epoch 316/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4058 - acc: 0.9233 - val_loss: 0.7170 - val_acc: 0.8390\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.87610\n",
            "Epoch 317/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4041 - acc: 0.9268 - val_loss: 0.7393 - val_acc: 0.8402\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.87610\n",
            "Epoch 318/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4051 - acc: 0.9244 - val_loss: 0.7704 - val_acc: 0.8386\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.87610\n",
            "Epoch 319/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3993 - acc: 0.9303 - val_loss: 0.7250 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.87610\n",
            "Epoch 320/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3967 - acc: 0.9294 - val_loss: 0.6212 - val_acc: 0.8671\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.87610\n",
            "Epoch 321/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4090 - acc: 0.9271 - val_loss: 0.7982 - val_acc: 0.8268\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.87610\n",
            "Epoch 322/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4062 - acc: 0.9286 - val_loss: 1.0962 - val_acc: 0.7685\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.87610\n",
            "Epoch 323/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4119 - acc: 0.9212 - val_loss: 0.7772 - val_acc: 0.8372\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.87610\n",
            "Epoch 324/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3956 - acc: 0.9279 - val_loss: 0.7862 - val_acc: 0.8282\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.87610\n",
            "Epoch 325/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3934 - acc: 0.9316 - val_loss: 0.6037 - val_acc: 0.8733\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.87610\n",
            "Epoch 326/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4120 - acc: 0.9258 - val_loss: 0.6404 - val_acc: 0.8621\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.87610\n",
            "Epoch 327/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4028 - acc: 0.9275 - val_loss: 0.6496 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.87610\n",
            "Epoch 328/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3904 - acc: 0.9321 - val_loss: 0.7076 - val_acc: 0.8561\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.87610\n",
            "Epoch 329/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3965 - acc: 0.9279 - val_loss: 0.9304 - val_acc: 0.8078\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.87610\n",
            "Epoch 330/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4102 - acc: 0.9238 - val_loss: 0.7075 - val_acc: 0.8351\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.87610\n",
            "Epoch 331/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3874 - acc: 0.9345 - val_loss: 0.6343 - val_acc: 0.8608\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.87610\n",
            "Epoch 332/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4024 - acc: 0.9275 - val_loss: 0.8051 - val_acc: 0.8257\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.87610\n",
            "Epoch 333/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3974 - acc: 0.9274 - val_loss: 0.6907 - val_acc: 0.8527\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.87610\n",
            "Epoch 334/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4089 - acc: 0.9235 - val_loss: 0.6992 - val_acc: 0.8460\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.87610\n",
            "Epoch 335/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3878 - acc: 0.9308 - val_loss: 0.8030 - val_acc: 0.8258\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.87610\n",
            "Epoch 336/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4027 - acc: 0.9302 - val_loss: 0.6839 - val_acc: 0.8459\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.87610\n",
            "Epoch 337/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3942 - acc: 0.9292 - val_loss: 0.9495 - val_acc: 0.8070\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.87610\n",
            "Epoch 338/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3972 - acc: 0.9277 - val_loss: 0.8858 - val_acc: 0.8087\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.87610\n",
            "Epoch 339/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4033 - acc: 0.9250 - val_loss: 0.7892 - val_acc: 0.8279\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.87610\n",
            "Epoch 340/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4085 - acc: 0.9278 - val_loss: 0.6984 - val_acc: 0.8452\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.87610\n",
            "Epoch 341/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3877 - acc: 0.9334 - val_loss: 0.7476 - val_acc: 0.8340\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.87610\n",
            "Epoch 342/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4124 - acc: 0.9227 - val_loss: 0.5957 - val_acc: 0.8746\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.87610\n",
            "Epoch 343/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3835 - acc: 0.9338 - val_loss: 0.6549 - val_acc: 0.8647\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.87610\n",
            "Epoch 344/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3840 - acc: 0.9348 - val_loss: 0.6656 - val_acc: 0.8564\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.87610\n",
            "Epoch 345/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3928 - acc: 0.9344 - val_loss: 0.8340 - val_acc: 0.8188\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.87610\n",
            "Epoch 346/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3858 - acc: 0.9328 - val_loss: 0.9548 - val_acc: 0.7966\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.87610\n",
            "Epoch 347/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3900 - acc: 0.9336 - val_loss: 0.6740 - val_acc: 0.8579\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.87610\n",
            "Epoch 348/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3869 - acc: 0.9326 - val_loss: 0.6302 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.87610\n",
            "Epoch 349/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4021 - acc: 0.9307 - val_loss: 0.6634 - val_acc: 0.8610\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.87610\n",
            "Epoch 350/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3923 - acc: 0.9352 - val_loss: 0.9078 - val_acc: 0.7977\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.87610\n",
            "Epoch 351/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4107 - acc: 0.9233 - val_loss: 0.7160 - val_acc: 0.8532\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.87610\n",
            "Epoch 352/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4034 - acc: 0.9261 - val_loss: 0.8320 - val_acc: 0.8162\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.87610\n",
            "Epoch 353/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3990 - acc: 0.9253 - val_loss: 0.7263 - val_acc: 0.8394\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.87610\n",
            "Epoch 354/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3888 - acc: 0.9346 - val_loss: 0.6705 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.87610\n",
            "Epoch 355/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3903 - acc: 0.9281 - val_loss: 0.9279 - val_acc: 0.8021\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.87610\n",
            "Epoch 356/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3859 - acc: 0.9307 - val_loss: 0.9692 - val_acc: 0.7914\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.87610\n",
            "Epoch 357/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3984 - acc: 0.9289 - val_loss: 0.6689 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.87610\n",
            "Epoch 358/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3836 - acc: 0.9345 - val_loss: 0.6116 - val_acc: 0.8653\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.87610\n",
            "Epoch 359/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3920 - acc: 0.9290 - val_loss: 0.8064 - val_acc: 0.8290\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.87610\n",
            "Epoch 360/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3975 - acc: 0.9303 - val_loss: 0.9404 - val_acc: 0.8059\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.87610\n",
            "Epoch 361/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3826 - acc: 0.9348 - val_loss: 0.7362 - val_acc: 0.8415\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.87610\n",
            "Epoch 362/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3835 - acc: 0.9349 - val_loss: 0.7913 - val_acc: 0.8265\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.87610\n",
            "Epoch 363/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4075 - acc: 0.9226 - val_loss: 0.6932 - val_acc: 0.8446\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.87610\n",
            "Epoch 364/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4175 - acc: 0.9244 - val_loss: 0.6743 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.87610\n",
            "Epoch 365/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3941 - acc: 0.9283 - val_loss: 0.6941 - val_acc: 0.8541\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.87610\n",
            "Epoch 366/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3858 - acc: 0.9325 - val_loss: 0.7486 - val_acc: 0.8320\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.87610\n",
            "Epoch 367/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4006 - acc: 0.9300 - val_loss: 0.7177 - val_acc: 0.8468\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.87610\n",
            "Epoch 368/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3900 - acc: 0.9329 - val_loss: 0.6551 - val_acc: 0.8657\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.87610\n",
            "Epoch 369/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3763 - acc: 0.9356 - val_loss: 0.6471 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.87610\n",
            "Epoch 370/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3754 - acc: 0.9374 - val_loss: 0.8011 - val_acc: 0.8410\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.87610\n",
            "Epoch 371/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3758 - acc: 0.9354 - val_loss: 0.8980 - val_acc: 0.8016\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.87610\n",
            "Epoch 372/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3899 - acc: 0.9300 - val_loss: 0.9133 - val_acc: 0.8018\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.87610\n",
            "Epoch 373/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3807 - acc: 0.9351 - val_loss: 0.7631 - val_acc: 0.8254\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.87610\n",
            "Epoch 374/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3905 - acc: 0.9301 - val_loss: 0.6738 - val_acc: 0.8633\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.87610\n",
            "Epoch 375/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3924 - acc: 0.9285 - val_loss: 0.5876 - val_acc: 0.8767\n",
            "\n",
            "Epoch 00375: val_acc improved from 0.87610 to 0.87670, saving model to /content/saved_models/cifar10_ResNet32v1_model.375.h5\n",
            "Epoch 376/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3895 - acc: 0.9340 - val_loss: 0.8150 - val_acc: 0.8214\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.87670\n",
            "Epoch 377/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3944 - acc: 0.9339 - val_loss: 0.7022 - val_acc: 0.8507\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.87670\n",
            "Epoch 378/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4037 - acc: 0.9253 - val_loss: 0.7304 - val_acc: 0.8461\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.87670\n",
            "Epoch 379/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3957 - acc: 0.9255 - val_loss: 0.8451 - val_acc: 0.8169\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.87670\n",
            "Epoch 380/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3855 - acc: 0.9304 - val_loss: 0.7484 - val_acc: 0.8373\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.87670\n",
            "Epoch 381/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4016 - acc: 0.9312 - val_loss: 0.8304 - val_acc: 0.8277\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.87670\n",
            "Epoch 382/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3944 - acc: 0.9282 - val_loss: 0.6126 - val_acc: 0.8750\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.87670\n",
            "Epoch 383/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3855 - acc: 0.9291 - val_loss: 0.7216 - val_acc: 0.8457\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.87670\n",
            "Epoch 384/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4017 - acc: 0.9316 - val_loss: 0.7278 - val_acc: 0.8428\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.87670\n",
            "Epoch 385/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3739 - acc: 0.9340 - val_loss: 0.7416 - val_acc: 0.8388\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.87670\n",
            "Epoch 386/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3953 - acc: 0.9314 - val_loss: 0.6210 - val_acc: 0.8680\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.87670\n",
            "Epoch 387/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3898 - acc: 0.9332 - val_loss: 0.6925 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.87670\n",
            "Epoch 388/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3914 - acc: 0.9290 - val_loss: 0.6547 - val_acc: 0.8626\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.87670\n",
            "Epoch 389/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3870 - acc: 0.9287 - val_loss: 0.7419 - val_acc: 0.8447\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.87670\n",
            "Epoch 390/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3845 - acc: 0.9316 - val_loss: 0.7843 - val_acc: 0.8294\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.87670\n",
            "Epoch 391/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3872 - acc: 0.9317 - val_loss: 0.7000 - val_acc: 0.8514\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.87670\n",
            "Epoch 392/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3847 - acc: 0.9341 - val_loss: 0.7841 - val_acc: 0.8400\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.87670\n",
            "Epoch 393/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3900 - acc: 0.9331 - val_loss: 0.6740 - val_acc: 0.8605\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.87670\n",
            "Epoch 394/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3769 - acc: 0.9366 - val_loss: 0.7212 - val_acc: 0.8437\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.87670\n",
            "Epoch 395/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3775 - acc: 0.9353 - val_loss: 1.0603 - val_acc: 0.7890\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.87670\n",
            "Epoch 396/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3910 - acc: 0.9315 - val_loss: 0.5970 - val_acc: 0.8697\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.87670\n",
            "Epoch 397/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3802 - acc: 0.9320 - val_loss: 0.8151 - val_acc: 0.8148\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.87670\n",
            "Epoch 398/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4083 - acc: 0.9221 - val_loss: 0.6908 - val_acc: 0.8476\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.87670\n",
            "Epoch 399/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3922 - acc: 0.9301 - val_loss: 0.8437 - val_acc: 0.8161\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.87670\n",
            "Epoch 400/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3892 - acc: 0.9316 - val_loss: 0.6420 - val_acc: 0.8624\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.87670\n",
            "Epoch 401/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3752 - acc: 0.9359 - val_loss: 0.7343 - val_acc: 0.8503\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.87670\n",
            "Epoch 402/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3686 - acc: 0.9395 - val_loss: 0.5192 - val_acc: 0.9009\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.87670 to 0.90090, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3371 - acc: 0.9506 - val_loss: 0.5078 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.90090 to 0.90310, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3193 - acc: 0.9604 - val_loss: 0.4944 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.90310 to 0.90650, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3282 - acc: 0.9570 - val_loss: 0.4922 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.90650 to 0.90870, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3144 - acc: 0.9603 - val_loss: 0.4899 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00406: val_acc did not improve from 0.90870\n",
            "Epoch 407/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3080 - acc: 0.9597 - val_loss: 0.4844 - val_acc: 0.9106\n",
            "\n",
            "Epoch 00407: val_acc improved from 0.90870 to 0.91060, saving model to /content/saved_models/cifar10_ResNet32v1_model.407.h5\n",
            "Epoch 408/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3048 - acc: 0.9645 - val_loss: 0.4796 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00408: val_acc improved from 0.91060 to 0.91190, saving model to /content/saved_models/cifar10_ResNet32v1_model.408.h5\n",
            "Epoch 409/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3037 - acc: 0.9621 - val_loss: 0.4845 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.91190\n",
            "Epoch 410/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3016 - acc: 0.9623 - val_loss: 0.4827 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00410: val_acc did not improve from 0.91190\n",
            "Epoch 411/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2921 - acc: 0.9661 - val_loss: 0.4818 - val_acc: 0.9096\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.91190\n",
            "Epoch 412/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2938 - acc: 0.9648 - val_loss: 0.4855 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00412: val_acc did not improve from 0.91190\n",
            "Epoch 413/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2888 - acc: 0.9675 - val_loss: 0.4822 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.91190\n",
            "Epoch 414/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2818 - acc: 0.9680 - val_loss: 0.4790 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.91190\n",
            "Epoch 415/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2801 - acc: 0.9695 - val_loss: 0.4769 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00415: val_acc improved from 0.91190 to 0.91280, saving model to /content/saved_models/cifar10_ResNet32v1_model.415.h5\n",
            "Epoch 416/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2834 - acc: 0.9681 - val_loss: 0.4845 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.91280\n",
            "Epoch 417/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2903 - acc: 0.9704 - val_loss: 0.4862 - val_acc: 0.9094\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.91280\n",
            "Epoch 418/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2812 - acc: 0.9707 - val_loss: 0.4902 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.91280\n",
            "Epoch 419/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2711 - acc: 0.9719 - val_loss: 0.4873 - val_acc: 0.9102\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.91280\n",
            "Epoch 420/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2748 - acc: 0.9709 - val_loss: 0.4884 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.91280\n",
            "Epoch 421/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2788 - acc: 0.9691 - val_loss: 0.4766 - val_acc: 0.9134\n",
            "\n",
            "Epoch 00421: val_acc improved from 0.91280 to 0.91340, saving model to /content/saved_models/cifar10_ResNet32v1_model.421.h5\n",
            "Epoch 422/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2723 - acc: 0.9703 - val_loss: 0.4791 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00422: val_acc did not improve from 0.91340\n",
            "Epoch 423/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2681 - acc: 0.9719 - val_loss: 0.4798 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.91340\n",
            "Epoch 424/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2626 - acc: 0.9747 - val_loss: 0.4822 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.91340\n",
            "Epoch 425/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2658 - acc: 0.9718 - val_loss: 0.4845 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.91340\n",
            "Epoch 426/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2633 - acc: 0.9732 - val_loss: 0.4857 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.91340\n",
            "Epoch 427/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2702 - acc: 0.9701 - val_loss: 0.4886 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.91340\n",
            "Epoch 428/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2621 - acc: 0.9757 - val_loss: 0.4850 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.91340\n",
            "Epoch 429/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2683 - acc: 0.9698 - val_loss: 0.4800 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.91340\n",
            "Epoch 430/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2677 - acc: 0.9730 - val_loss: 0.4829 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.91340\n",
            "Epoch 431/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2655 - acc: 0.9706 - val_loss: 0.4855 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.91340\n",
            "Epoch 432/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2549 - acc: 0.9743 - val_loss: 0.4802 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.91340\n",
            "Epoch 433/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2605 - acc: 0.9751 - val_loss: 0.4808 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.91340\n",
            "Epoch 434/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2624 - acc: 0.9723 - val_loss: 0.4874 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00434: val_acc did not improve from 0.91340\n",
            "Epoch 435/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2623 - acc: 0.9705 - val_loss: 0.4789 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.91340\n",
            "Epoch 436/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2557 - acc: 0.9733 - val_loss: 0.4796 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00436: val_acc improved from 0.91340 to 0.91370, saving model to /content/saved_models/cifar10_ResNet32v1_model.436.h5\n",
            "Epoch 437/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2555 - acc: 0.9730 - val_loss: 0.4960 - val_acc: 0.9091\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.91370\n",
            "Epoch 438/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2522 - acc: 0.9751 - val_loss: 0.4822 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.91370\n",
            "Epoch 439/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2584 - acc: 0.9738 - val_loss: 0.4777 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00439: val_acc improved from 0.91370 to 0.91600, saving model to /content/saved_models/cifar10_ResNet32v1_model.439.h5\n",
            "Epoch 440/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2507 - acc: 0.9755 - val_loss: 0.4875 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.91600\n",
            "Epoch 441/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2513 - acc: 0.9772 - val_loss: 0.4758 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.91600\n",
            "Epoch 442/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2560 - acc: 0.9741 - val_loss: 0.4842 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.91600\n",
            "Epoch 443/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2455 - acc: 0.9773 - val_loss: 0.4845 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.91600\n",
            "Epoch 444/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2430 - acc: 0.9776 - val_loss: 0.4935 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.91600\n",
            "Epoch 445/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2425 - acc: 0.9779 - val_loss: 0.4873 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.91600\n",
            "Epoch 446/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2491 - acc: 0.9753 - val_loss: 0.4884 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.91600\n",
            "Epoch 447/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.2533 - acc: 0.9731 - val_loss: 0.4857 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.91600\n",
            "Epoch 448/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2376 - acc: 0.9792 - val_loss: 0.4804 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.91600\n",
            "Epoch 449/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2433 - acc: 0.9773 - val_loss: 0.4812 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.91600\n",
            "Epoch 450/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2407 - acc: 0.9763 - val_loss: 0.4869 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.91600\n",
            "Epoch 451/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2386 - acc: 0.9788 - val_loss: 0.4854 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.91600\n",
            "Epoch 452/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2382 - acc: 0.9769 - val_loss: 0.4826 - val_acc: 0.9141\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.91600\n",
            "Epoch 453/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2345 - acc: 0.9808 - val_loss: 0.4892 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.91600\n",
            "Epoch 454/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2314 - acc: 0.9814 - val_loss: 0.4858 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.91600\n",
            "Epoch 455/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2341 - acc: 0.9795 - val_loss: 0.4862 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.91600\n",
            "Epoch 456/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2356 - acc: 0.9792 - val_loss: 0.4914 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.91600\n",
            "Epoch 457/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2297 - acc: 0.9794 - val_loss: 0.4986 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.91600\n",
            "Epoch 458/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2314 - acc: 0.9800 - val_loss: 0.4843 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.91600\n",
            "Epoch 459/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2379 - acc: 0.9782 - val_loss: 0.4841 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.91600\n",
            "Epoch 460/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2349 - acc: 0.9799 - val_loss: 0.4942 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.91600\n",
            "Epoch 461/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2317 - acc: 0.9809 - val_loss: 0.4860 - val_acc: 0.9146\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.91600\n",
            "Epoch 462/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2293 - acc: 0.9791 - val_loss: 0.4892 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.91600\n",
            "Epoch 463/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2322 - acc: 0.9802 - val_loss: 0.4841 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.91600\n",
            "Epoch 464/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2212 - acc: 0.9837 - val_loss: 0.4751 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.91600\n",
            "Epoch 465/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2247 - acc: 0.9819 - val_loss: 0.4849 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.91600\n",
            "Epoch 466/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2265 - acc: 0.9799 - val_loss: 0.5108 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.91600\n",
            "Epoch 467/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2251 - acc: 0.9808 - val_loss: 0.4922 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.91600\n",
            "Epoch 468/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2303 - acc: 0.9816 - val_loss: 0.4852 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.91600\n",
            "Epoch 469/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2213 - acc: 0.9814 - val_loss: 0.4902 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.91600\n",
            "Epoch 470/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2235 - acc: 0.9804 - val_loss: 0.4900 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.91600\n",
            "Epoch 471/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2205 - acc: 0.9822 - val_loss: 0.4941 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.91600\n",
            "Epoch 472/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2249 - acc: 0.9807 - val_loss: 0.4889 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.91600\n",
            "Epoch 473/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2118 - acc: 0.9852 - val_loss: 0.4872 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.91600\n",
            "Epoch 474/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2216 - acc: 0.9809 - val_loss: 0.4864 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.91600\n",
            "Epoch 475/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2184 - acc: 0.9827 - val_loss: 0.4809 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.91600\n",
            "Epoch 476/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2206 - acc: 0.9820 - val_loss: 0.5168 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.91600\n",
            "Epoch 477/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2209 - acc: 0.9813 - val_loss: 0.4950 - val_acc: 0.9106\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.91600\n",
            "Epoch 478/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2192 - acc: 0.9839 - val_loss: 0.5112 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.91600\n",
            "Epoch 479/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2249 - acc: 0.9792 - val_loss: 0.5007 - val_acc: 0.9085\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.91600\n",
            "Epoch 480/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2165 - acc: 0.9834 - val_loss: 0.5050 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.91600\n",
            "Epoch 481/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2116 - acc: 0.9852 - val_loss: 0.5015 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.91600\n",
            "Epoch 482/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2139 - acc: 0.9834 - val_loss: 0.5092 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.91600\n",
            "Epoch 483/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2143 - acc: 0.9821 - val_loss: 0.4949 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.91600\n",
            "Epoch 484/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2137 - acc: 0.9835 - val_loss: 0.4893 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.91600\n",
            "Epoch 485/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2142 - acc: 0.9817 - val_loss: 0.4913 - val_acc: 0.9146\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.91600\n",
            "Epoch 486/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2189 - acc: 0.9816 - val_loss: 0.4996 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.91600\n",
            "Epoch 487/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2106 - acc: 0.9851 - val_loss: 0.4971 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.91600\n",
            "Epoch 488/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2103 - acc: 0.9834 - val_loss: 0.5069 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.91600\n",
            "Epoch 489/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2078 - acc: 0.9848 - val_loss: 0.5195 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.91600\n",
            "Epoch 490/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2063 - acc: 0.9863 - val_loss: 0.4976 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.91600\n",
            "Epoch 491/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2053 - acc: 0.9873 - val_loss: 0.5055 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.91600\n",
            "Epoch 492/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2142 - acc: 0.9813 - val_loss: 0.5056 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.91600\n",
            "Epoch 493/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2128 - acc: 0.9834 - val_loss: 0.4994 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.91600\n",
            "Epoch 494/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2138 - acc: 0.9830 - val_loss: 0.4969 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.91600\n",
            "Epoch 495/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2062 - acc: 0.9848 - val_loss: 0.4953 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.91600\n",
            "Epoch 496/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2076 - acc: 0.9832 - val_loss: 0.5261 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.91600\n",
            "Epoch 497/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2050 - acc: 0.9851 - val_loss: 0.5012 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.91600\n",
            "Epoch 498/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2046 - acc: 0.9839 - val_loss: 0.5050 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.91600\n",
            "Epoch 499/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2065 - acc: 0.9864 - val_loss: 0.4925 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.91600\n",
            "Epoch 500/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2050 - acc: 0.9860 - val_loss: 0.4919 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.91600\n",
            "Epoch 501/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2071 - acc: 0.9844 - val_loss: 0.5037 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.91600\n",
            "Epoch 502/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1996 - acc: 0.9864 - val_loss: 0.5065 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.91600\n",
            "Epoch 503/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2016 - acc: 0.9862 - val_loss: 0.5050 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.91600\n",
            "Epoch 504/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2031 - acc: 0.9851 - val_loss: 0.4894 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.91600\n",
            "Epoch 505/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2120 - acc: 0.9830 - val_loss: 0.4769 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.91600\n",
            "Epoch 506/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2069 - acc: 0.9838 - val_loss: 0.5093 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.91600\n",
            "Epoch 507/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2063 - acc: 0.9834 - val_loss: 0.5116 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.91600\n",
            "Epoch 508/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2035 - acc: 0.9844 - val_loss: 0.5057 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.91600\n",
            "Epoch 509/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1994 - acc: 0.9865 - val_loss: 0.4964 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.91600\n",
            "Epoch 510/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2005 - acc: 0.9851 - val_loss: 0.5046 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.91600\n",
            "Epoch 511/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1989 - acc: 0.9861 - val_loss: 0.5215 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.91600\n",
            "Epoch 512/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1937 - acc: 0.9883 - val_loss: 0.5091 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.91600\n",
            "Epoch 513/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1983 - acc: 0.9863 - val_loss: 0.5247 - val_acc: 0.9078\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.91600\n",
            "Epoch 514/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1979 - acc: 0.9858 - val_loss: 0.5145 - val_acc: 0.9095\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.91600\n",
            "Epoch 515/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1965 - acc: 0.9860 - val_loss: 0.5166 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.91600\n",
            "Epoch 516/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1991 - acc: 0.9850 - val_loss: 0.5081 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.91600\n",
            "Epoch 517/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1986 - acc: 0.9862 - val_loss: 0.5098 - val_acc: 0.9114\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.91600\n",
            "Epoch 518/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1975 - acc: 0.9857 - val_loss: 0.5138 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.91600\n",
            "Epoch 519/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1974 - acc: 0.9859 - val_loss: 0.5366 - val_acc: 0.9077\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.91600\n",
            "Epoch 520/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1942 - acc: 0.9847 - val_loss: 0.4999 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.91600\n",
            "Epoch 521/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1919 - acc: 0.9885 - val_loss: 0.5169 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.91600\n",
            "Epoch 522/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1910 - acc: 0.9869 - val_loss: 0.4992 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.91600\n",
            "Epoch 523/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2011 - acc: 0.9858 - val_loss: 0.5100 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.91600\n",
            "Epoch 524/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1946 - acc: 0.9859 - val_loss: 0.5109 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.91600\n",
            "Epoch 525/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1908 - acc: 0.9879 - val_loss: 0.4969 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.91600\n",
            "Epoch 526/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1928 - acc: 0.9863 - val_loss: 0.5121 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.91600\n",
            "Epoch 527/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1892 - acc: 0.9874 - val_loss: 0.5115 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.91600\n",
            "Epoch 528/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1900 - acc: 0.9885 - val_loss: 0.5082 - val_acc: 0.9123\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.91600\n",
            "Epoch 529/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1923 - acc: 0.9874 - val_loss: 0.5133 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.91600\n",
            "Epoch 530/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1972 - acc: 0.9838 - val_loss: 0.5249 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.91600\n",
            "Epoch 531/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1877 - acc: 0.9888 - val_loss: 0.5239 - val_acc: 0.9089\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.91600\n",
            "Epoch 532/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1929 - acc: 0.9861 - val_loss: 0.5001 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.91600\n",
            "Epoch 533/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1925 - acc: 0.9842 - val_loss: 0.5277 - val_acc: 0.9068\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.91600\n",
            "Epoch 534/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1871 - acc: 0.9878 - val_loss: 0.5049 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.91600\n",
            "Epoch 535/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1856 - acc: 0.9894 - val_loss: 0.5054 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.91600\n",
            "Epoch 536/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1915 - acc: 0.9866 - val_loss: 0.5117 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.91600\n",
            "Epoch 537/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1899 - acc: 0.9890 - val_loss: 0.4988 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.91600\n",
            "Epoch 538/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1871 - acc: 0.9881 - val_loss: 0.5066 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00538: val_acc improved from 0.91600 to 0.91610, saving model to /content/saved_models/cifar10_ResNet32v1_model.538.h5\n",
            "Epoch 539/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1807 - acc: 0.9901 - val_loss: 0.5023 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.91610\n",
            "Epoch 540/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1901 - acc: 0.9860 - val_loss: 0.5528 - val_acc: 0.9068\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.91610\n",
            "Epoch 541/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1849 - acc: 0.9890 - val_loss: 0.4992 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.91610\n",
            "Epoch 542/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1862 - acc: 0.9894 - val_loss: 0.5118 - val_acc: 0.9114\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.91610\n",
            "Epoch 543/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1923 - acc: 0.9858 - val_loss: 0.5015 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.91610\n",
            "Epoch 544/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1822 - acc: 0.9897 - val_loss: 0.5084 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.91610\n",
            "Epoch 545/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1850 - acc: 0.9892 - val_loss: 0.5043 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.91610\n",
            "Epoch 546/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1876 - acc: 0.9871 - val_loss: 0.4984 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.91610\n",
            "Epoch 547/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1856 - acc: 0.9883 - val_loss: 0.5319 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.91610\n",
            "Epoch 548/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1851 - acc: 0.9873 - val_loss: 0.5076 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.91610\n",
            "Epoch 549/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1832 - acc: 0.9864 - val_loss: 0.5002 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.91610\n",
            "Epoch 550/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1825 - acc: 0.9893 - val_loss: 0.5027 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.91610\n",
            "Epoch 551/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1819 - acc: 0.9886 - val_loss: 0.5041 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.91610\n",
            "Epoch 552/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1817 - acc: 0.9890 - val_loss: 0.5398 - val_acc: 0.9066\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.91610\n",
            "Epoch 553/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1869 - acc: 0.9876 - val_loss: 0.5152 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.91610\n",
            "Epoch 554/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1803 - acc: 0.9895 - val_loss: 0.5052 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.91610\n",
            "Epoch 555/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1875 - acc: 0.9864 - val_loss: 0.5072 - val_acc: 0.9123\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.91610\n",
            "Epoch 556/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1758 - acc: 0.9913 - val_loss: 0.5078 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.91610\n",
            "Epoch 557/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1878 - acc: 0.9842 - val_loss: 0.5275 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.91610\n",
            "Epoch 558/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1810 - acc: 0.9894 - val_loss: 0.5094 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.91610\n",
            "Epoch 559/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1790 - acc: 0.9891 - val_loss: 0.5042 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.91610\n",
            "Epoch 560/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1758 - acc: 0.9903 - val_loss: 0.5091 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.91610\n",
            "Epoch 561/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1730 - acc: 0.9910 - val_loss: 0.5201 - val_acc: 0.9102\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.91610\n",
            "Epoch 562/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1814 - acc: 0.9883 - val_loss: 0.4936 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.91610\n",
            "Epoch 563/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1761 - acc: 0.9882 - val_loss: 0.5118 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.91610\n",
            "Epoch 564/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1761 - acc: 0.9897 - val_loss: 0.5207 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.91610\n",
            "Epoch 565/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1796 - acc: 0.9880 - val_loss: 0.5029 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.91610\n",
            "Epoch 566/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1815 - acc: 0.9870 - val_loss: 0.4993 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.91610\n",
            "Epoch 567/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1785 - acc: 0.9888 - val_loss: 0.5082 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.91610\n",
            "Epoch 568/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1806 - acc: 0.9886 - val_loss: 0.5070 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.91610\n",
            "Epoch 569/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1754 - acc: 0.9878 - val_loss: 0.5071 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.91610\n",
            "Epoch 570/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1776 - acc: 0.9895 - val_loss: 0.5162 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.91610\n",
            "Epoch 571/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1790 - acc: 0.9880 - val_loss: 0.5201 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.91610\n",
            "Epoch 572/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1762 - acc: 0.9879 - val_loss: 0.5182 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.91610\n",
            "Epoch 573/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1757 - acc: 0.9880 - val_loss: 0.5154 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.91610\n",
            "Epoch 574/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1779 - acc: 0.9888 - val_loss: 0.5188 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.91610\n",
            "Epoch 575/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1739 - acc: 0.9877 - val_loss: 0.5057 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.91610\n",
            "Epoch 576/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1726 - acc: 0.9889 - val_loss: 0.5182 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.91610\n",
            "Epoch 577/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1766 - acc: 0.9882 - val_loss: 0.5223 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.91610\n",
            "Epoch 578/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1769 - acc: 0.9876 - val_loss: 0.5188 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.91610\n",
            "Epoch 579/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1733 - acc: 0.9890 - val_loss: 0.5235 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.91610\n",
            "Epoch 580/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1667 - acc: 0.9929 - val_loss: 0.5231 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.91610\n",
            "Epoch 581/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1707 - acc: 0.9897 - val_loss: 0.5363 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.91610\n",
            "Epoch 582/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1758 - acc: 0.9888 - val_loss: 0.5306 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.91610\n",
            "Epoch 583/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1789 - acc: 0.9872 - val_loss: 0.5380 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.91610\n",
            "Epoch 584/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1729 - acc: 0.9894 - val_loss: 0.5069 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.91610\n",
            "Epoch 585/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1697 - acc: 0.9909 - val_loss: 0.5131 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.91610\n",
            "Epoch 586/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1735 - acc: 0.9881 - val_loss: 0.5221 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.91610\n",
            "Epoch 587/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1742 - acc: 0.9881 - val_loss: 0.5340 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.91610\n",
            "Epoch 588/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1770 - acc: 0.9871 - val_loss: 0.5305 - val_acc: 0.9083\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.91610\n",
            "Epoch 589/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1712 - acc: 0.9906 - val_loss: 0.5167 - val_acc: 0.9138\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.91610\n",
            "Epoch 590/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1707 - acc: 0.9904 - val_loss: 0.5065 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.91610\n",
            "Epoch 591/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1703 - acc: 0.9900 - val_loss: 0.5019 - val_acc: 0.9138\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.91610\n",
            "Epoch 592/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1718 - acc: 0.9891 - val_loss: 0.5121 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.91610\n",
            "Epoch 593/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1736 - acc: 0.9896 - val_loss: 0.5157 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.91610\n",
            "Epoch 594/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1706 - acc: 0.9880 - val_loss: 0.5084 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.91610\n",
            "Epoch 595/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1671 - acc: 0.9893 - val_loss: 0.5304 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.91610\n",
            "Epoch 596/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1643 - acc: 0.9921 - val_loss: 0.5157 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.91610\n",
            "Epoch 597/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1685 - acc: 0.9901 - val_loss: 0.5042 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.91610\n",
            "Epoch 598/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1720 - acc: 0.9889 - val_loss: 0.5076 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.91610\n",
            "Epoch 599/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1680 - acc: 0.9903 - val_loss: 0.5071 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.91610\n",
            "Epoch 600/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1707 - acc: 0.9879 - val_loss: 0.5286 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.91610\n",
            "Epoch 601/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1657 - acc: 0.9907 - val_loss: 0.5260 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.91610\n",
            "Epoch 602/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1666 - acc: 0.9911 - val_loss: 0.5080 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00602: val_acc did not improve from 0.91610\n",
            "Epoch 603/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1722 - acc: 0.9891 - val_loss: 0.5028 - val_acc: 0.9134\n",
            "\n",
            "Epoch 00603: val_acc did not improve from 0.91610\n",
            "Epoch 604/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1660 - acc: 0.9905 - val_loss: 0.5016 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00604: val_acc did not improve from 0.91610\n",
            "Epoch 605/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1682 - acc: 0.9894 - val_loss: 0.5002 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00605: val_acc did not improve from 0.91610\n",
            "Epoch 606/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1652 - acc: 0.9923 - val_loss: 0.5000 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00606: val_acc did not improve from 0.91610\n",
            "Epoch 607/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1621 - acc: 0.9926 - val_loss: 0.4988 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00607: val_acc did not improve from 0.91610\n",
            "Epoch 608/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1599 - acc: 0.9923 - val_loss: 0.4996 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00608: val_acc improved from 0.91610 to 0.91640, saving model to /content/saved_models/cifar10_ResNet32v1_model.608.h5\n",
            "Epoch 609/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1580 - acc: 0.9945 - val_loss: 0.4982 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00609: val_acc did not improve from 0.91640\n",
            "Epoch 610/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1640 - acc: 0.9911 - val_loss: 0.4986 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00610: val_acc did not improve from 0.91640\n",
            "Epoch 611/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1630 - acc: 0.9911 - val_loss: 0.4976 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.91640\n",
            "Epoch 612/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1644 - acc: 0.9903 - val_loss: 0.4964 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00612: val_acc improved from 0.91640 to 0.91670, saving model to /content/saved_models/cifar10_ResNet32v1_model.612.h5\n",
            "Epoch 613/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1638 - acc: 0.9911 - val_loss: 0.4958 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00613: val_acc did not improve from 0.91670\n",
            "Epoch 614/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1617 - acc: 0.9923 - val_loss: 0.4945 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.91670\n",
            "Epoch 615/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1641 - acc: 0.9908 - val_loss: 0.4985 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.91670\n",
            "Epoch 616/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1589 - acc: 0.9938 - val_loss: 0.4984 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00616: val_acc did not improve from 0.91670\n",
            "Epoch 617/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1620 - acc: 0.9905 - val_loss: 0.4968 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.91670\n",
            "Epoch 618/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1603 - acc: 0.9932 - val_loss: 0.4963 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00618: val_acc improved from 0.91670 to 0.91740, saving model to /content/saved_models/cifar10_ResNet32v1_model.618.h5\n",
            "Epoch 619/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1648 - acc: 0.9909 - val_loss: 0.4966 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00619: val_acc did not improve from 0.91740\n",
            "Epoch 620/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1601 - acc: 0.9923 - val_loss: 0.4959 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.91740\n",
            "Epoch 621/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1631 - acc: 0.9910 - val_loss: 0.4939 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00621: val_acc did not improve from 0.91740\n",
            "Epoch 622/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1586 - acc: 0.9923 - val_loss: 0.4951 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.91740\n",
            "Epoch 623/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1586 - acc: 0.9931 - val_loss: 0.4979 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.91740\n",
            "Epoch 624/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1631 - acc: 0.9920 - val_loss: 0.4984 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.91740\n",
            "Epoch 625/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1590 - acc: 0.9925 - val_loss: 0.4956 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.91740\n",
            "Epoch 626/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1607 - acc: 0.9913 - val_loss: 0.4957 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.91740\n",
            "Epoch 627/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1579 - acc: 0.9930 - val_loss: 0.4948 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00627: val_acc did not improve from 0.91740\n",
            "Epoch 628/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1560 - acc: 0.9940 - val_loss: 0.4929 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00628: val_acc did not improve from 0.91740\n",
            "Epoch 629/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1593 - acc: 0.9926 - val_loss: 0.4951 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.91740\n",
            "Epoch 630/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1616 - acc: 0.9918 - val_loss: 0.4941 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00630: val_acc did not improve from 0.91740\n",
            "Epoch 631/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1602 - acc: 0.9923 - val_loss: 0.4954 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00631: val_acc did not improve from 0.91740\n",
            "Epoch 632/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1625 - acc: 0.9918 - val_loss: 0.4944 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00632: val_acc did not improve from 0.91740\n",
            "Epoch 633/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1584 - acc: 0.9929 - val_loss: 0.4940 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.91740\n",
            "Epoch 634/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1609 - acc: 0.9912 - val_loss: 0.4931 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.91740\n",
            "Epoch 635/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1599 - acc: 0.9927 - val_loss: 0.4927 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.91740\n",
            "Epoch 636/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1615 - acc: 0.9924 - val_loss: 0.4927 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.91740\n",
            "Epoch 637/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1603 - acc: 0.9936 - val_loss: 0.4946 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00637: val_acc did not improve from 0.91740\n",
            "Epoch 638/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1582 - acc: 0.9934 - val_loss: 0.4948 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.91740\n",
            "Epoch 639/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1581 - acc: 0.9936 - val_loss: 0.4908 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.91740\n",
            "Epoch 640/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1570 - acc: 0.9939 - val_loss: 0.4915 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.91740\n",
            "Epoch 641/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1579 - acc: 0.9929 - val_loss: 0.4945 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.91740\n",
            "Epoch 642/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1589 - acc: 0.9930 - val_loss: 0.4972 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.91740\n",
            "Epoch 643/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1578 - acc: 0.9927 - val_loss: 0.4964 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.91740\n",
            "Epoch 644/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1595 - acc: 0.9922 - val_loss: 0.4944 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.91740\n",
            "Epoch 645/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1585 - acc: 0.9930 - val_loss: 0.4936 - val_acc: 0.9173\n",
            "\n",
            "Epoch 00645: val_acc did not improve from 0.91740\n",
            "Epoch 646/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1554 - acc: 0.9937 - val_loss: 0.4935 - val_acc: 0.9173\n",
            "\n",
            "Epoch 00646: val_acc did not improve from 0.91740\n",
            "Epoch 647/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1555 - acc: 0.9951 - val_loss: 0.4938 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00647: val_acc improved from 0.91740 to 0.91790, saving model to /content/saved_models/cifar10_ResNet32v1_model.647.h5\n",
            "Epoch 648/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1574 - acc: 0.9940 - val_loss: 0.4953 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.91790\n",
            "Epoch 649/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1561 - acc: 0.9937 - val_loss: 0.4991 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.91790\n",
            "Epoch 650/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1551 - acc: 0.9943 - val_loss: 0.4975 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00650: val_acc did not improve from 0.91790\n",
            "Epoch 651/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1569 - acc: 0.9936 - val_loss: 0.4948 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00651: val_acc did not improve from 0.91790\n",
            "Epoch 652/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1591 - acc: 0.9930 - val_loss: 0.4985 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00652: val_acc did not improve from 0.91790\n",
            "Epoch 653/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1580 - acc: 0.9917 - val_loss: 0.4984 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00653: val_acc did not improve from 0.91790\n",
            "Epoch 654/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1527 - acc: 0.9960 - val_loss: 0.4962 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00654: val_acc did not improve from 0.91790\n",
            "Epoch 655/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1563 - acc: 0.9942 - val_loss: 0.4956 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00655: val_acc did not improve from 0.91790\n",
            "Epoch 656/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1539 - acc: 0.9968 - val_loss: 0.4949 - val_acc: 0.9181\n",
            "\n",
            "Epoch 00656: val_acc improved from 0.91790 to 0.91810, saving model to /content/saved_models/cifar10_ResNet32v1_model.656.h5\n",
            "Epoch 657/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1562 - acc: 0.9947 - val_loss: 0.4942 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00657: val_acc improved from 0.91810 to 0.91860, saving model to /content/saved_models/cifar10_ResNet32v1_model.657.h5\n",
            "Epoch 658/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1560 - acc: 0.9931 - val_loss: 0.4956 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00658: val_acc did not improve from 0.91860\n",
            "Epoch 659/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1548 - acc: 0.9943 - val_loss: 0.4960 - val_acc: 0.9173\n",
            "\n",
            "Epoch 00659: val_acc did not improve from 0.91860\n",
            "Epoch 660/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1566 - acc: 0.9950 - val_loss: 0.4958 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00660: val_acc did not improve from 0.91860\n",
            "Epoch 661/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1548 - acc: 0.9950 - val_loss: 0.4957 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00661: val_acc did not improve from 0.91860\n",
            "Epoch 662/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1592 - acc: 0.9926 - val_loss: 0.4957 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00662: val_acc did not improve from 0.91860\n",
            "Epoch 663/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1578 - acc: 0.9940 - val_loss: 0.4964 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00663: val_acc did not improve from 0.91860\n",
            "Epoch 664/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1566 - acc: 0.9931 - val_loss: 0.4985 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00664: val_acc did not improve from 0.91860\n",
            "Epoch 665/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1548 - acc: 0.9942 - val_loss: 0.4973 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00665: val_acc did not improve from 0.91860\n",
            "Epoch 666/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1561 - acc: 0.9948 - val_loss: 0.4965 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00666: val_acc did not improve from 0.91860\n",
            "Epoch 667/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1583 - acc: 0.9934 - val_loss: 0.4976 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00667: val_acc did not improve from 0.91860\n",
            "Epoch 668/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1517 - acc: 0.9956 - val_loss: 0.4973 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00668: val_acc did not improve from 0.91860\n",
            "Epoch 669/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1541 - acc: 0.9950 - val_loss: 0.4961 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00669: val_acc did not improve from 0.91860\n",
            "Epoch 670/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1533 - acc: 0.9944 - val_loss: 0.4961 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00670: val_acc did not improve from 0.91860\n",
            "Epoch 671/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1547 - acc: 0.9942 - val_loss: 0.4960 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00671: val_acc did not improve from 0.91860\n",
            "Epoch 672/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1571 - acc: 0.9936 - val_loss: 0.4960 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00672: val_acc did not improve from 0.91860\n",
            "Epoch 673/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1539 - acc: 0.9942 - val_loss: 0.4977 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00673: val_acc did not improve from 0.91860\n",
            "Epoch 674/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1560 - acc: 0.9943 - val_loss: 0.5027 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00674: val_acc did not improve from 0.91860\n",
            "Epoch 675/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1553 - acc: 0.9936 - val_loss: 0.5009 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00675: val_acc did not improve from 0.91860\n",
            "Epoch 676/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1567 - acc: 0.9946 - val_loss: 0.4971 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00676: val_acc did not improve from 0.91860\n",
            "Epoch 677/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1549 - acc: 0.9948 - val_loss: 0.4983 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00677: val_acc did not improve from 0.91860\n",
            "Epoch 678/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1526 - acc: 0.9955 - val_loss: 0.4999 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00678: val_acc did not improve from 0.91860\n",
            "Epoch 679/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1531 - acc: 0.9940 - val_loss: 0.4997 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00679: val_acc did not improve from 0.91860\n",
            "Epoch 680/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1546 - acc: 0.9950 - val_loss: 0.4959 - val_acc: 0.9175\n",
            "\n",
            "Epoch 00680: val_acc did not improve from 0.91860\n",
            "Epoch 681/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1557 - acc: 0.9949 - val_loss: 0.4938 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00681: val_acc did not improve from 0.91860\n",
            "Epoch 682/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1543 - acc: 0.9931 - val_loss: 0.4966 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00682: val_acc did not improve from 0.91860\n",
            "Epoch 683/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1542 - acc: 0.9944 - val_loss: 0.4955 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00683: val_acc did not improve from 0.91860\n",
            "Epoch 684/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1538 - acc: 0.9946 - val_loss: 0.4967 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00684: val_acc did not improve from 0.91860\n",
            "Epoch 685/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1568 - acc: 0.9929 - val_loss: 0.4957 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00685: val_acc did not improve from 0.91860\n",
            "Epoch 686/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1571 - acc: 0.9925 - val_loss: 0.4969 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00686: val_acc did not improve from 0.91860\n",
            "Epoch 687/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1580 - acc: 0.9923 - val_loss: 0.5001 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00687: val_acc did not improve from 0.91860\n",
            "Epoch 688/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1547 - acc: 0.9933 - val_loss: 0.4991 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00688: val_acc did not improve from 0.91860\n",
            "Epoch 689/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1541 - acc: 0.9945 - val_loss: 0.4981 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00689: val_acc did not improve from 0.91860\n",
            "Epoch 690/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1523 - acc: 0.9946 - val_loss: 0.4959 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00690: val_acc did not improve from 0.91860\n",
            "Epoch 691/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1574 - acc: 0.9908 - val_loss: 0.4990 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00691: val_acc did not improve from 0.91860\n",
            "Epoch 692/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1497 - acc: 0.9959 - val_loss: 0.5001 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00692: val_acc did not improve from 0.91860\n",
            "Epoch 693/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1523 - acc: 0.9940 - val_loss: 0.4983 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00693: val_acc did not improve from 0.91860\n",
            "Epoch 694/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1558 - acc: 0.9935 - val_loss: 0.4997 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00694: val_acc did not improve from 0.91860\n",
            "Epoch 695/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1571 - acc: 0.9924 - val_loss: 0.4990 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00695: val_acc did not improve from 0.91860\n",
            "Epoch 696/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1564 - acc: 0.9926 - val_loss: 0.4983 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00696: val_acc did not improve from 0.91860\n",
            "Epoch 697/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1548 - acc: 0.9939 - val_loss: 0.4981 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00697: val_acc did not improve from 0.91860\n",
            "Epoch 698/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1574 - acc: 0.9924 - val_loss: 0.4980 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00698: val_acc did not improve from 0.91860\n",
            "Epoch 699/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1543 - acc: 0.9941 - val_loss: 0.5005 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00699: val_acc did not improve from 0.91860\n",
            "Epoch 700/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1542 - acc: 0.9925 - val_loss: 0.5021 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00700: val_acc did not improve from 0.91860\n",
            "Epoch 701/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1568 - acc: 0.9929 - val_loss: 0.5015 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00701: val_acc did not improve from 0.91860\n",
            "Epoch 702/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1527 - acc: 0.9955 - val_loss: 0.5027 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00702: val_acc did not improve from 0.91860\n",
            "Epoch 703/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1519 - acc: 0.9941 - val_loss: 0.5008 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00703: val_acc did not improve from 0.91860\n",
            "Epoch 704/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1529 - acc: 0.9942 - val_loss: 0.5023 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00704: val_acc did not improve from 0.91860\n",
            "Epoch 705/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1529 - acc: 0.9949 - val_loss: 0.5015 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00705: val_acc did not improve from 0.91860\n",
            "Epoch 706/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1543 - acc: 0.9943 - val_loss: 0.4983 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00706: val_acc did not improve from 0.91860\n",
            "Epoch 707/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1525 - acc: 0.9944 - val_loss: 0.5006 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00707: val_acc did not improve from 0.91860\n",
            "Epoch 708/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1539 - acc: 0.9946 - val_loss: 0.4992 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00708: val_acc did not improve from 0.91860\n",
            "Epoch 709/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1492 - acc: 0.9960 - val_loss: 0.5002 - val_acc: 0.9175\n",
            "\n",
            "Epoch 00709: val_acc did not improve from 0.91860\n",
            "Epoch 710/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1524 - acc: 0.9946 - val_loss: 0.5016 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00710: val_acc did not improve from 0.91860\n",
            "Epoch 711/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1534 - acc: 0.9921 - val_loss: 0.5022 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00711: val_acc did not improve from 0.91860\n",
            "Epoch 712/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1502 - acc: 0.9956 - val_loss: 0.5056 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00712: val_acc did not improve from 0.91860\n",
            "Epoch 713/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1555 - acc: 0.9925 - val_loss: 0.5044 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00713: val_acc did not improve from 0.91860\n",
            "Epoch 714/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1501 - acc: 0.9957 - val_loss: 0.5047 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00714: val_acc did not improve from 0.91860\n",
            "Epoch 715/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1572 - acc: 0.9928 - val_loss: 0.5056 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00715: val_acc did not improve from 0.91860\n",
            "Epoch 716/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1569 - acc: 0.9931 - val_loss: 0.5057 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00716: val_acc did not improve from 0.91860\n",
            "Epoch 717/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1526 - acc: 0.9938 - val_loss: 0.5060 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00717: val_acc did not improve from 0.91860\n",
            "Epoch 718/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1548 - acc: 0.9947 - val_loss: 0.5047 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00718: val_acc did not improve from 0.91860\n",
            "Epoch 719/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1530 - acc: 0.9944 - val_loss: 0.5031 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00719: val_acc did not improve from 0.91860\n",
            "Epoch 720/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1549 - acc: 0.9924 - val_loss: 0.5055 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00720: val_acc did not improve from 0.91860\n",
            "Epoch 721/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1539 - acc: 0.9939 - val_loss: 0.5047 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00721: val_acc did not improve from 0.91860\n",
            "Epoch 722/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1553 - acc: 0.9933 - val_loss: 0.5028 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00722: val_acc did not improve from 0.91860\n",
            "Epoch 723/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1530 - acc: 0.9942 - val_loss: 0.5043 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00723: val_acc did not improve from 0.91860\n",
            "Epoch 724/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1485 - acc: 0.9960 - val_loss: 0.5043 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00724: val_acc did not improve from 0.91860\n",
            "Epoch 725/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1549 - acc: 0.9922 - val_loss: 0.5061 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00725: val_acc did not improve from 0.91860\n",
            "Epoch 726/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1495 - acc: 0.9962 - val_loss: 0.5072 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00726: val_acc did not improve from 0.91860\n",
            "Epoch 727/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1539 - acc: 0.9929 - val_loss: 0.5055 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00727: val_acc did not improve from 0.91860\n",
            "Epoch 728/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1517 - acc: 0.9937 - val_loss: 0.5071 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00728: val_acc did not improve from 0.91860\n",
            "Epoch 729/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1552 - acc: 0.9942 - val_loss: 0.5058 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00729: val_acc did not improve from 0.91860\n",
            "Epoch 730/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1523 - acc: 0.9946 - val_loss: 0.5050 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00730: val_acc did not improve from 0.91860\n",
            "Epoch 731/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1489 - acc: 0.9960 - val_loss: 0.5030 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00731: val_acc did not improve from 0.91860\n",
            "Epoch 732/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1495 - acc: 0.9953 - val_loss: 0.5053 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00732: val_acc did not improve from 0.91860\n",
            "Epoch 733/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1499 - acc: 0.9957 - val_loss: 0.5058 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00733: val_acc did not improve from 0.91860\n",
            "Epoch 734/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1510 - acc: 0.9953 - val_loss: 0.5054 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00734: val_acc did not improve from 0.91860\n",
            "Epoch 735/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1511 - acc: 0.9955 - val_loss: 0.5067 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00735: val_acc did not improve from 0.91860\n",
            "Epoch 736/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1534 - acc: 0.9932 - val_loss: 0.5032 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00736: val_acc did not improve from 0.91860\n",
            "Epoch 737/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1478 - acc: 0.9963 - val_loss: 0.5046 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00737: val_acc did not improve from 0.91860\n",
            "Epoch 738/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1533 - acc: 0.9945 - val_loss: 0.5041 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00738: val_acc did not improve from 0.91860\n",
            "Epoch 739/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1506 - acc: 0.9957 - val_loss: 0.5008 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00739: val_acc did not improve from 0.91860\n",
            "Epoch 740/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1556 - acc: 0.9928 - val_loss: 0.5004 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00740: val_acc did not improve from 0.91860\n",
            "Epoch 741/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1488 - acc: 0.9948 - val_loss: 0.5000 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00741: val_acc did not improve from 0.91860\n",
            "Epoch 742/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1513 - acc: 0.9952 - val_loss: 0.5027 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00742: val_acc did not improve from 0.91860\n",
            "Epoch 743/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1529 - acc: 0.9939 - val_loss: 0.5028 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00743: val_acc did not improve from 0.91860\n",
            "Epoch 744/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1547 - acc: 0.9938 - val_loss: 0.5037 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00744: val_acc did not improve from 0.91860\n",
            "Epoch 745/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1498 - acc: 0.9950 - val_loss: 0.5016 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00745: val_acc did not improve from 0.91860\n",
            "Epoch 746/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1522 - acc: 0.9938 - val_loss: 0.5006 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00746: val_acc did not improve from 0.91860\n",
            "Epoch 747/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1497 - acc: 0.9952 - val_loss: 0.5016 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00747: val_acc did not improve from 0.91860\n",
            "Epoch 748/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1490 - acc: 0.9950 - val_loss: 0.5034 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00748: val_acc did not improve from 0.91860\n",
            "Epoch 749/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1515 - acc: 0.9947 - val_loss: 0.5007 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00749: val_acc did not improve from 0.91860\n",
            "Epoch 750/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1550 - acc: 0.9936 - val_loss: 0.4990 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00750: val_acc did not improve from 0.91860\n",
            "Epoch 751/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1502 - acc: 0.9943 - val_loss: 0.4987 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00751: val_acc did not improve from 0.91860\n",
            "Epoch 752/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1489 - acc: 0.9952 - val_loss: 0.5021 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00752: val_acc did not improve from 0.91860\n",
            "Epoch 753/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1493 - acc: 0.9956 - val_loss: 0.5023 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00753: val_acc did not improve from 0.91860\n",
            "Epoch 754/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1516 - acc: 0.9946 - val_loss: 0.5028 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00754: val_acc did not improve from 0.91860\n",
            "Epoch 755/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1523 - acc: 0.9925 - val_loss: 0.5035 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00755: val_acc did not improve from 0.91860\n",
            "Epoch 756/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1472 - acc: 0.9961 - val_loss: 0.5040 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00756: val_acc did not improve from 0.91860\n",
            "Epoch 757/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1493 - acc: 0.9958 - val_loss: 0.5024 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00757: val_acc did not improve from 0.91860\n",
            "Epoch 758/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1507 - acc: 0.9939 - val_loss: 0.5014 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00758: val_acc did not improve from 0.91860\n",
            "Epoch 759/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1553 - acc: 0.9912 - val_loss: 0.5045 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00759: val_acc did not improve from 0.91860\n",
            "Epoch 760/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1543 - acc: 0.9932 - val_loss: 0.5063 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00760: val_acc did not improve from 0.91860\n",
            "Epoch 761/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1525 - acc: 0.9940 - val_loss: 0.5045 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00761: val_acc did not improve from 0.91860\n",
            "Epoch 762/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1486 - acc: 0.9953 - val_loss: 0.5031 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00762: val_acc did not improve from 0.91860\n",
            "Epoch 763/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1522 - acc: 0.9948 - val_loss: 0.5050 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00763: val_acc did not improve from 0.91860\n",
            "Epoch 764/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1483 - acc: 0.9956 - val_loss: 0.5041 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00764: val_acc did not improve from 0.91860\n",
            "Epoch 765/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1509 - acc: 0.9949 - val_loss: 0.5029 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00765: val_acc did not improve from 0.91860\n",
            "Epoch 766/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1522 - acc: 0.9929 - val_loss: 0.5037 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00766: val_acc did not improve from 0.91860\n",
            "Epoch 767/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1509 - acc: 0.9937 - val_loss: 0.5041 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00767: val_acc did not improve from 0.91860\n",
            "Epoch 768/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1485 - acc: 0.9950 - val_loss: 0.5032 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00768: val_acc did not improve from 0.91860\n",
            "Epoch 769/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1512 - acc: 0.9933 - val_loss: 0.5067 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00769: val_acc did not improve from 0.91860\n",
            "Epoch 770/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1485 - acc: 0.9956 - val_loss: 0.5069 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00770: val_acc did not improve from 0.91860\n",
            "Epoch 771/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1464 - acc: 0.9970 - val_loss: 0.5033 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00771: val_acc did not improve from 0.91860\n",
            "Epoch 772/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1483 - acc: 0.9948 - val_loss: 0.5051 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00772: val_acc did not improve from 0.91860\n",
            "Epoch 773/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1545 - acc: 0.9929 - val_loss: 0.5084 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00773: val_acc did not improve from 0.91860\n",
            "Epoch 774/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1508 - acc: 0.9947 - val_loss: 0.5059 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00774: val_acc did not improve from 0.91860\n",
            "Epoch 775/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1498 - acc: 0.9947 - val_loss: 0.5039 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00775: val_acc did not improve from 0.91860\n",
            "Epoch 776/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1493 - acc: 0.9947 - val_loss: 0.5056 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00776: val_acc did not improve from 0.91860\n",
            "Epoch 777/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1480 - acc: 0.9966 - val_loss: 0.5060 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00777: val_acc did not improve from 0.91860\n",
            "Epoch 778/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1516 - acc: 0.9949 - val_loss: 0.5070 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00778: val_acc did not improve from 0.91860\n",
            "Epoch 779/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1487 - acc: 0.9953 - val_loss: 0.5061 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00779: val_acc did not improve from 0.91860\n",
            "Epoch 780/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1464 - acc: 0.9962 - val_loss: 0.5071 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00780: val_acc did not improve from 0.91860\n",
            "Epoch 781/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1535 - acc: 0.9926 - val_loss: 0.5059 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00781: val_acc did not improve from 0.91860\n",
            "Epoch 782/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1519 - acc: 0.9937 - val_loss: 0.5036 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00782: val_acc did not improve from 0.91860\n",
            "Epoch 783/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1504 - acc: 0.9935 - val_loss: 0.5045 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00783: val_acc did not improve from 0.91860\n",
            "Epoch 784/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1538 - acc: 0.9926 - val_loss: 0.5088 - val_acc: 0.9150\n",
            "\n",
            "Epoch 00784: val_acc did not improve from 0.91860\n",
            "Epoch 785/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1477 - acc: 0.9964 - val_loss: 0.5079 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00785: val_acc did not improve from 0.91860\n",
            "Epoch 786/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1481 - acc: 0.9948 - val_loss: 0.5046 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00786: val_acc did not improve from 0.91860\n",
            "Epoch 787/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1481 - acc: 0.9954 - val_loss: 0.5046 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00787: val_acc did not improve from 0.91860\n",
            "Epoch 788/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1516 - acc: 0.9931 - val_loss: 0.5029 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00788: val_acc did not improve from 0.91860\n",
            "Epoch 789/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1498 - acc: 0.9935 - val_loss: 0.5036 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00789: val_acc did not improve from 0.91860\n",
            "Epoch 790/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1482 - acc: 0.9953 - val_loss: 0.5059 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00790: val_acc did not improve from 0.91860\n",
            "Epoch 791/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1466 - acc: 0.9960 - val_loss: 0.5054 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00791: val_acc did not improve from 0.91860\n",
            "Epoch 792/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1489 - acc: 0.9949 - val_loss: 0.5046 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00792: val_acc did not improve from 0.91860\n",
            "Epoch 793/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1441 - acc: 0.9966 - val_loss: 0.5041 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00793: val_acc did not improve from 0.91860\n",
            "Epoch 794/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1462 - acc: 0.9963 - val_loss: 0.5076 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00794: val_acc did not improve from 0.91860\n",
            "Epoch 795/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1441 - acc: 0.9974 - val_loss: 0.5053 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00795: val_acc did not improve from 0.91860\n",
            "Epoch 796/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1498 - acc: 0.9943 - val_loss: 0.5081 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00796: val_acc did not improve from 0.91860\n",
            "Epoch 797/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1503 - acc: 0.9951 - val_loss: 0.5062 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00797: val_acc did not improve from 0.91860\n",
            "Epoch 798/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1474 - acc: 0.9964 - val_loss: 0.5041 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00798: val_acc did not improve from 0.91860\n",
            "Epoch 799/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1441 - acc: 0.9966 - val_loss: 0.5062 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00799: val_acc did not improve from 0.91860\n",
            "Epoch 800/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1487 - acc: 0.9954 - val_loss: 0.5072 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00800: val_acc did not improve from 0.91860\n",
            "Epoch 801/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1478 - acc: 0.9943 - val_loss: 0.5039 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00801: val_acc did not improve from 0.91860\n",
            "Epoch 802/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1491 - acc: 0.9940 - val_loss: 0.5045 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00802: val_acc did not improve from 0.91860\n",
            "Epoch 803/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1464 - acc: 0.9969 - val_loss: 0.5045 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00803: val_acc did not improve from 0.91860\n",
            "Epoch 804/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1477 - acc: 0.9948 - val_loss: 0.5052 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00804: val_acc did not improve from 0.91860\n",
            "Epoch 805/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1501 - acc: 0.9938 - val_loss: 0.5057 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00805: val_acc did not improve from 0.91860\n",
            "Epoch 806/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1520 - acc: 0.9939 - val_loss: 0.5053 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00806: val_acc did not improve from 0.91860\n",
            "Epoch 807/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1498 - acc: 0.9938 - val_loss: 0.5050 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00807: val_acc did not improve from 0.91860\n",
            "Epoch 808/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1531 - acc: 0.9938 - val_loss: 0.5050 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00808: val_acc did not improve from 0.91860\n",
            "Epoch 809/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1480 - acc: 0.9955 - val_loss: 0.5051 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00809: val_acc did not improve from 0.91860\n",
            "Epoch 810/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1520 - acc: 0.9935 - val_loss: 0.5051 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00810: val_acc did not improve from 0.91860\n",
            "Epoch 811/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1495 - acc: 0.9945 - val_loss: 0.5053 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00811: val_acc did not improve from 0.91860\n",
            "Epoch 812/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1478 - acc: 0.9953 - val_loss: 0.5053 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00812: val_acc did not improve from 0.91860\n",
            "Epoch 813/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1508 - acc: 0.9935 - val_loss: 0.5061 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00813: val_acc did not improve from 0.91860\n",
            "Epoch 814/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1489 - acc: 0.9951 - val_loss: 0.5066 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00814: val_acc did not improve from 0.91860\n",
            "Epoch 815/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1485 - acc: 0.9950 - val_loss: 0.5061 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00815: val_acc did not improve from 0.91860\n",
            "Epoch 816/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1468 - acc: 0.9954 - val_loss: 0.5060 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00816: val_acc did not improve from 0.91860\n",
            "Epoch 817/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1484 - acc: 0.9946 - val_loss: 0.5057 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00817: val_acc did not improve from 0.91860\n",
            "Epoch 818/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1490 - acc: 0.9945 - val_loss: 0.5064 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00818: val_acc did not improve from 0.91860\n",
            "Epoch 819/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1474 - acc: 0.9957 - val_loss: 0.5074 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00819: val_acc did not improve from 0.91860\n",
            "Epoch 820/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1488 - acc: 0.9942 - val_loss: 0.5066 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00820: val_acc did not improve from 0.91860\n",
            "Epoch 821/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1491 - acc: 0.9944 - val_loss: 0.5070 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00821: val_acc did not improve from 0.91860\n",
            "Epoch 822/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1483 - acc: 0.9945 - val_loss: 0.5063 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00822: val_acc did not improve from 0.91860\n",
            "Epoch 823/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1460 - acc: 0.9969 - val_loss: 0.5065 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00823: val_acc did not improve from 0.91860\n",
            "Epoch 824/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1473 - acc: 0.9949 - val_loss: 0.5066 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00824: val_acc did not improve from 0.91860\n",
            "Epoch 825/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1464 - acc: 0.9960 - val_loss: 0.5076 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00825: val_acc did not improve from 0.91860\n",
            "Epoch 826/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1481 - acc: 0.9948 - val_loss: 0.5075 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00826: val_acc did not improve from 0.91860\n",
            "Epoch 827/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1497 - acc: 0.9942 - val_loss: 0.5074 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00827: val_acc did not improve from 0.91860\n",
            "Epoch 828/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1480 - acc: 0.9951 - val_loss: 0.5071 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00828: val_acc did not improve from 0.91860\n",
            "Epoch 829/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1491 - acc: 0.9936 - val_loss: 0.5066 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00829: val_acc did not improve from 0.91860\n",
            "Epoch 830/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1475 - acc: 0.9942 - val_loss: 0.5060 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00830: val_acc did not improve from 0.91860\n",
            "Epoch 831/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1459 - acc: 0.9959 - val_loss: 0.5064 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00831: val_acc did not improve from 0.91860\n",
            "Epoch 832/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1470 - acc: 0.9954 - val_loss: 0.5061 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00832: val_acc did not improve from 0.91860\n",
            "Epoch 833/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1487 - acc: 0.9952 - val_loss: 0.5060 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00833: val_acc did not improve from 0.91860\n",
            "Epoch 834/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1462 - acc: 0.9971 - val_loss: 0.5062 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00834: val_acc did not improve from 0.91860\n",
            "Epoch 835/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1470 - acc: 0.9958 - val_loss: 0.5067 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00835: val_acc did not improve from 0.91860\n",
            "Epoch 836/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1499 - acc: 0.9951 - val_loss: 0.5057 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00836: val_acc did not improve from 0.91860\n",
            "Epoch 837/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1475 - acc: 0.9952 - val_loss: 0.5061 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00837: val_acc did not improve from 0.91860\n",
            "Epoch 838/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1492 - acc: 0.9937 - val_loss: 0.5062 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00838: val_acc did not improve from 0.91860\n",
            "Epoch 839/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1495 - acc: 0.9941 - val_loss: 0.5063 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00839: val_acc did not improve from 0.91860\n",
            "Epoch 840/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1486 - acc: 0.9945 - val_loss: 0.5065 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00840: val_acc did not improve from 0.91860\n",
            "Epoch 841/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1492 - acc: 0.9948 - val_loss: 0.5064 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00841: val_acc did not improve from 0.91860\n",
            "Epoch 842/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1515 - acc: 0.9940 - val_loss: 0.5063 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00842: val_acc did not improve from 0.91860\n",
            "Epoch 843/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1473 - acc: 0.9958 - val_loss: 0.5054 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00843: val_acc did not improve from 0.91860\n",
            "Epoch 844/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1515 - acc: 0.9940 - val_loss: 0.5075 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00844: val_acc did not improve from 0.91860\n",
            "Epoch 845/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1494 - acc: 0.9954 - val_loss: 0.5066 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00845: val_acc did not improve from 0.91860\n",
            "Epoch 846/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1520 - acc: 0.9936 - val_loss: 0.5065 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00846: val_acc did not improve from 0.91860\n",
            "Epoch 847/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1503 - acc: 0.9928 - val_loss: 0.5065 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00847: val_acc did not improve from 0.91860\n",
            "Epoch 848/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1489 - acc: 0.9954 - val_loss: 0.5070 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00848: val_acc did not improve from 0.91860\n",
            "Epoch 849/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1471 - acc: 0.9957 - val_loss: 0.5064 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00849: val_acc did not improve from 0.91860\n",
            "Epoch 850/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1485 - acc: 0.9954 - val_loss: 0.5067 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00850: val_acc did not improve from 0.91860\n",
            "Epoch 851/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1484 - acc: 0.9956 - val_loss: 0.5064 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00851: val_acc did not improve from 0.91860\n",
            "Epoch 852/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1458 - acc: 0.9961 - val_loss: 0.5068 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00852: val_acc did not improve from 0.91860\n",
            "Epoch 853/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1494 - acc: 0.9937 - val_loss: 0.5061 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00853: val_acc did not improve from 0.91860\n",
            "Epoch 854/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1481 - acc: 0.9951 - val_loss: 0.5068 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00854: val_acc did not improve from 0.91860\n",
            "Epoch 855/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1477 - acc: 0.9957 - val_loss: 0.5069 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00855: val_acc did not improve from 0.91860\n",
            "Epoch 856/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1493 - acc: 0.9945 - val_loss: 0.5064 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00856: val_acc did not improve from 0.91860\n",
            "Epoch 857/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1496 - acc: 0.9940 - val_loss: 0.5062 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00857: val_acc did not improve from 0.91860\n",
            "Epoch 858/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1500 - acc: 0.9954 - val_loss: 0.5065 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00858: val_acc did not improve from 0.91860\n",
            "Epoch 859/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1482 - acc: 0.9939 - val_loss: 0.5074 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00859: val_acc did not improve from 0.91860\n",
            "Epoch 860/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1495 - acc: 0.9943 - val_loss: 0.5067 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00860: val_acc did not improve from 0.91860\n",
            "Epoch 861/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1474 - acc: 0.9953 - val_loss: 0.5056 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00861: val_acc did not improve from 0.91860\n",
            "Epoch 862/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1498 - acc: 0.9952 - val_loss: 0.5058 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00862: val_acc did not improve from 0.91860\n",
            "Epoch 863/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1476 - acc: 0.9956 - val_loss: 0.5056 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00863: val_acc did not improve from 0.91860\n",
            "Epoch 864/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1472 - acc: 0.9959 - val_loss: 0.5064 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00864: val_acc did not improve from 0.91860\n",
            "Epoch 865/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1471 - acc: 0.9953 - val_loss: 0.5070 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00865: val_acc did not improve from 0.91860\n",
            "Epoch 866/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1462 - acc: 0.9959 - val_loss: 0.5083 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00866: val_acc did not improve from 0.91860\n",
            "Epoch 867/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1482 - acc: 0.9948 - val_loss: 0.5070 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00867: val_acc did not improve from 0.91860\n",
            "Epoch 868/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1508 - acc: 0.9928 - val_loss: 0.5069 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00868: val_acc did not improve from 0.91860\n",
            "Epoch 869/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1470 - acc: 0.9958 - val_loss: 0.5070 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00869: val_acc did not improve from 0.91860\n",
            "Epoch 870/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1460 - acc: 0.9958 - val_loss: 0.5071 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00870: val_acc did not improve from 0.91860\n",
            "Epoch 871/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1492 - acc: 0.9940 - val_loss: 0.5076 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00871: val_acc did not improve from 0.91860\n",
            "Epoch 872/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1468 - acc: 0.9953 - val_loss: 0.5070 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00872: val_acc did not improve from 0.91860\n",
            "Epoch 873/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1492 - acc: 0.9940 - val_loss: 0.5075 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00873: val_acc did not improve from 0.91860\n",
            "Epoch 874/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1469 - acc: 0.9946 - val_loss: 0.5067 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00874: val_acc did not improve from 0.91860\n",
            "Epoch 875/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1428 - acc: 0.9977 - val_loss: 0.5069 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00875: val_acc did not improve from 0.91860\n",
            "Epoch 876/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1465 - acc: 0.9953 - val_loss: 0.5068 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00876: val_acc did not improve from 0.91860\n",
            "Epoch 877/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1452 - acc: 0.9970 - val_loss: 0.5069 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00877: val_acc did not improve from 0.91860\n",
            "Epoch 878/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1468 - acc: 0.9951 - val_loss: 0.5071 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00878: val_acc did not improve from 0.91860\n",
            "Epoch 879/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1538 - acc: 0.9928 - val_loss: 0.5072 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00879: val_acc did not improve from 0.91860\n",
            "Epoch 880/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1477 - acc: 0.9954 - val_loss: 0.5061 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00880: val_acc did not improve from 0.91860\n",
            "Epoch 881/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1460 - acc: 0.9959 - val_loss: 0.5073 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00881: val_acc did not improve from 0.91860\n",
            "Epoch 882/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1495 - acc: 0.9948 - val_loss: 0.5070 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00882: val_acc did not improve from 0.91860\n",
            "Epoch 883/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1482 - acc: 0.9949 - val_loss: 0.5067 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00883: val_acc did not improve from 0.91860\n",
            "Epoch 884/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1490 - acc: 0.9943 - val_loss: 0.5075 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00884: val_acc did not improve from 0.91860\n",
            "Epoch 885/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1481 - acc: 0.9953 - val_loss: 0.5074 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00885: val_acc did not improve from 0.91860\n",
            "Epoch 886/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1470 - acc: 0.9954 - val_loss: 0.5076 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00886: val_acc did not improve from 0.91860\n",
            "Epoch 887/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1460 - acc: 0.9954 - val_loss: 0.5067 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00887: val_acc did not improve from 0.91860\n",
            "Epoch 888/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1471 - acc: 0.9958 - val_loss: 0.5070 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00888: val_acc did not improve from 0.91860\n",
            "Epoch 889/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1482 - acc: 0.9946 - val_loss: 0.5068 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00889: val_acc did not improve from 0.91860\n",
            "Epoch 890/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1476 - acc: 0.9954 - val_loss: 0.5080 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00890: val_acc did not improve from 0.91860\n",
            "Epoch 891/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1479 - acc: 0.9945 - val_loss: 0.5075 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00891: val_acc did not improve from 0.91860\n",
            "Epoch 892/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1487 - acc: 0.9946 - val_loss: 0.5079 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00892: val_acc did not improve from 0.91860\n",
            "Epoch 893/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1456 - acc: 0.9969 - val_loss: 0.5074 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00893: val_acc did not improve from 0.91860\n",
            "Epoch 894/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1485 - acc: 0.9941 - val_loss: 0.5076 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00894: val_acc did not improve from 0.91860\n",
            "Epoch 895/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1463 - acc: 0.9962 - val_loss: 0.5073 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00895: val_acc did not improve from 0.91860\n",
            "Epoch 896/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1476 - acc: 0.9945 - val_loss: 0.5084 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00896: val_acc did not improve from 0.91860\n",
            "Epoch 897/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1495 - acc: 0.9953 - val_loss: 0.5079 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00897: val_acc did not improve from 0.91860\n",
            "Epoch 898/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1499 - acc: 0.9945 - val_loss: 0.5066 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00898: val_acc did not improve from 0.91860\n",
            "Epoch 899/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1468 - acc: 0.9953 - val_loss: 0.5067 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00899: val_acc did not improve from 0.91860\n",
            "Epoch 900/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1481 - acc: 0.9954 - val_loss: 0.5082 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00900: val_acc did not improve from 0.91860\n",
            "Epoch 901/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1478 - acc: 0.9955 - val_loss: 0.5073 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00901: val_acc did not improve from 0.91860\n",
            "Epoch 902/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1528 - acc: 0.9935 - val_loss: 0.5077 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00902: val_acc did not improve from 0.91860\n",
            "Epoch 903/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1472 - acc: 0.9947 - val_loss: 0.5073 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00903: val_acc did not improve from 0.91860\n",
            "Epoch 904/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1488 - acc: 0.9944 - val_loss: 0.5059 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00904: val_acc did not improve from 0.91860\n",
            "Epoch 905/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1445 - acc: 0.9968 - val_loss: 0.5072 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00905: val_acc did not improve from 0.91860\n",
            "Epoch 906/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1449 - acc: 0.9962 - val_loss: 0.5060 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00906: val_acc did not improve from 0.91860\n",
            "Epoch 907/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1466 - acc: 0.9958 - val_loss: 0.5066 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00907: val_acc did not improve from 0.91860\n",
            "Epoch 908/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1475 - acc: 0.9960 - val_loss: 0.5071 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00908: val_acc did not improve from 0.91860\n",
            "Epoch 909/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1475 - acc: 0.9959 - val_loss: 0.5066 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00909: val_acc did not improve from 0.91860\n",
            "Epoch 910/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1462 - acc: 0.9961 - val_loss: 0.5068 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00910: val_acc did not improve from 0.91860\n",
            "Epoch 911/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1446 - acc: 0.9969 - val_loss: 0.5060 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00911: val_acc did not improve from 0.91860\n",
            "Epoch 912/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1449 - acc: 0.9963 - val_loss: 0.5054 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00912: val_acc did not improve from 0.91860\n",
            "Epoch 913/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1485 - acc: 0.9941 - val_loss: 0.5068 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00913: val_acc did not improve from 0.91860\n",
            "Epoch 914/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1479 - acc: 0.9953 - val_loss: 0.5065 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00914: val_acc did not improve from 0.91860\n",
            "Epoch 915/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1481 - acc: 0.9950 - val_loss: 0.5074 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00915: val_acc did not improve from 0.91860\n",
            "Epoch 916/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1460 - acc: 0.9967 - val_loss: 0.5067 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00916: val_acc did not improve from 0.91860\n",
            "Epoch 917/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1440 - acc: 0.9971 - val_loss: 0.5078 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00917: val_acc did not improve from 0.91860\n",
            "Epoch 918/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1446 - acc: 0.9969 - val_loss: 0.5066 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00918: val_acc did not improve from 0.91860\n",
            "Epoch 919/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1460 - acc: 0.9969 - val_loss: 0.5060 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00919: val_acc did not improve from 0.91860\n",
            "Epoch 920/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1475 - acc: 0.9944 - val_loss: 0.5063 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00920: val_acc did not improve from 0.91860\n",
            "Epoch 921/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1471 - acc: 0.9957 - val_loss: 0.5072 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00921: val_acc did not improve from 0.91860\n",
            "Epoch 922/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1486 - acc: 0.9929 - val_loss: 0.5070 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00922: val_acc did not improve from 0.91860\n",
            "Epoch 923/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1448 - acc: 0.9960 - val_loss: 0.5077 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00923: val_acc did not improve from 0.91860\n",
            "Epoch 924/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1482 - acc: 0.9948 - val_loss: 0.5059 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00924: val_acc did not improve from 0.91860\n",
            "Epoch 925/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1484 - acc: 0.9951 - val_loss: 0.5077 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00925: val_acc did not improve from 0.91860\n",
            "Epoch 926/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1469 - acc: 0.9957 - val_loss: 0.5081 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00926: val_acc did not improve from 0.91860\n",
            "Epoch 927/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1492 - acc: 0.9932 - val_loss: 0.5072 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00927: val_acc did not improve from 0.91860\n",
            "Epoch 928/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1502 - acc: 0.9947 - val_loss: 0.5071 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00928: val_acc did not improve from 0.91860\n",
            "Epoch 929/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1465 - acc: 0.9960 - val_loss: 0.5075 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00929: val_acc did not improve from 0.91860\n",
            "Epoch 930/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1447 - acc: 0.9965 - val_loss: 0.5085 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00930: val_acc did not improve from 0.91860\n",
            "Epoch 931/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1488 - acc: 0.9953 - val_loss: 0.5081 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00931: val_acc did not improve from 0.91860\n",
            "Epoch 932/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1477 - acc: 0.9952 - val_loss: 0.5076 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00932: val_acc did not improve from 0.91860\n",
            "Epoch 933/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1471 - acc: 0.9958 - val_loss: 0.5078 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00933: val_acc did not improve from 0.91860\n",
            "Epoch 934/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1469 - acc: 0.9959 - val_loss: 0.5071 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00934: val_acc did not improve from 0.91860\n",
            "Epoch 935/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1480 - acc: 0.9947 - val_loss: 0.5069 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00935: val_acc did not improve from 0.91860\n",
            "Epoch 936/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1453 - acc: 0.9954 - val_loss: 0.5084 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00936: val_acc did not improve from 0.91860\n",
            "Epoch 937/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1472 - acc: 0.9955 - val_loss: 0.5079 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00937: val_acc did not improve from 0.91860\n",
            "Epoch 938/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1488 - acc: 0.9944 - val_loss: 0.5076 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00938: val_acc did not improve from 0.91860\n",
            "Epoch 939/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1496 - acc: 0.9942 - val_loss: 0.5070 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00939: val_acc did not improve from 0.91860\n",
            "Epoch 940/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1501 - acc: 0.9937 - val_loss: 0.5078 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00940: val_acc did not improve from 0.91860\n",
            "Epoch 941/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1461 - acc: 0.9958 - val_loss: 0.5082 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00941: val_acc did not improve from 0.91860\n",
            "Epoch 942/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1471 - acc: 0.9962 - val_loss: 0.5082 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00942: val_acc did not improve from 0.91860\n",
            "Epoch 943/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1484 - acc: 0.9958 - val_loss: 0.5083 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00943: val_acc did not improve from 0.91860\n",
            "Epoch 944/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1431 - acc: 0.9974 - val_loss: 0.5075 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00944: val_acc did not improve from 0.91860\n",
            "Epoch 945/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1462 - acc: 0.9959 - val_loss: 0.5074 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00945: val_acc did not improve from 0.91860\n",
            "Epoch 946/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1481 - acc: 0.9957 - val_loss: 0.5075 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00946: val_acc did not improve from 0.91860\n",
            "Epoch 947/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1493 - acc: 0.9947 - val_loss: 0.5078 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00947: val_acc did not improve from 0.91860\n",
            "Epoch 948/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1457 - acc: 0.9967 - val_loss: 0.5067 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00948: val_acc did not improve from 0.91860\n",
            "Epoch 949/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1479 - acc: 0.9945 - val_loss: 0.5064 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00949: val_acc did not improve from 0.91860\n",
            "Epoch 950/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1464 - acc: 0.9957 - val_loss: 0.5060 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00950: val_acc did not improve from 0.91860\n",
            "Epoch 951/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1459 - acc: 0.9965 - val_loss: 0.5072 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00951: val_acc did not improve from 0.91860\n",
            "Epoch 952/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1461 - acc: 0.9960 - val_loss: 0.5064 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00952: val_acc did not improve from 0.91860\n",
            "Epoch 953/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1471 - acc: 0.9940 - val_loss: 0.5066 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00953: val_acc did not improve from 0.91860\n",
            "Epoch 954/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1498 - acc: 0.9954 - val_loss: 0.5066 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00954: val_acc did not improve from 0.91860\n",
            "Epoch 955/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1510 - acc: 0.9939 - val_loss: 0.5078 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00955: val_acc did not improve from 0.91860\n",
            "Epoch 956/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1483 - acc: 0.9954 - val_loss: 0.5068 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00956: val_acc did not improve from 0.91860\n",
            "Epoch 957/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1503 - acc: 0.9934 - val_loss: 0.5072 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00957: val_acc did not improve from 0.91860\n",
            "Epoch 958/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1446 - acc: 0.9963 - val_loss: 0.5070 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00958: val_acc did not improve from 0.91860\n",
            "Epoch 959/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1471 - acc: 0.9955 - val_loss: 0.5082 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00959: val_acc did not improve from 0.91860\n",
            "Epoch 960/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1473 - acc: 0.9952 - val_loss: 0.5069 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00960: val_acc did not improve from 0.91860\n",
            "Epoch 961/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1466 - acc: 0.9958 - val_loss: 0.5071 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00961: val_acc did not improve from 0.91860\n",
            "Epoch 962/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1502 - acc: 0.9945 - val_loss: 0.5074 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00962: val_acc did not improve from 0.91860\n",
            "Epoch 963/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1505 - acc: 0.9944 - val_loss: 0.5083 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00963: val_acc did not improve from 0.91860\n",
            "Epoch 964/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1464 - acc: 0.9954 - val_loss: 0.5061 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00964: val_acc did not improve from 0.91860\n",
            "Epoch 965/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1492 - acc: 0.9948 - val_loss: 0.5062 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00965: val_acc did not improve from 0.91860\n",
            "Epoch 966/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1471 - acc: 0.9950 - val_loss: 0.5070 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00966: val_acc did not improve from 0.91860\n",
            "Epoch 967/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1465 - acc: 0.9946 - val_loss: 0.5066 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00967: val_acc did not improve from 0.91860\n",
            "Epoch 968/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1477 - acc: 0.9952 - val_loss: 0.5065 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00968: val_acc did not improve from 0.91860\n",
            "Epoch 969/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1483 - acc: 0.9950 - val_loss: 0.5076 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00969: val_acc did not improve from 0.91860\n",
            "Epoch 970/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1477 - acc: 0.9941 - val_loss: 0.5071 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00970: val_acc did not improve from 0.91860\n",
            "Epoch 971/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1448 - acc: 0.9967 - val_loss: 0.5084 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00971: val_acc did not improve from 0.91860\n",
            "Epoch 972/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1461 - acc: 0.9959 - val_loss: 0.5065 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00972: val_acc did not improve from 0.91860\n",
            "Epoch 973/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1494 - acc: 0.9941 - val_loss: 0.5084 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00973: val_acc did not improve from 0.91860\n",
            "Epoch 974/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1464 - acc: 0.9967 - val_loss: 0.5068 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00974: val_acc did not improve from 0.91860\n",
            "Epoch 975/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1454 - acc: 0.9963 - val_loss: 0.5075 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00975: val_acc did not improve from 0.91860\n",
            "Epoch 976/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1490 - acc: 0.9947 - val_loss: 0.5076 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00976: val_acc did not improve from 0.91860\n",
            "Epoch 977/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1475 - acc: 0.9951 - val_loss: 0.5074 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00977: val_acc did not improve from 0.91860\n",
            "Epoch 978/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1462 - acc: 0.9948 - val_loss: 0.5071 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00978: val_acc did not improve from 0.91860\n",
            "Epoch 979/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1456 - acc: 0.9960 - val_loss: 0.5073 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00979: val_acc did not improve from 0.91860\n",
            "Epoch 980/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1468 - acc: 0.9954 - val_loss: 0.5071 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00980: val_acc did not improve from 0.91860\n",
            "Epoch 981/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1478 - acc: 0.9949 - val_loss: 0.5082 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00981: val_acc did not improve from 0.91860\n",
            "Epoch 982/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1424 - acc: 0.9974 - val_loss: 0.5074 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00982: val_acc did not improve from 0.91860\n",
            "Epoch 983/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1460 - acc: 0.9953 - val_loss: 0.5068 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00983: val_acc did not improve from 0.91860\n",
            "Epoch 984/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1436 - acc: 0.9968 - val_loss: 0.5071 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00984: val_acc did not improve from 0.91860\n",
            "Epoch 985/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1458 - acc: 0.9950 - val_loss: 0.5074 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00985: val_acc did not improve from 0.91860\n",
            "Epoch 986/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1483 - acc: 0.9950 - val_loss: 0.5064 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00986: val_acc did not improve from 0.91860\n",
            "Epoch 987/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1466 - acc: 0.9964 - val_loss: 0.5065 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00987: val_acc did not improve from 0.91860\n",
            "Epoch 988/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1446 - acc: 0.9962 - val_loss: 0.5059 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00988: val_acc did not improve from 0.91860\n",
            "Epoch 989/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1478 - acc: 0.9956 - val_loss: 0.5065 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00989: val_acc did not improve from 0.91860\n",
            "Epoch 990/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1484 - acc: 0.9948 - val_loss: 0.5063 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00990: val_acc did not improve from 0.91860\n",
            "Epoch 991/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1487 - acc: 0.9955 - val_loss: 0.5065 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00991: val_acc did not improve from 0.91860\n",
            "Epoch 992/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1476 - acc: 0.9955 - val_loss: 0.5076 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00992: val_acc did not improve from 0.91860\n",
            "Epoch 993/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1506 - acc: 0.9932 - val_loss: 0.5058 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00993: val_acc did not improve from 0.91860\n",
            "Epoch 994/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1483 - acc: 0.9942 - val_loss: 0.5064 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00994: val_acc did not improve from 0.91860\n",
            "Epoch 995/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1510 - acc: 0.9944 - val_loss: 0.5069 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00995: val_acc did not improve from 0.91860\n",
            "Epoch 996/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1465 - acc: 0.9960 - val_loss: 0.5062 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00996: val_acc did not improve from 0.91860\n",
            "Epoch 997/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1484 - acc: 0.9958 - val_loss: 0.5076 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00997: val_acc did not improve from 0.91860\n",
            "Epoch 998/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1451 - acc: 0.9965 - val_loss: 0.5070 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00998: val_acc did not improve from 0.91860\n",
            "Epoch 999/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1434 - acc: 0.9972 - val_loss: 0.5078 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00999: val_acc did not improve from 0.91860\n",
            "Epoch 1000/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1444 - acc: 0.9973 - val_loss: 0.5084 - val_acc: 0.9164\n",
            "\n",
            "Epoch 01000: val_acc did not improve from 0.91860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "x2NvLySCxHCC",
        "outputId": "55090288-1ad1-44c6-b1f0-952514c1fd70"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('simple_trainHistoryDict', \"rb\"))\n",
        "functions.plot_loss_acc(history, 2, 0.4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAGDCAYAAADZHo16AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9ebxkVX3u/V01n7nnge6GBm1AZgQRI9EmMYp6BRNNEKOZjLy5r3NibshNXk1I9HpjrvfGq8YhISZvAlyEGImCJBo6oEJkaqEbaLqBnml6Pn2mOqeGdf9Ye9XeVafG02coqp7v53M+tWvvXbtWHZpfPefZz/otY61FCCGEEEIIERJb6AEIIYQQQgjRbkgkCyGEEEIIUYFEshBCCCGEEBVIJAshhBBCCFGBRLIQQgghhBAVSCQLIYQQQghRgUSyEEIIIYQQFUgki5c8xpidxpg3LPQ4hBBC1Cao1RPGmNHIzxcWelxC1CKx0AMQQgghRNfwNmvt9+qdYIxJWGvzFfvi1tpCs2/S6vlCVENOsuhIjDFpY8z/MsbsD37+lzEmHRxbZoz5tjHmuDHmqDHmfmNMLDj2e8aYfcaYEWPMNmPMzy7sJxFCiM7GGPNrxpgfGmP+pzHmCPBHxpivG2P+0hhzlzFmDLjSGPMKY8ymoHZvNcZcHbnGtPMX7AOJjkFOsuhU/gC4HLgIsMC3gD8E/j/gd4C9wPLg3MsBa4w5C/gg8Cpr7X5jzHogPr/DFkKIruTVwK3ASiAJ/CXwbuAtwH8C+oDHgJuANwJXAN8yxlxqrd0WXCN6fmpeRy86EjnJolP5ZeBGa+1Ba+0h4I+B9wbHcsBq4DRrbc5ae7+11gIFIA2cY4xJWmt3WmufXZDRCyFEZ/JPgRPsf94f7N9vrf3f1tq8tXYi2Pcta+0PrbVFnOHRD3zGWjtlrf034NvAdZFrl8631mbn7yOJTkUiWXQqpwC7Is93BfsAPgvsAP7FGPOcMeYGAGvtDuCjwB8BB40xtxpjTkEIIcRs8XZr7aLIz9eC/XuqnBvddwqwJxDMnl3AmhrnC3HSSCSLTmU/cFrk+anBPqy1I9ba37HWngFcDfy2zx5ba2+21l4RvNYC/31+hy2EEF2JbbBvP7DOzx8JOBXY1+AaQswYiWTRKSSNMRn/A9wC/KExZrkxZhnwCeDvAYwx/8kY83JjjAGGcTGLojHmLGPMzwQT/LLABFCs/nZCCCHmkf8AxoH/YoxJGmM2Am/D5ZiFmBMkkkWncBdO1PqfDPAw8DjwBPAo8KfBuRuA7wGjwAPAl6y19+LyyJ8BDgMHgBXA78/fRxBCiI7nnyv6JH+zmRdZa6dwovjNuBr9JeBXrLVPz+FYRZdj3HwlIYQQQgghhEdOshBCCCGEEBU0FMnGmHXGmHuNMU8Gzbs/UuUcY4z5vDFmhzHmcWPMKyPHftUYsz34+dXZ/gBCCCHKMcZcFSyGs8N3b6lx3juMMdYYc2lk3+8Hr9tmjHnT/IxYCCHaj4ZxC2PMamC1tfZRY8wA8AiuhcuTkXPeAnwI18T71cBfWGtfbYxZgsuFXoqbdfoIcIm19ticfBohhOhyjDFx4Bng53CL5jwEXBet2cF5A8B3cIsufNBa+7Ax5hzcpNfLcC23vgecqeV9hRDdSEMn2Vr7grX20WB7BHiK8r6EANcAf2cdDwKLAnH9JuBfrbVHA2H8r8BVs/oJhBBCRLkM2GGtfS6Y7HQrrkZX8ie4FofRRReuAW611k5aa5/H9RO/bK4HLIQQ7UhLmeRgmd6Lca1YoqyhvIn33mBfrf1CCCHmhoZ1N4jErbPWfqfV1wohRLeQaPZEY0w/cAfwUWvtidkeiDHmeuB6gJ6enkvWrVvX0uuLxSKxWKj5Y8UcfWNuwbXx3rUU4pnZG2yLY1lINJb2HQdoLLVol7HMZBzPPPPMYWvt8jka0kkTLMbwOeDXTvI6J1WzT0xZjmYtr0gcwFAkn+glPXmUsb7T6BvbRbZnJbnEwMkMsWna5d8baCy1aJextMs4QGOpRatjqVuzrbUNf4AkcA/w2zWOfwWXefPPtwGrcWuqf6XWebV+LrnkEtsq9957b/mOg9us/eSg+9n1YMvXOxmmjWUB0Vim0y7jsFZjqUW7jGUm4wAetk3U1bn6AV4D3BN5/vvA70eeD+H6zO4MfrK41cwurXLuPcBrGr3nTGr23z+40572e9+22a//grVffp213/8Taz85ZO3hHa5ub76l5WvOlHb592atxlKLdhlLu4zDWo2lFq2OpV7Nbqa7hQH+GnjKWvu5GqfdCfxK0OXicmDYWvtCUGDfaIxZbIxZDLwx2Df3RJd315wTIUT38BCwwRhzujEmBbwLV6MBsNYOW2uXWWvXW2vXAw8CV1trHw7Oe5cxJm2MOR238M6P52KQiZgBoGgSUCy4n1gCYnF3QlF1WwixsDQTt3gt8F7gCWPM5mDff8WtmY619su41c7egpvkMQ78enDsqDHmT3BFG+BGa+3R2Rt+HaIiWcVWCNElWGvzxpgP4gyJOHCTtXarMeZGnGNyZ53XbjXG3AY8CeSBD9g56mwRD26HWhOHYg6KeSeQTSCSZW4IIRaYhiLZWvsDwDQ4xwIfqHHsJuCmGY3uZIgWWBVbIUQXYa29C2deRPd9osa5Gyuefwr41JwNLqDkJMcSTiDbohPIcpKFEG1C0xP3XnLISRZiQcjlcuzdu5dsNtv45BoMDQ3x1FNPzeKoZn8cmUyGtWvXkkwm53lUnUG8FLeIO5Hs4xZykoWYVzqpZkPtscykZneHSI5uCyHmlL179zIwMMD69etxUxpaZ2RkhIGB+elsMJNxWGs5cuQIe/fu5fTTT1+Akb30ScYDkUw8yCTnIRaLOMmq20LMB51Us6H6WGZas9ujX8dcICdZiAUhm82ydOnSGRfblwLGGJYuXXpSzku34zPJRROHQs45xyYOJvhakpMsxLygml2bzhXJRXW3EGKh6ORi6+mGzziXlHe3yKu7hRALSDfUs5l8xs4VyXKShehKjh8/zpe+9KWWX/eWt7yF48ePz8GIRDWqZ5LV3UKIbqOda3Z3iGQVWyG6hloFN5/P133dXXfdxaJFi+ZqWKIC7yQXfCbZxy3kJAvRVbRzze6OiXsqtkJ0DTfccAPPPvssF110Eclkkkwmw+LFi3n66ad55plnePvb386ePXvIZrN85CMf4frrrwdg/fr1PPzww4yOjvLmN7+ZK664gh/84AesW7eOb33rW/T09CzwJ+ssvJNcKPVJlpMsRDcymzX7Rz/6EStXruQ73/nOrNTsDhbJ0T7JmiUtxELwx/+8lSf3n2j5dYVCgXg8XvXYOacM8sm3nVvztZ/5zGfYsmULmzdvZtOmTbz1rW9ly5YtpRnNN910E0uWLGFiYoJXvepVvOMd72Dp0qVl19i+fTu33HILn/vc53jf+97HHXfcwXve856WP4eoTSLubmQWSpnkYDERdbcQYsF4qdfsr33ta/zCL/zCrNXs7ohbyEkWomu57LLLylr+fP7zn+fCCy/k8ssvZ8+ePWzfvn3aa04//XQuuugiAC655BJ27tw5X8PtGkoT94gFi4mou4UQ4uRr9kUXXTRrNbuDnWRlkoVYaOq5B/WYzZ6bfX19pe1Nmzbxve99jwceeIDe3l42btxYtSVQOp0ubcfjcSYmJmZlLCIkHs0kA+SngsVEjBPKMjeEmHc6pWbncrlZGYucZCFERzEwMMDIyEjVY8PDwyxevJje3l6efvppHnzwwXkenfAk4pUiOesWEwHnKMvcEKIraOea3blOsvokC9GVLF26lNe+9rWcd9559PT0sHLlytKxq666ii9/+cu84hWv4KyzzuLyyy9fwJF2Nz5ukTfB11BhKpy0F4vL3BCiS2jnmt25IllOshBdy80331x1fzqd5u677656zGfYli1bxpYtW0r7P/7xj8/6+ES44l7B39DMT7q4BQROsibuCdEtzGbN/vCHPzxr0Y/uiFuo2AohRFtRcpKtj1tMhp0t5CQLIdqA7hDJKrZCCNFWVM0k+7iFiSkmJ4RYcDpYJBeqbwshhFhw4qVMciCMC3KShRDtRQeLZDnJQgjRriR8Jrla3ELdLYQQbUB3iGQVWyGEaCu8k5yLTtxTdwshRBvRwSLZhtta3lQIIdoKP3GvYNXdQgjRnnSuSC4qkyyEaEx/f/9CD6Er8RP3JmLB6lr5iUgmWSvuCSGqM581u3NFsjLJQgjRtvhM8rH0mnCnMslCiDaiOxYTUbEVomu44YYbWLduHR/4wAcA+KM/+iMSiQT33nsvx44dI5fL8ad/+qdcc801CzzS7iZIW3A0tTpo+VZUJlmILqSda3Z3iGQVWyEWhrtvgANPtPyynkIe4jXK06rz4c2fqfnaa6+9lo9+9KOlgnvbbbdxzz338OEPf5jBwUEOHz7M5ZdfztVXX40xpuWxidnBGEPcQI44DK2D47vkJAux0Khml9HBIlmZZCG6kYsvvpiDBw+yf/9+Dh06xOLFi1m1ahUf+9jHuO+++4jFYuzbt48XX3yRVatWLfRwu5qYgXzBwpIzApEcfCXJSRaia2jnmt3BIjnqJGuWtBALQh33oB4TIyMMDAzM+G1/8Rd/kdtvv50DBw5w7bXX8g//8A8cOnSIRx55hGQyyfr168lmszO+vpgd4gbyxUAkP3dvZMU9dbcQYkFQzS6jO0SynGQhuoprr72W97///Rw+fJh///d/57bbbmPFihUkk0nuvfdedu3atdBDFEA8BoWiheUvczuCyXzqbiFEd9GuNbuDRXK0T7KKrRDdxLnnnsvIyAhr1qxh9erV/PIv/zJve9vbOP/887n00ks5++yzF3qIgiBuUSw6Jxkq+iSrbgvRLbRrze5ckeyFsYqtEF3JE0+Ek0+WLVvGAw88UPW80dHR+RqSqCBujHOSvUhWdwshupZ2rNmd3yc5nlSxFUKINiRmIFewsOg0wKi7hRCirehcJ9mL5FhSxVYIIdqQuAkyyckMvOYDcMaV7kAsrgnXQogFp/NFcjyhYiuEEG1IqbsFwJs+FR4wMSjmF2ZQQggR0MFxi8A9jqfkJAsxz9joxNkOpRs+41wTi0GhmomhTLIQ80o31LOZfMaGItkYc5Mx5qAxZkuN479rjNkc/GwxxhSMMUuCYzuNMU8Exx5ueXQnQzRuoWIrxLyRyWQ4cuRIRxdday1Hjhwhk8ks9FCqYoy5yhizzRizwxhzQ5XjvxWpzT8wxpwT7F9vjJmI1PQvz+U448a4xUSmDVCZZCHmC9Xs2jQTt/g68AXg72q88WeBzwIYY94GfMxaezRyypXW2sMtjWo2iMYtVGyFmDfWrl3L3r17OXTo0Iyvkc1m20KA1htHJpNh7dq18zyixhhj4sAXgZ8D9gIPGWPutNY+GTntZmvtl4PzrwY+B1wVHHvWWnvRfIw15jPJ0w7ISRZivuikmg21xzKTmt1QJFtr7zPGrG/yetcBt7Q0grnC/0UkJ1mIeSWZTHL66aef1DU2bdrExRdfPEsjeumPo0UuA3ZYa58DMMbcClwDlESytfZE5Pw+YEEspLiBXDWRLCdZiHmjk2o2zO5YTDP2eiCSv22tPa/OOb041+Ll3kk2xjwPHMMV4K9Ya79a5/XXA9cDrFy58pJbb721+U+B65vX399fer7++VtYv+tWRvtOY6JnFVvP+68tXe9kqBzLQqKxtO84QGOpRbuMZSbjuPLKKx+x1l46R0NqiDHmncBV1trfDJ6/F3i1tfaDFed9APhtIAX8jLV2e1DrtwLPACeAP7TW3l/jfU6qZgPc+MNRMqk4/+VVPWX7z93yaXomDvDwqz7f8jVnQrv8ewONpRbtMpZ2GQdoLLVodSx1a7a1tuEPsB7Y0uCca4F/rti3JnhcAfwEeF0z73fJJZfYVrn33nvLd3z/T6395JC1f/laa//h2pavdzJMG8sCorFMp13GYa3GUot2GctMxgE8bJuoc3P1A7wT+KvI8/cCX6hz/ruBvw2208DSYPsSYA8w2Og9Z1KzrbX2jZ+5y/7Sl380/cCt77H2C5fN6JozoV3+vVmrsdSiXcbSLuOwVmOpRatjqVezZ7O7xbuoiFpYa/cFjweBb+JuA84PtujaCOm2nRCiu9gHrIs8Xxvsq8WtwNsBrLWT1tojwfYjwLPAmXM0TuIxZZKFEO3LrIhkY8wQ8HrgW5F9fcaYAb8NvBGo2iFjTvAiWcVWCNFdPARsMMacboxJ4QyMO6MnGGM2RJ6+Fdge7F8eTPzDGHMGsAF4bq4GGjNGmWQhRNvScOKeMeYWYCOwzBizF/gkkASwwexo4OeBf7HWjkVeuhL4pjHGv8/N1trvzt7QG2ALcpKFEF2HtTZvjPkgcA8QB26y1m41xtyIu614J/BBY8wbgBxu3sivBi9/HXCjMSYHFIHfsuXdimaVhIGpfJU+ySYmc0MIseA0093iuibO+TquVVx033PAhTMd2Elji85FlpMshOgyrLV3AXdV7PtEZPsjNV53B3DH3I4uJBGD0UKNxUSsVkoVQiwsHbzino04ySq2QgjRbiRjtZxkmRtCiIWng0WyzyTrtp0QQrQjiZipLpJjMcXkhBALTueK5GIBjFEmWQgh2pREDHLV4ha6AyiEaAM6VyTboiu0yiQLIURbkqgVt1DdFkK0AR0uktXdQggh2pVkzDBZ00lW3RZCLCydL5JjcSjqtp0QQrQb3kl2i15FUN0WQrQBHSySfZ9kTQARQoh2JBF8A+UrFxRR3RZCtAGdJZJ/8n/g0Da3rT7JQgjR1niRPC2XrLothGgDOkckWwvf+gA88rfhc2WShRCibUm6FVmni2TVbSFEG9AxIjleGIdiDgpTboctuhZwciSEEKItKTnJlZP3VLeFEG1Ax4jkZO6E2/AiuViQkyyEEG1MzbiFiQPW3REUQogFooNE8ojbKOTcY1mfZM2SFkKIdiMZC+IW1ZxkkJsshFhQOkgkVzjJpT7JmiUthBDtSLymkxwcUO0WQiwgHSSSvZNcIZKVbRNCiLYkWa+7Bah2CyEWlA4Syd5J9nELZZKFEKKdSdSKW5hAJKt2CyEWkA4SyZVOslWfZCGEaGO8k5yTkyyEaEM6SCQHTnIxOnHPBE6yJu4JIUS74TPJkzWdZNVuIcTC0Xkiuay7hTLJQgjRriiTLIRoZzpGJCfyFXGLUp9kdbcQQoh2pJRJVncLIUQb0jEiWd0thBDipYWcZCFEO9NBIrla3CKu7hZCCNGm+BX3cupuIYRoQzpDJFtb30m2RS1vKoQQbUbCaMU9IUT70hkieWqUmM277ULwWFpxT7OkhRCiHUnUXHFPdVsIsfB0hkgeP+IeY8kqTnLwEYv5hRmbEEKIqniRPKlMshCiDekskTywqlwkxyJOsoqtEEK0FbWdZHW3EEIsPB0iko+5x/6V1fskg4qtEEK0GTFjSMbN9Il7cpKFEG1Ah4jkGk6ykZMshBDtTDIeq5NJVt0WQiwcnSGSz38nP3jt/w/LNkxfTCSWcM81AUQIIdqOVCKm7hZCiLYksdADmBVicfLJQTC9gHWF1fdJVrEVQoi2JVXXSZa5IYRYODrDSfbEk+6xMBWJW2gCiBBCtCvVnWTflUh1WwixcHSYSE65x8KUWzwkOnFPxVYIIdqOVEKZZCFEe9KhIjnniqsxKrZCCNHGVI1byNwQQrQBDUWyMeYmY8xBY8yWGsc3GmOGjTGbg59PRI5dZYzZZozZYYy5YTYHXhU/Sc/HLWLxcJ8WExFCdAmNaq8x5reMMU8ENfsHxphzIsd+P3jdNmPMm+Z6rFXjFjI3hBBtQDNO8teBqxqcc7+19qLg50YAY0wc+CLwZuAc4LpoIZ4TyuIWxfLuFkVNABFCdD5N1t6brbXnW2svAv4M+Fzw2nOAdwHn4ur+l4LrzRlNO8m5CRg/OpdDEUKIMhqKZGvtfcBMKtNlwA5r7XPW2ingVuCaGVyneUoiOT99MRE5yUKI7qBh7bXWnog87QNssH0NcKu1dtJa+zywI7jenJFKxKYvJlKtu8W9n4ab5tzYFkKIErPVAu41xpifAPuBj1trtwJrgD2Rc/YCr651AWPM9cD1ACtXrmTTpk0tDWB0dJStB5/hXOChB3/IeWOjnDh4iEN2G+cBD/34Qcb6D7R0zZkyOjra8vjnCo2lfccBGkst2mUs7TKOFmmq9hpjPgD8NpACfiby2gcrXrum2pucbM0G9/sdHc4ykrNlrx84sZ1LgCd+spkj+1zXogueup/BE3v5wRz892in/84aS3XaZSztMg7QWGoxm2OZDZH8KHCatXbUGPMW4J+ADa1exFr7VeCrAJdeeqnduHFj068dyea483v3c+Z5F8KT8KpXXgg70vSsOoWV51wIW+FVr7wITrmo1WHNiE2bNtHK+OcSjaV9xwEaSy3aZSztMo65wFr7ReCLxph3A38I/GqLr59xzfZs2rSJlSv6mTo6zsaNrwsP7F8Ej8L5550DZwfX3TIGNjcn/z3a6b+zxlKddhlLu4wDNJZazOZYTrq7hbX2hLV2NNi+C0gaY5YB+4B1kVPXBvtmnX97+iB/8IMJDo0HdwwLuUgLOJ9J1gQQIURX0GrtvRV4+wxfe9I0teKetXB8DxRzquVCiHnjpEWyMWaVMcYE25cF1zwCPARsMMacboxJ4SaD3Hmy71eNdMIV1Clb0d1CmWQhRPfRsPYaY6J3+94KbA+27wTeZYxJG2NOx90V/PFcDjYdr5dJDgTx+BHIT7jtfHYuhyOEECUaxi2MMbcAG4Flxpi9wCeBJIC19svAO4H/bIzJAxPAu6y1FsgbYz4I3APEgZuCrPKsk044rT9lA81fmAr7JKsFnBCii7DWVq29xpgbgYettXcCHzTGvAHIAccIohbBebcBTwJ54APWzm0ftqqLiVQ6ycd3h8fyk5Dqm8shCSEE0IRIttZe1+D4F4Av1Dh2F3DXzIbWPKFIjgjiUp9kOclCiO6iWu211n4isv2ROq/9FPCpuRtdOfVX3Av2D0fmIcpJFkLMEx2x4l466T7GpA0Ka7U+yWpKL4QQbUeyWp9kl+CLOMkRkZybmJ+BCSG6no4Qyam4E8eTVTPJmrgnhBDtSt2Je97cKHOSJ+dnYEKIrqcjRHLoJPtMcjADWhP3hBCirUnFY+QKFjeVJcBUZpKjIllOshBifugIkZyKu4+RLUadZOsKrSbuCSFE25Lyc0qibvI0J3k3JDJuW06yEGKe6AiR7J3kbLFOJlkiWQgh2o7SxOtoLrmak7z05W5bmWQhxDzRGSI56JM8WfRxi6C7RVkLOGWShRCi3UjGq4jkWKS7RbEI2eMwtNbtk5MshJgnOkIk+9t1E8XKPsnKJAshRDtTNW5hglpeLEBu3G33LnWPyiQLIeaJjhDJ/nbdRKEibhFTJlkIIdoZP6ckl49M3Itmkn28omexe5STLISYJzpCJCdiBgNki5HuFj6TbOQkCyFEuxI6yZFIXDSTnBtz271L3ONMMsknXoBb3g3ZEycxUiFEt9ERItkYQzIG2YJxxVV9koUQ4iVBf9rV6JFsxMiIZpKngrhFTyCSm3GSiwXIDofPd/0Qtn0HDm+fhRELIbqFjhDJAMl4MPEjnpJIFkKIlwhL+1MAHBmdCneaKnEL7yQ3k0n+yS3wFxe6u4oAE8fco+4oCiFaoGNEciJmmMwXQpEMQZ9kxS2EEKJdWdqfBuDwaMQhLtXtYhi3yCxyj804ycP7nDDOZ91ziWQhxAzoGJGcjMFkrgjxRFgY1SdZCCHamqV9zkkuE8m+u0XUSU71uwVFmskkF4JreSd5/Kh71PeAEKIFOkYkJ2IwWQjiFt5pKOuTrOIohBDtRiYZZyCT4HBZ3MI4oVwswFTgJCd7nEhuxknOV4jkCS+Sc7M3cCFEx9MxIjkZM4GTnAydBmWShRCi7VnWny53ksHF5cqc5N5AJGcbX9CL42Klk6zvASFE83SQSA6a0Ued5JgyyUII0e4s609NF8mxePliIsleSDYrkr2THLjTE4pbCCFap6NE8mQumLgXzSSboC2ciqMQQrQlS/vS5d0tIHCSi+UiuVknOR9cqxDUfWWShRAzoINEsmEyH8QtSt0tgo8XS7jbdkIIIdqOZQN1nOSpqEhOQ05OshBifugYkZyIBX2SYxWZZAiKrYqjEEK0I8v60xwbz5ErFMOdJhZkksedgxyLQaKnybhFII6LOecm+4VFCvoeEEI0T8eI5GScsE9yqbtFkEeOJTRhQwgh2hTfK/nYWCRyEc0kJ3vdvkS6xbhFrnzlPZklQogW6ByRHDPBxL1kJJNs3KOcZCGEaFuWB6vuHSrrlRx0t5iKiORks05ypAWcj1qAvgeEEC3RMSI5UVpMJOokRzLJKo5CCNGWhKvu1XCSUxEnualMctD6rTAVTtoDfQ8IIVqiY0RyMkYwca+iuwVIJAshRBuzLBDJR6Y5yUF3i2SP29dsJtkbJcV8hZOs2J0QonkSCz2A2SLpJ+7Fk+V9kkGZZCGEaGOW9VdZmjoWrLiXm4Bkn9vXbCY52t1i4ni4X2aJEKIFOshJNpGJe5VOsjLJQgjRrvSnE6QSsYqlqX0meSyMWzSbSY5O3CtzkrUstRCieTpHJMehaKEYS4SFUHELIYRoe4wxLO5NMjweEbGlTPJEJG7RbCY5IpKVSRZCzJCOEcmJ4JMUTDLcWSaSFbcQQoh2ZSCT5EQ2IpK9k5wbi8QtelyUwtr6F4v2SZ44Cj1LgudNfA/kJuAbvw7D+1r/EEKIjqJjRHIy5tq9FUwkZu37JGtZaiGEaGsGMwlGspE6XctJhsaRi3w0k3wM+pa55818DxzeDlv/EfY82NoHEEJ0HB0kkt1jdsVF4c6yPslykoUQol0Z7KnmJBddn+RU4CR7sVxNJBcL8OjfucdSC7icE9mpvuZjd6WohowVIbqdjhPJwxt+AQZOcU98sVMmWQgh2pqBTJITE9FMcqz6insQOsVRdj8Ad34Idv2ofDGRfDZY1jrZmkjWJD8hup4OEsnONZ4qWHjfPfCyn4G1l7mDEslCCNHWTItbmLgTyNjyPsng3OFKpvlXT7UAACAASURBVMbc4+RIpE9yznW6iKfc90Az7nB00p8QoqvpmD7JfuLeZL4IK0+F934zPCiRLIQQbY2PW1hrMca4mNzkCXcwFemTDNWdZC+cJ0eAYGJfYco5yZmh5luB+vZx+s4Qoutp6CQbY24yxhw0xmypcfyXjTGPG2OeMMb8yBhzYeTYzmD/ZmPMw7M58EqSJZFcJXusTLIQooswxlxljNlmjNlhjLmhyvHfNsY8GdTu7xtjToscKwQ1e7Mx5s75GvNAJkGuYJ3RAc79HTvitktOcsY95qs4yV44ZyOLhxTyTignUjPIJMtJFqLbaSZu8XXgqjrHnwdeb609H/gT4KsVx6+01l5krb10ZkNsjkQQtygV2ChykoUQXYIxJg58EXgzcA5wnTHmnIrTHgMutdZeANwO/Fnk2ERQsy+y1l49L4MGBjOufWcpl7zyXDix1237THLSi+QqTrIXztEV9ryTnMi0IJIjUQ0hRFfTUCRba+8DjtY5/iNr7bHg6YPA2lkaW0skg25vNUWylZMshOgKLgN2WGufs9ZOAbcC10RPsNbea60dD54uWN2OMtgTiGTf4WLdq8ODpYl7gUge3gvFilrvFxmZOBbuK2WS0833y492xhBCdDWznUl+H3B35LkF/sUYY4GvWGsrXeYSxpjrgesBVq5cyaZNm1p643x2AjA8uvlxzAvlH+u8Y8dJTx7nkRavOVNGR0dbHv9cobG07zhAY6lFu4ylXcbRImuAPZHne4FX1zgXptftTBCPywOfsdb+U7UXnWzNhvLf785DzuXd9KMfs3dRnHS2yGuC8zY/tZ3jBzbRO7abywDueB/7HvgG28/8z6Vrrdv9JC8DDuzcxqpg395dz7NiYoRDB4+wZCrH8At7ebrKOKPjWL3/cc4Cnn9uB7uKrX+mk6Wd/s1pLO07DtBYajGrY7HWNvwB1gNbGpxzJfAUsDSyb03wuAL4CfC6Zt7vkksusa3yD//8fXva733bfmvzvukHb3m3tV/6qZavOVPuvffeeXuvRmgs02mXcVirsdSiXcYyk3EAD9sm6txc/QDvBP4q8vy9wBdqnPsenJOcjuzzdfsMYCfwskbvOZOabW357/fhnUftab/3bXvv0y+6HcWitX9+trWfHLR294/DfbsesPYvr7D2KxsrLvbf3Lk3v8s9fnLQ2n/+mLWfXmvt3TdY+/lXWvuNX284DvsfX3Wv/d6NM/pMJ0u7/Nu3VmOpRruMw1qNpRatjqVezZ6VFnDGmAuAvwKusdYeiQjwfcHjQeCbuNuAc0Jp4l6u1sQ9ZZKFEF3BPmBd5PnaYF8Zxpg3AH8AXG2tLYV8I3X7OWATcPFcDtYz1OPuAJ7wbeCMgXXBV4afuGcMnHo5nHIxDO8pv4DvbhGNW/hMcryViXtBzEKZZCG6npMWycaYU4F/BN5rrX0msr/PGDPgt4E3AlU7ZMwGvgXcVGEeJu7lJ2H04OxdTwghZo+HgA3GmNONMSngXUBZlwpjzMXAV3AC+WBk/2JjTDrYXga8FnhyPgY9EEzcG4muunfq5e4xM1h+8qJ1MHaovF+yn8xXNnEvF3S3yLSQSfYLkchYEaLbaZhJNsbcAmwElhlj9gKfBJIA1tovA58AlgJfMm4Z6Lx1nSxWAt8M9iWAm621352DzwCEi4lM5uZBJD/wRfiPr8DHt83eNYUQYhaw1uaNMR8E7gHiwE3W2q3GmBtxtxXvBD4L9APfCGr0bus6WbwC+IoxpogzUT5jrZ0XkRx2t4jU6kt+DYbWwqJTy08eCozy4X2w7OVu23e3iLaAmxp1j4lU83cU5SQLIQIaimRr7XUNjv8m8JtV9j8HXDj9FXOD725R20mexe4WJ/bDmJxkIUR7Yq29C7irYt8nIttvqPG6HwHnz+3oqpNJxkjGTdjdAlzM4hVvm35ySSTvDkVyqbtFNZHcQgu4fGRJayFEV9MxK+6FmeRqInmWM8lTY2CLrgVRrGNW9hZCiAXDGMNAJlket6jFUNCxbnhvuC8fiOToQiOTgUiulUne8b0gVpEJ9/nFROQkC9H1dIzCixlDImZqrLg3y3GL3Jh71GRAIYSYNQYzifK4Rc0TTwETg+ORyXteJHtiiQonOTk9Z3zf/4BNny7fV+qTrPouRLfTMSIZIJ2Ika2ZSZ7FuMWUF8lyGoQQYrYYyCTL4xa1iCdhYHW5k5yrWKo61Rc6yYl09TuK2eMwdrh8n1bcE0IEdJRI7ksnGJ+q8tf/rIvkYKEqZdaEEGLWGOxJMJJt0sEdWlfeBq5yqepUP0yNuO1Euvodxeyw65Lh+kI7fNxC9V2IrqejRHJ/OsHoZJUCa2KznEkO3AnFLYQQYtYYzCQ5MdGkOB1aWyGSK53k/kgmuYZInjgOhSkS+bHIdXwmWfVdiG6no0RyXy2RPOuZZDnJQggx2wxkEs3FLcD1Sh7e5yZQQ9jdwpPqAxvcQSw5yZE7ioVcaX5JMhftrSwnWQjh6DCRHGdsPkSyj1sosyaEELOGc5KbrNUDq10NnjjqnldO3Ev1hdvVMsnZ4fDUqXBbfZKFEJ6OEskublGju4UtlOfOToapFrpbWCtHQgghmmBpf5qJXKG62VFJstc9+jt700Ryf7hdiltEanGZSI46yVpxTwjh6DiRXNNJhtmZvGdt2AKumSK67W74s5eFwloIIURVlg+kATg8OtngTNxCIxDGLHJZwITHK53keNIZGzt/AN/5eNnKfFXjFnKSheh6Okok99UUycFyfLMRuShMhddppoge3wWTw2WuhRBCiOks608BTYrkRLAAiJ+wl89Cz2K3beKQjCwQEs0kb/8XeOhrbuXUgDInOa9MshDC0VEiuT+dYKSukzwLIjnqCDdTREuN6adO/r2FEKKD8U7yoZFmnORABOeybvJeYRJ6l7h98ZRbPMQTzST7VnGHtpUOl2eS5SQLIRwdJZL70gmm8kVyhYoFRbxItrMQt4iK5GZEd2mmtPJtQghRj+X9gUgebcJUSARxi/xEmEfuCURyIuWEsifaAs6f60Vyz+KKuIVW3BNCODpKJPennRieFrmYzUyynyQCrTnJciWEEKIuS/pSGDMDJ9kL35KTHGSQPdHFREpO8tPucemG6hP3VLOF6Ho6UiRP65VcLZM8fhQmR1p/E7+QSOX1aqGem0II0RSJeIwlvakmM8l1nOR4qrpILkSc5MPbXSRj0anV4xaq2UJ0PR0lkvtaEck3/xJ894bmLjxxDMYOu+2piJPcjNNQlJMshBDNsnwg3bqTnAsm7/VG4hbRTHK8ipOcn4DMEPSvKI9baMU9IURAh4lkJ4Zrxy0i+w8+Dcf30BTf+Tjc/utuuyxu0YyTrHybEEI0y7L+dOvdLbzwrRa3iCUhFpueSQboWQR9y0gUsqEBIidZCBHQUSJ5IOOd5IrscaVIzg7D1EjzbdlGX4TRQ267LG7RTCZZM6WFEKJZlvWnmnOSE9FMcuAk+xZw8WQokhNuMuA0Jxmck9y3wm2PHXSPmkcihAjoKJHc1+zEveF97nHyRHMXzmfDyRxTrU7ckyshhBDNsnzAOcm20QqpyUgm2S8o0rvUPSbSYdwiKpKx5XcDM0OQGXTbk4EBohX3hBABnSWSU01mkk8EIrlZJzmXDXNqLbeA8wuPqOAKIUQjlvWnyeaK0+t4JYkq3S16onGLVLgN4ffAZORuYGZRZAJgcA3d/RNCBHSUSC51t8g2cpL3usfssFtmuhHR2dO5mfZJVsEVQohGhEtTN+iVbIwTytH6nB5wq+3FkxAP6n6Zk0y50ZEZikwAHHemhg367KtmC9H1dJRIbhy3qHCSi/lwVnQ9ctlQ7La84p5cCSGEaJZl/V4kN5lLjna3SPZAqs8JY+8kVxPJfjszFDrJ0TqfyLjFp5oxUYQQHUtHieRUIkYqEWN0qslMMjQXuYjOnm61BVypu4VEshBCNKK1pal7yutzIuP2RZel9iLZT+SbGoWhtW67Z1HoJOcnQpGc6nOPqttCdDUdJZLBRS6mO8mVmeS94bFmRHIumLhnrYtbeNHdzMSOokSyEEI0S8tOcn4y7G6RyEDfctcKzoviykyyLcCi09x2ZgiSvW476iQnA5GsO4BCdDWJhR7AbNOXjk/PJJsKkTy8D9JDMDncuMOFtWEBLky5W3WZRTB+uDUnWcVWCCEasqQvRazppal7XNTCd7dIZuBdN7ts8q4fun2VcQuA1RfAqZfDWW8NvxfKnORAOMvcEKKr6TgnuS+VqN8n2VqXSV7xCrevkZNcyIUTOfJBw/nMUHisEZq4V527b4DHv7HQoxBCtBnxmGFJXwsLiuQj3S0SPbD4tMBJrpFJBucUX/lfYWBl2EouF4lt+LiFuhIJ0dV0nEgeyFSLW0RE8vhRV1CbFcn5yMS+/JTLs3mR3FR3C+8kq9iWseV2ePbfFnoUQog2pPmlqXsiLeBMGLGAsO77VnFRkeyFc/R4biKs18kmnOR9j8A3fj2c69Lp3P8/4Pb3LfQohJhXOk4k96UTjNWbuOc7W6w4xz02Esm5yBKmhUnXJmgmIllOcjn5SUVQhBBVWdaf4lCjFnAQtoDLTTjBbEx4rNQnOXgsE8mZ6dv57PSJe/Vq1PP3wdZ/hInjjcfZCex7FPY9vNCjEGJe6UiRPL1PciSTPH7EbS89wz225CRPukxyuh9MTC3gTob8ZPi7EUKICMsH0hxuyUmeLBe+UH1Zak/USY7FKMRSgZPcQncLb6AUmhhnJzA1JrNHdB0dJ5L7U4kqK+4FxdEWQlHcv8o5DK04yflJl0lO9bv2Qk1N3POZZMUtSljrvlj0OxFCVGF5f5pDzSxNXVpMZKJFkVx+bjGWquEk16lRfnnrfLb2OZ1EblzGhug6Ok4kD/UmGZ7IlRfXaCbZi+KeRS420ai7RdRJLky6THKy1xXgplrA+WWp9Rd4CT85Rr8TIUQVlg+kmcoXOVF5V7CSZLCYyNRY2JHCE6tsAVfDSSYQybnxyMS9fvdYzzn14jjfJcJxSiJZdB8dJ5JXDmaYzBcZnogUt2gm2YvkzBCkB1t3knMTrhjH4lqWeqb4Lxf9ToQQVWi6V3IiWExk/Aj0Lis/Vq+7RTUnOZedPnGv3h/y3knulrhFTnEL0X00JZKNMTcZYw4aY7bUOG6MMZ83xuwwxjxujHll5NivGmO2Bz+/OlsDr8WqQVf8XhiOiNtoJjk77PLEqX4nlFvJJOeC23rJ3tbjFnJNQ0pOsuIWQswFxpirjDHbgpp8Q5Xjv22MeTKo1983xpwWOTavNbsaXiQ37HDhneSxw9BXKZIr4xbx8FiFSC7E00HcwjvJvrtFvbhFlznJ0cy2EF1Cs07y14Gr6hx/M7Ah+Lke+EsAY8wS4JPAq4HLgE8aYxbPdLDNsGrIFb8D9URyZsjNgs4MQbZG3OKJ2+F/X1q+DLUX1KW4hZalnhElJ1kFV4jZxhgTB76Iq8vnANcZY86pOO0x4FJr7QXA7cCfBa+d95pdDb80ddNO8tgh6F1afqzZiXt4Jzk6cS+IW3hz4/ie8I97T84vMlVljD/5P/AXF0KxWH/8C8XEcfjaz8D+zc2/ZmrcfYe262cSYg5oSiRba+8DjtY55Rrg76zjQWCRMWY18CbgX621R621x4B/pb7YPmlWD1Vzkisyyb6FW6ZO3OLFrXBkO4y+GO6bOOYeS06yWsDNCP9lo9+JEHPBZcAOa+1z1top4FZcjS5hrb3XWusdgAeBtcH2vNfsaizrd1GJhh0ukoEjXM1JrptJroxbeCe5Sp/kqTH40uXwwBfKr+/vMlabuHfoKTi2s/xOZDtxaJvr81z5meqRG3OPuisquojZyiSvAfZEnu8N9tXaP2csH0gTM3BgOFKcykTy8YhIrhO3mAoKQjWRnOqFeKKxyLNWcYtq+C8V/U6EmAtarbvvA+6e4WvnhMW9KeIxw6FmnGQA7PRMcqrPCWXvMEcXGqlwkgvxyol7kUzy/sfchO19j5Zf3zvJ1eIW/vsj16Yi2bdCffLO8HutHvmp0BTSHUDRRSQanzI/GGOux0U1WLlyJZs2bWrp9aOjo6XXDKYMj23byabUCwAkcie4Ati+7WlWHNxNMZbiJ5s2ccahE6wZP8b9Vd7rrN07WA3sf2YzpwT7dj/zOKcCW7c/z/rsFGMv7ufJyGuTU8fJJ/oYHZ9k06ZNmGKB1+O6bBzYt5enW/xMs0H097LQ+LEMDm/jlcDYiWEe0u9EY6lCu4ylXcYxVxhj3gNcCrx+Bq89qZoN9X+/A0l4YvsuNqUP1Hz96v27OSvYfnL3IQ5Oll+r95L/ycSxFdhNm+gf2cGlwf4fP/o4433hzdGzijHGjh9k39NbORN4fNvzXAA8sfkx+sZ2cQYwvusRfhwZ6yVHDzIAbH38MQ4dKO+scfauHawCHrzv+2R7Vjb+RUSYj39zq174IWcDFCZ55h8/zf41b607lkRulCuCfT+4717yycE5HV+9sSw07TIO0FhqMZtjmS2RvA9YF3m+Nti3D9hYsX9TtQtYa78KfBXg0ksvtRs3bqx2Wk02bdqEf81pW38ImQQbN77aHcwOww9hw8vOgOH7Ydl6d655CPb8Exuv+ClIpMovePBv4ACcMhADp7U5dVk/7IFzL3wVHL6bviVLWHHxBndw8BT48w3w6t9iU/+l7vpT43CfO7xqxVJWtfiZZoPo72WhKY3l+Tg8Bn2Z5IKMrS1/J22AxtK+42iRWvW4DGPMG4A/AF5vrZ2MvHZjxWs3VXuTk63ZUP/3u+bx+zG9aTZuvKz2BTa/AM+4zXMu/WnOeVmdMRxYCo+4zct+6qdhcWmuIi8++Tn6TIwzzzgNtsMFr3w1PAHnn3s2bH4MgN6JA2z8qctCl3lLAkbh3LNeDhdWvO+Lfw0vwuWXXAgrzq49pirMy7+5+x+FbcCyszjz+P2c+e4/K1+tsHIsw/vgh27fFZdfBgOr5nZ8VWiX/xfbZRygsdRiNscyW3GLO4FfCbpcXA4MW2tfAO4B3miMWRxM/nhjsG9OWT2YqZi4VyOT7DNso1WcilLcInKslEnuCeMW//xhuPND7rba2CGX9fJE4wTK34aoT7IQc8lDwAZjzOnGmBTwLlyNLmGMuRj4CnC1tfZg5NCC1OxqXLB2ET9+/uj0xaGiRGMTlXGLSupkkl3cIrqYSCSTvPfH0LMYsPDiFnjor4JV/iIT93Y/CFv+MbxgKW4Rmfg9W1gL3/4YPPK3M7/G+BEXVbnioy4//ez3658fjY0obiG6iGZbwN0CPACcZYzZa4x5nzHmt4wxvxWcchfwHLAD+Brw/wJYa48Cf4Ir2g8BNwb75pRVQ02K5KUvd49Hnp1+EV/kRiKZZJ9f9lm3Ys5NGBl5wWWdwW17osJY7c5CSt0t9DsRYrax1uaBD+LE7VPAbdbarcaYG40xVwenfRboB75hjNlsjLkzeO2C1OxqvOOVa5jIFbj7iRdqn5TsCbcrJ+5V0qi7RX4irNm+u8WRZ535ceF17vm//CF853fg+fsimeRJeOCL8K0PhgbAXGaSn/03ePgm2PrNmV9j/IjLap/3Trf67I8aTODzk/ZAho/oKpqKW1hrr2tw3AIfqHHsJuCm1oc2c1YPZRiZzDOSzTGQSYbFMTfh/rLPLHLPSyJ5B7zsyvKL+KIwdjBY+jRb4SQHLeByEzA5EgroE/vDa0T/4lZhCSnISRZiLrHW3oUzL6L7PhHZfkOd1857za7GJactZv3SXu54dC+/eOm66idFHeHKFnCV1OmTXIylgz74k66PvhfRux9wj+f/Ijz017DnP9zzyRORPsnBIlO5Mdh5P7z8DW6iH8y+k1wswvf/2G0f3z3z64wdhr6lLmZ46W/Apk/D6EHoX1H9/GgrVH2XiS6i41bcg7BX8osngiJmYk4ojwQCticQyQOrnGNwZMf0i3gnoJh3zrGJV7SAS7hjuQm3fyLiJPslscucZBWWEmoBJ4RogDGGn794LQ8+d7T2oiLeSU4PTnOHp1HHSS7E087UyGfdSn2+fdzxXe5x2QZYfmb4guxw+Yp7/u7Ytu+6x7kSyfsfgxd+AoNrYHjvzHsWR1coXHK6e6y3sFaZk6y4hegeOlIkrx5yhbPUK9kYWHIG7H3YPfdxC2Ng6cvg8PbpF5mKFIVEjyuqlSK5kAvaBk2EreJy4yTywWsLLWSSx4/CiTq3FTsJLUsthGiC89a4Lgp7j9UQm94RbhS1gPK+yRWT1IqxYOJ29rg77tvFjRxwojnVD6svgtSA2z9xFGzBbeenQjH8zD3OJJmruMVEkHw57bVOnI8dmtl1xiN9pf3vsN5Y5SSLLqVDRXKVBUWWnw2HnnbbXiSDi1wc2eH+ih6JTNKLiuRkxhVKXwh93KKYD/cd21k6PT0Z9KCM/sXdKJN8zx/Abb/SxKfrADRxTwjRBCsH/V3BBk5yo0l7EDrJFVELiIjk47uhf3l47tSou7Yx8HM3wv/z7+7O5GhkrmNh0kUvTAyGd7vJ2ycxcc8U826hD39HMoq/3vKg8d3wnunnNMPYkTCe4n+H1RZFqXxfkJMsuoqOFMkrBt2ttAOVItlTKZKP74ab3wU3X+v2WRveLoPASY4UVr/inneSoUwkp6aqiORGf32PHXR/3b/UmThWfSJkFDnJQogm8LX80EgNAdeSkxxkkqvEMkoi+ehON5EtuvBIXyAme5e4O4/pgXKR7J3kRae658d3hd8LrTrJz9/Pq//jP7slo5+7d/px7+j677OZ5JJ9ftqL5GacZIlk0aV0pEhOJ+Is7UuVO8kraonkDYCF3T8KC18+CzaS9Upmwj7K8ZRr/xZPwNRIeE6ZkxzcEvPusYk3Liy5bOiwvlQp5ODvrgn/2KhF6XNaKBbmfFhCiJcmS/vcCqqNneQGk/agrpNciAf1fXiPm6sSi4jkymunB6s4yRMuJwzlwnWqRSf5iW+QmQyuPVolSuGzwV4keyc5ly2/+1kPv9qe/8PCL8Fdz0lW3EJ0KR0pksFN3itN3IM6TvLLwm1fgCoLWyITFlZfUGJJyJ4Izzm2s3TOtLhFqq9x3CI/8dIXyff9uZtUMtGgY1S0GMuVEELUIB4zLB9Il9fyKC05yV4kV3OS/T7rRHLUSa6McqQHwzko4OpZfsItKAXlEYhW4xZTYxRiwWeK3s0sXS9we/tXuO8xL8jv/t3G5oRnLLhj6T9XUk6yELXoWJG8eihT7iQvfblzdCFsAQdu1nKixxU+L45LxSmY3JHIuMkcEIrkeNK1fvMM73FFp3fpdJGc7Gn813d+8qUtkk/sh/v/3P2OG32O6HG5EkKIOqwczHCwVneLVD+c9RY448rqx6PUzSRHhPPAqiCaEdT/aU5ytbjFRLAKnXFdJzytxi1y40ylgu+naiLZf0el+mDoVDgeCPLD25uPXvhYX2Xcoq6TrO4WojvpWJHsFhSJFKhE2nW4iCXLG9CnB+BDj8BPfchNJMtPhQXB94yMxi38SkyxeDi7GZxT3LMIBk8hNRU4qV4AJnsbT1LLTdQvUu3Ow3/johPn/nzjL4bo59QiK0KIOqwYyNR2kmMxuO4WOOP1jS9Ux0kuxS0ABla7R+8mV7rU6YHyqF1+wgnH1EDg7p6MkzzKVCq401ktPpEbc4ZNLO4y0N61HjvUQtwi+H4qxS2C78OmnWQZG6J76FiRvHqoh2PjObK5iJBdfpYrYpVr1A+tCVdYyo2FxcbfPotO3PMFJZpZ82QWwcAppCeDv9RLqzf1NV5dLp91QnqmfS8XkvwkPPI3cOabXKzFFuoXUjnJQogmWTGYru0kt0IsFiwUUqe7BUD/yuD8oMZXc5Kj+P7CyR43uS/q6LbqJE+NU4j3uO+jyRpxC/8dtGidE+TWughFNee5GmMzcJIVtxBdSseK5FVB66CyDhc//Tvw5v9e/QXeIZ4aC4uNn4jhW8ABJPvcY7yaSB6CgVXhxL1S3KJJJxnC1eheSmy72zkZl72/uXxbmZMskSyEqM3KgQxHx6aYys+CgRBL1O9uAREnOXCe64nkRCZcSCrZAz2Ly/PKrTrJuXEK8YwzVmrFLVLBd9DQOudojx12/Z3z2cZmDLi4hYmHscNmnOSp8dBIkkgWXUTHiuSqvZLXvBLOf2f1F/gCMDUeOsm+WDbrJPcsgswQibxfiSkXvqaZTDK0R+Rix/fh6HPNn39om3tc/9PNuRJlTrIKrhCiNit9G7jR2XCTEzW6W0QzyRVOcmXcIjMY2V7kBCoEInkJEPQ3Tg/OKG4RiuQacQs/L8bf6TzweNnrGzJxzH1XxYKv/2adZC+qdfdPdBEdK5L90tQHTjR5u8sXntxYWNh8ESrLJHsnObLEqc+6ZRZBepCYzblC0mx3C2tdrg3md/Le5Ajs3zx9/x2/CT/6QvPXGd7jblEm0s25EmXdLZRJFkLUxvdKrplLboVGTnKqP3SK47XiFhGR3LMIJoK4RSLj4haevuUzilsUY2k3jqlRNyHvO78TtsqMxi38nc4ykdxELnniePnkdWPc2Os6yWPus4KMDdFVdLxILnOS61EvbpHoiXS3qOIke8e5ZxGkA0d6ciSMEiR76//1XciFfZln2UmO58dh23erH3zk6/DVjXDwqXCftS5j1+wkEIAT+2Bordtu1UlW3EIIUYcVA66mHKzVK7kVYvHyidsBpe4WPo8MkUxylYl7nswimAxagSZ7Ayc5oG/5ScQt+l0Nfua78NBfhavBTo2FRo03cV74Sfj6Zpzk7HAoeD2JTBNOcjChUCJZdBEdK5J7UwmGepLlmeR6VItbDAbiN5kJ3YdSn+SIk+yLVWYoLKCTI5GJezUyyS9udctRRwtpfnYL0Cn774Fbrg1nNEcZPwpYuP9z4b7chJt410pxH94byW834yRr4p4Qojn80tQHa6261wp9K4JWbeWUnGRveEBwt9C4nHGU2zilrwAAIABJREFUMpE8RClekcyUn9u3rDUnuVgMRXI6cJInjrljpRX8xsPvIN9y7oUW4xbZ4fK1AsDV7UaZZMUtRBfSsSIZ3OS9/cebLKzRuEUpkxztblHZJ7maSF4UEdujFRP38s6ljfL4bfDAF6Y3pp9FeiZecBvRns6V77Xl9nApaX9es+Ow1onkoXXueclJruP65LNhz2oVXCFEHZb2pehNxbnj0X0MT5xkvfiN78Lrfnfa7mIsCZhyAR1LOsc1WuuhQiRHohfJ3jBuEU87IdrKinuBEC5lkicjItl/J0XjFvGkc76PPhteo1pHjEqyFXELaM5JTvc3t3qsEB1ER4vk9ct6ee5Qk21x/C0sH7dI9LgWO2dcCeteFYq/VGTFPY8X0z2LajjJwbUrBaGfHOeXCYVZzyRnsv42XbV2QoErYYvw1J3l5zXrgEwcc9cZ8tEUL5IbOMk+lqK4hRCiDrGY4X/84oU8uX+Y9//dwyd3sd4lVeMWGOME59KXh/viyelRCwgzyVHzBFzt805yqi9wZ2ciktPhxD3fOcNfJxq3gNCg8dSKye17BP7XBe7u4UycZP9dEU9JJIuuoqNF8tmrBtl5ZKy8V3ItSiJ5PCxEiTT8yj/BmksiLeAif8WD67vpFx3JREXyaPliIjBdEB573j36vpUwB05y4FJXnSk94XJzg2vCXLLP1zUrkv3qUj6TXGoBVy+TnHWN90FOshCiIW8+fzUf+pkN/Pj5oxwbmyOR9v5/g9d+JHweS0yftAehSE5GVmKFcic51d9YeFYS1GjXJ3kgEMneSa4St4AqIrmGKbTj+3B8Fxx+xgnvVjPJvvVcPKWaLbqKDhfJAxQtbH+xCTe5LG4xXv7XOlTJJCfD574w9kTiFpMngr+4TSiso8XFWji6022PR0TybPZJLuTJZIPlU+s5ySteAQefDMYdxC2aLe4n9rnHQT9xL/isDZ3kQCTLSRZCNMFlp7s6u3nP8bl5g6E14Z1CgAt+CS581/TzfO1K9pa3k0tmwol7qT7XUz8/0fwCUYFIdt0t+lwP5IlgLkn0Dl+ZSA7u4HnHu5ZIPvCEezy2y9XcVpxkayNOclI1W3QVicanvHQ5a5UrZk8dOMH5a4fqn5zsAUwYt/Bi1zNNJMfD1539n1xkYumGUDT6THI8GQrqg085EXzGxmCFpECQjs1R3GJ4D4agQFd1krOusK84B56/37Vj85m2Zm8TztRJ9nELtYATQjTBBWuHiBl4bPcxrjx7xdy/4Ws+UH2/F8mJSGtQCLpb+B7J/aE5ks+Wi+9aRDPJ6ZiLwfmuFrlxJ1anxsqv5SeXL17vzJZacYsXt7jHI9vdY7VMsnetK5kaA6x7X8UtRJfR0U7yaUv7yCRjbDtQZdJaJcYEf72PTy9EEGkB5yfuVTjJV3zMNWcvawGXd0XFT/zY9Gm45Tr3Hj5qAeVOsr/ldegZeG5TS593Gsd2htu14hbJXieSC5MuI93qxL3hPe6PgL7l7nmzTrJWbxJCtEBvKsHZqwZ5bK6c5GaJOsnxikxyb9RJ9ncnmzQcSnGLTFgfRyNxuXwWsNWd5EWnusdqE/cmR+Fo8H1z2IvkKk5yrZp/+Bn3uOQM972nuIXoIjpaJMdjhjNXDjQnksEVn6nR6ZMjIHSSKyfuJSvEdCqaSa5wkkcOuIK543th0YKKTPIk/PAv4EuXw9+/4+Sc1jKRXCtu0ePiFuAiF6VMcrNO8j53m9Kv3tTISba23EnWrTshRJNcfOoiNu8+TrFoG588V6T63FyUZKWT3OPEbSwZZpKh+Vpa2d2i8piPQ1TLJPevdPGOanX+4JOU2tQd2eEeKzPJ9eIW3oVeeZ6cZNF1dLRIBjhr5QBPHzjR3MmpPleMpsbqxC0qJu5VzpSOJyjEUi5KUZgKnOTg3NEgH/zkt8qXfR6vIpJt0TnR2WG480PwjV9v7jNEObYTi3HbNZ3kHlh+liv6B5+KZN+adZL3hnlkaNzdopDD3brzE/cUtxBCNMfFpy5mZDLPs812LZoLjHFucjKyyFQ87SJ4xrj+yP44wGN/7xZuakTJSU5P//6J9u9PVRHJfUuDO6FVfi8+j5waCEVypZNcb+Lei1udAF98euAkSySL7qHzRfKqAQ6PTnF4tImsbyluMTL9L/lS3CLY7xcTqXSSCWYn+xZwsWR4bja4TfjMd91f975QVWaSJ0fCfp3Z465IRVfFa5ZjO8lmVlLKWleSn3DxiGSPu5V2cGsYtyhMhkuh1mPiqPtS8DTqk+wLsSbuCSFa5KJ1rmY+vnd4YQeSHqzonx+ZwHf1/3ZdMvx3w31/Dt+/0d1F+4+vwN5Hql+zNHGvipM8NRo60tHvnKFT4aL3wJlXhW3jKnlxC6SHYPUFYf2tzCTXdZK3wspz3N1CxS1El9HxIvnlK9xf5M8fbmKZ5WSvE8gjL4Zt3Ty+aby/TVXLSQbyid6wBVw8GZ4LsOJcV/CeuhNWnu/2RfskewfaT4TLHncTKiabdMOjHN/FRM+q2sUz2ph+2VlweEf5oiPN5JIre24a44RyrYLrxXNamWQhRGusX9pHOhHjqRdmUA9nk+Vnw7IN0yd0A2z4ORdh846vLbgav/tBuPv34NGvV79m2cS9genHqonkeALe/kVYdb6rqdUyyUeedWONfqc1u5iItc6JXnlu8H6KW4juouNF8hnLApF8qAmRnOqD47udi+pXkPO87Gfhl28P87veHa4yazl0koO4RXThkXOudtc5882uvVCipzxu4ZeP9iJ5IhDJ2Rk4JxPHyCWHat+Gi7YTGlwNowfKi2wzbeCqNaavd+vOt7hLqbuFEKI1EvEYZ60a4KlmI3RzxXtuhzd9KrzDGG0F56m8y3jvpwAb1vhKyibuVTrJ42Gv5FqdMlL91ev81Jgzefzkaqg9cS+6Kuzj32DNvu84o2bleW6f+iSLLqPjRfKaxT0k44bnmnGSU32ujySEs4Y98YRzCDx14xbBBMBCrjyTDG5Fpg0/B+++FV75Xvee0b/M/SQ+//4Tx5xQnhptXVBOjjhX2zvJO74HD/9NeDzqJPevcu8VFeyNJpzksq6wttJzs+QkK24hhGidV6wa5KkXRrB2ASfvefzEvSrfA6Xamh50i5LsvN89n6jozjE1BlvucI+xJDaWKBfJsaTr319ykisEtKeeSE71Qd+K8LzKpbZLMbmIuXHfZ9mw42tuuySSlUkW3UXHi+R4zHDqkl6eP9zERI9UH6VZwENr655aP27REy4mEk+EghrCZUs96cgEjair7J3s47vCMbUauZgcCVZvCkTyQ38N93/OHSvknED14/cZaD+xA2pP3nv8NrjjN8Px1HKSn74L9lYsI+uLcK2luoUQog6vWD3A0bEp9h6b4CcL3Q4uXiWT7PHC+bSfgnWXh/sr+xFvuQNu/w23dLR3iVORuMXgaucil0RylWW1oU6sbswJaz93pDJqEb1m1NyYGqMQy7iFSlZFnWSJZNE9dLxIBjh9WX/zmWRPI5FcqwUcPm4x6kToNCd5SfnJPnYQT7tC5fPJ/v2jXTCyLXwh5CehMBU4yYHDEF3ApNROqEIkeycdajvJO74PW78ZOiK1JoF89wbXqaNsXJq4J4SYOa9Y7eaH/MbXH+Lnv/RDjs7VMtXNUC2T7Mkscl2DzrgSTg1EcnooXEXPc3yPe3zh8fD7IOokD64Jui41iFvUyiR7J9lnkitNDQid5D0/dqIdYGqUF1b/LPzOtrBeK24huoyuEMlnLO9j55Hxxr01fWFKZNztsXrUcZIL8Z7yuEWsIm5R7T2TGVdwfaeLvmVOOEdFayu55GACXlncYvyw229tbZFsC2ERrZUrHjvk2tMd3+2eT3OS0+6140emC20ft5CTLISYAWcHInn7wVGKFl4YbmLuxFyRqJNJ7lsK7/83eNX74Lx3wIXvhvPfEUzEHoW/vRoOPg0n9rvzJ4dDsZ1IuzuQqX5XX6dGnSMMDeIWVcygqXEnrH0mubJHMoTfA5v+m5tcCJAbd0tkR6MZiluILqMrRPLpy/qYyhfZ36iYeuE2uMZ1aahHnUyyi1v4iXvJ8iJTWaBKwjxoJ+TjFql+d2500ZGWRLKLQhTiEZE8dsSJ2/xk2MfYj79/Vfhan12r5SSPHXKPR591j9NEck+Yo67MJvvniYz7HUokCyFaYKgnyZpFPcSCEn1wpIn2nnNFvKJ/fiWnXOy+A4bWwM//pYvR5bOw/1F4/t/dPJET+8LzvUvsV4DtWRx0XRqfbmxUkup3dwqjWe1iwdX6VH8okus5yYefCToz5aEw5SYRln1exS1Ed9E1IhmaaAPnBWOjqAU0nriXzzpRG0835yQn0uVdIdL97nZdtIBmW8gklznJ/W5G9WQgsqPi1RfH3qXhZ/K35WpNvvOTC48EInna6k2Z0B2pFNo+PjK0zv1eFLcQQrTIZ95xPp/7pYsAOHRiAUVyaeJeDeFaiV+22ve9P/pchUjuL9/OLHLCuSxuUctJ7nOLUEXvAEbbxpXiFvUyyeNOVJdMlkqRrD7JorvoKpH8XKM2cL74NCOSG8UtwP1VvvqCSCbZTC9QfoJGMtKY3u/PDFGatAcziluUJu6NHSw/VtlzMxZzS5tC6DhUE8nWNuckjx6ofo39m91EkKG1QcFVCzghRGv89IblXHWeu/t1qJmFouaKRk5yJd4kOfikezz6LAxHRHLUdPF3E1P9gZM8Fq7sVw0vsKO55GiOOdXn5sQMrJr+2sq4SGCEFOLp8v1ykkWX0ZRINsZcZYzZZozZYYy5ocrx/2mM2Rz8PGOMOR45Vogcu3M2B98sKwbSrB7K8C9PHqh/YisiuX+liyUsP3vaoXwiUujWX+EKC7iCF6v4lUdz0NGClO6f7tCeTCY5StRJjhZ3L5L9YzWRnB0O3d8jNURyMuMcDZjuJL+wGU65yN1OjMtJFmIuaKJmv84Y86gxJm+MeWfFsQWv2c2QScYZyCQ4eKKJRY/mCu8kJ1oUyS8GIvmFx5349XG36KS8s9/iVtJL9gYt4Cbqi3HfKSnaBs5vewH9vn+FKz46/bWV1w1MlWJMcQvR3SQanWCMiQNfBH4O2As8ZIy501r7pD/HWvuxyPkfAi6OXGLCWnvR7A25dYwx/Mpr1vPfv/s0T71wojQ7ehqtxC16FsHvbq96qOQkx9Ow9jIYfTF4zeLpJ5cm7vWEcYdY0rnK3nVO9rlbYDNykquI5MnRsL1btDgOrHaP/YGTXG3i3likj/Lx3a5oVroQ0S+MqVAkxwqT7jbjmVcFOzQJRIjZppmaDewGfg34eJVLLHjNbpYVA+mFzST72te0k1wRt/CdLk5/HTxxW/mkvDf8kXu877NuLsnE8dpRCwiPRUVy5R3DZS+v/trKGj7qRPJ0J1lxC9FdNOMkXwbssNY+Z62dAm4Frqlz/nXALbMxuNnk3ZedSk8yzk0/eL72Sb7NTTMiuQ4lkbz2Vc5V9XGLqiI5+AvfZ5IhdAS8k9y71DWkn8HEvVImOcrUaPWemwM+blFn4p6PWkDYCaNykmM0NhJxo/tHd7rXnBJ8/ypuIcRc0LBmW2t3WmsfB4oLMcDZYsVAhkNtMXGvRlu2Svx3gG/F6fm/7N13fJvVucDx39G0POS9ndhO7OydkEVCwibsMlqgrLaQTmhLoZf29lKgvR2Utre0FFpWgbassgMkjCQkZO/EcfZwYscr3tuW9N4/juQVObYTx1Ls5/v5+CPplV7pkZ0cPz56znMyz9OX/pJgX+JcfqCt17E/cSP15d4lbce6q2NufY1O8bcmyTKTLAa3bmeSgVTgaLvb+cAMfw9USqUDmcDSdodDlFIbARfwG8Mw3uni3IXAQoDExESWL1/eg9Da1NbWdnvOtATFom35XB5XjvLTvUJ5PCRnL6Qwz8A42rvXb8/q/UP7MGkcXr4ca3Ml5wJlDbCjU4xpRwvJAo5X1WEoM/FAo8fK2uXLySiuJAOocVuwYKcqbw/V//ox1c4R1EZ0MSPgNeTINoYDVY0edpfl074oZOeWdZg8LkYD6zbvoCFUt51LP95IJrDjUDHjgUP7dpHX0jHeuNI1jGt3u95jZX2n9zS86Di+Tb2NlnpWLP2E6eu/x3ClP5pck9dIU/FyZjS1UF2Yz65e/qxPV0/+rfQXicW/YIklWOLopR6P2V3olzEbTv/7azQ0klfpOe2f0anGYXI3c64phH3HqijqwfkmdxPedJhmaxS2Fl2ZuK7IwjnKypGSKmrjO8aSfCyfkYC7MIey2GnknuR1xsdMJWLln1jbMh6P2U50+RYmApt37qU6v4taZsDeWMqsdrfzcjeQDtQ2dfzeZhwpIMPjYvmypboHdD8Klv+LwRIHSCxd6ctYepIk98ZNwH8Mw3C3O5ZuGEaBUmoYsFQptcMwjAOdTzQM4+/A3wGmTZtmzJ8/v1cvvHz5cro7J892mJXv7WTM1FkkOv30tQTgYkb06pVP9MUnNZA6lYwr7yMjfqTui7kaYlOHnxjj5iNwAOKS0vSgcxxCIuP04+w7Ie91IuKHQEM5jlBI2v8MTLgJ5t918iA+WwGHLYRGRDNq2BTY03bX2KyhujXQbpgxZz44U/Qdm/Lg8L8Zf84c2GUjMzWRzM7xbjwIO4GIFKg5RmhM8onvyb1S/1oGFAbzJmXBiiIcAKGxzLr0Bj37nOPEERdDYi9/1qerJ/9W+ovE4l+wxBIscfSzfhmz4fS/v1/U5rJ1XR7z5s3zO/HRL3Gcs5VRYXGMar9p1Mms0V2MbNnzIfcdQDHj0htgQjYZ0Zkc3rCjYyzbS2EvmD1NJIycQcLJ4sy0wwuXcV54HsxYCLtqYDtMmX6uXkTelboyWIv+HWR4SI8NgSNgD4/m3PavZ9oIeTB/7rkdPzHsB8HyfzFY4gCJpSt9GUtP/hQsgNaJQYA07zF/bqJTqYVhGAXey4PAcjrWK/er7ARddrC/pAdbVJ8GlzVCN5GP9378ZTpZuUW7hXu+cgtfeYRvQVxojK5Pzt+kF8SV+a+F7qCpRpePKNWupMP7/E21bfXG7WvRUibrmrnozLZd8zrz1STHj+gYY3udt2j11mQXJl0IV/2prTxDdm8S4kzozZh9gmAas7uT4LTT2OKhtimAZVvO5I67qnbHV5ecNF6PzeGJ+vy0aXoDks7al0rEDDv5c6fPgugMOLJG3/ZtLtJtuUVIx+ev1WV1fsstQMZtMWj0JEneAGQrpTKVUjZ0InzCimel1CggGljT7li0UsruvR4HnAvkdj63v2Ql6mRxX3FNN4/sY2YbKHNba7X22iewvr/MfTXJvoV7jmjvrkveuMv2d/1aDRW696YvSYa2ATJqqL701wIO9EzDfx3Sg741tG3DkfbqSnUsvkV+/npudl7p7U2Sj8fNgtFXtR03WaS7hRB9r0djtj/BNmZ3JyFCJ3EBXbzXW77JEmcKxGTqjUZOpn3Hi5jM7p8/ckhb7+WeJsm+MTtxrL70jtldJ8lSlywGh27LLQzDcCmlvgcsAczA84Zh7FRKPQpsNAzDN/jeBLxqGO23+2E08DellAedkP+m0wrrfhUfbscZYmHfGZ5JPoHFBre8rmdqO2vf3aL1WKeFe47otu2cQSfCdWX+Zx2W/hL2fKRfy+7s+BrhibojRXONdwZZdf2RmSWki5nkUp3s+7bt7tFMsl4E0qE1HshKaSHOgJ6M2Uqpc4C30RMbVymlHjEMYyxBNmZ3Jz5Cj19rDpRxvKaJGcP8jInBxpckRyTDxb/ovrbX2ouZZNALzw+t1Ndberhwz2SCa57USXLuu60LtP1uJgIybotBo0c1yYZhfAh82OnYQ51uP+znvNXA+NOIr08ppchOjDjj5RZ+ZV/k/3j7cgtfb2HfDHD7meTOCWvZfv9J8vG9ehYhLK7dTLI36Q6L09ebavWmINbQrrfftoZ2XW4RFt+2ytrvFqfehD8sXg+2rSulO80wm6y6tZEQok91N2YbhrEBXYbR+bygGrO7k+BNkn/2Tg5x4XY2/qyLcTaYhLZLkhNO7LN/At9MsiWkrZ/yyThToaZQrzvxzST3pPvG5Fvbkt8uW8DJTLIYXAbFjnvtZSeEByZJ7opvxz1/NcnOFJ1wxma1JaNDvIvUu6pLrjyiL4tzTyy3CI3TpRy+zUQ6z/i2Zz3ZTHKcfi7oIkn2DqyR3rLIOt9McqckWWaShRCnwVduAXC8tomSmgBuLNJTrTPJPUh4oS3Bjc48cTMqf5wputVmbbFOki2Ornfp68xs1W3tPC36UnU6T5JkMcgMuiQ5KyGcsrpmyuuC5D95a7mFn5rk0Bj40W69+YavdGLEZXoG1l9dssfTtsWpp8XPTHK8TsqbfEnySWYXupxJ7km5hTcZjvImya2zEv7KLYLk5yCEOOtEhlr52RWjeeRqXUube6w6wBH1QGyWnu31N3b64/sd0ZN6ZGjr819VoJNkWw97OHd+PX/nSbmFGGQGXZKcnagTx/WHygMciVdYnG4kn3bOiTPJoOuSlWobUJMm6MFy3yfw11lQsLntsbVFHRfCtZZtOOGKP8CkW9rNJNeffJcoq+PEhXseN9SX96Dcwvs+fDPJrYtA/JVbyGArhDh1d80dxrWT9OK3XYX9vCj7VMz8Lnx3Xdelbp35JjN6Uo8MOgEHqM73jvPd1CN35puk8XeezCSLQWbQJcnTM2IYFh/Gz97JoaQ6CD6aM1vhjvchfbZe4AdtyW17Q2dC1kUwZDrEZkNxDpTkwu4P2h7jK7Xwaf8853xDz+zaI7zdLRpOniT7W7hXXw4YOklOmQzn/gCyLjzx3FBvi6PY4fqytgRMVjymTm2SzBbZcU8IcdoiQ62kRjnILTwLZpLNFv9jfFdsYTDnhzDhKz17vK/vffUx70xyL5Nk3ySN35lkaQEnBpdBlyQ7bGaevnUqdU0uHn5/Z6DD6cjfTLJP7HC49U09Kzxkuu5UEZ0BR9fpRLNoB1R6N9nyLe7wlWi0Z/POJLsaTmzV1p6/cgvfltRhcTq5v/gR/72fkyfB15dA9iX6dm2Jnp3oPHMiM8lCiD4yOtnJrrMhSe4tpeCih0++GUh7jmg9fp9uuYW/crzWcouzqOWeEKdh0CXJACMSI7hjdgaLc4oorPJTdxsoviTZ7idJbm/OD+CHO3V9cv5GWP0neHoO7P9E3z9snvd5/MxW2MPb1SR3U27RUg/HtugyC2iXJPvp99yeUnrm2zfIupv8x2K2ycd2Qog+MSbFycHSWjYfqaCyfhCPK0rpkgtfuUWvZ5LDOl625/sd5QqCT2GF6AeDMkkG+OqMoRjAK+uOdPvYfuNbuOdvJrkzs1V3unA1wIrH9bGcN/WCusRx+ra/xNTWvtziZAv3HDop/vt8yHlLH/Mlyb7OFt1p//w2f0mylFsIIfrGmGQnHgOu++tqFr60iY4t+wcZZ4q33KK29zXJvt8//n4/+CZW/C3qFmIAGrRJ8pCYUC4YmcC/1x+lxe0JdDiar0zC2c0OTD5DZ+pL3+IMj0svlvPVAnc1k9xSpxPlk7WAix+lk2GTBYp36GO+Lam7m0n2sdgB1XUsUm4hhOgj80fG88ClI7lzdgbrD5fzcW5xoEMKnMg0b7lF/SmUW/hqkv0k15Iki0Fm0CbJADdNH8rx2iZW7T8e6FC0IefAD3MhfkTPHu9MgcihEJYA592vj0UNhSEzdceM1KknnuMbACvzIO4krzP1DvjxAd2u6Li33Vxdqd4dyl8dsj9Ktc1G+C23kD7JQoi+EWI1893zs/jZFaMZHh/GbxfvxuMZpLPJUel6Q5G6431bbiFJshhkBnWSfN6IOCJCLLy/rTDQobSJ7OEsss8Vv4cvPQ3jrtO3o4bqnfjueL+tX2Z77eudx1zT/fPHZetd/EAnyaFxPWto7+ObxfBXZy077gkh+pjFbOLuucM4WFrH/tIg2jiqP2WcCxjQVHUK5RYnWbjnW+wtNclikOjRttQDld1i5tKxSSzZWUSTaxx2Sw93JQomIy5pu/6lv8PQGSd/vK82ODZbl1R0JzYb9nykZ3zry3peauHjm3nociZ5EC+wEUKcEdMzdRvKjYcrGJHYi3ZrA0Xa9LZORn3ZAq51Jrn+9OIT4iwxqGeSAa6ckExNo4uH38sNru2qT8XEr+i2cCfjm9Edc03PmtnHZevZ3oq8ti2pe8M3G+F34Z6UWwgh+l5mXBixYTY25gXJplH9zWKDjLn6em9rkk+2mUhrkiwzyWJwGPRJ8rlZcVw8JpHXNx7l1mfXDfwatoTReuemiTf37PG+uuXje9u2pO6Nk80kW0IAA1zSc1MI0XeUUkxJj2ZTXgUAu4uqueKJlcGxgVR/8W301JNuSe2dbFtqk1mXyclMshgkBn2SbDWbeOb2afz2+gkUVTey89gAbEbfXnQG3LsF4rJ69vhY7+PK9ulFIL1Okr0Drr+aZN9mJ40D/HsuhOh309KjySurp7SmiedWHmLnsWrWHCwLdFj9J+si3Z0oIql3552sBZzvuNQki0Fi0CfJPvNHxqMULN1dEuhQgosjSifGRTnQVH0K5RYnmUkO8SbJTZIkCyH61rQM3YXng+3HeH/7MQB25FcFMqT+FZMJ926FUVf27ryTdbcA3TpUuluIQUKSZK+4cDsT0qJYukeS5BPEj4IDn+nrp1pu4e8jP1/iLEmyEKKPjU+NYmRiBA+/n0tji4foUCs5xwZRkgwQNUSXSPRGtzPJDkmSxaAhSXI7F4xMYHt+JWsOlA3u3Zo6m3qn7mwBp75wz1da0Z7vWFPNKYcmhBD+2CwmXlk4k8lDo5ieGcMVE5LZWVA98NednK7YLL2hVcJo//dbHHqnVyEGAUmS27l2cgpRDis3P7OW//t0X6DDCR5jv9RWm9yXC/d8x6QmWQhxBsSE2Xjr27P5910zGJ8aSU2Ti7xyWXR2Us5kuC9XdzbbkDOVAAAgAElEQVTyR2aSxSAiSXI76bFhrHrwAuZmx/HqhiMy4+BjMsP5/627UURn9u5c20kW7oXITLIQ4sxSSmExmxibEglATsEgK7noa1aHtIATg4YkyZ2E2ixcPyWN4uomtuZXBjqc4DHuOnjwKIT35UyyLNwTQvSPEYkR2Mwmth2Vcf20WEKkBZwYNCRJ9uP8UQlYTIolOUWBDiW4WGy9P6d14d5JkmQptxBCnGE2i4kZw2L4ZFexrDk5HVaHtIATg4YkyX5EOqzMzorj3a3HeG/bMeqbXYEO6ew18gqYfQ+Expx4n8WmZyVkJlkI0Q+unJBMXlk9OQXVFFY1SEndqbA6ZCZZDBqSJHfh7rmZ1DW7uPeVLcz+zVJe33g00CGdnRJGwSW/7HoLbHuEJMlCiH5x6dgkrGbFf725nVm/XsoHOwoDHdLZR2qSxSAiSXIX5mbHs+V/Lua1hTMZEh3Krz7chVtmHfqe3SkL94QQ/SIq1Mbc7HhyC/Uf5nuKZOzpNWkBJwYRSZJPwmI2MWNYLHefN4zK+ha2y0K+vmePkJpkIUS/+dElI7jngizSoh0cLqsLdDhnH2kBJwYRS6ADOBvMzYpDKVix9ziTh0YHOpyBJSRIZ5INAwxP73erEkIEtbEpkYxNiWR7fhV5ZVJb22tWB7ibweOW8VEMeDKT3APRYbbWLav/uTaPR97fyXNfHAp0WAOD3RmcNckrfw9/namTZSHEgJMRG8rhsjr2FNXwq3UN5B4LwnEoGFlC9KXMJotBQGaSe2hedhxPLN3PtqOVhFhNNLZ4GJviZOaw2ECHdnazO4Oz3OLQCji+F2pLICIx0NEIIfpYemwYNY0uXlh1iL0VHm55di2jk5zYrSZeuPMcVFeLjQc7a6i+dDX63yRKiAFEZpJ76LopaczNjuOZ26ex9aFLSHKG8Nji3dJv83QFY7mFYUBxjr5esjOwsQghzoiMOJ3svbftGClhiuRIB4eO17F8Tymb8ioCHF0Qs/pmkqVURQx8kiT3UEZcGC9/YwYXj0kkxGrm3guz2Xykks92lQDQ5HIHOMKzlK8FnMcT6Eja1JZAfZm+Xpzb+/NdzbD5JTj4Obilx7YQwSg9NgyA+mY3UxMtfPT9uXz2o3mE2sy8uTk/wNEFMd9MsrSBE4OAJMmn6MZpaWTGhfH4x3t4duVBJjz8MccqpUar1+xOwICWIFhl3lAJa5+Cwm1tx0p6kCR7PFB5pO32tlfgvXvgpathyU/7Pk4hxGlLi3Zg8lZUjIrRC9DC7BYuG5fEom2FNLbIxIdfFplJFoOHJMmnyGo2cd/FI9hdVMMvP9hFk8vD8j2lgQ7r7GP3blcdiLpkjwfqy9tub3wOFj8Iy3+lbydPhOKTlFv4Fq4s+yX83wTY/YG+veMNiM2CkZdDzn/0KnAhRFCxW8ykRDmwmhVZ0W2/Cq+fkkZNk4vP97aN5/kV9ZI0+1gd+lK2phaDQI+SZKXUZUqpPUqp/UqpB/3cf6dSqlQptdX7dVe7++5QSu3zft3Rl8EH2hXjk5k0JIrshHASnXZW7pMkuddCnPqyv+uSDQPeXgh/mgg1xfrYno/05bEtEJECGXOhdLf/JHfvx/CbobDyD7D2ab2j4Jt3wY7/wOGVMP7LMO56XbaRv7H/3pcQ9GjMPk8ptVkp5VJK3dDpvgE7Znc2IS2S2cPjsJvbFulNTY/GYlJsO6r74tc2ubj4Dyuko5GPL0mW7hZiEOi2u4VSygw8CVwM5AMblFLvGYbR+XPo1wzD+F6nc2OAnwPTAAPY5D13QKyKMJkUry6ciUkpfvbODhbnFPHEZ/t4Z30DyaNqGJkUEegQg5/dlyT34UyyYUDBZkid0vV22Ntf1zO+AF/8Eeb8UCezsVlQth8Sx0LCGD1bUroHyg/Axhf0gr6RC2Dfp+Bugc8eARTc/i4s+gG8+Q39nBNuBEcMKDPsXQxDZ/Td++sJjwf2fwo1x3S/58ZqCIvTv9jqy2H63RAa0/Z4VzMxZZthdQ5kXwxH10FVPgydBQeXQcku3Rs1ZTJEpUNjJZTshphMiBoKZhvUlep67poifX/scDBZoLGqY2yGARhtl+2PmSzgiCb74G4o/Jt+TnuErvNuqgZHNITG6se5GiA8SV9W5EF1AUQOAUeUfo9WBzhT9WXJLrCFQXgihERCQwXUH9fPawvTq/RtEWC26HNL94DFDhn399MPrO/0cMw+AtwJ3N/p3AE9Znf2x69MwjBg7aqVrcdCrGZGJEawo0D/u91wuJyGFre0iPORFnBiEOlJC7jpwH7DMA4CKKVeBa4BerKi6VLgE8Mwyr3nfgJcBrxyauEGnxCrrmWbmx3P6xvz+cMnezEpuOovX5AZG8ats9K5bWZ6gKMMYr4kuS/LLfZ8CK/eApc/rpNBVzNYbK13K48blvwEhszUSd7G573JtAHXPgWv3QbpsyB5gj7hqVn6Miod0s6BTS/q21/9D3z6MKRMhGHz4O5l8MF9OjGOGaYfkz4bdr6lk8uQSJ1QxmSePH5Xs04CTd4PejxuQEFtMWz6B6RMghGXtf0BUF0IO16HXe/rxTQWu04uK/O6fo3NL8KQ6eBxQeJ42PwiE6oLYAfw8X93fKzJov9oAFj9Z30O6IRz+2u0Jrq+x4Yn6p/r/k918hviBNX5QyvljV+1+0NGgacF6stJMIeCO10n9o1VOgmPSNJ144XbdAyWEDi4QifB0emQNAEqDkP1MZ1IN1XD0fX6D52E0Tp5z1utn88RrZ/bYofmOmiqheZa/YdASBTEZeuf2dmp2zHbMIzD3vs6r5gd8GN2e3aL/80wxqU6+XRXCYZhsPaAXsR7oLS2P0MLXq0t4CRJFgNfT5LkVOBou9v5gL9pseuVUucBe4EfGoZxtItzU/29iFJqIbAQIDExkeXLl/cgtDa1tbW9PqdPNRsoIDlMsXC0h1WlJvZW1PHwuzmYSg+QGqGTBMMwyKv2kO409UsfzoB/X9rxF0to3RGmAzu3rKW0oPdtu+NLVtFidVIZPb712NicPxMPuJY8RNXaV4kp30xNxDBKEuZSlHQhttJdUF9GTuZd1IYMZ6p6H+vav9JoT2Dt/jpMk5/A47LCruNET3gYZ/VeGkPiKUmYh2EyExkyG2tLFccLLDDqUUCB733F3a4vvbcTQ6Yw6vAXqNdva42vISSJFmsETfY4Uq0J7CpaTl1YGhZXPfGlq0kq+gxDWWlwJKEMF6H1x1rPNRktANQ7kvGYbCjDQ2h9AQoP1RHZNNuiMTU3Y5jiKBpzI1WRYwBwm0OxtlRiKAvWlipG7nkS88G1mDwthOx6n+qIEewZ/kPccSOJLdtIXdhQ6sIyiKzaRVXkKFpsUQCo7BZszVV4TDZabE5M7iZszRWYPM20WKNosYa3JcSGGzB1PZvfFcOgtq6O8PBT6MGacOJzgeEnSe+ZYPr/0ws9HbN7eu4ZGbMheL6/neOw17dQXtfMW4uXsWRrEwD7S2pYumwZpjM8bgfL9wT8xxLSUMxMYPeOLRQd7799AoLl+xIscYDE0pW+jKWvNhN5H3jFMIwmpdQ3gReBC3rzBIZh/B34O8C0adOM+fPn9yqA5cuX09tz+pottYgxyU4ObF/PnTfMp7yumQt+v5x3jzl4beFMlFJ8vLOIh5ds4rk7pnHh6DO/SUUwfF98/MZSWwobYKz5MMzzzmBueFbPuo79Epit+lh9OeS8qa9bHfoj8qIdkPt7Pct40cOwaxGMvRYqNsOIy7AcWEZs1XaYdifOwm04D7xAVuUXFNizwWxn3NX36o/Zz18Aez4kJCqd+emzOkV9fuu10a3XOr2Hk5oPTT/WG5O01EPRDhx5q3A01ULVUeIK16EK203mmaww/gawhBBRla/fW8xVOtF0NeuZ8QNLCT3s/XjYMCDhJphwE864rA6vfNJfX1fd1XZ+TRHOiCTqPv/c+/O5ud0Dr+nFe+07wfLvNljiCEanO2ZD8Hx/O8cReaSCl3NX447P5kjNdlKjHBRUNpA9cQZDYkL7NZZA8j9ml8A6GDU8nVHT5/s7rf9iCYBgiQMklq70ZSw9SZILgCHtbqd5j7UyDKOs3c1ngcfanTu/07nLexvk2eLSsUkAHPDejgmz8cClI/nvt3P4KKeIy8cn8/Ja/RH4kp1FrUny3uIaMuPCsJoHYbOR8HiY9yB8/hv9EXn8KPjQWyb54f2QPAnG3wjr/gbFO048f/yNugPFkp+C2Q5HVuvj5z0Ac+7TH/UneNPbXe/Da7eSwn5dd+vbLSrECRNvOnPv0R6u66MBMubAzG+33rVi6SfMG5ema2Ctobp2OSTy5M8Xlw0zvtk3sSkFzuS+eS4RLLods7s5d36nc5f3SVRnkdHJTswmxZPL9uMx4ObpQ3j8473sL63FZFL8/N0cRiRG8OPLRgU61P4nNcliEOlJkrwByFZKZaIH0JuAW9o/QCmVbBhGoffm1cAu7/UlwK+UUtHe25cAPzntqM8iN50zlJdW5/HbxbvJTghn5b7j2Cwmlu4uweMx2F5QxbVPruLm6UP59XXju3/CgWj+g3qh17qn9e3M82DWPbB7ka4hfe97OgG+5XVImaJr4Zpq9MK5pAl6Ada+j3XLtddu07WoqVNP/Jh/9FWQdRFq/6f6sUHAMFl1Ep8wuvsHC9Ez3Y7ZJzHox2zQa01GJ0eQU1DNgnFJ3DhNJ8mf7Srm+69sobbJxae7SkiNdvDVGYNszYm0gBODSLdJsmEYLqXU99CDpxl43jCMnUqpR4GNhmG8B9yrlLoacAHl6FXTGIZRrpT6BXrQBnjUtyBksDCbFD+5fBR3vrCBK574ArNJ8eNLR/LLD3axNb+SP36yF4BXNxzh1plDGZvSzSziQKQULPitTo63vwYLHtOLtEZcors0HFiqOxakTfN/fngCTL5VX79zkV581VXd4ILHKH3lO8SPCUwZgRBnWk/GbKXUOcDbQDRwlVLqEcMwxsqY3eavt0ylyeUmOzECwzCICrXyz7VHCLOZ+eS+eTz6fi4Pv7eTy8YmERtuD3S4/cds1Qt0ZTMRMQj06PN9wzA+NAxjhGEYww3D+F/vsYe8CTKGYfzEO8BONAzjfMMwdrc793nDMLK8Xy+cmbcR3OaNiOexGyZwy4yh/PLacdw4dQhmk+KBN7axct9x7r0giyiHlYff24nHY1BS0zg4G9ePugK+/JJOkH1MJsi+qOsEuTOldMeCrsQOZ+e4n3RsfybEANODMXuDYRhphmGEGYYRaxjG2HbnDvoxG2BobCjZibqNp1KK4fG6POuuucMYHh/OA5eOpMVt8NnukkCGGRgWR/BtS52/Ef4yva3vvRB9oK8W7omTUErx5WlDOhy7e+4wPt9bytzsOL5zfhZDYkJ54D/buf8/2/hoRxHZieG8unAmoTb5EQkhRKCNT43kSHk9d5+n2zuOTXGSGuXg453F2C0mdhXW8IOLslvbgg5oVkfwzSSv+hMc3wP7lsCU2wMdjRggBuFKseDw4IJRfPT9ubz8jRmEWM3cMDWNi8ck8tbmAuIj7OwoqOK+17ZhGAYvr83jx//ZxpoDZd0/sRBCiD734IJRfPyD8wi364kLpRQXjU5gxb5SHnhjO09/foDr/rqaqoaWAEfaD6IzdGnchmd7f271MTiy9sTjrmZvy8ZeqC+HJ2fCsl/D7g/0sQPLuj/PMKBgk//dVIVoR5LkIKGU4rHrJ/Cji0fw7nfP5ceXjmLxziL+ue4Iv3g/lzc25XPzM2vZePjE8sAtRyr4+j82UNfkCkDkQggx8IVYzUSH2Tocu2RsEs0uDxEhFn5z3XhyC6t5f9sxFm0/xg1PrabZ1XmvFq2+2cUPXt1CXlldf4Te977yT92p54MfweFVsO01WPt0z85d9EN48Wq9+NqnsQr+MBrWPtW7OHa9D6W7dHckw+3dIXS5XsvSWXMdvHAFrPkrrH8GnrkAlv9a39dQCYt/Cp8+AsU92SdNDBbyWX4QiQ6zcc+F2QDcNTeT1zce5X/eycFqViz5wXnc+PQanl91iGkZbfW0bo/BT9/OYVdhNZ/uKuaaSX77/gshhOhj0zNjuGxsErfMGMrc7Dj+vvIgH+UUUlbbzO6iGpbvKeGSsUknnPf5nlLe2XqM7MQIvnt+lp9nDnIRifDll+HJ6fDmXVBTCBh6x8zZ9+jHGAbs/wzW/x3qSvRupdMX6k5Ehgf2LtE94QG2vqK7FK17CrIuhLfuhuhMqDuuOx99fYl+3PH9sOx/4eJHIWoI5L6rZ7WTJ+kWmsPmw9sLoWibbie64VnYsxjiR+g66rwv9JfZph+/8g+6pd22V6D8kF7TsvF5uC9X9+IXg54kyUHKajbx40tH8u1/beaW6UMZkRjBTdOH8OzKQxRUNpAa5WBfcQ3vbzvGrsJqrGbFRzuKJEkWQoh+YjWbePq2qa23F4xL4sllB1pvv7O1wG+SvHxPKQA7j1Wd+SDPFFsoXPJLeOMOSJ0Gkanw8c90khk/Csr2602UwpMgfqROWHPe1AlySBTsfBsKNuvEdO8SsIZB5RF4+TqdGNdX6Nrn43tg2ysoTya8dRcc2wJ1pXqR96HPdVJ+0cM6Jt+ivY+8bUVLd+tYNn6hj4+/EarydV/6ry+Gf14PS38BESm6MxIKXrgMtr0K53wjAN9UEWwkSQ5il41L4qmvTmHuiHgAbpuZzjMrDvI/7+QwZWgUj3+s28fNHh5LVkI4r204Sl2TizBvzdyHOwrZX+piPtDs8mA1qw5bYbe4PdQ0uogJs1FW20Sz20NypKO/36YQQgwIC8Yl8+SyAzisZq6ckMy7245R1dBCpMPa+hjDMPh8r06SdxScxUkywJhr4OZXYcgMPfOaOU/PFFceAUcMfOlvMPY6sNj0wrpPHoLhF0DMcNjwTMfnuupPutyhOh+u+ENbkvrMhbD2KbJCRuoEecy1kPuOLpfwuHQMPhGJcP7PYPNL+vatb0LWRTo53/wyXPpr3U60qUZ3OPrmCr0A0Zmqk3XDgJTJuuxj6p1gCpJFmFX5+g8L3wZYot9IkhzElFIsGN+2G1padCgPXz2Wh9/bydLdJVw5IZnvzM8iOzGczXkVvLQmj+/9ezPjUyNxOqz88gO9p8uq8jVsOVJJmN3M1RNT+PlVY3lh9WGe/vwAdU0ult0/n2++vInSmiaW3j8Pu6VtYGhyuTvcbi+vrI6hMaEdEm8hhBisxqY4GZPsZHpmDNdNSeWNTfl8uKOQm6cPbX3MnuIaiqobGR4fxoHSOirrm4kKtZ3kWYOYUjByQdvtc77R9Qzs7HvBHgEZc/VM8IZnYPJtemOnvR/BhJt08pq3RieoPjO/DW9+g1QOwIxvwWW/gU8f1i3fMuboUov25j2gv9obd73+8vG1AA2NAdq1A1UKZn5Xz1g/Ngwy5+o/AELjIPsSOL6HcTv+F9JcOvnuisetE3iTFdb8WSe4U+/Q99Ud16UdJjN8/pje8fTiX+jb216BujJImwq7P4T6Mqg6CvnetuXxo/VuscPmw97FTNv5CRSMgIxzdaJfsAl2/AcSx8K534fkibq0ZP+nun67bB8MmQmTbtYz92X7wd2kZ/fLDkJ0ut7xtWy/rhMPT9AbeMUMgz0fQXWB9/4DuoRGmXUpS1g8URVVUJIE+z/RnwCYrHomP3mSbuEaFq+/J64mqDisPyFI9X4Kc2yL3jnXFg7JE/S/kYJNes+DsHj9/as4DA3l+jVDY3Rs1lD9/SzYpD/ZyL4EnCld/1xOgSTJZ5nbZ2WQGRfG9vwqvjVvOGaTTlCnZcQwe3gsu4tq+HxvKR4D5mTF4WipJKe8nhunpVHZ0MKLa/LYXlDFliOVzBwWw/pD5fzg1a1sPVoJwJubCrhlhh7QcwqquOnva3nk6rFcPzWtQxzL9pTwtRc28MevTORLkzveJ4QQg5FSikX3zGndy2h4fBhvby7okCS/vUXvEP6d+Vn86I1t5BRUMyc7LhDh9i+lYNrX9fW4bPj2aogbCWYLjPLugDr7nraaZp8x18CRteTUxzBuwU/1sYsfOXNxjr9Bz3zv+xgOfq6TSwBbBLgaifW4dZlG3AidQMZ7Z7jdLZAySc9Gb3sFaoshcRwUbNTnVx3VW3lvfL6tfZ7dqf8w2P6Gruduv4uhxaFLWCwOXU7idul66rVPweonQJlpjhqnk8d93pptk1Un0UfXwcvXdnxf4Yk65o3Pwfq/nd73yBqmZ+1dzbDjdQAmAWx7qOPjTFb9vnr6nK5GvQDzdNy75fTO70SS5LPQ3Ox45mbHdzhmNin+ffdMAAqrGlixt5QrJ6SwYc0XzJ8/H9Af8zlDrLyy/ghfmpzK72+cyL2vbmHR9kKiQ62kRjv46/L9LBiXRFSolUffz6W2ycXvluzhignJrf0/W9wefrFIrwB+/ovDXDspVWaThRACMJnaxsLrpqTxuyV7OFpez5CYUN7eks/fPj/ItZNSuHB0AqBLLnxJ8qa8ct4/0MzsOR5slgHefCpxbPePAb3D3xWPc3z58jMaTiuldGI+5hqd8DZW6kT0i/8DDFZHXce5ziLdRePgMtj+qq5ptoXqGXHQNdrps/XCwgsfgqMbYMXv9Czo2Gt1yUhdqb48vke307OF61n52Cw9c5wxBxzRnYJ7wDvbvhristm+/Yj+/V59TM/8Rg3VZS++Gfnje3WSmjBWL4g0maGqQD+/q0nPENvC9ExyTKaeIW6p18l0SJRO7I9t0TPCGXN0KUpjla4zN3n/fTbXQUMF2z99nQnpUZB1sT7ubtaLKgu36fPrjutZbYvdm7Bn6zhMVkidohdqGm7IWwVH1+vZZ0e0Pq++XL+38AQ9S19/XH//Whp0nMkT9c/p8Bf6eTjSZ/8cJEkegJIjHXzlnKEnHFdK8eg1Y7l8fBKzhsViMim+NW84i7YXctusDM7JiOb259dz7m+XMiIxgq1HK7lucipvbSng+qdWU9vk4vyRCRwtr+dgaR0Xj0nkk9xithytZMpQ/Z95d1E1R8rq/S5WEUKIweSaSSn8bske3t1awNfOzeS/385hRmYMv71hAnaLmbRoB5uPVLQ+/uH3ctlR0MLRZ9fx1K1TBtd218FIKZ2oOaLhyy8C0LJ8Ocy8FmZ+SyfRDRX6fqV04mkYYA3R51/7lD7udkHJTl2L3bmuOGy2TqjbG31V1zHZI2DEpd4b3mTQmdKxzMAeASMu0V+dRabqL3+SJ3S8HZ2uv9rr3PXDFga2MMpjp8C0+Sc+Z+oU/eVPXHanAyZdSjLMz/N0MOLEQ85kSBjdzXm9N8D/VBWdWc0m5mbHYzHrH/241Eg+vHcu91yQxdzseJb84DyumpCCzWLSA/yNE1kwLomy2mYyYsP417o8thyt5Dvzh/PHr0wi3G7hR69v47kvDpFfUc+tz65n4cubeHltXoDfqRBCBFZadCgzh8Xw6oajfLijkPpmNz+6ZGTrOo8F45L4JLeY1QeOk3usmh0FVUxJMLMtv5Kr/7KqtQzOp6KumZfX5nXZf1n0M6V0fazvk1SLvS1B9t0PuqQkeaIsvDsLyUyyYEyKs/X6iMQIfntDx78mn7q1rcVRQ7Mbm8XUWgv9hy9P5Mll+/nFolx+/eEuzCbFzGExPPRuDuF2M1+anEZFXTOf7S7B1tS2m1Jji647GhRbuAohBq275gzjrpc28otFuaRGOZiW3vYR+n0Xj+TTXSXc//o2RiU7sZlNfH2cnaFjJrPwpU1c++QqLhqdwF9umcL+kloWvrSRY1WNOEMshFjNPPHZPt789uwO4+jq/cdJjXaQHit9foU4XZIki15x2DomtZeMTeKSsUms2n+c33+8h9tmpbNgXDJf/8cG7n9jO69tOMrmI5U0uzxkR5lYcJGHRduP8fB7uVQ3tnBORgyvLZwpNc1CiAHpwtEJjEl2kltYzVdnpneoWXbYzPzppknc/dLG1o5F4bZqJqRF8fF95/HCF4f546d7eWzxHhbnFAIQZjOz/lA5pTVN7DxWzed7S7nUW97W2OLm6y9uYNawWF742vSAvF8hBhJJkkWfODcrjnOz2lZoP3P7NL7/6lZdgjEjnQSnnd98tJsZv/qM8rpmpqZHExduY8nOYsrrmqX2TggxICml+NElI/jOvzZz/ZQTOwFNSItixY/PZ+muEqamR5O7eS0AzhAr378omwOltTy/6hBmk+LNb8/m/z7dy5oDZZTWNgGwOKeoNUled6icxhYPq/aXUdPYQkSItcNrVTW0EGozYzVLpaUQPSFJsjgjwuwWnr1jWodj23YfoMQTxs+uGM01k1L5dFcxS3YWU1DZIEmyEGLAunB0IjmPXNplcmq3mFt74ud2uu9nV4xm/aFybpuVzqQhUUzPjGndsS/RaefT3OLWfvafe483uz0s31PKVRNTKKttIr+igfWHyvndkj0sPG8Y91868oy9VyEGEkmSRb/5ykgb8+e3reJNjdK7+x2rbGBCWlSgwhJCiDPuVGdvE5whrHrwgtZ1IDMyYwG9JuzBBaP44Wvb+DS3hCsmJLN8bwlzs+PIPVbNi6sP8+bmfFbuO47bo9eD2CwmPt1V3CFJbnF72Ftcw9iUyNN8h0IMPJIki4BJi9ZJcn5FQ4AjEUKI4GVuV8c8PjWSEKuJEYkRXDE+hSeXHeDBt7ZTXN3IwdI6bp2RTlq0g1fWHyUhws635g1jytBonA4r6w6W8fjHeymvayYmTO/y99C7Obyy/ig/v2oMXzs3M1BvUYigJEmyCJhIh5VQm5mCSkmShRCiJ2wWE/9z5RhSohzYLCb+8bVzuP6p1Ty6KJckZwgLxidxtTmFeSPiOX9UQmu7OQBfrr3uYBkLxiezOKeIV9YfJdFp59FFuWTEhXH+yIQAvTMhgo8kySJglFKkRjk4JkmyEEL02FdntG3wkBYdytvfOZfCqgYmpkW19sC/bFzyCedNSIsi1DPYN6IAACAASURBVGZmzcEykiJD+NHrWxmfGsm/757BZf+3kpdWH5YkWYh2JEkWAZUS5ZCZZCGEOA0pUQ5SvGs8TsZqNnFORgxvbsrnP5vyiY+w8+wd04gIsbJgXBIvrcljX3ENjy7KJTshghGmtk1L9pfUUtPYwuShnbdKFmLgkiRZBFRqtIPt+ZXdP1AIIcRpu2N2Oi6Ph7SoUO65MItEp94hbsH4JJ794hC3PreO8rpm1h0qJ9RsMGtmHc99cYh/rs3DY8DFYxJ58pYp2CzSRk4MfJIki4BKjXJQUd9CfbOLUJv8cxRCiDPpglGJXDAq8YTjk4dEkxBhp7i6iR9eNIJLxyVy9RMrueD3n+MxDG6fmU6IzczfPj/IxsPlzG7XF1+IgUr+FBQB1b4NnBBCiMAwmRQ3TE0jKyGcb84bxqgkJ3dNsDMuxcmrd8/kkWvGce2kVACqG1sCHK0Q/UOm7kRApXrbwBVUNpKVEBHgaIQQYvD68WWjuP+Ska1bZ09PsvDjm+a03h8RolOG6gZXQOITor/JTLIIqKExoQBsOyp1yUIIEWimdj2ZO3M69DbXMpMsBgtJkkVAJTpDmDcinn+sPkx9s8xOCCFEsAq3WVAKqhskSRaDgyTJIuDuuSCL8rpmXll/NNChCCGE6ILJpIiwW6hulAkNMThIkiwCblpGDDOHxfDU8v3yMZ4QQgQxp8MqM8li0JAkWQSF/758DGV1zTzx6b5AhyKEEKILzhCrTGaIQUO6W4igMD4tkq9MG8I/Vh/GYTPzzXnDCbfLP08hhAgmTodFuluIQUNmkkXQ+MmC0Vw6Lok/L93PN1/eiMdjBDokIYQQ7chMshhMJEkWQSMy1MqTt0zhV18az6r9Zfzps300trgDHZYQQggvp8NKjSzcE4NEj5JkpdRlSqk9Sqn9SqkH/dx/n1IqVym1XSn1mVIqvd19bqXUVu/Xe30ZvBiYbp4+hAXjkvjTZ/uY8MjH/PrDXdQ2yaAsRE/1YMy2K6Ve896/TimV4T2eoZRqaDdmP93fsYvgFhFikYV7YtDotuhTKWUGngQuBvKBDUqp9wzDyG33sC3ANMMw6pVS3wYeA77iva/BMIxJfRy3GMCUUjxx82RW7itl0fZC/rbiICv3HeeNb80iTOqUhTipHo7Z3wAqDMPIUkrdBPyWtjH7gIzZoivOECs1TS7cHgPzSTYeEWIg6MlM8nRgv2EYBw3DaAZeBa5p/wDDMJYZhlHvvbkWSOvbMMVgYzWbuGBUIn/48iSeu2Mau4uque/1rbS4PYEOTYhg1+2Y7b39ovf6f4ALlVKS8Yhu+Xbdq5WSCzEIKMM4+eIopdQNwGWGYdzlvX0bMMMwjO918fi/AEWGYfzSe9sFbAVcwG8Mw3ini/MWAgsBEhMTp7766qu9eiO1tbWEh4f36pwzRWLx73Ri+eRwC//a3cywSBO3jraRGWniVH+nD5TvSV+TWPomjvPPP3+TYRjTzlBI3erJmK2UyvE+Jt97+wAwAwgHdgJ7gWrgZ4ZhrOzidU5rzIaz++d8pgR7LCvzW3gup5nfnecgPrT/ljUFy/clWOIAiaUrvY3lpGO2YRgn/QJuAJ5td/s24C9dPPZW9Eyyvd2xVO/lMOAwMLy715w6darRW8uWLev1OWeKxOLf6cayaNsxY9zPFxvp/7XIuOKJFcb+khoj91iVUVzd0K9x9CWJxb9gieVU4gA2Gt2McWfyqydjNpADpLW7fQCIA+xArPfYVOAo4OzuNU9lzDaMs/vnfKYEeyyLcwqN9P9aZOzIrwx4LIEQLHEYhsTSld7GcrIxuycFngXAkHa307zHOlBKXQT8NzDPMIymdkl4gffyoFJqOTDZOyAL0StXTEhmTnYcH+4o5LHFu7nw958DkOQM4bVvziQ9NizAEQoRFHoyZvsek6+UsgCRQJn3F0YTgGEYm7wzzCOAjWc8anFWcIbocgtpAycGg558VrIByFZKZSqlbMBNQIcuFUqpycDfgKsNwyhpdzxaKWX3Xo8DzgXaLx4RolciHVZunj6UD+6dyzfPG8b/XDmGRpeba59cxV0vbmRxTpFvZkyIwarbMdt7+w7v9RuApYZhGEqpeO/CP5RSw4Bs4GA/xS3OAk6HnluTNnBiMOh2JtkwDJdS6nvAEsAMPG8Yxk6l1KPoKer3gN+ha9ne8NaJHjEM42pgNPA3pZQHnZD/xui4wlqIU5IS5eAnl48GYPbwWP6ybD9bj1TyrX9uYuKQKC4fl8R1U9KIj7AHOFIh+lcPx+zngJeVUvuBcnQiDXAe8KhSqgXwAN8yDKO8/9+FCFatM8nSBk4MAj3qp2UYxofAh52OPdTu+kVdnLcaGH86AQrRndHJTp68ZQout4dX1h/h1Q1H+fVHu/n9x3u5cmIyX5udyfi0yECHKUS/6cGY3Qjc6Oe8N4E3z3iA4qzl625RLTPJYhCQprNiwLCYTdw2K4PbZmVwsLSWF1cf5j+b8nlrcwET0yKpbXJRUtNEmNnNs9lVjEuVxFkIIXoj3NurXmaSxWAg21KLAWlYfDiPXDOONT+9kIeuHIPHgPTYMK6fkkazG77+jw0898Uhnv78AIVVDYEOVwghzgpmkyLCbpGFe2JQkJlkMaA5Q6x8fU4mX5+T2XpsuCrmsY0t/GKRLo9/bPFuRiU5iQ23YRjwk8tHMTZFZpmFEMKfqDArBRUyuSAGPkmSxaAzJMLEFw9eQGOLm6YWD29tyWdTXgU1jS4KKhu4/qnVTE2PJtRm4ZIxiVw8JpGoUFugwxZCiKBw4ahE/r3uCOV1zcSEydgoBi5JksWgFOmwEuldgPKDi0a0Hi+paeTn7+6kpKaJw8er+SS3GItJkR4bSly4nZumD2HLkUpKqpu4Y3YGM4fFnPLOf0IIcTa6afoQ/rH6MG9tzueuucMCHY4QZ4wkyUK0kxARwlO3TgX0bpQ7Cqr4KKeII2X15BZW88PXtmE1K5whVhbvLGLK0Cjuv2Qks7PiAKhtcqGAMLv81xJCDEyjkpxMHhrFK+uP8I05mTJRIAYs+U0uRBeUUkxIi2JCWhQAbo/B6gPHyYwLIy7czhub8nl6+QFueXYd542Ip9nlZnNeJXaLie9flE1dk5uxKU4uGpMY4HcihBB968apQ/jp2zvYU1zDqCRnoMMR4oyQJFmIHjKbFHOz41tv3zYznRunpvHnpfv4YHshUaE2bp+VzvaCKn75wa7Wx83JimNGZgxOh5WkyBCmpUcDEGI14zEMWtwerGZpNCOEOHtcNDqBn74Nn+YWS5IsBixJkoU4DSFWMw9cOooHLh3VeszjMcgtrCYt2sFrG47yr3VH+GL/8a6fZMlHDI8PIy06FJvFxMVjEjErRWltE6E2M6E2C4lOO6lRDmqbXJhNCovJhMvjYURiBAoo8y6g6ZxsN7s8lNQ0YjWbiA61YbNIMi6EOH0JzhAmDonik10lfO+C7ECHI8QZIUmyEH3MZFKtG5V8c95wvjlvOA3NbuqbXRworWN7fiVWs4nGFje5ew+Qnp7OjoIqyuqaKa9r5pPc4h6/VoTdgtswqG9269dWOnGPCbNhNikKKxtpdnsAUArSoh2MTHTi8nhIjXKQ5Azh0PE6yuubyS9u4IncVcwYFktGbChhdgthdgsRdgtRoVZsZjP5lfWMS43EGWKlpLqRZXtKOF7bTESIhSlDo7FZTESFWkmICKG2Se/IZTEpCqsaSY4Modnt4UBJLWF2C84QvXgyxGrqtqaxyeXmeG0zYTYzYXYLbo9BTaOL6FArn+4qZl9xLQvnDcNqMlHT5EKptu1z3R6DbfmVRDqsxIXZsVtNhFjNfl+nxe1hb3EN6bFhrZsmCCH8u3h0Ao9/vJcvP70Gh83Mc3dMwyKfiokBRH4LCNEPHDYzDpuZ2HA70zNjWo8vN44yf/7I1tuGYbDzWDUhVhPJkQ4aWtzUN7nJr6ynqKqRiBArbo+hvwyDNQfKsJkVwxPCqahrweXxUNfkpqK+GbfH4LJxIQyLC6PFbVBa08S+khoOlNRhtSg2Hq6gtslFSmQIseF2rCYwKcUzKw7i8hhdvpcIu4WMuDB2FFR1+Zi0aAcFlQ0Y7Z7GbFJ4DKPDMaB1IWSkw0qEw0q43czu/HqqPv4Qu8WEzWKiqqEFfyGZTQq3944PdhRS1dBCYVUjANGhVobHh1NW18yh43Udzgu3W3DYzMSH25maHs2Gw+UUVzdS3+ymyeUhxGri8vHJXBnf9fdBiMHuojGJPP7xXnYeq6Ku2c2Tyw7w/YtkVlkMHJIkCxFElFIdtssOs1sgHIbGhvp9/NUTU075tdweg8YWd2snjuXLlzN//mwamnWSXdvk0l+NLirqm2lq8RAbbuPtLQUUVTXywKUjuXB0AplxYRyvbWZzXgVKQV5ZPTvyq7hhahoOq5lml4fEyBDyKxowK8WYFCdNLjfVDS6qGlqobmyhuqHFe91FTWMLw6NMTBmZQYvbQ5PLTXSojZQoBw3Nbuq8M8XhdguFVY2MSXFiNZt49P1cshPD+cacTNweg8Nl9RwsrSUhws49F2RhGOj34fJQWtNEk8vDgdJaXll/hClDo5meGYPNbGJsqpMNhyuoamjBJKv2hejSqCQn//zGDEYmRfC/H+TyxNJ9zBgWQ0qkgyPl9czJjgt0iEKcFkmShRikzCblt1WdnvV2dHnehaNP7NaRGuUgNarrc3pLJ+yjun9gO5ePTz6l1zIM44Ryjy9NTmuNQwjRNV8i/Itrx7G9oIpv/3MTLo9BbZOLFQ+cz5AY/3/gC3E2kOIhIcSgJj1ehTh9ESFWnr19Gm6PQXJkCAp4dcORQIclxGmRJFkIIYQQp21YfDgrfnw+H9w7lwtGJfDahnyaXZ5AhyXEKZMkWQghhBB9IipUt6L86ox0jtc28fcVB6ioa2bF3lKMzqt2hQhyUpMshBBCiD41b0Q8V01M4fGP9/LX5Qeob3bzx69MbK33F+JsIEmyEEIIIfqUyaT445cnEhFioaKumYLKBn6xaBdLd5dS09jCM7dPk51GRdCTJFkIIYQQfc5iNvGrL40HYHdRNVc+8QVLdhbR7PLw8po8kiJDCLWZmT8yIcCRCuGfJMlCCCGEOKNGJTlZdO8c4sLt/PC1rfzyg9zWDYKum5zK5eOTSY12MDQm1G9rSiECQf4lCiGEEOKMG5XkBODhq8dy90sbuXHqEGoaW3h25SHe2lIAQGyYjRe/Pr3DpkpCBIokyUIIIYToN8Pjw1n6o/mtt++9MJsdBVUUVTXym492c/Pf13LLjKEUVjWyYl8p9U1ubh1tYT6QU1DFxsPlTB4azfjUSDZ4r9ssUt8s+p4kyUIIIYQImBCrmXMyYgCYkh7NQ+/k8NwXh3DYzFw2Noncwmpe2V0N7+fy/KpDgN4xdFRSBDuPVXPn7AwevnpsIN+CGKAkSRZCCCFEUEiNcvDcnedQ3diCzWwixGpmf0ktl/7xc55fdYjrp6Tx3fOH8/uP9/LF/uNMz4jh5bV5KAVLd5fwhy9PZGp6TIfnXJxTxO+W7Ob3X57ExLRIDEN33xCiO5IkCyGEECKoOEOsrdezEsK5bYwNS3QqP7l8NGaT4smvTsHtMahuaGH+48t5YdVhIuwW7nxhA4/fOJFQm5m3NxcwaWgUv1uyh5pGF7c9uw6nw4rdamLx98+TEg3RLUmShRBCCBHU5g+xMn/+mA7HzCZFdJiN5+6YRkV9C2NSnNz09zV88+VNANgtJt7aUkCYzcyrC2fyvx/swmpWbD5SyX825XPLjKGU1TaxPb+KjLgwFucUYTEp7j5vWCDeoghCkiQLIYQQ4qw1LaOtvOKz++azcl8p5XXNXDUxheV7SokLtzEtI4b375mDYRhc99Rq/rJ0H1uPVvDetmM0tng6PF9qtIPLxyf399sQQUiSZCGEEEIMCDaLiQtHJ7bevmxcUof7lVLcd/EIbntuPR/tKOKqCSlcNTGFvLI6JqRF8dB7O3nwze1syqvAYlaU1TZTWd/CmOQIZg2Po7Tew9qDZYxIjCAmzNbfb0/0M0mShRBCCDFozM2OZ8UD55McFdJua+x4AJ64aRL3v7GNf63Lw+OB2HAb4XYLS3cX88TS/fqhK9YSE2bjztkZlNc1c+vMoWQlRLQ+v2EYeAxdDuL2GJiUTs47a2xxYzapDttzL9tdwq8/2sVl45IZmRhBRIiF80bEn3BudWML+yrczGxxE2I19903p59UNbQQ6bB2/8AAkyRZCCGEEIPK0NhQv8fTY8N441uz8XgMVLvktqKume0FVSxbt5VZU8bz56X7+MMnezGbFB/sKOS/LhvFscoGwu0WXt94lLyyeuZmx7HuUDmRDiu3zBjKprwKnTCj2FNcw+GyOiwmxZhkJ1+dkU5RdSNPfLaP6DAbT3y2rzWmey/IIjrMRovbw5cmp2EYBjc9s5aDpY38ccsn3H/JSL52bkZrrC1uD4ahZ9ULqxqwW8zEhNkwDIMnPtvPlqMV3Dk7g3Oz4tieX8ne4lpuOmdIh0S+sr6ZUJuldXFjs8tDk8tNRMjJE9uSmkaiQ20dEn+fhmY3NouJJz7bx5+X7uOZ26cxf2QCe4trUAqyEyIwe7uOFFY1AJDkDKGyvgWnw9p6H0CTy01VQwsJESHd/qxPhyTJQgghhBDtdG4RFx1mY96I+P9v7+6DpKjvPI6/v8w+sMvCLrCCLCK7CIsBH4CABxcUzWEELicX76IkKc4LpFKm8qDmwZCzKmWlLqloKleRYMUzajRqYh48c9ydSRQUQwwEkUdBlmcUXJ5ZYGFZ2N3v/dG96zDMwKIzvb3L51U1tT2/6Z7+zq+7v/ub7l/PD383n+tHXszkD/XnwLFGDh8/xa3/uYSv/2Z127xV5T2YduUAXt24j48M7cumPfV8//cbGFhWRHFBguYWZ3j/ntx8dQUnm1t4+a293PPcGgAmVV/EvE+P5tCxU9Q3NvHo4q3vncEGvvfCBsygKD/B7SMKeLu5lO/8b/D70T0K8shLGFv21VOYl2Dm+ME8/to2enXP52efHcf/rall3iub6VGQYFHNPgoS3TjZHPTH3lB7hNrDJ9i45yj9enXn9e0HGdynmLtvrGbrvmM8vXQHB46dpGdhHhVlRVSUdeeqS8qYNbGKBxds4rX1DTywejHra48wpLwHN47oz+qddZQVFVDdv4QTTS088dp28hPGsbCxfN//rOOypTtYVLMPgJEVvfjax6qpb2zma79exalmp2dhHkcbmyjKTzBxWDl3T66msryYmY8tY8Xbhxg7uDfb9h/j8ot7Me/Toykrzm4XmHY1ks1sCvAgkAAedffvp7xeCPwc+DBwALjN3beHr30LmA00A19x9z9mLXoRETmDcrZIbiW6Gf16dqdfz+689NVJ7DrUwPCLe1J3/BTlJQXkJZ1JPdXcwq5DDQzuW5y228U9Nw1n5Tt1DCjtzoDSIoC2M7Y/+OTVjL+sLyMrelGYl+Cl9Xs4cuIU064YwIHNK5k0aRxPL93Bsu2HONnUzMmmFsZV9mHlO3XMe2UzV11Sys5DDUx9cDEAt4wZyPc+cSWLavayfPshBvUpZsPuozy5ZAeFed34yNBy3q1r4HMTq3hh7W7ufHYVANcPv4gJQ/pSe/gE79Y1sKuugQcXbuLhV7fQ2NTC0LJu9C7K467Jw5i/6l0e/fM2Rlb0Yt/Ro7y4fjctDtNHVVBckEdFaXdGXVrGzMeW8c7BBr5x03B6Fxfw45c3MeuJ5QB8eHBvbhzRn52HjjO4Tw921TXw3IqdTJu7mF7d86hvbGLGuEGsfLuOa6r6sOCtvdzyk7/w9Oy/yep2Pmcj2cwSwEPAjcBO4HUzm+/u65Nmmw0ccvehZjYDuB+4zcxGADOAkUAFsMDMqt29OaufQkREAOVskaiVlxRSXlIIwMWlZ/YPzk90o7K8R8blzYwxl/ZO+1qim3Hr2EFtz4f2K2mbXrQ5WHbmhEpmTqg8bblTzS38efN+Jgzpy9sHj/PbN3Zyw/B+jB/SBzNjyhUDmHJF8AsezS3edmNi8vvfObmamt1HqCovSXuT4p827uNHCzbyuWuHUHyghuuvnwDAlz86jMamZooLgiZmfWMThxtOMbCs6LTl50y9nEt6F/HxqyqAoAG/ZMsBdhw4xq3jBrUt3+ruydU8t2Inr23ez82jKpg+amDba8u2HWTuwk1Z7+fcnjPJ1wCb3X0rgJk9C0wHkhPudOC+cPq3wDwLvi5NB55190Zgm5ltDt9vSXbCFxGRFMrZIhe4/EQ3bhjeD4Dq/j35t2kfyjhvopud0cgGKCnMO2P0wmTXVV/UdlPhokU1p71fcgO3pDCPksIzm5t3TLrstOfd8xPccHm/jOsrLc5n1sQqZk2sOuO1a6r68NTsa9Keqf8g2jPczEDgnaTnO8OytPO4exNwGOjbzmVFRCR7lLNF5IKT7QYyxOjGPTP7PPD58Gm9mdWcbf40yoH92Y3qfVMs6cUllrjEAYolk7jE8n7iGJyLQOImCzkbOvd2zhXFkl5cYolLHKBYMjnfWDLm7PY0kncBg5KeXxKWpZtnp5nlAaUEN4O0Z1kA3P0R4JF2xJOWmS1397Hvd/lsUizpxSWWuMQBiiWTuMQSlzjOU6fI2RCf+o1LHKBYMolLLHGJAxRLJtmMpT3dLV4HhplZlZkVENzUMT9lnvnA7eH0PwMvu7uH5TPMrNDMqoBhwLJsBC4iImkpZ4uIZME5zyS7e5OZfQn4I8HPCT3u7uvM7DvAcnefDzwGPBXe5HGQICkTzvdrghtGmoAv6i5pEZHcUc4WEcmOdvVJdvcXgBdSyr6dNH0C+GSGZb8LfPcDxNheH+iyX5YplvTiEktc4gDFkklcYolLHOelk+RsiE/9xiUOUCyZxCWWuMQBiiWTrMViwRU2ERERERFp1Z4+ySIiIiIiF5Qu0Ug2sylmVmNmm81sTsTrHmRmr5jZejNbZ2Z3huX3mdkuM1sVPqZFEMt2M1sbrm95WNbHzF4ys03h3/TD+mQ3juFJn3uVmR0xs7uiqhMze9zM9prZm0llaevBAnPDfWeNmY2JIJYfmNmGcH3Pm1lZWF5pZg1J9fNwBLFk3CZm9q2wXmrM7KYcx/GrpBi2m9mqsDzXdZLp+O2Q/eVCoZx9WjwdnreVs88ZywWds88SS+R5O/Kc7e6d+kFwY8oWYAhQAKwGRkS4/gHAmHC6J7ARGEEwmtXXI66L7UB5StkDwJxweg5wfwdsn90Ev0MYSZ0A1wFjgDfPVQ/ANOD3gAHjgb9GEMvHgLxw+v6kWCqT54uoXtJuk3AfXg0UAlXhMZbIVRwpr/8Q+HZEdZLp+O2Q/eVCeChnnxFPrPK2crZydntjSXk9krwddc7uCmeS24ZgdfeTQOsQrJFw91p3XxFOHwXeIl4jVE0HngynnwT+MeL1/x2wxd13RLVCd/8TwR37yTLVw3Tg5x5YCpSZ2YBcxuLuL3owyhnAUoLfos25DPWSSdvwxO6+DWgdnjincZiZAbcCv8zGutoRS6bjt0P2lwuEcva5dWTeVs5Wzj6vWKLM21Hn7K7QSI7NMKpmVgmMBv4aFn0pPL3/eK4vl4UceNHM3rBgNCyA/u5eG07vBvpHEEeyGZx+4ERdJ60y1UNH7z+zCL7ltqoys5Vm9qqZXRtRDOm2SUfVy7XAHnfflFQWSZ2kHL9x3V+6gtjUYQxyNsQvbytnn51y9pk6JG9HkbO7QiM5FsysBHgOuMvdjwA/AS4DRgG1BJcicm2iu48BpgJfNLPrkl/04NpDZD9nYsFABjcDvwmLOqJOzhB1PWRiZvcS/BbtM2FRLXCpu48Gvgr8wsx65TiMWGyTJJ/i9H/QkdRJmuO3TVz2F8mumORsiFHeVs4+O+XsjCLP21Hl7K7QSG73MKq5Ymb5BBvrGXf/LwB33+Puze7eAvyULF72yMTdd4V/9wLPh+vc03ppIfy7N9dxJJkKrHD3PWFckddJkkz10CH7j5n9K/Bx4DPhAU14mexAOP0GQZ+y6lzGcZZtEnm9WDA88i3Ar5Liy3mdpDt+idn+0sV0eB3GJWeH641T3lbOzkA5O72OyNtR5uyu0EhuzxCsORP2xXkMeMvd/yOpPLnPyyeAN1OXzXIcPcysZ+s0wY0Gb3L68LO3A/+dyzhSnPbtMuo6SZGpHuYD/xLeATseOJx0ySYnzGwKcA9ws7sfTyq/yMwS4fQQgiGBt+Y4lkzbpCOGJ54MbHD3nUnx5bROMh2/xGh/6YKUs99bZ9zytnJ2GsrZZxVp3o48Z3uO7sqM8kFw9+JGgm8r90a87okEp/XXAKvCxzTgKWBtWD4fGJDjOIYQ3Nm6GljXWg9AX2AhsAlYAPSJqF56AAeA0qSySOqEIMnXAqcI+h/NzlQPBHe8PhTuO2uBsRHEspmgj1Tr/vJwOO8/hdtuFbAC+IcIYsm4TYB7w3qpAabmMo6w/AngjpR5c10nmY7fDtlfLpSHcnZbLLHJ28rZZ43lgs7ZmWIJyyPN21HnbI24JyIiIiKSoit0txARERERySo1kkVEREREUqiRLCIiIiKSQo1kEREREZEUaiSLiIiIiKRQI1k6FTNrNrNVSY85WXzvSjOL8ndARUS6NOVs6czyOjoAkfPU4O6jOjoIERFpF+Vs6bR0Jlm6BDPbbmYPmNlaM1tmZkPD8koze9nM1pjZQjO7NCzvb2bPm9nq8PG34VslzOynZrbOzF40s6Jw/q+Y2frwfZ7toI8pItIlKGdLZ6BGsnQ2RSmX7m5Leu2wu18JzAN+FJb9GHjS3a8CngHmhuVzgVfd/WpgDMHoQBAMn/mQu48E6ghGDgKYA4wO3+eOXH04EZEuRjlbOi2NuCedipnVu3tJmvLtwEfdfauZ5QO73b2vme0nGLbzVFhe6+7lZrYPuMTdG5PeoxJ4yd2Hhc+/CeS7+7+bys6a+gAAAR1JREFU2R+AeuB3wO/cvT7HH1VEpNNTzpbOTGeSpSvxDNPnozFpupn3+u3/PcH472OA181M/flFRD4Y5WyJNTWSpSu5LenvknD6L8CMcPozwOJweiHwBQAzS5hZaaY3NbNuwCB3fwX4JlAKnHFmREREzotytsSavllJZ1NkZquSnv/B3Vt/Uqi3ma0hOLPwqbDsy8DPzOwbwD7gs2H5ncAjZjab4OzDF4DaDOtMAE+HSdmAue5el7VPJCLSdSlnS6elPsnSJYT928a6+/6OjkVERM5OOVs6A3W3EBERERFJoTPJIiIiIiIpdCZZRERERCSFGskiIiIiIinUSBYRERERSaFGsoiIiIhICjWSRURERERSqJEsIiIiIpLi/wGd3XIcU4NNIgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXfd0FQq4UHz",
        "outputId": "07867d01-b23e-4960-f4b4-2d97a5f80677"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9164000153541565"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv0kNxrQxlFN",
        "outputId": "eeb47724-f441-4ebe-cc92-52ec4333bfdb"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0835999846458435"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBFMbHvLIf5g"
      },
      "source": [
        "#### Model with clipping to 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8s3DicMIfMr",
        "outputId": "c58de7d9-ef61-433f-8f94-eaec54ab900e"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ju7AUyp1rfh",
        "outputId": "01908cff-b5aa-468a-ddcf-c5def0dce235"
      },
      "source": [
        "callbacks = functions.standard_callbacks(model_type) + [functions.Clipping(0.5, \"simple\")]\n",
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'simple_trainHistoryDict_clip_05', steps_per_epoch=100, epochs=1000,\n",
        "                       batch_size=100,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Epoch 1/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 80ms/step - loss: 2.4961 - acc: 0.2745 - val_loss: 2.3687 - val_acc: 0.2634\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.26340, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 2.0267 - acc: 0.2734 - val_loss: 3.5508 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.26340\n",
            "Epoch 3/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.6703 - acc: 0.3801 - val_loss: 4.0442 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.26340\n",
            "Epoch 4/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.4953 - acc: 0.4573 - val_loss: 3.7763 - val_acc: 0.1020\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.26340\n",
            "Epoch 5/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 1.4011 - acc: 0.4952 - val_loss: 1.8179 - val_acc: 0.3784\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.26340 to 0.37840, saving model to /content/saved_models/cifar10_ResNet32v1_model.005.h5\n",
            "Epoch 6/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.3052 - acc: 0.5429 - val_loss: 2.0324 - val_acc: 0.4364\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.37840 to 0.43640, saving model to /content/saved_models/cifar10_ResNet32v1_model.006.h5\n",
            "Epoch 7/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 1.2558 - acc: 0.5547 - val_loss: 3.6933 - val_acc: 0.2808\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.43640\n",
            "Epoch 8/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.1894 - acc: 0.5800 - val_loss: 4.1107 - val_acc: 0.3053\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.43640\n",
            "Epoch 9/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.1473 - acc: 0.6001 - val_loss: 4.9442 - val_acc: 0.2951\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.43640\n",
            "Epoch 10/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 1.1280 - acc: 0.5991 - val_loss: 3.3506 - val_acc: 0.3538\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.43640\n",
            "Epoch 11/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 1.0914 - acc: 0.6218 - val_loss: 4.2881 - val_acc: 0.2564\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.43640\n",
            "Epoch 12/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.0249 - acc: 0.6402 - val_loss: 2.0313 - val_acc: 0.5011\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.43640 to 0.50110, saving model to /content/saved_models/cifar10_ResNet32v1_model.012.h5\n",
            "Epoch 13/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.0595 - acc: 0.6340 - val_loss: 3.0947 - val_acc: 0.4379\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.50110\n",
            "Epoch 14/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.0442 - acc: 0.6330 - val_loss: 2.6556 - val_acc: 0.4220\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.50110\n",
            "Epoch 15/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.0126 - acc: 0.6508 - val_loss: 3.9034 - val_acc: 0.3024\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.50110\n",
            "Epoch 16/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9848 - acc: 0.6557 - val_loss: 2.4264 - val_acc: 0.4552\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.50110\n",
            "Epoch 17/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 1.0260 - acc: 0.6438 - val_loss: 4.8315 - val_acc: 0.2737\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.50110\n",
            "Epoch 18/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9841 - acc: 0.6528 - val_loss: 2.3878 - val_acc: 0.4344\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.50110\n",
            "Epoch 19/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9305 - acc: 0.6768 - val_loss: 4.7044 - val_acc: 0.3144\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.50110\n",
            "Epoch 20/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.9517 - acc: 0.6677 - val_loss: 2.1569 - val_acc: 0.4595\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.50110\n",
            "Epoch 21/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9211 - acc: 0.6837 - val_loss: 1.7206 - val_acc: 0.5643\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.50110 to 0.56430, saving model to /content/saved_models/cifar10_ResNet32v1_model.021.h5\n",
            "Epoch 22/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.9175 - acc: 0.6909 - val_loss: 2.9203 - val_acc: 0.3961\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.56430\n",
            "Epoch 23/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.9362 - acc: 0.6752 - val_loss: 3.9322 - val_acc: 0.3250\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.56430\n",
            "Epoch 24/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.9154 - acc: 0.6836 - val_loss: 2.4561 - val_acc: 0.4656\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.56430\n",
            "Epoch 25/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.9021 - acc: 0.6843 - val_loss: 1.2974 - val_acc: 0.6201\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.56430 to 0.62010, saving model to /content/saved_models/cifar10_ResNet32v1_model.025.h5\n",
            "Epoch 26/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8966 - acc: 0.6969 - val_loss: 3.3461 - val_acc: 0.3886\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.62010\n",
            "Epoch 27/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8932 - acc: 0.6899 - val_loss: 4.7853 - val_acc: 0.3065\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.62010\n",
            "Epoch 28/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8397 - acc: 0.7107 - val_loss: 2.3325 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.62010\n",
            "Epoch 29/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.8786 - acc: 0.7018 - val_loss: 1.4734 - val_acc: 0.5560\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.62010\n",
            "Epoch 30/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.8694 - acc: 0.6908 - val_loss: 1.9378 - val_acc: 0.5679\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.62010\n",
            "Epoch 31/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8614 - acc: 0.7023 - val_loss: 2.4650 - val_acc: 0.4922\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.62010\n",
            "Epoch 32/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8578 - acc: 0.7136 - val_loss: 2.2796 - val_acc: 0.4821\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.62010\n",
            "Epoch 33/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8174 - acc: 0.7155 - val_loss: 2.1179 - val_acc: 0.4913\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.62010\n",
            "Epoch 34/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8661 - acc: 0.6988 - val_loss: 1.9174 - val_acc: 0.5322\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.62010\n",
            "Epoch 35/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8364 - acc: 0.7091 - val_loss: 2.1190 - val_acc: 0.5181\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.62010\n",
            "Epoch 36/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.8305 - acc: 0.7152 - val_loss: 2.5887 - val_acc: 0.4977\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.62010\n",
            "Epoch 37/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.8387 - acc: 0.7138 - val_loss: 5.2942 - val_acc: 0.3438\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.62010\n",
            "Epoch 38/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.8284 - acc: 0.7165 - val_loss: 1.6969 - val_acc: 0.5744\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.62010\n",
            "Epoch 39/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.8161 - acc: 0.7218 - val_loss: 2.7154 - val_acc: 0.4759\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.62010\n",
            "Epoch 40/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.7992 - acc: 0.7326 - val_loss: 2.6493 - val_acc: 0.4489\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.62010\n",
            "Epoch 41/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.7874 - acc: 0.7391 - val_loss: 3.1118 - val_acc: 0.4197\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.62010\n",
            "Epoch 42/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.7658 - acc: 0.7398 - val_loss: 2.3187 - val_acc: 0.4810\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.62010\n",
            "Epoch 43/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8074 - acc: 0.7273 - val_loss: 3.2401 - val_acc: 0.4447\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.62010\n",
            "Epoch 44/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7875 - acc: 0.7301 - val_loss: 1.9602 - val_acc: 0.5172\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.62010\n",
            "Epoch 45/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.7887 - acc: 0.7345 - val_loss: 3.1250 - val_acc: 0.3818\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.62010\n",
            "Epoch 46/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.7728 - acc: 0.7372 - val_loss: 3.4557 - val_acc: 0.3807\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.62010\n",
            "Epoch 47/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7780 - acc: 0.7411 - val_loss: 2.7777 - val_acc: 0.4120\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.62010\n",
            "Epoch 48/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7853 - acc: 0.7330 - val_loss: 2.8838 - val_acc: 0.4745\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.62010\n",
            "Epoch 49/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7502 - acc: 0.7377 - val_loss: 2.5999 - val_acc: 0.4906\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.62010\n",
            "Epoch 50/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7720 - acc: 0.7377 - val_loss: 2.9383 - val_acc: 0.4290\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.62010\n",
            "Epoch 51/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7724 - acc: 0.7384 - val_loss: 2.3470 - val_acc: 0.5034\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.62010\n",
            "Epoch 52/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7605 - acc: 0.7416 - val_loss: 2.0470 - val_acc: 0.4949\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.62010\n",
            "Epoch 53/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.7902 - acc: 0.7321 - val_loss: 3.5146 - val_acc: 0.3746\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.62010\n",
            "Epoch 54/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7530 - acc: 0.7498 - val_loss: 2.3436 - val_acc: 0.5069\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.62010\n",
            "Epoch 55/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7350 - acc: 0.7451 - val_loss: 1.3898 - val_acc: 0.6162\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.62010\n",
            "Epoch 56/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7797 - acc: 0.7425 - val_loss: 4.1654 - val_acc: 0.3071\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.62010\n",
            "Epoch 57/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7844 - acc: 0.7365 - val_loss: 4.0516 - val_acc: 0.3953\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.62010\n",
            "Epoch 58/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7515 - acc: 0.7501 - val_loss: 1.0983 - val_acc: 0.6634\n",
            "\n",
            "Epoch 00058: val_acc improved from 0.62010 to 0.66340, saving model to /content/saved_models/cifar10_ResNet32v1_model.058.h5\n",
            "Epoch 59/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7350 - acc: 0.7496 - val_loss: 5.5268 - val_acc: 0.3554\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.66340\n",
            "Epoch 60/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7341 - acc: 0.7522 - val_loss: 4.3813 - val_acc: 0.4069\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.66340\n",
            "Epoch 61/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7265 - acc: 0.7510 - val_loss: 1.7946 - val_acc: 0.5661\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.66340\n",
            "Epoch 62/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7352 - acc: 0.7509 - val_loss: 2.0315 - val_acc: 0.5437\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.66340\n",
            "Epoch 63/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7598 - acc: 0.7484 - val_loss: 3.8254 - val_acc: 0.3514\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.66340\n",
            "Epoch 64/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7375 - acc: 0.7489 - val_loss: 1.7266 - val_acc: 0.5577\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.66340\n",
            "Epoch 65/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.7357 - acc: 0.7536 - val_loss: 2.7573 - val_acc: 0.4146\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.66340\n",
            "Epoch 66/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7480 - acc: 0.7445 - val_loss: 1.9116 - val_acc: 0.5623\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.66340\n",
            "Epoch 67/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7207 - acc: 0.7584 - val_loss: 6.1730 - val_acc: 0.2538\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.66340\n",
            "Epoch 68/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.7296 - acc: 0.7533 - val_loss: 3.3845 - val_acc: 0.3965\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.66340\n",
            "Epoch 69/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7311 - acc: 0.7528 - val_loss: 1.7301 - val_acc: 0.5771\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.66340\n",
            "Epoch 70/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7277 - acc: 0.7517 - val_loss: 1.9728 - val_acc: 0.5540\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.66340\n",
            "Epoch 71/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7291 - acc: 0.7494 - val_loss: 3.1997 - val_acc: 0.4128\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.66340\n",
            "Epoch 72/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7041 - acc: 0.7644 - val_loss: 2.5316 - val_acc: 0.4585\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.66340\n",
            "Epoch 73/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6877 - acc: 0.7699 - val_loss: 2.5004 - val_acc: 0.4269\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.66340\n",
            "Epoch 74/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7207 - acc: 0.7628 - val_loss: 1.6933 - val_acc: 0.5724\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.66340\n",
            "Epoch 75/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7260 - acc: 0.7570 - val_loss: 1.8037 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.66340\n",
            "Epoch 76/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7424 - acc: 0.7499 - val_loss: 2.4706 - val_acc: 0.5157\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.66340\n",
            "Epoch 77/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7107 - acc: 0.7571 - val_loss: 4.5954 - val_acc: 0.4142\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.66340\n",
            "Epoch 78/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7373 - acc: 0.7564 - val_loss: 2.0356 - val_acc: 0.5575\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.66340\n",
            "Epoch 79/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6824 - acc: 0.7698 - val_loss: 1.6400 - val_acc: 0.6090\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.66340\n",
            "Epoch 80/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7469 - acc: 0.7494 - val_loss: 4.3057 - val_acc: 0.4344\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.66340\n",
            "Epoch 81/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7116 - acc: 0.7624 - val_loss: 2.8942 - val_acc: 0.4213\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.66340\n",
            "Epoch 82/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7060 - acc: 0.7593 - val_loss: 2.0561 - val_acc: 0.5449\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.66340\n",
            "Epoch 83/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7019 - acc: 0.7662 - val_loss: 10.3437 - val_acc: 0.2668\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.66340\n",
            "Epoch 84/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6747 - acc: 0.7702 - val_loss: 5.4969 - val_acc: 0.3671\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.66340\n",
            "Epoch 85/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6900 - acc: 0.7636 - val_loss: 1.8250 - val_acc: 0.6034\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.66340\n",
            "Epoch 86/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7001 - acc: 0.7633 - val_loss: 2.6402 - val_acc: 0.4252\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.66340\n",
            "Epoch 87/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7045 - acc: 0.7577 - val_loss: 2.6103 - val_acc: 0.4811\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.66340\n",
            "Epoch 88/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6850 - acc: 0.7675 - val_loss: 1.4544 - val_acc: 0.6028\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.66340\n",
            "Epoch 89/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7185 - acc: 0.7545 - val_loss: 3.1104 - val_acc: 0.4451\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.66340\n",
            "Epoch 90/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6524 - acc: 0.7839 - val_loss: 1.4566 - val_acc: 0.5993\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.66340\n",
            "Epoch 91/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6876 - acc: 0.7691 - val_loss: 2.7292 - val_acc: 0.4948\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.66340\n",
            "Epoch 92/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6919 - acc: 0.7643 - val_loss: 2.3936 - val_acc: 0.4968\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.66340\n",
            "Epoch 93/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7156 - acc: 0.7553 - val_loss: 1.5716 - val_acc: 0.6295\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.66340\n",
            "Epoch 94/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6711 - acc: 0.7793 - val_loss: 1.6036 - val_acc: 0.5593\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.66340\n",
            "Epoch 95/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6549 - acc: 0.7826 - val_loss: 1.7167 - val_acc: 0.5193\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.66340\n",
            "Epoch 96/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6876 - acc: 0.7709 - val_loss: 1.6980 - val_acc: 0.5813\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.66340\n",
            "Epoch 97/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6702 - acc: 0.7719 - val_loss: 1.9412 - val_acc: 0.5434\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.66340\n",
            "Epoch 98/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6847 - acc: 0.7656 - val_loss: 2.4018 - val_acc: 0.5269\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.66340\n",
            "Epoch 99/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6812 - acc: 0.7701 - val_loss: 2.6139 - val_acc: 0.4216\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.66340\n",
            "Epoch 100/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6760 - acc: 0.7658 - val_loss: 1.7783 - val_acc: 0.5635\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.66340\n",
            "Epoch 101/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6947 - acc: 0.7663 - val_loss: 1.3618 - val_acc: 0.6297\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.66340\n",
            "Epoch 102/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6693 - acc: 0.7735 - val_loss: 4.6574 - val_acc: 0.3744\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.66340\n",
            "Epoch 103/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6976 - acc: 0.7629 - val_loss: 1.2257 - val_acc: 0.6568\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.66340\n",
            "Epoch 104/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6267 - acc: 0.7988 - val_loss: 2.6044 - val_acc: 0.4638\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.66340\n",
            "Epoch 105/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6564 - acc: 0.7760 - val_loss: 1.6351 - val_acc: 0.6113\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.66340\n",
            "Epoch 106/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6730 - acc: 0.7730 - val_loss: 2.3879 - val_acc: 0.4939\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.66340\n",
            "Epoch 107/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6977 - acc: 0.7590 - val_loss: 1.3455 - val_acc: 0.6405\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.66340\n",
            "Epoch 108/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6712 - acc: 0.7821 - val_loss: 2.6905 - val_acc: 0.3703\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.66340\n",
            "Epoch 109/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7090 - acc: 0.7608 - val_loss: 1.6855 - val_acc: 0.6194\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.66340\n",
            "Epoch 110/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6512 - acc: 0.7785 - val_loss: 2.0857 - val_acc: 0.5295\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.66340\n",
            "Epoch 111/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6704 - acc: 0.7758 - val_loss: 2.4000 - val_acc: 0.4602\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.66340\n",
            "Epoch 112/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6846 - acc: 0.7743 - val_loss: 8.3181 - val_acc: 0.2301\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.66340\n",
            "Epoch 113/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6554 - acc: 0.7814 - val_loss: 2.0810 - val_acc: 0.5046\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.66340\n",
            "Epoch 114/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6707 - acc: 0.7749 - val_loss: 2.3973 - val_acc: 0.5226\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.66340\n",
            "Epoch 115/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6701 - acc: 0.7783 - val_loss: 6.5143 - val_acc: 0.3131\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.66340\n",
            "Epoch 116/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7006 - acc: 0.7664 - val_loss: 1.9892 - val_acc: 0.5652\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.66340\n",
            "Epoch 117/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6631 - acc: 0.7757 - val_loss: 1.4318 - val_acc: 0.6420\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.66340\n",
            "Epoch 118/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6576 - acc: 0.7770 - val_loss: 2.3878 - val_acc: 0.5089\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.66340\n",
            "Epoch 119/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6729 - acc: 0.7768 - val_loss: 2.9909 - val_acc: 0.4171\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.66340\n",
            "Epoch 120/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6605 - acc: 0.7715 - val_loss: 1.2225 - val_acc: 0.6462\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.66340\n",
            "Epoch 121/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6516 - acc: 0.7817 - val_loss: 3.1772 - val_acc: 0.4651\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.66340\n",
            "Epoch 122/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6365 - acc: 0.7907 - val_loss: 1.4915 - val_acc: 0.6266\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.66340\n",
            "Epoch 123/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6792 - acc: 0.7679 - val_loss: 4.1000 - val_acc: 0.4084\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.66340\n",
            "Epoch 124/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6401 - acc: 0.7826 - val_loss: 1.3431 - val_acc: 0.6536\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.66340\n",
            "Epoch 125/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6990 - acc: 0.7647 - val_loss: 3.9881 - val_acc: 0.3819\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.66340\n",
            "Epoch 126/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6728 - acc: 0.7784 - val_loss: 2.3656 - val_acc: 0.5148\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.66340\n",
            "Epoch 127/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6553 - acc: 0.7787 - val_loss: 1.3877 - val_acc: 0.6183\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.66340\n",
            "Epoch 128/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6567 - acc: 0.7774 - val_loss: 1.7049 - val_acc: 0.6174\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.66340\n",
            "Epoch 129/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6882 - acc: 0.7773 - val_loss: 2.2733 - val_acc: 0.5099\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.66340\n",
            "Epoch 130/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6412 - acc: 0.7829 - val_loss: 4.4648 - val_acc: 0.3565\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.66340\n",
            "Epoch 131/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6414 - acc: 0.7857 - val_loss: 2.1474 - val_acc: 0.5083\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.66340\n",
            "Epoch 132/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6430 - acc: 0.7848 - val_loss: 1.7463 - val_acc: 0.5747\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.66340\n",
            "Epoch 133/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6649 - acc: 0.7770 - val_loss: 1.1431 - val_acc: 0.6917\n",
            "\n",
            "Epoch 00133: val_acc improved from 0.66340 to 0.69170, saving model to /content/saved_models/cifar10_ResNet32v1_model.133.h5\n",
            "Epoch 134/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6580 - acc: 0.7820 - val_loss: 2.3627 - val_acc: 0.5073\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.69170\n",
            "Epoch 135/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6460 - acc: 0.7826 - val_loss: 2.4779 - val_acc: 0.4771\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.69170\n",
            "Epoch 136/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6598 - acc: 0.7847 - val_loss: 2.3029 - val_acc: 0.5100\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.69170\n",
            "Epoch 137/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6723 - acc: 0.7708 - val_loss: 1.6440 - val_acc: 0.6060\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.69170\n",
            "Epoch 138/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6519 - acc: 0.7798 - val_loss: 2.7246 - val_acc: 0.5317\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.69170\n",
            "Epoch 139/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6475 - acc: 0.7776 - val_loss: 3.1578 - val_acc: 0.4554\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.69170\n",
            "Epoch 140/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6684 - acc: 0.7755 - val_loss: 2.6267 - val_acc: 0.4506\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.69170\n",
            "Epoch 141/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6585 - acc: 0.7747 - val_loss: 3.3063 - val_acc: 0.3966\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.69170\n",
            "Epoch 142/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6586 - acc: 0.7779 - val_loss: 1.1619 - val_acc: 0.6746\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.69170\n",
            "Epoch 143/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6501 - acc: 0.7788 - val_loss: 2.2481 - val_acc: 0.5708\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.69170\n",
            "Epoch 144/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6457 - acc: 0.7870 - val_loss: 2.2965 - val_acc: 0.3690\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.69170\n",
            "Epoch 145/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6307 - acc: 0.7879 - val_loss: 1.5660 - val_acc: 0.6141\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.69170\n",
            "Epoch 146/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6578 - acc: 0.7819 - val_loss: 2.9671 - val_acc: 0.4481\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.69170\n",
            "Epoch 147/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6237 - acc: 0.7938 - val_loss: 1.5742 - val_acc: 0.5697\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.69170\n",
            "Epoch 148/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6608 - acc: 0.7802 - val_loss: 3.3719 - val_acc: 0.4391\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.69170\n",
            "Epoch 149/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6496 - acc: 0.7820 - val_loss: 1.9456 - val_acc: 0.4997\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.69170\n",
            "Epoch 150/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6423 - acc: 0.7886 - val_loss: 1.5872 - val_acc: 0.5693\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.69170\n",
            "Epoch 151/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6243 - acc: 0.7952 - val_loss: 5.5867 - val_acc: 0.3654\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.69170\n",
            "Epoch 152/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6512 - acc: 0.7818 - val_loss: 1.2946 - val_acc: 0.6089\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.69170\n",
            "Epoch 153/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6537 - acc: 0.7864 - val_loss: 4.1899 - val_acc: 0.2853\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.69170\n",
            "Epoch 154/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6399 - acc: 0.7947 - val_loss: 3.7695 - val_acc: 0.4140\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.69170\n",
            "Epoch 155/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6429 - acc: 0.7862 - val_loss: 1.7939 - val_acc: 0.5874\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.69170\n",
            "Epoch 156/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6513 - acc: 0.7850 - val_loss: 2.3602 - val_acc: 0.5066\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.69170\n",
            "Epoch 157/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6607 - acc: 0.7784 - val_loss: 2.0345 - val_acc: 0.5062\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.69170\n",
            "Epoch 158/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6332 - acc: 0.7888 - val_loss: 1.6904 - val_acc: 0.6227\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.69170\n",
            "Epoch 159/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6165 - acc: 0.7952 - val_loss: 2.5651 - val_acc: 0.4154\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.69170\n",
            "Epoch 160/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6395 - acc: 0.7815 - val_loss: 2.0289 - val_acc: 0.5428\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.69170\n",
            "Epoch 161/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6412 - acc: 0.7866 - val_loss: 2.0601 - val_acc: 0.5388\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.69170\n",
            "Epoch 162/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6439 - acc: 0.7908 - val_loss: 2.9921 - val_acc: 0.4384\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.69170\n",
            "Epoch 163/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6364 - acc: 0.7903 - val_loss: 2.8969 - val_acc: 0.4656\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.69170\n",
            "Epoch 164/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6728 - acc: 0.7732 - val_loss: 1.5135 - val_acc: 0.6002\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.69170\n",
            "Epoch 165/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6671 - acc: 0.7774 - val_loss: 2.1561 - val_acc: 0.5476\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.69170\n",
            "Epoch 166/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6578 - acc: 0.7838 - val_loss: 5.2662 - val_acc: 0.2926\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.69170\n",
            "Epoch 167/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6335 - acc: 0.7870 - val_loss: 1.4008 - val_acc: 0.6141\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.69170\n",
            "Epoch 168/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6473 - acc: 0.7834 - val_loss: 1.7361 - val_acc: 0.5695\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.69170\n",
            "Epoch 169/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6141 - acc: 0.7922 - val_loss: 2.3658 - val_acc: 0.5148\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.69170\n",
            "Epoch 170/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6319 - acc: 0.7877 - val_loss: 1.2719 - val_acc: 0.6118\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.69170\n",
            "Epoch 171/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6538 - acc: 0.7794 - val_loss: 2.4754 - val_acc: 0.5353\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.69170\n",
            "Epoch 172/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6274 - acc: 0.7861 - val_loss: 1.6644 - val_acc: 0.5259\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.69170\n",
            "Epoch 173/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6553 - acc: 0.7778 - val_loss: 1.4066 - val_acc: 0.6292\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.69170\n",
            "Epoch 174/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6141 - acc: 0.7933 - val_loss: 3.0938 - val_acc: 0.5025\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.69170\n",
            "Epoch 175/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6335 - acc: 0.7890 - val_loss: 1.8985 - val_acc: 0.5387\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.69170\n",
            "Epoch 176/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6119 - acc: 0.7990 - val_loss: 1.2695 - val_acc: 0.6654\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.69170\n",
            "Epoch 177/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6439 - acc: 0.7885 - val_loss: 3.0810 - val_acc: 0.4167\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.69170\n",
            "Epoch 178/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6377 - acc: 0.7890 - val_loss: 1.7960 - val_acc: 0.5597\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.69170\n",
            "Epoch 179/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6347 - acc: 0.7890 - val_loss: 2.6293 - val_acc: 0.4685\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.69170\n",
            "Epoch 180/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6073 - acc: 0.7974 - val_loss: 4.1391 - val_acc: 0.3201\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.69170\n",
            "Epoch 181/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6257 - acc: 0.7947 - val_loss: 4.9447 - val_acc: 0.3682\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.69170\n",
            "Epoch 182/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6183 - acc: 0.7932 - val_loss: 1.6037 - val_acc: 0.5827\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.69170\n",
            "Epoch 183/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6490 - acc: 0.7840 - val_loss: 1.5900 - val_acc: 0.5673\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.69170\n",
            "Epoch 184/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6272 - acc: 0.7916 - val_loss: 1.4930 - val_acc: 0.6191\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.69170\n",
            "Epoch 185/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5993 - acc: 0.8026 - val_loss: 1.9081 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.69170\n",
            "Epoch 186/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6209 - acc: 0.7949 - val_loss: 2.5313 - val_acc: 0.4212\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.69170\n",
            "Epoch 187/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6215 - acc: 0.7946 - val_loss: 6.2979 - val_acc: 0.2941\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.69170\n",
            "Epoch 188/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6494 - acc: 0.7778 - val_loss: 3.2742 - val_acc: 0.4697\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.69170\n",
            "Epoch 189/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6468 - acc: 0.7881 - val_loss: 1.1341 - val_acc: 0.6736\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.69170\n",
            "Epoch 190/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5929 - acc: 0.8012 - val_loss: 1.4528 - val_acc: 0.6195\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.69170\n",
            "Epoch 191/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6182 - acc: 0.7928 - val_loss: 1.7220 - val_acc: 0.5864\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.69170\n",
            "Epoch 192/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6238 - acc: 0.7916 - val_loss: 1.4044 - val_acc: 0.6153\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.69170\n",
            "Epoch 193/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5995 - acc: 0.7991 - val_loss: 2.2870 - val_acc: 0.4959\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.69170\n",
            "Epoch 194/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6140 - acc: 0.7971 - val_loss: 2.1232 - val_acc: 0.4841\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.69170\n",
            "Epoch 195/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6403 - acc: 0.7821 - val_loss: 2.6390 - val_acc: 0.4173\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.69170\n",
            "Epoch 196/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6023 - acc: 0.7998 - val_loss: 2.7887 - val_acc: 0.4825\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.69170\n",
            "Epoch 197/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6173 - acc: 0.7903 - val_loss: 3.0014 - val_acc: 0.4111\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.69170\n",
            "Epoch 198/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6331 - acc: 0.7895 - val_loss: 0.9907 - val_acc: 0.6918\n",
            "\n",
            "Epoch 00198: val_acc improved from 0.69170 to 0.69180, saving model to /content/saved_models/cifar10_ResNet32v1_model.198.h5\n",
            "Epoch 199/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6270 - acc: 0.7892 - val_loss: 1.5638 - val_acc: 0.5842\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.69180\n",
            "Epoch 200/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6059 - acc: 0.7989 - val_loss: 2.9976 - val_acc: 0.4557\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.69180\n",
            "Epoch 201/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6377 - acc: 0.7959 - val_loss: 2.5037 - val_acc: 0.4776\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.69180\n",
            "Epoch 202/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6275 - acc: 0.7885 - val_loss: 4.7550 - val_acc: 0.3258\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.69180\n",
            "Epoch 203/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6012 - acc: 0.8011 - val_loss: 1.3699 - val_acc: 0.6517\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.69180\n",
            "Epoch 204/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6005 - acc: 0.8010 - val_loss: 2.4978 - val_acc: 0.4068\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.69180\n",
            "Epoch 205/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5955 - acc: 0.8056 - val_loss: 5.1404 - val_acc: 0.3082\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.69180\n",
            "Epoch 206/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6117 - acc: 0.7948 - val_loss: 1.8549 - val_acc: 0.5799\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.69180\n",
            "Epoch 207/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6013 - acc: 0.8016 - val_loss: 1.7712 - val_acc: 0.5473\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.69180\n",
            "Epoch 208/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6265 - acc: 0.7894 - val_loss: 3.1182 - val_acc: 0.3801\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.69180\n",
            "Epoch 209/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6274 - acc: 0.7925 - val_loss: 1.2982 - val_acc: 0.6286\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.69180\n",
            "Epoch 210/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6198 - acc: 0.7948 - val_loss: 2.1144 - val_acc: 0.5363\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.69180\n",
            "Epoch 211/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5937 - acc: 0.8003 - val_loss: 2.6071 - val_acc: 0.4458\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.69180\n",
            "Epoch 212/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6218 - acc: 0.7990 - val_loss: 2.9722 - val_acc: 0.4295\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.69180\n",
            "Epoch 213/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6046 - acc: 0.7925 - val_loss: 7.6109 - val_acc: 0.2049\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.69180\n",
            "Epoch 214/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5975 - acc: 0.8020 - val_loss: 1.8052 - val_acc: 0.5266\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.69180\n",
            "Epoch 215/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6243 - acc: 0.7939 - val_loss: 1.9337 - val_acc: 0.5853\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.69180\n",
            "Epoch 216/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6309 - acc: 0.7861 - val_loss: 1.9327 - val_acc: 0.5561\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.69180\n",
            "Epoch 217/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6106 - acc: 0.7958 - val_loss: 1.7930 - val_acc: 0.5421\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.69180\n",
            "Epoch 218/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6156 - acc: 0.7954 - val_loss: 2.2368 - val_acc: 0.4413\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.69180\n",
            "Epoch 219/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5847 - acc: 0.8054 - val_loss: 1.7478 - val_acc: 0.5871\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.69180\n",
            "Epoch 220/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6301 - acc: 0.7918 - val_loss: 1.5144 - val_acc: 0.5806\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.69180\n",
            "Epoch 221/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6291 - acc: 0.7883 - val_loss: 2.6389 - val_acc: 0.4226\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.69180\n",
            "Epoch 222/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5910 - acc: 0.8043 - val_loss: 1.3919 - val_acc: 0.6376\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.69180\n",
            "Epoch 223/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6114 - acc: 0.7949 - val_loss: 2.9768 - val_acc: 0.4033\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.69180\n",
            "Epoch 224/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5739 - acc: 0.8102 - val_loss: 1.4338 - val_acc: 0.6063\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.69180\n",
            "Epoch 225/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6223 - acc: 0.7921 - val_loss: 1.3874 - val_acc: 0.6007\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.69180\n",
            "Epoch 226/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6149 - acc: 0.7925 - val_loss: 2.5943 - val_acc: 0.4615\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.69180\n",
            "Epoch 227/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6280 - acc: 0.7929 - val_loss: 1.1415 - val_acc: 0.6617\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.69180\n",
            "Epoch 228/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6229 - acc: 0.7945 - val_loss: 1.4958 - val_acc: 0.5621\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.69180\n",
            "Epoch 229/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5877 - acc: 0.7991 - val_loss: 1.3681 - val_acc: 0.6438\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.69180\n",
            "Epoch 230/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6097 - acc: 0.7938 - val_loss: 3.8865 - val_acc: 0.3117\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.69180\n",
            "Epoch 231/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6243 - acc: 0.7906 - val_loss: 1.0872 - val_acc: 0.7102\n",
            "\n",
            "Epoch 00231: val_acc improved from 0.69180 to 0.71020, saving model to /content/saved_models/cifar10_ResNet32v1_model.231.h5\n",
            "Epoch 232/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5901 - acc: 0.8062 - val_loss: 2.5271 - val_acc: 0.5217\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.71020\n",
            "Epoch 233/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5682 - acc: 0.8098 - val_loss: 2.0462 - val_acc: 0.5206\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.71020\n",
            "Epoch 234/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6475 - acc: 0.7824 - val_loss: 1.6540 - val_acc: 0.5950\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.71020\n",
            "Epoch 235/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6176 - acc: 0.7956 - val_loss: 1.9222 - val_acc: 0.5535\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.71020\n",
            "Epoch 236/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6213 - acc: 0.7930 - val_loss: 1.9829 - val_acc: 0.5246\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.71020\n",
            "Epoch 237/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6072 - acc: 0.7991 - val_loss: 2.3507 - val_acc: 0.4579\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.71020\n",
            "Epoch 238/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6146 - acc: 0.7964 - val_loss: 1.9330 - val_acc: 0.5414\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.71020\n",
            "Epoch 239/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6272 - acc: 0.7945 - val_loss: 1.7059 - val_acc: 0.6011\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.71020\n",
            "Epoch 240/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5913 - acc: 0.8026 - val_loss: 2.5509 - val_acc: 0.5207\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.71020\n",
            "Epoch 241/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6149 - acc: 0.7964 - val_loss: 1.3931 - val_acc: 0.5961\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.71020\n",
            "Epoch 242/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6464 - acc: 0.7821 - val_loss: 1.5056 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.71020\n",
            "Epoch 243/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6296 - acc: 0.7999 - val_loss: 1.6235 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.71020\n",
            "Epoch 244/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6106 - acc: 0.8014 - val_loss: 1.7001 - val_acc: 0.5367\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.71020\n",
            "Epoch 245/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5904 - acc: 0.8035 - val_loss: 1.3767 - val_acc: 0.6060\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.71020\n",
            "Epoch 246/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5925 - acc: 0.8027 - val_loss: 1.7549 - val_acc: 0.5371\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.71020\n",
            "Epoch 247/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6088 - acc: 0.7934 - val_loss: 1.3621 - val_acc: 0.5975\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.71020\n",
            "Epoch 248/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6175 - acc: 0.7911 - val_loss: 1.5804 - val_acc: 0.5824\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.71020\n",
            "Epoch 249/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5971 - acc: 0.7992 - val_loss: 2.9954 - val_acc: 0.4453\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.71020\n",
            "Epoch 250/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6109 - acc: 0.7917 - val_loss: 2.9152 - val_acc: 0.4067\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.71020\n",
            "Epoch 251/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6053 - acc: 0.8017 - val_loss: 2.2472 - val_acc: 0.5096\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.71020\n",
            "Epoch 252/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5872 - acc: 0.8062 - val_loss: 0.8816 - val_acc: 0.7278\n",
            "\n",
            "Epoch 00252: val_acc improved from 0.71020 to 0.72780, saving model to /content/saved_models/cifar10_ResNet32v1_model.252.h5\n",
            "Epoch 253/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5951 - acc: 0.8010 - val_loss: 1.4704 - val_acc: 0.6347\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.72780\n",
            "Epoch 254/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5964 - acc: 0.8053 - val_loss: 2.4353 - val_acc: 0.4869\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.72780\n",
            "Epoch 255/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6118 - acc: 0.7892 - val_loss: 1.3419 - val_acc: 0.6462\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.72780\n",
            "Epoch 256/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6001 - acc: 0.7996 - val_loss: 0.9697 - val_acc: 0.7157\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.72780\n",
            "Epoch 257/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6015 - acc: 0.7937 - val_loss: 1.3868 - val_acc: 0.6178\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.72780\n",
            "Epoch 258/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6049 - acc: 0.8006 - val_loss: 1.1362 - val_acc: 0.6472\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.72780\n",
            "Epoch 259/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6379 - acc: 0.7879 - val_loss: 1.3539 - val_acc: 0.5961\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.72780\n",
            "Epoch 260/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6047 - acc: 0.8015 - val_loss: 3.8199 - val_acc: 0.3318\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.72780\n",
            "Epoch 261/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5903 - acc: 0.8074 - val_loss: 1.4824 - val_acc: 0.6075\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.72780\n",
            "Epoch 262/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6011 - acc: 0.8001 - val_loss: 2.9282 - val_acc: 0.4127\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.72780\n",
            "Epoch 263/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6034 - acc: 0.7949 - val_loss: 2.1544 - val_acc: 0.5097\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.72780\n",
            "Epoch 264/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6023 - acc: 0.7981 - val_loss: 3.1177 - val_acc: 0.4653\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.72780\n",
            "Epoch 265/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5871 - acc: 0.8044 - val_loss: 1.3019 - val_acc: 0.6139\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.72780\n",
            "Epoch 266/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6083 - acc: 0.7987 - val_loss: 3.5199 - val_acc: 0.4483\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.72780\n",
            "Epoch 267/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5911 - acc: 0.8004 - val_loss: 1.8136 - val_acc: 0.5414\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.72780\n",
            "Epoch 268/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6066 - acc: 0.7992 - val_loss: 1.4310 - val_acc: 0.6277\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.72780\n",
            "Epoch 269/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6069 - acc: 0.7963 - val_loss: 1.5166 - val_acc: 0.5606\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.72780\n",
            "Epoch 270/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5617 - acc: 0.8149 - val_loss: 2.5040 - val_acc: 0.4400\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.72780\n",
            "Epoch 271/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5831 - acc: 0.8091 - val_loss: 1.2345 - val_acc: 0.6453\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.72780\n",
            "Epoch 272/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6349 - acc: 0.7914 - val_loss: 2.2920 - val_acc: 0.5211\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.72780\n",
            "Epoch 273/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6023 - acc: 0.8037 - val_loss: 1.4362 - val_acc: 0.5896\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.72780\n",
            "Epoch 274/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5834 - acc: 0.8099 - val_loss: 1.4102 - val_acc: 0.5840\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.72780\n",
            "Epoch 275/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6058 - acc: 0.8011 - val_loss: 1.9957 - val_acc: 0.5447\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.72780\n",
            "Epoch 276/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5953 - acc: 0.8009 - val_loss: 4.9922 - val_acc: 0.3036\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.72780\n",
            "Epoch 277/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5832 - acc: 0.8015 - val_loss: 1.2450 - val_acc: 0.6281\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.72780\n",
            "Epoch 278/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5965 - acc: 0.8019 - val_loss: 1.5689 - val_acc: 0.5923\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.72780\n",
            "Epoch 279/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6012 - acc: 0.8048 - val_loss: 1.9127 - val_acc: 0.5453\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.72780\n",
            "Epoch 280/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5768 - acc: 0.8087 - val_loss: 1.9382 - val_acc: 0.5508\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.72780\n",
            "Epoch 281/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5813 - acc: 0.8108 - val_loss: 2.0631 - val_acc: 0.5384\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.72780\n",
            "Epoch 282/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6100 - acc: 0.7906 - val_loss: 2.1296 - val_acc: 0.4725\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.72780\n",
            "Epoch 283/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6107 - acc: 0.7938 - val_loss: 1.9705 - val_acc: 0.5461\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.72780\n",
            "Epoch 284/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5953 - acc: 0.8040 - val_loss: 1.1999 - val_acc: 0.6411\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.72780\n",
            "Epoch 285/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6025 - acc: 0.8034 - val_loss: 3.1651 - val_acc: 0.4301\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.72780\n",
            "Epoch 286/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5942 - acc: 0.8043 - val_loss: 1.8694 - val_acc: 0.5248\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.72780\n",
            "Epoch 287/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5874 - acc: 0.8023 - val_loss: 1.0919 - val_acc: 0.6722\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.72780\n",
            "Epoch 288/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5869 - acc: 0.8036 - val_loss: 2.1337 - val_acc: 0.4886\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.72780\n",
            "Epoch 289/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5767 - acc: 0.8053 - val_loss: 1.7048 - val_acc: 0.5736\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.72780\n",
            "Epoch 290/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5943 - acc: 0.7972 - val_loss: 0.9614 - val_acc: 0.7099\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.72780\n",
            "Epoch 291/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5855 - acc: 0.8063 - val_loss: 4.2043 - val_acc: 0.3645\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.72780\n",
            "Epoch 292/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6119 - acc: 0.7972 - val_loss: 1.5635 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.72780\n",
            "Epoch 293/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5870 - acc: 0.8026 - val_loss: 1.4180 - val_acc: 0.6314\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.72780\n",
            "Epoch 294/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5954 - acc: 0.8008 - val_loss: 2.1236 - val_acc: 0.5136\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.72780\n",
            "Epoch 295/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5911 - acc: 0.8058 - val_loss: 1.2742 - val_acc: 0.6164\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.72780\n",
            "Epoch 296/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5924 - acc: 0.8014 - val_loss: 2.7390 - val_acc: 0.4188\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.72780\n",
            "Epoch 297/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5887 - acc: 0.8065 - val_loss: 1.1740 - val_acc: 0.6423\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.72780\n",
            "Epoch 298/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5689 - acc: 0.8044 - val_loss: 1.3817 - val_acc: 0.6216\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.72780\n",
            "Epoch 299/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5787 - acc: 0.8059 - val_loss: 1.8981 - val_acc: 0.5466\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.72780\n",
            "Epoch 300/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6141 - acc: 0.7954 - val_loss: 2.2859 - val_acc: 0.5039\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.72780\n",
            "Epoch 301/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5633 - acc: 0.8118 - val_loss: 1.7002 - val_acc: 0.5585\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.72780\n",
            "Epoch 302/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5808 - acc: 0.8055 - val_loss: 2.3638 - val_acc: 0.5349\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.72780\n",
            "Epoch 303/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6063 - acc: 0.8010 - val_loss: 1.4752 - val_acc: 0.6044\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.72780\n",
            "Epoch 304/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5733 - acc: 0.8080 - val_loss: 1.3228 - val_acc: 0.6113\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.72780\n",
            "Epoch 305/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5912 - acc: 0.8022 - val_loss: 2.4445 - val_acc: 0.5038\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.72780\n",
            "Epoch 306/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5856 - acc: 0.8091 - val_loss: 2.3870 - val_acc: 0.4796\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.72780\n",
            "Epoch 307/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5719 - acc: 0.8078 - val_loss: 3.7578 - val_acc: 0.4270\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.72780\n",
            "Epoch 308/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6114 - acc: 0.7942 - val_loss: 1.8929 - val_acc: 0.5441\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.72780\n",
            "Epoch 309/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5880 - acc: 0.8043 - val_loss: 1.7630 - val_acc: 0.5440\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.72780\n",
            "Epoch 310/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5944 - acc: 0.8043 - val_loss: 1.5889 - val_acc: 0.5767\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.72780\n",
            "Epoch 311/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5692 - acc: 0.8058 - val_loss: 1.5342 - val_acc: 0.6191\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.72780\n",
            "Epoch 312/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5936 - acc: 0.8073 - val_loss: 1.7177 - val_acc: 0.5569\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.72780\n",
            "Epoch 313/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5720 - acc: 0.8098 - val_loss: 1.2869 - val_acc: 0.6061\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.72780\n",
            "Epoch 314/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5959 - acc: 0.8003 - val_loss: 1.9485 - val_acc: 0.5829\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.72780\n",
            "Epoch 315/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5826 - acc: 0.8102 - val_loss: 3.5614 - val_acc: 0.3873\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.72780\n",
            "Epoch 316/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6051 - acc: 0.7940 - val_loss: 1.5267 - val_acc: 0.5092\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.72780\n",
            "Epoch 317/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6001 - acc: 0.8013 - val_loss: 1.9882 - val_acc: 0.5319\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.72780\n",
            "Epoch 318/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5895 - acc: 0.8068 - val_loss: 1.3238 - val_acc: 0.6555\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.72780\n",
            "Epoch 319/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5650 - acc: 0.8122 - val_loss: 2.1049 - val_acc: 0.4287\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.72780\n",
            "Epoch 320/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5615 - acc: 0.8112 - val_loss: 1.9728 - val_acc: 0.5050\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.72780\n",
            "Epoch 321/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5936 - acc: 0.7994 - val_loss: 2.4259 - val_acc: 0.4611\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.72780\n",
            "Epoch 322/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6028 - acc: 0.8038 - val_loss: 5.6012 - val_acc: 0.2765\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.72780\n",
            "Epoch 323/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6124 - acc: 0.7950 - val_loss: 1.3729 - val_acc: 0.5974\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.72780\n",
            "Epoch 324/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5986 - acc: 0.8040 - val_loss: 1.2291 - val_acc: 0.6525\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.72780\n",
            "Epoch 325/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5722 - acc: 0.8086 - val_loss: 1.9663 - val_acc: 0.5254\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.72780\n",
            "Epoch 326/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5750 - acc: 0.8140 - val_loss: 1.8282 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.72780\n",
            "Epoch 327/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5859 - acc: 0.8082 - val_loss: 1.9824 - val_acc: 0.5192\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.72780\n",
            "Epoch 328/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5878 - acc: 0.7995 - val_loss: 0.9289 - val_acc: 0.7149\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.72780\n",
            "Epoch 329/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5812 - acc: 0.8034 - val_loss: 4.1726 - val_acc: 0.3703\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.72780\n",
            "Epoch 330/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5703 - acc: 0.8088 - val_loss: 1.6336 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.72780\n",
            "Epoch 331/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5899 - acc: 0.8058 - val_loss: 1.5631 - val_acc: 0.5531\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.72780\n",
            "Epoch 332/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5540 - acc: 0.8214 - val_loss: 2.0044 - val_acc: 0.5300\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.72780\n",
            "Epoch 333/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5771 - acc: 0.8061 - val_loss: 4.1627 - val_acc: 0.3348\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.72780\n",
            "Epoch 334/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5905 - acc: 0.8082 - val_loss: 1.7538 - val_acc: 0.5641\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.72780\n",
            "Epoch 335/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5773 - acc: 0.8053 - val_loss: 1.4825 - val_acc: 0.5753\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.72780\n",
            "Epoch 336/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5781 - acc: 0.8071 - val_loss: 1.3363 - val_acc: 0.6479\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.72780\n",
            "Epoch 337/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5890 - acc: 0.8024 - val_loss: 2.0779 - val_acc: 0.5182\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.72780\n",
            "Epoch 338/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5877 - acc: 0.7981 - val_loss: 1.7753 - val_acc: 0.5536\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.72780\n",
            "Epoch 339/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5772 - acc: 0.8095 - val_loss: 0.9296 - val_acc: 0.7014\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.72780\n",
            "Epoch 340/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5832 - acc: 0.8043 - val_loss: 1.3184 - val_acc: 0.6108\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.72780\n",
            "Epoch 341/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5881 - acc: 0.8074 - val_loss: 1.4240 - val_acc: 0.5974\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.72780\n",
            "Epoch 342/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5764 - acc: 0.8047 - val_loss: 1.1765 - val_acc: 0.6634\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.72780\n",
            "Epoch 343/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5943 - acc: 0.8061 - val_loss: 2.9630 - val_acc: 0.4227\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.72780\n",
            "Epoch 344/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5791 - acc: 0.8122 - val_loss: 3.2062 - val_acc: 0.4172\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.72780\n",
            "Epoch 345/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5796 - acc: 0.8106 - val_loss: 3.7268 - val_acc: 0.4420\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.72780\n",
            "Epoch 346/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5759 - acc: 0.8070 - val_loss: 2.7452 - val_acc: 0.4944\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.72780\n",
            "Epoch 347/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6029 - acc: 0.8016 - val_loss: 1.4150 - val_acc: 0.5922\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.72780\n",
            "Epoch 348/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6145 - acc: 0.7974 - val_loss: 3.6222 - val_acc: 0.3705\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.72780\n",
            "Epoch 349/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5876 - acc: 0.8022 - val_loss: 4.2642 - val_acc: 0.4307\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.72780\n",
            "Epoch 350/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5971 - acc: 0.8037 - val_loss: 1.4335 - val_acc: 0.6173\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.72780\n",
            "Epoch 351/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5782 - acc: 0.8101 - val_loss: 1.3298 - val_acc: 0.6478\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.72780\n",
            "Epoch 352/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5978 - acc: 0.8098 - val_loss: 1.0485 - val_acc: 0.7010\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.72780\n",
            "Epoch 353/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5834 - acc: 0.8093 - val_loss: 1.6674 - val_acc: 0.5848\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.72780\n",
            "Epoch 354/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5921 - acc: 0.7993 - val_loss: 1.2266 - val_acc: 0.6431\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.72780\n",
            "Epoch 355/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6044 - acc: 0.7962 - val_loss: 6.9729 - val_acc: 0.3361\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.72780\n",
            "Epoch 356/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6043 - acc: 0.8031 - val_loss: 2.8183 - val_acc: 0.4400\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.72780\n",
            "Epoch 357/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5922 - acc: 0.8056 - val_loss: 5.7500 - val_acc: 0.3289\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.72780\n",
            "Epoch 358/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5835 - acc: 0.8085 - val_loss: 1.3585 - val_acc: 0.5976\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.72780\n",
            "Epoch 359/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5386 - acc: 0.8216 - val_loss: 4.3435 - val_acc: 0.3499\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.72780\n",
            "Epoch 360/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5714 - acc: 0.8054 - val_loss: 3.9870 - val_acc: 0.3782\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.72780\n",
            "Epoch 361/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5781 - acc: 0.8104 - val_loss: 1.1735 - val_acc: 0.6839\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.72780\n",
            "Epoch 362/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5826 - acc: 0.8059 - val_loss: 2.0534 - val_acc: 0.5482\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.72780\n",
            "Epoch 363/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5971 - acc: 0.8049 - val_loss: 1.9416 - val_acc: 0.5797\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.72780\n",
            "Epoch 364/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5854 - acc: 0.8033 - val_loss: 1.3020 - val_acc: 0.6477\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.72780\n",
            "Epoch 365/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5917 - acc: 0.8045 - val_loss: 2.4504 - val_acc: 0.5078\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.72780\n",
            "Epoch 366/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5989 - acc: 0.7978 - val_loss: 1.1581 - val_acc: 0.6465\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.72780\n",
            "Epoch 367/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5943 - acc: 0.8027 - val_loss: 2.0930 - val_acc: 0.5060\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.72780\n",
            "Epoch 368/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5702 - acc: 0.8069 - val_loss: 1.6041 - val_acc: 0.5054\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.72780\n",
            "Epoch 369/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5771 - acc: 0.8059 - val_loss: 1.2024 - val_acc: 0.6228\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.72780\n",
            "Epoch 370/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5899 - acc: 0.8027 - val_loss: 1.6400 - val_acc: 0.5395\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.72780\n",
            "Epoch 371/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5650 - acc: 0.8105 - val_loss: 0.8564 - val_acc: 0.7240\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.72780\n",
            "Epoch 372/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6026 - acc: 0.7959 - val_loss: 2.0871 - val_acc: 0.5480\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.72780\n",
            "Epoch 373/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5747 - acc: 0.8069 - val_loss: 1.2657 - val_acc: 0.6467\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.72780\n",
            "Epoch 374/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5823 - acc: 0.8064 - val_loss: 2.3315 - val_acc: 0.4802\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.72780\n",
            "Epoch 375/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6042 - acc: 0.7956 - val_loss: 2.2245 - val_acc: 0.5212\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.72780\n",
            "Epoch 376/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5856 - acc: 0.8095 - val_loss: 2.0866 - val_acc: 0.4717\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.72780\n",
            "Epoch 377/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5874 - acc: 0.8020 - val_loss: 1.9544 - val_acc: 0.5408\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.72780\n",
            "Epoch 378/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5905 - acc: 0.8095 - val_loss: 1.7435 - val_acc: 0.5292\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.72780\n",
            "Epoch 379/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5723 - acc: 0.8144 - val_loss: 4.5223 - val_acc: 0.3098\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.72780\n",
            "Epoch 380/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5625 - acc: 0.8088 - val_loss: 3.1188 - val_acc: 0.4243\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.72780\n",
            "Epoch 381/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5793 - acc: 0.8041 - val_loss: 3.7055 - val_acc: 0.4129\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.72780\n",
            "Epoch 382/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5849 - acc: 0.8053 - val_loss: 3.8679 - val_acc: 0.3452\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.72780\n",
            "Epoch 383/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5902 - acc: 0.8061 - val_loss: 2.5600 - val_acc: 0.4807\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.72780\n",
            "Epoch 384/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5640 - acc: 0.8157 - val_loss: 2.2177 - val_acc: 0.4888\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.72780\n",
            "Epoch 385/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5765 - acc: 0.8090 - val_loss: 1.1294 - val_acc: 0.6526\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.72780\n",
            "Epoch 386/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5586 - acc: 0.8174 - val_loss: 1.7658 - val_acc: 0.5340\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.72780\n",
            "Epoch 387/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6047 - acc: 0.8019 - val_loss: 1.2524 - val_acc: 0.6576\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.72780\n",
            "Epoch 388/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5926 - acc: 0.8045 - val_loss: 2.4131 - val_acc: 0.4949\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.72780\n",
            "Epoch 389/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5780 - acc: 0.8072 - val_loss: 7.1386 - val_acc: 0.2403\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.72780\n",
            "Epoch 390/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5844 - acc: 0.8086 - val_loss: 1.0555 - val_acc: 0.6784\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.72780\n",
            "Epoch 391/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5971 - acc: 0.8049 - val_loss: 1.6941 - val_acc: 0.5489\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.72780\n",
            "Epoch 392/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5973 - acc: 0.7996 - val_loss: 1.7943 - val_acc: 0.5326\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.72780\n",
            "Epoch 393/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5677 - acc: 0.8088 - val_loss: 2.5399 - val_acc: 0.4899\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.72780\n",
            "Epoch 394/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5812 - acc: 0.8081 - val_loss: 1.7366 - val_acc: 0.5767\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.72780\n",
            "Epoch 395/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5869 - acc: 0.8048 - val_loss: 1.7830 - val_acc: 0.5379\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.72780\n",
            "Epoch 396/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6046 - acc: 0.8060 - val_loss: 1.6148 - val_acc: 0.5737\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.72780\n",
            "Epoch 397/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5613 - acc: 0.8182 - val_loss: 1.7874 - val_acc: 0.5692\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.72780\n",
            "Epoch 398/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5937 - acc: 0.8028 - val_loss: 1.6979 - val_acc: 0.5597\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.72780\n",
            "Epoch 399/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5906 - acc: 0.8029 - val_loss: 2.3462 - val_acc: 0.4702\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.72780\n",
            "Epoch 400/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6078 - acc: 0.7960 - val_loss: 1.7247 - val_acc: 0.5436\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.72780\n",
            "Epoch 401/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5876 - acc: 0.8006 - val_loss: 3.8131 - val_acc: 0.4011\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.72780\n",
            "Epoch 402/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5054 - acc: 0.8388 - val_loss: 0.5592 - val_acc: 0.8161\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.72780 to 0.81610, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4066 - acc: 0.8691 - val_loss: 0.4887 - val_acc: 0.8373\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.81610 to 0.83730, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3742 - acc: 0.8864 - val_loss: 0.4482 - val_acc: 0.8504\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.83730 to 0.85040, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3427 - acc: 0.8939 - val_loss: 0.4037 - val_acc: 0.8678\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.85040 to 0.86780, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3441 - acc: 0.8875 - val_loss: 0.3950 - val_acc: 0.8708\n",
            "\n",
            "Epoch 00406: val_acc improved from 0.86780 to 0.87080, saving model to /content/saved_models/cifar10_ResNet32v1_model.406.h5\n",
            "Epoch 407/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3343 - acc: 0.8904 - val_loss: 0.4339 - val_acc: 0.8569\n",
            "\n",
            "Epoch 00407: val_acc did not improve from 0.87080\n",
            "Epoch 408/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3421 - acc: 0.8869 - val_loss: 0.4342 - val_acc: 0.8602\n",
            "\n",
            "Epoch 00408: val_acc did not improve from 0.87080\n",
            "Epoch 409/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3319 - acc: 0.8922 - val_loss: 0.4007 - val_acc: 0.8694\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.87080\n",
            "Epoch 410/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3169 - acc: 0.8960 - val_loss: 0.3786 - val_acc: 0.8764\n",
            "\n",
            "Epoch 00410: val_acc improved from 0.87080 to 0.87640, saving model to /content/saved_models/cifar10_ResNet32v1_model.410.h5\n",
            "Epoch 411/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3126 - acc: 0.9011 - val_loss: 0.4027 - val_acc: 0.8674\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.87640\n",
            "Epoch 412/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3054 - acc: 0.8996 - val_loss: 0.4097 - val_acc: 0.8686\n",
            "\n",
            "Epoch 00412: val_acc did not improve from 0.87640\n",
            "Epoch 413/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3045 - acc: 0.9020 - val_loss: 0.4241 - val_acc: 0.8598\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.87640\n",
            "Epoch 414/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2790 - acc: 0.9101 - val_loss: 0.3678 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00414: val_acc improved from 0.87640 to 0.87780, saving model to /content/saved_models/cifar10_ResNet32v1_model.414.h5\n",
            "Epoch 415/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2871 - acc: 0.9075 - val_loss: 0.3734 - val_acc: 0.8820\n",
            "\n",
            "Epoch 00415: val_acc improved from 0.87780 to 0.88200, saving model to /content/saved_models/cifar10_ResNet32v1_model.415.h5\n",
            "Epoch 416/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2997 - acc: 0.9047 - val_loss: 0.4263 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.88200\n",
            "Epoch 417/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2841 - acc: 0.9057 - val_loss: 0.3763 - val_acc: 0.8753\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.88200\n",
            "Epoch 418/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2762 - acc: 0.9112 - val_loss: 0.4179 - val_acc: 0.8671\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.88200\n",
            "Epoch 419/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2653 - acc: 0.9143 - val_loss: 0.3671 - val_acc: 0.8819\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.88200\n",
            "Epoch 420/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2886 - acc: 0.9049 - val_loss: 0.3931 - val_acc: 0.8710\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.88200\n",
            "Epoch 421/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2766 - acc: 0.9077 - val_loss: 0.4148 - val_acc: 0.8693\n",
            "\n",
            "Epoch 00421: val_acc did not improve from 0.88200\n",
            "Epoch 422/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2609 - acc: 0.9147 - val_loss: 0.3692 - val_acc: 0.8852\n",
            "\n",
            "Epoch 00422: val_acc improved from 0.88200 to 0.88520, saving model to /content/saved_models/cifar10_ResNet32v1_model.422.h5\n",
            "Epoch 423/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2553 - acc: 0.9173 - val_loss: 0.3680 - val_acc: 0.8824\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.88520\n",
            "Epoch 424/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2687 - acc: 0.9131 - val_loss: 0.3712 - val_acc: 0.8827\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.88520\n",
            "Epoch 425/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2689 - acc: 0.9154 - val_loss: 0.3686 - val_acc: 0.8781\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.88520\n",
            "Epoch 426/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2548 - acc: 0.9197 - val_loss: 0.3619 - val_acc: 0.8858\n",
            "\n",
            "Epoch 00426: val_acc improved from 0.88520 to 0.88580, saving model to /content/saved_models/cifar10_ResNet32v1_model.426.h5\n",
            "Epoch 427/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2596 - acc: 0.9205 - val_loss: 0.3679 - val_acc: 0.8820\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.88580\n",
            "Epoch 428/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2687 - acc: 0.9091 - val_loss: 0.4027 - val_acc: 0.8737\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.88580\n",
            "Epoch 429/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2573 - acc: 0.9193 - val_loss: 0.3977 - val_acc: 0.8714\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.88580\n",
            "Epoch 430/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2465 - acc: 0.9204 - val_loss: 0.3648 - val_acc: 0.8766\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.88580\n",
            "Epoch 431/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2528 - acc: 0.9146 - val_loss: 0.4329 - val_acc: 0.8646\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.88580\n",
            "Epoch 432/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2454 - acc: 0.9241 - val_loss: 0.3735 - val_acc: 0.8781\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.88580\n",
            "Epoch 433/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2505 - acc: 0.9200 - val_loss: 0.3690 - val_acc: 0.8822\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.88580\n",
            "Epoch 434/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2239 - acc: 0.9283 - val_loss: 0.3248 - val_acc: 0.8935\n",
            "\n",
            "Epoch 00434: val_acc improved from 0.88580 to 0.89350, saving model to /content/saved_models/cifar10_ResNet32v1_model.434.h5\n",
            "Epoch 435/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2326 - acc: 0.9258 - val_loss: 0.4357 - val_acc: 0.8638\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.89350\n",
            "Epoch 436/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2427 - acc: 0.9228 - val_loss: 0.3603 - val_acc: 0.8864\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.89350\n",
            "Epoch 437/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2383 - acc: 0.9275 - val_loss: 0.3491 - val_acc: 0.8856\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.89350\n",
            "Epoch 438/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2358 - acc: 0.9247 - val_loss: 0.3782 - val_acc: 0.8798\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.89350\n",
            "Epoch 439/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2188 - acc: 0.9283 - val_loss: 0.3496 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.89350\n",
            "Epoch 440/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2136 - acc: 0.9296 - val_loss: 0.3451 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.89350\n",
            "Epoch 441/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2302 - acc: 0.9248 - val_loss: 0.3965 - val_acc: 0.8732\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.89350\n",
            "Epoch 442/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2334 - acc: 0.9260 - val_loss: 0.4086 - val_acc: 0.8735\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.89350\n",
            "Epoch 443/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2268 - acc: 0.9244 - val_loss: 0.3425 - val_acc: 0.8913\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.89350\n",
            "Epoch 444/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2112 - acc: 0.9334 - val_loss: 0.3643 - val_acc: 0.8837\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.89350\n",
            "Epoch 445/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2242 - acc: 0.9283 - val_loss: 0.3251 - val_acc: 0.8934\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.89350\n",
            "Epoch 446/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2214 - acc: 0.9254 - val_loss: 0.3457 - val_acc: 0.8863\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.89350\n",
            "Epoch 447/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2196 - acc: 0.9285 - val_loss: 0.3833 - val_acc: 0.8782\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.89350\n",
            "Epoch 448/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2158 - acc: 0.9324 - val_loss: 0.3954 - val_acc: 0.8754\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.89350\n",
            "Epoch 449/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2232 - acc: 0.9255 - val_loss: 0.3640 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.89350\n",
            "Epoch 450/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2111 - acc: 0.9336 - val_loss: 0.4462 - val_acc: 0.8639\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.89350\n",
            "Epoch 451/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2061 - acc: 0.9337 - val_loss: 0.4065 - val_acc: 0.8710\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.89350\n",
            "Epoch 452/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2266 - acc: 0.9228 - val_loss: 0.3788 - val_acc: 0.8791\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.89350\n",
            "Epoch 453/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2146 - acc: 0.9312 - val_loss: 0.3581 - val_acc: 0.8874\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.89350\n",
            "Epoch 454/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2002 - acc: 0.9355 - val_loss: 0.3630 - val_acc: 0.8813\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.89350\n",
            "Epoch 455/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2161 - acc: 0.9281 - val_loss: 0.3615 - val_acc: 0.8876\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.89350\n",
            "Epoch 456/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1986 - acc: 0.9350 - val_loss: 0.3455 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.89350\n",
            "Epoch 457/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2110 - acc: 0.9331 - val_loss: 0.3457 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.89350\n",
            "Epoch 458/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2020 - acc: 0.9348 - val_loss: 0.3395 - val_acc: 0.8891\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.89350\n",
            "Epoch 459/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1981 - acc: 0.9363 - val_loss: 0.3788 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.89350\n",
            "Epoch 460/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1951 - acc: 0.9383 - val_loss: 0.3497 - val_acc: 0.8926\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.89350\n",
            "Epoch 461/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2017 - acc: 0.9373 - val_loss: 0.3400 - val_acc: 0.8937\n",
            "\n",
            "Epoch 00461: val_acc improved from 0.89350 to 0.89370, saving model to /content/saved_models/cifar10_ResNet32v1_model.461.h5\n",
            "Epoch 462/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2005 - acc: 0.9380 - val_loss: 0.3973 - val_acc: 0.8785\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.89370\n",
            "Epoch 463/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1982 - acc: 0.9337 - val_loss: 0.3619 - val_acc: 0.8870\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.89370\n",
            "Epoch 464/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2045 - acc: 0.9359 - val_loss: 0.3882 - val_acc: 0.8788\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.89370\n",
            "Epoch 465/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2055 - acc: 0.9326 - val_loss: 0.3942 - val_acc: 0.8788\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.89370\n",
            "Epoch 466/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1881 - acc: 0.9386 - val_loss: 0.3937 - val_acc: 0.8794\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.89370\n",
            "Epoch 467/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1852 - acc: 0.9401 - val_loss: 0.3495 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.89370\n",
            "Epoch 468/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1919 - acc: 0.9355 - val_loss: 0.3912 - val_acc: 0.8779\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.89370\n",
            "Epoch 469/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1855 - acc: 0.9424 - val_loss: 0.3454 - val_acc: 0.8908\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.89370\n",
            "Epoch 470/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1863 - acc: 0.9417 - val_loss: 0.3484 - val_acc: 0.8898\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.89370\n",
            "Epoch 471/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1796 - acc: 0.9484 - val_loss: 0.3923 - val_acc: 0.8799\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.89370\n",
            "Epoch 472/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1834 - acc: 0.9406 - val_loss: 0.3221 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00472: val_acc improved from 0.89370 to 0.89810, saving model to /content/saved_models/cifar10_ResNet32v1_model.472.h5\n",
            "Epoch 473/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1940 - acc: 0.9350 - val_loss: 0.3540 - val_acc: 0.8882\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.89810\n",
            "Epoch 474/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1875 - acc: 0.9416 - val_loss: 0.4083 - val_acc: 0.8728\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.89810\n",
            "Epoch 475/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1944 - acc: 0.9365 - val_loss: 0.3651 - val_acc: 0.8857\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.89810\n",
            "Epoch 476/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1806 - acc: 0.9412 - val_loss: 0.3838 - val_acc: 0.8810\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.89810\n",
            "Epoch 477/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1875 - acc: 0.9409 - val_loss: 0.3689 - val_acc: 0.8895\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.89810\n",
            "Epoch 478/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1752 - acc: 0.9444 - val_loss: 0.3176 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00478: val_acc improved from 0.89810 to 0.89970, saving model to /content/saved_models/cifar10_ResNet32v1_model.478.h5\n",
            "Epoch 479/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1830 - acc: 0.9435 - val_loss: 0.4146 - val_acc: 0.8748\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.89970\n",
            "Epoch 480/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1829 - acc: 0.9411 - val_loss: 0.3288 - val_acc: 0.8954\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.89970\n",
            "Epoch 481/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1802 - acc: 0.9428 - val_loss: 0.3758 - val_acc: 0.8850\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.89970\n",
            "Epoch 482/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1789 - acc: 0.9410 - val_loss: 0.3383 - val_acc: 0.8930\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.89970\n",
            "Epoch 483/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1701 - acc: 0.9463 - val_loss: 0.3429 - val_acc: 0.8906\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.89970\n",
            "Epoch 484/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1891 - acc: 0.9392 - val_loss: 0.3503 - val_acc: 0.8902\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.89970\n",
            "Epoch 485/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1838 - acc: 0.9419 - val_loss: 0.3799 - val_acc: 0.8840\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.89970\n",
            "Epoch 486/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1982 - acc: 0.9324 - val_loss: 0.3255 - val_acc: 0.8934\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.89970\n",
            "Epoch 487/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1829 - acc: 0.9398 - val_loss: 0.4175 - val_acc: 0.8744\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.89970\n",
            "Epoch 488/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1745 - acc: 0.9450 - val_loss: 0.4021 - val_acc: 0.8767\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.89970\n",
            "Epoch 489/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1700 - acc: 0.9479 - val_loss: 0.3254 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.89970\n",
            "Epoch 490/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1751 - acc: 0.9451 - val_loss: 0.3701 - val_acc: 0.8868\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.89970\n",
            "Epoch 491/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1736 - acc: 0.9412 - val_loss: 0.3517 - val_acc: 0.8905\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.89970\n",
            "Epoch 492/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1729 - acc: 0.9444 - val_loss: 0.3938 - val_acc: 0.8792\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.89970\n",
            "Epoch 493/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1728 - acc: 0.9484 - val_loss: 0.3973 - val_acc: 0.8812\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.89970\n",
            "Epoch 494/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1695 - acc: 0.9454 - val_loss: 0.4391 - val_acc: 0.8665\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.89970\n",
            "Epoch 495/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1623 - acc: 0.9492 - val_loss: 0.3261 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.89970\n",
            "Epoch 496/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1633 - acc: 0.9503 - val_loss: 0.3271 - val_acc: 0.8965\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.89970\n",
            "Epoch 497/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1737 - acc: 0.9439 - val_loss: 0.3882 - val_acc: 0.8834\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.89970\n",
            "Epoch 498/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1774 - acc: 0.9416 - val_loss: 0.3702 - val_acc: 0.8879\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.89970\n",
            "Epoch 499/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1547 - acc: 0.9520 - val_loss: 0.3757 - val_acc: 0.8851\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.89970\n",
            "Epoch 500/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1689 - acc: 0.9482 - val_loss: 0.3624 - val_acc: 0.8918\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.89970\n",
            "Epoch 501/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1635 - acc: 0.9479 - val_loss: 0.3325 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.89970\n",
            "Epoch 502/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1616 - acc: 0.9466 - val_loss: 0.3283 - val_acc: 0.8964\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.89970\n",
            "Epoch 503/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1495 - acc: 0.9523 - val_loss: 0.3819 - val_acc: 0.8825\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.89970\n",
            "Epoch 504/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1609 - acc: 0.9523 - val_loss: 0.3505 - val_acc: 0.8904\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.89970\n",
            "Epoch 505/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1674 - acc: 0.9421 - val_loss: 0.4030 - val_acc: 0.8799\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.89970\n",
            "Epoch 506/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1511 - acc: 0.9524 - val_loss: 0.3270 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.89970\n",
            "Epoch 507/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1731 - acc: 0.9473 - val_loss: 0.3382 - val_acc: 0.8966\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.89970\n",
            "Epoch 508/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1594 - acc: 0.9504 - val_loss: 0.4659 - val_acc: 0.8692\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.89970\n",
            "Epoch 509/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1582 - acc: 0.9496 - val_loss: 0.4282 - val_acc: 0.8746\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.89970\n",
            "Epoch 510/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1569 - acc: 0.9521 - val_loss: 0.4871 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.89970\n",
            "Epoch 511/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1582 - acc: 0.9474 - val_loss: 0.3335 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.89970\n",
            "Epoch 512/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1566 - acc: 0.9479 - val_loss: 0.3564 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.89970\n",
            "Epoch 513/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1591 - acc: 0.9487 - val_loss: 0.5226 - val_acc: 0.8473\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.89970\n",
            "Epoch 514/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1674 - acc: 0.9440 - val_loss: 0.3468 - val_acc: 0.8915\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.89970\n",
            "Epoch 515/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1626 - acc: 0.9468 - val_loss: 0.4318 - val_acc: 0.8742\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.89970\n",
            "Epoch 516/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1646 - acc: 0.9441 - val_loss: 0.4265 - val_acc: 0.8738\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.89970\n",
            "Epoch 517/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1568 - acc: 0.9504 - val_loss: 0.3423 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.89970\n",
            "Epoch 518/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1409 - acc: 0.9566 - val_loss: 0.3741 - val_acc: 0.8840\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.89970\n",
            "Epoch 519/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1734 - acc: 0.9448 - val_loss: 0.3384 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.89970\n",
            "Epoch 520/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1655 - acc: 0.9432 - val_loss: 0.3415 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.89970\n",
            "Epoch 521/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1476 - acc: 0.9548 - val_loss: 0.3241 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.89970\n",
            "Epoch 522/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1488 - acc: 0.9520 - val_loss: 0.3979 - val_acc: 0.8807\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.89970\n",
            "Epoch 523/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1539 - acc: 0.9512 - val_loss: 0.3567 - val_acc: 0.8918\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.89970\n",
            "Epoch 524/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1414 - acc: 0.9554 - val_loss: 0.3427 - val_acc: 0.8933\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.89970\n",
            "Epoch 525/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1575 - acc: 0.9518 - val_loss: 0.3487 - val_acc: 0.8967\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.89970\n",
            "Epoch 526/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1492 - acc: 0.9530 - val_loss: 0.3894 - val_acc: 0.8856\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.89970\n",
            "Epoch 527/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1519 - acc: 0.9507 - val_loss: 0.3596 - val_acc: 0.8899\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.89970\n",
            "Epoch 528/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1635 - acc: 0.9485 - val_loss: 0.3817 - val_acc: 0.8847\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.89970\n",
            "Epoch 529/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1627 - acc: 0.9482 - val_loss: 0.4022 - val_acc: 0.8838\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.89970\n",
            "Epoch 530/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1445 - acc: 0.9559 - val_loss: 0.3528 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.89970\n",
            "Epoch 531/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1555 - acc: 0.9513 - val_loss: 0.3792 - val_acc: 0.8858\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.89970\n",
            "Epoch 532/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1419 - acc: 0.9558 - val_loss: 0.3579 - val_acc: 0.8952\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.89970\n",
            "Epoch 533/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1491 - acc: 0.9531 - val_loss: 0.4207 - val_acc: 0.8768\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.89970\n",
            "Epoch 534/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1334 - acc: 0.9561 - val_loss: 0.4017 - val_acc: 0.8827\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.89970\n",
            "Epoch 535/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1527 - acc: 0.9517 - val_loss: 0.3788 - val_acc: 0.8864\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.89970\n",
            "Epoch 536/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1378 - acc: 0.9587 - val_loss: 0.3362 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.89970\n",
            "Epoch 537/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1456 - acc: 0.9569 - val_loss: 0.4381 - val_acc: 0.8688\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.89970\n",
            "Epoch 538/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1400 - acc: 0.9564 - val_loss: 0.3868 - val_acc: 0.8853\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.89970\n",
            "Epoch 539/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1469 - acc: 0.9588 - val_loss: 0.3909 - val_acc: 0.8848\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.89970\n",
            "Epoch 540/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1476 - acc: 0.9522 - val_loss: 0.4637 - val_acc: 0.8697\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.89970\n",
            "Epoch 541/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1424 - acc: 0.9547 - val_loss: 0.3964 - val_acc: 0.8812\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.89970\n",
            "Epoch 542/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1491 - acc: 0.9539 - val_loss: 0.3711 - val_acc: 0.8871\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.89970\n",
            "Epoch 543/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1268 - acc: 0.9597 - val_loss: 0.3702 - val_acc: 0.8875\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.89970\n",
            "Epoch 544/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1364 - acc: 0.9554 - val_loss: 0.3735 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.89970\n",
            "Epoch 545/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1456 - acc: 0.9584 - val_loss: 0.3608 - val_acc: 0.8928\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.89970\n",
            "Epoch 546/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1405 - acc: 0.9604 - val_loss: 0.4043 - val_acc: 0.8815\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.89970\n",
            "Epoch 547/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1464 - acc: 0.9532 - val_loss: 0.3861 - val_acc: 0.8824\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.89970\n",
            "Epoch 548/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1389 - acc: 0.9567 - val_loss: 0.3144 - val_acc: 0.9016\n",
            "\n",
            "Epoch 00548: val_acc improved from 0.89970 to 0.90160, saving model to /content/saved_models/cifar10_ResNet32v1_model.548.h5\n",
            "Epoch 549/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1445 - acc: 0.9529 - val_loss: 0.3447 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.90160\n",
            "Epoch 550/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1443 - acc: 0.9567 - val_loss: 0.3353 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.90160\n",
            "Epoch 551/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1313 - acc: 0.9569 - val_loss: 0.3524 - val_acc: 0.8932\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.90160\n",
            "Epoch 552/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1421 - acc: 0.9548 - val_loss: 0.3453 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.90160\n",
            "Epoch 553/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1373 - acc: 0.9546 - val_loss: 0.4278 - val_acc: 0.8767\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.90160\n",
            "Epoch 554/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1456 - acc: 0.9532 - val_loss: 0.3496 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.90160\n",
            "Epoch 555/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1369 - acc: 0.9569 - val_loss: 0.3217 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.90160\n",
            "Epoch 556/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1449 - acc: 0.9531 - val_loss: 0.3400 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.90160\n",
            "Epoch 557/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1393 - acc: 0.9567 - val_loss: 0.3992 - val_acc: 0.8855\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.90160\n",
            "Epoch 558/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1365 - acc: 0.9600 - val_loss: 0.3298 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.90160\n",
            "Epoch 559/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1304 - acc: 0.9586 - val_loss: 0.4002 - val_acc: 0.8817\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.90160\n",
            "Epoch 560/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1360 - acc: 0.9562 - val_loss: 0.4003 - val_acc: 0.8857\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.90160\n",
            "Epoch 561/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1361 - acc: 0.9576 - val_loss: 0.4453 - val_acc: 0.8733\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.90160\n",
            "Epoch 562/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1282 - acc: 0.9586 - val_loss: 0.3825 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.90160\n",
            "Epoch 563/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1188 - acc: 0.9643 - val_loss: 0.3698 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.90160\n",
            "Epoch 564/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1437 - acc: 0.9565 - val_loss: 0.3383 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.90160\n",
            "Epoch 565/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1383 - acc: 0.9559 - val_loss: 0.3901 - val_acc: 0.8884\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.90160\n",
            "Epoch 566/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1433 - acc: 0.9534 - val_loss: 0.4001 - val_acc: 0.8843\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.90160\n",
            "Epoch 567/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1249 - acc: 0.9615 - val_loss: 0.4231 - val_acc: 0.8800\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.90160\n",
            "Epoch 568/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1365 - acc: 0.9605 - val_loss: 0.3212 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.90160\n",
            "Epoch 569/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1317 - acc: 0.9590 - val_loss: 0.3847 - val_acc: 0.8846\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.90160\n",
            "Epoch 570/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1376 - acc: 0.9547 - val_loss: 0.3750 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.90160\n",
            "Epoch 571/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1218 - acc: 0.9645 - val_loss: 0.4024 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.90160\n",
            "Epoch 572/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1279 - acc: 0.9593 - val_loss: 0.3724 - val_acc: 0.8909\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.90160\n",
            "Epoch 573/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1281 - acc: 0.9607 - val_loss: 0.4688 - val_acc: 0.8681\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.90160\n",
            "Epoch 574/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1367 - acc: 0.9600 - val_loss: 0.3693 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.90160\n",
            "Epoch 575/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1267 - acc: 0.9608 - val_loss: 0.4588 - val_acc: 0.8701\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.90160\n",
            "Epoch 576/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1362 - acc: 0.9562 - val_loss: 0.3457 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.90160\n",
            "Epoch 577/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1324 - acc: 0.9571 - val_loss: 0.3622 - val_acc: 0.8910\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.90160\n",
            "Epoch 578/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1260 - acc: 0.9617 - val_loss: 0.3413 - val_acc: 0.8998\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.90160\n",
            "Epoch 579/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1273 - acc: 0.9602 - val_loss: 0.3713 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.90160\n",
            "Epoch 580/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1223 - acc: 0.9623 - val_loss: 0.3778 - val_acc: 0.8926\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.90160\n",
            "Epoch 581/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1286 - acc: 0.9589 - val_loss: 0.3530 - val_acc: 0.8966\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.90160\n",
            "Epoch 582/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1195 - acc: 0.9640 - val_loss: 0.3975 - val_acc: 0.8872\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.90160\n",
            "Epoch 583/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1263 - acc: 0.9595 - val_loss: 0.4278 - val_acc: 0.8783\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.90160\n",
            "Epoch 584/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1241 - acc: 0.9597 - val_loss: 0.3469 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.90160\n",
            "Epoch 585/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1201 - acc: 0.9630 - val_loss: 0.4126 - val_acc: 0.8810\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.90160\n",
            "Epoch 586/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1273 - acc: 0.9589 - val_loss: 0.3600 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.90160\n",
            "Epoch 587/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1269 - acc: 0.9619 - val_loss: 0.4083 - val_acc: 0.8830\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.90160\n",
            "Epoch 588/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1253 - acc: 0.9659 - val_loss: 0.3412 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.90160\n",
            "Epoch 589/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1213 - acc: 0.9626 - val_loss: 0.4309 - val_acc: 0.8777\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.90160\n",
            "Epoch 590/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1259 - acc: 0.9604 - val_loss: 0.4039 - val_acc: 0.8877\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.90160\n",
            "Epoch 591/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1254 - acc: 0.9616 - val_loss: 0.3991 - val_acc: 0.8845\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.90160\n",
            "Epoch 592/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1272 - acc: 0.9592 - val_loss: 0.3911 - val_acc: 0.8871\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.90160\n",
            "Epoch 593/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1302 - acc: 0.9573 - val_loss: 0.4658 - val_acc: 0.8699\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.90160\n",
            "Epoch 594/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1392 - acc: 0.9555 - val_loss: 0.3575 - val_acc: 0.8953\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.90160\n",
            "Epoch 595/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1219 - acc: 0.9629 - val_loss: 0.3239 - val_acc: 0.9022\n",
            "\n",
            "Epoch 00595: val_acc improved from 0.90160 to 0.90220, saving model to /content/saved_models/cifar10_ResNet32v1_model.595.h5\n",
            "Epoch 596/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1134 - acc: 0.9657 - val_loss: 0.3244 - val_acc: 0.9043\n",
            "\n",
            "Epoch 00596: val_acc improved from 0.90220 to 0.90430, saving model to /content/saved_models/cifar10_ResNet32v1_model.596.h5\n",
            "Epoch 597/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1138 - acc: 0.9640 - val_loss: 0.3498 - val_acc: 0.8953\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.90430\n",
            "Epoch 598/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1257 - acc: 0.9591 - val_loss: 0.3464 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.90430\n",
            "Epoch 599/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1373 - acc: 0.9554 - val_loss: 0.4347 - val_acc: 0.8826\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.90430\n",
            "Epoch 600/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1276 - acc: 0.9584 - val_loss: 0.3903 - val_acc: 0.8882\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.90430\n",
            "Epoch 601/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1338 - acc: 0.9603 - val_loss: 0.4808 - val_acc: 0.8686\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.90430\n",
            "Epoch 602/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1242 - acc: 0.9622 - val_loss: 0.2935 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00602: val_acc improved from 0.90430 to 0.91330, saving model to /content/saved_models/cifar10_ResNet32v1_model.602.h5\n",
            "Epoch 603/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1075 - acc: 0.9681 - val_loss: 0.2803 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00603: val_acc improved from 0.91330 to 0.91700, saving model to /content/saved_models/cifar10_ResNet32v1_model.603.h5\n",
            "Epoch 604/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1046 - acc: 0.9694 - val_loss: 0.2781 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00604: val_acc did not improve from 0.91700\n",
            "Epoch 605/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0974 - acc: 0.9731 - val_loss: 0.2741 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00605: val_acc improved from 0.91700 to 0.91890, saving model to /content/saved_models/cifar10_ResNet32v1_model.605.h5\n",
            "Epoch 606/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0954 - acc: 0.9748 - val_loss: 0.2714 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00606: val_acc did not improve from 0.91890\n",
            "Epoch 607/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0861 - acc: 0.9794 - val_loss: 0.2732 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00607: val_acc did not improve from 0.91890\n",
            "Epoch 608/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0963 - acc: 0.9719 - val_loss: 0.2698 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00608: val_acc did not improve from 0.91890\n",
            "Epoch 609/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0868 - acc: 0.9754 - val_loss: 0.2699 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00609: val_acc improved from 0.91890 to 0.92020, saving model to /content/saved_models/cifar10_ResNet32v1_model.609.h5\n",
            "Epoch 610/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0838 - acc: 0.9751 - val_loss: 0.2726 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00610: val_acc did not improve from 0.92020\n",
            "Epoch 611/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0864 - acc: 0.9755 - val_loss: 0.2710 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.92020\n",
            "Epoch 612/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0942 - acc: 0.9756 - val_loss: 0.2699 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00612: val_acc did not improve from 0.92020\n",
            "Epoch 613/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0847 - acc: 0.9774 - val_loss: 0.2692 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00613: val_acc improved from 0.92020 to 0.92130, saving model to /content/saved_models/cifar10_ResNet32v1_model.613.h5\n",
            "Epoch 614/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0877 - acc: 0.9760 - val_loss: 0.2689 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.92130\n",
            "Epoch 615/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0804 - acc: 0.9795 - val_loss: 0.2759 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.92130\n",
            "Epoch 616/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0834 - acc: 0.9775 - val_loss: 0.2664 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00616: val_acc improved from 0.92130 to 0.92140, saving model to /content/saved_models/cifar10_ResNet32v1_model.616.h5\n",
            "Epoch 617/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.0935 - acc: 0.9737 - val_loss: 0.2707 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.92140\n",
            "Epoch 618/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0859 - acc: 0.9770 - val_loss: 0.2683 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00618: val_acc did not improve from 0.92140\n",
            "Epoch 619/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0784 - acc: 0.9779 - val_loss: 0.2824 - val_acc: 0.9181\n",
            "\n",
            "Epoch 00619: val_acc did not improve from 0.92140\n",
            "Epoch 620/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0813 - acc: 0.9798 - val_loss: 0.2731 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.92140\n",
            "Epoch 621/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0714 - acc: 0.9839 - val_loss: 0.2684 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00621: val_acc improved from 0.92140 to 0.92200, saving model to /content/saved_models/cifar10_ResNet32v1_model.621.h5\n",
            "Epoch 622/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0816 - acc: 0.9796 - val_loss: 0.2733 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.92200\n",
            "Epoch 623/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0758 - acc: 0.9824 - val_loss: 0.2774 - val_acc: 0.9190\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.92200\n",
            "Epoch 624/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0782 - acc: 0.9808 - val_loss: 0.2713 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.92200\n",
            "Epoch 625/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0797 - acc: 0.9791 - val_loss: 0.2705 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.92200\n",
            "Epoch 626/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0787 - acc: 0.9789 - val_loss: 0.2704 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.92200\n",
            "Epoch 627/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0710 - acc: 0.9807 - val_loss: 0.2712 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00627: val_acc did not improve from 0.92200\n",
            "Epoch 628/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0763 - acc: 0.9812 - val_loss: 0.2695 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00628: val_acc did not improve from 0.92200\n",
            "Epoch 629/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.0759 - acc: 0.9780 - val_loss: 0.2792 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.92200\n",
            "Epoch 630/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0814 - acc: 0.9771 - val_loss: 0.2691 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00630: val_acc improved from 0.92200 to 0.92280, saving model to /content/saved_models/cifar10_ResNet32v1_model.630.h5\n",
            "Epoch 631/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0766 - acc: 0.9796 - val_loss: 0.2688 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00631: val_acc did not improve from 0.92280\n",
            "Epoch 632/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0768 - acc: 0.9779 - val_loss: 0.2705 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00632: val_acc did not improve from 0.92280\n",
            "Epoch 633/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0807 - acc: 0.9764 - val_loss: 0.2698 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.92280\n",
            "Epoch 634/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0691 - acc: 0.9821 - val_loss: 0.2705 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.92280\n",
            "Epoch 635/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.0710 - acc: 0.9817 - val_loss: 0.2765 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.92280\n",
            "Epoch 636/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.0736 - acc: 0.9807 - val_loss: 0.2729 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.92280\n",
            "Epoch 637/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0742 - acc: 0.9794 - val_loss: 0.2711 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00637: val_acc did not improve from 0.92280\n",
            "Epoch 638/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0652 - acc: 0.9846 - val_loss: 0.2734 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.92280\n",
            "Epoch 639/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0731 - acc: 0.9814 - val_loss: 0.2694 - val_acc: 0.9208\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.92280\n",
            "Epoch 640/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0708 - acc: 0.9825 - val_loss: 0.2694 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.92280\n",
            "Epoch 641/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0694 - acc: 0.9830 - val_loss: 0.2713 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.92280\n",
            "Epoch 642/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0705 - acc: 0.9827 - val_loss: 0.2738 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.92280\n",
            "Epoch 643/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0756 - acc: 0.9808 - val_loss: 0.2717 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.92280\n",
            "Epoch 644/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0663 - acc: 0.9840 - val_loss: 0.2730 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.92280\n",
            "Epoch 645/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0671 - acc: 0.9849 - val_loss: 0.2728 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00645: val_acc did not improve from 0.92280\n",
            "Epoch 646/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0696 - acc: 0.9826 - val_loss: 0.2789 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00646: val_acc did not improve from 0.92280\n",
            "Epoch 647/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0675 - acc: 0.9831 - val_loss: 0.2736 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00647: val_acc did not improve from 0.92280\n",
            "Epoch 648/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0771 - acc: 0.9785 - val_loss: 0.2740 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.92280\n",
            "Epoch 649/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0730 - acc: 0.9793 - val_loss: 0.2799 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.92280\n",
            "Epoch 650/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0625 - acc: 0.9832 - val_loss: 0.2716 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00650: val_acc improved from 0.92280 to 0.92300, saving model to /content/saved_models/cifar10_ResNet32v1_model.650.h5\n",
            "Epoch 651/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0662 - acc: 0.9829 - val_loss: 0.2741 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00651: val_acc did not improve from 0.92300\n",
            "Epoch 652/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0764 - acc: 0.9784 - val_loss: 0.2751 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00652: val_acc did not improve from 0.92300\n",
            "Epoch 653/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0713 - acc: 0.9817 - val_loss: 0.2759 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00653: val_acc did not improve from 0.92300\n",
            "Epoch 654/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0713 - acc: 0.9809 - val_loss: 0.2742 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00654: val_acc did not improve from 0.92300\n",
            "Epoch 655/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0634 - acc: 0.9830 - val_loss: 0.2769 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00655: val_acc did not improve from 0.92300\n",
            "Epoch 656/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0672 - acc: 0.9819 - val_loss: 0.2762 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00656: val_acc did not improve from 0.92300\n",
            "Epoch 657/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0643 - acc: 0.9821 - val_loss: 0.2760 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00657: val_acc did not improve from 0.92300\n",
            "Epoch 658/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0644 - acc: 0.9836 - val_loss: 0.2769 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00658: val_acc did not improve from 0.92300\n",
            "Epoch 659/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0632 - acc: 0.9840 - val_loss: 0.2776 - val_acc: 0.9208\n",
            "\n",
            "Epoch 00659: val_acc did not improve from 0.92300\n",
            "Epoch 660/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0698 - acc: 0.9832 - val_loss: 0.2791 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00660: val_acc did not improve from 0.92300\n",
            "Epoch 661/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0654 - acc: 0.9826 - val_loss: 0.2773 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00661: val_acc did not improve from 0.92300\n",
            "Epoch 662/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0614 - acc: 0.9853 - val_loss: 0.2800 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00662: val_acc did not improve from 0.92300\n",
            "Epoch 663/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0612 - acc: 0.9855 - val_loss: 0.2800 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00663: val_acc did not improve from 0.92300\n",
            "Epoch 664/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0639 - acc: 0.9831 - val_loss: 0.2793 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00664: val_acc did not improve from 0.92300\n",
            "Epoch 665/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.0620 - acc: 0.9853 - val_loss: 0.2784 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00665: val_acc did not improve from 0.92300\n",
            "Epoch 666/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0587 - acc: 0.9831 - val_loss: 0.2764 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00666: val_acc did not improve from 0.92300\n",
            "Epoch 667/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0635 - acc: 0.9852 - val_loss: 0.2841 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00667: val_acc did not improve from 0.92300\n",
            "Epoch 668/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0603 - acc: 0.9838 - val_loss: 0.2870 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00668: val_acc did not improve from 0.92300\n",
            "Epoch 669/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0596 - acc: 0.9840 - val_loss: 0.2812 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00669: val_acc did not improve from 0.92300\n",
            "Epoch 670/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.0595 - acc: 0.9851 - val_loss: 0.2775 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00670: val_acc did not improve from 0.92300\n",
            "Epoch 671/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0623 - acc: 0.9837 - val_loss: 0.2756 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00671: val_acc did not improve from 0.92300\n",
            "Epoch 672/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0620 - acc: 0.9873 - val_loss: 0.2785 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00672: val_acc did not improve from 0.92300\n",
            "Epoch 673/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0618 - acc: 0.9834 - val_loss: 0.2810 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00673: val_acc did not improve from 0.92300\n",
            "Epoch 674/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0581 - acc: 0.9853 - val_loss: 0.2824 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00674: val_acc did not improve from 0.92300\n",
            "Epoch 675/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0636 - acc: 0.9835 - val_loss: 0.2847 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00675: val_acc did not improve from 0.92300\n",
            "Epoch 676/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0560 - acc: 0.9861 - val_loss: 0.2819 - val_acc: 0.9208\n",
            "\n",
            "Epoch 00676: val_acc did not improve from 0.92300\n",
            "Epoch 677/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0622 - acc: 0.9855 - val_loss: 0.2781 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00677: val_acc did not improve from 0.92300\n",
            "Epoch 678/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.0602 - acc: 0.9841 - val_loss: 0.2790 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00678: val_acc did not improve from 0.92300\n",
            "Epoch 679/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0576 - acc: 0.9875 - val_loss: 0.2840 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00679: val_acc did not improve from 0.92300\n",
            "Epoch 680/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0633 - acc: 0.9840 - val_loss: 0.2822 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00680: val_acc did not improve from 0.92300\n",
            "Epoch 681/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0606 - acc: 0.9834 - val_loss: 0.2793 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00681: val_acc did not improve from 0.92300\n",
            "Epoch 682/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0580 - acc: 0.9862 - val_loss: 0.2872 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00682: val_acc did not improve from 0.92300\n",
            "Epoch 683/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0622 - acc: 0.9844 - val_loss: 0.2835 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00683: val_acc did not improve from 0.92300\n",
            "Epoch 684/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0607 - acc: 0.9854 - val_loss: 0.2871 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00684: val_acc did not improve from 0.92300\n",
            "Epoch 685/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.0676 - acc: 0.9838 - val_loss: 0.2836 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00685: val_acc did not improve from 0.92300\n",
            "Epoch 686/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0574 - acc: 0.9883 - val_loss: 0.2820 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00686: val_acc did not improve from 0.92300\n",
            "Epoch 687/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0599 - acc: 0.9860 - val_loss: 0.2826 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00687: val_acc did not improve from 0.92300\n",
            "Epoch 688/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0625 - acc: 0.9848 - val_loss: 0.2833 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00688: val_acc did not improve from 0.92300\n",
            "Epoch 689/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0609 - acc: 0.9873 - val_loss: 0.2861 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00689: val_acc did not improve from 0.92300\n",
            "Epoch 690/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0563 - acc: 0.9875 - val_loss: 0.2826 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00690: val_acc did not improve from 0.92300\n",
            "Epoch 691/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0607 - acc: 0.9843 - val_loss: 0.2906 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00691: val_acc did not improve from 0.92300\n",
            "Epoch 692/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0553 - acc: 0.9884 - val_loss: 0.2832 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00692: val_acc did not improve from 0.92300\n",
            "Epoch 693/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0571 - acc: 0.9864 - val_loss: 0.2907 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00693: val_acc did not improve from 0.92300\n",
            "Epoch 694/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0539 - acc: 0.9872 - val_loss: 0.2851 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00694: val_acc did not improve from 0.92300\n",
            "Epoch 695/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0627 - acc: 0.9844 - val_loss: 0.2833 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00695: val_acc did not improve from 0.92300\n",
            "Epoch 696/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0603 - acc: 0.9860 - val_loss: 0.2815 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00696: val_acc improved from 0.92300 to 0.92350, saving model to /content/saved_models/cifar10_ResNet32v1_model.696.h5\n",
            "Epoch 697/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0585 - acc: 0.9845 - val_loss: 0.2815 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00697: val_acc did not improve from 0.92350\n",
            "Epoch 698/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0575 - acc: 0.9860 - val_loss: 0.2822 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00698: val_acc did not improve from 0.92350\n",
            "Epoch 699/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0599 - acc: 0.9855 - val_loss: 0.2859 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00699: val_acc did not improve from 0.92350\n",
            "Epoch 700/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0541 - acc: 0.9878 - val_loss: 0.2846 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00700: val_acc did not improve from 0.92350\n",
            "Epoch 701/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0580 - acc: 0.9861 - val_loss: 0.2863 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00701: val_acc did not improve from 0.92350\n",
            "Epoch 702/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0566 - acc: 0.9867 - val_loss: 0.2866 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00702: val_acc did not improve from 0.92350\n",
            "Epoch 703/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0582 - acc: 0.9851 - val_loss: 0.2806 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00703: val_acc did not improve from 0.92350\n",
            "Epoch 704/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0587 - acc: 0.9860 - val_loss: 0.2831 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00704: val_acc did not improve from 0.92350\n",
            "Epoch 705/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0568 - acc: 0.9881 - val_loss: 0.2853 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00705: val_acc did not improve from 0.92350\n",
            "Epoch 706/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0588 - acc: 0.9863 - val_loss: 0.2822 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00706: val_acc did not improve from 0.92350\n",
            "Epoch 707/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0554 - acc: 0.9867 - val_loss: 0.2864 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00707: val_acc did not improve from 0.92350\n",
            "Epoch 708/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0570 - acc: 0.9862 - val_loss: 0.2869 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00708: val_acc did not improve from 0.92350\n",
            "Epoch 709/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0517 - acc: 0.9883 - val_loss: 0.2830 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00709: val_acc did not improve from 0.92350\n",
            "Epoch 710/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0534 - acc: 0.9876 - val_loss: 0.2849 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00710: val_acc did not improve from 0.92350\n",
            "Epoch 711/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0563 - acc: 0.9854 - val_loss: 0.2809 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00711: val_acc did not improve from 0.92350\n",
            "Epoch 712/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0507 - acc: 0.9889 - val_loss: 0.2878 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00712: val_acc did not improve from 0.92350\n",
            "Epoch 713/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0570 - acc: 0.9874 - val_loss: 0.2861 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00713: val_acc did not improve from 0.92350\n",
            "Epoch 714/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0587 - acc: 0.9851 - val_loss: 0.2828 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00714: val_acc did not improve from 0.92350\n",
            "Epoch 715/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0544 - acc: 0.9869 - val_loss: 0.2839 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00715: val_acc did not improve from 0.92350\n",
            "Epoch 716/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0579 - acc: 0.9862 - val_loss: 0.2961 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00716: val_acc did not improve from 0.92350\n",
            "Epoch 717/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0579 - acc: 0.9864 - val_loss: 0.2885 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00717: val_acc did not improve from 0.92350\n",
            "Epoch 718/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0517 - acc: 0.9877 - val_loss: 0.2846 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00718: val_acc did not improve from 0.92350\n",
            "Epoch 719/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0526 - acc: 0.9865 - val_loss: 0.2886 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00719: val_acc did not improve from 0.92350\n",
            "Epoch 720/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0553 - acc: 0.9871 - val_loss: 0.2890 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00720: val_acc did not improve from 0.92350\n",
            "Epoch 721/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0577 - acc: 0.9849 - val_loss: 0.2942 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00721: val_acc did not improve from 0.92350\n",
            "Epoch 722/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0568 - acc: 0.9838 - val_loss: 0.2874 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00722: val_acc did not improve from 0.92350\n",
            "Epoch 723/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0536 - acc: 0.9880 - val_loss: 0.2854 - val_acc: 0.9183\n",
            "\n",
            "Epoch 00723: val_acc did not improve from 0.92350\n",
            "Epoch 724/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0565 - acc: 0.9865 - val_loss: 0.2872 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00724: val_acc did not improve from 0.92350\n",
            "Epoch 725/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0545 - acc: 0.9862 - val_loss: 0.2959 - val_acc: 0.9184\n",
            "\n",
            "Epoch 00725: val_acc did not improve from 0.92350\n",
            "Epoch 726/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0546 - acc: 0.9860 - val_loss: 0.2919 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00726: val_acc did not improve from 0.92350\n",
            "Epoch 727/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0524 - acc: 0.9889 - val_loss: 0.2903 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00727: val_acc did not improve from 0.92350\n",
            "Epoch 728/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0560 - acc: 0.9851 - val_loss: 0.2851 - val_acc: 0.9208\n",
            "\n",
            "Epoch 00728: val_acc did not improve from 0.92350\n",
            "Epoch 729/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0555 - acc: 0.9874 - val_loss: 0.2888 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00729: val_acc did not improve from 0.92350\n",
            "Epoch 730/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0566 - acc: 0.9865 - val_loss: 0.2880 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00730: val_acc did not improve from 0.92350\n",
            "Epoch 731/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0524 - acc: 0.9890 - val_loss: 0.2905 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00731: val_acc did not improve from 0.92350\n",
            "Epoch 732/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0576 - acc: 0.9861 - val_loss: 0.2875 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00732: val_acc did not improve from 0.92350\n",
            "Epoch 733/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0465 - acc: 0.9893 - val_loss: 0.2872 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00733: val_acc did not improve from 0.92350\n",
            "Epoch 734/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0518 - acc: 0.9885 - val_loss: 0.2933 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00734: val_acc did not improve from 0.92350\n",
            "Epoch 735/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0524 - acc: 0.9858 - val_loss: 0.2879 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00735: val_acc did not improve from 0.92350\n",
            "Epoch 736/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0504 - acc: 0.9896 - val_loss: 0.2929 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00736: val_acc did not improve from 0.92350\n",
            "Epoch 737/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0515 - acc: 0.9870 - val_loss: 0.2990 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00737: val_acc did not improve from 0.92350\n",
            "Epoch 738/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0512 - acc: 0.9881 - val_loss: 0.2832 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00738: val_acc did not improve from 0.92350\n",
            "Epoch 739/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0498 - acc: 0.9875 - val_loss: 0.2896 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00739: val_acc did not improve from 0.92350\n",
            "Epoch 740/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0540 - acc: 0.9851 - val_loss: 0.2867 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00740: val_acc did not improve from 0.92350\n",
            "Epoch 741/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0494 - acc: 0.9880 - val_loss: 0.2897 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00741: val_acc did not improve from 0.92350\n",
            "Epoch 742/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0519 - acc: 0.9869 - val_loss: 0.2878 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00742: val_acc did not improve from 0.92350\n",
            "Epoch 743/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0502 - acc: 0.9892 - val_loss: 0.2891 - val_acc: 0.9187\n",
            "\n",
            "Epoch 00743: val_acc did not improve from 0.92350\n",
            "Epoch 744/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0618 - acc: 0.9837 - val_loss: 0.2926 - val_acc: 0.9188\n",
            "\n",
            "Epoch 00744: val_acc did not improve from 0.92350\n",
            "Epoch 745/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0514 - acc: 0.9878 - val_loss: 0.2958 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00745: val_acc did not improve from 0.92350\n",
            "Epoch 746/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0507 - acc: 0.9890 - val_loss: 0.2901 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00746: val_acc did not improve from 0.92350\n",
            "Epoch 747/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0500 - acc: 0.9874 - val_loss: 0.2889 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00747: val_acc did not improve from 0.92350\n",
            "Epoch 748/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0523 - acc: 0.9867 - val_loss: 0.2938 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00748: val_acc did not improve from 0.92350\n",
            "Epoch 749/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0477 - acc: 0.9905 - val_loss: 0.2977 - val_acc: 0.9188\n",
            "\n",
            "Epoch 00749: val_acc did not improve from 0.92350\n",
            "Epoch 750/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0507 - acc: 0.9878 - val_loss: 0.2918 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00750: val_acc did not improve from 0.92350\n",
            "Epoch 751/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0459 - acc: 0.9897 - val_loss: 0.2856 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00751: val_acc did not improve from 0.92350\n",
            "Epoch 752/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0527 - acc: 0.9859 - val_loss: 0.2929 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00752: val_acc did not improve from 0.92350\n",
            "Epoch 753/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0513 - acc: 0.9874 - val_loss: 0.2991 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00753: val_acc did not improve from 0.92350\n",
            "Epoch 754/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0519 - acc: 0.9876 - val_loss: 0.2898 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00754: val_acc did not improve from 0.92350\n",
            "Epoch 755/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0522 - acc: 0.9876 - val_loss: 0.2923 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00755: val_acc did not improve from 0.92350\n",
            "Epoch 756/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0533 - acc: 0.9869 - val_loss: 0.2979 - val_acc: 0.9178\n",
            "\n",
            "Epoch 00756: val_acc did not improve from 0.92350\n",
            "Epoch 757/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0465 - acc: 0.9897 - val_loss: 0.2935 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00757: val_acc did not improve from 0.92350\n",
            "Epoch 758/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0465 - acc: 0.9894 - val_loss: 0.2935 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00758: val_acc did not improve from 0.92350\n",
            "Epoch 759/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0495 - acc: 0.9865 - val_loss: 0.2958 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00759: val_acc did not improve from 0.92350\n",
            "Epoch 760/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0513 - acc: 0.9879 - val_loss: 0.3015 - val_acc: 0.9185\n",
            "\n",
            "Epoch 00760: val_acc did not improve from 0.92350\n",
            "Epoch 761/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0530 - acc: 0.9877 - val_loss: 0.2943 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00761: val_acc did not improve from 0.92350\n",
            "Epoch 762/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0511 - acc: 0.9884 - val_loss: 0.2931 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00762: val_acc did not improve from 0.92350\n",
            "Epoch 763/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0507 - acc: 0.9873 - val_loss: 0.2902 - val_acc: 0.9190\n",
            "\n",
            "Epoch 00763: val_acc did not improve from 0.92350\n",
            "Epoch 764/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0452 - acc: 0.9905 - val_loss: 0.2969 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00764: val_acc did not improve from 0.92350\n",
            "Epoch 765/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0488 - acc: 0.9892 - val_loss: 0.3045 - val_acc: 0.9175\n",
            "\n",
            "Epoch 00765: val_acc did not improve from 0.92350\n",
            "Epoch 766/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0495 - acc: 0.9875 - val_loss: 0.2919 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00766: val_acc did not improve from 0.92350\n",
            "Epoch 767/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0522 - acc: 0.9869 - val_loss: 0.2924 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00767: val_acc did not improve from 0.92350\n",
            "Epoch 768/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0560 - acc: 0.9865 - val_loss: 0.3009 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00768: val_acc did not improve from 0.92350\n",
            "Epoch 769/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0502 - acc: 0.9891 - val_loss: 0.3038 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00769: val_acc did not improve from 0.92350\n",
            "Epoch 770/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0474 - acc: 0.9892 - val_loss: 0.2950 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00770: val_acc did not improve from 0.92350\n",
            "Epoch 771/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0460 - acc: 0.9907 - val_loss: 0.3003 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00771: val_acc did not improve from 0.92350\n",
            "Epoch 772/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0477 - acc: 0.9881 - val_loss: 0.3042 - val_acc: 0.9188\n",
            "\n",
            "Epoch 00772: val_acc did not improve from 0.92350\n",
            "Epoch 773/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0519 - acc: 0.9871 - val_loss: 0.3059 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00773: val_acc did not improve from 0.92350\n",
            "Epoch 774/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0486 - acc: 0.9889 - val_loss: 0.2992 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00774: val_acc did not improve from 0.92350\n",
            "Epoch 775/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0471 - acc: 0.9891 - val_loss: 0.2972 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00775: val_acc did not improve from 0.92350\n",
            "Epoch 776/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0498 - acc: 0.9883 - val_loss: 0.2943 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00776: val_acc did not improve from 0.92350\n",
            "Epoch 777/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0473 - acc: 0.9893 - val_loss: 0.2922 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00777: val_acc did not improve from 0.92350\n",
            "Epoch 778/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0460 - acc: 0.9907 - val_loss: 0.2952 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00778: val_acc did not improve from 0.92350\n",
            "Epoch 779/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0442 - acc: 0.9915 - val_loss: 0.3029 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00779: val_acc did not improve from 0.92350\n",
            "Epoch 780/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0447 - acc: 0.9918 - val_loss: 0.2941 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00780: val_acc did not improve from 0.92350\n",
            "Epoch 781/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0455 - acc: 0.9905 - val_loss: 0.3008 - val_acc: 0.9187\n",
            "\n",
            "Epoch 00781: val_acc did not improve from 0.92350\n",
            "Epoch 782/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0499 - acc: 0.9864 - val_loss: 0.2962 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00782: val_acc did not improve from 0.92350\n",
            "Epoch 783/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0490 - acc: 0.9890 - val_loss: 0.2985 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00783: val_acc did not improve from 0.92350\n",
            "Epoch 784/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0430 - acc: 0.9895 - val_loss: 0.3021 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00784: val_acc did not improve from 0.92350\n",
            "Epoch 785/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0460 - acc: 0.9899 - val_loss: 0.3022 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00785: val_acc did not improve from 0.92350\n",
            "Epoch 786/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0527 - acc: 0.9884 - val_loss: 0.2967 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00786: val_acc did not improve from 0.92350\n",
            "Epoch 787/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0488 - acc: 0.9886 - val_loss: 0.2969 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00787: val_acc did not improve from 0.92350\n",
            "Epoch 788/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0446 - acc: 0.9903 - val_loss: 0.3041 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00788: val_acc did not improve from 0.92350\n",
            "Epoch 789/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0498 - acc: 0.9882 - val_loss: 0.2976 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00789: val_acc did not improve from 0.92350\n",
            "Epoch 790/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0535 - acc: 0.9876 - val_loss: 0.3051 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00790: val_acc did not improve from 0.92350\n",
            "Epoch 791/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0436 - acc: 0.9907 - val_loss: 0.2989 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00791: val_acc did not improve from 0.92350\n",
            "Epoch 792/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0451 - acc: 0.9894 - val_loss: 0.2973 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00792: val_acc did not improve from 0.92350\n",
            "Epoch 793/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0494 - acc: 0.9881 - val_loss: 0.2981 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00793: val_acc did not improve from 0.92350\n",
            "Epoch 794/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0445 - acc: 0.9910 - val_loss: 0.2991 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00794: val_acc did not improve from 0.92350\n",
            "Epoch 795/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0473 - acc: 0.9884 - val_loss: 0.2976 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00795: val_acc did not improve from 0.92350\n",
            "Epoch 796/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0466 - acc: 0.9893 - val_loss: 0.2961 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00796: val_acc did not improve from 0.92350\n",
            "Epoch 797/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0482 - acc: 0.9875 - val_loss: 0.2959 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00797: val_acc did not improve from 0.92350\n",
            "Epoch 798/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0449 - acc: 0.9901 - val_loss: 0.2967 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00798: val_acc did not improve from 0.92350\n",
            "Epoch 799/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0457 - acc: 0.9906 - val_loss: 0.2950 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00799: val_acc did not improve from 0.92350\n",
            "Epoch 800/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0457 - acc: 0.9899 - val_loss: 0.3040 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00800: val_acc did not improve from 0.92350\n",
            "Epoch 801/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0464 - acc: 0.9894 - val_loss: 0.3003 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00801: val_acc did not improve from 0.92350\n",
            "Epoch 802/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0492 - acc: 0.9887 - val_loss: 0.2953 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00802: val_acc did not improve from 0.92350\n",
            "Epoch 803/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0467 - acc: 0.9904 - val_loss: 0.2927 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00803: val_acc did not improve from 0.92350\n",
            "Epoch 804/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0387 - acc: 0.9930 - val_loss: 0.2915 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00804: val_acc did not improve from 0.92350\n",
            "Epoch 805/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0492 - acc: 0.9883 - val_loss: 0.2912 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00805: val_acc did not improve from 0.92350\n",
            "Epoch 806/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0495 - acc: 0.9882 - val_loss: 0.2904 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00806: val_acc did not improve from 0.92350\n",
            "Epoch 807/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0497 - acc: 0.9881 - val_loss: 0.2887 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00807: val_acc did not improve from 0.92350\n",
            "Epoch 808/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0473 - acc: 0.9883 - val_loss: 0.2887 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00808: val_acc did not improve from 0.92350\n",
            "Epoch 809/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0455 - acc: 0.9896 - val_loss: 0.2882 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00809: val_acc did not improve from 0.92350\n",
            "Epoch 810/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0424 - acc: 0.9908 - val_loss: 0.2886 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00810: val_acc did not improve from 0.92350\n",
            "Epoch 811/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0445 - acc: 0.9908 - val_loss: 0.2884 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00811: val_acc did not improve from 0.92350\n",
            "Epoch 812/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0478 - acc: 0.9885 - val_loss: 0.2878 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00812: val_acc did not improve from 0.92350\n",
            "Epoch 813/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0478 - acc: 0.9899 - val_loss: 0.2873 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00813: val_acc did not improve from 0.92350\n",
            "Epoch 814/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0452 - acc: 0.9910 - val_loss: 0.2871 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00814: val_acc did not improve from 0.92350\n",
            "Epoch 815/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0448 - acc: 0.9912 - val_loss: 0.2870 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00815: val_acc did not improve from 0.92350\n",
            "Epoch 816/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0441 - acc: 0.9907 - val_loss: 0.2865 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00816: val_acc did not improve from 0.92350\n",
            "Epoch 817/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0501 - acc: 0.9905 - val_loss: 0.2854 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00817: val_acc did not improve from 0.92350\n",
            "Epoch 818/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0490 - acc: 0.9890 - val_loss: 0.2860 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00818: val_acc did not improve from 0.92350\n",
            "Epoch 819/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0436 - acc: 0.9923 - val_loss: 0.2861 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00819: val_acc did not improve from 0.92350\n",
            "Epoch 820/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0475 - acc: 0.9889 - val_loss: 0.2868 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00820: val_acc did not improve from 0.92350\n",
            "Epoch 821/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0443 - acc: 0.9910 - val_loss: 0.2867 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00821: val_acc did not improve from 0.92350\n",
            "Epoch 822/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0475 - acc: 0.9908 - val_loss: 0.2863 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00822: val_acc did not improve from 0.92350\n",
            "Epoch 823/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0473 - acc: 0.9895 - val_loss: 0.2863 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00823: val_acc did not improve from 0.92350\n",
            "Epoch 824/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0457 - acc: 0.9899 - val_loss: 0.2869 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00824: val_acc did not improve from 0.92350\n",
            "Epoch 825/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0489 - acc: 0.9884 - val_loss: 0.2876 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00825: val_acc did not improve from 0.92350\n",
            "Epoch 826/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0465 - acc: 0.9898 - val_loss: 0.2890 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00826: val_acc did not improve from 0.92350\n",
            "Epoch 827/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0428 - acc: 0.9918 - val_loss: 0.2881 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00827: val_acc did not improve from 0.92350\n",
            "Epoch 828/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0432 - acc: 0.9924 - val_loss: 0.2879 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00828: val_acc did not improve from 0.92350\n",
            "Epoch 829/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0424 - acc: 0.9920 - val_loss: 0.2879 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00829: val_acc did not improve from 0.92350\n",
            "Epoch 830/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0422 - acc: 0.9924 - val_loss: 0.2879 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00830: val_acc did not improve from 0.92350\n",
            "Epoch 831/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0452 - acc: 0.9899 - val_loss: 0.2874 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00831: val_acc did not improve from 0.92350\n",
            "Epoch 832/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0457 - acc: 0.9901 - val_loss: 0.2869 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00832: val_acc did not improve from 0.92350\n",
            "Epoch 833/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0447 - acc: 0.9910 - val_loss: 0.2876 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00833: val_acc did not improve from 0.92350\n",
            "Epoch 834/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0454 - acc: 0.9895 - val_loss: 0.2872 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00834: val_acc did not improve from 0.92350\n",
            "Epoch 835/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0461 - acc: 0.9900 - val_loss: 0.2879 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00835: val_acc did not improve from 0.92350\n",
            "Epoch 836/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0493 - acc: 0.9878 - val_loss: 0.2886 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00836: val_acc did not improve from 0.92350\n",
            "Epoch 837/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0447 - acc: 0.9903 - val_loss: 0.2883 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00837: val_acc did not improve from 0.92350\n",
            "Epoch 838/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0427 - acc: 0.9915 - val_loss: 0.2879 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00838: val_acc did not improve from 0.92350\n",
            "Epoch 839/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0476 - acc: 0.9878 - val_loss: 0.2870 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00839: val_acc did not improve from 0.92350\n",
            "Epoch 840/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0470 - acc: 0.9878 - val_loss: 0.2871 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00840: val_acc did not improve from 0.92350\n",
            "Epoch 841/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0461 - acc: 0.9891 - val_loss: 0.2867 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00841: val_acc did not improve from 0.92350\n",
            "Epoch 842/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0444 - acc: 0.9903 - val_loss: 0.2878 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00842: val_acc did not improve from 0.92350\n",
            "Epoch 843/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0433 - acc: 0.9902 - val_loss: 0.2866 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00843: val_acc did not improve from 0.92350\n",
            "Epoch 844/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0401 - acc: 0.9929 - val_loss: 0.2861 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00844: val_acc did not improve from 0.92350\n",
            "Epoch 845/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0456 - acc: 0.9907 - val_loss: 0.2867 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00845: val_acc did not improve from 0.92350\n",
            "Epoch 846/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0453 - acc: 0.9906 - val_loss: 0.2880 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00846: val_acc did not improve from 0.92350\n",
            "Epoch 847/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0419 - acc: 0.9928 - val_loss: 0.2873 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00847: val_acc did not improve from 0.92350\n",
            "Epoch 848/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0449 - acc: 0.9919 - val_loss: 0.2870 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00848: val_acc did not improve from 0.92350\n",
            "Epoch 849/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0439 - acc: 0.9905 - val_loss: 0.2866 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00849: val_acc did not improve from 0.92350\n",
            "Epoch 850/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0434 - acc: 0.9915 - val_loss: 0.2866 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00850: val_acc did not improve from 0.92350\n",
            "Epoch 851/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0421 - acc: 0.9911 - val_loss: 0.2859 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00851: val_acc did not improve from 0.92350\n",
            "Epoch 852/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0408 - acc: 0.9929 - val_loss: 0.2873 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00852: val_acc did not improve from 0.92350\n",
            "Epoch 853/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0453 - acc: 0.9905 - val_loss: 0.2876 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00853: val_acc did not improve from 0.92350\n",
            "Epoch 854/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0394 - acc: 0.9932 - val_loss: 0.2868 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00854: val_acc did not improve from 0.92350\n",
            "Epoch 855/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0448 - acc: 0.9901 - val_loss: 0.2880 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00855: val_acc did not improve from 0.92350\n",
            "Epoch 856/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0471 - acc: 0.9928 - val_loss: 0.2874 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00856: val_acc did not improve from 0.92350\n",
            "Epoch 857/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0431 - acc: 0.9922 - val_loss: 0.2868 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00857: val_acc did not improve from 0.92350\n",
            "Epoch 858/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0409 - acc: 0.9915 - val_loss: 0.2867 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00858: val_acc did not improve from 0.92350\n",
            "Epoch 859/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0417 - acc: 0.9923 - val_loss: 0.2858 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00859: val_acc did not improve from 0.92350\n",
            "Epoch 860/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0448 - acc: 0.9899 - val_loss: 0.2864 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00860: val_acc did not improve from 0.92350\n",
            "Epoch 861/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0445 - acc: 0.9909 - val_loss: 0.2863 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00861: val_acc did not improve from 0.92350\n",
            "Epoch 862/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0439 - acc: 0.9915 - val_loss: 0.2868 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00862: val_acc did not improve from 0.92350\n",
            "Epoch 863/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0496 - acc: 0.9862 - val_loss: 0.2869 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00863: val_acc did not improve from 0.92350\n",
            "Epoch 864/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0436 - acc: 0.9922 - val_loss: 0.2865 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00864: val_acc did not improve from 0.92350\n",
            "Epoch 865/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0444 - acc: 0.9901 - val_loss: 0.2863 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00865: val_acc did not improve from 0.92350\n",
            "Epoch 866/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0430 - acc: 0.9912 - val_loss: 0.2861 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00866: val_acc did not improve from 0.92350\n",
            "Epoch 867/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0468 - acc: 0.9891 - val_loss: 0.2867 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00867: val_acc did not improve from 0.92350\n",
            "Epoch 868/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0436 - acc: 0.9928 - val_loss: 0.2868 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00868: val_acc did not improve from 0.92350\n",
            "Epoch 869/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0407 - acc: 0.9931 - val_loss: 0.2871 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00869: val_acc did not improve from 0.92350\n",
            "Epoch 870/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0453 - acc: 0.9902 - val_loss: 0.2875 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00870: val_acc did not improve from 0.92350\n",
            "Epoch 871/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0435 - acc: 0.9899 - val_loss: 0.2878 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00871: val_acc did not improve from 0.92350\n",
            "Epoch 872/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0425 - acc: 0.9910 - val_loss: 0.2859 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00872: val_acc did not improve from 0.92350\n",
            "Epoch 873/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0434 - acc: 0.9908 - val_loss: 0.2866 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00873: val_acc did not improve from 0.92350\n",
            "Epoch 874/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0427 - acc: 0.9918 - val_loss: 0.2866 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00874: val_acc did not improve from 0.92350\n",
            "Epoch 875/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0458 - acc: 0.9904 - val_loss: 0.2872 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00875: val_acc did not improve from 0.92350\n",
            "Epoch 876/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0417 - acc: 0.9909 - val_loss: 0.2872 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00876: val_acc did not improve from 0.92350\n",
            "Epoch 877/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0443 - acc: 0.9908 - val_loss: 0.2875 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00877: val_acc did not improve from 0.92350\n",
            "Epoch 878/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0438 - acc: 0.9908 - val_loss: 0.2866 - val_acc: 0.9231\n",
            "\n",
            "Epoch 00878: val_acc did not improve from 0.92350\n",
            "Epoch 879/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0439 - acc: 0.9925 - val_loss: 0.2857 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00879: val_acc did not improve from 0.92350\n",
            "Epoch 880/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0440 - acc: 0.9911 - val_loss: 0.2866 - val_acc: 0.9231\n",
            "\n",
            "Epoch 00880: val_acc did not improve from 0.92350\n",
            "Epoch 881/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0446 - acc: 0.9908 - val_loss: 0.2854 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00881: val_acc did not improve from 0.92350\n",
            "Epoch 882/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0399 - acc: 0.9930 - val_loss: 0.2870 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00882: val_acc did not improve from 0.92350\n",
            "Epoch 883/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0383 - acc: 0.9936 - val_loss: 0.2868 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00883: val_acc did not improve from 0.92350\n",
            "Epoch 884/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0465 - acc: 0.9886 - val_loss: 0.2861 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00884: val_acc did not improve from 0.92350\n",
            "Epoch 885/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0412 - acc: 0.9909 - val_loss: 0.2866 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00885: val_acc did not improve from 0.92350\n",
            "Epoch 886/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0426 - acc: 0.9927 - val_loss: 0.2866 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00886: val_acc did not improve from 0.92350\n",
            "Epoch 887/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0424 - acc: 0.9925 - val_loss: 0.2865 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00887: val_acc did not improve from 0.92350\n",
            "Epoch 888/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0431 - acc: 0.9928 - val_loss: 0.2866 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00888: val_acc did not improve from 0.92350\n",
            "Epoch 889/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0411 - acc: 0.9930 - val_loss: 0.2858 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00889: val_acc did not improve from 0.92350\n",
            "Epoch 890/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0422 - acc: 0.9925 - val_loss: 0.2867 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00890: val_acc did not improve from 0.92350\n",
            "Epoch 891/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0421 - acc: 0.9913 - val_loss: 0.2858 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00891: val_acc did not improve from 0.92350\n",
            "Epoch 892/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0421 - acc: 0.9916 - val_loss: 0.2865 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00892: val_acc did not improve from 0.92350\n",
            "Epoch 893/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0447 - acc: 0.9903 - val_loss: 0.2866 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00893: val_acc did not improve from 0.92350\n",
            "Epoch 894/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0477 - acc: 0.9878 - val_loss: 0.2863 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00894: val_acc did not improve from 0.92350\n",
            "Epoch 895/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0463 - acc: 0.9901 - val_loss: 0.2857 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00895: val_acc did not improve from 0.92350\n",
            "Epoch 896/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0392 - acc: 0.9936 - val_loss: 0.2855 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00896: val_acc did not improve from 0.92350\n",
            "Epoch 897/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0419 - acc: 0.9907 - val_loss: 0.2863 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00897: val_acc did not improve from 0.92350\n",
            "Epoch 898/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0397 - acc: 0.9921 - val_loss: 0.2862 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00898: val_acc did not improve from 0.92350\n",
            "Epoch 899/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0418 - acc: 0.9918 - val_loss: 0.2860 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00899: val_acc did not improve from 0.92350\n",
            "Epoch 900/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0428 - acc: 0.9901 - val_loss: 0.2862 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00900: val_acc did not improve from 0.92350\n",
            "Epoch 901/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0454 - acc: 0.9902 - val_loss: 0.2863 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00901: val_acc did not improve from 0.92350\n",
            "Epoch 902/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0446 - acc: 0.9896 - val_loss: 0.2865 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00902: val_acc did not improve from 0.92350\n",
            "Epoch 903/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0436 - acc: 0.9909 - val_loss: 0.2858 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00903: val_acc did not improve from 0.92350\n",
            "Epoch 904/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0423 - acc: 0.9902 - val_loss: 0.2857 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00904: val_acc did not improve from 0.92350\n",
            "Epoch 905/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0466 - acc: 0.9885 - val_loss: 0.2864 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00905: val_acc did not improve from 0.92350\n",
            "Epoch 906/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0487 - acc: 0.9893 - val_loss: 0.2860 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00906: val_acc did not improve from 0.92350\n",
            "Epoch 907/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0372 - acc: 0.9930 - val_loss: 0.2862 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00907: val_acc did not improve from 0.92350\n",
            "Epoch 908/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0429 - acc: 0.9931 - val_loss: 0.2861 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00908: val_acc did not improve from 0.92350\n",
            "Epoch 909/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0404 - acc: 0.9928 - val_loss: 0.2858 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00909: val_acc did not improve from 0.92350\n",
            "Epoch 910/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0413 - acc: 0.9915 - val_loss: 0.2856 - val_acc: 0.9234\n",
            "\n",
            "Epoch 00910: val_acc did not improve from 0.92350\n",
            "Epoch 911/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0427 - acc: 0.9908 - val_loss: 0.2855 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00911: val_acc did not improve from 0.92350\n",
            "Epoch 912/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0390 - acc: 0.9934 - val_loss: 0.2862 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00912: val_acc did not improve from 0.92350\n",
            "Epoch 913/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0433 - acc: 0.9920 - val_loss: 0.2869 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00913: val_acc did not improve from 0.92350\n",
            "Epoch 914/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0395 - acc: 0.9924 - val_loss: 0.2862 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00914: val_acc did not improve from 0.92350\n",
            "Epoch 915/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0432 - acc: 0.9913 - val_loss: 0.2866 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00915: val_acc did not improve from 0.92350\n",
            "Epoch 916/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0439 - acc: 0.9918 - val_loss: 0.2854 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00916: val_acc did not improve from 0.92350\n",
            "Epoch 917/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0478 - acc: 0.9893 - val_loss: 0.2862 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00917: val_acc did not improve from 0.92350\n",
            "Epoch 918/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0432 - acc: 0.9911 - val_loss: 0.2862 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00918: val_acc did not improve from 0.92350\n",
            "Epoch 919/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0428 - acc: 0.9920 - val_loss: 0.2861 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00919: val_acc did not improve from 0.92350\n",
            "Epoch 920/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0391 - acc: 0.9934 - val_loss: 0.2859 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00920: val_acc did not improve from 0.92350\n",
            "Epoch 921/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0428 - acc: 0.9895 - val_loss: 0.2864 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00921: val_acc did not improve from 0.92350\n",
            "Epoch 922/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0388 - acc: 0.9929 - val_loss: 0.2867 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00922: val_acc did not improve from 0.92350\n",
            "Epoch 923/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0441 - acc: 0.9911 - val_loss: 0.2860 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00923: val_acc did not improve from 0.92350\n",
            "Epoch 924/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0423 - acc: 0.9915 - val_loss: 0.2867 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00924: val_acc did not improve from 0.92350\n",
            "Epoch 925/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0411 - acc: 0.9919 - val_loss: 0.2868 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00925: val_acc did not improve from 0.92350\n",
            "Epoch 926/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0457 - acc: 0.9893 - val_loss: 0.2871 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00926: val_acc did not improve from 0.92350\n",
            "Epoch 927/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0430 - acc: 0.9913 - val_loss: 0.2866 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00927: val_acc did not improve from 0.92350\n",
            "Epoch 928/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0437 - acc: 0.9902 - val_loss: 0.2863 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00928: val_acc did not improve from 0.92350\n",
            "Epoch 929/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0416 - acc: 0.9902 - val_loss: 0.2860 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00929: val_acc did not improve from 0.92350\n",
            "Epoch 930/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0458 - acc: 0.9903 - val_loss: 0.2864 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00930: val_acc did not improve from 0.92350\n",
            "Epoch 931/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0408 - acc: 0.9922 - val_loss: 0.2862 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00931: val_acc did not improve from 0.92350\n",
            "Epoch 932/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0451 - acc: 0.9892 - val_loss: 0.2862 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00932: val_acc did not improve from 0.92350\n",
            "Epoch 933/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0440 - acc: 0.9906 - val_loss: 0.2859 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00933: val_acc did not improve from 0.92350\n",
            "Epoch 934/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0438 - acc: 0.9902 - val_loss: 0.2859 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00934: val_acc did not improve from 0.92350\n",
            "Epoch 935/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0426 - acc: 0.9896 - val_loss: 0.2865 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00935: val_acc did not improve from 0.92350\n",
            "Epoch 936/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0419 - acc: 0.9934 - val_loss: 0.2870 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00936: val_acc did not improve from 0.92350\n",
            "Epoch 937/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0425 - acc: 0.9928 - val_loss: 0.2864 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00937: val_acc did not improve from 0.92350\n",
            "Epoch 938/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0408 - acc: 0.9930 - val_loss: 0.2871 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00938: val_acc did not improve from 0.92350\n",
            "Epoch 939/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0432 - acc: 0.9904 - val_loss: 0.2871 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00939: val_acc did not improve from 0.92350\n",
            "Epoch 940/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0434 - acc: 0.9901 - val_loss: 0.2865 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00940: val_acc did not improve from 0.92350\n",
            "Epoch 941/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0400 - acc: 0.9921 - val_loss: 0.2857 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00941: val_acc did not improve from 0.92350\n",
            "Epoch 942/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0470 - acc: 0.9901 - val_loss: 0.2864 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00942: val_acc did not improve from 0.92350\n",
            "Epoch 943/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0433 - acc: 0.9900 - val_loss: 0.2861 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00943: val_acc did not improve from 0.92350\n",
            "Epoch 944/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0410 - acc: 0.9922 - val_loss: 0.2863 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00944: val_acc did not improve from 0.92350\n",
            "Epoch 945/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0458 - acc: 0.9904 - val_loss: 0.2861 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00945: val_acc did not improve from 0.92350\n",
            "Epoch 946/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0429 - acc: 0.9915 - val_loss: 0.2861 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00946: val_acc did not improve from 0.92350\n",
            "Epoch 947/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0454 - acc: 0.9900 - val_loss: 0.2868 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00947: val_acc did not improve from 0.92350\n",
            "Epoch 948/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0414 - acc: 0.9918 - val_loss: 0.2863 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00948: val_acc did not improve from 0.92350\n",
            "Epoch 949/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0430 - acc: 0.9919 - val_loss: 0.2864 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00949: val_acc did not improve from 0.92350\n",
            "Epoch 950/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0424 - acc: 0.9920 - val_loss: 0.2867 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00950: val_acc did not improve from 0.92350\n",
            "Epoch 951/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0433 - acc: 0.9896 - val_loss: 0.2866 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00951: val_acc did not improve from 0.92350\n",
            "Epoch 952/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0427 - acc: 0.9909 - val_loss: 0.2858 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00952: val_acc did not improve from 0.92350\n",
            "Epoch 953/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0415 - acc: 0.9905 - val_loss: 0.2864 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00953: val_acc did not improve from 0.92350\n",
            "Epoch 954/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0422 - acc: 0.9915 - val_loss: 0.2870 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00954: val_acc did not improve from 0.92350\n",
            "Epoch 955/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0422 - acc: 0.9905 - val_loss: 0.2876 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00955: val_acc did not improve from 0.92350\n",
            "Epoch 956/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0378 - acc: 0.9926 - val_loss: 0.2875 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00956: val_acc did not improve from 0.92350\n",
            "Epoch 957/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0452 - acc: 0.9891 - val_loss: 0.2876 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00957: val_acc did not improve from 0.92350\n",
            "Epoch 958/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0418 - acc: 0.9923 - val_loss: 0.2873 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00958: val_acc did not improve from 0.92350\n",
            "Epoch 959/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0440 - acc: 0.9908 - val_loss: 0.2877 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00959: val_acc did not improve from 0.92350\n",
            "Epoch 960/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0412 - acc: 0.9922 - val_loss: 0.2871 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00960: val_acc did not improve from 0.92350\n",
            "Epoch 961/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0403 - acc: 0.9924 - val_loss: 0.2874 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00961: val_acc did not improve from 0.92350\n",
            "Epoch 962/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0425 - acc: 0.9918 - val_loss: 0.2863 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00962: val_acc did not improve from 0.92350\n",
            "Epoch 963/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0415 - acc: 0.9916 - val_loss: 0.2871 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00963: val_acc did not improve from 0.92350\n",
            "Epoch 964/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0401 - acc: 0.9935 - val_loss: 0.2869 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00964: val_acc did not improve from 0.92350\n",
            "Epoch 965/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0451 - acc: 0.9888 - val_loss: 0.2869 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00965: val_acc did not improve from 0.92350\n",
            "Epoch 966/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0479 - acc: 0.9894 - val_loss: 0.2873 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00966: val_acc did not improve from 0.92350\n",
            "Epoch 967/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0422 - acc: 0.9903 - val_loss: 0.2872 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00967: val_acc did not improve from 0.92350\n",
            "Epoch 968/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0417 - acc: 0.9904 - val_loss: 0.2873 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00968: val_acc did not improve from 0.92350\n",
            "Epoch 969/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0447 - acc: 0.9910 - val_loss: 0.2870 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00969: val_acc did not improve from 0.92350\n",
            "Epoch 970/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0449 - acc: 0.9880 - val_loss: 0.2869 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00970: val_acc did not improve from 0.92350\n",
            "Epoch 971/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0450 - acc: 0.9891 - val_loss: 0.2869 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00971: val_acc did not improve from 0.92350\n",
            "Epoch 972/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0430 - acc: 0.9911 - val_loss: 0.2864 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00972: val_acc did not improve from 0.92350\n",
            "Epoch 973/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0415 - acc: 0.9925 - val_loss: 0.2880 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00973: val_acc did not improve from 0.92350\n",
            "Epoch 974/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0419 - acc: 0.9913 - val_loss: 0.2871 - val_acc: 0.9233\n",
            "\n",
            "Epoch 00974: val_acc did not improve from 0.92350\n",
            "Epoch 975/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0420 - acc: 0.9918 - val_loss: 0.2863 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00975: val_acc did not improve from 0.92350\n",
            "Epoch 976/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0443 - acc: 0.9915 - val_loss: 0.2868 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00976: val_acc did not improve from 0.92350\n",
            "Epoch 977/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0431 - acc: 0.9915 - val_loss: 0.2877 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00977: val_acc did not improve from 0.92350\n",
            "Epoch 978/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0455 - acc: 0.9898 - val_loss: 0.2878 - val_acc: 0.9231\n",
            "\n",
            "Epoch 00978: val_acc did not improve from 0.92350\n",
            "Epoch 979/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0432 - acc: 0.9917 - val_loss: 0.2876 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00979: val_acc did not improve from 0.92350\n",
            "Epoch 980/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0395 - acc: 0.9919 - val_loss: 0.2875 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00980: val_acc did not improve from 0.92350\n",
            "Epoch 981/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0411 - acc: 0.9913 - val_loss: 0.2878 - val_acc: 0.9231\n",
            "\n",
            "Epoch 00981: val_acc did not improve from 0.92350\n",
            "Epoch 982/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0395 - acc: 0.9927 - val_loss: 0.2876 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00982: val_acc did not improve from 0.92350\n",
            "Epoch 983/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0400 - acc: 0.9928 - val_loss: 0.2869 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00983: val_acc did not improve from 0.92350\n",
            "Epoch 984/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0404 - acc: 0.9921 - val_loss: 0.2870 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00984: val_acc did not improve from 0.92350\n",
            "Epoch 985/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0411 - acc: 0.9917 - val_loss: 0.2881 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00985: val_acc did not improve from 0.92350\n",
            "Epoch 986/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0398 - acc: 0.9918 - val_loss: 0.2881 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00986: val_acc did not improve from 0.92350\n",
            "Epoch 987/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0384 - acc: 0.9935 - val_loss: 0.2876 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00987: val_acc did not improve from 0.92350\n",
            "Epoch 988/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0398 - acc: 0.9929 - val_loss: 0.2875 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00988: val_acc did not improve from 0.92350\n",
            "Epoch 989/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0398 - acc: 0.9930 - val_loss: 0.2875 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00989: val_acc did not improve from 0.92350\n",
            "Epoch 990/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0398 - acc: 0.9919 - val_loss: 0.2884 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00990: val_acc did not improve from 0.92350\n",
            "Epoch 991/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.0411 - acc: 0.9907 - val_loss: 0.2881 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00991: val_acc did not improve from 0.92350\n",
            "Epoch 992/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0403 - acc: 0.9918 - val_loss: 0.2873 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00992: val_acc did not improve from 0.92350\n",
            "Epoch 993/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0417 - acc: 0.9914 - val_loss: 0.2883 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00993: val_acc did not improve from 0.92350\n",
            "Epoch 994/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0406 - acc: 0.9903 - val_loss: 0.2878 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00994: val_acc did not improve from 0.92350\n",
            "Epoch 995/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0437 - acc: 0.9909 - val_loss: 0.2887 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00995: val_acc did not improve from 0.92350\n",
            "Epoch 996/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0424 - acc: 0.9913 - val_loss: 0.2879 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00996: val_acc did not improve from 0.92350\n",
            "Epoch 997/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0399 - acc: 0.9928 - val_loss: 0.2880 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00997: val_acc did not improve from 0.92350\n",
            "Epoch 998/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0428 - acc: 0.9903 - val_loss: 0.2878 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00998: val_acc did not improve from 0.92350\n",
            "Epoch 999/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0427 - acc: 0.9911 - val_loss: 0.2877 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00999: val_acc did not improve from 0.92350\n",
            "Epoch 1000/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0413 - acc: 0.9909 - val_loss: 0.2876 - val_acc: 0.9224\n",
            "\n",
            "Epoch 01000: val_acc did not improve from 0.92350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "KqtP1kexx3yY",
        "outputId": "018676c0-6e65-453f-f40d-c48ac6a939d8"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('simple_trainHistoryDict_clip_05', \"rb\"))\n",
        "functions.plot_loss_acc(history, 2, 0.4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3PeG4ir4ZaK",
        "outputId": "a7e64e5f-c51d-4f73-b49d-bfb67ed00c49"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9223999977111816"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKjOwC70x-LH",
        "outputId": "f8308c6c-4b99-4bee-e9ee-f3f41e7022c9"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07760000228881836"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npx7NtMb2D0_"
      },
      "source": [
        "#### Model with clipping to 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZNaQkpfVJdo",
        "outputId": "ad975116-ef05-436c-db0c-f1dc5182c53a"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NwiXcn9VhF8",
        "outputId": "1039b95c-3078-40b1-bbe5-e95e52a1bc19"
      },
      "source": [
        "callbacks = functions.standard_callbacks(model_type) + [functions.Clipping(1, \"simple\")]\n",
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'simple_trainHistoryDict_clip_1', steps_per_epoch=100, epochs=1000,\n",
        "                       batch_size=100,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Epoch 1/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 84ms/step - loss: 3.4927 - acc: 0.2104 - val_loss: 3.0568 - val_acc: 0.1511\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.15110, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 1.8758 - acc: 0.3446 - val_loss: 3.4404 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.15110\n",
            "Epoch 3/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 1.6200 - acc: 0.4300 - val_loss: 4.0561 - val_acc: 0.1126\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.15110\n",
            "Epoch 4/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.5210 - acc: 0.4705 - val_loss: 2.6097 - val_acc: 0.1881\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.15110 to 0.18810, saving model to /content/saved_models/cifar10_ResNet32v1_model.004.h5\n",
            "Epoch 5/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 1.3719 - acc: 0.5192 - val_loss: 1.7108 - val_acc: 0.4398\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.18810 to 0.43980, saving model to /content/saved_models/cifar10_ResNet32v1_model.005.h5\n",
            "Epoch 6/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 1.2721 - acc: 0.5692 - val_loss: 1.4435 - val_acc: 0.4937\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.43980 to 0.49370, saving model to /content/saved_models/cifar10_ResNet32v1_model.006.h5\n",
            "Epoch 7/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 1.2316 - acc: 0.5784 - val_loss: 2.5135 - val_acc: 0.3416\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.49370\n",
            "Epoch 8/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.1521 - acc: 0.6111 - val_loss: 2.4890 - val_acc: 0.3723\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.49370\n",
            "Epoch 9/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.1211 - acc: 0.6160 - val_loss: 1.4654 - val_acc: 0.5285\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.49370 to 0.52850, saving model to /content/saved_models/cifar10_ResNet32v1_model.009.h5\n",
            "Epoch 10/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.0841 - acc: 0.6277 - val_loss: 1.4693 - val_acc: 0.5430\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.52850 to 0.54300, saving model to /content/saved_models/cifar10_ResNet32v1_model.010.h5\n",
            "Epoch 11/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 1.0559 - acc: 0.6437 - val_loss: 1.5235 - val_acc: 0.5216\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.54300\n",
            "Epoch 12/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 1.0164 - acc: 0.6616 - val_loss: 1.5416 - val_acc: 0.5559\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.54300 to 0.55590, saving model to /content/saved_models/cifar10_ResNet32v1_model.012.h5\n",
            "Epoch 13/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.9809 - acc: 0.6761 - val_loss: 1.4763 - val_acc: 0.5366\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.55590\n",
            "Epoch 14/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.9719 - acc: 0.6792 - val_loss: 1.2907 - val_acc: 0.5951\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.55590 to 0.59510, saving model to /content/saved_models/cifar10_ResNet32v1_model.014.h5\n",
            "Epoch 15/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.9302 - acc: 0.6962 - val_loss: 1.7420 - val_acc: 0.5103\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.59510\n",
            "Epoch 16/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.9324 - acc: 0.6940 - val_loss: 1.5657 - val_acc: 0.5594\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.59510\n",
            "Epoch 17/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.8930 - acc: 0.7080 - val_loss: 1.6859 - val_acc: 0.5660\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.59510\n",
            "Epoch 18/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.8663 - acc: 0.7138 - val_loss: 1.8574 - val_acc: 0.5107\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.59510\n",
            "Epoch 19/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.8595 - acc: 0.7150 - val_loss: 1.5631 - val_acc: 0.5568\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.59510\n",
            "Epoch 20/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.8685 - acc: 0.7200 - val_loss: 1.4054 - val_acc: 0.6051\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.59510 to 0.60510, saving model to /content/saved_models/cifar10_ResNet32v1_model.020.h5\n",
            "Epoch 21/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.8246 - acc: 0.7287 - val_loss: 3.1877 - val_acc: 0.4147\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.60510\n",
            "Epoch 22/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.8215 - acc: 0.7374 - val_loss: 2.0542 - val_acc: 0.5273\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.60510\n",
            "Epoch 23/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.8271 - acc: 0.7302 - val_loss: 1.6116 - val_acc: 0.5815\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.60510\n",
            "Epoch 24/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7758 - acc: 0.7469 - val_loss: 1.1919 - val_acc: 0.6567\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.60510 to 0.65670, saving model to /content/saved_models/cifar10_ResNet32v1_model.024.h5\n",
            "Epoch 25/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7733 - acc: 0.7506 - val_loss: 1.4244 - val_acc: 0.6075\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.65670\n",
            "Epoch 26/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7931 - acc: 0.7466 - val_loss: 1.2490 - val_acc: 0.6380\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.65670\n",
            "Epoch 27/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.7721 - acc: 0.7477 - val_loss: 0.8730 - val_acc: 0.7197\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.65670 to 0.71970, saving model to /content/saved_models/cifar10_ResNet32v1_model.027.h5\n",
            "Epoch 28/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7391 - acc: 0.7652 - val_loss: 1.3001 - val_acc: 0.6130\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.71970\n",
            "Epoch 29/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7569 - acc: 0.7584 - val_loss: 1.1886 - val_acc: 0.6645\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.71970\n",
            "Epoch 30/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7552 - acc: 0.7549 - val_loss: 2.4495 - val_acc: 0.4685\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.71970\n",
            "Epoch 31/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7247 - acc: 0.7659 - val_loss: 1.2323 - val_acc: 0.6473\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.71970\n",
            "Epoch 32/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7212 - acc: 0.7620 - val_loss: 1.9246 - val_acc: 0.5743\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.71970\n",
            "Epoch 33/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6872 - acc: 0.7740 - val_loss: 1.6670 - val_acc: 0.5374\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.71970\n",
            "Epoch 34/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7320 - acc: 0.7630 - val_loss: 1.6776 - val_acc: 0.5623\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.71970\n",
            "Epoch 35/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7109 - acc: 0.7740 - val_loss: 1.4196 - val_acc: 0.5895\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.71970\n",
            "Epoch 36/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7007 - acc: 0.7714 - val_loss: 1.4143 - val_acc: 0.6167\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.71970\n",
            "Epoch 37/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6732 - acc: 0.7799 - val_loss: 1.7636 - val_acc: 0.5860\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.71970\n",
            "Epoch 38/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6878 - acc: 0.7750 - val_loss: 1.5026 - val_acc: 0.6189\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.71970\n",
            "Epoch 39/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6555 - acc: 0.7926 - val_loss: 1.4598 - val_acc: 0.6059\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.71970\n",
            "Epoch 40/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6701 - acc: 0.7868 - val_loss: 1.6271 - val_acc: 0.6131\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.71970\n",
            "Epoch 41/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7050 - acc: 0.7741 - val_loss: 1.0708 - val_acc: 0.6890\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.71970\n",
            "Epoch 42/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6526 - acc: 0.7900 - val_loss: 1.2763 - val_acc: 0.6702\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.71970\n",
            "Epoch 43/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6571 - acc: 0.7854 - val_loss: 1.1273 - val_acc: 0.6869\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.71970\n",
            "Epoch 44/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6184 - acc: 0.8013 - val_loss: 1.6595 - val_acc: 0.5973\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.71970\n",
            "Epoch 45/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6620 - acc: 0.7883 - val_loss: 1.1225 - val_acc: 0.7003\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.71970\n",
            "Epoch 46/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6323 - acc: 0.8009 - val_loss: 1.1074 - val_acc: 0.6824\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.71970\n",
            "Epoch 47/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.6444 - acc: 0.7969 - val_loss: 1.3818 - val_acc: 0.6387\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.71970\n",
            "Epoch 48/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6295 - acc: 0.7976 - val_loss: 1.6746 - val_acc: 0.6121\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.71970\n",
            "Epoch 49/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6731 - acc: 0.7833 - val_loss: 1.4762 - val_acc: 0.6085\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.71970\n",
            "Epoch 50/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6259 - acc: 0.8012 - val_loss: 2.0484 - val_acc: 0.5369\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.71970\n",
            "Epoch 51/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6358 - acc: 0.7940 - val_loss: 1.3493 - val_acc: 0.6614\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.71970\n",
            "Epoch 52/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6448 - acc: 0.7868 - val_loss: 1.8909 - val_acc: 0.5794\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.71970\n",
            "Epoch 53/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6450 - acc: 0.7982 - val_loss: 1.1936 - val_acc: 0.6485\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.71970\n",
            "Epoch 54/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.5862 - acc: 0.8133 - val_loss: 1.0878 - val_acc: 0.6651\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.71970\n",
            "Epoch 55/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6332 - acc: 0.7946 - val_loss: 1.2041 - val_acc: 0.6551\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.71970\n",
            "Epoch 56/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6153 - acc: 0.8039 - val_loss: 1.8265 - val_acc: 0.5328\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.71970\n",
            "Epoch 57/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6227 - acc: 0.8092 - val_loss: 1.6186 - val_acc: 0.5791\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.71970\n",
            "Epoch 58/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6199 - acc: 0.8016 - val_loss: 2.2924 - val_acc: 0.4710\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.71970\n",
            "Epoch 59/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6174 - acc: 0.7964 - val_loss: 1.5858 - val_acc: 0.6104\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.71970\n",
            "Epoch 60/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5778 - acc: 0.8109 - val_loss: 1.5309 - val_acc: 0.5990\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.71970\n",
            "Epoch 61/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6025 - acc: 0.8085 - val_loss: 0.9114 - val_acc: 0.7263\n",
            "\n",
            "Epoch 00061: val_acc improved from 0.71970 to 0.72630, saving model to /content/saved_models/cifar10_ResNet32v1_model.061.h5\n",
            "Epoch 62/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5889 - acc: 0.8127 - val_loss: 1.5682 - val_acc: 0.6317\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.72630\n",
            "Epoch 63/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5694 - acc: 0.8174 - val_loss: 1.1556 - val_acc: 0.6806\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.72630\n",
            "Epoch 64/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5772 - acc: 0.8215 - val_loss: 3.0519 - val_acc: 0.4420\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.72630\n",
            "Epoch 65/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6067 - acc: 0.8101 - val_loss: 1.0299 - val_acc: 0.7065\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.72630\n",
            "Epoch 66/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5914 - acc: 0.8095 - val_loss: 1.7376 - val_acc: 0.5226\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.72630\n",
            "Epoch 67/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6004 - acc: 0.8073 - val_loss: 1.2355 - val_acc: 0.6413\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.72630\n",
            "Epoch 68/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5980 - acc: 0.8099 - val_loss: 1.8713 - val_acc: 0.5833\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.72630\n",
            "Epoch 69/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5780 - acc: 0.8172 - val_loss: 2.6887 - val_acc: 0.4963\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.72630\n",
            "Epoch 70/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5706 - acc: 0.8215 - val_loss: 0.9820 - val_acc: 0.7201\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.72630\n",
            "Epoch 71/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5819 - acc: 0.8131 - val_loss: 2.8270 - val_acc: 0.4576\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.72630\n",
            "Epoch 72/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5574 - acc: 0.8231 - val_loss: 0.9261 - val_acc: 0.7212\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.72630\n",
            "Epoch 73/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5698 - acc: 0.8174 - val_loss: 1.6540 - val_acc: 0.5999\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.72630\n",
            "Epoch 74/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5668 - acc: 0.8210 - val_loss: 1.1362 - val_acc: 0.6671\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.72630\n",
            "Epoch 75/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5734 - acc: 0.8203 - val_loss: 1.9984 - val_acc: 0.5287\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.72630\n",
            "Epoch 76/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5885 - acc: 0.8105 - val_loss: 0.9276 - val_acc: 0.7403\n",
            "\n",
            "Epoch 00076: val_acc improved from 0.72630 to 0.74030, saving model to /content/saved_models/cifar10_ResNet32v1_model.076.h5\n",
            "Epoch 77/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5958 - acc: 0.8109 - val_loss: 1.0806 - val_acc: 0.7116\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.74030\n",
            "Epoch 78/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5676 - acc: 0.8158 - val_loss: 1.5623 - val_acc: 0.5908\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.74030\n",
            "Epoch 79/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5596 - acc: 0.8211 - val_loss: 1.3092 - val_acc: 0.6632\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.74030\n",
            "Epoch 80/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5568 - acc: 0.8262 - val_loss: 1.2624 - val_acc: 0.6517\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.74030\n",
            "Epoch 81/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5418 - acc: 0.8207 - val_loss: 1.0830 - val_acc: 0.6769\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.74030\n",
            "Epoch 82/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5736 - acc: 0.8229 - val_loss: 1.0063 - val_acc: 0.7208\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.74030\n",
            "Epoch 83/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5448 - acc: 0.8264 - val_loss: 1.2420 - val_acc: 0.6725\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.74030\n",
            "Epoch 84/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5478 - acc: 0.8260 - val_loss: 2.9566 - val_acc: 0.4784\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.74030\n",
            "Epoch 85/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5567 - acc: 0.8209 - val_loss: 1.4362 - val_acc: 0.6246\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.74030\n",
            "Epoch 86/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5660 - acc: 0.8225 - val_loss: 1.9088 - val_acc: 0.5514\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.74030\n",
            "Epoch 87/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5562 - acc: 0.8246 - val_loss: 0.7967 - val_acc: 0.7493\n",
            "\n",
            "Epoch 00087: val_acc improved from 0.74030 to 0.74930, saving model to /content/saved_models/cifar10_ResNet32v1_model.087.h5\n",
            "Epoch 88/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5449 - acc: 0.8272 - val_loss: 1.6223 - val_acc: 0.6238\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.74930\n",
            "Epoch 89/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5395 - acc: 0.8240 - val_loss: 1.0713 - val_acc: 0.6935\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.74930\n",
            "Epoch 90/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5230 - acc: 0.8375 - val_loss: 2.2110 - val_acc: 0.5531\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.74930\n",
            "Epoch 91/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5379 - acc: 0.8346 - val_loss: 1.4868 - val_acc: 0.6611\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.74930\n",
            "Epoch 92/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5422 - acc: 0.8316 - val_loss: 1.3350 - val_acc: 0.6431\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.74930\n",
            "Epoch 93/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5162 - acc: 0.8371 - val_loss: 1.5340 - val_acc: 0.5713\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.74930\n",
            "Epoch 94/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5414 - acc: 0.8331 - val_loss: 1.0361 - val_acc: 0.6941\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.74930\n",
            "Epoch 95/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5331 - acc: 0.8350 - val_loss: 0.9382 - val_acc: 0.7254\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.74930\n",
            "Epoch 96/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5343 - acc: 0.8353 - val_loss: 1.4428 - val_acc: 0.6097\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.74930\n",
            "Epoch 97/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5562 - acc: 0.8293 - val_loss: 0.9032 - val_acc: 0.7141\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.74930\n",
            "Epoch 98/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5417 - acc: 0.8281 - val_loss: 0.8951 - val_acc: 0.7556\n",
            "\n",
            "Epoch 00098: val_acc improved from 0.74930 to 0.75560, saving model to /content/saved_models/cifar10_ResNet32v1_model.098.h5\n",
            "Epoch 99/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5134 - acc: 0.8402 - val_loss: 1.9917 - val_acc: 0.5209\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.75560\n",
            "Epoch 100/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5284 - acc: 0.8311 - val_loss: 1.6336 - val_acc: 0.6290\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.75560\n",
            "Epoch 101/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5437 - acc: 0.8332 - val_loss: 1.7284 - val_acc: 0.6006\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.75560\n",
            "Epoch 102/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5429 - acc: 0.8277 - val_loss: 1.2683 - val_acc: 0.6841\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.75560\n",
            "Epoch 103/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5220 - acc: 0.8302 - val_loss: 1.1728 - val_acc: 0.6649\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.75560\n",
            "Epoch 104/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5835 - acc: 0.8107 - val_loss: 1.0791 - val_acc: 0.7115\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.75560\n",
            "Epoch 105/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4976 - acc: 0.8449 - val_loss: 1.4686 - val_acc: 0.6220\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.75560\n",
            "Epoch 106/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5309 - acc: 0.8298 - val_loss: 0.9090 - val_acc: 0.7370\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.75560\n",
            "Epoch 107/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5108 - acc: 0.8407 - val_loss: 1.2533 - val_acc: 0.6687\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.75560\n",
            "Epoch 108/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5587 - acc: 0.8250 - val_loss: 4.9938 - val_acc: 0.2735\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.75560\n",
            "Epoch 109/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5255 - acc: 0.8355 - val_loss: 1.3709 - val_acc: 0.6401\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.75560\n",
            "Epoch 110/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5310 - acc: 0.8282 - val_loss: 1.0710 - val_acc: 0.6945\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.75560\n",
            "Epoch 111/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5304 - acc: 0.8338 - val_loss: 1.1143 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.75560\n",
            "Epoch 112/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5156 - acc: 0.8403 - val_loss: 0.7581 - val_acc: 0.7762\n",
            "\n",
            "Epoch 00112: val_acc improved from 0.75560 to 0.77620, saving model to /content/saved_models/cifar10_ResNet32v1_model.112.h5\n",
            "Epoch 113/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5157 - acc: 0.8373 - val_loss: 0.8440 - val_acc: 0.7530\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.77620\n",
            "Epoch 114/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5140 - acc: 0.8387 - val_loss: 1.0127 - val_acc: 0.7106\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.77620\n",
            "Epoch 115/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5258 - acc: 0.8317 - val_loss: 1.2680 - val_acc: 0.6524\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.77620\n",
            "Epoch 116/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5012 - acc: 0.8403 - val_loss: 0.9600 - val_acc: 0.7266\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.77620\n",
            "Epoch 117/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5143 - acc: 0.8426 - val_loss: 0.8323 - val_acc: 0.7664\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.77620\n",
            "Epoch 118/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5246 - acc: 0.8312 - val_loss: 0.8759 - val_acc: 0.7460\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.77620\n",
            "Epoch 119/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5408 - acc: 0.8284 - val_loss: 1.2843 - val_acc: 0.6678\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.77620\n",
            "Epoch 120/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5187 - acc: 0.8377 - val_loss: 2.3948 - val_acc: 0.5495\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.77620\n",
            "Epoch 121/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4964 - acc: 0.8471 - val_loss: 1.8127 - val_acc: 0.5790\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.77620\n",
            "Epoch 122/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5107 - acc: 0.8477 - val_loss: 0.8622 - val_acc: 0.7526\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.77620\n",
            "Epoch 123/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5163 - acc: 0.8399 - val_loss: 0.9296 - val_acc: 0.7338\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.77620\n",
            "Epoch 124/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5323 - acc: 0.8350 - val_loss: 2.9160 - val_acc: 0.4695\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.77620\n",
            "Epoch 125/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4995 - acc: 0.8502 - val_loss: 0.9948 - val_acc: 0.7326\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.77620\n",
            "Epoch 126/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5127 - acc: 0.8375 - val_loss: 1.1612 - val_acc: 0.6781\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.77620\n",
            "Epoch 127/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4967 - acc: 0.8438 - val_loss: 0.9416 - val_acc: 0.7064\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.77620\n",
            "Epoch 128/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5127 - acc: 0.8406 - val_loss: 1.0388 - val_acc: 0.6972\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.77620\n",
            "Epoch 129/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4968 - acc: 0.8444 - val_loss: 0.8895 - val_acc: 0.7446\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.77620\n",
            "Epoch 130/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4905 - acc: 0.8429 - val_loss: 1.4403 - val_acc: 0.6326\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.77620\n",
            "Epoch 131/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5055 - acc: 0.8497 - val_loss: 1.2550 - val_acc: 0.6494\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.77620\n",
            "Epoch 132/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4673 - acc: 0.8515 - val_loss: 0.9410 - val_acc: 0.7311\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.77620\n",
            "Epoch 133/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4999 - acc: 0.8497 - val_loss: 2.0108 - val_acc: 0.5949\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.77620\n",
            "Epoch 134/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5094 - acc: 0.8461 - val_loss: 0.9193 - val_acc: 0.7426\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.77620\n",
            "Epoch 135/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4944 - acc: 0.8443 - val_loss: 1.1573 - val_acc: 0.6653\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.77620\n",
            "Epoch 136/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4961 - acc: 0.8531 - val_loss: 1.6696 - val_acc: 0.6316\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.77620\n",
            "Epoch 137/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5035 - acc: 0.8429 - val_loss: 1.1330 - val_acc: 0.6741\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.77620\n",
            "Epoch 138/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5330 - acc: 0.8299 - val_loss: 0.7480 - val_acc: 0.7835\n",
            "\n",
            "Epoch 00138: val_acc improved from 0.77620 to 0.78350, saving model to /content/saved_models/cifar10_ResNet32v1_model.138.h5\n",
            "Epoch 139/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5162 - acc: 0.8363 - val_loss: 0.7461 - val_acc: 0.7711\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.78350\n",
            "Epoch 140/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4956 - acc: 0.8403 - val_loss: 0.7107 - val_acc: 0.7856\n",
            "\n",
            "Epoch 00140: val_acc improved from 0.78350 to 0.78560, saving model to /content/saved_models/cifar10_ResNet32v1_model.140.h5\n",
            "Epoch 141/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5255 - acc: 0.8329 - val_loss: 1.1373 - val_acc: 0.6798\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.78560\n",
            "Epoch 142/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4922 - acc: 0.8457 - val_loss: 1.3883 - val_acc: 0.6009\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.78560\n",
            "Epoch 143/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4889 - acc: 0.8488 - val_loss: 0.8979 - val_acc: 0.7516\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.78560\n",
            "Epoch 144/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4968 - acc: 0.8447 - val_loss: 3.3859 - val_acc: 0.4211\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.78560\n",
            "Epoch 145/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5007 - acc: 0.8426 - val_loss: 1.8408 - val_acc: 0.6066\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.78560\n",
            "Epoch 146/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4954 - acc: 0.8446 - val_loss: 1.0400 - val_acc: 0.7117\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.78560\n",
            "Epoch 147/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4674 - acc: 0.8543 - val_loss: 3.5054 - val_acc: 0.4147\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.78560\n",
            "Epoch 148/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5224 - acc: 0.8370 - val_loss: 1.0234 - val_acc: 0.7193\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.78560\n",
            "Epoch 149/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4975 - acc: 0.8448 - val_loss: 0.9179 - val_acc: 0.7208\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.78560\n",
            "Epoch 150/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4663 - acc: 0.8564 - val_loss: 1.2353 - val_acc: 0.6809\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.78560\n",
            "Epoch 151/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4664 - acc: 0.8492 - val_loss: 1.3795 - val_acc: 0.6517\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.78560\n",
            "Epoch 152/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4963 - acc: 0.8460 - val_loss: 1.0176 - val_acc: 0.7136\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.78560\n",
            "Epoch 153/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4907 - acc: 0.8496 - val_loss: 0.9585 - val_acc: 0.7259\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.78560\n",
            "Epoch 154/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4794 - acc: 0.8476 - val_loss: 0.8010 - val_acc: 0.7689\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.78560\n",
            "Epoch 155/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4750 - acc: 0.8533 - val_loss: 1.3888 - val_acc: 0.6359\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.78560\n",
            "Epoch 156/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4952 - acc: 0.8477 - val_loss: 1.0177 - val_acc: 0.7152\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.78560\n",
            "Epoch 157/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4842 - acc: 0.8486 - val_loss: 1.9893 - val_acc: 0.5689\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.78560\n",
            "Epoch 158/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4907 - acc: 0.8413 - val_loss: 1.1089 - val_acc: 0.6956\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.78560\n",
            "Epoch 159/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4845 - acc: 0.8491 - val_loss: 0.6824 - val_acc: 0.7865\n",
            "\n",
            "Epoch 00159: val_acc improved from 0.78560 to 0.78650, saving model to /content/saved_models/cifar10_ResNet32v1_model.159.h5\n",
            "Epoch 160/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4982 - acc: 0.8435 - val_loss: 1.4189 - val_acc: 0.6348\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.78650\n",
            "Epoch 161/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4674 - acc: 0.8540 - val_loss: 1.1458 - val_acc: 0.6728\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.78650\n",
            "Epoch 162/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5019 - acc: 0.8453 - val_loss: 1.4148 - val_acc: 0.6454\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.78650\n",
            "Epoch 163/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5022 - acc: 0.8446 - val_loss: 0.7108 - val_acc: 0.7831\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.78650\n",
            "Epoch 164/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4857 - acc: 0.8495 - val_loss: 1.0084 - val_acc: 0.7039\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.78650\n",
            "Epoch 165/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4641 - acc: 0.8579 - val_loss: 1.0368 - val_acc: 0.7212\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.78650\n",
            "Epoch 166/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4681 - acc: 0.8561 - val_loss: 1.1399 - val_acc: 0.6746\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.78650\n",
            "Epoch 167/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4913 - acc: 0.8468 - val_loss: 1.0235 - val_acc: 0.7090\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.78650\n",
            "Epoch 168/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4931 - acc: 0.8488 - val_loss: 2.0403 - val_acc: 0.5352\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.78650\n",
            "Epoch 169/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4649 - acc: 0.8545 - val_loss: 1.1442 - val_acc: 0.6885\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.78650\n",
            "Epoch 170/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4872 - acc: 0.8506 - val_loss: 0.7954 - val_acc: 0.7644\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.78650\n",
            "Epoch 171/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4758 - acc: 0.8489 - val_loss: 0.9449 - val_acc: 0.7392\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.78650\n",
            "Epoch 172/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4665 - acc: 0.8527 - val_loss: 0.7329 - val_acc: 0.7754\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.78650\n",
            "Epoch 173/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4630 - acc: 0.8567 - val_loss: 1.0774 - val_acc: 0.7046\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.78650\n",
            "Epoch 174/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4890 - acc: 0.8456 - val_loss: 0.9698 - val_acc: 0.7255\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.78650\n",
            "Epoch 175/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4890 - acc: 0.8526 - val_loss: 0.7724 - val_acc: 0.7713\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.78650\n",
            "Epoch 176/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4636 - acc: 0.8557 - val_loss: 1.3550 - val_acc: 0.6435\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.78650\n",
            "Epoch 177/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4730 - acc: 0.8559 - val_loss: 1.4186 - val_acc: 0.6795\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.78650\n",
            "Epoch 178/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4831 - acc: 0.8523 - val_loss: 1.0302 - val_acc: 0.6967\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.78650\n",
            "Epoch 179/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4663 - acc: 0.8611 - val_loss: 2.0261 - val_acc: 0.5891\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.78650\n",
            "Epoch 180/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4634 - acc: 0.8612 - val_loss: 0.8430 - val_acc: 0.7554\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.78650\n",
            "Epoch 181/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4708 - acc: 0.8508 - val_loss: 1.1855 - val_acc: 0.6782\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.78650\n",
            "Epoch 182/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4594 - acc: 0.8581 - val_loss: 1.0836 - val_acc: 0.7102\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.78650\n",
            "Epoch 183/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4540 - acc: 0.8611 - val_loss: 0.7801 - val_acc: 0.7782\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.78650\n",
            "Epoch 184/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4680 - acc: 0.8624 - val_loss: 1.2117 - val_acc: 0.6932\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.78650\n",
            "Epoch 185/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4523 - acc: 0.8588 - val_loss: 1.1248 - val_acc: 0.6787\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.78650\n",
            "Epoch 186/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4674 - acc: 0.8605 - val_loss: 0.9997 - val_acc: 0.7331\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.78650\n",
            "Epoch 187/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4682 - acc: 0.8506 - val_loss: 1.2519 - val_acc: 0.6760\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.78650\n",
            "Epoch 188/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4905 - acc: 0.8481 - val_loss: 0.8288 - val_acc: 0.7418\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.78650\n",
            "Epoch 189/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4315 - acc: 0.8716 - val_loss: 1.7520 - val_acc: 0.6337\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.78650\n",
            "Epoch 190/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4634 - acc: 0.8615 - val_loss: 2.4953 - val_acc: 0.5063\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.78650\n",
            "Epoch 191/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4822 - acc: 0.8522 - val_loss: 1.2226 - val_acc: 0.6605\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.78650\n",
            "Epoch 192/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4648 - acc: 0.8556 - val_loss: 1.3906 - val_acc: 0.6735\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.78650\n",
            "Epoch 193/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4698 - acc: 0.8511 - val_loss: 0.9075 - val_acc: 0.7332\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.78650\n",
            "Epoch 194/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4792 - acc: 0.8443 - val_loss: 1.1028 - val_acc: 0.7055\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.78650\n",
            "Epoch 195/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4965 - acc: 0.8427 - val_loss: 1.1554 - val_acc: 0.6602\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.78650\n",
            "Epoch 196/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4840 - acc: 0.8508 - val_loss: 0.7874 - val_acc: 0.7646\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.78650\n",
            "Epoch 197/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4745 - acc: 0.8516 - val_loss: 0.8169 - val_acc: 0.7584\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.78650\n",
            "Epoch 198/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4808 - acc: 0.8534 - val_loss: 1.2003 - val_acc: 0.6760\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.78650\n",
            "Epoch 199/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4722 - acc: 0.8508 - val_loss: 0.9741 - val_acc: 0.7358\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.78650\n",
            "Epoch 200/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4654 - acc: 0.8555 - val_loss: 1.2830 - val_acc: 0.6245\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.78650\n",
            "Epoch 201/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4894 - acc: 0.8512 - val_loss: 0.7985 - val_acc: 0.7538\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.78650\n",
            "Epoch 202/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4574 - acc: 0.8641 - val_loss: 1.2284 - val_acc: 0.6923\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.78650\n",
            "Epoch 203/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4505 - acc: 0.8605 - val_loss: 0.9800 - val_acc: 0.7339\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.78650\n",
            "Epoch 204/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4679 - acc: 0.8551 - val_loss: 0.9153 - val_acc: 0.7550\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.78650\n",
            "Epoch 205/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4589 - acc: 0.8608 - val_loss: 1.0556 - val_acc: 0.7173\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.78650\n",
            "Epoch 206/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4481 - acc: 0.8611 - val_loss: 1.1211 - val_acc: 0.6854\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.78650\n",
            "Epoch 207/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4630 - acc: 0.8631 - val_loss: 1.2782 - val_acc: 0.6652\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.78650\n",
            "Epoch 208/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4638 - acc: 0.8554 - val_loss: 1.8457 - val_acc: 0.5658\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.78650\n",
            "Epoch 209/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4524 - acc: 0.8589 - val_loss: 0.9270 - val_acc: 0.7110\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.78650\n",
            "Epoch 210/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4331 - acc: 0.8717 - val_loss: 1.2317 - val_acc: 0.6831\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.78650\n",
            "Epoch 211/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4705 - acc: 0.8550 - val_loss: 1.0203 - val_acc: 0.7187\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.78650\n",
            "Epoch 212/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4514 - acc: 0.8601 - val_loss: 0.6992 - val_acc: 0.7898\n",
            "\n",
            "Epoch 00212: val_acc improved from 0.78650 to 0.78980, saving model to /content/saved_models/cifar10_ResNet32v1_model.212.h5\n",
            "Epoch 213/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4846 - acc: 0.8472 - val_loss: 0.8174 - val_acc: 0.7632\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.78980\n",
            "Epoch 214/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4568 - acc: 0.8555 - val_loss: 0.7979 - val_acc: 0.7645\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.78980\n",
            "Epoch 215/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4675 - acc: 0.8540 - val_loss: 1.3549 - val_acc: 0.6309\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.78980\n",
            "Epoch 216/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4601 - acc: 0.8554 - val_loss: 1.1142 - val_acc: 0.6919\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.78980\n",
            "Epoch 217/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4526 - acc: 0.8659 - val_loss: 0.9376 - val_acc: 0.7545\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.78980\n",
            "Epoch 218/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4457 - acc: 0.8587 - val_loss: 0.6351 - val_acc: 0.8056\n",
            "\n",
            "Epoch 00218: val_acc improved from 0.78980 to 0.80560, saving model to /content/saved_models/cifar10_ResNet32v1_model.218.h5\n",
            "Epoch 219/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4419 - acc: 0.8720 - val_loss: 0.9955 - val_acc: 0.7100\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.80560\n",
            "Epoch 220/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4626 - acc: 0.8564 - val_loss: 1.5445 - val_acc: 0.6406\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.80560\n",
            "Epoch 221/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4649 - acc: 0.8566 - val_loss: 0.8820 - val_acc: 0.7401\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.80560\n",
            "Epoch 222/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4443 - acc: 0.8644 - val_loss: 1.0887 - val_acc: 0.6962\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.80560\n",
            "Epoch 223/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4395 - acc: 0.8636 - val_loss: 0.9030 - val_acc: 0.7369\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.80560\n",
            "Epoch 224/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4653 - acc: 0.8540 - val_loss: 0.9219 - val_acc: 0.7387\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.80560\n",
            "Epoch 225/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4527 - acc: 0.8590 - val_loss: 1.9765 - val_acc: 0.5559\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.80560\n",
            "Epoch 226/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4749 - acc: 0.8568 - val_loss: 1.5506 - val_acc: 0.6117\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.80560\n",
            "Epoch 227/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4510 - acc: 0.8599 - val_loss: 1.2464 - val_acc: 0.6678\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.80560\n",
            "Epoch 228/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4525 - acc: 0.8616 - val_loss: 1.3055 - val_acc: 0.6336\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.80560\n",
            "Epoch 229/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4574 - acc: 0.8585 - val_loss: 1.9682 - val_acc: 0.5474\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.80560\n",
            "Epoch 230/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4772 - acc: 0.8565 - val_loss: 1.1374 - val_acc: 0.6724\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.80560\n",
            "Epoch 231/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4705 - acc: 0.8597 - val_loss: 0.8475 - val_acc: 0.7515\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.80560\n",
            "Epoch 232/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4357 - acc: 0.8648 - val_loss: 1.5153 - val_acc: 0.6498\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.80560\n",
            "Epoch 233/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4243 - acc: 0.8694 - val_loss: 1.1923 - val_acc: 0.6878\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.80560\n",
            "Epoch 234/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4694 - acc: 0.8508 - val_loss: 1.3803 - val_acc: 0.6852\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.80560\n",
            "Epoch 235/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4555 - acc: 0.8613 - val_loss: 0.9798 - val_acc: 0.7357\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.80560\n",
            "Epoch 236/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4829 - acc: 0.8580 - val_loss: 0.8357 - val_acc: 0.7580\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.80560\n",
            "Epoch 237/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4436 - acc: 0.8604 - val_loss: 0.8688 - val_acc: 0.7406\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.80560\n",
            "Epoch 238/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4440 - acc: 0.8650 - val_loss: 0.8652 - val_acc: 0.7645\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.80560\n",
            "Epoch 239/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4488 - acc: 0.8626 - val_loss: 1.0672 - val_acc: 0.7100\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.80560\n",
            "Epoch 240/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4318 - acc: 0.8696 - val_loss: 1.2739 - val_acc: 0.6580\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.80560\n",
            "Epoch 241/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4703 - acc: 0.8502 - val_loss: 0.7988 - val_acc: 0.7678\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.80560\n",
            "Epoch 242/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4421 - acc: 0.8660 - val_loss: 1.1033 - val_acc: 0.7132\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.80560\n",
            "Epoch 243/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4434 - acc: 0.8669 - val_loss: 2.6673 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.80560\n",
            "Epoch 244/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4537 - acc: 0.8624 - val_loss: 1.5659 - val_acc: 0.5881\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.80560\n",
            "Epoch 245/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4602 - acc: 0.8606 - val_loss: 1.1321 - val_acc: 0.7012\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.80560\n",
            "Epoch 246/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4461 - acc: 0.8603 - val_loss: 1.1912 - val_acc: 0.6669\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.80560\n",
            "Epoch 247/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4354 - acc: 0.8596 - val_loss: 1.3899 - val_acc: 0.6901\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.80560\n",
            "Epoch 248/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4548 - acc: 0.8589 - val_loss: 1.9470 - val_acc: 0.5422\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.80560\n",
            "Epoch 249/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4489 - acc: 0.8642 - val_loss: 1.1480 - val_acc: 0.6952\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.80560\n",
            "Epoch 250/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4304 - acc: 0.8706 - val_loss: 0.9474 - val_acc: 0.7427\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.80560\n",
            "Epoch 251/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4572 - acc: 0.8620 - val_loss: 0.7951 - val_acc: 0.7610\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.80560\n",
            "Epoch 252/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4355 - acc: 0.8720 - val_loss: 0.9395 - val_acc: 0.7195\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.80560\n",
            "Epoch 253/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4466 - acc: 0.8629 - val_loss: 1.1292 - val_acc: 0.6813\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.80560\n",
            "Epoch 254/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4490 - acc: 0.8667 - val_loss: 0.9680 - val_acc: 0.7244\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.80560\n",
            "Epoch 255/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4389 - acc: 0.8708 - val_loss: 1.2166 - val_acc: 0.6540\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.80560\n",
            "Epoch 256/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4426 - acc: 0.8652 - val_loss: 1.0656 - val_acc: 0.7031\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.80560\n",
            "Epoch 257/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4677 - acc: 0.8586 - val_loss: 1.3986 - val_acc: 0.6350\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.80560\n",
            "Epoch 258/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4510 - acc: 0.8623 - val_loss: 0.9321 - val_acc: 0.7227\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.80560\n",
            "Epoch 259/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4411 - acc: 0.8630 - val_loss: 0.7525 - val_acc: 0.7783\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.80560\n",
            "Epoch 260/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4552 - acc: 0.8587 - val_loss: 0.8367 - val_acc: 0.7510\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.80560\n",
            "Epoch 261/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4501 - acc: 0.8644 - val_loss: 0.9961 - val_acc: 0.7354\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.80560\n",
            "Epoch 262/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4451 - acc: 0.8625 - val_loss: 1.1925 - val_acc: 0.6718\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.80560\n",
            "Epoch 263/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4233 - acc: 0.8689 - val_loss: 1.4398 - val_acc: 0.6720\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.80560\n",
            "Epoch 264/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4539 - acc: 0.8609 - val_loss: 1.0997 - val_acc: 0.7277\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.80560\n",
            "Epoch 265/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4275 - acc: 0.8716 - val_loss: 1.6534 - val_acc: 0.5978\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.80560\n",
            "Epoch 266/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4304 - acc: 0.8675 - val_loss: 0.7441 - val_acc: 0.7691\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.80560\n",
            "Epoch 267/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4455 - acc: 0.8658 - val_loss: 1.3156 - val_acc: 0.6797\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.80560\n",
            "Epoch 268/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4370 - acc: 0.8701 - val_loss: 1.1202 - val_acc: 0.7019\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.80560\n",
            "Epoch 269/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4446 - acc: 0.8659 - val_loss: 0.9763 - val_acc: 0.7286\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.80560\n",
            "Epoch 270/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4442 - acc: 0.8626 - val_loss: 1.0098 - val_acc: 0.7156\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.80560\n",
            "Epoch 271/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4366 - acc: 0.8670 - val_loss: 2.1920 - val_acc: 0.5306\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.80560\n",
            "Epoch 272/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4381 - acc: 0.8700 - val_loss: 1.6539 - val_acc: 0.5931\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.80560\n",
            "Epoch 273/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4379 - acc: 0.8665 - val_loss: 1.3009 - val_acc: 0.6843\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.80560\n",
            "Epoch 274/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4308 - acc: 0.8638 - val_loss: 1.3837 - val_acc: 0.6526\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.80560\n",
            "Epoch 275/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4423 - acc: 0.8655 - val_loss: 1.9175 - val_acc: 0.5220\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.80560\n",
            "Epoch 276/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4220 - acc: 0.8763 - val_loss: 1.1674 - val_acc: 0.6870\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.80560\n",
            "Epoch 277/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4449 - acc: 0.8650 - val_loss: 0.9038 - val_acc: 0.7472\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.80560\n",
            "Epoch 278/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4274 - acc: 0.8737 - val_loss: 1.1657 - val_acc: 0.7004\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.80560\n",
            "Epoch 279/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4301 - acc: 0.8693 - val_loss: 1.3126 - val_acc: 0.6632\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.80560\n",
            "Epoch 280/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4337 - acc: 0.8660 - val_loss: 0.7526 - val_acc: 0.7860\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.80560\n",
            "Epoch 281/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4290 - acc: 0.8652 - val_loss: 0.7950 - val_acc: 0.7625\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.80560\n",
            "Epoch 282/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4369 - acc: 0.8646 - val_loss: 0.8883 - val_acc: 0.7520\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.80560\n",
            "Epoch 283/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4234 - acc: 0.8729 - val_loss: 1.3827 - val_acc: 0.6584\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.80560\n",
            "Epoch 284/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4468 - acc: 0.8641 - val_loss: 0.9741 - val_acc: 0.7238\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.80560\n",
            "Epoch 285/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4392 - acc: 0.8630 - val_loss: 1.1753 - val_acc: 0.6896\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.80560\n",
            "Epoch 286/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4422 - acc: 0.8620 - val_loss: 1.9851 - val_acc: 0.5790\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.80560\n",
            "Epoch 287/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4663 - acc: 0.8546 - val_loss: 0.8918 - val_acc: 0.7523\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.80560\n",
            "Epoch 288/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4133 - acc: 0.8736 - val_loss: 0.9592 - val_acc: 0.7283\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.80560\n",
            "Epoch 289/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4434 - acc: 0.8661 - val_loss: 1.2871 - val_acc: 0.6789\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.80560\n",
            "Epoch 290/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4320 - acc: 0.8692 - val_loss: 0.6702 - val_acc: 0.7973\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.80560\n",
            "Epoch 291/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4304 - acc: 0.8718 - val_loss: 0.8889 - val_acc: 0.7565\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.80560\n",
            "Epoch 292/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4253 - acc: 0.8707 - val_loss: 0.9012 - val_acc: 0.7310\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.80560\n",
            "Epoch 293/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4395 - acc: 0.8708 - val_loss: 0.9524 - val_acc: 0.7349\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.80560\n",
            "Epoch 294/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4566 - acc: 0.8576 - val_loss: 1.2981 - val_acc: 0.6541\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.80560\n",
            "Epoch 295/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4491 - acc: 0.8611 - val_loss: 1.2677 - val_acc: 0.6637\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.80560\n",
            "Epoch 296/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4521 - acc: 0.8686 - val_loss: 1.2379 - val_acc: 0.6761\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.80560\n",
            "Epoch 297/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4507 - acc: 0.8613 - val_loss: 1.0793 - val_acc: 0.7189\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.80560\n",
            "Epoch 298/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4459 - acc: 0.8620 - val_loss: 1.4759 - val_acc: 0.6374\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.80560\n",
            "Epoch 299/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4330 - acc: 0.8697 - val_loss: 1.0431 - val_acc: 0.7116\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.80560\n",
            "Epoch 300/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4429 - acc: 0.8628 - val_loss: 1.3420 - val_acc: 0.6546\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.80560\n",
            "Epoch 301/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4331 - acc: 0.8653 - val_loss: 0.9842 - val_acc: 0.7104\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.80560\n",
            "Epoch 302/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.4376 - acc: 0.8709 - val_loss: 0.7333 - val_acc: 0.7771\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.80560\n",
            "Epoch 303/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4436 - acc: 0.8656 - val_loss: 1.1645 - val_acc: 0.6815\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.80560\n",
            "Epoch 304/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4278 - acc: 0.8727 - val_loss: 1.1825 - val_acc: 0.6920\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.80560\n",
            "Epoch 305/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4537 - acc: 0.8641 - val_loss: 0.7038 - val_acc: 0.7949\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.80560\n",
            "Epoch 306/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4330 - acc: 0.8639 - val_loss: 0.9108 - val_acc: 0.7481\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.80560\n",
            "Epoch 307/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4351 - acc: 0.8658 - val_loss: 0.7427 - val_acc: 0.7682\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.80560\n",
            "Epoch 308/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4268 - acc: 0.8677 - val_loss: 1.0026 - val_acc: 0.7138\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.80560\n",
            "Epoch 309/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4377 - acc: 0.8660 - val_loss: 0.8039 - val_acc: 0.7632\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.80560\n",
            "Epoch 310/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4278 - acc: 0.8717 - val_loss: 0.8997 - val_acc: 0.7308\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.80560\n",
            "Epoch 311/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4347 - acc: 0.8725 - val_loss: 0.7335 - val_acc: 0.7748\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.80560\n",
            "Epoch 312/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4153 - acc: 0.8770 - val_loss: 0.8523 - val_acc: 0.7499\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.80560\n",
            "Epoch 313/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4147 - acc: 0.8775 - val_loss: 2.0113 - val_acc: 0.5671\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.80560\n",
            "Epoch 314/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4504 - acc: 0.8653 - val_loss: 1.0327 - val_acc: 0.7125\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.80560\n",
            "Epoch 315/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4287 - acc: 0.8736 - val_loss: 1.0378 - val_acc: 0.7137\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.80560\n",
            "Epoch 316/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4235 - acc: 0.8707 - val_loss: 1.0142 - val_acc: 0.7216\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.80560\n",
            "Epoch 317/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4263 - acc: 0.8726 - val_loss: 1.1437 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.80560\n",
            "Epoch 318/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4425 - acc: 0.8654 - val_loss: 1.3721 - val_acc: 0.6678\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.80560\n",
            "Epoch 319/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3987 - acc: 0.8850 - val_loss: 1.0385 - val_acc: 0.6902\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.80560\n",
            "Epoch 320/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4461 - acc: 0.8642 - val_loss: 0.9304 - val_acc: 0.7165\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.80560\n",
            "Epoch 321/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4339 - acc: 0.8678 - val_loss: 1.0937 - val_acc: 0.7163\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.80560\n",
            "Epoch 322/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4508 - acc: 0.8585 - val_loss: 1.3187 - val_acc: 0.6380\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.80560\n",
            "Epoch 323/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4199 - acc: 0.8752 - val_loss: 0.9055 - val_acc: 0.7470\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.80560\n",
            "Epoch 324/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4261 - acc: 0.8725 - val_loss: 2.2059 - val_acc: 0.4974\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.80560\n",
            "Epoch 325/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4157 - acc: 0.8769 - val_loss: 1.6234 - val_acc: 0.6505\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.80560\n",
            "Epoch 326/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4421 - acc: 0.8599 - val_loss: 1.4212 - val_acc: 0.6859\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.80560\n",
            "Epoch 327/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4378 - acc: 0.8637 - val_loss: 0.6179 - val_acc: 0.8249\n",
            "\n",
            "Epoch 00327: val_acc improved from 0.80560 to 0.82490, saving model to /content/saved_models/cifar10_ResNet32v1_model.327.h5\n",
            "Epoch 328/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4570 - acc: 0.8583 - val_loss: 1.1534 - val_acc: 0.6616\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.82490\n",
            "Epoch 329/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4300 - acc: 0.8621 - val_loss: 1.0686 - val_acc: 0.7207\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.82490\n",
            "Epoch 330/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4438 - acc: 0.8657 - val_loss: 1.1930 - val_acc: 0.6928\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.82490\n",
            "Epoch 331/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4445 - acc: 0.8689 - val_loss: 2.4978 - val_acc: 0.5173\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.82490\n",
            "Epoch 332/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4298 - acc: 0.8677 - val_loss: 2.0504 - val_acc: 0.5125\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.82490\n",
            "Epoch 333/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4311 - acc: 0.8663 - val_loss: 1.4010 - val_acc: 0.6457\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.82490\n",
            "Epoch 334/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4139 - acc: 0.8724 - val_loss: 0.8333 - val_acc: 0.7697\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.82490\n",
            "Epoch 335/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4323 - acc: 0.8640 - val_loss: 0.6387 - val_acc: 0.8101\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.82490\n",
            "Epoch 336/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4217 - acc: 0.8742 - val_loss: 1.3381 - val_acc: 0.6328\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.82490\n",
            "Epoch 337/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4495 - acc: 0.8633 - val_loss: 1.1482 - val_acc: 0.6834\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.82490\n",
            "Epoch 338/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.4320 - acc: 0.8718 - val_loss: 1.2635 - val_acc: 0.6669\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.82490\n",
            "Epoch 339/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4413 - acc: 0.8697 - val_loss: 0.9920 - val_acc: 0.7167\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.82490\n",
            "Epoch 340/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4112 - acc: 0.8785 - val_loss: 1.2122 - val_acc: 0.6957\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.82490\n",
            "Epoch 341/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4420 - acc: 0.8685 - val_loss: 0.6683 - val_acc: 0.7936\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.82490\n",
            "Epoch 342/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4321 - acc: 0.8701 - val_loss: 0.6893 - val_acc: 0.7937\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.82490\n",
            "Epoch 343/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.4159 - acc: 0.8733 - val_loss: 1.4930 - val_acc: 0.6440\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.82490\n",
            "Epoch 344/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4426 - acc: 0.8668 - val_loss: 2.0236 - val_acc: 0.5773\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.82490\n",
            "Epoch 345/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4295 - acc: 0.8723 - val_loss: 1.1873 - val_acc: 0.6737\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.82490\n",
            "Epoch 346/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4231 - acc: 0.8716 - val_loss: 0.8405 - val_acc: 0.7591\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.82490\n",
            "Epoch 347/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4200 - acc: 0.8718 - val_loss: 1.0004 - val_acc: 0.7215\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.82490\n",
            "Epoch 348/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4523 - acc: 0.8706 - val_loss: 0.8324 - val_acc: 0.7644\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.82490\n",
            "Epoch 349/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4284 - acc: 0.8701 - val_loss: 1.2706 - val_acc: 0.6862\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.82490\n",
            "Epoch 350/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4258 - acc: 0.8709 - val_loss: 1.7743 - val_acc: 0.6280\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.82490\n",
            "Epoch 351/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4441 - acc: 0.8602 - val_loss: 1.7968 - val_acc: 0.5659\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.82490\n",
            "Epoch 352/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4187 - acc: 0.8814 - val_loss: 0.8423 - val_acc: 0.7592\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.82490\n",
            "Epoch 353/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4097 - acc: 0.8697 - val_loss: 1.0106 - val_acc: 0.7299\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.82490\n",
            "Epoch 354/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4050 - acc: 0.8814 - val_loss: 0.7254 - val_acc: 0.7806\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.82490\n",
            "Epoch 355/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4372 - acc: 0.8709 - val_loss: 2.1858 - val_acc: 0.5305\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.82490\n",
            "Epoch 356/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4359 - acc: 0.8626 - val_loss: 1.1196 - val_acc: 0.6626\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.82490\n",
            "Epoch 357/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4092 - acc: 0.8783 - val_loss: 1.0700 - val_acc: 0.7135\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.82490\n",
            "Epoch 358/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4460 - acc: 0.8642 - val_loss: 1.1731 - val_acc: 0.7102\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.82490\n",
            "Epoch 359/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4196 - acc: 0.8696 - val_loss: 1.4195 - val_acc: 0.6109\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.82490\n",
            "Epoch 360/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4365 - acc: 0.8665 - val_loss: 2.0660 - val_acc: 0.5878\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.82490\n",
            "Epoch 361/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4524 - acc: 0.8617 - val_loss: 0.7398 - val_acc: 0.7844\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.82490\n",
            "Epoch 362/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4098 - acc: 0.8781 - val_loss: 0.8072 - val_acc: 0.7744\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.82490\n",
            "Epoch 363/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4161 - acc: 0.8738 - val_loss: 1.0344 - val_acc: 0.7188\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.82490\n",
            "Epoch 364/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4317 - acc: 0.8681 - val_loss: 0.6234 - val_acc: 0.8117\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.82490\n",
            "Epoch 365/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4163 - acc: 0.8716 - val_loss: 1.0677 - val_acc: 0.6880\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.82490\n",
            "Epoch 366/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4242 - acc: 0.8709 - val_loss: 1.1943 - val_acc: 0.6761\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.82490\n",
            "Epoch 367/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4022 - acc: 0.8804 - val_loss: 0.8122 - val_acc: 0.7774\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.82490\n",
            "Epoch 368/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4112 - acc: 0.8741 - val_loss: 1.2099 - val_acc: 0.6806\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.82490\n",
            "Epoch 369/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.4240 - acc: 0.8701 - val_loss: 1.0940 - val_acc: 0.7079\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.82490\n",
            "Epoch 370/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4440 - acc: 0.8650 - val_loss: 0.9884 - val_acc: 0.7284\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.82490\n",
            "Epoch 371/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4235 - acc: 0.8736 - val_loss: 0.9335 - val_acc: 0.7421\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.82490\n",
            "Epoch 372/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4290 - acc: 0.8691 - val_loss: 0.6799 - val_acc: 0.7848\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.82490\n",
            "Epoch 373/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4340 - acc: 0.8656 - val_loss: 2.5278 - val_acc: 0.4953\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.82490\n",
            "Epoch 374/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4552 - acc: 0.8588 - val_loss: 0.6722 - val_acc: 0.7910\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.82490\n",
            "Epoch 375/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4244 - acc: 0.8709 - val_loss: 0.7795 - val_acc: 0.7730\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.82490\n",
            "Epoch 376/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4326 - acc: 0.8695 - val_loss: 1.1923 - val_acc: 0.6663\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.82490\n",
            "Epoch 377/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4271 - acc: 0.8668 - val_loss: 0.8798 - val_acc: 0.7453\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.82490\n",
            "Epoch 378/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4065 - acc: 0.8787 - val_loss: 1.2230 - val_acc: 0.6815\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.82490\n",
            "Epoch 379/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.4267 - acc: 0.8725 - val_loss: 1.0207 - val_acc: 0.7430\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.82490\n",
            "Epoch 380/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4114 - acc: 0.8746 - val_loss: 1.5223 - val_acc: 0.6409\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.82490\n",
            "Epoch 381/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4532 - acc: 0.8628 - val_loss: 1.2862 - val_acc: 0.6786\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.82490\n",
            "Epoch 382/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4138 - acc: 0.8766 - val_loss: 0.9217 - val_acc: 0.7178\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.82490\n",
            "Epoch 383/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4166 - acc: 0.8726 - val_loss: 0.7506 - val_acc: 0.7661\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.82490\n",
            "Epoch 384/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4302 - acc: 0.8682 - val_loss: 0.9492 - val_acc: 0.7318\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.82490\n",
            "Epoch 385/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4289 - acc: 0.8664 - val_loss: 0.8556 - val_acc: 0.7443\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.82490\n",
            "Epoch 386/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4264 - acc: 0.8683 - val_loss: 0.8902 - val_acc: 0.7512\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.82490\n",
            "Epoch 387/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4274 - acc: 0.8720 - val_loss: 0.6395 - val_acc: 0.8001\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.82490\n",
            "Epoch 388/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4244 - acc: 0.8674 - val_loss: 1.1535 - val_acc: 0.6935\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.82490\n",
            "Epoch 389/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4378 - acc: 0.8657 - val_loss: 0.6996 - val_acc: 0.7947\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.82490\n",
            "Epoch 390/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4192 - acc: 0.8685 - val_loss: 1.0877 - val_acc: 0.7247\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.82490\n",
            "Epoch 391/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4119 - acc: 0.8760 - val_loss: 1.0407 - val_acc: 0.7164\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.82490\n",
            "Epoch 392/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4365 - acc: 0.8705 - val_loss: 0.9433 - val_acc: 0.7374\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.82490\n",
            "Epoch 393/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4131 - acc: 0.8740 - val_loss: 1.6400 - val_acc: 0.5864\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.82490\n",
            "Epoch 394/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4270 - acc: 0.8696 - val_loss: 1.2606 - val_acc: 0.6705\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.82490\n",
            "Epoch 395/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4267 - acc: 0.8713 - val_loss: 0.8629 - val_acc: 0.7460\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.82490\n",
            "Epoch 396/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4267 - acc: 0.8689 - val_loss: 0.9475 - val_acc: 0.7252\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.82490\n",
            "Epoch 397/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4064 - acc: 0.8778 - val_loss: 1.0721 - val_acc: 0.7170\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.82490\n",
            "Epoch 398/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3979 - acc: 0.8775 - val_loss: 2.0498 - val_acc: 0.5445\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.82490\n",
            "Epoch 399/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4355 - acc: 0.8627 - val_loss: 0.7403 - val_acc: 0.7990\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.82490\n",
            "Epoch 400/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4130 - acc: 0.8736 - val_loss: 0.8941 - val_acc: 0.7373\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.82490\n",
            "Epoch 401/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4186 - acc: 0.8710 - val_loss: 0.9654 - val_acc: 0.7238\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.82490\n",
            "Epoch 402/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3683 - acc: 0.8948 - val_loss: 0.3938 - val_acc: 0.8804\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.82490 to 0.88040, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3261 - acc: 0.9047 - val_loss: 0.3740 - val_acc: 0.8866\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.88040 to 0.88660, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2762 - acc: 0.9207 - val_loss: 0.3488 - val_acc: 0.8964\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.88660 to 0.89640, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.2858 - acc: 0.9201 - val_loss: 0.3623 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00405: val_acc did not improve from 0.89640\n",
            "Epoch 406/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2626 - acc: 0.9251 - val_loss: 0.3653 - val_acc: 0.8937\n",
            "\n",
            "Epoch 00406: val_acc did not improve from 0.89640\n",
            "Epoch 407/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2576 - acc: 0.9307 - val_loss: 0.3709 - val_acc: 0.8901\n",
            "\n",
            "Epoch 00407: val_acc did not improve from 0.89640\n",
            "Epoch 408/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2668 - acc: 0.9238 - val_loss: 0.3422 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00408: val_acc improved from 0.89640 to 0.89800, saving model to /content/saved_models/cifar10_ResNet32v1_model.408.h5\n",
            "Epoch 409/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2499 - acc: 0.9316 - val_loss: 0.3590 - val_acc: 0.8940\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.89800\n",
            "Epoch 410/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2556 - acc: 0.9294 - val_loss: 0.3318 - val_acc: 0.9012\n",
            "\n",
            "Epoch 00410: val_acc improved from 0.89800 to 0.90120, saving model to /content/saved_models/cifar10_ResNet32v1_model.410.h5\n",
            "Epoch 411/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2433 - acc: 0.9350 - val_loss: 0.3548 - val_acc: 0.8952\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.90120\n",
            "Epoch 412/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2365 - acc: 0.9315 - val_loss: 0.3432 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00412: val_acc did not improve from 0.90120\n",
            "Epoch 413/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2453 - acc: 0.9281 - val_loss: 0.3196 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00413: val_acc improved from 0.90120 to 0.90650, saving model to /content/saved_models/cifar10_ResNet32v1_model.413.h5\n",
            "Epoch 414/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2220 - acc: 0.9414 - val_loss: 0.3422 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.90650\n",
            "Epoch 415/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2328 - acc: 0.9354 - val_loss: 0.3469 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00415: val_acc did not improve from 0.90650\n",
            "Epoch 416/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2111 - acc: 0.9448 - val_loss: 0.3518 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.90650\n",
            "Epoch 417/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2245 - acc: 0.9384 - val_loss: 0.3331 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.90650\n",
            "Epoch 418/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2318 - acc: 0.9345 - val_loss: 0.3408 - val_acc: 0.9023\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.90650\n",
            "Epoch 419/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2096 - acc: 0.9429 - val_loss: 0.3193 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00419: val_acc improved from 0.90650 to 0.90670, saving model to /content/saved_models/cifar10_ResNet32v1_model.419.h5\n",
            "Epoch 420/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2225 - acc: 0.9361 - val_loss: 0.3171 - val_acc: 0.9079\n",
            "\n",
            "Epoch 00420: val_acc improved from 0.90670 to 0.90790, saving model to /content/saved_models/cifar10_ResNet32v1_model.420.h5\n",
            "Epoch 421/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2092 - acc: 0.9445 - val_loss: 0.3186 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00421: val_acc improved from 0.90790 to 0.90930, saving model to /content/saved_models/cifar10_ResNet32v1_model.421.h5\n",
            "Epoch 422/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2142 - acc: 0.9413 - val_loss: 0.3381 - val_acc: 0.9014\n",
            "\n",
            "Epoch 00422: val_acc did not improve from 0.90930\n",
            "Epoch 423/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2130 - acc: 0.9394 - val_loss: 0.3414 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.90930\n",
            "Epoch 424/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2164 - acc: 0.9407 - val_loss: 0.3185 - val_acc: 0.9081\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.90930\n",
            "Epoch 425/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2137 - acc: 0.9399 - val_loss: 0.3246 - val_acc: 0.9073\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.90930\n",
            "Epoch 426/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1931 - acc: 0.9511 - val_loss: 0.3223 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.90930\n",
            "Epoch 427/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1953 - acc: 0.9491 - val_loss: 0.3322 - val_acc: 0.9032\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.90930\n",
            "Epoch 428/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1905 - acc: 0.9483 - val_loss: 0.3303 - val_acc: 0.9060\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.90930\n",
            "Epoch 429/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2025 - acc: 0.9446 - val_loss: 0.3237 - val_acc: 0.9057\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.90930\n",
            "Epoch 430/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.2100 - acc: 0.9403 - val_loss: 0.3308 - val_acc: 0.9077\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.90930\n",
            "Epoch 431/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1908 - acc: 0.9451 - val_loss: 0.3300 - val_acc: 0.9053\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.90930\n",
            "Epoch 432/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1817 - acc: 0.9513 - val_loss: 0.3406 - val_acc: 0.9030\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.90930\n",
            "Epoch 433/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1821 - acc: 0.9519 - val_loss: 0.3516 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.90930\n",
            "Epoch 434/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1985 - acc: 0.9443 - val_loss: 0.3176 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00434: val_acc improved from 0.90930 to 0.91120, saving model to /content/saved_models/cifar10_ResNet32v1_model.434.h5\n",
            "Epoch 435/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1814 - acc: 0.9532 - val_loss: 0.3460 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.91120\n",
            "Epoch 436/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1798 - acc: 0.9521 - val_loss: 0.3287 - val_acc: 0.9041\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.91120\n",
            "Epoch 437/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1778 - acc: 0.9546 - val_loss: 0.3166 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00437: val_acc improved from 0.91120 to 0.91130, saving model to /content/saved_models/cifar10_ResNet32v1_model.437.h5\n",
            "Epoch 438/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1818 - acc: 0.9507 - val_loss: 0.3190 - val_acc: 0.9095\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.91130\n",
            "Epoch 439/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1941 - acc: 0.9493 - val_loss: 0.3273 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.91130\n",
            "Epoch 440/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1864 - acc: 0.9534 - val_loss: 0.3294 - val_acc: 0.9074\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.91130\n",
            "Epoch 441/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1922 - acc: 0.9491 - val_loss: 0.3123 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.91130\n",
            "Epoch 442/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1883 - acc: 0.9490 - val_loss: 0.3367 - val_acc: 0.9056\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.91130\n",
            "Epoch 443/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1816 - acc: 0.9548 - val_loss: 0.3299 - val_acc: 0.9071\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.91130\n",
            "Epoch 444/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1795 - acc: 0.9512 - val_loss: 0.3179 - val_acc: 0.9090\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.91130\n",
            "Epoch 445/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1820 - acc: 0.9522 - val_loss: 0.3284 - val_acc: 0.9090\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.91130\n",
            "Epoch 446/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1894 - acc: 0.9514 - val_loss: 0.3508 - val_acc: 0.9035\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.91130\n",
            "Epoch 447/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1730 - acc: 0.9529 - val_loss: 0.3235 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.91130\n",
            "Epoch 448/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1647 - acc: 0.9593 - val_loss: 0.3416 - val_acc: 0.9043\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.91130\n",
            "Epoch 449/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1778 - acc: 0.9533 - val_loss: 0.3200 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.91130\n",
            "Epoch 450/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1740 - acc: 0.9540 - val_loss: 0.3162 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.91130\n",
            "Epoch 451/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1684 - acc: 0.9575 - val_loss: 0.3314 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.91130\n",
            "Epoch 452/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1700 - acc: 0.9552 - val_loss: 0.3624 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.91130\n",
            "Epoch 453/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1651 - acc: 0.9582 - val_loss: 0.3391 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.91130\n",
            "Epoch 454/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1656 - acc: 0.9572 - val_loss: 0.3309 - val_acc: 0.9066\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.91130\n",
            "Epoch 455/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1708 - acc: 0.9567 - val_loss: 0.3316 - val_acc: 0.9094\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.91130\n",
            "Epoch 456/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1576 - acc: 0.9620 - val_loss: 0.3375 - val_acc: 0.9041\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.91130\n",
            "Epoch 457/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1501 - acc: 0.9634 - val_loss: 0.3435 - val_acc: 0.9060\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.91130\n",
            "Epoch 458/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1596 - acc: 0.9600 - val_loss: 0.3320 - val_acc: 0.9089\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.91130\n",
            "Epoch 459/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1604 - acc: 0.9568 - val_loss: 0.3484 - val_acc: 0.9032\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.91130\n",
            "Epoch 460/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1662 - acc: 0.9561 - val_loss: 0.3125 - val_acc: 0.9123\n",
            "\n",
            "Epoch 00460: val_acc improved from 0.91130 to 0.91230, saving model to /content/saved_models/cifar10_ResNet32v1_model.460.h5\n",
            "Epoch 461/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1583 - acc: 0.9582 - val_loss: 0.3225 - val_acc: 0.9106\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.91230\n",
            "Epoch 462/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1616 - acc: 0.9592 - val_loss: 0.3123 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00462: val_acc improved from 0.91230 to 0.91370, saving model to /content/saved_models/cifar10_ResNet32v1_model.462.h5\n",
            "Epoch 463/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1491 - acc: 0.9619 - val_loss: 0.3351 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.91370\n",
            "Epoch 464/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1598 - acc: 0.9594 - val_loss: 0.3286 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.91370\n",
            "Epoch 465/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1542 - acc: 0.9599 - val_loss: 0.3076 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00465: val_acc improved from 0.91370 to 0.91670, saving model to /content/saved_models/cifar10_ResNet32v1_model.465.h5\n",
            "Epoch 466/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1587 - acc: 0.9621 - val_loss: 0.3188 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.91670\n",
            "Epoch 467/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1527 - acc: 0.9610 - val_loss: 0.3071 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.91670\n",
            "Epoch 468/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1550 - acc: 0.9645 - val_loss: 0.3142 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.91670\n",
            "Epoch 469/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1457 - acc: 0.9645 - val_loss: 0.3494 - val_acc: 0.9032\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.91670\n",
            "Epoch 470/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1469 - acc: 0.9661 - val_loss: 0.3205 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.91670\n",
            "Epoch 471/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1492 - acc: 0.9630 - val_loss: 0.3419 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.91670\n",
            "Epoch 472/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1425 - acc: 0.9649 - val_loss: 0.3191 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.91670\n",
            "Epoch 473/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1421 - acc: 0.9658 - val_loss: 0.3224 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.91670\n",
            "Epoch 474/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1458 - acc: 0.9648 - val_loss: 0.3275 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.91670\n",
            "Epoch 475/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1366 - acc: 0.9660 - val_loss: 0.3272 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.91670\n",
            "Epoch 476/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1344 - acc: 0.9687 - val_loss: 0.3451 - val_acc: 0.9071\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.91670\n",
            "Epoch 477/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1423 - acc: 0.9640 - val_loss: 0.3446 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.91670\n",
            "Epoch 478/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1362 - acc: 0.9676 - val_loss: 0.3316 - val_acc: 0.9123\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.91670\n",
            "Epoch 479/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1422 - acc: 0.9658 - val_loss: 0.3131 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.91670\n",
            "Epoch 480/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1381 - acc: 0.9676 - val_loss: 0.3316 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.91670\n",
            "Epoch 481/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1425 - acc: 0.9642 - val_loss: 0.3493 - val_acc: 0.9047\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.91670\n",
            "Epoch 482/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1462 - acc: 0.9636 - val_loss: 0.2986 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00482: val_acc improved from 0.91670 to 0.91760, saving model to /content/saved_models/cifar10_ResNet32v1_model.482.h5\n",
            "Epoch 483/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1405 - acc: 0.9663 - val_loss: 0.3261 - val_acc: 0.9084\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.91760\n",
            "Epoch 484/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1461 - acc: 0.9620 - val_loss: 0.3087 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.91760\n",
            "Epoch 485/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1405 - acc: 0.9656 - val_loss: 0.3432 - val_acc: 0.9083\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.91760\n",
            "Epoch 486/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1408 - acc: 0.9669 - val_loss: 0.3402 - val_acc: 0.9068\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.91760\n",
            "Epoch 487/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1307 - acc: 0.9693 - val_loss: 0.3324 - val_acc: 0.9114\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.91760\n",
            "Epoch 488/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1385 - acc: 0.9652 - val_loss: 0.3327 - val_acc: 0.9085\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.91760\n",
            "Epoch 489/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1420 - acc: 0.9635 - val_loss: 0.3243 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.91760\n",
            "Epoch 490/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1350 - acc: 0.9680 - val_loss: 0.3062 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.91760\n",
            "Epoch 491/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1254 - acc: 0.9707 - val_loss: 0.3167 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.91760\n",
            "Epoch 492/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1374 - acc: 0.9653 - val_loss: 0.3179 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.91760\n",
            "Epoch 493/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1339 - acc: 0.9680 - val_loss: 0.3244 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.91760\n",
            "Epoch 494/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1296 - acc: 0.9686 - val_loss: 0.3805 - val_acc: 0.9020\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.91760\n",
            "Epoch 495/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1325 - acc: 0.9671 - val_loss: 0.3418 - val_acc: 0.9079\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.91760\n",
            "Epoch 496/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1279 - acc: 0.9688 - val_loss: 0.3252 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.91760\n",
            "Epoch 497/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1272 - acc: 0.9721 - val_loss: 0.3370 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.91760\n",
            "Epoch 498/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1208 - acc: 0.9728 - val_loss: 0.3393 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.91760\n",
            "Epoch 499/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1265 - acc: 0.9704 - val_loss: 0.3433 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.91760\n",
            "Epoch 500/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1205 - acc: 0.9691 - val_loss: 0.3119 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.91760\n",
            "Epoch 501/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1283 - acc: 0.9718 - val_loss: 0.3270 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.91760\n",
            "Epoch 502/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1271 - acc: 0.9713 - val_loss: 0.3461 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.91760\n",
            "Epoch 503/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1231 - acc: 0.9727 - val_loss: 0.3251 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.91760\n",
            "Epoch 504/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1159 - acc: 0.9735 - val_loss: 0.3421 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.91760\n",
            "Epoch 505/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1245 - acc: 0.9703 - val_loss: 0.3374 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.91760\n",
            "Epoch 506/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1319 - acc: 0.9658 - val_loss: 0.3619 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.91760\n",
            "Epoch 507/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1228 - acc: 0.9718 - val_loss: 0.3429 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.91760\n",
            "Epoch 508/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1251 - acc: 0.9706 - val_loss: 0.3317 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.91760\n",
            "Epoch 509/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1264 - acc: 0.9672 - val_loss: 0.3744 - val_acc: 0.9050\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.91760\n",
            "Epoch 510/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1252 - acc: 0.9717 - val_loss: 0.3531 - val_acc: 0.9066\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.91760\n",
            "Epoch 511/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1201 - acc: 0.9734 - val_loss: 0.3343 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.91760\n",
            "Epoch 512/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1246 - acc: 0.9718 - val_loss: 0.4159 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.91760\n",
            "Epoch 513/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1235 - acc: 0.9702 - val_loss: 0.3342 - val_acc: 0.9141\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.91760\n",
            "Epoch 514/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1254 - acc: 0.9689 - val_loss: 0.3373 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.91760\n",
            "Epoch 515/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1206 - acc: 0.9722 - val_loss: 0.3222 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.91760\n",
            "Epoch 516/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1178 - acc: 0.9730 - val_loss: 0.3436 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.91760\n",
            "Epoch 517/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1175 - acc: 0.9732 - val_loss: 0.3280 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.91760\n",
            "Epoch 518/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1199 - acc: 0.9700 - val_loss: 0.3184 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.91760\n",
            "Epoch 519/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1203 - acc: 0.9720 - val_loss: 0.3232 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.91760\n",
            "Epoch 520/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1169 - acc: 0.9749 - val_loss: 0.3272 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.91760\n",
            "Epoch 521/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1198 - acc: 0.9733 - val_loss: 0.4072 - val_acc: 0.8957\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.91760\n",
            "Epoch 522/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1194 - acc: 0.9716 - val_loss: 0.3239 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.91760\n",
            "Epoch 523/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1160 - acc: 0.9756 - val_loss: 0.3658 - val_acc: 0.9085\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.91760\n",
            "Epoch 524/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1226 - acc: 0.9705 - val_loss: 0.3434 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.91760\n",
            "Epoch 525/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1174 - acc: 0.9756 - val_loss: 0.3365 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.91760\n",
            "Epoch 526/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1284 - acc: 0.9711 - val_loss: 0.3296 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.91760\n",
            "Epoch 527/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1194 - acc: 0.9750 - val_loss: 0.3367 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.91760\n",
            "Epoch 528/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1137 - acc: 0.9728 - val_loss: 0.3587 - val_acc: 0.9040\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.91760\n",
            "Epoch 529/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1089 - acc: 0.9772 - val_loss: 0.3403 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.91760\n",
            "Epoch 530/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1090 - acc: 0.9766 - val_loss: 0.3425 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.91760\n",
            "Epoch 531/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1127 - acc: 0.9737 - val_loss: 0.3459 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.91760\n",
            "Epoch 532/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1055 - acc: 0.9783 - val_loss: 0.3237 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.91760\n",
            "Epoch 533/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1082 - acc: 0.9777 - val_loss: 0.3328 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.91760\n",
            "Epoch 534/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1092 - acc: 0.9759 - val_loss: 0.3448 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.91760\n",
            "Epoch 535/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1133 - acc: 0.9760 - val_loss: 0.3537 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.91760\n",
            "Epoch 536/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1203 - acc: 0.9715 - val_loss: 0.3355 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.91760\n",
            "Epoch 537/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1108 - acc: 0.9755 - val_loss: 0.3349 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.91760\n",
            "Epoch 538/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1129 - acc: 0.9737 - val_loss: 0.3533 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.91760\n",
            "Epoch 539/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1104 - acc: 0.9758 - val_loss: 0.3481 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.91760\n",
            "Epoch 540/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1125 - acc: 0.9744 - val_loss: 0.3630 - val_acc: 0.9060\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.91760\n",
            "Epoch 541/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1092 - acc: 0.9755 - val_loss: 0.3811 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.91760\n",
            "Epoch 542/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1048 - acc: 0.9801 - val_loss: 0.3745 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.91760\n",
            "Epoch 543/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1126 - acc: 0.9716 - val_loss: 0.3268 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.91760\n",
            "Epoch 544/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1066 - acc: 0.9788 - val_loss: 0.3268 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.91760\n",
            "Epoch 545/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1083 - acc: 0.9762 - val_loss: 0.3367 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.91760\n",
            "Epoch 546/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1086 - acc: 0.9740 - val_loss: 0.3770 - val_acc: 0.9049\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.91760\n",
            "Epoch 547/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1147 - acc: 0.9725 - val_loss: 0.3398 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.91760\n",
            "Epoch 548/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1093 - acc: 0.9758 - val_loss: 0.3371 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.91760\n",
            "Epoch 549/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1085 - acc: 0.9735 - val_loss: 0.3581 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.91760\n",
            "Epoch 550/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1154 - acc: 0.9704 - val_loss: 0.3344 - val_acc: 0.9146\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.91760\n",
            "Epoch 551/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1062 - acc: 0.9772 - val_loss: 0.3516 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.91760\n",
            "Epoch 552/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0995 - acc: 0.9800 - val_loss: 0.3220 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.91760\n",
            "Epoch 553/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1052 - acc: 0.9756 - val_loss: 0.3623 - val_acc: 0.9078\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.91760\n",
            "Epoch 554/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1060 - acc: 0.9761 - val_loss: 0.3647 - val_acc: 0.9043\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.91760\n",
            "Epoch 555/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1140 - acc: 0.9748 - val_loss: 0.3502 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.91760\n",
            "Epoch 556/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1030 - acc: 0.9802 - val_loss: 0.3375 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.91760\n",
            "Epoch 557/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1035 - acc: 0.9781 - val_loss: 0.3478 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.91760\n",
            "Epoch 558/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1104 - acc: 0.9770 - val_loss: 0.3508 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.91760\n",
            "Epoch 559/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1132 - acc: 0.9740 - val_loss: 0.3573 - val_acc: 0.9096\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.91760\n",
            "Epoch 560/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1031 - acc: 0.9792 - val_loss: 0.3542 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.91760\n",
            "Epoch 561/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1077 - acc: 0.9774 - val_loss: 0.3643 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.91760\n",
            "Epoch 562/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0992 - acc: 0.9816 - val_loss: 0.3601 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.91760\n",
            "Epoch 563/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1083 - acc: 0.9744 - val_loss: 0.3660 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.91760\n",
            "Epoch 564/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1071 - acc: 0.9767 - val_loss: 0.3601 - val_acc: 0.9102\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.91760\n",
            "Epoch 565/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1060 - acc: 0.9767 - val_loss: 0.3321 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.91760\n",
            "Epoch 566/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1011 - acc: 0.9801 - val_loss: 0.3617 - val_acc: 0.9068\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.91760\n",
            "Epoch 567/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1068 - acc: 0.9768 - val_loss: 0.3373 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.91760\n",
            "Epoch 568/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1005 - acc: 0.9779 - val_loss: 0.3672 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.91760\n",
            "Epoch 569/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0935 - acc: 0.9804 - val_loss: 0.3535 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.91760\n",
            "Epoch 570/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1082 - acc: 0.9741 - val_loss: 0.3573 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.91760\n",
            "Epoch 571/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0999 - acc: 0.9786 - val_loss: 0.3475 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.91760\n",
            "Epoch 572/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1064 - acc: 0.9742 - val_loss: 0.3306 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00572: val_acc improved from 0.91760 to 0.91930, saving model to /content/saved_models/cifar10_ResNet32v1_model.572.h5\n",
            "Epoch 573/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0972 - acc: 0.9800 - val_loss: 0.3631 - val_acc: 0.9091\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.91930\n",
            "Epoch 574/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1063 - acc: 0.9776 - val_loss: 0.3611 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.91930\n",
            "Epoch 575/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1017 - acc: 0.9794 - val_loss: 0.3433 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.91930\n",
            "Epoch 576/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1060 - acc: 0.9746 - val_loss: 0.3470 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.91930\n",
            "Epoch 577/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0957 - acc: 0.9789 - val_loss: 0.3808 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.91930\n",
            "Epoch 578/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0980 - acc: 0.9803 - val_loss: 0.3506 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.91930\n",
            "Epoch 579/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0942 - acc: 0.9799 - val_loss: 0.3526 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.91930\n",
            "Epoch 580/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0981 - acc: 0.9794 - val_loss: 0.3735 - val_acc: 0.9056\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.91930\n",
            "Epoch 581/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0948 - acc: 0.9795 - val_loss: 0.3555 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.91930\n",
            "Epoch 582/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0994 - acc: 0.9790 - val_loss: 0.3658 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.91930\n",
            "Epoch 583/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1014 - acc: 0.9797 - val_loss: 0.3728 - val_acc: 0.9035\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.91930\n",
            "Epoch 584/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0879 - acc: 0.9828 - val_loss: 0.3644 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.91930\n",
            "Epoch 585/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0954 - acc: 0.9790 - val_loss: 0.3419 - val_acc: 0.9134\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.91930\n",
            "Epoch 586/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1027 - acc: 0.9760 - val_loss: 0.3513 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.91930\n",
            "Epoch 587/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1017 - acc: 0.9778 - val_loss: 0.4285 - val_acc: 0.8949\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.91930\n",
            "Epoch 588/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0959 - acc: 0.9796 - val_loss: 0.4158 - val_acc: 0.9007\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.91930\n",
            "Epoch 589/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1005 - acc: 0.9791 - val_loss: 0.3492 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.91930\n",
            "Epoch 590/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0933 - acc: 0.9802 - val_loss: 0.4137 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.91930\n",
            "Epoch 591/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1004 - acc: 0.9775 - val_loss: 0.3543 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.91930\n",
            "Epoch 592/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1004 - acc: 0.9764 - val_loss: 0.3561 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.91930\n",
            "Epoch 593/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0884 - acc: 0.9832 - val_loss: 0.3604 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.91930\n",
            "Epoch 594/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0994 - acc: 0.9790 - val_loss: 0.3387 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.91930\n",
            "Epoch 595/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0990 - acc: 0.9796 - val_loss: 0.3879 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.91930\n",
            "Epoch 596/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0903 - acc: 0.9825 - val_loss: 0.3856 - val_acc: 0.9094\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.91930\n",
            "Epoch 597/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0968 - acc: 0.9801 - val_loss: 0.3403 - val_acc: 0.9181\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.91930\n",
            "Epoch 598/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1012 - acc: 0.9784 - val_loss: 0.3690 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.91930\n",
            "Epoch 599/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0950 - acc: 0.9817 - val_loss: 0.3549 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.91930\n",
            "Epoch 600/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0955 - acc: 0.9806 - val_loss: 0.3426 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.91930\n",
            "Epoch 601/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0878 - acc: 0.9828 - val_loss: 0.3889 - val_acc: 0.9039\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.91930\n",
            "Epoch 602/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0855 - acc: 0.9831 - val_loss: 0.3311 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00602: val_acc did not improve from 0.91930\n",
            "Epoch 603/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0845 - acc: 0.9849 - val_loss: 0.3224 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00603: val_acc improved from 0.91930 to 0.92020, saving model to /content/saved_models/cifar10_ResNet32v1_model.603.h5\n",
            "Epoch 604/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0798 - acc: 0.9880 - val_loss: 0.3193 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00604: val_acc did not improve from 0.92020\n",
            "Epoch 605/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0786 - acc: 0.9874 - val_loss: 0.3207 - val_acc: 0.9244\n",
            "\n",
            "Epoch 00605: val_acc improved from 0.92020 to 0.92440, saving model to /content/saved_models/cifar10_ResNet32v1_model.605.h5\n",
            "Epoch 606/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0756 - acc: 0.9883 - val_loss: 0.3157 - val_acc: 0.9234\n",
            "\n",
            "Epoch 00606: val_acc did not improve from 0.92440\n",
            "Epoch 607/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0813 - acc: 0.9853 - val_loss: 0.3138 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00607: val_acc did not improve from 0.92440\n",
            "Epoch 608/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0826 - acc: 0.9843 - val_loss: 0.3041 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00608: val_acc improved from 0.92440 to 0.92470, saving model to /content/saved_models/cifar10_ResNet32v1_model.608.h5\n",
            "Epoch 609/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0833 - acc: 0.9855 - val_loss: 0.3073 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00609: val_acc improved from 0.92470 to 0.92540, saving model to /content/saved_models/cifar10_ResNet32v1_model.609.h5\n",
            "Epoch 610/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0798 - acc: 0.9858 - val_loss: 0.3107 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00610: val_acc did not improve from 0.92540\n",
            "Epoch 611/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0727 - acc: 0.9904 - val_loss: 0.3097 - val_acc: 0.9240\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.92540\n",
            "Epoch 612/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0804 - acc: 0.9856 - val_loss: 0.3076 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00612: val_acc did not improve from 0.92540\n",
            "Epoch 613/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0785 - acc: 0.9882 - val_loss: 0.3046 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00613: val_acc did not improve from 0.92540\n",
            "Epoch 614/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0799 - acc: 0.9865 - val_loss: 0.3067 - val_acc: 0.9234\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.92540\n",
            "Epoch 615/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0748 - acc: 0.9885 - val_loss: 0.3068 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.92540\n",
            "Epoch 616/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0789 - acc: 0.9865 - val_loss: 0.3085 - val_acc: 0.9245\n",
            "\n",
            "Epoch 00616: val_acc did not improve from 0.92540\n",
            "Epoch 617/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0756 - acc: 0.9885 - val_loss: 0.3061 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.92540\n",
            "Epoch 618/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0742 - acc: 0.9885 - val_loss: 0.3037 - val_acc: 0.9264\n",
            "\n",
            "Epoch 00618: val_acc improved from 0.92540 to 0.92640, saving model to /content/saved_models/cifar10_ResNet32v1_model.618.h5\n",
            "Epoch 619/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0762 - acc: 0.9876 - val_loss: 0.3032 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00619: val_acc did not improve from 0.92640\n",
            "Epoch 620/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0732 - acc: 0.9897 - val_loss: 0.3065 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.92640\n",
            "Epoch 621/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0722 - acc: 0.9884 - val_loss: 0.3080 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00621: val_acc did not improve from 0.92640\n",
            "Epoch 622/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0754 - acc: 0.9887 - val_loss: 0.3058 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.92640\n",
            "Epoch 623/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0710 - acc: 0.9898 - val_loss: 0.3062 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.92640\n",
            "Epoch 624/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0715 - acc: 0.9920 - val_loss: 0.3055 - val_acc: 0.9245\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.92640\n",
            "Epoch 625/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0707 - acc: 0.9894 - val_loss: 0.3077 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.92640\n",
            "Epoch 626/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0731 - acc: 0.9894 - val_loss: 0.3086 - val_acc: 0.9242\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.92640\n",
            "Epoch 627/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0694 - acc: 0.9904 - val_loss: 0.3088 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00627: val_acc did not improve from 0.92640\n",
            "Epoch 628/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0721 - acc: 0.9895 - val_loss: 0.3108 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00628: val_acc did not improve from 0.92640\n",
            "Epoch 629/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0736 - acc: 0.9892 - val_loss: 0.3082 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.92640\n",
            "Epoch 630/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0705 - acc: 0.9919 - val_loss: 0.3111 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00630: val_acc did not improve from 0.92640\n",
            "Epoch 631/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0664 - acc: 0.9928 - val_loss: 0.3085 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00631: val_acc did not improve from 0.92640\n",
            "Epoch 632/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0687 - acc: 0.9912 - val_loss: 0.3057 - val_acc: 0.9242\n",
            "\n",
            "Epoch 00632: val_acc did not improve from 0.92640\n",
            "Epoch 633/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0677 - acc: 0.9912 - val_loss: 0.3087 - val_acc: 0.9244\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.92640\n",
            "Epoch 634/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0716 - acc: 0.9902 - val_loss: 0.3099 - val_acc: 0.9236\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.92640\n",
            "Epoch 635/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0669 - acc: 0.9919 - val_loss: 0.3094 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.92640\n",
            "Epoch 636/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0681 - acc: 0.9913 - val_loss: 0.3141 - val_acc: 0.9245\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.92640\n",
            "Epoch 637/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0706 - acc: 0.9897 - val_loss: 0.3088 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00637: val_acc did not improve from 0.92640\n",
            "Epoch 638/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0727 - acc: 0.9891 - val_loss: 0.3126 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.92640\n",
            "Epoch 639/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0734 - acc: 0.9896 - val_loss: 0.3082 - val_acc: 0.9231\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.92640\n",
            "Epoch 640/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0718 - acc: 0.9902 - val_loss: 0.3101 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.92640\n",
            "Epoch 641/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0662 - acc: 0.9919 - val_loss: 0.3144 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.92640\n",
            "Epoch 642/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0677 - acc: 0.9920 - val_loss: 0.3127 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.92640\n",
            "Epoch 643/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0713 - acc: 0.9880 - val_loss: 0.3107 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.92640\n",
            "Epoch 644/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0691 - acc: 0.9908 - val_loss: 0.3115 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.92640\n",
            "Epoch 645/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0652 - acc: 0.9910 - val_loss: 0.3102 - val_acc: 0.9234\n",
            "\n",
            "Epoch 00645: val_acc did not improve from 0.92640\n",
            "Epoch 646/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0674 - acc: 0.9912 - val_loss: 0.3091 - val_acc: 0.9241\n",
            "\n",
            "Epoch 00646: val_acc did not improve from 0.92640\n",
            "Epoch 647/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0677 - acc: 0.9905 - val_loss: 0.3136 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00647: val_acc did not improve from 0.92640\n",
            "Epoch 648/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0684 - acc: 0.9902 - val_loss: 0.3120 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.92640\n",
            "Epoch 649/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0675 - acc: 0.9913 - val_loss: 0.3106 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.92640\n",
            "Epoch 650/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0729 - acc: 0.9871 - val_loss: 0.3121 - val_acc: 0.9236\n",
            "\n",
            "Epoch 00650: val_acc did not improve from 0.92640\n",
            "Epoch 651/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0654 - acc: 0.9906 - val_loss: 0.3098 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00651: val_acc did not improve from 0.92640\n",
            "Epoch 652/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0686 - acc: 0.9914 - val_loss: 0.3088 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00652: val_acc did not improve from 0.92640\n",
            "Epoch 653/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0698 - acc: 0.9901 - val_loss: 0.3117 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00653: val_acc did not improve from 0.92640\n",
            "Epoch 654/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0668 - acc: 0.9920 - val_loss: 0.3116 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00654: val_acc did not improve from 0.92640\n",
            "Epoch 655/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0696 - acc: 0.9909 - val_loss: 0.3083 - val_acc: 0.9245\n",
            "\n",
            "Epoch 00655: val_acc did not improve from 0.92640\n",
            "Epoch 656/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0675 - acc: 0.9913 - val_loss: 0.3102 - val_acc: 0.9233\n",
            "\n",
            "Epoch 00656: val_acc did not improve from 0.92640\n",
            "Epoch 657/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0681 - acc: 0.9919 - val_loss: 0.3144 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00657: val_acc did not improve from 0.92640\n",
            "Epoch 658/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0660 - acc: 0.9923 - val_loss: 0.3125 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00658: val_acc did not improve from 0.92640\n",
            "Epoch 659/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0648 - acc: 0.9912 - val_loss: 0.3116 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00659: val_acc did not improve from 0.92640\n",
            "Epoch 660/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0634 - acc: 0.9916 - val_loss: 0.3131 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00660: val_acc did not improve from 0.92640\n",
            "Epoch 661/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0683 - acc: 0.9911 - val_loss: 0.3107 - val_acc: 0.9244\n",
            "\n",
            "Epoch 00661: val_acc did not improve from 0.92640\n",
            "Epoch 662/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0691 - acc: 0.9918 - val_loss: 0.3124 - val_acc: 0.9244\n",
            "\n",
            "Epoch 00662: val_acc did not improve from 0.92640\n",
            "Epoch 663/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0643 - acc: 0.9912 - val_loss: 0.3132 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00663: val_acc did not improve from 0.92640\n",
            "Epoch 664/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0650 - acc: 0.9923 - val_loss: 0.3128 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00664: val_acc did not improve from 0.92640\n",
            "Epoch 665/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0677 - acc: 0.9908 - val_loss: 0.3092 - val_acc: 0.9244\n",
            "\n",
            "Epoch 00665: val_acc did not improve from 0.92640\n",
            "Epoch 666/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0673 - acc: 0.9907 - val_loss: 0.3125 - val_acc: 0.9262\n",
            "\n",
            "Epoch 00666: val_acc did not improve from 0.92640\n",
            "Epoch 667/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0662 - acc: 0.9918 - val_loss: 0.3103 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00667: val_acc did not improve from 0.92640\n",
            "Epoch 668/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0661 - acc: 0.9916 - val_loss: 0.3104 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00668: val_acc did not improve from 0.92640\n",
            "Epoch 669/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0642 - acc: 0.9932 - val_loss: 0.3120 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00669: val_acc did not improve from 0.92640\n",
            "Epoch 670/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0622 - acc: 0.9938 - val_loss: 0.3092 - val_acc: 0.9264\n",
            "\n",
            "Epoch 00670: val_acc did not improve from 0.92640\n",
            "Epoch 671/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0611 - acc: 0.9936 - val_loss: 0.3105 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00671: val_acc did not improve from 0.92640\n",
            "Epoch 672/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0695 - acc: 0.9895 - val_loss: 0.3109 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00672: val_acc did not improve from 0.92640\n",
            "Epoch 673/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0655 - acc: 0.9913 - val_loss: 0.3147 - val_acc: 0.9242\n",
            "\n",
            "Epoch 00673: val_acc did not improve from 0.92640\n",
            "Epoch 674/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0652 - acc: 0.9919 - val_loss: 0.3160 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00674: val_acc did not improve from 0.92640\n",
            "Epoch 675/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0613 - acc: 0.9941 - val_loss: 0.3159 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00675: val_acc did not improve from 0.92640\n",
            "Epoch 676/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0670 - acc: 0.9912 - val_loss: 0.3171 - val_acc: 0.9242\n",
            "\n",
            "Epoch 00676: val_acc did not improve from 0.92640\n",
            "Epoch 677/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0659 - acc: 0.9911 - val_loss: 0.3103 - val_acc: 0.9243\n",
            "\n",
            "Epoch 00677: val_acc did not improve from 0.92640\n",
            "Epoch 678/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0673 - acc: 0.9901 - val_loss: 0.3109 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00678: val_acc did not improve from 0.92640\n",
            "Epoch 679/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0605 - acc: 0.9938 - val_loss: 0.3125 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00679: val_acc did not improve from 0.92640\n",
            "Epoch 680/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0653 - acc: 0.9907 - val_loss: 0.3131 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00680: val_acc did not improve from 0.92640\n",
            "Epoch 681/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0678 - acc: 0.9901 - val_loss: 0.3123 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00681: val_acc did not improve from 0.92640\n",
            "Epoch 682/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0726 - acc: 0.9903 - val_loss: 0.3118 - val_acc: 0.9246\n",
            "\n",
            "Epoch 00682: val_acc did not improve from 0.92640\n",
            "Epoch 683/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0683 - acc: 0.9903 - val_loss: 0.3135 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00683: val_acc did not improve from 0.92640\n",
            "Epoch 684/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0659 - acc: 0.9927 - val_loss: 0.3112 - val_acc: 0.9246\n",
            "\n",
            "Epoch 00684: val_acc did not improve from 0.92640\n",
            "Epoch 685/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0668 - acc: 0.9911 - val_loss: 0.3127 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00685: val_acc did not improve from 0.92640\n",
            "Epoch 686/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0667 - acc: 0.9895 - val_loss: 0.3110 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00686: val_acc did not improve from 0.92640\n",
            "Epoch 687/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0642 - acc: 0.9923 - val_loss: 0.3108 - val_acc: 0.9246\n",
            "\n",
            "Epoch 00687: val_acc did not improve from 0.92640\n",
            "Epoch 688/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0623 - acc: 0.9935 - val_loss: 0.3133 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00688: val_acc did not improve from 0.92640\n",
            "Epoch 689/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0643 - acc: 0.9930 - val_loss: 0.3134 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00689: val_acc did not improve from 0.92640\n",
            "Epoch 690/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0643 - acc: 0.9925 - val_loss: 0.3149 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00690: val_acc did not improve from 0.92640\n",
            "Epoch 691/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0647 - acc: 0.9915 - val_loss: 0.3154 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00691: val_acc did not improve from 0.92640\n",
            "Epoch 692/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0639 - acc: 0.9924 - val_loss: 0.3202 - val_acc: 0.9242\n",
            "\n",
            "Epoch 00692: val_acc did not improve from 0.92640\n",
            "Epoch 693/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0626 - acc: 0.9919 - val_loss: 0.3165 - val_acc: 0.9240\n",
            "\n",
            "Epoch 00693: val_acc did not improve from 0.92640\n",
            "Epoch 694/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0606 - acc: 0.9943 - val_loss: 0.3152 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00694: val_acc did not improve from 0.92640\n",
            "Epoch 695/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0652 - acc: 0.9908 - val_loss: 0.3181 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00695: val_acc did not improve from 0.92640\n",
            "Epoch 696/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0638 - acc: 0.9926 - val_loss: 0.3204 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00696: val_acc did not improve from 0.92640\n",
            "Epoch 697/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0633 - acc: 0.9928 - val_loss: 0.3162 - val_acc: 0.9241\n",
            "\n",
            "Epoch 00697: val_acc did not improve from 0.92640\n",
            "Epoch 698/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0655 - acc: 0.9918 - val_loss: 0.3185 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00698: val_acc did not improve from 0.92640\n",
            "Epoch 699/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0613 - acc: 0.9924 - val_loss: 0.3171 - val_acc: 0.9231\n",
            "\n",
            "Epoch 00699: val_acc did not improve from 0.92640\n",
            "Epoch 700/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0633 - acc: 0.9916 - val_loss: 0.3153 - val_acc: 0.9263\n",
            "\n",
            "Epoch 00700: val_acc did not improve from 0.92640\n",
            "Epoch 701/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0590 - acc: 0.9957 - val_loss: 0.3184 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00701: val_acc did not improve from 0.92640\n",
            "Epoch 702/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0598 - acc: 0.9938 - val_loss: 0.3178 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00702: val_acc did not improve from 0.92640\n",
            "Epoch 703/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0605 - acc: 0.9930 - val_loss: 0.3187 - val_acc: 0.9241\n",
            "\n",
            "Epoch 00703: val_acc did not improve from 0.92640\n",
            "Epoch 704/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0682 - acc: 0.9881 - val_loss: 0.3166 - val_acc: 0.9241\n",
            "\n",
            "Epoch 00704: val_acc did not improve from 0.92640\n",
            "Epoch 705/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0647 - acc: 0.9928 - val_loss: 0.3170 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00705: val_acc did not improve from 0.92640\n",
            "Epoch 706/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0631 - acc: 0.9930 - val_loss: 0.3180 - val_acc: 0.9246\n",
            "\n",
            "Epoch 00706: val_acc did not improve from 0.92640\n",
            "Epoch 707/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0606 - acc: 0.9941 - val_loss: 0.3170 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00707: val_acc did not improve from 0.92640\n",
            "Epoch 708/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0598 - acc: 0.9939 - val_loss: 0.3177 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00708: val_acc did not improve from 0.92640\n",
            "Epoch 709/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0606 - acc: 0.9929 - val_loss: 0.3159 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00709: val_acc did not improve from 0.92640\n",
            "Epoch 710/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0634 - acc: 0.9913 - val_loss: 0.3184 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00710: val_acc did not improve from 0.92640\n",
            "Epoch 711/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0617 - acc: 0.9931 - val_loss: 0.3170 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00711: val_acc did not improve from 0.92640\n",
            "Epoch 712/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0605 - acc: 0.9937 - val_loss: 0.3162 - val_acc: 0.9241\n",
            "\n",
            "Epoch 00712: val_acc did not improve from 0.92640\n",
            "Epoch 713/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0570 - acc: 0.9945 - val_loss: 0.3155 - val_acc: 0.9236\n",
            "\n",
            "Epoch 00713: val_acc did not improve from 0.92640\n",
            "Epoch 714/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0631 - acc: 0.9917 - val_loss: 0.3166 - val_acc: 0.9236\n",
            "\n",
            "Epoch 00714: val_acc did not improve from 0.92640\n",
            "Epoch 715/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0603 - acc: 0.9936 - val_loss: 0.3165 - val_acc: 0.9261\n",
            "\n",
            "Epoch 00715: val_acc did not improve from 0.92640\n",
            "Epoch 716/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0601 - acc: 0.9926 - val_loss: 0.3134 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00716: val_acc did not improve from 0.92640\n",
            "Epoch 717/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0625 - acc: 0.9928 - val_loss: 0.3176 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00717: val_acc did not improve from 0.92640\n",
            "Epoch 718/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0647 - acc: 0.9912 - val_loss: 0.3124 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00718: val_acc did not improve from 0.92640\n",
            "Epoch 719/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0592 - acc: 0.9935 - val_loss: 0.3144 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00719: val_acc did not improve from 0.92640\n",
            "Epoch 720/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0620 - acc: 0.9932 - val_loss: 0.3159 - val_acc: 0.9244\n",
            "\n",
            "Epoch 00720: val_acc did not improve from 0.92640\n",
            "Epoch 721/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0581 - acc: 0.9944 - val_loss: 0.3151 - val_acc: 0.9245\n",
            "\n",
            "Epoch 00721: val_acc did not improve from 0.92640\n",
            "Epoch 722/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0602 - acc: 0.9945 - val_loss: 0.3143 - val_acc: 0.9268\n",
            "\n",
            "Epoch 00722: val_acc improved from 0.92640 to 0.92680, saving model to /content/saved_models/cifar10_ResNet32v1_model.722.h5\n",
            "Epoch 723/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0592 - acc: 0.9943 - val_loss: 0.3164 - val_acc: 0.9262\n",
            "\n",
            "Epoch 00723: val_acc did not improve from 0.92680\n",
            "Epoch 724/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0584 - acc: 0.9941 - val_loss: 0.3196 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00724: val_acc did not improve from 0.92680\n",
            "Epoch 725/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0653 - acc: 0.9917 - val_loss: 0.3175 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00725: val_acc did not improve from 0.92680\n",
            "Epoch 726/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0583 - acc: 0.9940 - val_loss: 0.3208 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00726: val_acc did not improve from 0.92680\n",
            "Epoch 727/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0584 - acc: 0.9943 - val_loss: 0.3190 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00727: val_acc did not improve from 0.92680\n",
            "Epoch 728/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0588 - acc: 0.9946 - val_loss: 0.3158 - val_acc: 0.9240\n",
            "\n",
            "Epoch 00728: val_acc did not improve from 0.92680\n",
            "Epoch 729/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0610 - acc: 0.9929 - val_loss: 0.3165 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00729: val_acc did not improve from 0.92680\n",
            "Epoch 730/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0676 - acc: 0.9904 - val_loss: 0.3188 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00730: val_acc did not improve from 0.92680\n",
            "Epoch 731/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0604 - acc: 0.9934 - val_loss: 0.3160 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00731: val_acc did not improve from 0.92680\n",
            "Epoch 732/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0606 - acc: 0.9926 - val_loss: 0.3176 - val_acc: 0.9245\n",
            "\n",
            "Epoch 00732: val_acc did not improve from 0.92680\n",
            "Epoch 733/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0629 - acc: 0.9913 - val_loss: 0.3160 - val_acc: 0.9268\n",
            "\n",
            "Epoch 00733: val_acc did not improve from 0.92680\n",
            "Epoch 734/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0618 - acc: 0.9918 - val_loss: 0.3179 - val_acc: 0.9246\n",
            "\n",
            "Epoch 00734: val_acc did not improve from 0.92680\n",
            "Epoch 735/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0602 - acc: 0.9929 - val_loss: 0.3188 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00735: val_acc did not improve from 0.92680\n",
            "Epoch 736/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0571 - acc: 0.9953 - val_loss: 0.3228 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00736: val_acc did not improve from 0.92680\n",
            "Epoch 737/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0586 - acc: 0.9931 - val_loss: 0.3238 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00737: val_acc did not improve from 0.92680\n",
            "Epoch 738/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0586 - acc: 0.9946 - val_loss: 0.3217 - val_acc: 0.9262\n",
            "\n",
            "Epoch 00738: val_acc did not improve from 0.92680\n",
            "Epoch 739/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0602 - acc: 0.9930 - val_loss: 0.3213 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00739: val_acc did not improve from 0.92680\n",
            "Epoch 740/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0597 - acc: 0.9916 - val_loss: 0.3221 - val_acc: 0.9246\n",
            "\n",
            "Epoch 00740: val_acc did not improve from 0.92680\n",
            "Epoch 741/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0588 - acc: 0.9931 - val_loss: 0.3188 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00741: val_acc did not improve from 0.92680\n",
            "Epoch 742/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0617 - acc: 0.9922 - val_loss: 0.3207 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00742: val_acc did not improve from 0.92680\n",
            "Epoch 743/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0582 - acc: 0.9938 - val_loss: 0.3209 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00743: val_acc did not improve from 0.92680\n",
            "Epoch 744/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0610 - acc: 0.9935 - val_loss: 0.3211 - val_acc: 0.9243\n",
            "\n",
            "Epoch 00744: val_acc did not improve from 0.92680\n",
            "Epoch 745/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0595 - acc: 0.9932 - val_loss: 0.3185 - val_acc: 0.9244\n",
            "\n",
            "Epoch 00745: val_acc did not improve from 0.92680\n",
            "Epoch 746/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0578 - acc: 0.9941 - val_loss: 0.3235 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00746: val_acc did not improve from 0.92680\n",
            "Epoch 747/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0577 - acc: 0.9949 - val_loss: 0.3244 - val_acc: 0.9244\n",
            "\n",
            "Epoch 00747: val_acc did not improve from 0.92680\n",
            "Epoch 748/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0605 - acc: 0.9934 - val_loss: 0.3226 - val_acc: 0.9236\n",
            "\n",
            "Epoch 00748: val_acc did not improve from 0.92680\n",
            "Epoch 749/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0595 - acc: 0.9932 - val_loss: 0.3249 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00749: val_acc did not improve from 0.92680\n",
            "Epoch 750/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0607 - acc: 0.9932 - val_loss: 0.3251 - val_acc: 0.9236\n",
            "\n",
            "Epoch 00750: val_acc did not improve from 0.92680\n",
            "Epoch 751/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0564 - acc: 0.9954 - val_loss: 0.3228 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00751: val_acc did not improve from 0.92680\n",
            "Epoch 752/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0585 - acc: 0.9941 - val_loss: 0.3222 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00752: val_acc did not improve from 0.92680\n",
            "Epoch 753/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0613 - acc: 0.9929 - val_loss: 0.3241 - val_acc: 0.9242\n",
            "\n",
            "Epoch 00753: val_acc did not improve from 0.92680\n",
            "Epoch 754/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0582 - acc: 0.9940 - val_loss: 0.3207 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00754: val_acc did not improve from 0.92680\n",
            "Epoch 755/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0585 - acc: 0.9940 - val_loss: 0.3188 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00755: val_acc did not improve from 0.92680\n",
            "Epoch 756/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0548 - acc: 0.9963 - val_loss: 0.3260 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00756: val_acc did not improve from 0.92680\n",
            "Epoch 757/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0580 - acc: 0.9927 - val_loss: 0.3178 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00757: val_acc did not improve from 0.92680\n",
            "Epoch 758/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0605 - acc: 0.9915 - val_loss: 0.3220 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00758: val_acc did not improve from 0.92680\n",
            "Epoch 759/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0591 - acc: 0.9938 - val_loss: 0.3254 - val_acc: 0.9236\n",
            "\n",
            "Epoch 00759: val_acc did not improve from 0.92680\n",
            "Epoch 760/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0616 - acc: 0.9924 - val_loss: 0.3243 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00760: val_acc did not improve from 0.92680\n",
            "Epoch 761/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0565 - acc: 0.9941 - val_loss: 0.3264 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00761: val_acc did not improve from 0.92680\n",
            "Epoch 762/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0574 - acc: 0.9945 - val_loss: 0.3280 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00762: val_acc did not improve from 0.92680\n",
            "Epoch 763/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0598 - acc: 0.9940 - val_loss: 0.3291 - val_acc: 0.9240\n",
            "\n",
            "Epoch 00763: val_acc did not improve from 0.92680\n",
            "Epoch 764/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0606 - acc: 0.9920 - val_loss: 0.3249 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00764: val_acc did not improve from 0.92680\n",
            "Epoch 765/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0577 - acc: 0.9939 - val_loss: 0.3230 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00765: val_acc did not improve from 0.92680\n",
            "Epoch 766/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0641 - acc: 0.9908 - val_loss: 0.3212 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00766: val_acc did not improve from 0.92680\n",
            "Epoch 767/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0575 - acc: 0.9928 - val_loss: 0.3237 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00767: val_acc did not improve from 0.92680\n",
            "Epoch 768/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0609 - acc: 0.9912 - val_loss: 0.3261 - val_acc: 0.9243\n",
            "\n",
            "Epoch 00768: val_acc did not improve from 0.92680\n",
            "Epoch 769/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0552 - acc: 0.9951 - val_loss: 0.3261 - val_acc: 0.9242\n",
            "\n",
            "Epoch 00769: val_acc did not improve from 0.92680\n",
            "Epoch 770/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0564 - acc: 0.9947 - val_loss: 0.3250 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00770: val_acc did not improve from 0.92680\n",
            "Epoch 771/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0555 - acc: 0.9956 - val_loss: 0.3222 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00771: val_acc did not improve from 0.92680\n",
            "Epoch 772/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0552 - acc: 0.9958 - val_loss: 0.3264 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00772: val_acc did not improve from 0.92680\n",
            "Epoch 773/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0581 - acc: 0.9937 - val_loss: 0.3241 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00773: val_acc did not improve from 0.92680\n",
            "Epoch 774/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0593 - acc: 0.9929 - val_loss: 0.3238 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00774: val_acc did not improve from 0.92680\n",
            "Epoch 775/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0586 - acc: 0.9934 - val_loss: 0.3213 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00775: val_acc did not improve from 0.92680\n",
            "Epoch 776/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0567 - acc: 0.9950 - val_loss: 0.3224 - val_acc: 0.9261\n",
            "\n",
            "Epoch 00776: val_acc did not improve from 0.92680\n",
            "Epoch 777/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0612 - acc: 0.9922 - val_loss: 0.3273 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00777: val_acc did not improve from 0.92680\n",
            "Epoch 778/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0579 - acc: 0.9946 - val_loss: 0.3278 - val_acc: 0.9241\n",
            "\n",
            "Epoch 00778: val_acc did not improve from 0.92680\n",
            "Epoch 779/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0586 - acc: 0.9938 - val_loss: 0.3291 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00779: val_acc did not improve from 0.92680\n",
            "Epoch 780/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0541 - acc: 0.9953 - val_loss: 0.3268 - val_acc: 0.9239\n",
            "\n",
            "Epoch 00780: val_acc did not improve from 0.92680\n",
            "Epoch 781/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0589 - acc: 0.9933 - val_loss: 0.3289 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00781: val_acc did not improve from 0.92680\n",
            "Epoch 782/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0564 - acc: 0.9943 - val_loss: 0.3235 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00782: val_acc did not improve from 0.92680\n",
            "Epoch 783/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0579 - acc: 0.9955 - val_loss: 0.3259 - val_acc: 0.9239\n",
            "\n",
            "Epoch 00783: val_acc did not improve from 0.92680\n",
            "Epoch 784/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0588 - acc: 0.9935 - val_loss: 0.3302 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00784: val_acc did not improve from 0.92680\n",
            "Epoch 785/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0574 - acc: 0.9940 - val_loss: 0.3253 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00785: val_acc did not improve from 0.92680\n",
            "Epoch 786/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0594 - acc: 0.9927 - val_loss: 0.3234 - val_acc: 0.9234\n",
            "\n",
            "Epoch 00786: val_acc did not improve from 0.92680\n",
            "Epoch 787/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0564 - acc: 0.9946 - val_loss: 0.3215 - val_acc: 0.9231\n",
            "\n",
            "Epoch 00787: val_acc did not improve from 0.92680\n",
            "Epoch 788/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0554 - acc: 0.9949 - val_loss: 0.3259 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00788: val_acc did not improve from 0.92680\n",
            "Epoch 789/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0572 - acc: 0.9940 - val_loss: 0.3266 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00789: val_acc did not improve from 0.92680\n",
            "Epoch 790/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0594 - acc: 0.9936 - val_loss: 0.3252 - val_acc: 0.9240\n",
            "\n",
            "Epoch 00790: val_acc did not improve from 0.92680\n",
            "Epoch 791/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0547 - acc: 0.9963 - val_loss: 0.3232 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00791: val_acc did not improve from 0.92680\n",
            "Epoch 792/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0575 - acc: 0.9945 - val_loss: 0.3226 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00792: val_acc did not improve from 0.92680\n",
            "Epoch 793/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0566 - acc: 0.9942 - val_loss: 0.3251 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00793: val_acc did not improve from 0.92680\n",
            "Epoch 794/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0561 - acc: 0.9946 - val_loss: 0.3231 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00794: val_acc did not improve from 0.92680\n",
            "Epoch 795/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0563 - acc: 0.9953 - val_loss: 0.3231 - val_acc: 0.9240\n",
            "\n",
            "Epoch 00795: val_acc did not improve from 0.92680\n",
            "Epoch 796/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0577 - acc: 0.9939 - val_loss: 0.3238 - val_acc: 0.9239\n",
            "\n",
            "Epoch 00796: val_acc did not improve from 0.92680\n",
            "Epoch 797/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0579 - acc: 0.9932 - val_loss: 0.3248 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00797: val_acc did not improve from 0.92680\n",
            "Epoch 798/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0566 - acc: 0.9941 - val_loss: 0.3259 - val_acc: 0.9234\n",
            "\n",
            "Epoch 00798: val_acc did not improve from 0.92680\n",
            "Epoch 799/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0552 - acc: 0.9948 - val_loss: 0.3287 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00799: val_acc did not improve from 0.92680\n",
            "Epoch 800/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0554 - acc: 0.9950 - val_loss: 0.3252 - val_acc: 0.9239\n",
            "\n",
            "Epoch 00800: val_acc did not improve from 0.92680\n",
            "Epoch 801/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0584 - acc: 0.9926 - val_loss: 0.3291 - val_acc: 0.9241\n",
            "\n",
            "Epoch 00801: val_acc did not improve from 0.92680\n",
            "Epoch 802/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0553 - acc: 0.9942 - val_loss: 0.3262 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00802: val_acc did not improve from 0.92680\n",
            "Epoch 803/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0598 - acc: 0.9930 - val_loss: 0.3249 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00803: val_acc did not improve from 0.92680\n",
            "Epoch 804/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0599 - acc: 0.9920 - val_loss: 0.3246 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00804: val_acc did not improve from 0.92680\n",
            "Epoch 805/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0570 - acc: 0.9936 - val_loss: 0.3243 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00805: val_acc did not improve from 0.92680\n",
            "Epoch 806/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0569 - acc: 0.9930 - val_loss: 0.3230 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00806: val_acc did not improve from 0.92680\n",
            "Epoch 807/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0556 - acc: 0.9953 - val_loss: 0.3241 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00807: val_acc did not improve from 0.92680\n",
            "Epoch 808/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0589 - acc: 0.9937 - val_loss: 0.3233 - val_acc: 0.9245\n",
            "\n",
            "Epoch 00808: val_acc did not improve from 0.92680\n",
            "Epoch 809/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0551 - acc: 0.9951 - val_loss: 0.3229 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00809: val_acc did not improve from 0.92680\n",
            "Epoch 810/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0539 - acc: 0.9958 - val_loss: 0.3220 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00810: val_acc did not improve from 0.92680\n",
            "Epoch 811/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0568 - acc: 0.9951 - val_loss: 0.3223 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00811: val_acc did not improve from 0.92680\n",
            "Epoch 812/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0552 - acc: 0.9935 - val_loss: 0.3215 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00812: val_acc did not improve from 0.92680\n",
            "Epoch 813/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0575 - acc: 0.9938 - val_loss: 0.3216 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00813: val_acc did not improve from 0.92680\n",
            "Epoch 814/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0559 - acc: 0.9948 - val_loss: 0.3217 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00814: val_acc did not improve from 0.92680\n",
            "Epoch 815/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0574 - acc: 0.9941 - val_loss: 0.3211 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00815: val_acc did not improve from 0.92680\n",
            "Epoch 816/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0545 - acc: 0.9946 - val_loss: 0.3211 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00816: val_acc did not improve from 0.92680\n",
            "Epoch 817/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0578 - acc: 0.9947 - val_loss: 0.3206 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00817: val_acc did not improve from 0.92680\n",
            "Epoch 818/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0557 - acc: 0.9939 - val_loss: 0.3211 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00818: val_acc did not improve from 0.92680\n",
            "Epoch 819/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0552 - acc: 0.9954 - val_loss: 0.3213 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00819: val_acc did not improve from 0.92680\n",
            "Epoch 820/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0609 - acc: 0.9934 - val_loss: 0.3212 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00820: val_acc did not improve from 0.92680\n",
            "Epoch 821/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0546 - acc: 0.9955 - val_loss: 0.3218 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00821: val_acc did not improve from 0.92680\n",
            "Epoch 822/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0569 - acc: 0.9934 - val_loss: 0.3208 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00822: val_acc did not improve from 0.92680\n",
            "Epoch 823/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0551 - acc: 0.9944 - val_loss: 0.3209 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00823: val_acc did not improve from 0.92680\n",
            "Epoch 824/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0545 - acc: 0.9952 - val_loss: 0.3209 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00824: val_acc did not improve from 0.92680\n",
            "Epoch 825/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0592 - acc: 0.9931 - val_loss: 0.3216 - val_acc: 0.9261\n",
            "\n",
            "Epoch 00825: val_acc did not improve from 0.92680\n",
            "Epoch 826/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0555 - acc: 0.9952 - val_loss: 0.3222 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00826: val_acc did not improve from 0.92680\n",
            "Epoch 827/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0558 - acc: 0.9951 - val_loss: 0.3217 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00827: val_acc did not improve from 0.92680\n",
            "Epoch 828/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0560 - acc: 0.9940 - val_loss: 0.3215 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00828: val_acc did not improve from 0.92680\n",
            "Epoch 829/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0579 - acc: 0.9937 - val_loss: 0.3215 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00829: val_acc did not improve from 0.92680\n",
            "Epoch 830/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0571 - acc: 0.9941 - val_loss: 0.3222 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00830: val_acc did not improve from 0.92680\n",
            "Epoch 831/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0565 - acc: 0.9948 - val_loss: 0.3215 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00831: val_acc did not improve from 0.92680\n",
            "Epoch 832/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0558 - acc: 0.9949 - val_loss: 0.3210 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00832: val_acc did not improve from 0.92680\n",
            "Epoch 833/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0543 - acc: 0.9948 - val_loss: 0.3215 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00833: val_acc did not improve from 0.92680\n",
            "Epoch 834/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0566 - acc: 0.9937 - val_loss: 0.3216 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00834: val_acc did not improve from 0.92680\n",
            "Epoch 835/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0544 - acc: 0.9964 - val_loss: 0.3218 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00835: val_acc did not improve from 0.92680\n",
            "Epoch 836/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0584 - acc: 0.9935 - val_loss: 0.3210 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00836: val_acc did not improve from 0.92680\n",
            "Epoch 837/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0541 - acc: 0.9957 - val_loss: 0.3219 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00837: val_acc did not improve from 0.92680\n",
            "Epoch 838/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0552 - acc: 0.9947 - val_loss: 0.3214 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00838: val_acc did not improve from 0.92680\n",
            "Epoch 839/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0570 - acc: 0.9933 - val_loss: 0.3220 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00839: val_acc did not improve from 0.92680\n",
            "Epoch 840/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0560 - acc: 0.9940 - val_loss: 0.3208 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00840: val_acc did not improve from 0.92680\n",
            "Epoch 841/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0520 - acc: 0.9970 - val_loss: 0.3212 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00841: val_acc did not improve from 0.92680\n",
            "Epoch 842/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0564 - acc: 0.9943 - val_loss: 0.3214 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00842: val_acc did not improve from 0.92680\n",
            "Epoch 843/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0526 - acc: 0.9960 - val_loss: 0.3213 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00843: val_acc did not improve from 0.92680\n",
            "Epoch 844/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0562 - acc: 0.9939 - val_loss: 0.3211 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00844: val_acc did not improve from 0.92680\n",
            "Epoch 845/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0549 - acc: 0.9953 - val_loss: 0.3220 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00845: val_acc did not improve from 0.92680\n",
            "Epoch 846/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0565 - acc: 0.9953 - val_loss: 0.3223 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00846: val_acc did not improve from 0.92680\n",
            "Epoch 847/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0567 - acc: 0.9945 - val_loss: 0.3221 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00847: val_acc did not improve from 0.92680\n",
            "Epoch 848/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0538 - acc: 0.9952 - val_loss: 0.3220 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00848: val_acc did not improve from 0.92680\n",
            "Epoch 849/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0538 - acc: 0.9956 - val_loss: 0.3214 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00849: val_acc did not improve from 0.92680\n",
            "Epoch 850/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0577 - acc: 0.9924 - val_loss: 0.3211 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00850: val_acc did not improve from 0.92680\n",
            "Epoch 851/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0561 - acc: 0.9947 - val_loss: 0.3208 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00851: val_acc did not improve from 0.92680\n",
            "Epoch 852/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0543 - acc: 0.9958 - val_loss: 0.3210 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00852: val_acc did not improve from 0.92680\n",
            "Epoch 853/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0562 - acc: 0.9944 - val_loss: 0.3212 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00853: val_acc did not improve from 0.92680\n",
            "Epoch 854/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0582 - acc: 0.9931 - val_loss: 0.3221 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00854: val_acc did not improve from 0.92680\n",
            "Epoch 855/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0522 - acc: 0.9962 - val_loss: 0.3215 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00855: val_acc did not improve from 0.92680\n",
            "Epoch 856/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0538 - acc: 0.9948 - val_loss: 0.3216 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00856: val_acc did not improve from 0.92680\n",
            "Epoch 857/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0566 - acc: 0.9933 - val_loss: 0.3209 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00857: val_acc did not improve from 0.92680\n",
            "Epoch 858/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0530 - acc: 0.9957 - val_loss: 0.3210 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00858: val_acc did not improve from 0.92680\n",
            "Epoch 859/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0540 - acc: 0.9955 - val_loss: 0.3208 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00859: val_acc did not improve from 0.92680\n",
            "Epoch 860/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0564 - acc: 0.9946 - val_loss: 0.3210 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00860: val_acc did not improve from 0.92680\n",
            "Epoch 861/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0554 - acc: 0.9950 - val_loss: 0.3206 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00861: val_acc did not improve from 0.92680\n",
            "Epoch 862/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0556 - acc: 0.9946 - val_loss: 0.3211 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00862: val_acc did not improve from 0.92680\n",
            "Epoch 863/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0546 - acc: 0.9948 - val_loss: 0.3210 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00863: val_acc did not improve from 0.92680\n",
            "Epoch 864/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0551 - acc: 0.9942 - val_loss: 0.3209 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00864: val_acc did not improve from 0.92680\n",
            "Epoch 865/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0554 - acc: 0.9942 - val_loss: 0.3208 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00865: val_acc did not improve from 0.92680\n",
            "Epoch 866/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0582 - acc: 0.9927 - val_loss: 0.3209 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00866: val_acc did not improve from 0.92680\n",
            "Epoch 867/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0562 - acc: 0.9948 - val_loss: 0.3224 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00867: val_acc did not improve from 0.92680\n",
            "Epoch 868/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0535 - acc: 0.9954 - val_loss: 0.3217 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00868: val_acc did not improve from 0.92680\n",
            "Epoch 869/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0552 - acc: 0.9949 - val_loss: 0.3212 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00869: val_acc did not improve from 0.92680\n",
            "Epoch 870/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0557 - acc: 0.9950 - val_loss: 0.3212 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00870: val_acc did not improve from 0.92680\n",
            "Epoch 871/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0523 - acc: 0.9955 - val_loss: 0.3219 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00871: val_acc did not improve from 0.92680\n",
            "Epoch 872/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0565 - acc: 0.9948 - val_loss: 0.3220 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00872: val_acc did not improve from 0.92680\n",
            "Epoch 873/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0587 - acc: 0.9934 - val_loss: 0.3221 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00873: val_acc did not improve from 0.92680\n",
            "Epoch 874/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0548 - acc: 0.9959 - val_loss: 0.3213 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00874: val_acc did not improve from 0.92680\n",
            "Epoch 875/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0550 - acc: 0.9949 - val_loss: 0.3210 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00875: val_acc did not improve from 0.92680\n",
            "Epoch 876/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0515 - acc: 0.9959 - val_loss: 0.3217 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00876: val_acc did not improve from 0.92680\n",
            "Epoch 877/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0522 - acc: 0.9955 - val_loss: 0.3219 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00877: val_acc did not improve from 0.92680\n",
            "Epoch 878/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0544 - acc: 0.9945 - val_loss: 0.3218 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00878: val_acc did not improve from 0.92680\n",
            "Epoch 879/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0545 - acc: 0.9941 - val_loss: 0.3209 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00879: val_acc did not improve from 0.92680\n",
            "Epoch 880/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0550 - acc: 0.9964 - val_loss: 0.3216 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00880: val_acc did not improve from 0.92680\n",
            "Epoch 881/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0542 - acc: 0.9954 - val_loss: 0.3216 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00881: val_acc did not improve from 0.92680\n",
            "Epoch 882/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0586 - acc: 0.9934 - val_loss: 0.3217 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00882: val_acc did not improve from 0.92680\n",
            "Epoch 883/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0532 - acc: 0.9951 - val_loss: 0.3228 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00883: val_acc did not improve from 0.92680\n",
            "Epoch 884/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0541 - acc: 0.9954 - val_loss: 0.3217 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00884: val_acc did not improve from 0.92680\n",
            "Epoch 885/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0553 - acc: 0.9949 - val_loss: 0.3217 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00885: val_acc did not improve from 0.92680\n",
            "Epoch 886/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0529 - acc: 0.9948 - val_loss: 0.3211 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00886: val_acc did not improve from 0.92680\n",
            "Epoch 887/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0543 - acc: 0.9962 - val_loss: 0.3210 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00887: val_acc did not improve from 0.92680\n",
            "Epoch 888/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0590 - acc: 0.9921 - val_loss: 0.3214 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00888: val_acc did not improve from 0.92680\n",
            "Epoch 889/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0536 - acc: 0.9958 - val_loss: 0.3212 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00889: val_acc did not improve from 0.92680\n",
            "Epoch 890/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0541 - acc: 0.9945 - val_loss: 0.3218 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00890: val_acc did not improve from 0.92680\n",
            "Epoch 891/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0545 - acc: 0.9949 - val_loss: 0.3216 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00891: val_acc did not improve from 0.92680\n",
            "Epoch 892/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0543 - acc: 0.9958 - val_loss: 0.3217 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00892: val_acc did not improve from 0.92680\n",
            "Epoch 893/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0552 - acc: 0.9944 - val_loss: 0.3223 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00893: val_acc did not improve from 0.92680\n",
            "Epoch 894/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0547 - acc: 0.9949 - val_loss: 0.3223 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00894: val_acc did not improve from 0.92680\n",
            "Epoch 895/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0562 - acc: 0.9938 - val_loss: 0.3222 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00895: val_acc did not improve from 0.92680\n",
            "Epoch 896/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0553 - acc: 0.9949 - val_loss: 0.3222 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00896: val_acc did not improve from 0.92680\n",
            "Epoch 897/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0577 - acc: 0.9927 - val_loss: 0.3225 - val_acc: 0.9239\n",
            "\n",
            "Epoch 00897: val_acc did not improve from 0.92680\n",
            "Epoch 898/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0563 - acc: 0.9941 - val_loss: 0.3215 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00898: val_acc did not improve from 0.92680\n",
            "Epoch 899/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0563 - acc: 0.9931 - val_loss: 0.3218 - val_acc: 0.9246\n",
            "\n",
            "Epoch 00899: val_acc did not improve from 0.92680\n",
            "Epoch 900/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0516 - acc: 0.9960 - val_loss: 0.3225 - val_acc: 0.9246\n",
            "\n",
            "Epoch 00900: val_acc did not improve from 0.92680\n",
            "Epoch 901/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0547 - acc: 0.9951 - val_loss: 0.3225 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00901: val_acc did not improve from 0.92680\n",
            "Epoch 902/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0546 - acc: 0.9949 - val_loss: 0.3222 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00902: val_acc did not improve from 0.92680\n",
            "Epoch 903/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0533 - acc: 0.9955 - val_loss: 0.3219 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00903: val_acc did not improve from 0.92680\n",
            "Epoch 904/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0528 - acc: 0.9957 - val_loss: 0.3221 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00904: val_acc did not improve from 0.92680\n",
            "Epoch 905/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0546 - acc: 0.9929 - val_loss: 0.3234 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00905: val_acc did not improve from 0.92680\n",
            "Epoch 906/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0552 - acc: 0.9953 - val_loss: 0.3225 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00906: val_acc did not improve from 0.92680\n",
            "Epoch 907/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0544 - acc: 0.9947 - val_loss: 0.3223 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00907: val_acc did not improve from 0.92680\n",
            "Epoch 908/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0555 - acc: 0.9943 - val_loss: 0.3227 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00908: val_acc did not improve from 0.92680\n",
            "Epoch 909/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0566 - acc: 0.9933 - val_loss: 0.3220 - val_acc: 0.9262\n",
            "\n",
            "Epoch 00909: val_acc did not improve from 0.92680\n",
            "Epoch 910/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0547 - acc: 0.9948 - val_loss: 0.3226 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00910: val_acc did not improve from 0.92680\n",
            "Epoch 911/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0557 - acc: 0.9943 - val_loss: 0.3215 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00911: val_acc did not improve from 0.92680\n",
            "Epoch 912/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0543 - acc: 0.9949 - val_loss: 0.3222 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00912: val_acc did not improve from 0.92680\n",
            "Epoch 913/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0550 - acc: 0.9940 - val_loss: 0.3226 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00913: val_acc did not improve from 0.92680\n",
            "Epoch 914/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0534 - acc: 0.9951 - val_loss: 0.3221 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00914: val_acc did not improve from 0.92680\n",
            "Epoch 915/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0539 - acc: 0.9955 - val_loss: 0.3219 - val_acc: 0.9264\n",
            "\n",
            "Epoch 00915: val_acc did not improve from 0.92680\n",
            "Epoch 916/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0550 - acc: 0.9944 - val_loss: 0.3211 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00916: val_acc did not improve from 0.92680\n",
            "Epoch 917/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0566 - acc: 0.9936 - val_loss: 0.3218 - val_acc: 0.9262\n",
            "\n",
            "Epoch 00917: val_acc did not improve from 0.92680\n",
            "Epoch 918/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0560 - acc: 0.9943 - val_loss: 0.3221 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00918: val_acc did not improve from 0.92680\n",
            "Epoch 919/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0528 - acc: 0.9956 - val_loss: 0.3218 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00919: val_acc did not improve from 0.92680\n",
            "Epoch 920/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0548 - acc: 0.9954 - val_loss: 0.3221 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00920: val_acc did not improve from 0.92680\n",
            "Epoch 921/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0588 - acc: 0.9945 - val_loss: 0.3229 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00921: val_acc did not improve from 0.92680\n",
            "Epoch 922/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0550 - acc: 0.9949 - val_loss: 0.3217 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00922: val_acc did not improve from 0.92680\n",
            "Epoch 923/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0546 - acc: 0.9946 - val_loss: 0.3214 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00923: val_acc did not improve from 0.92680\n",
            "Epoch 924/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0518 - acc: 0.9963 - val_loss: 0.3220 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00924: val_acc did not improve from 0.92680\n",
            "Epoch 925/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0556 - acc: 0.9949 - val_loss: 0.3230 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00925: val_acc did not improve from 0.92680\n",
            "Epoch 926/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0524 - acc: 0.9963 - val_loss: 0.3222 - val_acc: 0.9261\n",
            "\n",
            "Epoch 00926: val_acc did not improve from 0.92680\n",
            "Epoch 927/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0537 - acc: 0.9961 - val_loss: 0.3211 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00927: val_acc did not improve from 0.92680\n",
            "Epoch 928/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0554 - acc: 0.9954 - val_loss: 0.3221 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00928: val_acc did not improve from 0.92680\n",
            "Epoch 929/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0533 - acc: 0.9946 - val_loss: 0.3219 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00929: val_acc did not improve from 0.92680\n",
            "Epoch 930/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0535 - acc: 0.9942 - val_loss: 0.3223 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00930: val_acc did not improve from 0.92680\n",
            "Epoch 931/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0533 - acc: 0.9961 - val_loss: 0.3233 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00931: val_acc did not improve from 0.92680\n",
            "Epoch 932/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0541 - acc: 0.9966 - val_loss: 0.3230 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00932: val_acc did not improve from 0.92680\n",
            "Epoch 933/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0589 - acc: 0.9930 - val_loss: 0.3218 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00933: val_acc did not improve from 0.92680\n",
            "Epoch 934/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0563 - acc: 0.9944 - val_loss: 0.3222 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00934: val_acc did not improve from 0.92680\n",
            "Epoch 935/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0577 - acc: 0.9941 - val_loss: 0.3223 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00935: val_acc did not improve from 0.92680\n",
            "Epoch 936/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0552 - acc: 0.9941 - val_loss: 0.3225 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00936: val_acc did not improve from 0.92680\n",
            "Epoch 937/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0567 - acc: 0.9936 - val_loss: 0.3224 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00937: val_acc did not improve from 0.92680\n",
            "Epoch 938/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0608 - acc: 0.9916 - val_loss: 0.3224 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00938: val_acc did not improve from 0.92680\n",
            "Epoch 939/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0556 - acc: 0.9942 - val_loss: 0.3223 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00939: val_acc did not improve from 0.92680\n",
            "Epoch 940/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.0543 - acc: 0.9954 - val_loss: 0.3220 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00940: val_acc did not improve from 0.92680\n",
            "Epoch 941/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0540 - acc: 0.9949 - val_loss: 0.3223 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00941: val_acc did not improve from 0.92680\n",
            "Epoch 942/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0565 - acc: 0.9928 - val_loss: 0.3224 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00942: val_acc did not improve from 0.92680\n",
            "Epoch 943/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0558 - acc: 0.9950 - val_loss: 0.3220 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00943: val_acc did not improve from 0.92680\n",
            "Epoch 944/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0539 - acc: 0.9951 - val_loss: 0.3219 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00944: val_acc did not improve from 0.92680\n",
            "Epoch 945/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0523 - acc: 0.9962 - val_loss: 0.3225 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00945: val_acc did not improve from 0.92680\n",
            "Epoch 946/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0563 - acc: 0.9936 - val_loss: 0.3231 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00946: val_acc did not improve from 0.92680\n",
            "Epoch 947/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0540 - acc: 0.9950 - val_loss: 0.3225 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00947: val_acc did not improve from 0.92680\n",
            "Epoch 948/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0523 - acc: 0.9961 - val_loss: 0.3221 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00948: val_acc did not improve from 0.92680\n",
            "Epoch 949/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0545 - acc: 0.9945 - val_loss: 0.3213 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00949: val_acc did not improve from 0.92680\n",
            "Epoch 950/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0538 - acc: 0.9956 - val_loss: 0.3210 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00950: val_acc did not improve from 0.92680\n",
            "Epoch 951/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0564 - acc: 0.9942 - val_loss: 0.3211 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00951: val_acc did not improve from 0.92680\n",
            "Epoch 952/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0596 - acc: 0.9921 - val_loss: 0.3217 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00952: val_acc did not improve from 0.92680\n",
            "Epoch 953/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0527 - acc: 0.9950 - val_loss: 0.3222 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00953: val_acc did not improve from 0.92680\n",
            "Epoch 954/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0575 - acc: 0.9947 - val_loss: 0.3217 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00954: val_acc did not improve from 0.92680\n",
            "Epoch 955/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0540 - acc: 0.9952 - val_loss: 0.3215 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00955: val_acc did not improve from 0.92680\n",
            "Epoch 956/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0552 - acc: 0.9951 - val_loss: 0.3217 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00956: val_acc did not improve from 0.92680\n",
            "Epoch 957/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0551 - acc: 0.9945 - val_loss: 0.3211 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00957: val_acc did not improve from 0.92680\n",
            "Epoch 958/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0534 - acc: 0.9952 - val_loss: 0.3213 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00958: val_acc did not improve from 0.92680\n",
            "Epoch 959/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0536 - acc: 0.9946 - val_loss: 0.3223 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00959: val_acc did not improve from 0.92680\n",
            "Epoch 960/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0549 - acc: 0.9953 - val_loss: 0.3218 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00960: val_acc did not improve from 0.92680\n",
            "Epoch 961/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0568 - acc: 0.9937 - val_loss: 0.3220 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00961: val_acc did not improve from 0.92680\n",
            "Epoch 962/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0551 - acc: 0.9953 - val_loss: 0.3220 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00962: val_acc did not improve from 0.92680\n",
            "Epoch 963/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0536 - acc: 0.9957 - val_loss: 0.3219 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00963: val_acc did not improve from 0.92680\n",
            "Epoch 964/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0542 - acc: 0.9952 - val_loss: 0.3226 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00964: val_acc did not improve from 0.92680\n",
            "Epoch 965/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0544 - acc: 0.9950 - val_loss: 0.3220 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00965: val_acc did not improve from 0.92680\n",
            "Epoch 966/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0517 - acc: 0.9963 - val_loss: 0.3227 - val_acc: 0.9262\n",
            "\n",
            "Epoch 00966: val_acc did not improve from 0.92680\n",
            "Epoch 967/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0538 - acc: 0.9955 - val_loss: 0.3221 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00967: val_acc did not improve from 0.92680\n",
            "Epoch 968/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0520 - acc: 0.9965 - val_loss: 0.3228 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00968: val_acc did not improve from 0.92680\n",
            "Epoch 969/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0537 - acc: 0.9948 - val_loss: 0.3213 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00969: val_acc did not improve from 0.92680\n",
            "Epoch 970/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0555 - acc: 0.9943 - val_loss: 0.3212 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00970: val_acc did not improve from 0.92680\n",
            "Epoch 971/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0556 - acc: 0.9949 - val_loss: 0.3217 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00971: val_acc did not improve from 0.92680\n",
            "Epoch 972/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0587 - acc: 0.9933 - val_loss: 0.3211 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00972: val_acc did not improve from 0.92680\n",
            "Epoch 973/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0524 - acc: 0.9953 - val_loss: 0.3218 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00973: val_acc did not improve from 0.92680\n",
            "Epoch 974/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0526 - acc: 0.9959 - val_loss: 0.3222 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00974: val_acc did not improve from 0.92680\n",
            "Epoch 975/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0528 - acc: 0.9962 - val_loss: 0.3222 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00975: val_acc did not improve from 0.92680\n",
            "Epoch 976/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0536 - acc: 0.9961 - val_loss: 0.3216 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00976: val_acc did not improve from 0.92680\n",
            "Epoch 977/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0593 - acc: 0.9945 - val_loss: 0.3222 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00977: val_acc did not improve from 0.92680\n",
            "Epoch 978/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0557 - acc: 0.9947 - val_loss: 0.3220 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00978: val_acc did not improve from 0.92680\n",
            "Epoch 979/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0543 - acc: 0.9955 - val_loss: 0.3223 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00979: val_acc did not improve from 0.92680\n",
            "Epoch 980/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0533 - acc: 0.9959 - val_loss: 0.3217 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00980: val_acc did not improve from 0.92680\n",
            "Epoch 981/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0523 - acc: 0.9963 - val_loss: 0.3217 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00981: val_acc did not improve from 0.92680\n",
            "Epoch 982/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0557 - acc: 0.9940 - val_loss: 0.3215 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00982: val_acc did not improve from 0.92680\n",
            "Epoch 983/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0533 - acc: 0.9944 - val_loss: 0.3223 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00983: val_acc did not improve from 0.92680\n",
            "Epoch 984/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0535 - acc: 0.9960 - val_loss: 0.3225 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00984: val_acc did not improve from 0.92680\n",
            "Epoch 985/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0557 - acc: 0.9950 - val_loss: 0.3227 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00985: val_acc did not improve from 0.92680\n",
            "Epoch 986/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0543 - acc: 0.9951 - val_loss: 0.3228 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00986: val_acc did not improve from 0.92680\n",
            "Epoch 987/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0536 - acc: 0.9957 - val_loss: 0.3220 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00987: val_acc did not improve from 0.92680\n",
            "Epoch 988/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0542 - acc: 0.9950 - val_loss: 0.3220 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00988: val_acc did not improve from 0.92680\n",
            "Epoch 989/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0508 - acc: 0.9972 - val_loss: 0.3219 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00989: val_acc did not improve from 0.92680\n",
            "Epoch 990/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0545 - acc: 0.9942 - val_loss: 0.3220 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00990: val_acc did not improve from 0.92680\n",
            "Epoch 991/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0540 - acc: 0.9953 - val_loss: 0.3228 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00991: val_acc did not improve from 0.92680\n",
            "Epoch 992/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0552 - acc: 0.9954 - val_loss: 0.3226 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00992: val_acc did not improve from 0.92680\n",
            "Epoch 993/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.0569 - acc: 0.9941 - val_loss: 0.3218 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00993: val_acc did not improve from 0.92680\n",
            "Epoch 994/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.0541 - acc: 0.9953 - val_loss: 0.3223 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00994: val_acc did not improve from 0.92680\n",
            "Epoch 995/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0568 - acc: 0.9937 - val_loss: 0.3225 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00995: val_acc did not improve from 0.92680\n",
            "Epoch 996/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0551 - acc: 0.9939 - val_loss: 0.3230 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00996: val_acc did not improve from 0.92680\n",
            "Epoch 997/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0534 - acc: 0.9959 - val_loss: 0.3228 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00997: val_acc did not improve from 0.92680\n",
            "Epoch 998/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0554 - acc: 0.9941 - val_loss: 0.3228 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00998: val_acc did not improve from 0.92680\n",
            "Epoch 999/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0542 - acc: 0.9963 - val_loss: 0.3232 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00999: val_acc did not improve from 0.92680\n",
            "Epoch 1000/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0550 - acc: 0.9959 - val_loss: 0.3228 - val_acc: 0.9253\n",
            "\n",
            "Epoch 01000: val_acc did not improve from 0.92680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "4pcLscHEEYsd",
        "outputId": "fbf6c2ab-f772-452d-8275-8961cca6afd6"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('simple_trainHistoryDict_clip_1', \"rb\"))\n",
        "functions.plot_loss_acc(history, 2, 0.4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uhRD_zK5NN1",
        "outputId": "071d143f-13fa-4b38-e103-c4c5415e816b"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9253000020980835"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsdFJk6P0Eex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3256d5-916f-4795-eb8a-328e1872e52f"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0746999979019165"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYsweyOS3wPM"
      },
      "source": [
        "#### Plotting final graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "MOF7V2LgY8_K",
        "outputId": "053b2067-9163-4a20-982e-a6104dfeaf6f"
      },
      "source": [
        "plot_final_graph(\"simple_\", ylim_loss=2, ylim_error=0.4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAGDCAYAAABqc/JJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9ebxdZXk2fN1r2HufKScTZMaEwRASApiAUbBErYooKIID2tep2tpKW9vXWn31A/GtVesnah1bFFNsha+VyqA4UCWCCkWQmRgyEEISMk9n3HsN9/fHM6xnTXvvk5wk55w81+93fufstdda+9n7JOs+17qu+7qJmWFhYWFhYWFhYWFhYWEx9uEc6wVYWFhYWFhYWFhYWFhYtAdL4CwsLCwsLCwsLCwsLMYJLIGzsLCwsLCwsLCwsLAYJ7AEzsLCwsLCwsLCwsLCYpzAEjgLCwsLCwsLCwsLC4txAkvgLCwsLCwsLCwsLCwsxgksgbOwsLCwsLCwsLCwsBgnsATOwuIIgYg2EdEfHut1WFhYWFhYjBXI2jhERP3G11eP9bosLMYTvGO9AAsLCwsLCwsLi+MKlzDzfzfbgYg8Zg4z21xmjtp9kZHub2ExXmAVOAuLowgiqhLRl4hom/z6EhFV5XPTieiHRLSfiPYS0b1E5Mjn/o6IthJRHxGtJaJXHtt3YmFhYWFhMXogoncT0a+J6ItEtAfAJ4loFRF9g4juJKIBAC8nokVEtFrWyieJ6FLjHLn9j9kbsrA4grAKnIXF0cXHAawAcDYABnAbgE8A+H8A/G8AWwCcIPddAYCJaCGAqwCcy8zbiGg+APfoLtvCwsLCwuKI48UAbgYwA4AP4BsA3g7gYgCvB9AF4GEANwB4NYALANxGRMuZea08h7l/5aiu3sLiKMEqcBYWRxfvAPApZt7JzLsAXAvgf8nnAgCzALyAmQNmvpeZGUAEoArgDCLymXkTM284Jqu3sLCwsLA4fNwqFTT19X65fRszf4WZQ2YekttuY+ZfM3MMcfOzG8BnmbnBzL8A8EMAVxrn1vsz8/DRe0sWFkcPlsBZWBxdzAbwrPH4WbkNAD4PYD2AnxHRRiL6KAAw83oAHwLwSQA7iehmIpoNCwsLCwuL8Yk3MvNk4+t6uf25gn3NbbMBPCfJnMKzAOaU7G9hMSFhCZyFxdHFNgAvMB6fJLeBmfuY+X8z88kALgXwN6rXjZm/x8wXyGMZwOeO7rItLCwsLCyOOLjFtm0A5qn+cImTAGxtcQ4LiwkFS+AsLI4sfCKqqS8ANwH4BBGdQETTAVwN4N8AgIheT0SnEhEBOABhnYyJaCERvUKGnQwDGAIQF7+chYWFhYXFhMX/ABgE8BEi8oloJYBLIPrmLCyOG1gCZ2FxZHEnBOFSXzUADwJ4DMDjAH4H4O/lvqcB+G8A/QDuA/B1Zr4bov/tswB2A9gO4EQAHzt6b8HCwsLCwmJUcUdmDtwP2jmImRsQhO21EDXx6wDeycy/P4JrtbAYcyCRkWBhYWFhYWFhYWFhYWEx1mEVOAsLCwsLCwsLCwsLi3GClgSOiOYR0d1E9JQcmPhXBfsQEf0TEa0noseI6EXGc+8ionXy612j/QYsLCwsLCyOJYjoIiJaK2vgR5vsdzkRMREtN7Z9TB63lohec3RWbGFhYWExntHSQklEswDMYubfEVEPgIcg4l+fMva5GMBfQAxOfDGALzPzi4loKkS/z3KIVKCHACxj5n1H5N1YWFhYWFgcRRCRC+BpAK8CsAXAbwFcadZIuV8PgB9BDBa+ipkfJKIzIIKNzoOIR/9vAC9k5ugovgULCwsLi3GGlgocMz/PzL+TP/cBWIP0vA0AeAOAG1ngfgCTJfF7DYC7mHmvJG13AbhoVN+BhYWFhYXFscN5ANYz80YZsHAzRE3M4v9CjP8wBwu/AcDNzFxn5mcg5kCed6QXbGFhYWExvjGiHjgimg/gHIgYVxNzkB6cuEVuK9tuYWFhYWExEdCyzsm2gnnM/KORHmthYWFhYZGF1+6ORNQN4BYAH2Lmg6O9ECL6EwB/AgAdHR3L5s2bd8jn6hjaDoobGOw6SW/zw37UhrbjaZ6LoLoLDgExGHMrc+EYPHYwHsTucDfmhBEmRxGGO2Yg8HoAAF7Yj46h7dhW6cQBhJhXmQOHQ3QOPIenqx0IEGGyOxmT3Emp9XQObgPAGOycgwPhXhyI+wEAc71ZcBwfcRzDcZI1dPc/g9DrxnDtBL3NjYbQObgVg51z0DH0PAJ/EurV6egY2gbiGIOdc+EHB8H13dhYEb/WKbGDntrc3OdTaexDtb4H/T2ngEEAgJ6+DWhUpqBenYqevvUAgOHaDNSGd4AdDzH5YHLghQMACH09p6CnbwPUvMy+nlPR07cBkdsBNxrEUMdseGEf3GgYA11ibnXXwGbETgVDHTPRMfS8PJc41g8OoDa8C/3dC8Dk5tbc3b8RgT8JsVNBdXgnnqpWMNmdDJdc7An3YLY/G5OGtgNw4MbDaMjPpzK8C9WwD33dJ7f8dzMWkP23MJYxntYKjK/1Hk9rffrpp3cz8wmt9xyfkAOHrwPw7sM4x6jVRyD5nfUHjN1DjBO7QuyOtqMzcjHoRpgbONgWz8bsHmBLYwumuFPQ4/ZgIB7AnnAPPPJQjQJMjyI863s4wTsBHU4HAGB3uBsBBwg5xCR3Ek4MA2zAIDwADQJm+jNRoQoAoKd/I8AxBrpegNjxUec6dgQ7AACTUMHkyszUehW6Bp6DE9cx1DETodede39eNIiOwW2I3BoGO5MaSBxjc7AF06MIe1wP3W4PJruTm35W24PtiDlACE69TwVVL/t6TkV3/0YQxxjqmIXQ7cTm4DlMjWJUarOxPdgu3pc7Sb+mqmuR24GOoecx2DkPkVtt+/cIAH7Qh9rwDoReF4Y6ZqF7YBPWeg66nE5M9qdjV7gLEUeY6c8sPL42tB1uXMdA1wtQre+GHxxEf/fJqb8txgrG03URGF/rHU9rBcbXeo9YjWTmll8AfAA/BfA3Jc//M4TnXz1eC2AWgCsB/HPZfmVfy5Yt48PC967kvn88K73tif9ivmYSv+qj3+DF3zmLX/ydpbxk1RLePbg7tdsdG+7gJauW8H99fhbzNZOYH/vP5Mknb2W+ZhL/w00X8TnfWczcv5t52yPM10zi19z0Ml6yaglf/9j1+fV8+zXMq17PzMxfuOfjvGTVEl6yagnv2r2WmZnvvvvu9P6fO5n5jg+lt635kVjP1t8x/8M85js/Irbf+Ebmf3mF+Pl33+VH/mG6Pv///dcLij+f//kXca6+Hcm2ayYx//zvk5+vmcT8yE3i++dPY151CfO/v5X5mkkcfXKq2O/aqeL5T04Wj7/6YubPzhfb1t3F/F9/ynzdkuQ1vnwO83++R/x88zvk6/SKxw98Szw+uL14zX8/k/kn/4f5oRv54Cd7ecmqJbzqiVX8ww0/5CWrlvDG/RuZv30R83dex/yp6cw/u5qZmTdf/05x7DhB7t/CGMZ4Wivz+Frv8bRWAA9yG3VorH4BeAmAnxqPPwbgY8bjXoh5VZvk1zCAbRC94dl9fwrgJc1e77DrIye/szse3cov+Lsf8s/WPcxLVi3ht331pbxk1RK+87qX80s/83OO45jPufEc/sJvv8DMzP+59j95yaolfMktF/MfffM0vutzM3jJqiX842d+rM/9oV98iN946xt52XeX8Rce/ALHP/k/vPQ7i/mKfzufl6xawo/vejxZyD+eIq77+zYzM/P92+7X9euj/3V5br0a33yZOO7pnxW/wWd+JZ7/zutSm+Mo4iWrlvBXvziPX7zqLP7cA59r+Vm96bY38WtveS0vWbWEf/rMT/M7qHrJzPzp2eLnNT/icLifl6xawld/ZT4/vutx/b4+/8Dnk2P/YS7zjz/K/NTt4rhtj7ZcTw5P3SGO/fe3iMdfOIPPveEM/n9Xf5SZma/6+VX8ptveVHr481+/lPmLZ4oHd36E+TPzxM83Xpb8bTFGMJ6ui8zja73jaa3M42u9R6pGtpNCSQC+DWANM19XstvtAN4p0yhXADjAzM/LYvRqIppCRFMAvFpuO7LgGEyU3iZVHRcxAIYnlSNGOsQl5hgAEGUON88RcYQIAIgAqWCxDINR31OIGoBbkedPno/L1u+4AGeebQi1Cn4X4DhALHvcmeU6AIBS7yb3GShUpUI4LITUMA7xnOca51Gnk/884lD8rB6D0t/V9plLgKG9xjYCzBVxpD/D5LuT/p593/pYeR4iBHKdvuPDleeJORafWxyJ9bp+8hnYWYcWFhZHDr8FcBoRLSCiCoC3QdREAAAzH2Dm6cw8n5nnA7gfwKXM/KDc721EVCWiBQBOA/DA0Vq4p+4Ks7iOBuqhU0UUM4gI0zqmYc/wHgBJfay6FUQAhuS1OIxDfc6IIzjkwCUXYRwi7D4RMRE6ek/Sz2tUuuRCqvnzoMl1W9UPdXwWfi11XoVYntMBwyFCFLfOimlEDXR6nbn1NQU5ev0h0u85Nis/kah5USAey7o1ItR65blUTRU10nOEE8d3/BbrdpK6G4eAPA7klNdjCwuLY452NL3zAfwvAK8gokfk18VE9AEi+oDc504AGyEasK8H8OcAwMx7IRq3fyu/PiW3HVlwjIRkSDji4uYgBlEMT/5Rn72Aq8exJifGeeSFjTlGTCTImnxelZq46IKXInDJ84X7AuLCmS0sgSRwlS5xodYFgZP3SpSsG00IYk0SuPoBAMBPn/kJ3jB3NvriIL8OwCBw8r1S5rPRBO7M9LFZ8qRIFpB8z57r4LaSRavPmtBQBM714cjX1gQuasjXUe5gskXIwsLiiIGZQwBXQdycXAPgP5j5SSL6FBFd2uLYJwH8B4CnAPwEwAf5KCZQVjxxLSUW18t9XkOsy6khjMW1e1ptGvYMCQKniEjFrSIkwrCTJ3Axx3DJhed4iOIIwfI/BgDUKt36eQ1fEjBJXFLnaUbg1PW9jMB5ksBl7IjqtV0GPFCaTJYgiAN0eMI22Xr/pJ5pAkeUes+pm7yKJKn37RwKgZP1XJJxBiEkgi/P5TkegmxtN8BURuBs7bSwGMto2QPHzL9Cjg3l9mEAHyx57gYANxzS6g4VTRQ4R2hn8FkQnyyJ0gpccmDypLyrF8mLYYQYnnxeHRcX0aYo0AXKLEql5YncvGrUMAicUpoAqcAlKlZsLJfLfm0ZBW7f8D4ERBjiCD2pdcjzRqG4mOcUPVWsJBmbsSR9LGUUuDg21qr63OQ55r0YqPQA37kIeO0/Asvfk34p+fsyFbiKU0kTOHKBsC72d8x/2laBs7CwOHJg5jshbmSa264u2Xdl5vGnAXz6iC2uCZQC1+ufiKm0GDsrT4o1UU27RaZ1TMPOwZ0AkhucFaeCQQLq8vpbpMB5jocwDlFnUS81CYoLFDhJtEyi0Yw63O00sKunG2+p5PvfxBsrVuAUAXMAOO0SuCghcKVK1gmLxHfjpmbEhgJnvOfU3xyKPGkFru1YggQZBS6US1AErpUCx0TJ3xNZBc7WTguLMYtDuFqMBxiqlIK8KLmawMUQhsp0mVAX9CirDAH6QhmHdYCAiGN4WoFr10JpKHBlF0dyDIVNojEovmcVOI5LLZRxGe1WF/y6IHCNuC7XU7AOoNxC2UqBy6pfHCX7pooEgBMXAX/xIPC9twK//lKewCkFjhwE8mUrbkLgIo7EOUOZ0K0tlI61UFo0RRAE2LJlC4aHh1vvfJTQ29uLNWvWHOtltIV211qr1TB37lz4/iGoDBZHBJ6rFDRgkfsXWDf419hZGQK5NYSRuHZPq03Dmj3i96vqY9WtIgJhuMBCqRU48hBxhHok6kuH36Gf16h0yoWkLZQesyZARbjNGcKGST14SysFLmuhVAocGC7lb+AWwVTgCpWsv34qUcEUDAUuIkq1ahQSOHXeQ1Hg1A1ZWVPVCk0LZTMFLm2hjAx3jLVQWgjYGnl4OFI1cmISOI7FH+4m5J1Gh2SBiCWBi0egwCkCFzUATxA49bwqNsUWyiAhcOaFvIzAmT1uCo1+cQ7Xlwqc+TqmhdJ4L8VnT4qNVOACefcvzK5npD1w3ScC3TOA/h1tWCiVEmd8vj0zgVlLgXV35desFDjTQlnUAxcVKHC2CFk0wZYtW9DT04P58+eDyvpGjzL6+vrQ09PTescxgHbWyszYs2cPtmzZggULFhyllVm0QsVVCloMxDW8de8ZOMH9Gbp7ehFJC+X0junYO7wXMcdJD5xXQ0jFPXAxx6IHznERxIGuL1rFYkMNqnSLWiHrgiIaFeamFspIOTHKFDhJFssUOJcBF9RWT1sjbmjyWajY9RZMfSAHslMeIaWVvlTffdZCeSg9cJrAqT5G4XwxLZTNFbgSCyVs/7iFgK2Rh4cjVSPHRwbnSFHUA5cKMVEWyvwFWT3W6lVKgRPRv3HUkPsmPXBKySvvgfNzz5deG6kkxETdbTQVukyIiXlUyxATqcCpoplbuSJbWjlTPXDq5TIEDkhslOQiF2ISGwpcNsREwaslKloKrElhINdhKnCawAXyWH0nM7MGC4sMhoeHMW3atDFTmCYiiAjTpk0bU3dwLQBPErggihHGjC6u4bL+AcRuR9ID1zENEUc4UD9g9MBVhAJX0gOnQkxSCpxXoMD5nak+NXWeGjOamRsjiJEE8DtL3pg8Z6YHTlkZhQLntKfAtWOh1DBqsTx3CKRuFBdbKFUP3CHcU3c9SYSVhVL8Tj1Zv1srcJT8PZHrgbO108LWyKOBQ6mRE5bA5RU4cTEjEhcqlUKZtVAmClxGZQI08YkUgUNCFENuReBGoMAVWSiDwaTh2+yBU8RGvLkUaSstTVV5J0AqcA39fkoUOPGgXIEz51soG6VS7FIKnJFC6WR64BS8atLHZkIT1bQCV9oDJ3sJbAqlRTuwhenIw37GYw+eJGBBxIjixCERep1JD1xtGgBgz9CepAfOFQpcXSlwXNwDF8UR6tKiX3OFrTFVI6vdKZWsXQUuBlB3nHTtSb0xZaGspDbrHjipwLVKoWTmlIWyJYHTpdHR+2YVuOYWykM0RU1ZIBwwgL7B6VN7KZQ5BY6shdIiD3v9PvIY6Wc8QQlcwYVfKXCKwMldSi2URQqcvNPF6sJs9J+1DjEZQQ9c4RiBfkOBy/TA6feYtVCW/GNwXBEYohW4htw/A5PAkUngMvZHc79ZS8V310cuxcq0UBqRxyl4HUAwlP8dKlWVSNx5RZrAiR44N1HvTBuIVeAsjkN0dwt72bZt23DFFVcc8nne97734amnnhqtZVmMIVQ8aaGMGGHMiJUl3a2lFDgA2DO8x7BQihRKZaFMhY8YKZRhHGoLZadUy1KkafkfAxd/Xj9URKPaogdOWyjL4LjAnOXAjDNTm5MeOMAlp2WIScghGDyCFEoJ49wh0nU/b6HkwxsjAADvuRN4+f8BAGPMjvhdtrZQUtKSEcewKZQWxwvGe42coD1wjBw31WMEzBTKJhZKvSVTJGqTEWFI7pukKkbyQlceYqIslO2kUBb1wA0mDd+5FMoSC2XZ+QGhwtWzPXDZdbjGz0kPnLZQZnvgAGDRpcCbvgXMOgt5C6WRQumUWSir4pgoyNw9VSEmRgqlW0mIsxodoHvgjBATIPM5WVgcP5g9eza+//3vH/Lx3/rWt0ZxNRZjCYkCF4ueNzXr1OsAMxDHjMlV0Tqwv74fIYcgiBljIVAYYpJKoeRQWygLFbiZS8SXhCZwcWsFrtE8HBt4/89zm5IUSoaL1gQu27/X3IoIpPrRY3UzOB2WEmduuh72GAEgFaKiUig9SghcxJG2tuaR7YEza7O9+Wkx8TFea+QEVeAKxghoC6W4UCnmWjrIu6w41HoR6763JO1S2Q9zFkrmJnPgyiyUZT1w3QXPp+fApVMomxQ4rwqEQnkLVQ9cbkqAscGYA5cjbibRc31g6Zs12cpbKDMplDkLpbS+FPbBCQulSeByFkpzHSbsnUSLMYpNmzZh0aJFeP/734/Fixfj1a9+NYaGxE2iRx55BCtWrMDSpUtx2WWXYd++fbnjd+zYgcsuuwxnnXUWzjrrLPzmN7/JnX/JEvFH8qpVq/CGN7wBK1euxGmnnYZrr71W73P66afjHe94BxYtWoQrrrgCg4Mi+XblypV48MEHAYg7lh//+Mdx1llnYcWKFdixYwcAYMOGDVixYgXOPPNMfOITn9B3Ni3GNvxMDxzLOhlrxYlRkbUriAOhrjlSXSMSNkZkeuDiGI6TDPJWFn2twDUhTYogVZmbDvKOOnoR0QgGa6u1GXPgXGo9RkCtp+bWQO2EnhiuFGUrDU84vQmBy4wRcIwadojQCpxhoQTKP6vyOXDWQmkxNmBrZDEmqALXLMQkiSkGChQ4Nci7yEIJCAI3LH4hIUf6+chUgkxk0qXaTqEsslBOmi2fd5PzmnPgQCnS1nQQqlsRxBJJD1yKUJ79RxkLZdEYAeM5ADc8cQNeMe8VmN8739ieCTHJKm85C6XshzD74NS6SFko8z1wwkJprDfbY2f74CzawLV3PImnth0c1XOeMXsSrrlkcdN91q1bh5tuugnXX3893vKWt+C2227D+9//frzzne/EV77yFVx44YW4+uqrce211+JLX/pS6ti//Mu/xIUXXogf/OAHiKII/f39TV/rgQcewBNPPIHOzk6ce+65eN3rXofp06dj7dq1+Pa3v43zzz8f733ve/H1r38dH/7wh1PHDgwMYMWKFfj0pz+Nj3zkI7j++uvxV3/1V/rryiuvxDe/+c1D+6Asjjp8nULJCKMYJP941wQuZlQcSeCiABFHyZBuFCtwMdKDvFV9aceGqM5TYS6/wQkg7p4BDG5DI2rouPx2oFMoIS2ULXrgdE+eW9Hvpy0YASmhX02nUBYO8g6E+jYKLpFQ1jxPh5nI8QJxoMl4ZrHFISbZMUAWFrA1cizVyAmswLVnoRzRGAFAEDj5o7ZNIiFLWUVPkaSiEJPcvvolCyyUwWCSuJWyUMapu35pC2UzBS4hcKpIKesFPnkAeOPX0ncDmw7ydjAcDuOLD30Rdz17V/r5bA9cNsQkR+AKFDhd8DIKXHaQt1nItYVSnd8SOIuxiwULFuDss88GACxbtgybN2/GgQMHsH//flx44YUAgHe961245557csf+4he/wJ/92Z8BAFzXRW9vb9PXetWrXoVp06aho6MDb3rTm/CrX/0KADBv3jycf/75AIA/+qM/0ttNVCoVvP71r9fr3LRpEwDgvvvuw5vf/GYAwNvf/vaRvn2LYwQ1B05bKOV1mT1Ra8KY4cubj0EcIIqlPZI8hI6LIdnznO2BUymURRbKpgROqlYVtFDg5DlaWxozx8UqxERYKFulUCry6Tt+y16yFMwQkzjM9L6XKHCHGmCSQTBpllizHH0wMgUuyihwtm5ajA3YGpnHBFbgMpDEwZEWSmWwG9EgbwCo9ernYtlXZZaj3B26LIFLXchL0HKMgBFikrJQOmkLZdn51XoyBC53xzOrwOkxApnPxrjbmPf3G+czLZSUUcgU1PyelIVSKXBOOsTEzcyBK7RQKgXO3km0aI1WdwGPFKrVJInPdV2E4cisYSNBNulKPS7bbsL3fb39SK/T4sjDd5SFUoSYmD1wQIgoShO4mGN45EkFjjFE4tqc64GDowlPQ4ZkFQ7yziCIAnggOFwSCCahbrwqctgu0iEmlJ5JV7QeWRt91xektcX+hi0lUeDiMJ1CGRcQuDjMJWYeKsI/+DBw91Xwe+cBSCtwRWDzhnEcJi4Ya6G0KICtkeX7AUe3Rk5MBQ7cUoFTFspsMRmJAhdyhHxwSFaBS6dLpefAjWCMQGMw6YErCzFxfb0Wjznf02bCTeL69RiBnMDWwkJpjBFIwl/MT8MIMWHODPJuFmKCYgVOJmHqmGTHh+OUKXDWQmkxvtHb24spU6bg3nvvBQB897vf1XcaTbzyla/EN77xDQBAFEU4cOBA0/Pedddd2Lt3L4aGhnDrrbfqO4qbN2/GfffdBwD43ve+hwsuuKDtta5YsQK33HILAODmm29u+ziLYwvfkxbIjAIHP+mBUwqOslCq/jYAGAxED0i2B073yXHSA6cVuCY2xDAO4UMQrKYplLLeqHO3Cx1i4lbguP7oK3DGTU2dQmkocC65JQpc0id/uAh8UUMVcWulwOk6zWznwFmMKxzvNXJiEriiHjh5UVJz4HQKZaaYJESkXIFTxCiS9sXQ7DvLFoScAtdOD1xGgWOWYwSkhdJU6IwkTLi+7oFz0cI06PqaXJYrcMUplMm2VgqcYcHQJEwROC99DgVtoTTvrKYtlKoHruJW4CAzRkDBWigtJgD+9V//FX/7t3+LpUuX4pFHHsHVV1+d2+fLX/4y7r77bpx55plYtmxZyzjj8847D5dffjmWLl2Kyy+/HMuXLwcALFy4EF/72tewaNEi7Nu3T1tO2sGXvvQlXHfddVi6dCnWr1/f0qJiMTbg6RASocBt6DwHOOvtGOqcLbfHWoFrxA1EcdIDBwB9jT65Xz6FUoWYNBvkHcQBBoIB/TjkUCpwLVIo5TmUutcuNJF6zT/A65ndfg+cU4HruCOwUCYBKSoBEhCkqjjEZBQJnKzriri1pcABBQTOplBajH0czzVywloomTJvTV6k3HZTKLNR+Qq1Xk3uYjnIOzV7rRWBM/YuT6F0krksgCAzHCUWSlOBi6Mketit6HfjcgsLpVc15sCpMQKHOMjbuNtYGJEMJIqitlBmvpvrAjIKXJy8nDFGID/I2ziXtVBajBPMnz8fTzzxhH784Q9/GH194g/js88+G/fff3/T42fMmIHbbrstt101amfPP3fuXNx66625/T3Pw7/927/ltq9evTp3TgC44oorcMUVV6Cvrw9z5szB/fffDyLCzTffjLVr1zZds8XYgC974BqhUOD21uYBl30DzgObAYgQE48SAmCGmADQ5CulwMkeuGyISaeXT6H88kNfxi+3/BJ3XHaHPo8POvIKXM8sOI6PMBxoun/KQtlWD1xy41eRQ1OB8xyvIMREjs051BlwGag1ZhW48n5BReAi8WX2p9u6aTEGYGtkMSYsgXCro6gAACAASURBVMsrcOKi5DvyQlqSQpmzUGYVoo7JhoVSKHCRsU8rC6V58W4eYmIUCmlTgd+VPM+ycMVBcsF1K3ptLriNHjipwMnvuf1zFsrWPXB5W6iamC4/UZUUmbU4KrQVYiIeVdyKtvIIBc60UGbGFFgriIXFEcNDDz2Eq666CsyMyZMn44YbbjjWS7JoA0QEzyGEcYwginWoiSvnw0Uxg4jgOz6CKEiRMyCpn2ZvmEnyzDECHX46hZKZ8eNNP9YqHiBIhgeCgxY9cEqBGyGBM4mU67iI4xgxx4jiSCuNJlIWynZ64FIWStmawJF+z3kFjhIF7lBnwGWgSWdGgWsaYgLIXrwoXZstgbOwGBUciRo5QQmcEeyhoIZauuIPeV/xipIUyiSOvyjERPwYSaJoXhZbKXCR8XxTC6VZmBqS0RcqcGFy5y7VA9fKQlnRNkVtocweYcbyUzMFztV3G1OE2PTQaxXNzXwvIXBBUYhJMkbAY4ZDjlbgmDljoRT/tDXZtIXIwgLvfve78e53vzu3PXsHcqR42ctehkcfffQwVmZxrOC5hDBiobZJ4uYZBA4QZCClwGUcLqa6w/La7JEYIF2P6iL4RB6jauSavWuwc3Bn6lxagWNu2p92qAROkRhl8Yw4wo1P3ohb1t2iVcCi93UoYwTMpExNHMnL94mrFMpRslCq99i+hVLWyDgqmANnb3xaHF8YTzVygvbAcekgb63AqcHbZSmUakM22MOwUEYyVdEMCykncFX5eqYCV4LsGIGGVOCKUijNC65b0e+7PQVOpVCKC36uNLWcA9dCgTM99FkLZWmISQsFjhwERDpFNDUHrlkKpfXyW1hYWOTgOw4acpC3K2/aKQUulASu4lbQiBqCwDku3MzA6cIeOMdFEAc42DiISdVJOnBKkaDVz60Wx3Kot5kK3JGwUKo6ZRK4Zw4+g+cHni/c3+wnG+kYAdNCaSpwhXPgRtFCqYjayEJMkKRh2kHeFhbjAhOUwDUZ5O2Ii2erFMo4qzIppObAiUHekbFPjsCFisDlUyhLFbjsGIGG9OkXKXBRmsBpCyUD3CyF0pgDpxrBc3N3Sghcct4WPXCmBUNbKDMKXM5CWTDI2xwjAEIDpBXU1BgBa6G0sLCwGBF8z8kpcG6JAhfHcaoHTiHbA+eSqwnS/vp+TKlOSV+rkRA4IKlBYRzCg+rhbkOBG2GIiR7kTYKERnGEvkZfqTpl2hFH1AMHI8QkProhJqUKXFSmwMlabAmchcW4woQlcKVjBFSIifx7viyFMiwjP2YKZSzGCERtKXD5FMq2xwhkLZQmwUspcL6mYN6oKHCZQd4562QyRkD3DrZroTwUBc6wUKpSlx4jYJwrm0JpC5GFhYVFDqoHLoxiTdzKLJQhh6keOIUiBU4Rnn3D+zC5Njnlltg+sB1r9q7BjM4ZABIlLYgD+CA44KOmwPU1+nQfXBa6B67dOXBmD5xS4DgdYpIfI8CjaqFUpFb19GkFrnTtqkZG6R44G2JiYTGmMWEJXFmISZJCWWyhTBQ4iaJB3ikLZVqBy5EyHWJSkEJZRrEcN51CGWQslE5m8GahAteKwFW1Otj2IO9sX6CRJKkb01MqnjkHLk4fo4tEZl3NFDgjxEQpcGqMQE6Bcydme6eFhYXFaMJ3HTTCrAKn7I6SwLm+7uVynXwPXLMUyn3D+zClOiXVA/fk7icBAOfPEfOVFFESCpxIoWzaA3eIg7xzChxH6Jc3SItUuEMfI5AeraOTIanMQtkYNQvlUDgEIBnb0FqBs2MELCzGIyYsgcv1wFF6kLdfYqFUd81KQ0yqkxILZZECl6VNUd5CWWbfTNbqYDilwEkLpUqhdLwkpTIO0gROzfRuGWLiJxZKeWGPqD0LZV6Ja2MOXDaFstRCqRS4oWRbSoEDAlOBK+uB02TOSZ/DwmKM4ic/+QkWLlyIU089Fdddd13u+VWrVuGEE07A2WefjbPPPhvf+ta3jsEqLSYaJnX42DtQRxAzPFdcL71MD5xKocyOEVDIKnA6hZJD7KunFbiQQ60STa5OBpAQMWWhdJjzln4DZkDISKDnwDnC4hlzjP6gP/ce1u9bj3f86B3YNbRLv/+R9cBRSvFSBLW5hXJ0CNxgMAgC6cHpSokrT6FsFmJiFTiLsQGzPn72s5/NPX881scJKlMUpFBKxYdI9cCJzSMeI+C4iB0jur5VD1zGQslgeMwIiUotlFs4wCWd/bh571osnLow3wOXCjGJUimUjDZDTLwqENUBZl0Ec5aV0jECatuhzIFrZaEsUOD0OUWISYNIE3DVTB/Hcckg7+w5LCzGHqIowgc/+EHcddddmDt3LpYtW4Y3v/nNOOOMM1L7vfWtb8VXv/rVY7RKi4mIhTO68cAze1MKnFPWAyfVNde4WdbhdRSmUDrkIIxDDAaDmFKdkprZqchEl7wpqQidCjExFbhfb/01tgfbU2s+1BRKdYNW9eiFcagVK/M9PLnnSTy2+zFUZT1Sc+Bav17+pqb5/kpDTOJw1CyUg+EgOv1OkKzPSvkst1BmxwgY/eP2xqfFGEC2Pp577rl45StfiXPPPTe13/FWHyewApd5a5TpgZN397IkShOR5MDc6WN5LnFBpFTvWCsLZcQxVOkrU+B2U4yQgO0DsmhpAicGoaZDTIrnwHncJCQFSEhfHOoeuKZjBJoO8naLFbgiC2U2xCSnlJJQ4cKSMQIQg7y1hVL9UYCshdKmUFqMHzzwwAM49dRTcfLJJ6NSqeDyyy8vHDxqYTHaWDhzErYdGEYUc3kPnGGh9MhLKXBdflepAjcUDiHiCFNqU0BEcGRvmCJLmsAZFkofBIeTkTufvO+TuOvAXak1qzp9qBZKRTBjjgstlMOy/jy26zEAwkLpURsKnDEj1dxX2RfLe+BGV4FTQ9OBRIFrbaGUBI6Mm6uWwFmMAWTr49ve9jb86Ec/OtbLOuaYmApckx44kgTOb6HAhdlh1QYiR4wZjWKpwLUVYpIM8lYWyrJB3sq+qe+YBRkLZS7ERClwBoErHxMu95VjDYIh/TqtFbjsGIHkuVIFTr+p7BgBL/3YhFfNKHDmGAFCg5BYKM0eOPNc2UHhVoGzaAc//iiw/fHRPefMM4HX5i0fJrZu3Yp58+bpx7Nnz8Zjjz2W2++WW27BPffcgxe+8IX44he/mDrGwuJQcPrMHv1zNoUylL1mvuOjETXgOV4uxKTb706pO0UqnbJKKtKkyIQiGvkeONY3FOthHYPOYGrNqs4o0tWIGvj+09/H1v6t+PDyD2v1KQttoTQIpqn+KShVThFEpcCNaIyA8beFeg3XuNkp9iNRG0cxhVIpcAo+jSTEJLQhJhbNcQxqZLY+zp07F/fee29uv+OtPk5QBa5gDpz8496BInAlPXBtKHBMadIQmxbK0h649hW4SPUKqGLRGBDHe/ICr0JMmMVFVxVTx9VrEzHMTSDXEwZJYYyzbzVF4KiAbBl2kbikBw5I1gkYFsqsmmfAqwHBUH67UuCMMQKp2UKFFko7RsBiYuCSSy7Bpk2b8Nhjj+FVr3oV3vWudx3rJVlMACw0CJzrFo8RqDgVPcg7S+B6Kj2lKZQKU2pTxHklgVFkQilwiigJCyXkHDh5MzUOMRinCZyZQtnf6Mdlt12GzzzwGdz41I0YUDc8C5BV4FT/G5BWqIaidP3RPXCtUigNd4pZC9X7Oxpz4IaCoZQC136ISXaMgCVwFuMHx2N9PH4UOCJEcLQC58jny+bARc0UOJNgebXUyIG8ApdPoWwVYqL62HSscWMAMO6o6R44VTSNQqn681wwGs00OEkGA4PAhdn1pMYIiBlsgHHBNz6j0jlwgPh9qKLVykIJlCtwsg8vIEK36oErmwOni6EiipbAWbSBFkrZkcKcOXPw3HPP6cfbtm3DnDlzUvtMmzZN//y+970PH/nIR47a+iwmLmb11tBT89A3HJbPgXN9BI1AK1dZBW7H4A792EyhVJhSTQhcxJEmE4rAqcdhHMInSs2BC+IAQ0gTKlVn6lEd6/evx+a+zThz+pl4fPfjTYNNTAXOVAjV6ygMGSFaHnlaUWzfQumk9m1EDU0a06N2Rn8O3GA4qBMogXZCTGSNLAoxsXXTIotjUCOz9XHLli2YPXt2ap/jsT5OTAXuT+/F+lP/OLc5hguSRcFlQ0Uz0F4PnDFGwKumFbgWFkqRQik2lYWYRMq+ou72NQaBSneyg+qBUxdk1yRw4mePgbjZtVdaKBvG3cocnSy1UOqNej3FKZSG+pWzUJaEmACA11HcA2eEmFTktlQPXGEKpTqFvZNoMXZx7rnnYt26dXjmmWfQaDRwyy234NJLL03t8/zzz+ufb7/9dixatOhoL9NiAoKItI3Sc9IplO2EmHRXujU5YGY9aiBloawJC6UmcJkeuFQKJafnwBUqcHGiwA3Km5ALehcAaJ5MqccIOPkkzWwPnKotigCNNIUyFWJiELjSMQLOKPbAGTd8VYhJ+edipFCCbQqlxZhDtj7efPPNuPjii1P7HI/1cWIqcF3TEHlduc0xmQqcET9v7qMVOLmhQCGKyQFYqT4uIsO6lw8xyQ/yLptBp8+RU+D6kwRKoKkCx7IAmz0EhXCVApfcaczFNreyUBalUKJAgYNpoWwxRgBoosAZc+BUJoppZ9WFxzUSM62F0mLsw/M8fPWrX8VrXvMaRFGEd7zjHVi8eDGuvvpqLF++HJdeein+6Z/+Cbfffjs8z8PUqVOxatWqY71siwmChTN78NtN++BlLJS5MQJufoxAt58QOHNQdpEC5zgixETtr4hGOoVS3FmOOQYzI+RyC2UQBxgMxXO91V5xriZJkaqmKjJlIqvATe+YDjAwHImbiSMicMypvy3qUR0uuaAMsUsIXDh6ISbhIGZ7iTrRtgKnPjezf9wSOIsxgGx9fO9734tFixYd9/VxYhK4EsRwtAKnCFxZCmVkeNlz56l0AcND+oIYGRfecgul7MkCw+WSfdU5JOnQBSUYTBIogWTQtzq3k1fgWs6BK7BQ5hQ7J2OhpKwdsdUcOIM8ZVMomypwJSmU8pyNghTKVA9cqhDaFEqL8YGLL75Y31Xs6+sDAHzqU5/Sz3/mM5/BZz7zmWOyNouJjYUzJwFIiJv6HqseODfpgcuqV2YKpbqBZ5K8qlvVlj7VAxfEATzy9KyydAql6uFmfd6AAzSiBipuBcysI7rqUT0hcBVB4A7ZQhmlFbhOrxOnTTkNj+56FAD0YPLmSOqNuW8jlgocnIIUytG3UKYUOKd8jMAXH/oiFsR7cQYgxgoBGQXO1k2LsQGzPgKiRh7v9fG4InARXEAqcC4MG6QBHcbR9DycOjaSF14CFYeYkKvJRcQR3JIRBnoNlFEH6/1pC6VW4NRwbIPAyaLkcZsKXJgQuCi79pyFMnMOrcC5LVIom1koyxQ4g8CpcxpjBCpFPXDZhEtxUPocFhYWFhYpJBbK9BiBrAKn+9soIWe+6xcrcHKfydXJOhVS9YAFcQDP8VCRdSibQukYBE3hYOMgpndMT6c7Rg0dWqKSLtuxUDrk6BmiCibBGQ6H0eF14EMv+hC29m8Vnwm1EWJi1DNznUEUaOtp3kIZAXEwegQuM0ZAWygzISbMjBueuAFv8BbhjUD+hrC1UFpYjGlMzB64EsRGiAmV9MC1Y6FUd//0vlLx8R2/2EJpXJiZWatHpQqc/J6kUPZleuCcdA9cykKpQkzaS6FsGEQpb6E03ruhwBG3qcClQkwyKZRNLZQZBS43RoCgI0qK5sCZn0fWQtm/C/jh34i+QgsLCwsLnDmnF5ecNRvL508FALg63VdcNz3HQxAHCOMwpa7VvFqK2JgWRUWQVAKl2q4GefuOrwmc2QPng7RLJUvggHSNCeJA98D11qQCV5K2aB7bSoEbCodQ82o4adJJeMnsl6Q+g3aRtVA65BRbKMN0n/zhIqvAuY4Lh5zc2vXIJFX3sxZKMua4WlhYjDkcVwqcsFBK5QbFBK4dC6XaJ7FQio/Rd/3kfN//Y2D2OTIeuGIcG2sFrqwHLjJtgYBQ4KoZBS4OxV07oCCFMoJr2EwKUdADl1PsUgWuqAfO0d/V+07fXTRDTMoslAUEzq+le+DMQd7kIECiwAHQw2HbslBu/g3w4LeBhRcDp/1h/rUtLCwsjjPUfBdfufIc/dilvALXiBsioIRcTc5qbg2+I+qe+hLHJwRJKWOAUIOUAue7PqoyTEuRiyAO4KOq7yybBK6vIWzFWWI0GA6CQOjxe1LnKkJKgWuWQhkNodvvTj3vOm77FkrOWCijBlwSRCptoaTkZuUoKHBBJEi2qcAB4veX7YFL/taR69EELjOjlbm4TltYWBxTHF8KHIkB3ADgwLDemfu0E2IiyUjWQqkKGcIG8NStwKZ7pQJn9shxyxRKpRolKZT9QDWZ1QPHS4eYmOdXc+DQQoHzZOE04pJbDvIuGM2gvqtilbakmiEmygbZzhiBEgVOriGgZI4fkNzVTWbMFVkolewpP7MdozyI0sLCwmKCQM2DS/XASQulS6625XV4HUmPVRymCJLargJM1HZtoSQPFSevwKlB3uZ2ADhYzytwKoWy0+/Ual47PXCe4+UslNkQE9Wfp9BWiIkuZ5yzepamUKqblaOgwKl+QFOBA4rVQ/Ve9DvSFspMf7q1UVpYjEm0JHBEdAMR7SSiJ0qe/1siekR+PUFEERFNlc9tIqLH5XMPjvbiR4rICDFRFsqyFMq4iQKn7qBp0qKi+x1PHL93gyAKg3vzFkrEcFvMgYuyISb1rIXSTZKrgHILZbMGZFksgqYWyrIxAhkLpTFGIFecxEbDQpkckzqHiWwKZWqMACEk0kmeQNIYn1gok0KYs1Cqu6LbC/85W1hYWIwYRHQREa0lovVE9NGC5z9g1MJfEdEZcvt8Ihoyaug3j/7q8yjsgZMWSsdxUgElvpOkHBalUJoWStdxEcfSQumK4dgEQiNq6MRJb9ZZcJpYKLPEaCgUg6vVOpqlUCrS0kqBGw6H0eF3pJ5vqwduxQfF985Mr14sFDhCgYUyGj0Cp+bXZRW4IgKnnUTqVm+YCTGx/eMWFmMa7ShwqwBcVPYkM3+emc9m5rMBfAzAL5l5r7HLy+Xzyw9vqYePGI4OMUGJhTIhcBJFChxnFThpoXR8Qe52PiV2HNorLZTJhTniWPtWywd5y33jSJC0cDitwKnCk4v9FRZKYsBpaaFUCpxB4LKEL5VC2XyMgCpsOXsIIAqADlzJKnAlKZSGtdMcI8AMQeCMpWoFTvZtmHPxckVIK3CWwFlYWBw+iMgF8DUArwVwBoArFUEz8D1mPlPWyX8EcJ3x3AZVQ5n5A0dn1c2RDPIW103f8cFgTURSPXBOMmfMtFCq7WoGHGAocFEA3/FBRKi4FTSihiZX3sylcC8Sw4KLLJTKAQOkFTgVlz/SFEpllcz1wGUUONMqWooVH8DqlbcB1e6chZKIklqlkFLgDt9CqfoBzUHeau05C6W6AZ3rgVMWSjuCx8JiLKMlgWPmewDsbbWfxJUAbjqsFR1BRHCh6JHDxRZKTco0byvogcvYBSMnE2Kyc43YUSlw0q4ICIXKa3FBVOpfGIciwATIh5gAxh2ztIXSASMxi5ZA2U2MApnvgWtTgTOKUtsWyqYplCU9cCDt13czBC7iqDDEJHcOVVR3rwOC4YL9LCyOPt773vfixBNPxJIlS471UixGjvMArGfmjczcAHAzgDeYOzDzQeNhF8Z4OoTqgdODvCU5Gg6H2yJwpsJlWihTYwTkcRW3gkbc0MTLd3wdTlUPWyhwcUOEdhgKXLs9cOo1lEKYU+AyJEhZLlv3wQlkrZ5qDlzqxuoo98CNyELJykJZRuCshdJi7MDWyDxGLcSEiDohlLqrjM0M4GdExAD+mZn/pcnxfwLgTwBgxowZWL169WGtp7+/P3eOBTEQyYKgrsEbN27E6r3Jfgf6DgBIQkwe+t3v0Le+L3UedSfrmWefweqDq3FweBjoBBrDDRyoH8DujfdgOgAe2o8927eiNtzAg3Itw41hKF1rze/XYMrWKbm17ty7B3CATZs34b5d/42XAPj9pq3YXhf7nPTsszgZwMMP3o9zADz+5Brs2SEI3uBwHVQVzLwRBKWfY3V4J14C4JnNG/S2XXt2p/fnCCvljxueeQaxU8FpADhmrF69GssHBtANYMfOXXjiSaFo7dmzR59j7nMbcCqAX917L7r7N+BsAA8/+hgOPBuhu28jlgM40NePh7O/p63bcVIwhF/K7bWhHVgB4Pdr12LvFhEZ7cSRfp04ivHclufw8LZunAOgf6iuP++euihKDzzwPxjseh6ztj2FhfK9PfiTf0d/zymFn8+xQtG/27GK8bRWoHy9vb29eu7ascJb3vIWvOc978Gf/umfoq+vD1EUHfM1tYuRrHV4eHhc/ZtpE3MAPGc83gLgxdmdiOiDAP4GQAXAK4ynFhDRwwAOAvgEM99bcOwRr48mBgPxR/3adeuxOngWmw9uFtsbg9ixfQd+fe+vAQAD+wewoS5qyL2/Tpa97ul12OnuBABs27ANq7eL1xocGMSO+g4wGMOR/LcQApue24TV/WKfTRs36R673z7yW33OJzc8idV7V+NAeEBv29+3HzzIiBHj4QcfBgA8+sSj8J8ptiNuOCDW+qt7f4WN/RsBAG5dVOQ1a9dg9fNyncEgdm7dmfqMNh8Qn8EvfvkLVJ3kpmwW6rPdtHdT8nk2BuFEDnbt3IWB+oA+76KduzBDEqQn167Drn2r8yc0EHCAr+z4Ct405U2YX52fe/7p4acBAGufWIt4fUK8wnqIbc9vS72ffeE+AEBdKo9rn3oCCwE8+fu12LV3NeZt3oRTANxzzy8Ru+Xv92hiotScsYhma7U18vBwpGrkaKZQXgLg1xn75AXMvJWITgRwFxH9Xip6OUhy9y8AsHz5cl65cuVhLWb16tVYuXIl7tt2H675zTW47Y23Yec9LlxfDrp2PAARTpp/ElaenbzWV27/CtBIFLhly5YBc16UPvmNABiYM3cOVp67Ev+1pReIBtDb3QuHHEzfKS6ihBjTOxioToF6P97Nnu6BO23haVj5wpV6rQq3930X2LsRs+bMwkvmLwHuB05fuhynL5b7/PpR4BngnDPPAB4BzjzrHOA08dzDz3XDiQZBDLi+i9LPsW87cD9w4szp4s8NAL1Tp6T3ZwZ+KX485ZRThTK2HnCIxH5reoABYMbM2Vi4aCHwK2DylMnJOe5fA2wALrjgfGBrB/AocM6LlgEnrQC2TwceAnon9ebXSL8FNsdY+bILhB1y3ybgf4DTT1+EgWknA3cDVbUGANWbq5g1exbOmb0MeATonpSs4cn/EH9onLd8OTDjDOCBdYD49WD53CpwTsnnc4yQ/bcwljGe1gqUr3fNmjXo6enJH3AUcdFFF2HTpk1wHAc9PT3o6+s75mtqFyNZa61WwznnnNN6xwkIZv4agK8R0dsBfALAuwA8D+AkZt5DRMsA3EpEizOK3RGrj2UYbITAz3+K+QtOxsoLT8GO3+8A/gcIEWLenHl4xXmvAL4LzJkxB4vnLAZ+DZz74nOFqnULcMbpZ2BW9yz888/+GRe86AKcN+s8AMDX7/g6pnZOFb10DQcrV65Ez/d7MG3GNKxYvgL4/4DTX3i6UOfuA04/43RA8EBMnjEZK1+6EtsHtgPfF9u8qge/5mNabRouWHEBcAtw6sJTsfLU4ve25tE1wCPAyy98OQ6sPwDcB8w/cT42bdmE+afMx8rFK0VYy7MxFp6yECuXJufZ/ORm4EHgpRe8FD2V8n/v6rO9/4H7AWnGiShCV0cXZp0wC8/vfD757Pd+T7+/xWeeDSwq/50AwNb+rXjmlmfgzfOw8oyCfZ8DsAN46bkvxeJpi/Xm6269DlMnT039zrf2bwVuAeAKpW3hqQuAp4HFS5YCZ6wUf2dsBP7ggvPTKdjHEBOl5oxFNFurrZGHhyNVI0eTwL0NGfskM2+V33cS0Q8grCaFBO5IYd2+dXh+4HnsH94vLZRqXploKC4PMZHIWPyYOWcXDB0XiKTPPGoIwjH1ZGDvRqB/O9AzSx9v9sCVpVBGpoWyriyUBT1w2jtvhpgQnJDhgFuEmKhB3knDd95CKQZnA1xsodQ5L462lRTPgWOjj60dC6W82xcOA253apB3WGKhTIeYtGGhBNkgE4scPvfA5/D7vb8f1XOePvV0/N15fzeq57QYU9gKYJ7xeK7cVoabAXwDAJi5DqAuf36IiDYAeCGAYxr65WTHCBh93KY9subWUimUymbokINlJy7Dx877GF40I7kB6pKLkMO8hTJq6PCRilPRg7+Ho8Tmnk2h9BxPWCiDQczrmdeWhdK0eJZZKIci0X9dZqFsmUQpYe4XxqGeA1cY9AWkWiHKoCylanh5FqoHrmiMQC7EJM6EmKi+86yFcmy7fS2OMmyNHDsYlTECRNQL4EIAtxnbuoioR/0M4NUAjvpfzKoA1KM6Ik4GUzJEE3OWRCU9cMUplCZBURfo2EnmwEXhoHiNF5wvdurbkfK2xxzrHrjSEBNdPIOEwFUzKZRAkl5lzoEjFwTxi2162VWDvI0euFyICZCa9ZaQrTYHeZtN0DqFUp2vRYgJkPQGGGMEAtnAbqZQ6h44da5UCqWTPodax7RTbZCJhYXFaOC3AE4jogVEVIG4mXm7uQMRnWY8fB2AdXL7CTIEBUR0MoDTAGw8KqtuApVCGRsplAqql8sjL9UDl02h9F0fb1/0dv08ADiOk6RQynMqAqfJh9+pyZWZKJntgetwO8RxmR64ZimUURwl68+kZGoCJ4lMzcuHmKj3WYZfbP4FPr7l42hEjVx9V6QxHfRl1D/Xxz1b7sGD28u5uwp1GQhLCFxYTOCKRiDoHji1hoFdck12jICFxXhASwWOtGqiKgAAIABJREFUiG4CsBLAdCLaAuAaAD4AMLOKPL4MwM+Y2byqzADwA3knzYNI4frJ6C29PQyHCYFjuGCtwIm7YWUKXFmbsnnxTUJMxAXPczywCsaYfwHw8HcFyTLuXjKz7oErI3BqaxSHYgYckA4x0QqcajrOhpgIapVT1EyoOXCxvOsZc/H+jgtEkTxjyRw4x9GfRaECBzZSKBXJajFGAEjPgpP7qhCT4hTKokHeagmZFMqZS4Bnf5Pfz+K4hr0LaDFSMHNIRFcB+CnEBJcbmPlJIvoUgAeZ+XYAVxHRHwIIAOyDsE8CwB8A+BQRBRCX/g9k2hCOCdzsGAE3TeAAYFJ1EqbWpsInSWw4hCPH82Qj+s1jVYiJiumvOBXU47pWlbr8Lk021A3YLqcrSaGU1/KaV0Nfow/MnJoD14xgRRxpcqi+91Z74ZKrUyjVa2YVOEX4sn8zmHj24LM4GB1Ef9Cf208TuLjgJicAdnxc+5trsXDqQiyfWRzarQicIrtZmCTYRDMFLlBr6N8hF2rHCFiUw9bIsYOWBI6Zr2xjn1UQ4wbMbRsBnHWoCxstqLkojagBBw6IFEFzk/lhBrQVUKtL5QqcJnuSOPiOjzgcFgrSnGXJQYYCF3EyB64s5j9WClwUAHVJ4KpFKZSS4Jhz4MiBw4DDLebAqeQwWbRqHCMsulCnFLjWKZTlClxZCmUzBa6eHC/Pp9boGu8tPwcu+eOBs2tWxb3ak0m6tLCwsDg0MPOdAO7MbLva+PmvSo67BaITaUyBiOA6lKRQGjcJHVl/bnztjZjeMV0rRqaqpvbJwhzkrYifGhKuVKVOr1OTNaWm9bg9eQXO68Ce4T0I4qDtFEo1iBxILJHdfncqZl/9zdDhZiyU8rhm51fPBZGYmWcqX3oOXIkCtzU4iJ1DO3FKXB6spRW4MgtlWDxGoEiBS+bASfQ9L77nBnlbC6WFxVjEqFgoxxou+cEluHnPzQCSu2nD0TAiw1jILGwUZXPgysYImBHC6oJoKnAxR0DXiUDX9OQgU4FDrNWjVgpcyIYCV52U7KAVOEXgzDlwDgiiB67pHDgiwK0ikAWyxiUKXAGBIzbOIZ/TClzZHLhSC2WBAudnLJQGYVQELmuhjDk2yGEzBU6uw63YwmQxZnDllVfiJS95CdauXYu5c+fixhtvPNZLsjjO4RJpW33WQgkAL5j0AnT5XSkLpaoDrRQ4NcgbEMPA61FagVPHKwdNt9Od9MDFiQIXc4yII3T6nXodTS2UhgKnXqOn0pNSqNRrlilwqu7/aOOP8PVHvp7aRxM4OVKhaqQ3agUuOwdO4uG+Z/Qay9AOgau61ZRtVa29TIGLEAMdU0S7B1AwRsDWSYtjD1sj8xjNEJMxg5hjDMXiLpq6GDeiBjx2UhbKQgVOExGJbIiJQRySfrlEgWOOgUonUO0VF0COcwqcIh9lBC5KKXAyjKxS0AOnQ0xMCyW1Z6EEALeiL+pV5pIeOINo5UJMEnKn3ku6p7DIQplR4IpQ2gNnWCjjgh44VXhSFsrMMFK9Dt9aQyzGDG66KT0+c7zEI1tMXJQpcFlyVjgHruTesEsu6lzPhZjsr+/X9r8uv0uHmCjC0uP2YH19PaI40nXX7FHr8DrgkFNIVEykFDiTwLkJgVMqVrYHLkvgfr7553h89+P487P/XO+jHC1hHCKKI1TdqiZbLrlwyCkNMfmdHHHQzAKqyGkzC2W2/w0Qv7/+uD+1Tb3fkEOg6wQRuAYUDPK2ddLi2MPWyDwmpALX4XWgweJCZ/bARUiGaIZwkz/8DagCFJaEmJj7qzuBkbSLeIoQ+h3C5tghB5gaBI45UeDKUihZvmbEobBQuhXAM4Z8qgtsQYgJyx44By0slADgCQLnkQuPSwhfYYiJflJ+S4hw6vNsZqFsGmIi71oGWQUOhSEmiYUy219XYqEkR+xjC5OFhYVFITyHEEbiulkxalgZgTMVOKfoug5hrYziCEEU5EJMFNHp9Dv1ayjC0u2KG5j9Qb+uNaZCpkiL7/iaRBUhiiNtnVTq2OTqZHjktVbgKN0DF0RBTgkzFbiIo5wC18xC+fD+tanzF0H3wIXFBG4oHMr1vwHNLZQxYqBzOjAs5+tlCZxNobSwGJOYkASu0+9MCFyUKHCRNBYCQBy7eTsDWitwZgOySnGK5UXYV+fzu8QOHVPFd0MRijiGq9aAEgVOnV+FmFQyM1hyISZmCqUDkj1wTS2UAOBW0IgD+I4HF4yosAfO6AXMFuUCC2Xx3UWDwGUVuMIxAuUKXCg/HY/TClxrC6VB4BwvUUctLCwsLHJwXUIk611KgXPKCZyqj9l99LHkIuIon0IZN1IWSkUAVf3uccQYnYONgwmBM3rUumTN9R0fjbg9C+V5s87DZ1/2WSyetlgocFGawLVS4BpxA0PBUKrmKcJZRuBcxy20UO53HGzoFwNZy5w5QBsWymAwRzyB5iEmEUdA17TkiVwPnK2TFhZjEROSwHV4HajH4kJnKnAhJ3PglAJX1gMXE0n6kyFwZgqlmqPiOCCZLslgocABQKcicOLuJbPoS1MzzFqNEYhiqcBlh2g62R44k8ARHDCo1Rw4ua4gDuGTB4eBqM0euLZDTMwUK2Vd1MmVbShwOsREnZM0yXSLCFzhHLishdISOAsLC4tWKOuBy6prpoWypQInr9WmhdLsgXPIQc2t5RS4HjchcGaIiYJSnSpGW0ARTAul7/h43cmvAxGlCI4OMWnRA9eIGgg5TBFGbUuUaqSpXCoFrugm5yNVUfN6Kj1NLZTt9MC1q8CpG9ARR0KB0wu1KZQWFuMBE5bAtbRQtuiBAyTVayOFMiYHLgBH9ZFV5AW0I0Pg5Gsr+1+ZhVJZGbUCZwaYAAnpifIKHJOj58C11QPHEXzHFSPOiy7UKaJVMkaAKH03L/t8ag5cxkJZOEZAFs5siAk5pSEmogcuP0aAszYQpdRZAmdhoOz/osXowX7G4wvt9sCZ89FUjSsjcEqBC+LEQqlsj4PhILo80f+WU+Akgetr9KXGCCi0baE0FDgTJsEpGyOQHeStiJtJplIWyjiC53hJaIpTcNNYPvdEtQIHDpZOX9rUQnk4PXDlg7zDdOiaDTGxKIC9fh95jPQznpAErtPrTBS4nIVSKUXNUygBpdU1SaFUd7DIgcsMRypsUHfAOtMWSnVhbp1CqWbwhCLEJGuhzIaYmAockhCTlv8YvCoacYiK4wsLZdsKnH5Sr6dliMmILJRZBS4/RsA3Qkw0EdcWyiIFzpgD51gCZ5GgVqthz549tkAdQTAz9uzZg1qt1npnizGBQ+qBi5unUCoCY1ooTQVOqUc5BU5ZKOsHC0NM1HFFRMWEqcCZKFLgchZK2QOn6r4iikUETg0198jTr6dSKFOtDYqoOoSqV0Wn35n6GyMLdUN6IBwovF4NhuUWytIeOI4zCpy1UFqkYWvkkceh1MgJmUKpFLjr79mIgUBcjOtRHRE70sLIaLCr7waaMElVSAS/WQqlUp2I4AIglrZFReAyISbqH7/q3yrrgUuNEaj3J0RQgTIELptCyYBbFkpiwvURsJjH4zBKeuAUaSNNtsggVGqf4jECxh08baHMjhFoNgduSG4wxwjImTpFYwScZgTOWigtijF37lxs2bIFu3btOtZL0RgeHh43ZKfdtdZqNcydO/corMhiNOA4JWMEMv1t5iBvnUJZosB55OUslGYPnOplU3Pk1A3YmiP+fdWjeusQkyYErkyBM1Moh8IhOOSg4lRS+xRZKIG0GqaeC+IAIYdwHVcnY4o5tJmbxqpdAiIEzSOvrRCTmGMMR8M5sjYYlFsom/fAFSlw1kJpIWBr5OHhSNXICUvghuM6Pn3nGsw6U1xcG1EDIRzEMuMx5IKZLEju0EUcFStwxsU1GSNAcBlwOBakqaQHTs/IaWGhVDPoImWhnHxSegdVQHUKZTp1UVgohRrIzDqSOQe3ioCHdIhJcQqlQbQOeZB3nLdQOs0slM0UuCYhJs0slCkFThI4sDh32edjcVzA930sWLDgWC8jhdWrV+Occ8451stoC+NprRbtwzMtlG7rHrh2UyhVr5wZYhLGIfob/ZrAZRU4TRLjUJOkIgVODQUvQxzHuRlpQF6Bq7m1XN1U61XEp9BCGSWDvKM40qMN1Ht3UGyhDIngOi5cx21rjIB63RyBC8stlGU9cHkLZfbmqlVdjnfYGnl4OFJrnZAWyg6/AyECADEasRliQoAMEQm4PIVSX6gL/q43UyhVsQpBcMEgjoVCVylOoVSEzWWl1pWEmMjvYVmISVaBKwwxUedqcvF1fQQco0Ie3FYKXMEYgecowu3dXYChZBaGmCiiBBjFoR0FrmiQtyRwxu65OXBFCpweIxAbBA7W329hYWFRANchhCOYA6dsg0X7mMcqFUmRQqV07a/v10RMEcB6WAeBClU+M4WyXQUu5LBYgXPSKZRFNsRcD1xU3gOn1umRp62XzebAhQBcabdsR4EDivvghsKhtnvg1PsoDTGxFkoLizGNCUng9AXMCRAYvXARXMRgOGCEKFfgVLGKDdugfr4ghVINz3aiQDyrFTgZzSsVOPVaOmSktAdOIOSoOMREzTvTBM6wUMoeOKdFnx0AwKumQ0wKFbhEZcuSrdtpAJ+YPhUMaqHAFVgoHdmp13SMQF6BU5Ye1yDS7fXAmRZKxxYnCwsLiybwHAdRNLJB3u2kUNbldd3sgQOAffV96PLSClw9qsN3fH0+c5C3IlkE0mqc53hNxwjEHJeGmJhz4LL9b0DSAxdwElQCiH40BfXaQRRosqgVOJIWyoI2g0iqb57jNe2BMwlcNoky5viQ58BxpzlGIJtCaW9yWliMRUxIAqcv7M6QDi0ZDut6DpwDIIALB+m7XSxVMXVnUFzu2rNQesxwo0CQPjUHrsRCqUNGStQxTeDiEKj3lc+BKxzkTWIOnPGeSuFWEMi7hA5YB4SkYIaNZCwVoXy9iKhYgTMLJUf5bY6LQgul44jPrIkC5xufne4rGJGF0vr7LSwsLMqQ6oFr00I5EgXO7IEDgH3D+5IeOKXARXV4jgdxizH9GopkdXgdev9WFsqIo7ZCTIoUOLVebaEs6IHTFso4QBzH2hap3ntZCmVEjg48UdbGIjQjcCrgpEiB8xzRW2e+diqQraM32dmmUFpYjAtMbALn9ett9aiOWKZQisAOkUJpEhx1cdMKHBUocAUWSh1iEtYREwC/A88efBa7lVKWCTFxwHC4iQJn9sCBm8yBq4uLrOMYx6oUyuZBKWpdATMqjle+Hm2hzA/y1gPHgWIFrmgOnNkAT255/5lXAwI1yDvWa9FjBIpSKB0PmDQHmDI/vwaYCpxnFTgLCwuLJjB74JT6JLZ7mf3yBK7ZGAGlUpk9cICo0dkUynpUh+/6+nHEiQKnCJypOLWTQllqoVQELiomcIqIqf0KCVxmDpwrg0nUZ+LIP7n03x3KQimJXpEryITZAzcYpi2U6nGRAmeOelAwiWIAADVJ4rIJ0bZGWliMSUzIEBN1ASM3uUNVDxsyhTKGC9KDvCOOsHd4L2KO0VsRFzBVkIouW0UWygjCsuhEdfFspRN/vfqvsWTK6fjUgj8A5rxI7KcUOE5CRoqguEmoClGZAhcOZ+yCgqY4UmXUayy+GQq4FTQQo5tcOGhjkHdWjVRE00nmwKX9/eYcuISEaThNCJzfAag7jFqASxS4bAplxJE414eeyJwzYwNRvXKWwFlYWFiUwuyBM4ddt6PANbNQZo9TFkoAxQoceZr4BHGQS6E0FSff8ZtaKEsVODfpgRsKhgotlGqdjagBZm49B04RuIyFUq1DEDv5mBy9bysLZYfXgaFwKNcDp9bRTD0M41AT5txIpK4TgOEDtgfOwmKcYGIrcCaBU4O8OZZkxYEDodz8/f1/j4/e+1FNsFIhJiWDvDVpgIwABsMJ64JW+J3ob/RjZ30v8K47gJlnAkgsk8o4WDrIO6XAAaj2pHdQF9iwkSNwMZHosVN8pVmIiVdBAIZPLpyyUJWCFEo1RkBbPZF8LsUN2AWDvNXPmUL/m22/wS1P3wLUJotioo4XBxSmULrkJp+lkw5byVsoo/TrNmkYt7CwsDhe4TqE2HA6qD/8cz1wxny0Vj1w5ggCrcAZcf1FBM5U4MykS03gDMWpnRTK7BgEtRalSBXF8wMJgatH9ZTKZ/bAZQd5q7429Z7U+8oqcJHslWvHQjmlKsYTZS2Ue4f3AgCm1qbmjlOftblus1aHcZgEmZBV4CwsxgMmNoEzLJTDUR0RXAARHBY9cJDhGzsHd+JA/UBioVSDt0Eo64EzY3mVAkdhXfbAdSCKI/Q1+tLHyjteJFMiy6wSSgkLSwmc0QNnNJcDMsSEk1U3DTFxBYGrOJ74ZFqmUKb/uagyE1HyuRQNKRUhJplB3vrn9Of7g3U/wLce/5aYoTe0LzkekCEm0kJpEDgyevDKYVooXXt30cLCwqIJhAKXXB8VCcgSICKCR15bPXAmsctaKAHkxghkFbiII93GUHOlhdJr30LZtAcuSo8RyMIkcCkrY0EPXMpC6aRTKAHDyaMtlCQInOO2VOCm1IoJ3K5BMaNresf03HFm0IyCaacMoiAZJZBV4OwYAQuLMYmJTeAMBa4RNYwQE0aExG8+EAyk7uypO4KFCpwsHhWnkvR9QVj6nHBY9sB1IeQQB+sHU8dqBY6bp1CqIQA6VCRnoTRSKDPFVFgok19scwJXRQPQCly7g7wV1N6RkUKZIlJk9J9pC2WGwFGeIAdxkCZwLcYI6B64QiiiphZte+AsLCwsWsHsgQMSwlWW4tjOHDiTPGVDTICEjKlB3mEcwnf9FEnMKnAdfqKW/f/svXuQHMd9JvhlVlV3T/cAM3iDAEkQ4JsgKVEiJdESpaFO1tryQ+c731p+7K1uV6eww7713q7D6729kON0foXPe7txYXll+azw4ywrpJXtlSVKa4ni0BYpUSQo8E3wBRJPAoOZwcx0Tz/qkfdH5i8rqyqrugcYko1hfg4HBt1d1dkNqnK++r7f95lWSBtKi7wN4ldWI5AhcEm2j42gUyjJQsmzM3BM7e16v2JZC+WwGoFBPMB0Y1q+b5QjcN1yAmedgcvPw1ESpbNQOjhcEtiQBI4l8kLLfHmBa3gNHWISQ35ocwZuNVzN3D1MawSAvEJEd84CLzB64GS3HNMWygnEoqjAmTUCTFSlUCoFji7kVSEmVgul0CEm1SmUgbZQltYIcFOBywaCmCEmlT1wmSJv4/u0WCijJEoJ3GpegQOixF7kXbbpCb1kw0LJ/fQ7dAlbDg4ODgWYM3CAocBZFCyK4b8QBc42A2cjeqRO0XvUfXncWhS4RCRDUyjLagQYY6h79YICZxI4IkVREkkLJSumUAI2CyVLawREXLpv9+IeWn4Lda9emIE71z0Hn/laoTNhU+AKFsrpK4HaJiMUzVkoHRzGGRsyxGS1Ly9A3JMWys31zRjEfcSoQ0AqYDE4IGQKZSfqZGx4GQtlyQyc2atCCpwXdpHUANSaiJMYq/EqhBCZwWWAFLLyIm+tbGkFLmehNIu8c+QuofOTY7AqhdKvI2JAwD0MsBYLpSJwsgshMwNXGmKSxDkSCKuFMhaxvINapsCpz+MbZHMkBU5bKGNnoXRwcHAYglFn4IB0P9Qz4ny4AkcEzqwoyBd5m6/Lk0Sf+ajxmiZ99NoqAhfGYWlPmlkjYIviB+R30I/6GZWvrEbAFmKiLZS5UK9YKYxm2qaZ/EkYxAPUvTpaQatgoTzXPYetE1tLFUYgq7plQkySCHjXLwA3fTg9yNUIODiMNTakAtfuqbANpcBN1ae0hTJmTBV5e2DKrtAJO5mNIa0RAAoEI0ltlto2iETaIsMeBGMQ/oS2Apq9LbpGQIghRd7Us6aeL1Pg4hILpdEDN2wGbsAYAvDhFspMiAmtUy3DmIHLWigN8mQWbevniwpcnBgWyrAjSapxt5IUOC/DE1n15wRyPXCGddMROAcHB4cC/JwCZ85y5UEz4UN74HhRWavzERU4tV+bNs2p+lRGcQq8IKOO5TFIBpnQFPM4Wn8vtitwQOrmKbNQ6hCTONR2TSuBy8/AMZ7pjCtzlPTjPmpeDU2/WZyB685hx8QO63HWGTizRiAJgVoL2H5tepC7yengMNbYkArcUocUOEXgalNY6p1AAq4Vqkh4YGDoRT1ESaQtD4AxA2cpmSbbY+AFunclFgk8xsCiLoAAid/Q51oeLOvNoFDkXZZCqf6MIQkZK60RsFkokYleGVrkDSAAU/EuQ1Io82SW/mTpbGD2/cwagbhA1hBMAH4981AkyEIpff7onjfm58waAeNjVChwwlQBAUXgmm5zcnBwcKiAVzYDZ1HXSMEaNgOXUda8YoiJnoErUeAyJJF7+KMP/lFm5osUONP5YmIQDzLvl38PGnsoI3A1r5axUPrMz/Sx6R44Idfpcz/bA1dmoQRDYHTGldX/9OM+Gn4DraBVtFCunsNlrcus6zZrBAgFBS6P/N7p4OAwVtiQBG6hHUEkHrjfgQApcC8iIgIngBgeGONYDuUFO6PAeeU1AtYUSiFLCbgiMUnQ0K9b7i9jZ3MngPSi7ak1lNkbzUejHTcgqLWyL9B3MYUlhZJ64FTU/7AUSsYQCAFPCCS2C7VW4FBUy2iNxvtk3s9Uuci6aOK//6N0cJrOmcg7rHFjSu5f3UWYFspYxPCFyFDJqhm4goXS9cA5ODg4DIXPeZbAedUzcFES6Rt5o4SYjJJCSecGJFnKK3BXT1+dOX+N1yAgSi2IYRLaFTi1luWBDB6zhZgARQVuujGtlTDauwCpwEVJlFHgPOZZQkzIQgld5A2gtEqgH0kFrhW0rCEmN2+/2XrcSDUCebgUSgeHscaGtFCeXekDogbBpX1xuj6NQTKQChxj8CAQgYOB6ztuZrpVtsh7eAplnMTwGUttizwlFCthGmRCjzEhCVaZOhYbj0d3/a/FsutMGXaxyHvUHrjI85EwhhokqbT3wFXMwGmrZ3o3zxpiAiHv4uU3/j23ycFpA3oDpOqE7mKmRiBK4kyACTBsBo6WYFgomZuBc3BwcKgCzylwRHyqCNxaFDhbCmW+B858XUGBKynkBlBqoxymwFGX2qb83LlC3a+jF/X0+afr01oJM8kR3RCmZEn6TGUzcBEkQSULZZIU9yUqD697dTSDZkaBi5IIi71F7GhWWyjLUiitc4NuzMDBYayxIQnc3EofTKQX6c21zRgkA8RCplAyyBRKBqYJnG0Gzhpiomhdzatl5r44uE5+NC+MZpWAHvBWayivEUgRX/eh4gsKXWrm+jByD1yojg2EABdGbYHtvSwELrV6poEsGVWRDbFQWkBEMGwYBC5TIxAVZOOqGbiihdKFmDg4ODgMQ34GbpQagaEzcBYFblgKpdk/Z446VIV1lAWZ9OO+fo3tuMWeDM7aXNtsPb7u1TGIBzqsZEtjCzpRB0KIQsdaLGJpobQVedOepmfgmAw8MUrR8yDVzxZistBbgIAonYEbpsDZvy9H4BwcxhkbksCdXenDE2pTED4m/AlESYgITCZGCiJwPPWsG3cPNYGzhJiYJE+nUIoEHuP6yzQTqsiSAaQXbeppKw0x8VPyGVXNpQGAZ7NQjhZiEqrNIhACXlkqJhGgfIIkjBk4pAmeWQulQfiS2IgnLgdtXAOyjeYVOJHAsyhw5RbKbPWB64FzcHBwGI7CDJyXzqLl4TNfz30Ba7RQKmXP575Wx8w5u9IZOAtJpHOVEbgwCTOEMf/ZhipwXh29uJdaKOvTOvgkr8BZLZSspAcOyIaYWMq8e1FPryE/A1fVAQcMV+AqLZRuBs7BYSyxIQnc3EofHuSFnIma3hRCJnvSqMib5T4+2SLo9TFQJC3UQ+b5aQ9cEkkCp65z5oXcJHCZGoGqHjgj5tjqhc8ocHkLpZwPoxm4qhCTAZefrSaSihATs8jbUiMA2YNnErf057wCZ78ra0IrcCaBMxW4JIaf+0hUyG5H7i5i4mbgHBwcHIbBY6MXeV9MCqXPfTCwTB2AdQZuBJsmETErIcEaLJSBncA1vAYG8UD/rrClLhMwO2Enc+OWvotCjQBKagTU5zNrBGxrBySBa/rNzAzcudVzAFCqwNFnNlOxR56Bc3ukg8NYYkMSuLMrfdSYukiLQN9xCxnTRd4hih1kdIFMawRY4TXaQqlm4IQQqu8lVeDMiGGzzFuHmAhZtF1eI5A+br2wmqQtn0IpEnDGjaj/8otvRBbKRFoo7Qpc0UKpzy1oBk5kNoP83UVJ4JJiiIkFegbOb8j3yyhwXFkoswyuisDZUyg9d3fRwcHBoQKel7VQrvcMHO2zjDEZzOG3Kl9HISaVM3C8fAaOQkYCr2ihJJI1350HUK7A1bxaVoFryLTk1XA1c+NWjmzEupybPpM5A/fjf/Pj+OrSEQBAxOTno9faFDgiXzWvpmfg6HcKUuDKZuCIHOfn5ghuBs7B4dLDhiRw3/43d+PylooBTlIFbsDSnrRYFBU4ukCmM3AoLfLWr1Ebisc8rXqVWSh1iAmGWCiNx63WwKoQEyFUPEvxXHmEyqYSJDE8jNADlyOzkfprnHufVPUz7IvJaDNwtKmEIjLKvFMLpUyhzB7jFDgHBweH9YXPGWIjTGOkFMoLsFACKSmpet1aFDgbISHSVZVCOcxC2fAbmSLvjAJnvCf9LmHOtXk8tVD24z6OLh3F0YGcuYshpIVSfW7rDFycnYETEOhGXQApgdvW2FY4DkgJnDk351IoHRwubWxIAtcIPEwo1U0kpgIHxEYKZf7jawVO1wgUFTg9J+elBC5KIng8Vb3MC7lVgYOyUJb1wIlhCly5hTIRCZihBlZZKFfVhXlChZgML/LOzpOZISbmZqB/zitwI1go6bPrMu/uokGylIUyt6GMNgNHb+CKvB2dM65FAAAgAElEQVQcHByGYa09cBeaQgmkpKTqdR7zhs7ZVYWY5EckbMct9BbgM7+0RiDfAzdVnwIArEZZBa4fpQSObKOmAkcEL9KJztnXWmfgYmMGzs8SsvnuPKbr01Z1ESghcElsnY3TcDc5HRzGGhuSwAHQFsrEIHADLnTMfmyxUGqLgrpDlwB48MwjeOj0Q/o1RIh02XcSK9uin4aYmDNwlhRKpnrMSnvgTAXOciGvDjFJwBkDE8N74Nrqoj0pAB9C/l+e8I1UI1AyA2eSJJGMFGKiLZQZAkdrUSmUuTWuyUKZ74Gzfb8ODg4Ob3LkZ+BMIpUHFXmvKYXS2LtqvFY6A2dT4Djj1qLuKgsl7cvDFLhNtU3WcwPFHrgtDfsMnFbgTAsluO6B0wROpHupWfo9dAZOqZVagVudKw0woXVzxgsK3IQniap9ZtDd5HRwGGdsyCJvwCBhSaB/jpi60yXUDJwYbqH8g6f/FPVaC++87J3yMXVh1UEnqljUN1MoTQXO0gMntb+KGTjjcas3vSrERAiko9LVM3AdyHNPJol+faEAVdcIsIIF0izyNjccgYu3UA7igSRw7bPI1ggk8Ea0UIZJiE7SU0twPXAODg4Oo6IwA+dVzMAxSeBiEYOBlRKgTIiJsc80gyamalP674wxMDAIRWzo2H7U13PeNujAsrUqcF6WwJWh7tUzChxZKFfDVV09wMC0Wpa3UNK66XhKmY6EkGMYFUXe5gycVs7U6851z5UGmADy+8xXD0RJhLpfx0q4UjID5+bEHRzGGRuWwNWZigpOAnCmkqmYQMIAX0ClUNoVOLqYJ4yhn/TBk/SCX5iBU4PRHvd1D1xmBs5Q4EjdommyUSyU9hm4ih64NVgoV9Q6W0lKimIRwzf/s9A1ArZOvPTuoVk8ardQjphCmVfg5o7kiryLISZlRd6fe+Zz+OPFP8b75SLUot0MnIODg8Mw+CUWyqoZOKGISBmIoHDGM2TuN97zG9gcZLvXyDJpKnCdpKNCw+zvUWWhzO/vtuPO985j19Zdpeuve3WESajPRRZKcwauzuoZC6UtxEQTOEOBM2sEbEXe9J4Nr5HOyqkbnvO9eezbvK903YC0UbbDtv57LGI0vEbmPBk4AufgMNYYKokwxj7LGDvLGHuy5PkZxtgSY+yw+v9PGM/9EGPsCGPsBcbYr63nwoeBCJxIAnjMqBGArBGINI1KYVPgekZpJ1AkcJGQxaIe8zUJogu5z/3MDJxW4MSQGoE1zcDZLJR8pCLvjlrnpjjUASwFy6bVQqk+D/0pcgqckRqpHhk9hTKxWCgzNQKRNcTERnTnVuewnHRoUfJPPQOn1uIInIODw0Vi2F7HGPt5xtgTao/8NmPsJuO5f6uOO8IY+0ev78rL4TGGWBQJXFWRN9kby8/pZc5FOLjtIK7YfEXmMTqPrhFQKZRxUv4eVRZKrcBVWCgjEVUrcL78vWJlsAKPefq1poWyxmupAmdYKM0eOFpLqBS4GEKmUFZYKK0KnPr9oBf10PAbpesGgMlgspBCScfYCZyzUDo4jDNGmYH7EwA/NOQ1/yCEeKv6/08CAGPMA/ApAD8M4CYAP21uWq819EVaBOAwFDioFMpRLJSMYRAPMnYGTeBIpROJjgsm0kQEbmt9a7bIW4eYiNc2hZIxXXZdZaFsq9SVVm9Zk8/Cmqw1AiPOwJke+lEtlCJnoewvA0SgGSmExRk4m9IYixgx6YQuhdLBweE1wIh73eeEELcIId4K4HcB/N/q2JsAfATAQch99g/U+d5weJxDCCBRKhzti/0IWOpmFa6ABzpgxKu4UUfEK0/g7O+fJXvmnN2FKHBaIbMUeZuBKsMslIAkcDUvndvrRFkFjkq3PZYmS5o9cP2EZuAMC6WhwNkIFf1+UvfqhbqBSETWgnUTzaCZVeCSOA14czUCDg6XHIb+Ri2E+HsACxdw7ncAeEEI8ZIQYgDg8wA+fAHnuSCkClwNTKQELmYyBTLUNCoFXSD1xRFAP8kqcDqFMmeh5LwYYrKlsQXtsK0vsmaNwKgWytI7Y0RALCmUMBS4KgtlGzE8IdDozIO2wwJhrCryVqeOkKxbCmVBgQOUCifXUlbkbSO69N3FxppdD5yDg8M6Y+heJ4RYNv7aQmor+DCAzwsh+kKIowBeUOd7w+F78vpNc3B00/K3vnoEv/D/Hcq+1lDg8qMJJojMDCMbQFGB85g3VOUbZQauykIJQM+y2UCEpx22EfAAPvdR9+qZHrg6q2drBCoslKHat2IkGbI3LMSElDq64RklUaV1FbAocCLSn8fVCDg4XHpYrxm4OxljjwE4BeBXhBBPAdgL4LjxmhMA3ll2AsbYxwF8HAB27dqF2dnZi1pQMlAkSAR47PBTACSBY2DgQiAWHhYXlwAAHjzEiHHkRVmq+fyzz8tzAOj0O+CRp9fz7MqzAIDjL8uP9sB3HsBgMEA37mob4mNPPCbfuiv//vX7vo6W18KTq9KFygXAIDA3P4fZ2Vm02+3M511YXNAD3Ie+fwidiXTwmPBecHAkOHVmDs8Zx7Y7bcRhuok+cugRnKufs35HRxZewGQiEC6eAm/Itf79t/8em7z0DuSNZ+ewC8DDhx6FYD7eAXk5n52dxSCOAA68cvIE2kl6Z++BBx7AlD+FqfNP4TYAhx87jMvnzqDeX8WhIf+uRJYff/JxXNHp4CYALz75MK4G8MihR7HQXsQeRbroOzt2/hgA4Fv3fSuzsZ+YPwEAiBnwwrPP4NXz92FGxHj52Aksn38StwJ49NAjWH4htbm+0cj/tzDOuJTWClxa63VrvaQw0l7HGPtFAP8KQA1Qo7ny2O/mjt1rOXZd98dR/s1eOSoJw33334+6x7DYWUSDNfDoi4vgCDLHn50/i26/i2PHj0HEovTcT68+DQBIomTo+yex3MNfeekV7OA7sNBdQHvQxvETx0uPnwtlH9rjTz6OxstZS+GRrtzfn378aQyeG1iPA4DzZ86Xru1o+ygA4NiZY0As96BABHj+lechzsh9yRe+JmDPP/c8VhNJml584UXMe7Io/ImnnwAALCwtIYbcU4+/chzNMzJd8tHDj6J7pJt57yeW5TGPPPQIToen5c+PPoKlxhIG0QCnT56u/E5Xz6/ibHhWv2bh/AJqrAYGhhePvojZ89ljJ1dewu0AnnjiccyfttcqvN641K41l9J6L6W1ApfWel+rta4HgXsUwD4hRJsx9iEAfwPg2rWeRAjxGQCfAYDbb79dzMzMXNSiHrvnMaAtZ+DecuvbgfuBiCW6/S0Cx/TUFmAJmG5MY743j8uuuAxYAt5yy1uA+6SFMmYJao0aaD2nnz0NPATccO0N+PLDX8Yd77wD+FtgqrUFTPGka2+4Fvg2cGD3ATz38nO49Y5bpb//OIBvyQRKDmB66xbMzMxgdnYW5uf9k6//Cern6ujFPRy85SDuuvyu4gf8tg9EEfZcfgX2GMf+3l//HupRA54iMm+97a146863Wr+jv/uHv8PkEkctXIbXkFaQO3/gzmwc8eLngbPAHXe8A/BqwMNSPZyZmcHvHfMAEeKyvXvQOPcqVKgl3nXnu7CrtQt4pQ4cBt56663A6gNAe4Bh/67iz+QmeM311+AmTALP/AdcfdkW4CXg9ttvR/PQ38E7L19L5zry2BHgMHDX++7K3EmdfXAWeB6IwXDDddfhhrfeBdwPXHXgGmDvW4AngLfd9lbgytL7Cq878v8tjDMupbUCl9Z63Vo3HoQQnwLwKcbYzwD43wH80zUcu6774yj/Zs/zl4DnnsG733MXJus+3ivei/+p9z/jjv/z29i5qZ45/qHvPYTvv/B9XLbnMtRerpWem5/gwL3AZGNy6PvXP19Ht9/FDdfdgMlXJ7Fneg9OvnoSu/fsRv1Y3Xr86fZp4Ety/5i5Nvs8vfc73v4O3Lrj1sxzr3ZeBf6z/Pmmq2/CzK32tQ1eHgD3A37Lx2RffobpL01jascUrt1zLXAOskNOCVoHbzwoxyi+B9xw3Q3Y2dwJfAu46pqrgO8Bzc2Tepb8mgPX4I7L7gDuAQ7echDvvfy9mfd++cmXgUPA+9/7fhxZOAJ8Hbj51ptx5547If5M4MC+A5h5W/l3eu8D9+L0qdP6e/vMVz+DzfXNePHki9hz5R7MvD137OmtwCHgloM3ATeWn/f1xKV2rbmU1nsprRW4tNb7Wq31onvghBDLQoi2+vkeAAFjbDuAkwDMqeTL1WOvC9IUyhqEslDGXKZQcsgZOLJQTtenAaTlm9pHz6QVoyrEhHrgPC/QXybZEei8y6F0z2RqBIYUeevzlxVUk12ipMibFLiyoBRA2kAmWQBAwBspxCRb5K1n4ES2yNveAzc8hVIIoS0hGQvl6jwtRoWY5FIo1dxA/vukf4eIqTXTGjMWSufvd3BwuCisda/7PID/9gKPfd3gcXn9jpVXnjOOxTZHnAisDrL7hE6hxGgplBdiofS5n+63ZTNwyh5p7tkEHTJiqREYdQaOQj9oBg6Q6Y5mkXedpzN2nHFtd7SnUCaI1D7pc7+yyNsMMTFn5WjfHPad2moEfObDY571+3JjBg4O442LJnCMsd1MRSsxxt6hzjkP4GEA1zLG9jPGapCD2l++2PcbFXQRFSKASJRfnAmZQikEInja2k1RwOYFEgC6lk4WurAWUigtM3BbG1sBpFUCukZASBWrKsSENiJ7wSZS4mYNMeHgalOoTKEMO2ipsJfyEBOqEUgJnC4JVy+JkGRDTJALMaEeuCEplIX+u4YkwOkMHEOcxAXZmMhqnuzS+WIwFaSivkvXA+fg4LB+GLrXMcZMV8qPAHhe/fxlAB9hjNUZY/sh3Svfex3WPBTpDFx6jXxpThKAbmgncMNSKNcUYpJLrPSZb+y31SEmVLRtgh6rSqEERgwxCVf0Ht0MmoUZOP0Z8imUyKZQRiLRCtywGbh+3NeE0EyhpN9Phs3AEYGj30NiEUvSqGYLC3B7pIPDWGPobTDG2F8CmAGwnTF2AsCvAzLWUQjxaQA/CeAXGGMRgC6Ajwh5hYgYY78E4L9C5oZ8Vs3GvS6oqeoAkaQELmYJPLWYCB6ESqEkAqeHnNXFvKsIi3l3ihQtInk6hdKrgasLI13IpxUBoSqBQpF3SUJkIhJ9fluhpzyJPcREQIAbhaBVBG5lsIId6o6iVg/z76dTKItF3pEOMxF6405EYlHgMFKIiblpyRRKReB6S7QYeacxr8Cp8+Y/K32WWCbGpATOpVA6ODisE4QQ1r2OMfZJAI8IIb4M4JcYYx+ANJovQtkn1eu+AOBpSOPdLwpRZrt4fUE3Ac0qgZfm5KzzIEoQJ0KrdD73dQrlSDUCliCR4vvnQky4JBpV71GVQrmuISaDNi6fvByAJHDne+czNQIEn6WqGmNMr5tuFkeIEavv2eMpgSsr8q57dTDGMnUDdFN5FAVOQKAbddEMmjr4xINn/z3DpVA6OIw1hhI4IcRPD3n+9wH8fslz9wC458KWdnHY5m/Dvsnr8HRvL+JEWgpjliBmUheKwSGEvECR1ZG6W+hivqo2p4wCl0uhDONQ2kZMBU5dyOm8FN1r1ggMS6GkTaBUgRtqoeSZ97ShE3awP5iUpyFVraDAlffA5Yu8feZjIAYGgcv1wA2pETA/q1TgJLE2FbiyHjigeNdSRyzLb1uqgIAjcA4ODusK214nhPiE8fMvVxz7mwB+87Vb3YXBJwulUeZ99FxqweuGMSbrcv8xic1IFko23EJZUOAMla/sPXQKpcUSqB02NgXOW5sCF4s4tVD6LZwMT1oVOM54ZQ9cJBIal8uQvTILJb1/RoFT++YwAjep9vpO2EEzaOr6o6EWSpdC6eAwlrhoC+W4osEb+J13fRZJfw8GUQKf1RDzBAkYPEEKnLyYlipwSuWyzsB5WauGxwNtGKTHJvyJzPFmjQAX1RZK2hxsF3IAqR0xdzcxEQk491ILZVUPXNjGpNqs6NJfWiNgUeDolTQDZ3bjqYPkH9QDN8RCab53mITyswWtXI1ApOf1CGUzcNpCqRU4NwPn4ODgMApIXYtiU4FLCdzqIL3hdsUmOcZ3dPnoa6bAUZF3lQJHNkWbhZIIlnUGziCUm4LhRd5ASgRbQavUQulz3z4DlxgWSkOBo9fafjcYxAO9dvpOwiQcmcA1A5lwSTeUaQaOrKkFuBk4B4exxoYlcABQ82lgOIHPa0hYokJMBLhHOlhK4EiBo4vkKksVOJFTqLTXXpE+vmkXeGsHgHSjIAJHF2s6lgsMLfLWM3ZDFbgsKZIzcAaBSyoI3KCNlvrsWoHLv57OzzjSmTaJtMhb2iZpA9FEKi2jG0mBM8kqfa+YmAa6KnayJMSkbAZOWyjBnIXSwcHBYQ2gGThTgXvpXBt1ta92jSCT/VP7AQAvL71cTeBy5dxVsBV5D1PgGGMIeFBpobQVeTPG9P41WZssXZN5LJHQVtBCJ+pgEA/AGUfA0s+WV+CoyDtV4GJ5g1E9X1Xk3Yt7+v3NWTna54apmqTAURccKXAcvOT3DGehdHAYZ2xoAkcbjVbgmBwY5ozB5x5EMkSBYylh0WQgb6FUG4W/+QrwH5dOUlLcNIFT56X5OU4WyhJrQgJDgSsbhyBildsIEyRgO64De8fP67/bMIgHGCQDbFJBKxdS5J3oYWg5B2j68vUx9HoRDydweQUOkDZKSs5iagYud1zZDJy2UFIKpSZwrsjbwcHBoQr5Gbilbohz7QFuvEzOiJlBJvs27wMDQ5iElRbKiyry5l6qwPHyvaTm1ayWwKoZOCDd00eZgQNSBc4MManxWubz54u8yUJJds6Q+4g37dGfc1iR98VYKFuBrAoiBS5OYh2cYg8xIQLn9kgHh3HEhiZwpMD1owQ+C5AwObXFweF7DEluBo4uqnQXrGtsErQh5BU4Osa8OJcpcEQodIiJSPDU/FP47NxnMxfQJEkqh7EBpATEMgPHmzvAr//hzHrzoIt4q7ldrwmoslCmM3AsVyMQKwWuYKE0SdJaLZS0AVMSpXrnOIkLChxt5nm7Ka0johRKYZuBG4u8AAcHB4exgq+vq/J6S/NvB/dIgmNWCdS9OvZOyv7x1zKFEpBEpooklipwyQAMrFSpCngAj3l637YhQ+CMGgEBgeXBsj6H+Rno754RLqZDTBhD9NG/TV+7xhm4OInXTOCoSsBMobT+nuFcKg4OY42NTeC8VIHzmLRQxozBA0PgFUNM6A6dxzz4QmgLJZAqcOS/p4ulSfro4mx67c0BYVLcPJH2wD3y6iP4/ur3cb5/Xr9XRoEbNgNnqREw067KQkw6A3kR39TaBQCaFK0lxCQ/A0cbo1YWMz1wI6RQJhYFbsIgcGUhJhTYklM0iymUJoFz9hAHBweHMuRn4CiB8uAeNXKQ64IjG+UoM3AXqsAB0FbFMpQRuDAOUfNq+kar7bhNtU2lzwNAw2von80QEwBY6i8h8AL4hkfErBEw92X6XSNMQr3vmTNw5kza2dWzOHz2cFaBM153oQSOUih9+EMUOLdHOjiMIzY0gasH6oIfJfBYgITHSAAwxuFzpgkcWSZMNY2LNIUSyCpwnHG9EVHH22QwqYkEbR4e8xDwQF+szRAT6oGj1/ainn6vTAplWY0AkSEvp8AhyaiBZQrcSiirDVqtnYDOrBymwGU3NkqhjER2Bu5CLZTmZ81YKNPFSAK3523AP/kb/eiwFMpCD5wLMXFwcHCoBKVQklX+7IrcH/dvl0QgX+ZNBG6UFMo1KXDK2WG6XioVOC+wWyiTgTWB0jyuKoESkCQp/xkoHOR8/3zGBkmfobIHTs30AeUplJ9+7NP46Nc/iucXn6+0UJZ14xHKFDjOSmbgXAqlg8NYY0MTOK3AxXIGLvLb6HCOJhh8nloodZF3lBI4D0IXeQPpUHEsYnBwbdsj5WxTbZN+jDYPn/sIvEBbKM0aAQ5Jtui1eQJHm5Z5IT+ycATtgbwLWqbAEcHUPXAlM3B0EZ+sTwETW8DVNbqg+FUocGkPXJJJoUxDTAwPfZIMt1Am1RZKAUnyvGv+G+Dqu/XjtHHlA1i0hTI/A+eKvB0cHBwqoRU4ZaHs9CMwBmyfVCFf4YUrcKMQuHzlAB07SC5MgRvEg8r0S1LgqsAY0yTKtFACSoGzWCjps5r7srZQmkXc3F7kfXzlOGIRY7G/aCdw6ngzPMWG/AxclETyPeEslA4OlyI2NIELVIpWP4zhsQBhYwECwH/XF/A9jgmxG/s278O2xjb5ukTZIZkHDqBrKnDqAieEyFgdFnsy4n5TbVNBgeOMo8Zr+u9EKJiQqY9CiFSBi3MKnJftgZtbncNHvvIRfOG5L8gXlfTACSHA1P/R320gIjhZmwRaO3Q0f0GB0ymULKPAmcoezcAVQkwyPXBrCzHRMdCGAkczd3mrSJkCV0yhNCyU9Lnc5uTg4OBQgKd74OQ1st2PMFnzMVGT1868hfLA1AEAQwgcX7uFkkgXHTN0Bs5LXS8m+nHfWiGgjxuBwAHpHJwZYgLIm7kFAsc93LTtJnzslo/h7bveXrBQ5i2QWoEz9rJT7VO4ceuNqHt1tGotfV5AKXgjFnk3vAY85qUplEmc1gi4FEoHh0sOG5rAMcZQ8zn6sZyBA4CfWm7jKgTwPYZp9jZ85Se+In3r3E8rAchCac7AmQqcYaFc6i8BQMY7b1ooa16tYKGkQP4qCyUNPBMJ+drRryESkbZsggJW8imUeQVuSIjJZDAJtLbrFMpRZ+CyiZFxRjVMSaOhwF1IkTeQmYGLhH2jIuKcVxu1hZIhZ6F0NQIODg4OVfBzM3CdfoRW3UezJq+/Zg8ccGEWynufOYPfuueZ6tcqZWldZuAqLJTXb70eB7cdLH2eQCQwPwN3vn++OAOnfgf45bf9MppBMy3yTgwLJc3AGYEntBcmIsGpzincuedO/MWH/gK/fJvsgzdn4HQS9hACxxhDM2iiHbYhhJBuFl6VQumSmh0cxhnDb4Nd4qj7HIMoQY03weI6fv78CWBqCgE4ojj95T3ggSZRcrBXYMWw/JkqGgfXm4lpoSRbonlBNSONidhw00JZosARSaQL6z1H7wFgKFN0sc73wEGMZKHUKZRBSxI4UaLAmQTO6IEz7Y6R4eGn9ctjLrzIW99BNSyUsfos+RQxsq6WWihVaUM2xMQROAcHB4cycFLg1N7Q7kdo1T1MqNnybpi9dm5pbMF0fbqUXHUHMSJ1CaabfV95/DS++cwZ/G8furHw+vwMHF33h83Ama4XE4NkUKnA/e57f7f0ORMUZGL2wAGSdNlqBEwUeuDMGThjfo72rrnVOURJhL2Te3H91uv1eRiTaZprSaEE5A3bTtjR56duul7SK77Y7ZEODmONNwWB60cJ7pz+H/Hq41dhmv0GwH34jOk7i4C8+OmeNqXAmTDviHGeKnAmgTu7ehaAJcQkySlwqshbCKHJHc3f0XvQ8HOcxHh56WU8Nf8UAIPYlFgoE5GAMabv9A2zUG6qbQKa29MQk8IMnGmhTDdmU6kbkAdf3VUtDzG5gBRKw0IZKYKW36jKunOKKZSkwHF3d9HBwcGhAr62UBKBizHZCNAIOBgDuoOianP9lutL58x+8XOPYmJChmcRGTvX7mf2YRP5FEr6M0zCagWuxEI5iKsJ3Kio+3YLJYCChTLfV2edgaMQEuaBMZa5cXuqcwoAcFnrssI6PO5lZ+iG7K+AKh0POwXS6FIoHRwuPWx4AlfzpALX9LYDg+1AHZLAgSNM0o3DHKqWg725SHqDwJl9LUTgWn5Lz51FcTqUbFoo0xATgOVm4LpxV78XkTCf+YhEhK8e/SoYGBp+IyU2pGZ5Fgul+j/6uw3tsI2AB3JDa22HJ2B/vbXIO0uW+hTaohIx0xATgySJEUJMbEXehoUyLLNQUmVC7t+skEJp7YFzm5ODg4NDHrYQk8m6JBkTgVdIoQSA377rtwvXYcLJxS6mogEQpOrV3Epf35grvH++B86o7qks8uY1LIVLhceHpVCOijq3h5gA8nN5It3nCm6R3AxcLOJCiqTHPL0XnmyfBADdsWfC5z7CJFyTAkcEziSNPvOHhJi4m5wODuOIDT0DB8gqgUGUIBECiUjnxgLOMhZK80LLwcEntmbOQxe4WMRgYBkFbjKYtPbA+cy3KnAMKFooLTNwPpfDxQ+/+jBu2X4LtjW2DVXghBAjzcB1wk46sD29r1TF0nfhcjUCplo2EPIz0KyCtm2atQPJ6DNwE/6ENYUyJtsHt9tS8munzx7nUyhdD5yDg4NDJXxtTTdm4NT820TgoRsWCdyO5g7sbO60nq8fxQjVJZhI2bl2H2EsrE6RMgVuWIhJM2iiG3ULj1MP3MWioMD5FQocsytwpkJIapxO2+Se3l9PtZUCN1lU4HzuIxaxfu0oyZ55Bc5jMoXS1Qg4OFx62PAEruZx9KMYcSIQ08flHjyetVCatg/OOLx6No2KLnBCiMywcTfqaiJEj2kLpVLg8kXeHEJOZRkKHF3EAUmAGJi2SCz1l7CzuRM1r5a+TtcIZDeyBDkLZcnFd2Wwkt45vPWnwP/xn8rjLyjEJHsHMJ1FM4u8R0+hbHgNu4VS2GfgymoE6N8sZCxnoXQKnIODg0MVSOQiBW6lF2GyrghczUPXosBVoR8lCGWni7w5GSeY79AsmIXA8VyRt7G/VlkoJ/wJdKJO4fFhNQKjgmbgiAx63MOEPwFAkihzf8qrYvkQEyCdf9cJnczXe+Gp9ilsbWzV5zdB1scLUeDM5EqPyRqBxd4iHn71YXOx8k+3Rzo4jCU2PoFTISaSwKWqVeDxjHXDvPiZKZMEU4HjnGdUICJwZgolA9M1AnS3jcgRF2kKJT1n3jFMRCKrCpQCt9xfxub65gwZ1ATkAlMoO2FHJlACgOfD23o1AEtx+PbrgG3XAH6jfAZOfTd0B7CgwHEeEccAACAASURBVI1qoVSbyoQ/YbVQkgI3ao0A/T2mNZBq6HrgHBwcHCpBChzNwHUGMoUSKFfgqtALYwwMBW6hM9DuPNscHO3BRIjM636VAtcKWjoq38R6WSiJuJlkkFS4gAfwkK6tLMTEvGFL8+/0WrpxC0gCZ7NPAtC/H4QizBxfhVbQQjts633enIH786f/HB//xseNEnRH4BwcxhkbnsDVfY5BrCyURCi4D99jmbt+ZtkmY6xwhy8TYoIswSMiZNojiOAFXpAhf4D80jmqawTIphmLGEuDJUzVpiQZ1CmURQtlmnKZzsCVhZisDFZkB5xCWZIjbvxR4H85BHj+8Bk4UuAKF3xFnoZZKNWm0vAbqcUkaOrPGA0hcIUZOCJwLJ9C6Qicg4ODQxWsM3ANee1t1uwzcFXoRwmiuI5//fZ/jQ9e9UHMtVMSE1rm4OhGpKlMmc+VgQhcfu9brxATrcAZZJDcLKNaKE3kFTjOeKrAdU5hz+Qe6zoCHmRm6EZNoVwNVzMzcGShPNk+iSiJMN+bly92M3AODmONDU/gaj5HP5QETs+NeQF8zhHmUiiB9AJbqcDlFLrNtc0AoENMwiTUm41JulKCpYq8UWKhVCpawAO0wzb6cR+b65uz6VqWGThdFG5YKKsUOHP4ulDCbYUxA2cJHCkQuEyIyegplJmwFsb0HFyI6hCTfIJmGmIC1wPn4ODgsAYQgUsSIefXYqEtlI1gbRZKIYRS4BJ89OaPYu/kXsytpHtemQJnznWNqsA1/SYiEWVsioAicOuowJlkkJIoA280C6UJunmrlUZloUxEglPtcgJH1sdRi7xpnZkQE6MHjlK051bn1GLdHungMM54UxC4QZwgTgBhzI0Fnj3ExLQxAKkyl0mh5J7VQmmGmNDz+SJvpmieLvJW6lXBQqnm7BZ6CwCAqXqJAucZBE5ZF0ftgdMWSmPtZYQPQCaUxFTqChZKaw/ccAslHZeZgQO0jTJO0u4aE/nuHAKRzKhQI2AQuHxtgoODg4NDWuSdCLR78trZqslrbbO2NgtllAgkAgiNPfdcOyVY5l5M4IxnSRsvV7ZMEJnK2yiH9cCNioZfVODKLJSjKHB081anUCoL5bnuOYRJiD0tO4EjC+VaFTgBgZWBrHMgBS5MQpxZPQMAONuVRM7NwDk4jDc2PoFTNQKJEGCGauV7PGuh9FILJZCSAlKpzCJvBpa5y0ZWRE3g4lAfny/ypsfJQkkX34KFkjH43MdCVxG42lRuBq7CQmkQuDIL5fn+eUzX0/my0hRKEwaBM2flBjkFLn1PswduhBRKkaZQZnp8VJBJNEyBK5uBYxzOQung4OAwOjzdA5eg05fXTpqBa9Z8rFp64MrQj+R1dhCl11tTgRtYCNyFKnC0Z3fCbJDJuvXAeTKF0pyBK7NQls3AmdAWSrp5rEYnKIGyTIGjnti1EDgimu2wrY/xmAcBgVc7rwKwKHAuhdLBYSyx4Qkc1QjEiUBikJ6As8zdwHzSFZECujCX9cAB9hATs8OGVDMiZoBR5F1ioaT3IAWOQkw0saGIMGOD0xZKsEpFrRf10Ak72DaxTT9WRoLKkAkxUWui71CfIxNiEuN43MW/vO9fZsiqCauFEtAWyqjEKkLfdZ6slvfAec7f7+Dg4FCBtMgbaPfl/repkVooe+HoN796Sq0rI3A2C2VegTNvmuarZEwQSVmNsgpcmITr0wPnZXvgAIPAeTkCl1unzUJJISZmXUKSJJjrSiK1q7nLug6PeYhEWuSdT2e2gdTJ5cGyPkc+PZve193kdHAYb7wpirz7isCZwR+FGgFuV+DIZmgqcJzzjBWCZuDMC2EtqOnzmimUdBwTorIHjhQ42oRIgdNEr2IGjrPqIu/F3iIAYGsj7bori+Iv4O5/h0NLW7CJemSEqEihNO7gJTH+fjCHe889jhMrJ3DNlmsKpybiN+FPIEoiCCHkhkcWypIaAdoUyxS4yNUIODg4OKwJ3FTglNqWKnDehSlwGQulQeAs+07Nq2myBKxdgStYKNdZgSsNMalKoaywUJpjHJGI9O8EZNnMI+DB2hU4InB9ReC4l1kvYChwLoXSwWGssfEJnC8JnKAQEwGrhXKYAmeGmJjxxpGI0hRKGDNwhoXSVODovGShJHJHNgqhwk044xmiUpyBU88Zd/h0z5xK0jQfM0EpUxkCN4qFEgDe96tYmZ1FU6lbNSHQFVllrGChFAkgErwSdyrfgzYi2rDCRBWvKgtlKKoVuLIZuJhxS4iJ25wcHBwcymCdgTN64NaSQkkKXBgLJIkA5yyjwIUWBe6f3fzP8KMHflT/vSrd0YTNQhknMWIRr08PnJ/tgQOMEJNcD9woBI7m380ZuDiJNbEzSawJmpW7EAslKXB5y6fPfGMGjm5yDj2tg4PDG4CNb6H0OQZRjFgIeJwDYKoHjmV74FguhVJdTGm+zbRQUtokvSZvoYySSF9Ma15Nq0mUYAm5ioyFku62mSqaeUGequdm4HSIydotlGTLNAnchVoo66JIgssslMdUuSp9l3mYRd4AjDJvZaEsIXClM3BkoWSAVAHV+zIvVTAdgXNwcHAoIJ2BE9pCOWn0wPWjBImlgNuGfmha7uXP59p91Dx57bZZKPdP7cc7L3un/nu+q7UMVHptWijpxue6plCWKHCccb0H5y2TzEhypn1Oh5jkZuCGETif+wiTMJMoOQxENDMhJgaBu3bLtTi3ek4t1rlUHBzGGW8KAictlMoSwj2pwHGetVAqImReRAF7iElepcunUJrH00U+TEKtrAGyzDtjoVQKnE6SNLrmPOah6Tcz83RDLZQVBG6+W67AVaZQGiCyVBNFG2pZiMmxWA5OF8rC6ZxGkTeAlKxObJHPq1uB+Y3KFtiSiESrjxHjykKpPpuzUDo4ODhUwizy7uQIXFOlUY6aRNmPjNoZReDm2n3smpLkxBZiUlzPhYeYkNNlPSyU10xfg92t3ZkZ8pbfypw/r2wRzN8RaJ+jvd+cgYtENJzAqbqBNc3A+TkCZ1goPebhxm036hm41agrfxtxe6SDw1hiwxM4qhFIEgHOIImPJxU4W4gJFVpXhZjQa+iCaSVwRo0AIDeQOIkLFsoyBc7jnl7TVH0KjLGSEJNiCiVjTN/ps6VQrocCZyNwpT1wSYwQwCmlwOX72ghmCiWQ3jXFW34a+PAfIPLld5nfqGxrN3+WM3CmhdKlUDo4ODhUgbaYyFDgTAslMDqBMwNPBlGCQZTg/GqIPVPyWm+rEchjVAWOVCYrgVsHBe6O3XfgGz/5Df0+5nvSTcx8mIlt3bTPUYiJeWN4rRZKn/nWgJQ86PcZW4jJ9ont2N3cjYXeApb6S/jBL30Q/2WyBeehdHAYT2x8AudxCCHvAHpM2iflDBzL1ghwuwLX9JtgYNkib2RtltpCadgjzBRKQJIRAaGPZRDSQhnnFDjDBknnp5CUmleTSp5ZSm4qcCP2wC30FjDhT2Q2IG1/HLEXjV5ns1AWeuCSGKd8XytoZSTRTKEEDAvl5A7gtp/VJNqMlgbs6qH5OWL6d3EhJg4ODg4jIavAqRoBRdwmAkXgRpyDMxW4QZxgviPJyZ5pReBGsGKuVYEzu1W1hXIdFDgb8gTO577V0miSLNrniKiZAWqxiNGP+qXnofeIkghxEo80/wYUFTiqEQCAXa1d2NHcAQD45ivfxPJgGXO+7/ZIB4cxxYYncPVAfsRuGBcslHEitEKlFbjcDFzdq+sLJSAVrXxSpU2BM2fgAHkH0BZiklfgaD1mB85UXYZ4mHZMM1GToC2UqLZQLvQWMuqbufa1zsDVjI20UORtEKdXgnSdmYoAA2YKJWBYKBXKvP7DFLi4kELpFDgHBweHKqgRODUDF6IRcPhqZu1iFTgKMNk9pW7WjaDAmaTtpblV/OH9L1pfV+M1+My3KnDrEWJiA1ko6fw0C5eH+RlMC6WpoFG/Wz/ul6pv9B6xiGVo2gjzb0DJDJyyUO5q7sKOCUngvnb0awCMCh4HB4exw4YncDQkvdyN5FD2vncDe25D4KnONjUHZ0b4AikpqHt1BDzQ5CEWcZoWRQQuKJ+BI1ITxmGWwIksgaO7cEQ8GGP6HKYCp19bUeTNGEtTKC0WyvnuPLY1tmUeW+sMHNkda7tu0Y8VawRSAnfcIHBlKp8OMVF3JrWFkt6zJG3LRlazFkrkeuBMBc7ZQxwcHBzyYIzB40wRuFjPvwHpDNyoSZQZBS5KdIXAZYrA2UJM8jCv+y/OreILjxwvXfdEMJGpESACV0WILgZmiAn9aZtJM106poXSJGBUIzCMwHnMsFCOqMDRurSFkqcWyl3NVIF7+MzDAIybnw4ODmOHDU/g3rZvCzzO8J2X5qWF8mc+D9z2cyqRMu2foTtneXWNFLhMD5xhoWx4jcKx9BxgKHBJVoFjSAkKA0M36kIIYU2h1AqcoeZVpVDme+CW+ksZImdT4Ghubs0KXK2lH9MWyiQ/AxfhFT9d57AagQlPKXA5pa5sWNtK4AoWStlFJ9flFDgHBweHYfC4HDXo9KMMgZtQN+SquuCiOMEXHj6OOBG6Bw6QnXBtZcnc0lSukjUqcHHCrNUDhFbQyihwtJesxwxc2fsBWQulTYEzH6Mblb24Vyj/TpJkKIHTKZQiGinABJD7fDNoagLnMz9D4HY2dwJI91JdwePg4DB22PAE7tbLp/HJDx8EkApCALQCR977vIWS/qx5tYyF0iRhHvO0fdI8BkhJBm0Yg3iQqRHgSMnaBFd34uJ+hoTRhdVqoaQLvnHhN3vg6H3O98/jA1/8AO49dq9+3UJvAVsnsgQOSPtnRoEmcMZMQUGB0y+OcSzwtd1yWI1A3ZebVt5CSWvL20WsM3BlFkrG5XS+64FzcHBwqITPmSzy7kc6wARILZS9Cgvld16ax69+6XEcemUR/TA7A0fHbWrIc4YjzMCZs89xIpW8MrT8VrZG4DW2UF6z5Rr8xDU/gbfverteq83WaE2hjHqZ11K65CgELhbxmhQ4QNooMzNwZKFs7cKW+pbMGmNyrzg4OIwdNjyBA4Cffec+/MoHr8MP3rRbP6ZLStVdvHyICRGwht9AwIOsAsdTBc4kcOaAMl2QacOg8BFzBo7Q5NKXnidwWoGr2RQ4npIRBTMAhdZyqn0KvbiHk+2T+jWLvcWCAkefnc7Rj/v4rYd+C+d7563fKZGwOk83mPIQkwjHAh/7AupzK68R8JmfJaqW98yHmAxV4GgTSiKD+DLA+fsdHBwcSiEtlMBKjsCNYqGk8u/lbphR4MLIJHDyWj5KCqVJcuKYVap2zaCZtVCuYw+cDXWvjk+++5PaglhWI2D+jqAtlHE/s6d5fG0WyrWEmAAyyESXhzMP2/3t2FzbjBu33giPe9je2C5//2C+U+AcHMYYbwoCBwC/9P5r8Ws/fIP+u68LROXFqaDAcbsCl0mhZJ4u+gagH6fn6HigqMAx44Zjg0srRTfqpjUCLK0R2FyXM3BEBgfxAJjeB0xfmfmMJvmjP8/1ZCkn3Y1cGawgElFhBo5eT8rVkYUj+Mtn/xLfOf2dwuvM9zIVuAKBU37/MOrilO/javWeVTUCHvdS0lsSYjJKkXehRoAslOaxbnNycHBwKIVnKHBZC+XwFEoid51BlFHqbArcKDNwprMkTqq745pB8zXrgRsFZrqjCfN3BJPAZSyUTDph+lFfu1HK3mOtM3BAmkQJSLK4PdiOB376AVw1dRUAYHdrN27ceiMm/AkkI1QTODg4vDEYSuAYY59ljJ1ljD1Z8vzPMsYeZ4w9wRh7kDH2FuO5l9Xjhxljj6znwi8WOsQkySpwthk4U4ETQqRVA9zTASbmsebx2kKZDDCIB/rv5hc/wYoWSmuIiXEu3P7PgV/KfqU055aqfFyXdndDecdtvlcs8TbXTO9PqZjn+3YFTvfA2SyUuR645cEyYsawqzadOTaPJJH21FIFTil3+Y1xpBk4kZQQuNEsow4ODg42MMZ+iDF2hDH2AmPs1yzP/yvG2NNqn7yXMbbPeC5W++NhxtiXX9+VD0fN41jpR0UCN0IK5ap6rt2PMgrcIEp0KiWdM0xGu5FG1/6hCpzftFooXy8CF/DASqrM3xHyRMr8eRQLZcADxEm8phk4ANn6IMtxv/4Dv47ffM9vgnOedqg6ODiMHUb5X/2fAPh9AH9W8vxRAO8TQiwyxn4YwGcAvNN4/m4hxLmLWuVrAOq4IQUub6E0UygLCpx67mM3f0zPpwF2CyVtGGEcoh22tWJn3teiGbhe1NMXbI5hISYcef5Ns2e0DsaYJnC0mS10VYl3yQwcfU7qpSslcNQD5xUtlDowRa0jVlaWuhrarpqB85mvzzNqCqXe1EsVOKQzcOZcglPgHBwcLgKMMQ/ApwD8IIATAB5mjH1ZCPG08bLvA7hdCLHKGPsFAL8L4KfUc10hxFtf10WvAbddOY2HXlpAP4qzM3DBcAtljxQ4C4HrhjECj6Huyz0srJhnM6GDOxJWPQOXCzFZzyLvUVAWYmKzUAIoKHBRIi2UW4Itpe9BaZVhEq55Bk6fwzKnd92W6/T5E8DtkQ4OY4qhCpwQ4u8BLFQ8/6AQYlH99bsALl+ntb2m8PM1AvkeuBIFzgwx+dCBD+Hde9+tz5m/CAPZIu/VcBWTARG41DJCBK4bdTXx4IzriysROCJLtBnlYfbA0TmIiNE8wKgKHNUaLPWXrO9lU+B0GbgmT2rOUKl/E+qOYxmBixJpoTRJb/55WqcJ+vcwkzYLISZwBM7BwWHd8Q4ALwghXhJCDAB8HsCHzRcIIe4TQpAcdMnskQAwc/1OnDzfxbn2AJN1o8NMEbhXl3pY6tp7PYnctfux1ULZ8D0EPqVBjxZVT4pRFAOJkB11NrSClnUG7rUKMcmjLMQESPcrSqEEiiXlo4aYXOgMnPlepednvqsRcHAYY4z+v/rR8M8BfM34uwDwd4wxAeAPhRCfKTuQMfZxAB8HgF27dmF2dvaiFtJutyvPceRVSQa+89D3cGITx9GVowCAleUVzM7O4sz8GQDAU489hW67i7OrZzE7O4uV9grmB/PWc5ukYXF+EbOzs3g1fBUA8NiTj+Hs0lnwoBhi4sfyn+GhQw9hmy/nxJ478hzmwjm51sNHsBgs4mhfrvGRw49g9cgq8qD3euaZZ9A81oQwNrdXTr+C2dlZPLTyEADg2UefxSnvVOb4KIxw4tQJzM7O4nD7sHzvV45gdjX7WdvtNp5+Rt5gPnPyjH78icNPAABefOlFzM7Pgsc9vBfA3NlTwCZgfk7y/Gefexazp4vf3/H544jDGIe+d0ie7+kn0DyWbjYvLb4EDo77778/c1w3kQTxuReew+xZed6Tg5P6+UGS4NSpkwA4tkUJvqP+7e5KBE4dO4YXL/K/tfXEsP9uxwmX0lqBS2u9bq2XDPYCMAvJTiDrQMkjv0c21HhBBOB3hBB/Yzvo9d4fCbVueoNr7vQJzM6e1X+fDIA/efBl/OmDL+MTdzawfypLBo68KEnTkReOomsIdY8/+TSOnk/AEeM7D3xbvub5FzAbHxu6XqFuuA6UBfPe+2ZR84pzWucWz6E9SD/jkytyAuTQQ4fwom8vAF8vtNtttFfb6Md9+3estuXjR9P/bPrd9LVn589itbeKqB9hejBd+u908vxJREmEufk59JLeyP9NLM2nN2W/++B3IbrCemw4CBEmAidPHMfzY/K/70vtWnMprfdSWitwaa33tVrruhE4xtjdkJvTe4yH3yOEOMkY2wngG4yxZ5WiV4Aid58BgNtvv13MzMxc1HpmZ2dRdY7+U68Chw/htre9HTfvncLC8wvAg8DWLVsxMzODB777AHAEuPOOO3H/9+6Hz33MzMzg3//1v8furbsx877iueMkBv5c/rx7p3zNiZUTwF8BV193NZLDCfbv2Q88JYu8CVP1KaAH3HDzDXKQ+K+Bm268CcdXjgOPAR+46wPY2tiKnfM7ga8ANxy8ATNXFt//hcUXgC8DNx+8GTNXzcD/Cx+DSG6irekWZmZm8NThp8AWGD5094cKd+0aX2xg1+5dmHn3DOaemwO+A9Sn64XvcXZ2FtfuvRZ4ELj6qqvxzce/CQB4x+3vAL4C7LtqH2beMgOEXeAfgE2bpMK4/8qrgecfwv6r92PmpuL673vwPkycnMBdP3AX8J+BA9cdwMx16esOPXIItWdrhfWshqvA54D9B/Zj5mb53DPzzwBfkc8Lz8OenbsBCKDTTI9/MMAVl+/FFRf539p6Yth/t+OES2mtwKW1XrfWjQfG2M8BuB3A+4yH96k98gCAbzHGnhBCFBjG670/mvjDZ+/Hc2fauPn6azBz1wH9+JcPtvHwywv4N196Av6uazDzrn2Z47619CRw9BVs3XUZVgcxJs6cQTeMceDa67Dw8iI2ry7g/TPvA77xNVy5bz9mZq4dut7GFxpod9tIhCSL73r3e7C5UVTVnn3sWdx7+F68573vgc99nHzmJPA9YOY9M5huTI/0uS8Us7Oz+MQPfALdqIvbdt5WeN77c9nzduuNt+KLD3wRALBpcpP+9/iH7/wDjhw7As45rthzBWbePWN9n2ceewbisEBrqoWmaI787/nwww/jgacfAAC876734ZEHH7Ee2/xSE6LNsXfPZdg7Jv/7vtSuNZfSei+ltQKX1npfq7WuSwolY+xWAP8vgA8LIebpcSHESfXnWQB/DWk3GQsM64Ej+0PeQhmLWCdU5lFV5B0mITphRxd+2mbgunE3kyR5xaYrsHNipz3ExAKagct32QHZGbjp+rTVckH9MwDQj6SFci0hJjqFEtkUykhFFtfVZy9NoUzkMHaVhbKqW6dsBi5T5G0ez52F0sHB4aJwEsAVxt8vV49lwBj7AIB/B+DHhRB9etzYI18CMAug+Bv/G4yZ62W5sxliAgAHdkziH99+BSYCD0fnOoXjTAtlP0x04uQgSi2UVOczSg8cYNj01WW7bA6O9lmag3u9Q0xu2HqDlbwBRscsrxVqi4B0Fn2UEBNAzs7nq3WqQN8NUJwnN+ExLx0/cHBwGDtcNIFjjF0J4K8A/BMhxHPG4y3G2Cb6GcAHAViTLN8IjBpiUvNq8L1ckXfJ15YJMVHnWWgrQhT30Qk7OsSEW2bg+lE/kyT5Y1f/GL75P3xTX2TLiA1BH6vWZ66HCNzSYCkTvGLCrBEYFmKSqNSwkUJMVKIlEbjSHjgRyxoBnnbnmSiLS7bNwJlzdpF8Us3AuRoBBweHdcPDAK5ljO1njNUAfARAJk2SMXYbgD+EJG9njce3MMbq6uftAN4NwAw/GQvMXC+7zaYmiiSBMYb921s4eq5deK6bCTGJiwQu8MAYQ+BVJ0qaSImOCj8pOY7mvKjv7LUu8l4LaL8KvDSpMj8/n4gEg3hQPQOnvot+3L+oGoEyeNxLE5wdHBzGDkP/V88Y+0sAMwC2M8ZOAPh1AAEACCE+DeATALYB+ANFGCIhxO0AdgH4a/WYD+BzQoivvwaf4YIwLMQkU+TN7CEmNnDGkYgEPvdxrt3Hj/0/30Xj2jQMhEJM+NQ+AMsAsimUZogJkCVhmRRKC8wKAvMcQBpisjJY0YpeHh73NDGjEJM8gXt+8Xl0k64mYRkFjvlgYMUQE0XgGrVqBS5OYnjMy5SfmyiLS7YpcJlKAZ1CGadF3oAjcA4ODhcFIUTEGPslAP8VgAfgs0KIpxhjnwTwiBDiywD+LwCTAL6ors3HhBA/DuBGAH/IGEsgGcnv5NIrxwJ3HtiG//Szb8PdN+y0Pn9gRwtPniyGXXWNGgGPMV3aTTUCFITicz5Skbd8Ld0kpI7R8hATIFXgOmFHRvuvIW7/tQJT+yIlLvfjfoZIUTjJIBlU9sDRMb2oV0nE8sikUFaEmGgFzu2RDg5jiaFXMyHETw95/mMAPmZ5/CUAbykeMR4IqMg7Ga7ABV6QqRGoulhycCRI4DEPcyt9hJGHBoDFngzwaAUt4N+eAHvui8Cj/wGAQeDiXqGMO7NmI9HShoKF0lAK6U5ke9DOlI9n1m4qcIp0dcIOwjhE4AUQQuDn7vk53N26Gwd3H5TfjxHLTEWrqQKniFU8AMBRG0GB87mfKnBKaTy+chxffemrGMQD63dP/2YZ0qY+BwNTBC5xCpyDg8O6QwhxD4B7co99wvj5AyXHPQjgltd2dRcPxhh++JbLSp8/sL2Frz35KgZRgppv3DQcyOt8px+h7nNtwRzEskaAFDnfY/pG6jCkShNX57LfDCSSQjcuT7RPYO/k3swN0TcKoyhw/bgPATE0hRKQvzeshZhSfYFZjG6DxzzEgEuhdHAYU6zLDNylCPLeRyUKXKYHjvkZBY6hfBMwawhWehHkV8yw2JcEbjKYBOqbwA0rh6nAVRG4YQpcvsibNqum39Qb2fJgGZtqm6zHU3wxrYWwNJB3V8MkxGq0itVkVa/TVOA85mkFUi1AHqfO5deacs6uYgaOzmF+5/cduw+fOvwpPHjqQavXnzGWU/5SC2XAArkJ6Rk4R+AcHBwc1gv7d7QQJwLHFrLJyN1cD1wj4Kj5PGOhBOTN1MhS5P3osUX8zfez44Sa6AhF4EoUOLIJdiKpwJ1YOYHLN41HewPty6YiaO5rHvcg1IjFKASuH63NQknqZJX6Bqgbuq5GwMFhbPGmJXCkwIUlM3A7mzuxtbEVNV7LFHknIqm88GkLJvfR7ocAGDzmY6Enq/TozqBJ0GqsBp/5UoEjFc3yTzNqDxwRTHqPvZv2ohf3ECexLBMP7AqcSeDIQgkA53vSRkkqXoRIfx/mBkN39FIlTM3AqXP5flMOaA+ZgQPk3Un6nETkznXPlW5UGeXP+C585udm4JyF0sHBwWG9sH+73E+OnssGmeR74OqBh7rHMYgT9CPTQsn0jVQTf/zto/g//vapzGN5Ba5sBs60UAohEz3a0gAAIABJREFUcHzlOC6fHA8CZ/6OoBU4nlXgCKPMwHXj7gUVeQ87xue+UuDcHungMI540xI4j1enUP7kdT+Jr/7EV9WQ9egzcHR3LVXgAA+BtlCmRd6piuczHw2/IRU4dSfSZhUcaqEUdgslbVzdqFs5A2eSL1OBI/WQHotEZFfguF2Bi9R35wUTclOomIEz70iayZ/6PUrIs2n/NI8JWJBaKEXsCJyDg4PDOmL/NkmW8kEmqzkFru6nClx3EKMRkJWQWy2Ui50BFlfDTAm43hdpBq4sxMSwUC4PltEO22OjwNEeFvByCyVhFAWuLNyrDKROjqzAuRRKB4exxJuWwJXVCOhYX+7rWTGf+ZkZuGEhJoDcaIjAceZnZ+CQVeA8eKh79YwCZ7NpMsYQ8KDcQqkutEQi6c+9k3sByECSftwvnYHLWCjjnl4jBbBQMmUkImuIiVbgkCNwNLTtBfCYl0mINBGJtCbA56mFUtshjQ3PtnZzBs60UEbq27HPwLnNycHBweFCMdUMsK1VKyhwFGLSDWN0BzHqvpdaKCPTQmlPoVzoyH3u1aX0ZmI+hXJYjcBquCr7VAFcsekK62tfb9DeHvAgdf6YChxfG4HL/zwMmsANCT7xmCd3cneT08FhLPHGRzK9QSirEbB1vJkKnBCimsAhnYFr9xWBQ4ClgVLgqEbAOIepwOXn2PKoebWhFkpzDg+AvvN4dlUmWJfOwHFPq2P9uI/tje042z2rkyi1hdJQ4DLefebJEJfMBV+FiCBN3TKVMhOUQgkgY1ul2biPHvyorkPII6/AmRZKGYVsm4FzCVsODg4OF4v921t4KdcF1x3E8DhDnAgsrg7SGbg4OwPnl8zAEYE7bRI4un4rBW4wpEZgNVrFiZUTADA2CpwOMTFuSJohJObPlSmUhoK2lhATIrfDjvG5j4jcKw4ODmOHNy+B8+whJjZbQV6Bq7IeaAsl99AmBQ6+JhTaQsmyFsoJfwL9uF+oEcijxmuFeH2CJnBGD5zHPOxu7gaQEriqGTjTQrm7tTtD4EwLZZxIJdIkcJxxMMaQiATPLz6PJ889iZ9gDKH6rD73KxW4WMRa0Qt4kCFwPvfxL972L6zH0XtneuCUQugzYxNKIsDsAXIWSgcHB4eLxoEdLdx3ZE7/PUkEumGMnZvqOLvSRyIgFTiPox/KGoGGMQOXt1AKIUkfAJxe6mKrelzXCOgZOLuDYsKfAGcci/1FvaeOywwcM/ZD6wyc8XPDa5Se54IVuGA0BU66aVyIiYPDuOJNbKFUG0CuRsAa37+GGThT/SIFjiElDTrExPjqPSYtlN2oW5lCSWsZlkJp9sBN16fRUv1rZ1bPAEDlDJxpoZyqT6Hu1bWF0lTgiMiaG4fHPE0C/+r5v8Jvf++3ATDExvOmspZHLNIZuIwCJ4Z7/AszcIkxAye/HXsPXMk8noODg4PDaLhiSxNzK330I0oxln/u2JQqSI2AI/C43hfNGbh8D9xKP9LkzFTg8imUZTNwjDHcsv0WfPfUd3F85Ti2NbZl+s/eSGRqBFj1DJw5opBHZu9dSw+cUieHKXAe99L5cQcHh7HDm5bAldUIWBU4RSaEECMTOJ/7WO5J0seV0Fn36lai6MFLQ0zUxTJJ7FUFNV7LJESaKPTAMY6tE1v1BZsIXNUMHL1/P+qj4TcwXZ/W83v5EBMibOZnJwVuEA8k6WUMUU6Bq7JQmkXqpKKNMqSdn4HTFkoYSVquB87BwcFh3dFSHW9UHUABJtsnUwJHM3C0Lzb8dAaOZtEJi530JuWrNgulmiMrm4EDgPdf+X48s/AMDp05NDb2SSC9eZuxUJaoaZUKHLswBY7650aZgXMplA4O44s3L4ErqRGoKtAm4jKyAtcjpUleKMl7DmRtFIwxNPwG+nFfE49/+tmH8czp5cL56159uIWSeuDAsLVuELiOJHCjzMD14h7qXh3T9eliiAkiHeaSjz+mFMowCSXpZVwrcGQZKU2hNGoE8iEmoyRm2UJMUgtlWYiJ25wcHBwcLgbNmrw+E3EjImcqcJRCudyV1/WJWjoDN4gSRHGCX/789/HcmRU9/wZICyUhnYGjIu/y6/fdV9wNAHhl+ZWxInDm3h942fqi/M+jKnBrmYED5O8iw/ZUR+AcHMYbb14CN6RGIPta+VwYh8NTKC0hJkzI483ZM3OQGQDqXKVQqotlnAAnF9ONi1AVYqItlOru5O7Wbly75VptHdEhJoGdwGUslFFK4PIzcKEIZeAI9zIbB6VQCghddRAhq8D53C/tgYuSyG6hHEGByxO4TI0APZi4GgEHBweH9UZTKXCrg0j9abNQeqj7HMu9vIVSKnCvLvfwXw6fwjeePqMJ3NZWLRtiwrIKXJmFEgD2T+3HVZuvAjA+CZRALsSEDZmB88sVOPN15iz6KGj6zZFcLa5GwMFhfPHmJXA6xGR0BY4UoVFDTFa0AicvlBkFzogSBqStIUrSdEchuPXuYtUMXF6B+/QHPo1fuf1XChbKUgXOtFDGfUz4E5huTFtTKG0zcETg4iRGGCv1jDOERgrlsBATU4Ezg2OGbVDVKZTC9cA5ODg4vEZoBjkFTlUI7JjMKXBeqsCRhdLncgaO+t5OLHY1gTu4Z7PdQkkzcBUWSgC4+0qpwo1LgAlgT6G8mB64/M+joOk3hytwnBQ4R+AcHMYRb1oCF1CNgFLgdB9LyQwcAE2cRpqBY35RgauVK3ABDxDGoe5yA+zdODVeKy3ypmPNLjqPe1qBm1udAwMrHebOh5jkFbh8jYBpoaT5Nw6pwBHZDcFljL+xnrXWCIRJuOYZOLMHTm9CBQul5zYnBwcHh4tE3kJJSlzGQqlqBGjPbdTMHjiB7kBev08srmoCd9OezZjvDDBQs+q031AKZZWFEgB+ZP+PYMKfwM3bb774D7lOoJu3ZgplPgyMMCqBW0uICSDD1EZJoXQWSgeH8cWbtkaAcwbOiiEmVRZKCg+puvDZirwhfICVKHBeSuAGycCYD2PWAe2aV0N70La+NxEYs6KAzk2hIJtqm4Z2zEVJhCiJUPfr8LiH5cEyEpFkirwpMZI2GzM4JRFJaqHkXM6gQW1YrHoGztzQ+pH8vi9kBs60UJYXebseOAcHB4eLBc2zdXMzcGaISUOFmJh/B1QKZZJo1e7kYhcLqwPUfI6rd8ibnuf72X2aeuDKagQI12+9Hg/9zEOFPfGNBGccDCzjYDFHEUYu8i7pjhsFm2ub9Q3ZqvM7Bc7BYXzxpiVwgByephoB08pwfGEVV2xNVSpSyUiBI/JlAz0nZ+Co/LtI4Ijw1Hi294ySJCGY9e5ilQKX74HTa2IME8EEVgYrpfNvgLRWLg+WNVGd8CbAfUmMVgYrxR44zgsWEFLxolipZ4xpBY6KvMsslCZR85mPTtLRj6+1RsC0UEYAEA8sRd7OQung4OBwsWjWaAYum0K5tVUDZ5A9cKpGgEAzcL7HpQJHFsrzXcy3B9jarGHP1AQAYKGnFDi1PwTcQx/VKZSEcSJvAHR/KmPM2gNnkrGRQ0zWaKH81Tt+tTQMzVynqxFwcBhfvGktlAAQcKYVOM44aryGxU6Cu373Pjx2/Lx+XUGBs6hBQggcPdcxLsQcvVDNsyXyMTPEhDYVcwYujENDReJWf3/gBaU1AlUl4DQHVzb/BgBTtSksD5Y1Uav7df36TtgpWCjNGgFTgRPCCDFhqQJHFsqyEJPCDJxIZ+DWGmJiplAKBiTnj6keOOO7cQTOwcHB4aKRWijldZcUuGbNQ0uRu0aQU+ACImNyXICOGUQJnjuzgq2tGi6bliEeROBov6z5vrJeXnrXb5O42UY39B7I/Mp972II3IHpA7h+6/WVr/G5j4Tmxx0cHMYOb2oC5+cKRP/j3f8RVwbvBwAcX1zVj9NFloiTjSDNPvf/s/fmUXKc53nv76ut99kw2AGCBAnukMRFJLVQgnbKsqKr3Htt6SQ3iSNHcWLn5tjZlHiNnThOrrfjREexHDuOHFmK5TiyotCWomUoivsurgCx78Ds03vXdv/46quq7q6e6QEG5ID4fufwYNBdVV3TGPY3z/c87/tO897fmEJdzvOSXb8w7G9ikh7mCdJZc4O0gBOZ8ZCcmRvYxEQJr6zOVarubdAMOICR3Ahe4MU1b3kzHx/f68B5odcVAUkLuSAM4iYmrhB4CIzoOVOYgyOUA2rgLmQOXDpCCeDPHwOvpR04jUajWWMG1cAVHTOeEaeamCgKthojIDdSVRMTgFfOSAG3ZUQJOPk5HTtwpoUTjR+43DAw4nV/uRq4nDU4Ppk+rvf8tcIUZlJ+oNFo1h1XtoAzBG5qgOi9O+5lbkkKnfQg0V4HLkvAnV9qyT4Z0XrSSWmUMJDHd40RoLuJiZp7pkYBDIxQmk4sjnpR95c1/HMYB27EGQGSbpU5Mxffc82tdc+Bi4Zur1wDJ/AEWCS1gYOamHih17WgdQm4FTL+aoC4Qr2GOs8LPWjOaQGn0Wg0a0xvhLIZpU+KjkUppwSJHCOgyMcCrrsGDmRzkvGSQylnMZK3mG9118A5poltGZelA6cilJCsT1kO3HL1b3BxDtwwGMKQBR16jdRo1iVXtoAzRZcDB3BsVtZdzTcSkTSMA9eIFVvUHSs63RAQBBljBDIilH7ox7n0kOzdRdXsJIthHLjlauBGc6OA7FaprqMEXDpCCfK9yHLglJCKh3BHc+BM5TgKe/AYgYt04NLCULl8aoGMn9ECTqPRaNaUvG0gBDTjCGUy662cs+KvuyOUUR24qoHrdG/sbSjJ+q/xkkPd7e5C6VgmtmnE3SkvJ9IRyuVq4FYl4FbZxGQYLMPSXSg1mnXMlS3gjKSlseLIjIxOzmU4cCq6mFUDlwg4Kcyi9YvxopPUwK0wRiD9Gss5cAMjlP4yAm4VDpwa+D0oQglSLJpGfw2cKUwCgvgeXUM2MbFS3TmHqoETSQ1c2pkbRFYXSktYsdPpq0J2PQdOo9Fo1hTZKMvsamJSsE2EEKkIpdkVoYwdOFUDFzlwSvCNF6WAK9gm7Wh5TRw4+7KNUJrC7EreQHYXyhUFnLj0DpzuQqnRrF+uaAFnm0kTE5CNSBIHLhFJvQ5cVlerePcwulws4EoOfiTgsmrgLLO7mFmJMBCZTUyW60LZ9JoIRNzZMo0ScMvWwPVGKFNNTGqdWpeAa3pN2cTEMOOWyPKusxw4sKPnV6qBU4vSRTtwkRhU77NnF9nv2LTS/3TC0IuTRqPRrAFFx6QRibCG68d1cV01cJEDJwRxnFLWossaOEPANZNynZwoO/H5bTXuJ3anZEOUyzFCKYToE3BpBy6ugVuFA7faOXDDIAd56yYmGs165YoWcCp7r5iuteMdxKwI5XIOXL2jyn3lWxpNEGCi6BBkCLh4DtwgB27QIG/TkeMGMj5U216bvJXPFJgqQqlEWhZ9EUozH99z1a3S9JMIZcNrxO+DaZgYRncNXDyEWxh4JBFKy7CWrYHr6kKZEnDDzIELU2IsrtFDnlcdv4pPbNvCnzdPJifpOXAajUazJhQck0Y76UKpZsMlEcqkC2XOMpIyAlPgBrILZcE22TkhRwdMRA5c0TGJLpty4C7fLpQGRn+EUlycgFO/P6wlpjC1A6fRrGOubAFndHd6PDYr45OOZXQ1MRmmBi5x4OSi1FICruTg+/1jBPoilGaPAxcaAyOUQGaMsuW3MhuYABSsQt899NIXobTy5M28nMnm1vsilEq0pQd6m8KUYwT8niYmGc5aGiVIkzk/9qocuN45cHGEMnqfF0a34QnBXJh634QBA8SkRqPRaIan5FhdXSgTB041MUnmwKn4JMhB3mEoN0ELjsmOcbnZOFFKCTi/ew5czrawzcvTgetqYpLVhVJFKFfqQjlgdtxaEQs43YVSo1mXXNECzu4ZI3B0RsYn924fzayBG66JiRRwyoEbLzkEfoYDF+0+KkGW5cB1vP4Pzvi4jBhl02tm1r9BqonJMjVwJbuEKUzON6WAy5k5hBCUnXJcA6eaoLT8VrcDJ1Q0RnQ1Y/EQ+ELEi40pzEwBFzcdyehCeSFz4PwgilBGP+LVykYAGmnBpmvgNBqNZk0oOGZcx9Z0AwpRZ8qN5TyjBRvDELEDV0gJOMuUa+FSyyNvm+wYjxy4WMBZfTVwOVMKuPZlWAOXjlBmzoGLvl5uiDdc+ho4U5hyhqre5NRo1iVr/3/9ZYRliq4mJsdmG1iGYO/2UV45s5QctwoBF8YOXIhpCEbyFm5jJ/duvYetpa3x8V0OnN/v8g2KUKpYRZYD1/bbgwXcEDVwQghGnBFmm7NA0gylbJflGAGvxUhuRMYpoxo4kO9P7xy4uImJEHh0Z/2zIpSqYcmgLpQrRUTUGAaFH3aPOaiVJmBWCziNRqO5FBSdpIlJs+NRiLpMfurea/jom+Xap+reuhy4KMmx1HQp2CY/tHcrM9U2120qx9dtRQ7cvdvv5bcbj1AeGaNpuZelA7d7dHe82ZhOpijU14PSNAohRNzs61LVwAH4YXBl7/RrNOuUK/r/S9X9SnFkts6O8QKTZYd6x6ftRcOge8RVVj1W041q4CI92OyElHMWjmXQaW7h9z74e13iqncOnNpta3uRgAuzO2yp47JmwbW8wRHKYWrgQA7zVgJLXavslKl35BgBdX5awJnC7JoD5wUeYRS7cIV04CwlzER2hFI5cEaqVs4LPcIwxA3cFWvgJguTnKufS64XRShVDdxSTjqH857LX/tPj1JtuVrAaTQazRpRsK2uLpRqNlw5Z7F7oxRjqgtleh5c2oErOCaT5Rw/88EbMA35uIxQymN3juzEXvw4eduOxw9cbvzC236BX3r7LwHLNzFZyYFLn3epulAC+LoGTqNZl1zhAs7o6kJ5bLbOrg0lxqPoxkLUyKR3jECWA1ePVphAOXAdqORlzCMI6Zs31zcHLqsLZcbu4nIRypbXGujAjeXGABjPj2c+r0gLPJXBL9tl5tvzeKEXPx+EQSK2UrVmhjBS34MUcC5gpTL/WV0o48HbPW2VvdAbqgZuZ2UnZxtnY2EbRyij+6rmpICdcz0eOjjL0ZmGFnAajUazRhQdMzUHLmlikiaOUDrpCGX0Gd1yu5y55LoWHR+CKC3T9nxytrGqJiYPH5zhn3zludV9Q68By40RWMmB6zp/DQXcz3/1BX71/pfje9IRSo1mfXJlC7jeCOVMg10binH3K1UHt5omJipC2YgcOFW03btTOGgOnHqNcJk5cLD6Jibvv+r9fP4Dn2d7eXvm84qRnBRo6Vk1ZafMTHOm63lIFpqueXAYiYsIeCIa5J3qtpU1B065cum6OvX4MDVwOyo7CMKAM/UzQBKhVE7nUlSOPW9LIdvxAzkTTgs4jUajuWiKjkk97cBliDEl4PJW8pwTOXDVltdVG5e+LhDX17XdIG6IMuwcuAdeneYrT53s20h9vYlr4DIakgzjwGUJwIvlyWPzPHtiIVmD9Rqp0axLrmgBZ6fGCDQ7PtW2x+aRPGORgFOdKIca5B1HKJWACyIHLhrs3bNwxALOzBZwMCBCGc14G+TADepcZZs2b9v2tszn0iiHLd3CuGJX4tECaYcuXa82yIHzAF8kDpxp9M+Bm2/NJwLOSLpQghRwwzhwO8o7ADhRPQFEM+VS91XtVAFoRl0oO16g58BpNBrNGlF0rHgjM92FMo0Td6FMRSiNxIHLFHDRGAI1qqftBfFIgqxNziwaUUKmtc6anmSNEVBr1jAOXHoNXitqbZeOlyRsskYWaTSa158rWsBZRjLIWw3u3lBy4u5XahbchThw6Ro4oC/q0TcHLhJyiXu1+iYmLb9FwSws/02vgBJo6ShmyS7FglHNioPkfTCF2dXEJBGhyRw4y0wilGkHbq41x/u+8j6+ffzb8vmeou5YwK2ww7izshOAk1U5580PfXlfUQ1crVMDoB3NsnP9QM+B02g0mjVCNjGRdcstNyCfIeDszAilavwVZMYulZPX7PgEQUjHlw6cs4oxAkr8tdz1FQdcbozAqhy4NRRw9bZPxwuSMgY9RkCjWZdc0QIuPUdGxSXHSw7jRSk25iJRF89oi+agLdeFUs0Fb7QDynk7FaEc4MANiFAyIEKphFXTa/Y9t1wN3LAogZbe/UuPHkg7cOnFQ82EE0J0CThPKAdOLkaWsAjCIN7VO1M/gxu4HJg/AKSKsqPFww/9oRy4jcWNOIaTOHAqQtnjwHUC+b4lDpwWcBqNRnOxFByTIJTNSDp+QCXX/5kdO3CpCKVaI4HMGjg1R67e9uM1MWeZcv3OGLWTRezArVMBl3bg1No3zFreO09uLai1PNqeH6/p2oHTaNYnV7SAS9fAKQduouTEEcqFSNQ5hsNkYZKDCweBfgEXBGEi4FSEst1TA+cNVwOXngOXtTipgdyZAs5vdUUfL4Q4QpmKYqZHD6Rr4LIcOFOYXTVwLnQ5cElrYvl+LbQWADhbPxufD90O3LBz4HZUdnCyFjlwKkJJt4BzAynCO74WcBqNRrNWqMikmqe6aaRfgKjuk7n0HLio2ySQGaFU8+SarkfbVQLOwLayNzmzSBy49fV5n9WFMmflcAxnxYZjkFov16gGru1JkdzxEwfO1w6cRrMuGUrACSH+QAhxXgjxwoDnhRDid4QQB4UQPxBC3J567m8KIV6N/vuba3Xja4GZilDGDlzRwbEMKjkrduCEELx545s5unRUntdTA9fykl095cDV2yHlnDmwBi7uQmkO6EIZZsdDlIBruI2+51peK37+QokjlCkHrmyX+56HlIDrGeSdrs+TTUzAjOIg6r1TNW/z7XmAuPlIb1tk5XoOs8O4o7KjP0IZvd5SR871c0N5PVcLOI1Gs0YIIe4TQuyP1sDPZDz/M0KIl6L18dtCiF2p59btGrkalIA7Egm4zRkCLm5ikqqBs1MjBQpO/68kJSdx4NRon5xt4Jgm7pA1barEYb05cFmDvAtWga989Ct87NqPrXj+WkcoVTftthvoMQIazTpnWAfuD4H7lnn+w8Ce6L9PA58DEEJMAL8I3A3cBfyiEGLlbaXXCNvoj1Cq+rexkh03MQF488Y3x18r8fWTf/w0v3r/y7H7BokD13ahlLPiyMiKNXAZDlw7Y3FS89x6HbggDJYd5D0scYTSyhZw6Rq4dL1a2oFL4wnwhNE1RgCSuW+9DlxvDZwStCvNgQPZyORE9QRhGMYCrteBC3ABX763WsBpNJqLRAhhAp9FroM3A58UQtzcc9gzwJ1hGL4J+FPg30Xnrus1cjUop0wJuC3LCLhCxiDv3seT68rHGh0/XhNzltnnwLl+wIm5/o1NIO6O2fYGC7i/+0dP8q++/tLA5y8F4zn5T63G/Ch2j+2+4DlwTxyd4//83MMsNvtnxa5EvS03Vjt+0DXIW6PRrD+GEnBhGH4PmFvmkI8BXwgljwJjQoitwIeA/x2G4VwYhvPA/2Z5IfiaYpkCX0Uo6x0MAaMFKTQmik7cxAS6BZwSEy+cWuS5Ewvx7h6AmkoQYvSMEVihBs7sceAGNDEZFKFUdWdrFqE0B0QoMxy49+x8D+/a8a6uxxQuAk8YfQtNHKFsSwHX8OTC2xuhXI0Dt7Oyk4bXYL493z8HLhJw8ibb2oHTaDRrxV3AwTAMD4dh2AG+jFwTY8Iw/G4YhkpdPArsiL5e12vkaij1OXD9a1HShbK/iUnv48l15Wd/o+OlBFx/E5Pf//4R3v+bD7DY6BcujSEilC+dWWL/uerA5y8Fezfu5esf/zp7xvdc0Pm9G54Ajx6a5alj83zh4aOrvl61FXX6dIN4LfbRa6RGsx5Zqxq47cCJ1N9PRo8Nenxd0NXEpNFhrOhgRnn8saIT18UB3Lzh5vjDMhYFLY/5Rid24CxDxBFKQpNSzorjIQMdOLPfgZOdLFcn4JTQuVgHTtW4DWpikv5aibIf3/vj/M1bZPJHfV8K2cRE9BVrqwilEnC911THq+9z2AglyE6UvV0o07FOYXR0ExONRrNWrHad+xTwFxd47rpFOWVHZ+vkLCPeDE1TdGRn5g3lxF2yUwIuswtllwMXRSijOXBBSDzb7VsvnaPtBTx7cqHvGvUhmphUWx61dv+M0kvNrpFdKx80gKwmJueq8neB33/oyKq/H1Ur2PHTAk5HKDWa9cjatS66SIQQn0bGL9m8eTNTU1MXdb1arbbiNc6cbtN2Paampth/tEWOID6nU2txej7ousY2exvHO8d57tnnqOaqLDY6eK7Lg48+DkDJjpqV5IDQ4NihAyw4cnF6/MlnqB5JFqdZbxaAY68cY1ewi8ceeQyARqcBkQhqtt3M78HCYv/h/UzNJ8/Ne7KW7PjB40ydW/77Xo4FTy5+S3NL8Wuf7pyOn3/m8WcwMfHxOXfmXN/9zUzPdP296Xm4Jsyen2VqaopD1UMAPPjQg4xZYxyYPtB1/IvPv0hwMODlxssAPPnskwAcOXhkxe/rTEfW0X3z8W8yV53DEhatXKvvOGF0eOXAQc60zzHebPLoRf6srSXD/NyuFy6ne4XL6371vb4xEUL8deBO4N2rPO81Xx9Xy+EFKY5ePbvIiC144IEHMo/7l/fkmKwfZmrqiDxvMRFVRw8eYKp5pOv4ZtTM6/mXD9A6KzdE97/0AierUrh9e+oB/ACePi4Nzq9+7xnC093xw2pTJlSeeu55zHMv991TGIYsNV2m5xbX5Xs78LWqcjzOQ997KN5YfvFwi7wJCw2XX/7j7/BD1ywfxUzf73PTUsD5QciLL8g4ab3ZWDf/f19unzWX0/1eTvcKl9f9Xqp7XSsBdwrYmfr7juixU8C+nsensi4QhuHngc8D3HnnneG+ffuyDhuaqakpVrrGo81X+O6JI+zbt4/fPfAoO/IB+/a9HYDvVV/i+dkTXdd49PFH+eLLX+SO2+/gxvG9+N/4S+oe3HjLm+HRx9idmjz4AAAgAElEQVQyVuZMbGoa3HXbXrkL+cQj3LL3TdyybYRa22PXhhIn5ho0vz/HjXd/FPPsK9z9zrvhi+DhQVRHF2Bkfg+lL5eY3DrJvnuS544sHoFT8KZb3sS+3ct/38vR9Jr8/Bd/np1bd7LvnfI6Z2pn+Df//d8A8L53vY9f+dKv4Ic+O7bv6LoHgL/43l9Aev21bXzDZ/vW7ex7xz7mX52Hh+Gue+5iW3kbf/SNP4JU2cLtb7mdu7fejXPKgW/Bnpv2wDTcdMNN7Lt++e+r5bX41S/+KqM7RymfKFN2ylSowKJ83hCGbIlstNm562q2VrdB/ZUVf05eS4b5uV0vXE73CpfX/ep7vawYtP51IYR4P/CzwLvDMGynzt3Xc+5U77mvx/q4Wradq8Kj36Ppwd4d4+zb97ahztt0egkeeRCA2990K/v2bu163g9C+Nb9bN25i1uu2QCPPspb77iN4uklOPAS97z9nTxyaIYgfBrHMlgwx9i37674/CAIaf/l/QBcu+dG9t2xg17qbY/gG98gtPIX/b68lv8/fOEbX+Dw2cO8Z9974tr833rh+9x1rUMYhnzr5BI/98l3MJLvd0Oz7rf63Gl46hkAbr5lL3wP7Fxu3fz/fbl91lxO93s53StcXvd7qe51rSKUXwP+RtSN8h5gMQzDM8A3gA8KIcajwuwPRo+tC2xT4AZJExPVwARgy2iOWttjIRWjvG3TbYCMMS61ZM7eD0LOR5GFiZKDH0RxkNCg5HTXwP3bv3yFv/MF6SidmGvgtbZx4KysF1BRCDlzRWCbskA7zOgAVbAKlyxCmTfz2Ibd3cQkVQOXN/NxlDSrsUhvDZxsYiL6umXFTUzaC111db01cKuJUOatPDkzR7VTTZqYpO5HFYwLo0PHD3WEUqPRrAVPAHuEENcIIRzgE8g1MUYIcRvwu8BfCcPwfOqpdb1GroZ0A5JNGfVvg0hHKLOGf5uGwDH6I5ROdJ7rBzxwYIZyzuIje7fy7IkFwjDkz589JTdKU7FJ1TH6D75/hGOz9fhxVfulIoSvFfvPVvnE5x+Jf4dYLZawsAwrFm8A55babK7k+Gf33ch8o8Nnv3tw6OulI5dB9LuMjlBqNOuTYccIfAl4BLhBCHFSCPEpIcRPCCF+IjrkfuAwcBD4PeDvA4RhOAf8CnKBewL45eixdYFpCMJQirC5RreAu2mrFBUvnVmKH/vArg/wufd/juvHr48/8AFOzUuRIQWcelTIGriUgJupdeJj1YiC43NJ846kfkxQjoagun62gFNNPxSqiUnBvLgxAkIIPrX3U7x/1/vjx0p2CYHAMRxMw0wEnLGygHMR+NDXpdINpQBeaC10FXD3Cj3V1GXYNsklu0Tdrfd1oQSYLExGN9nWNXAajWZNCMPQA34KKbxeBv4kDMMXhRC/LIT4K9Fh/x9QBr4ihHhWCPG16Nx1vUauhmJKfGV1oByElRrkndWFEiBn9jYxMeO1teMFfO/ANG+/dgNvvXqC+YbL/3jmFP/wy8/yxceOd4mylhtQb3v88tdf4te/mcT31YZs/TWsgXP9gJ/5k2d59PAcTxyZv6BrmIYZb/6C/F1mutZm00iOW7eP8ldv28F//v7Rgd05e6l3CTg9yFujWc8M9VtxGIafXOH5EPjJAc/9AfAHq7+1S09aXM3XO4wXMwTc6SXefq38xd8QBu/c/k4AaikBdzIl4JgVGJgoEaYGhXf8kFrbo97xabl+PLbgxFwDJqRwsg1bNtsIDUo5i/mGi+sHcetlRdEq9jlw6u8X68AB/ORbuv8pDWFQskuxOBvWgStYBTzPxRP9wswPfMIwZL49z3vH3stT557quqYSh2oo+LACrmgVqbk1vMDDNEzMILnHycIk++f3I4yO7kKp0WjWjDAM70duZKYf+4XU1+/vOyl5bt2ukauhlEs+o7NmwA1ipUHeADlL0GinxgjYRrwuHjxf49RCk5/Ydy1v2Snb8f/8V+XI2oVGh0Y75cC5fizovvniWRabLqMFm2ok4Fw/pOP1r7mXgs9NHeLF03KD+PB07YKuYRlW1xDv2XobPwjj9/+ffOgGvvbcKb742HE+8+EbV7xeemM6COV78Nq3ddFoNMNw6T+l1jFqsTi90MQLwi4HbrKcY/NIrsuBS9PlwC1I8TRecgCBiERIOZ+aA+cF8e7WbL3DbK3bgYOkI2W3A5fdiXJQhDJnXdwYgUGU7FIsDnu7cabpFXAucgGIu1DGs2V8Gl4DN3DZXt5OyS7J86OZQHGE0m92veYw99lwGwRh0OfAbShsAEBoB06j0WjWlJxloJJ8m0eHF3B22oHLiFCCcuB82m53F0qQAg7gxi0Vrt9cpmCb8dy3hYbbNae17fqxoGt7Af/rB7Lx1VJqPX8tXDg/CPnsdw/yQ3u3sHU0z+GZ+sonZWAbdlcS5vyS3PDcVJHv/5bRPBMlp6sUZDnS37sfvW2BjlBqNOuSK1rA3bhFtsT//kHZOTHtwAHcvHWEl04PEnDJrBkl4CaKNoQCEe1clXMWtpXk9NVCMltrxw7cqYVmPIsujkKERizgOhnDvAtWgYbbHYk4Pi87dVxshHIQFacSjzAY1oErWkW8sZ3RIG+r61w/8OMRAqO5UTYWNnY9r/5czRw4iCKUXj2zBk4JOGIHztQCTqPRaNYAIQTFaFN0c+XCauAGRygF9Y4X17Pl7SRCeWK+Eb1mHss0uH3XGNtG87x5xygLzU48Aw6g5QVdkco/fUpOcFhKDb1+LUYJ1NoyDnr7VePs3li6YAfOFGbX2qhq6dIz+IqOFQvaYe5LEUTN1Dw9B06jWZdc0QLu1h2jAEztnwZgotwj4LaNcPB8jbbnc3y20TVDpteBswzBSMEGBCEGpiG6dgldP4g/HGdrnVjA+UHIXEsKOMeQrx9G9XMg57H0UrS7I5SNjsevfeMHwNpEKLMo2+V4NpzFMjVwqR+pol3EHdmGF4mp9Dlu4LLQkgJuPD/OxqIUcOo4JWZVbd/QEUq7SN2tJxFKknucyGU5cHp3UaPRaNaCQjR0e8sqHLh0DVzWIG+QDlyz43N6oYVtCiaKDk60OapKGFTjlN/8kbfwlb/3djZW8iw2vS7x0nL9eCP13j2TPH18geOzja71fC0amRyZqXNmsTnweeV0lXMWuyfLHJ6uZzYsWwnLsLpnwEUOXDrCWrBNmkN+T7UuBy7qhq3XSI1mXXJFC7iRvM3ujSUePiQduIkeB+6mrSN4Qcj/+sEZ3vsbU3zp8ePxc0spB67jBRQck7xtEiIgFJQcU9a1qUJrP4w/tGciB05l/6ebkQOXjlDml3fg0gKu2vLwQikIc+aliVDeMnkLN07IDL0t5H1mRSjT3bAKVqFPgMU1cKHPfFsWbo/lxuIGI72DvFdy4Jodn1fOJi5pX4QyHek0y4SBFXWh1BFKjUajWUtUI5PV1MCtNMgbIG8J6h2fk/MNto8VMAyBY8pjT803GS3YsfjbPJJn+1iBsaLNYqNDo51uYuLH6/C9e+Sac2S23i3g2sO5VVkcPF/jVx5p8p5fn+If/PEzA4+LBVzeYvfGEtW2x3StPfD4QXzsuo/xqVs/Ff/93JJcLzemHNBSzuyKkS5Hl4DTXSg1mnXNuhnk/Xrx5h1jHJ6W+fN0DRzICCXAz331BbwgjHe3IHHgNpQcZusdio5J3jYgNAlDM45Aqhq4tpfs/M3WpQN309YRnj+1yPmGFBFJhFJQWaELZbcD54Nw4+cuBZ+56zPx170xxzTxGABh4ZgOTbd7DIB63g985ltSwI3nx9lU2NR97Z4ulFlxzY4X8GN/+DhPH1/gxX/5IWzTiLtQCgSm0V0DZ4ocYZADoxM5cEILOI1Go1kjio7ZJaaGwTJSDtyA5iE5E+Y7Hifnm+wYLwKJ8Ds538gUjGMFm4WmGztwpiFouUkpw1UTsu56ptruKom4mBq4b718jkOLAbsnS5xbZjRANXqNUs6iEs1oOzxdj2vXFhsu5byFmWrwksU9W+/hnq33xH8/t9RmQ8npqSu0WExFRJej3vZwLIOOFyQCTjtwGs265Ip24ADeFMUoQTUhSdi1oUTRSXavau3unHzJMZksy52uomORt03cuXcgZn4kjkCqRSb9ATpX7zBb73Dz1hEc02C6IT8gE5cpiVAOamKSHiPQ6HgI49I6cGmGaWJimza2YSdjAHqEmRd6LLZl3d5YbiyJUA7pwIVhyL/4H8/z6OE5Ol4QF6YXrShCGXp9TUwMchDkEKKtu1BqNBrNGlN0zK76q2FQa6RjGl1xyjSyBs6PBJzcpLQjsbfU8jIF3GjBptHx4wYe40W7y4G7elIKwelauytRczECrtbyEMA790x2uXq9dEcopZBUG8mNjsc7/u13+OozfbPgV+T8UotNPe9FcRURymrLY0P0e5DnawdOo1nPXPEO3Jt2yLbDjmVQ6olvmIbgLTvHmKt3qLa8rtEB1ZZLJW8zXpK7Z8UoQhl0NrE4t4mrd1jxNYSAhXqyQExX28w3OkxWHHaMF5huSpGSzHNJmpi0MyKURauIF3i4gYtt2DQjB87AyqxLW2uWa2KiIpS2YWMZVp8AU+d4gcd8ex5DGFScCu/c/k6em34uaWbSI+DSs24A7n/+LH/61Emu21Tm4PkaDddjFFtGKL0GlmHJ2XpCYApTNjUhRxg40oHTAk6j0WjWlPfdtDluyjUsQggsQ8gEywBypnSlOn4QCzgnJfayBoePFeWacWZRriETJYeWF8SNUDaWcxRsM3LgPCxD4AXhRTUxqbU9CpYsz6i2PMIw7CorUKQF3PaxAjnL4MiMbGRyeqFJre1xbMjZbWnOVVt9Ajq9Cb0S9Y7HRMnhzGIrroHTAk6jWZ9c8Q7cLdtGsAxZFJ31Qfu5v34Hf/ITb2O0YHd9sFdbHpW8Fccui45J3pLiJAyJBZiqg5tPtfE9PFPHD0LGiw47J4qcb/TUwIUrjxGAZPZb0/URhouB03fspWC5Qd7pJiRpB67XWfMDn4XWAmO5MQxhcO3Ytfzmvt+M34PlBnm7fsCvf3M/ezaV+XvvvhYgXqDUOIK6W49fU92TCHMQOAijjeuFWsBpNBrNGvKT77mO//d9e1Z9nmWKgfVvIOfAqYZeKkKZntWmoodpRqOa9tMLTYSAsYITOXDRWpGzmKw4zNSkgFMu3sU4cNWWR8ESjBQs/CAcKJyUO1fOWRiG4JrJUuzAnV2UpRpLQ8Ye05xfarO5570orqYGruXFv9OovWMt4DSa9ckVL+Dytsn1myt98UnFaMFmJG9TyVtdkYhqy6OctxiLFomCY3XtIJZyyWLkmAYL0YexIeDguSoAG8oOV00UmW721MBhxE1MMgWcLQWcGiXQiB2411bALdfExDGdZR041cRkLDe27Guo89Nu358+dZIjM3X+yYduoBK9T80eAeenOl+q1xahQxjkEGaHtnbgNBqNZl1gG8bAEQIgHThFHKFMOXBZsc3RglxPTy80KTkWeceUc+A6HoaQs+Q2lnMyQtl0486Zw7bcz6LWdilYxHVt6WhmmnqqBg6QowSiWXBno0Yky0Uws/D8gJlaO8OBs7pGKSxHve3HAk47cBrN+uaKF3AAP/uRm/inH7ph2WP6BZyMUKrOlUXb7CrcVh/MIDP+Koe/dbQQLxATpRw7JwrUXXm9dBOT5ebAFS25Axk7cB3pwInwtRVwWU1MVM2ZilCqe+yrgQs8FtoLAwWcei+yauD+w3cOcttVY3zg5s0Uo7bVvQ4cJK6f+jMMZITSNDu4epC3RqPRrAssUyzb+CSf6lTZ28QEsrtejikBt9iKEjIGLTeg3vYpORZCCCbLOWaqnbj2yzLExdXAtT3ylmAkEnCDRJj6HUBt9O6eLHN8roHrB3EnyUHibxCz9Q5BCBt73ouCbdJygxWjrW3Pp+MHsYBzlYDT+k2jWZdoAQe847pJ3nPjpmWPKeeszAilcu6KObNrB7HcJeAM5hvyw3jXhmL8+IaSEw8PX2gkAi5kdRHKuAtlaPcdeylQc+AMY3ATE8d0sA0bP5QLVe8YgZfOzC8r4AZFKOfrHU4tNPnI3q0IkcRu1A5jl4BLdcQECH0HAgfDTNXAEepZcBqNRvM6YpvG8hFKUx0n2BS1yHdWcOBUDdx0tU0pJ5uMtTzpwBWjC26sSAeu2nIZKdgUHfOim5gULBEnQwbFIKstD8c0yEVlF1dtKOIHIacXmpxdVA7c6gTcdFVGLzeWu98LJRKb7vLOYi3VWRu0A6fRrHe0gBuScr5HwLU9RvIWEz1NTBSlHgGnHLirJhIBN1Fy4pjHYtPFMZWDlh7knT1GANIRSg9hvIYCbpkmJkrACUxqreTe40He0Z//9bEjLLWXGMmNZL6Gaj7S68AdmZUxk2uizl1q7lBvhLLrNQ01usAmDHMgOtSNF/gPi8/LA7ULp9FoNK8btrlChDIa2r0tmgEHK9fAjRWSRErBlmN+Wq5PvSMdOIDJco75Rof5hkslb0UbtRceoZQ1cDBSSBy4WtvjH3/lOebrSR18ve11lVnsin4vODbbiCOUS83VCcm56Pobyt1JnEKcUln+eqo2cKIkBaAK/wRawGk06xIt4Iakkrezu1CqCKVjkUstKGkHzrGMeJ7bzh4BN5IScENHKO3+CCVGhzB4bQScGQk4kfHjowTcfD3gL5+fjh/vdeBarkfdrVO2y8u8jtnnwB2N6gSu7hFwKkKp3hugq4mJbdi4niD0c4SiTaP0v/jj6n55oBZwGo1G87phmWKoGjhV/wbdNXDpwdWKSt5C9SUr5eQGa8sNaLQTB26ykiMMpTtVyduUcsPXi2VRbfc4cC2XZ47P86dPneTJY/PxcVLAJb8j7Nog17Njc40LjlAqAad+J1EU7e5NzsH37kbny98j3Oht8LSA02jWJVrADUk5Z9HxA9qej+sHtNyAci7pQlmwTQxDxLuC5Z4aOIWKUJYix045cEtpAYcRLwDLRSi/8tQhABqujxAewWsk4GYbckE4Mt3se04JuMA3CYLkx6u3iYkbuFLAOYMFXFcTFJEIOEPAzqgOIo5QRvGQkpURoTQsinZRLmChQyhcAucEnhJuWsBpNBrN68bGci5uIpKFqoHbMZZs0CkBN1bMHhxuGEktmprTKh04L66dTscNR/IWpZ5SidVSayVjBEDOqJutSWGVniNbbXtdvyNsquTIWQbHZ+upCOXq7mNWOXA9DdmU01dfwVlUz1fydrTpLB/Xq6NGsz654ufADYsSVNWWhxFt61XyVrzbpT4k85ZBxwv6IpQKFaGciGIO6QhlPEaApLZrOQF3/0vH+a2PhrEDF/ivjYCrtU0woNnp35mLBVxoEobJotrrwAmzSUi4rANnGVY8sDyJUDbYPl6IhXLcxKQ9uAbOFCZFq0jLC+QcuAgt4DQajeb15/f/1lu7Njp7yXbg5PG9bfPTjBVtFpuudOAsg7Ynm5hMRuvvxkqyHozkbco564Jr4DxfzpgrWHZXDVw7UkLpBE+9R8AZhuCqiSKHpuvM1NoYQqZ8Bs2Ry2K+3sEQye8UChWhbLrLf19KYJZyJjnLoOPpGjiNZj2jHbghUR+2tZYXFxdX8jZbRvO86/qN3LFrAkgcoXIq364EXNEx46iHypmPZkQoBUYsUJbrQimMDrW2J2vghEvgvzZ6fKltRvc2WMCFgclkOdkt7Z0dJ0zp3qUjj72kO0+mI5RXb0hEmordZHWhjF0/Qwq4ZseHINlx9dACTqPRaF5vRgt2vBmXxUhOYAjYs7kSPyZnrIrMId7p60JU4hCtFXP1DsVcUgOnqOStqInJhdXAqfPyluyo6VgG1ZYXO2PVdreAS2/ygkznPH18niCUkcogXHmkwWe/e5C/84UnAenAjReduEZQ0VtmMIha7MDJchDlwF14RaBGo7mUaAE3JLGAa3txtKGSt7BNgy/87bu4Y9c4QBzlSH84O2biFqnI5UQxaX5iiG4BZyDiczoZDlzOkDuOQnSotlz5wWy4eK+RgFtsye8xK6IfO3CBSc5M7wTKRUUJOWHKWraVHDiFaZiEYcjRmXrcwEQ+LshZRtxhq2AVENFrqXsxhUnBKtByfSwhF+zAqxASLU5awGk0Gs26ZSJv8J1/tI8P3bK563HHNDIbmCiUgCulmozNNzpxXVhawI0UIgfuAmvgVA1ZIVq2RvIWSy2X2ZrsDtlVQ9/24lmviqsmSixE3aqv2yTXxZWGef/P507z4KvThGHIXL0d/36RRm1yriRM1f2VchaOaeC62oHTaNYzWsANSSU11yUt4HrJW/0Czo46aJVzJjnLpJKzYgdOCEHJkgXLsQMnjNi1y3Lgzi9FjxkdlpqenAMnXALfzoxcriVhGLLQkvfWcvtfS82B6xVwpxfkQuQH0e5g5MClHbNekppAKfxm6x2qba/LgQMpglXhuRAidvX6auBcH8fbzVX5O/EWbwPAE2gBp9FoNOucqydLfXHCT951FR9505aB54ypJmM5i7wt16ZGx4/X51LOih2qSlQDd6ERSlU7V4jW+5G8LR24uAauJ0Lp9Dtwius3SwG3XB3cUstl/7kqLTdgsekyX3czBZz6XleKUKrvu5yTbqV24DSa9Y0WcEOS1MC5SYQy119zphaJ3jlwkHyQ/quP38qPvePq+PmiLVhserHjZGBgGgLTELh+wA9OLvD08aSD1avn64SBjTDaXQ5cGNq0Vpj1crGcWmji+qqTZP/zaoH1fIOclbw/h6dlLVu9LXfzhCn/PowDZwk5dFV1oEw7cCCdzXQ8RDUyUeffsuEWbp28lWbHp2hs5KNbfo7Ak6/rIbSA02g0msuQn/vhm3nvjZsHPj+WduCspKyhmJo5p8oaVBfKC41QKgdLOXCVvMVS02WmniXg/L4I5VUpAbdnk4yKLteJ8pnjC/EI0zOLLWbr7b4RAjB8hHKx6SIElBzpwKnNYy3gNJr1iRZwQzIoQtlLLiNC2SvgPvaW7dy6fTR+vmSLriYmIh6GLccP/MrXX+Lv/tFTsbu2/2yVMMiB4VJtedTdDkIEENhxlNDzA7710jkOT9fW7k0AXj1XIwwjAZfRxES5Xr5vkk8JuINnpeNWbcr7E8bKDpyKW8YNTHpGCCgKjtnVIlk5cCpC+Utv/yV++o6flgXmtin/PaIGK64QepC3RqPRvAFREcpC1IVSkV6fVYyykrcoOSYdP8hMvqxEtdeBK9hUMyKUQRBS7/RHKNUsONsUsRu3XITyqdRYgrOLLeaiGrhe4k7NKwjTF04vcv2mCoYhyNkGHT/EROAL9Bqp0axDtIAbEvVhKwWcamLSL+BU3jwdj1D1bCWnv9UxQNGSAs4x5IevEh62Keh4Aeerbaarbb754jkA9p+rQuAgjA7VtkvdXQQgDPK0XenYvfc3HuDHv/Akv/7N/Rf9vad59XwVIgGX1YUyduA8Qc5KFpP956TjttTyCEMDYUUO3ApjBNJ/Hp2tYxqiqxMZyPe1y4GLRGHvoPGW68fF5UrA6QilRqPRvDEZK6Zr4JJfd9IOnOpIqSKUsPLQ6yyqrW4BV8lbLDZdZpSAiwRew/UJw+5GZwA7xosYQg4lH00NAh/EU8fmYvF5cqHJQtPtGyEAyRy45Ry4IAh5+tg8t0e1/MqBMxG6TlyjWadoATck6TECiQM3OEJZ6upCKaLHspuMFG2oppuYKAfOMuj4ATNVuQD810ePAXDgbJW8lQfRkQ5ccBaAoDNJ0/X548eOM1Nrs2tDkfNL8txHDs2y9xe/wXwU57hQDpyrUWICEVp4ndG+5+M5b75BISXgTs61WWq5ckcxNBDG8BFK1bny6GyDneOFrrEM0O/AKQGXboICclhrwTFxTIH60dcRSo1Go3ljEnehzPU4cKkN1k2VPAVb1qerpM2r52v88z97fsXh12l6I5QjeZtzS+24VlwJOFVr1vv7gGMZbB0tsGU0H/9uMShC6fkBzxxf4EO3bMYQ8MqZJcKQzBo4y5RdrRvL1MAdmq6x1PLiZmw5W45cMIWBL/QaqdGsR7SAG5KcZeKYBrW2x1LLJWclrf7T5G05Q8VKiQwlOMoDBFx/hFIKPsc0WGq61Ds+k+Ucjxye5fmTixyeqVNxSgijw1LTpUVKwHV8llou28YK3Lp9lLlIsL14epFq2+PEfOOi3odXz1XZkd/IHfwundaGvueTLpQWeTtZTILQ4AcnFllsuhCaCEMujMOMEVBRyulqm80j/R3Hio7VtTgpAafuRdHsyAilYxnxjDpXO3AajUbzhkQ1Melz4FIbrJ965zX81o++RR4XrdG/+8BhvvT4cb67/zwAX3r8OI8cml32tdQctXzKgUvXvSmBV0s1C+nlx95xNT/61p1dG8ZZvHK2SqPjc9c1E2yq5Hnx9BIA4xkCDqTjuJwYfTKKY94x0IHTEUqNZr2hBdwqKOctqi2Xk/NNto8VMo8Zydt9u2C21V0D14sScPGstMjFsi2Ds4stAP72O6+mYJt87LPfxw9CxvIlDFM6cK5xDkKL0B2j6fosNT1G8hYbSk48g0b9OXeRDtzB8zW2lYy4w1YvcZew0KSYEnCEBi+diQRc9GNnCaer02QvvRHKuXonu03yoAil0RuhDMj31MB5endRo9Fo3pBcu7GEYxns2lAiZ2U7cFdPlrjvVtnJUiVnpiLh9p1XzjNX7/DzX32B//Lw0WVfq9byECIZOj6SSuhsHc3HNXJKyGUJuB+/dzc/cufOeCN4UA3cK2erAOzdPsqW0TyvnJUCbkMpeyZeyVm+OctTx+aZKDlcHdXe5SyTtudLB06nVDSadYkWcKugnLOotTyOzNS7Wv6m+an3Xsfv/Y07ux5buQYOvCCMXaGkBs7g9IJs9nHD5gpf+6l38Hfu3c09uyfYXBnBNF2WWi6BdZ48mwGDlisduJGCFJKLTRc3FcOcb1y4gGu5PhjObHMAACAASURBVPWOz1heUMlbmQIurjsLLQp2soCVnRwn55ssNl3CUAm4bBGs6BVw8/VO5g5j0R4QoRTdC2QrjlAaEOoIpUaj0byR2b2xzIF/9WGu21TuilAWB6zFapPVC0IKtsnU/mm+/oPTeEEY17INohqNBjBE4sApdm0oxsJtUISyl0reHhihVMJuvOiwdTQfxzSzNjghKjPIiFB++fHjvDTry/q3q8aT9I+VOHCBTqloNOsSLeBWgRItx2YbfZ0QFZtH8l0dJmGYGrik9T6kauBMg3OR8Jos59izucI//6Gb+PKn38ZYvowwO0xX2whnhoqxFZAiZbHpMlqw44Lm+UYn5cAtPxh0OdSQ0bItqORlh60wDPnzZ09x//NnAOIh2mFoUrKT3cCtoyVORQJOEM1nYwUBl+pCGQQh840OExldtoo9DlxvF0qF7EJpSEdUNzHRaDSaK4Z0hHJgGiblzP3Ue69jptbm33/nIMBAAffwoRlOzDWotbo7S44Ukg3MXRMlmq6P5wfLRijTjBQslgZEKONr5C22jCZlBYMEXO8aCeAHIZ/5s+f5d0+0ODxTj+OTIAWcqoHTm5wazfpEC7hVUM5ZHJqu0XT9vllky9E7RqCXUiTgOq7801QOnGXgBzJ7PlnpjkYUrAJCdDi71MBwZpnIbQeIIpRuFOWU58zVO/HiczFNTBajXb+iLR041w9puQGfmzrEf37oCJASTaFJ0UnuedtoKXbgjEjAGSsIOOXUBYEhncYwO+NfcKzYgftvTxzHc+UxmU1MbJOcmdTAeQgI9KQbjUajeSMzjAOnRNXe7aN84q07EULWXudtg5la/9oZhiF/9wtP8Rvf3E+t7XWJsnSTMzXjrd72hxZwlbw9MEJZa3vkbQPbNNiaEnDjpeyShIJt9o0RUPextSSwTcG7rp+Mn8tFDpwhIgcOXQOn0aw3tIBbBZW8xdFZ2QTk6g0XIuAGjxEAaLvyOBVDdCLnDuhrD1ywCoSizdnGaYQI2FLYCUCzE7DU8hgpWPFu3Fytw2y0+FxMhHIhOlc5cCAHm59barHUlItBIuAsSikBt32sxMn5BgsNFyP6/kTY35AkjbrVtpvU7mW2SY5m9yy1XP7Zf3+e/Wfksb1jBJodOUZA1iSm58Dp3UWNRqN5IzNoDlya0aKNaQjuu3ULG8o53rJzDICP37aDWtuj5XaLoJlah2rb46UzS9TaXldsciT6upyz2Bi1+6+23aEjlCMDyhRArrvlnFyDt4zKjdBKzuqq80tTyslGXyfnG3zhkaNAIuDuu8bm5V++j1u2JckhFaG0MPQYAY1mnaIF3CpI75itxoFT3SrT8Yw0atMsamKFYSQ5dJDCMb34AOwe200g2lTthwDYWdkFwFy9jR+EjORtNkTzbWbrHaZrF18DFztwVrI4zdQ6zDfc+Dkl4MLQpOQkYmvneIV6x+fYbD0WViLILrhWuJEjGQRGfN+ZNXDRbuqxGSmufb97np68Rkjbk01Mumrg9JBSjUajecOTT3WNHuTAjRZsvvr3Za05wE+95zr+4fv28JadUtxMV9u8cGqR/+f3H6PZ8Tk+Vwfg0HSdmVqHcsp1U5uck2Wna45sLXLCVoxQLlMDV2158Rq8LXLgBnWghKTR1xcfO84v/PmLLDbd1NgD0dU1G1QTE+nA6TECGs36RAu4VaA+hB3TYNuALpRZOCuMESjGEUq5qJipJiZAvHuX5od3/zAOFeyJBwG4duwaAM5Fc99GC0k3zONzDTqe/AC+mC6UC5FIK0URSoCD0zUgmVeTduDKueS+d4zJeW+HpmuYUbQxDJZ34NQsVc8Xce1eVg1cIVqMj8zKxTTw5OumI5TNaOdUd6HUaDSaKw/LNLCizdHigM1UgL07RuPN0/fdtJmf/sD1bIxKGGZqbR44MM2Dr87w4ulFjqpNwyBk/9klKrl0DZz8ekM5F6/9tZZHre1iGqKrJi+LkcJgB67WTurtVA3coPo3kI2+Gm2fV8/J9bracmMHrpChZdUMWtmFEr3JqdGsQ7SAWwVqR23nRAHTECscnbBSExNVA1dryQ9JK2p/rwTcZIaAK1gFri98GCECAq/ItoqcyXZuSY4dGCnYjBcdhIAD56rxefMX0cRkqUvAyffi4Hm5IDQ6Pq4fdNXAlZ1EoF01IQVcEIIVOXDKKRuE2nz0fIO5uhSmWRl/tZt6dEYKOM+T4jpvJq//8hnZZvmayWLXHDgPtIDTaDSaK4C8LefBrWb9hmQNnql1OBnNUn3lbJVjc8lc1SAkswZuQylx4Kptj3rbp+SYycidAYwsVwPXSurtNlXyCJFdXqAo5SwaHY+D5+XvAtWWFws4NbcuTS4SsAbKgdMCTqNZb2gBtwrUB+Zq4pOQngOXHduINup4/MgiABMlKTzULuBkJfuD+S1jHyEMbMLORoo5i4Jtxl0rR/Iyyz9WsNkfzYzZPlZg7qJq4OTOYcFKWiSrBQGkwEtHKEfyctEzhMGuSMBB4oz53vIRylZ0q27agctqYmLL6ykBZ7vX8dvv+W1unbw1PubRw3II613XbOiKUOoaOI1Go7kyyNvGsu7bIBIB1+bEnBzts/9slWOzdbaPFeJNxHQXykrOksKqnIuduXrb62t2MohK3qLtBbS9/iZb1ZSAcyyD7WMFto4NTrQUHJN6x+d4JDiXeiKUvSQCTtfAaTTrlaEEnBDiPiHEfiHEQSHEZzKe/y0hxLPRfweEEAup5/zUc19by5t/rVGiZTUNTACu3Vhm80iOzSPZH7CGkJHEV87ID9etI7JjlYpeDhrOuak0TuvUJ2hPf5CiI3cWz8cOnLzXiZLD4WkpbK7bVGa+3iG8wN20xabLSN5CiH4HDmCp5WFEP1IitOIaOFOYjBSseBGzzcj9cpd34JTW7LiC+UaHnGVQsPtFsBLGKkLZaAe876r3de1wPnp4jhu3VJgoOZEw1g6cRqO5eIZYH98lhHhaCOEJIf6vnufeMOvj5UDOMgfWvy2HqiefrrY5ETlw+89Vo5FCRW7cUgG6HTjDEPzwm7bx7usnkxq4lket5a3YwASSMQRZMUrZMCVJo3zxx+/mH3/whoHXKtomfhASNbWOHDi5KVrIuBUl4EwM6cDpLpQazbpjxU8RIYQJfBb4AHASeEII8bUwDF9Sx4Rh+NOp4/8BcFvqEs0wDN+ydrf8+qE+nHet0oG7Z/cGHvsX71/2mNGCTb0ezUczVQ2cFCBZEUqQEQ2vdgsg2wQXbJPz1aQGDqT4OxQJuOs3l3ngwDTVtsdIPrvd8HIsNF3Goho0JWaPRK4XSIGnHLi85WCb8jUsQ4q+7eMFXjlbjR93VxJw7RBy4PpwfqnFRMnJjJ3ETUyiDqG1nnbJHS/gqWPz/OhbZadO2xRJhFI7cBqN5gIZZn0EjgN/C/jHGZd4w6yPlwN528AyVh88ylkmI3mLc0stTi8kDpwh4MN7t2IIePr4glwXU8vPv/+k/FWoGtUD1Noe9c5wAk6tsYtNt+93gGrL7RkUvvzvJMWe16u23VgYZkUoVfpHILQDp9GsU4b5JLsLOBiG4eEwDDvAl4GPLXP8J4EvrcXNrTeUKNq9SgE37LWVqIgHea8QoUx/gBcdk7xj4kVbbEqgpSOH122SMcaFC6yDW2h04l3BsiPjIa6f7MylI5Q5y8E2IgEXDeTeMS5r05woQtnu2APdwGbHp+2qoeAGB87VBhZpqwilatDS6HTvWD5/aoGm63PP7gn5+pZuYqLRaNaEFdfHMAyPhmH4A0B/0LzO5G2T4oBShpWYrOR48fQSrh9y45YKi02X+YbLrokiN20dAbrX5DSqA3W15XFirtE1u20Q6pp/8sSJrsfDMBw6hqnodR2XmkkNXJYDp373MIWBL9BrpEazDhnmE2A7kP4EOQncnXWgEGIXcA3wndTDeSHEk8i02q+FYfjVAed+Gvg0wObNm5mamhri1gZTq9Uu+hq9+H7IX7/JoX3ieaZOrq4IejlqtRpBy8SI/jnOnT3H1NQU585IN+3s0VeZah7pO+/wbLLV9+RjD+O3W/Hfn37sIUxD0Iq6UpZsOHPkAADfevARTtQCtpYMrh8ffjE7eb5J2RbUah7f+94D5E1oevLadRcefeo5bthYp9y5Gb81weOPPg5A6Ify3yJqRNJpyvsM/Bz/+ztTXfPuFGfrQTzIm9DkwNklbpgwMv9Nz9W7F5f5aoOpqSkeOuXy5wfbbH1K3od7+hWmZvbT8cNYwLkCnnryCaojC33XfT24FD+3l4rL6V7h8rpffa+XDUOvjwN4w6yPl5K1ul/LbWH6XNC1bK/JCydl4mRPqcUr6t7OHsHJyzXs1OEDlEqtzOvnTXhu/xGOzXq8Zdwd6h7u3W7xnx48zK7gDNvKcj1seTIKef70Maamzgx170dPS7G2IS+YbYU89/IBGm5IzoRGvd53LwfPyuPbrQ4Bgkcefph2frL3sq85V+rP7WvB5XSvcHnd76W619VX8y7PJ4A/DcMwnWHbFYbhKSHEbuA7QojnwzA81HtiGIafBz4PcOedd4b79u27qBuZmpriYq+RxQfX/IryXj9+z04OzZ7l/iXYvm07+962j0caL8Oxw+y75w7u2DXed97kqUX+7RPfRwj44Hv38fkDj3BsaZ6SY/K+974HgKc6+5k6cZCt42Xefc+b+O2nH2b7nlv4tS89w73XTfLpj7916Pv8xSe+yzXbxyiXF9m3bx/jj3yb5mKLW7ZP8PjRObbv3sPH7t7F1/5wG2dHW7z7nW+CL0M+l2ffvn0cNA/zreMvs2FsnFNzcozAHXe/nQ0ZEdGHD87Ay1FJSGjihXDtji3s23db37Hnl1rw4Lfjv3dCg3379vHtr77A+eYxzjd9btxS4aMffBcgZ8Lxnf8GgIfgjttvhx13DP0+XEou1c/tpeByule4vO5X3+sVwxtqfbxUrNX93na3ixBcUAnBV049zf55KZg+dd9d/M/PyhmsP/Suu7hp6wi7b5rm7ddu4KEHv5d5r2MPf5tzvkPIEh+6ey/79m5d8TVvvbPNe359im9Ol/nDH74LiDpNf+vbvPnmG9h3966h7r3z4ln4wVPcds0mHnx1mo1bd7LUchmZPU+5bPXdr/fSOXj2SYr5Al4L3nbP3TC2c6jXupRcqT+3rwWX073C5XW/l+peh4lQngLS/+fuiB7L4hP0xCfDMDwV/XkYmKK7Pk4T8el3XcvPfmQvQDzoWsUYsubAQbIIFWzZklg1+FAxR0gilBtKTvz1wwdn6HgBL0Wt9YdlsekyVuwfVLpns4xmLjXlrp3K+McRyigyefuucSZKDuWcvI8wyNHo9HfYAjiz2Io7Rao/B0YoU/GQgm3ScgM8P5C1AwXBv/74rfzcR26OjzEMgRnFOnWEUqPRXASrWR/70Ovja8towb4g8QZyIDeAEHDz1hE2j8h1+aoJ2XTs3ddvjEf/ZFHOW+w/K9fcG6KmJyu/Zo5P3nUV3391Bs+X65SqXVtNhFLV3O3ZXKYSDQivtryuuXVpcrZqRiYIdIRSo1mXDCPgngD2CCGuEUI4SJHW1y1LCHEjMA48knpsXAiRi76eBN4BvNR7rkbiGNECgYxjFBwTQ6xcA6fy7flIwI1mCLjJSo7x6Otvv3IekCJppcHeLddn/9kqQRBKAVdIC7ikK6djGixGM2saHTnnRgk3VQN3+1XjPP3zH6BgRwLOz1PvZA8qPbPYRHWKFNGf4xlDvOX3nyxCV0f1ifWOz2LTpWIL/trdu3jnnu74h2NGAg704qTRaC6UodbHLPT6eHmhGolsHcnjWAbXb64wWc4N1ZAEpOAKQrkxu1LTkTTXbSzjBSGnF2TpgWqIMqjeLgv1O8J1G8uMFCyWojlw5QHXUB2wBQY+ugulRrMeWVHAhWHoAT8FfAN4GfiTMAxfFEL8shDir6QO/QTw5bC7K8VNwJNCiOeA7yIz/nqBGoByrFQjkB+9cyf/+cfuGji3Rn2AF2IBJ89L7zCqEQSTJYdKzsIyBCfnm/HzL51e3oX7o0eO8cP//kFOLTQJw253T73+5tF8tCgknbaKOSsRcEb3/SuHkSBHvZ3twJ1ebMVCL2+phizZO6emIWK3cvfGSMC1PRabLsUBm61W1AlTO3AajeZCGWZ9FEK8VQhxEvi/gd8VQrwYna7Xx8uIyYpcS3dEjtvPfOB6/vXHb13ulC7UerlnU3lVg8R3bZCvdzQak6Oaj1RW4STu3T7KZz58Ix/eu4VK3pZjBFqDG6HkbLV5KnQTE41mnTLUFk4YhvcD9/c89gs9f/+ljPMeBvZexP1dUZiGiSGMWMBtKOd49/UbBx5vmQZFx6QYdWFMIpTJP2vswJVzCCEYKzrM1Nrcfc0Ejx2Z46Uzi33uVJqXz8iuW49Eg7DHig5Es7vVArK5kmOkYLOkHLi2dOAMYWAKs0/Aqb+HQb6vY6Ti7GKLkVyOBaDoOMwDEwPm4YHcYex4QdwhtNHxWGq6TNrZC6Vj2rSRTUz04qTRaC6UldbHMAyfQEYre8/T6+NlhHLgdo5LQXXbVf116cuhxNKw8UmFSpUci4Zw1y4gQmmZBj/x7msBGMlbVFsuzY7PVaVi5vF9DtwFzo7VaDSXjtUPRNFcUmzDjgXcMFTyVuzAqT/TDtz2sQIF24xHCCgX6703bmLbaH5FB+5QNOftscNzQHc8U+0obhnNM5K34whlvePFrqFlWInjFhE/FlqDHbiFJmNF2WpZDQQfH+DAgRxUCokDV2v7kQOXLeBypoUIBR4Cwux70Gg0Go0Gkhq4nROFCzpfRS1v2Lw6AbepkiNvGxyL1uJqe/UCLk0lb7HUdJePUFqq/lw5cFrAaTTrjbXuQqm5SP7pW/8pb9745qGPr+Tt2HnLZzQxGS3aPPaz74uLlVUd2W1XjfPE0TleXEbAhWHI4ekaAI/GDpyNGt2tXmdTJc9IQQq4MAxlDVw0a8c27MwIZdEqsYAY7MAttbh1ax5aUHbkzuegJiYgxatjGWwdlYurilCWrMELlIGBpx04jUaj0azAVRNFHMvglm2jF3S+ElzXr9KBE0Jw9YYSR2elA6eamFxoM5aRKELZ8YPBTUysXgdOr5EazXpDC7h1xo/c8COrOv79N22OXbEsAQfdH/TjRQfTEOzdPsrNW0f4zivn+Y8PHOJbL53jD//2XV27ejO1TrxYnFqQdXOjhUTA/eidO7l6Q5GCYzJasDkx16DtBfhBGO82WoaFaXQ7cB/Y9QHG7M38zg9ks5FeWq7PQsNlvBgJuHwuvvdBFB2LTZVcfP/T1TZeEDLItLNNgcDA1TVwGo1Go1mBDeUcT/yL93eVKKwGlVi5cZUCDqR4PBI5cCpCWbrAgeSVvKxX9/xwYAOWWMCFQk6fX09r5J99GoqTcN+vvt53otG8rmgBd5nzmQ/fGH8d18At053qQ7duZutYnoJjcvO2UYIQfu0v5EjS7786w323bomPVe7btRtLHJqWi8dYweZ09PzVk6U4nz8SxTLUWIBSKkKpulAq7t1xL3dsehu/82ffoNHud+Cmq+3otWSE8uYt49z5gevZVBlcAyfHE1jxgqQE56AIpXTgzChCuY4WJ41Go9GsS0YHdcUagvtu3YIXhGwZya/63KsnS0wdmCYIQmptl4JtYi0zsmA5KnmblivXvEERypylxOE6TKkcfQhyqxfBGs0bDS3g3kDEXSgLgxeZj9+2g4/fJuvpb981xkTJ4a/etp3/9sQJpvaf575bt3B4usZkJReLto+8aRu/8+1Xl732SEHOlqlHgky1Lc6KUALkLRMhsh24s0uyXfJEqRD9mefTb9uz7Pf+b/7qXkKkswayhg6gNEDA2aaBiBcnne/XaDQazaXjlm2jFxy/3LWhSMcLOLvUWrZ2bRjSG7yVnAXt/mPUHDhZA7eOxgiEPlTPQH0aAh+MC3MhNZo3AlrAvYFIHLjhdgk3VfI89XPvRwjB6cUmU/unOb/U4iO/830+dMtmJsuyePq9N27id779KnnbiGOavYwWbFw/ZLomV4N0hDJLwBmGoGib1Foez55YYO/20bi18rlIwG0oFuJrrMS2MXmsqqk7syivMUjAOaaBCA09RkCj0Wg065qro7lxR2frLLW8Vc2A6yU9fqCcHyDgLAMhIAwFPgy3Rv7xJ2DnW+Hef5Q89uh/hOlX4KO/fcH3m8bpLEgR5/uwcBwmrlmT62o0lyO6C+UbCNWFcnQZB64XIaTA2XfDJs4utfjpP3mWputz//Nneer4PFdvKHHD5gqGWP66SjSejYTTSg4cQDFn8V8eOcr/8dmH+O9Pn4wfP7ckV5TJciTgxPCLVcGWzp5y4IoDTnUsA0JDRyg1Go1Gs65Rs+COzTaotbyBzUeGIS3+yrnsNV0IucEaBmK4JiZeB179Jhx7pPvxQ9+BV75+wffaS649l/xl9tCaXVejuRzRAu4NxOaRPELAtrHVZ+z3RfPmHjo4y13XTND5/9k77zipynv/v8+Z3rcXtu+y9N5FlCIoKmhMjKImMbmaaNQYb/TmahKNmhhvzI3G/OwxRi/GiqgIWBFQpMpSl7aU7b3P7PSZ8/vj2UpZdgUU5Hm/Xvs6M+c85znfmd2dZz7n2yJRtpQ2k5dox2LUkZ1gI8Zy7CIiHYndFe1Nwjs8cHHmOGJNR++XMyTFQU6CDZtRx9ay5s79Na1+jHoVl1m8jr544DpQFAWbUd+ZA9erBw7d6RffL5FIJBJJN1JdFow6VQi4Ewyh7OGB60UIWk16oppCtC9pBg37hWfMU91zv68RvA0i3PEkYArUd7tm0UmZUyI5U5EhlN8iJufEsfbuWZ2l9PtDktPMiDQne6vdPHrVaG5/dQsFpc2dfdWumZiJL3TsD+EO79zbWyow6lQGJoq+c4/OePSYAmzhDZMBWPDcuh7tDGpa/SQ7TRhUMWd/BByI6lwdXrzeipgoARlCKZFIJJLTG52qkJNgY2dFC25/iAS77SvP1b2Kpt2kP1oEJQA2o/DA9alXat1usXXX9NzvaxLrq7cB7Elf2eYOOj1wqgHqpYCTnN1ID9y3CEVRvpJ46+DeS4fx2NVjSI+1cs2kTKCrMfZPz8/l9guOXUikI4RyV1Url4xMIba9Z1usORaHsfeKUSMGuNhT1Uo4IoRUTaufFKe5U7j1X8CJ8YoCx6r4bNCpaJpKCKSAk0gkEslpzexhSaw72EBVs7+HF62/OA/PgTsGVqMer2YRHriGg71PWrdXbNvqINKtsrS3XXB5ar+itT0xBepBZ4SUkcLr1xuaBp66k3JdieR0RAo4SSeTc+OZN2oAAJePSeO+ecO4aHjKcc4SdK9Oed2UrH5dd3iak0A4ysH2Pje1rQGSnObO/nH9FXAdYSFOswFVObYHDk32gZNIJBLJ6c/80QOIRDXcgXCvoY/Ho2cO3LHnsZl0NBMjcuCKP+95MODpGVZZ2+6BQ4O2drEWjYK/PTWi7WQJuAZwpEDCoOMLuL3L4bFhR3oFj4W3EV6cB03FJ2ynRPJ1IAWc5KgY9Sr/MS0Hq7FvC0VHCOXgZAcTso6e83YsOkorF1a2oGka1a1+kh3dPHD9KGICXQVUeiu6IjxwOhlCKZFIJJLTnsHJDvKTRGrCiVSh7C7aepvHYtQTiqpEVBVKvug64GuCvw6Gba927avbA/r26B93ex5coKVrbT1JnjBjsAGcaZAwEForINh27MHVOyAShOaSvk1eUSCEaumGk2KrRHKqkQJOclJwWQyMSHNy26yBnZUt+0pugg2TXqWwohVPIIw3GCHZacJuEIuVzdC/eP+OBao3AWc16tCiKmGQfeAkEolEclqjKArzR4sImRMRcHqdis2oQ68qmPTH/gpoM+oIhdvbCDTs7xJmlVsg6IEdi8TzcFBUhMw6RzzvGOdr6prspHrgUiG+PZ2jNy9cU7tw62v4Zktp+/jq3sdJJKcJUsBJTgo6VWHpL87rXGD6g16nMiTVSWFla2fxkRSXmSxnFs9f+Dznpp3br/lsfRBwMRYD0agiPXASiUQiOSOYP3oAelUh5QRy3UFUorSb9b3ebLUa9YQjEEUTbbyL14gDVdvFtvhzCLi7KlDmzhD7OwSQt5uA8/QxjLE3NE0IOOcASOiDgGvuEGR9vHZLeyujk5SvJ5GcaqSAk5wWDB/gpLCypbOPXJJDtBCYnDr5Kxcx6VXAWQ3tIZRIASeRSCSS056cBBurfz2TS0emntA8Tose23HSI2wmHcH24pMRo6MrjLJqGyg6EZ54YGVXBcrs8wClK+esuwfuZIRQ+prQRYNCwMW2N/Bu6iU8srmfHrjmsvbxJ0FsSiRfA1LASU4LRqe7aPWHeXdrBQDJTtNXnquziEmvAs4Imk6USD5JPWokEolEIjmVpMVY0Kn9S1M4HIfZcNwwTKtRTygsrhPNmNTNA7cN8ueA2QX7PhC5Y4oKSUPBlgDuKjHO116B0uQ6OSGUrZVi6xwARisY7aLq5dGIhESOHPT92p0eOCngJGcGUsBJTgsuG51GeqyFNzeLD9FkZ/+bkXfQlyImMVaDEHDSAyeRSCSSs4hxmTGMzey92JjVqCPcfm8zPHAW1O+D0vXQeADSxsPAObDjTVj3BORMB4MF7CldAqijhUDi4JPjgesQho72NA1b4rEFXEt5twIqfRVwHR44GUIpOTOQAk5yWmAx6njgsuEAOEz6zjDIr0JfipjEWNo9cDIHTiKRSCRnEb+9dBgPf3dkr2PEjVDxFTEy7DLRf+2Du8XB1NEw8krh6TrnNrjmNbHfkXJkEZOE/J5esKpt8M6tPfvF9YUOj5qzm4A7ltjqCJ/Um/smyCLhLg+fWxYxkZwZSAEnOW24YGgyl45KZUhq742/j0ffc+BUQkgBJ5FIJBJJd2wmPWjiK2LU7ILBF4sKlCAE3OCL4Z4yuOghMLRHzDiSuzxwLy4fzwAAIABJREFUvkYRZulIgbZ60RcOYOdi2Poy1O/tn0GtlWgoYj4Ae9KxPXAduXGpY/oWEumuEoVYnOmid1040D/bJJJvACngJKcVf18wlld/OuWE5uirgAMZQimRSCQSyeF098CFo2EY+0NxwJbUJaJMh91s7QihjEaEB84SJ8Zrka6cuPoisa3a1j+D6vfhNyeBrn1d7y2EsrlEFFoZMFZ44I7XKqgj/y19vNh6auGD3whPoURymiIFnOS0Qqcq6HUn9mdpNx0/B06EWcoQSolEIpFIDsdq7OaB06KQN0s00U4bf+yTHCliPW2rFzlwlliwJ4pjHaGMDR0Cbnv/DKoppM2W3fXclgjehqMXIWsuBVc6OFMh7BN963qjI/8tbUKXrbvfg+2v9aymKZGcRkgBJ/nWMT4rjgUTMxiTGXPMMYqiYFQN7SGUspG3RCKRSCQd2Iy6TgEX0SKg6uDHy2D+3459kj1ZbD3V7R64WOGBA5EHFwlB40Hx/GgeuKYS2PzikWtyyAcN+/HYs7pdK0mIRW/D0eeJyexmz3Hy4DoFXLs4rd8nGntHw7Dvo97PlUi+IaSAk3zrcFkM/M/3RnUWMzkWRr1RhlBKJBKJRHIYVpNe5JzRLuAA4nK6wiePhqO9P527WoRMWuOE0AJRibKpRIgicwxUbxd5cQF3lxdtw7Pw3i9h43M9563bA1r0MA9cgtgeLYyyuQRis7pd+zABp2ngb+l63lIO1njx+gAOrOg6tnvJsV+vRPINIgWc5KzFpDfKEEqJRCKRSA5DeOBEOkKkr71SYzLEtmF/lwfO3s0DV79PPB52uQhrrCyAx0fD54+K/dXtYZUf/hbKN3fNW1MIgMee3c3AY4izkE/k4cVkdRtzWCGT7W/AXwaKtgggmni70kVYJsCBT8V2yDzYvwKC3r69fonka0QKOMlZi1lvJAxSwEkkEolE0g2rSU9nGwGtjwLOkQJxeUIA+VtEERNzjGhB4Kntyn8beaXYvnurCIE8uFJ4xap3CHFnT4aP7+uat2YX6C34LN28f53C8DAPXPkmsU0aeuwQyqqtEAnCGz+C+v3QdAhcGaJAijVe2GSNh0k/FTl0HR65aLT/7Q8kklOEFHCSsxazwYimKESiZ+YHciSqocn8PYlEIpGcZKwGHWjtIZR99cAB5M2Eg6vEY0ssKIpo5n1wpfDA2ZIgYwqoBhEaqeigokCEPfqbIed80aKgaltX64GanZA0RIzt4FghlLveBYMV8i4QIZyKrmcfOhAeQkcqBDzwxHjxPH6gONYh+pJHQNY0MVfxF2Lfpufh8VEyb15yWiAFnOSsxWIwARA6AwWcpmlc/PhnPPZJ0TdtikQikUi+ZVhN3Rp599UDB5A7Q+S5gRBQAON/IgTZnmWisbfeKDxkig5m3CO8XNteF2OTR0LKSAi6hajTNCHgkof3vI45RojA7t61aERUj8yfA0arKLxiSzgyhLJhP2ROgWtfg1m/g2teF3ZAl4BLGQk6PcTnQeMBsa90nWgofryqlhLJ14AUcJKzFqvRCIA/EvqGLek/5U0+9tV4WL33ONW1JBKJRCLpJ0adikp7Dlx/BFz2NFDav1paYsV21NVgcom8uIR8se/8u+CSv8Coq8TzgpcABZKHQcoIsa96hxBo3gbhEeuOorT3gqvv2le2QYi1YZd37bMniQIqHYSDophK/EDh7Tv/v2Dw3K5m5N09cCBCQhvaBVxHCKhsLSA5DZACTnLWYjOKD2xv8MwTcAWlYgEprGzFH+rH4iqRSCQSyXFQFAWTKhp1V7dV9/1ES6xooA0iBw7AZIexPxCP49sF3LDLYeINoty/LUl4tuJyRXPwpGFCBNbsFIVO4EgBB6LHXPfwyF3vgs4E+Rd2G5Pc0wPXVCwai3fYccSc7bl1HSIyfqA4JxzsEnK+5r68ExLJKUUKOMlZi9UkQig9ocA3bEn/KSgRAi4c1dhZ0XKc0cdnc0kTizaXn5S5JBKJRHLmYyMTBR076nf078TcGWJr6daLdfJNEJsDOef1HKsokD5RPE4ZKbYGixBY1Ttg91LhvcuYdBQDk7pCKP0tsONNET5pcnSNcaaJEMiO4iMN+8W2I+ftcLKmQuoYSBjcPi5PCL7SdRBqr0YpPXCS0wAp4CRnLXZThwcu+A1b0jfqPQH+9cUhIlGNgtJmBieLRWpLaf/uBpY3eQmEu7x2vmCEG1/axF1vbmPe/1vDwnXFJ9FqiUQikZyJWI0WbKT3X8BN/CnM/K3wqHUQmwW/3Aqpo48cn3GYgAPhAavcCnuWihBHvenI87qHUH7+KHgbRUhkd/JmCnFXvlE87xRwuRyVwRfDTatFnh50Cb19H3aNkQJOchogBZzkrMVpsgCnp4ALRaK0eHuGdj618gAPvLeLl9eXsKuqlTnDksmIs7ClrPfFRNM0vEFx93FfjZuZ/7uKBc+tp9krXvfiLeU0eUP8/ZqxjE538X/rSmR1S4lEIjnLsRn1WLQcCusLifan3Y4zFab/WnjX+kLWNLHt8MSBEHPuSlGZsntOW3c6QiibimH9UzB6AQwY03NM3gWi2Mne98Xzhv1gTejKzzsenQLu/a59UsBJTgP6JOAURZmrKMpeRVH2K4py91GO/1hRlDpFUba2/9zY7dj1iqIUtf9cfzKNl0hOBKdF3NHzhk+vHDhfMMLVz65j1l9XUe8R4Z3BcJR3tlYA8NCy3USiGuOzYhmbEdurB07TNH77zk4m/PET1hTV87u3d2LW6yisaGXBc+vZX+vmn2sOMSrdxfxRqSyYlElRrYft5TKUUiLpK31YI89XFKVAUZSwoihXHnZMrpGS0xKrUYc+lI0n5KG4pfjU3djLmAi3bYbc6V37ktu9cUY75M06+nm2JNHPbeF3RUXLWfceOcbshOxzYd8H4nnDgWOHTx4Na3svu8aDIr8OhKiUSL5h9McboCiKDngSmAOUA5sURVmiadquw4a+rmnabYedGwf8HpgAaMDm9nPl7QvJN47TLEIofeFT30ag1u1HpyjE248SBtKNqKZx+2tb2FLWjE5R+MPSXTy+YCyf7qmhsS3Iz2fk8fQqkUg9NjOGkoY2lmyr5GCdB5tJzysbSll7oJ6DdW1MyoljaKqTVzaU4jDr+dELG4hq8D/fHUlarIVb/13AhY99RlSDxxeMQVEULh2Vyv1LClm0uZzRGTG92vp10+oPsXJPLd6gCP9sC4TRNEhymmj1h6ls9nHpyFRGpLmOOLfBE2BjdZiizw4yLT+BSFRj+Y4q4mxGxmTEsLmkia1lzTR5g9hNeganOEhxmjHoVPbXemj0BsmKs5HiMmEz6fEGI7R4QzR5gzR5g9S5g9hMOrLibYQiUdz+0BGtgjqeiv1a53FNA639qE5VcVr0lJYGWVK7lQZPkBZfCKtRh0Gn0uwNogFOswGHWY/VqMcXEn+/iXYT4ahGTWuAmlY/bn+IjDgrLouBZm8IDQ2LQU+Ky4TDbOBgnQe3P0yszUis1YDLYsAbjNDqC9PqDxGJalgMOswGHRajitWoR1UU3P4QNa1+Dta38eOp2WSe/F/1GUUf18hS4MfAXYedK9dIyWmLzaSnuS0DjLC5djP3rr2XEfEjuGfyPSf/YgmHiaqOcMpBF4mcuKMamCi2gVbREsCVdvRxg+bCB3cL8dawHwbO7p9t8QOh4kvRi652j/TASU4LjivggEnAfk3TDgIoivIacDlwuIA7GhcBH2ua1th+7sfAXODVr2auRHLycBiFmPKFTq0HLhLVWPDserzBCEtvn0aC3YQ/FMFs0B0xdk1FmI931fD7+cNo9oZ4fEURYzNiWLGnlmSniTvnDKKkoY2KJh8xViMTskWVr1l/XQ2IiJWxGTGcl5/Ah4U1vL+zmhmDE/nLlaO54aVNOMx6rpqQgaoqrLhzBg+/v5vyRh+XjEwFhDCYOyKFJdsqGZXuIsVlRq+qZMRZSI+19vn1hqNRTPqu16dpGuGohkGncrDOw6LN5eQm2rls9ACM+q5AAG8wzNr9DazcW0tBaTMKYNCr6FWFwsoW/KHew3ieWX2AucNTCEU0DDqFsZlCnH28q4aoBmzd3TlWpypEol0qKyfBRrzNSGmjl5V76zqPmfQqsVYji1srjrieTlWItRpIsJtw+8Ms2VaJXlWwm/To1KOFD4l9iiIedUQYKSgoCoQiGq2+EFEtSnJTIwl2I06LAV8wgicQJsZqRFWg1SdElDcYwWxQ0YDP3fXoVYVkp5kUl5nMeCtljV7KGr3EWI3oVIUGj5cvSxpp9YXIjrcRYzWwu6qVpjYhFG1GPU6LEId6nYI/FMUXjOALRfAFI0SiGnaznkS7iUFJQuRSd5SXeXZx3DVS07Ti9mOH/wHLNVJy2mIx6gg2JGCPtfPYl4/hDrlp8DWcGgF3OI5kuPAhUZTkWAy+GKbfDRN+Ao6UY4/rEHAf3A2ealGYpD/E5wkBF58P7hop4CSnBcrxXOLt4R5zNU27sf35D4HJ3b1tiqL8GHgYsZTvA/5T07QyRVHuAsyapv2xfdy9gE/TtP89ynV+BvwMIDk5efxrr712Qi/M4/Fgt9tPaI6vizPJVjiz7O3N1kJfIc/UPsOtDfkMGXf7CV9rS22YSBQmpPS8L1JQE+bvW0Qo5JA4FZdRYUN1hDizQn6MythkPWOTdJh0Cg984SEQVXlomoWwBg+t91PcKr7zzcs1cOUgI+Go8NcY2gVCYX2EUneUYETjnAF6kqxCEDX5o6yvinB+uh6bQUHTxHnqcfISDjZHeGSTH/9h3QnizApOo4JJB3EWBZcuTJrLRIJFxWVSqPFG2dUQYUNVGHcQkqwKVr1CKKrR4NfwhcFhAE+oyxvlNILTKOzRgBqvRjgKJh0MitWhVyEcFdU2U20qU9P0xJsVNMCsE9uWgIZZDyadwjv7g2yoiuA0gj8C9T4NuwHOTzcwzBkkLdbK9roIGjAhWY8/onGoJUquSyXe0iUkw1ENT0gjFBGvW6cqBCIanqB4HSYd2I0KZp0ot939PJ3Sc19/0TQNj6cNh+PU/Y9FNe24fwd95UQ/D2bOnLlZ07QJJ8WYb4C+rJHdxr4ILNU0bVH78z6tkWfz+ghnlr1nkq3Qu73/3BFgZ32E3GH/ZJ9/H3bVjifq4aH0h3DqnF+zpSf23o7Y8Udim7ajaFG2jX6QlphhfT43q/h1copf4VD2NSTVfoHXmkbhiCMipU+qvV83Z5KtcGbZe6rWyL544PrCe8CrmqYFFEW5CXgJOEbQ8tHRNO054DmACRMmaDNmzDghg1atWsWJzvF1cSbZCmeWvb3Zaqw0wsfQEobsERPJTrAB8MX+egpKmrh0VCq5iT3/6XZWtLD+YAMmvYpRr2LS63CY9azYU8srBaUA3DozHbvJwAc7q7jrosFs2LuftBiVX8wayN2Ld2DUq1x/ThZN3hBrD9SzoTrAuMwY/vTdkZR9sJLHp3iYOfMSAGbN0NhW3kxBSRNXjk8nxmo84nUc/dUJruj3Oybm++H8KBVNPuo8AUKRKEU1HjaXNOH2h2gLRCht9lHZHEEr61kAxqhTmTUkhUHJdopqPfhDEfQ6lQEuMzFWI7VuP8lOM9dOzqSwspV3tlQQaPeqaWhcFGNl5pBEJuXE9fDg9ZVLD7tZW9vqx2kxYDboOv8Wvsp78nXzbfkfk5wczub1Ec4se88kW6F3e1e1FrK1oZzvj/4+bxW9xe1jb+eWFbfgyHcwI7PnOX8v+Du5MbnMy533jdh6XDrO0zTG9uPmVb2vHldcDRS/Qs742bCpGJuq75MdZ9LfwplkK5xZ9p4qW/si4CqAjG7P09v3daJpWkO3p88Dj3Q7d8Zh567qr5ESyanAoBoACEUjfO/ptTz83ZHYTXp+8uImguEof/14HwNcZnIT7cwZlgzAH5ftIhQ5utf6pum5NLeFeHKlyFGLtRr48b82EYlq/PaSoSyYlEmC3cTgFAcZcSIcMRLVePPLMu5evIOf/GsT83QbuXTrEzBlOKSMRKcqjMuMZVxmHytmnSQMOpXsBFunqJ2al8D1U7N7jPnk05UMGj2ZsiYvNa1+suKtDE11YjX27b5Q0mAzMwcnnWzTe17DaT6l80sk9GGNPM65Mw47d9VJsUoiOUFsJh3eYISrB1/NgiEL8If96BU92+u3MzNzZue4cnc5/9jxD5IsSczNnotePVm+gVNAP8RbKBLisncu46qcedwx+FLImQ4734LmslNooETSN/ryX7YJyFcUJQex2CwAru0+QFGUVE3TqtqfXgZ0JJp8CPxJUZSOb58XAl9D8LREcnw6FpnJeTGsKjPys4WbURTIT7Lz/64Zx5r99RRWtFBY2crvlxQCcP6gRB753ij0OoVAOEogFMHtD2Mz6RiY5EDTNM7NTyA73kpOgo1fvLqFnRUtXD1JfL+b3S4EO9CpCgsmZbKxuJHFBRVMcdVAAKgo6NkT5zRErypkxlvJjO9bbpxE8i3luGtkL8g1UnLaYjXqiUQ1ghGR02zWmxkUN4gddT37wr174F0Aan21fFb+GbMy+xWAddqyr3kf7qCbt4rf55arVmDUGUX7gart37RpEsnxBZymaWFFUW5DLDQ64AVN0woVRXkQ+FLTtCXA7YqiXAaEgUZEtS00TWtUFOUPiAUO4MGOZG2J5JumwwNnMqh88MvzeHNzOav31vHA5cNJdpoZnOLoHLurspWShjYuHJ5yjOIUAkVRuGz0gM7n//rxRALh6FELlnTngcuGAzChul4IuGq5QEgkZwJ9WSMVRZkIvA3EAvMVRXlA07Thco2UnM5YjWLd8gYinSHtoxJGseTAEiLRCDpVR1SLsmT/EianTOZgy0EW7Vt0SgVcKBJCVVR0au9rar2vnsVFi/mPEf/RL4/g6rLVvLDzBZ6/8Hl2NYg6RM2BZj4t/ZS5OXOFgJNFTCSnAX36q9Y0bTmw/LB993V7fA/HuGuoadoLwAsnYKNEckro+FAPaSJP65pJmVwz6ehF0YcNcDJsQP+TthVFOa54A3CYDTx61Ria/tZe0q9q2/En37kYEgdD8vB+2yWRSE4efVgjNyHCI492rlwjJacltvZw+LagaDcCMCpxFK/tfY1X97yKO+gGoLKtkjvG38H+5v38Y/s/KGstI8OZccx5vyqapvHjD39MpiOTh897uNex961+lM9r3iPPMYILcqb2+RqLihZRUFvA1rqtFNYX4jQ6sRvsLNq3qF3AxUCoDcJB0B+Zky6RfF30qZG3RPJtRK90CbjTBYuvVjyo3gnRXuzSNHj3Vlj3ZN8n3/wifPmvE7JPIpFIJGcHVpO4+egJdPVKHZ04GoA/b/ozT217iqe2PYXL5GJW5iyuzL8Ss97M9R9cz6bqTUed83DWVqyluq0agIKaAv688c9omkYoEmLuW3N5a99bnWMLfYVsr9vOmoo1vTYVb/A28nm1aNz92s5P+vx6g5EgG6o2ALCuch27GnYxLH4Y383/LhuqN1DmLhNNvUE285Z840gBJzlr6fDAhU8XARcJYwrUgysDwj6oLzr22LZ6CHmhtbLv8294FjY+d+J2SiQSieRbT057Eav/+Ncmlu8QZQ4ynZk8NuMx/nXRv9h43UYWzV/Eq5e8iklnItWeysKLF2Iz2Ljxoxt5ZfcrlLaWcsfKO1i0dxEfFlYTCHett4daDnHzJzdz08c3Uemu5def/ZqXd79MSWsJuxt3U+GpYPkh4djWNI2PWj8CREjjodZDPWzVNI0bX9rEzQs388Dqf4ISQgvFsrV+Y59f7+aazfjCPkyqmVXlqyhqLmJY/DAuzb0UEOGVWNrTVWUYpeQbRgo4yVlLl4DrvTn0MQl64b07hJg6GbSWoxCFIe1lmHvLg2sWLQtwV/dtbk0T5zQVi8cSiUQikfTC8AEuXv/ZFOLsRm59pYC1++tp8YVYsy0VJZCLRW9hcNzgHuGSg+MG8/q81zk//Xwe3vgwl797OStKV/CH9X/k52++zUtrizvHLty1EJ2q42DLQS584zvUeGsAKKgtYEvtls7HbaE2vqz5kkOBQ1w39DoAttRs6WHrtvIWPtldy4d7ilhR+TaG4FDGxl6ITymlqO7Y66QnEOaq51bz8PLdrCr9DEXT01o7maKmIsLRMMPjh9Pc6sCmpPLy9g/Z527PPJICTvINIwWc5KzlhD1wlQWw+V9Q9PHJMahDlOXPBr259zy45hKxdffRA+dthKBHeO3a6k7MTolEIpGcFUzOjeeNm84hN8HGL1/fyjXPrefFtcVc848NLN9R1SOUMRLV+GJ/Pfe/W8Sebd8lOTqPPOtUFs1fDBEXlrRXWbhxL9GoRoOvgSUHlnB53uXEhmaj6N24grOINcfyz02f8PS6FSiohKNhZj7xPH/78mkcqoM7xt1BjCmWpzd8wudFYi0rc5fxyJp/Y4vbQtrwZ1F1fm4Z/XOuHj4LRdF4oUCs0Z5AmGc/28cVLz3JjH/cw+qiEn6xaBmFuv9mYemdvFq4nFBbLsm6rp7JHxToufzJL/A05VHu28mdy9o9fz4ZQin5ZjmNm3VIJKeWTgEX7YMHbv8KWH4X3LwGjCKspFMIdQivE6Vjnrg8SBrWNwHnbxGeQONxSvl3jAdoKgH7qe2/JpFIJJJvB1ajnieuHcflT36B2x/i8QVjeHFtMbf8u4Akh4khqU4sBpWC0mbq3AHsJj0Ts2OpbL6YL/e6ua++Hnf11diyn6aGD/l8/0Se2/4kgUiApOiFlO6vY1BuDvsOZZI7tJXiwE70+giKdyRY9uCzfsz2hhIuj7kcnWIk6sumKrybm15ex/wZ2/mo7C3CWhg1GeymNP4591UGxw0mHA3zm3UWPjjwOcrbY/hg/2cEYl9FNbSAEW5ZtQbUEHaTkbChkaDWxrS07/Dw7KuZ9eZTRDV490sfV4xNZ874q7nr8zV4nK3gQ3rgJN84UsBJzlo62gj0yQN3aDU0HoTGQ5AyQuzznGQB11SChoriShfX2LPs2GO7X9NdBfF5vc/dQ8AVQ8bEEzJVIpFIJGcPQ1OdvPrTKdhMOoakOLlwWAqLt5Sz8VAjh+rbqAxGGJsRw3fGpjFrSBJmgw5N07h/SSEvrSshP2k4QzMuYGX0C259cykMWEK0bQSPLG0iPdbB29ffwpxHV1NWlYI55UuiwO9mzmdNRSyrylehRSwYPFO4/dUt1NYNwJy8BTX9WZaXlGENnENL5SSeuHYMM/OGYdFbAHGTdmziJArqP2NJbTlKYjkZ9ix+M+VPGBU7t6+4kyjw6ryXsBosLNz5BjeP/QkOo4UfjbiGJm8b919/MQadii/sw6gaychzw044WFZO7phv9FfSL7zBMPXuIKkxZgw6GXz3bUAKOMlZS6eAow8euPr9YttS3iXgOj1wJUc/p780lxIwxWPWGSAmC7wNx/au9RBw1X0QcN3GNxWfFHMlEolEcvYwPiu287HFqOO6yVlcNznrmOMVReH+y4YzKMXB6PQYVHMiK8tWQOqTGHU6/vGdP/HqulYuGz0Am0nPvfOG8fS6Og6xFIAxSWPQ0FhVvgqTdzr/2qdg0NVw3fTpvFW1DM1YTk70p1iYwKUTXFwyeNgRNjw2+0Fe2f0Kq8tXMzLhSu6acBdWg1hTP7v2fULREA6j6Pn6X5Nv7zzvron/2WMei97ChJQJVHr2EkXhvQ2FvFH4KWMyYhg2wEms1Uh6rIVzByawr8bN06sOYPYFGT8lhMNsOO576wtGMOgU9DqVlXtqWbm3ljvnDMZlFeeGIlG2ljUTZzPS2BbkhTWHMOpV7pg9iJwEG63+EMu2V1HS4OWcvHhafSFW7qklFNXwBSOs2V+HPxRFpyrkJ9mZmB3HhOxY4m0mXv+yjK0HfWQf2EB+koPRGS5CEY19NW4+2FlNJKpx7eRMpg9KJCPOikmvUtHs44Od1Wwra6a8yceQVAdXjE0j1WUhqmmUNHjxhyJYDDpq3H7q3UFyEm0k2IyUNnppaAviD0VIdVnIT7aTn2SnLRjho8JqvMEIsVYjtW4/lc0+2gLivcmKt5FgN2I362luiZBd38YXB0ReZkaslXpPgJIGL4OSHYxKd5HiMmM26AiFo4QiUdyBMPuq3bj9YcZmxmDQqRTVeiiqdVPV7CfGaiAr3sZ5+QmEoxrby5rR61RirAZiLAZCEY3Sxja8wQiKAnaTgVirgRirAb2q4gmEOVjfRkl9G/nJdsZnxZHoMB33d/9VkQJOctbSryImDR0CrqxrX1t7yf+TFkJZgt+chBlEJUqA1gpIyD/K2FJIHAJ1e4QH7ng0lYjyx3pzl4BrKafeYKa4tZgJKRN6PV0ikUgkkv6iKEo3kedi2oDzWFP5Ob+a8N+MT89h/Pe7xl48MpU5w6/k3FcfQ1VUBsYMJMWWQrm7nDGOK/m/T/bywIJppMcZCa29jJkZM5mdNbvX68eZ47ht7G3cNva2I46Z9WbMYsXtE1MHTOV/v/xfaqyxzI4zUmSNYWtZM8t2dK3BaTEWalr9GPUq3mCE9x5awaAUB/lJdvIS7TR4AuysbCHFaSYv0Y5Op7CjvIVPdtfgshgZne5ixR7x3WJNUT23X5DPnmo3iwvKqXUHOq8TazUQDEdZtr0Kl8VAiy9EOKqhKvDM6gMAxNuMuCwGNOCqCRkMS3VS1uRle3kLiwvKWbhe3Hx2mvXkOBRafSH+vaGYT9dWUqIlo9fpOHdgAqFIlL98uJe/fLj3iPdkYJKdVJeZjwtrWFxQ0ef3si8oCiQ5TDjMBnzBCO9uq+xRg+2BdauOOMekVwmE+1+YzmUx4PaHiJ7kGm8F9845uRN2Qwo4yVlLVyPv4/yzRyMifBKEB66DjuqTLeUQCYPuBP+dmkvxWwaLx672nr8tZUcKuI6KkqOu6ruAay6F2CzQW4THcP8KePm7vDD4HP4dquLD731Iii3lxOyXSCQSiaS7Z03uAAAgAElEQVQXfjvlN3xY/CELhiw46nG9qu8UZTpVh8vk4q6Jd4lj1cWdrQ0emvbQ12NwNzpudG5xOLkkNsoT3xsHiOIoHn+YL0saeX1TGecOjOfui4fy7iefU6KkUFTr5rN9dSzaXI5RrzI0xcGGQ428s1UUIYuzGbluchaVzT7WHWjgxmk5zBySxC9e3cIdr29FVWBafiL3zU8nGI4SiWpcOioVTyDMC2uKcftDxFgNzBmWwuBkBxuLG7FrbYx1r0IdfDE4ko94LeFIlD3VbsqbfJw/KIGC1e8zLbmK6PqnUSs30zboCtQrnsFiEQK3Yv82DtS4ORhwMebgs6R498C1r5GSkAAID+KGQw20+EIAZMXbsBl1+EIREuwm4mxGDta10ewNkhFnJclpwqCqVLb4KKr1sL/GA8CcYcmkuMw0tgWJsxkxG3SdNgfCEdz+MM3eEG9/up7U7Hym5MaT6jJT2ugl3mYk0WGipMHL7qpWat0B/KEIRr2KQadiMejIT7ZjNerZUtqEpkF+sp28JDtOs4FIVHgd1xTVo9cpjMuMRVUUmn1Bmr0hVEUhK96Kw6wnqoHHH+48FopEsRr1ZMZZyYq3srfGze6qVuJsp67ZuxRwkrMWVVFRNQhp4d4HNpdAVHwo9fDAedo9cFpEVIOMyfzqxoSD0FqJP/Y88bxTwJUfObatDsJ+SB4BBhu0HkXANZeBLREM5q7XkDhYjC/5AgrfBtXAweb9RK0W3tz3Jr8Y+4uvbr9EIpFIJMch3ZHODSNv6HXMNyHO+sKQ2CHYDXa+NEe55MBK2PgPaK3AfnAVdnsy8waMY941PwVrHAA5ToWfjDBA4hQAWv0hTHoVk16IEn9I5N8bdSqqqhxxvU9+NZ2KJh/5STbMxiO/rluNeu6+eEjPnZrG9Jr/g88fg6Abdr8LP1gs3Fnd0OtURqS5GJGgg2W3ce6214EoamwOjPkBtq0vw2IvXPb/4NBq0t6+iTQtyvk6I0SCYpLCF+D8/4Ltr2NJG8+MwUeJFurGsAHOI/alx1pJj7Uyc3DPwmoDYixHjDXpdZjsOhLsJiam6JkxpSt8d2hq19zZCTay24X+sRiYZD9in05VGJrq7DHXV2VcZizjMmOPP/AEkAJOclajVxTCzWUQ8oGh/QOjw0ff8YHXIMIRMNgO88DVgTUBvPXCw9Uh4ForwRoP+n7EPldvBzTabO2hk84BoKhHF3AdIZsxWeBIOdIDF43CM9MgLkd8cFtixTn5F4oKmttfh73vw9D5lAR2Q6SNxfve4uZRN2PQHT9WXyKRSCSSsw2dqmNc8jg2NRZB2CYqUys6yJwibpru+xDWPQFzHoQJPyH34EJYvRjOuQ1m3YvzwAci9SFpCFRtw7ziD9BQBGYXTLkVBoyFSADiB4LBQlykgbj9L8Erz8HAOTD/cXFTVtOgcgsYrGKuDqJRWH4nfPmC6CcbnwdfPA47FombwlVbxfccd7WI3kER1a6bDlGefikZF90OaeNB1UHaWHj/bvj7WNF+KHsajPguVO+A0dfC2sfF3O4qcT2zCxa8IsZJvhakgJOc1eh1RsKRFtj5Foz9gdi57E4o3wQ/Ww2qCvVFYn/2NKjZ2XVyW53Yt++DLlEV8sOTU2DKz2HmPX035OBKAJpjRornOgM4UsWicDgdRVNiMoXQO1zAearB3yw+4F+aD9/7p/DYxWa3t0DQwFtPMP9CKrdtZkQgwE4aWFG6grk1h8QHf0zG4VeVSCQSieSsZkLyBD4r/4z66z4lobFUCKOOEMWaQvjwN7D0DqgsILNssRBj654QIifkBZML5j8G7/83oIjvELW74e2fdV1ENYhWP63tOWUZU2D7awTq97ArIZtQwz4mVewS50+8Ac67U+S3v3ML7Hsfzr0DZt8PWhSK14i5e6SKKOIGr6ITIvBHSzhQEiEjY1LXkIk3Qu5MWPGgOPeKZ3sWVLvgftizXLyu0ddCxZfi+4YlTtzAThkh0k/q9oj3KHkEeGrETWlfs/iO4m+FhIFCNNqTxM1mS5z4rpI0VNxY72jXYI4BW3zPX4amiaiocADicsVN746b8cqRHk0CbmFTB0a7SH2pKYSyDZB3gUg10TTRO7e1QtyQ9zaIOR2pQmQbDsub9DZCsE3Yb7SJa7troH4f5Jx3nL+or44UcJKzGr3ORNgSBxuehTHXiX/kL18ANNj/MQy6SBQwMbsgdbTYFwmJn6BH/DPv+7BLwFVshkALHFzVTwG3GpJHEjK6uva50nuGbHbQ1CHgMoQHrnzTYceLxXbq7bD+aXjjR+3jM8Ekqm2h6ilPHUJ0m8Y1rR6eTEtmyZ7XmbthsXhd5/9X322XSCQSieQsYGKKaMHzZc1mLsi6oLOataZpNDiT8c1/FP/yX+Hf+RpNMZkolz2Cf+9y/PV78KeOxrJ7KUlLf84YxYr6kw94qeYLajPyuSX2d7iCflBUKsrW8krjVkK5oxiTM4dLRt/AhvWPcvvuF/C6G8EIb15wN0M8zbDxOdj0vBCGIS9c/AhMvkkYq+iovvBB3vvsXq4efDXOYd8VYscSCyY7/rCfOm8dGc4MKFl15IuNz4OrXjr6G5EwEC56SNQCmPlbIcg2PCNubLtrxPcSRRUex6YSOPCpEECudPHdxTJKiMeaQtj6ivjecTwcqULcWeMZXV0MBU1dIldvFkIzEhTf1xIGQcZkEQlVvUP8HH6zW9WLVJPu+10ZIj0mEuCo6Izie5fBKt5LX6Pox9s5p0EcC7QACtxzlCiqk4QUcJKzGoNqIJw8FAqWiQ/BfR+A2SmKfax/ul3AFUF8vvjQ0aLin70jzNKZJj5UOkRV6VqxrSwQ3rjud2oiYXh1AeTNgnNu6dof8kHZRpj0057GudKhouBIo5tLxF0qk0Ncu7Xdno47To2HxHb8j8WdsE9+L57HZInXBpA1leKAuLOVGwxxrjmV9xt2EgF0Hf3tJBKJRCKRdDIkbgg2g42HNjzEf3/+30xMmci1Q67l+R3Ps6N+R9fAtPaiYKvu6NpXWgo2wJZMnMFB4vrfsbdpLwoKH1k+5uHzHmZ88nh+Vfw6+yINmLweXt36N7b5a3nv0Hukxg7k52N+zgPrHuCJYAVPXPwETPoZFC4WAuXcX6INGMfSA+/RGmxlePxwfr3pQaqi9bxXuZzfZoyluq2ayrZKyt3lrCxdiTvk5rK8y5gW7Qp9DEfDaJqGqqjoVB17G/dyz5p7MKpGZmTMYEf9DrbVbSMYCRKOhom8vIg5WXO4Z8o9xFsO85J1EI2KiKZjEQ6Ar5nG5kOYm8uxNh4S3ixrnBCCnloRAdVSDg0HUDQFMs8RIs1oJVS9k91RD3sJkhDwMai5irSN/4BoWIjInOmiDoC+4zuZJjxrzaWQNkF4QvcuF14zR6r4buccILbWOGFf40EoWy8EaqhNfE80u4Q302gXItbXBAGPEL8pI4XgO0VIASc5q9GresKx2cKFv1xUumL2A+Kf/tM/iNCGhgOQfV7PwiK69vw2W6JwuXd44ErWig+bSFDEm2dO6bpY7S7hwdv/sQglmH2/EF2l68XdntwZ0L0Krysddr/X84MvEhYev/T2sv+OVHGur6kzcZqmQ8IGVwZM/QUUfQyl6yAmg7Bq4I7sQXx/4DRKWoXozNRZGBfV82bET5HRwBBPzUl9jyUSiUQi+TagV/VcmX8lW2q3MCx+GMsOLuOXK39JvDmeX43/FfGWeMw6M2a9mT079zBl/BRMOhMWvQWTzoQv7KOktYS3it5iX9M+/ue8/yHHlcNv1/yWn3/yc85PO59dDbv46/S/MitzFr9f+3te2fMKceY4npz9JGn2NMrcZTxe8Dhv7H2DQy2HKPIX0Wz2Mq36cyoPvM77h97vtDfWFMu9U+7l71v+zo0f3dhj/4yMGcSZ41i4eyFLtaU88sYjhKIhWgLCo2RUjYxNHsuOuh3YDXbiLHE8ufVJBtgGMDtzNjaDDYNqoC3UxltFb7GmYg2JlkT0qh6dokOn6tCrekYljGJ88ni212+nylNFuiOdcDRMaWsppe5SmgPNDI0bSjgaZn3VemwGG5fmXkqMyYInUIw76MYT9OC2BvHorfhcieCHFKdKU81H1PnqaPI3odGtB4AOzpl0Gd/Jm8+ktHPZUbeD1eWrafAdojXQSkugBYfRQf6AfMKRSup3PkW9rx69Wc+UhEQa/FV8UbiIGFMMuTG55LnyiLPE4R2Qx7Y6D1tri3DpXSQZVQItm9A0DYveQlgL48OHt+YA3vJ3WJa57NT9LZ6ymSWSMwC9qicMcMMnIna8ZK0IPwh64bO/wMvfa+/FNrCrN1tLeVcooj1RhCaWrBPiqmwjDL0Mdr0jRJMzTXjjhl0utgCDL4Uv/gaDLxYC7+Aq4crPPEfEkXfgyhBCsK2uK8Z+3/vCA3jpo/jCPgz2RPFP7K7qEnCNh4T407ff+VnwsghTMNrYWLGW1Yofv6eIdMVHnDkOZ0ws47wifKHAZGJIm/TASSQSiURyNDraGgDcNPomPi39lLk5c3Eae1YvjO6PMipx1BHnZ7uymZ4xvce+ly5+iVs/uZVPyz7louyLuDD7QgD+cO4fGJ04mjFJY0izpwFw7ZBrWbhrIX9Y/wfMOjODYgfhMrl4sfBFolqUX477JTPSZ7CidAUXZl9IjiuH89PPZ0f9DvJi8siwZ/QoWDY3Zy4vfv4itmQhyOLN8ehVPY3+RtZVrmNkwkj+dN6fSLIm0eBrIM4ch3JYjtmCIQtYuGshbaE2IlqESDRCRIvgDXt5Y+8bvLz7ZfSqnmRrMp+UfIKqqGQ4MshwZjAsfhg763cSjoa5ceSNVLVV8VbRW0SiEewGO3aj+HEYHCRaE7HoLRRXF+MNeUm1pzIycSTx5ngGxQ5iaPxQmv3NrKtaxxt73+C/v/hdp41Oo5NUWyouk4scVw5NgSY+KvkIk85EgiWBRGsi7qCbF3a+gFlvZuqAqfjDfrbXbe8hipMsSUxKnURbqI16bz0WgwVFUWgNtqJTdNiNdpKsSVgNViJahFOFFHCSsxqjzkhbqE14uIZcKn5AJKxe85pIPm6rE0nETvHhSXOpSLgF4YGLyYQdb4rwy6AHhs4XgqlkLex6VxQTuXOvyI8zx8DlT8Ajy+DQ510CLn0imA4ra9tdMHYIuE3/BGca6+0ufvXGBcxPmsg9AC0VkDxcjGkqhticzmmiZhdNyUOJB5YdEneDNtVsos5XR5YzCxRIrdlJskOlwGzi2o72CBKJRCKRSI5JgiWBqwZfdcLzOI1Onp3zLG/vf5t5ufM696uKesT8VoOVpy54iqq2KqYOmIrVIIqL1Pvq8YV9ZDjEd4eBsQM7z0mxpRyz1+uIhBHMi53HjKkzjmvnsUIk82LyuH/q/Uc91hZqY0/jns7w03A0LNo4KccOqXzw3AfRKbpjjlm1ahUzZhzd3gxHBiMTR3LDiBsobChkU/Um8mLyODft3M6cxd5oC7VhUA0Yu4U/ekNeWoOtWPQWnEbnEQL2m6CXgFSJ5NvPmMQxbKjegD/sP/Jg3kz4wVvwu1pRSchoFTllLeVdPeBsiTDy+yL++c0fi31ZUyFzMhR9JMQbiMcVWyBtnPCUJQ0X/djcNSLUcuAFAHgiHhbuWkg4Gu7ZzFvThOA7uJLlg6fz809vwxv28nb1WtxGG+xeAojY9c/aSrnP6Gdj1UYAntjyBHMWzWFT9SZWlK5gdOJoolqUgy0HhYCLzUZpLmOc388WswlNCjiJRCKRSL5WrAYr1w29DpfJddyxwxOGMztrdqd4AyEmO8Tb6YTNYGN88nhsBtGbTa/qexVvIOoTHG/M8dCpOkYljuKGkTcwI2NGn8Rbh73Gw3LXrAYrKbYUXCbXaSHeQAo4yVnOJbmX0BZq47Pyz2jyN/HG3jeI9ii3CygK/rCfrbVb2ytDlovKS0aH8NQlDoYF/xb5bLHZIvE18xxxbv5F4EyHwndEDlzaeLE/a6oIt9z3fuc4TdP4d8O/eWTTI6ypWNMl4PYsFX3dXprHJzGJ3FO/ljFJY3hmzjP4In6WDTwHdryJ1tbALz75ObfGmnk7WMUfN/wRb8jL63tfJxQNcfPHN9MWauPWMbeS68oVZrQLOCJBxrV5qNXrqYh4RAEWiUQikUgkEslphxRwkrOaickTSbAksPTgUu7+/G7+sP4PrKtc12OMpmn8Zs1v+OH7P+RTZ4xofNlSJvLfOsg5H374Nlz2hHg++BLRG2X+32DQhXBgBVUq/KhpgxBnWVMpUMM8t+lRcAyAlJEsObCEnb6dKCgsP7RcVDcyOmDHm4QCrSw850f8V7yDkYkjefKCJ5mSOoWhcUN5Q+dDC/t5c/XvWFO1nl82NvOnnO9xqOUQv/7s17QGW7lrwl1oaCRaEpmUMom52XMByHZmCwEHjPWLsrmbzGZok144iUQikUgkktMRmQMnOavRqTrmZs/l5d0vAyLefOnBpZybdm7nmPcOvsfHJR9j1Vt5iEYmeutw7F0u8tba0TQNJburDC/WOLjiafE4/yKaCl7kZylJFHuKeX3v60yb+FuejXGy1qJxYco0YoOt/Hnjn8kz5TEmcwzLDy3HG/ZhHX89+wMN/Ge4jOLqVUwdMJW/TP9LZ9jE9wd/nwfXPcjt2YPYULuGKc5cbji0iujAy3muYTOry1eTH5vPj4b9iCFxQzrLAl+RfwW7G3czIXmCaEIJ5IdCZBljeMUZ5DvuWpSYzFP75kskEolEIpFI+o30wEnOei7JuQSA6enTuWLgFawoXYE35CWqRXln/zv8acOfGJc0jn9c+A/qQ25uy87n0RgnBy2iEuXCXQu5ZPElNPgajpi7JdDCM21FXJmWSpVBz7ikcWyo2kCTwcQmiwWAZXYb7+x/B3fIzZVxV3JJziX4wj4+q/iMtSMu5Uee7XjCXp684Ememf1Mj0pX83Pn8/1B3+eA2YY1EuHB4j0ogC4ujxtHipLB1wy5BkVRmJw6ubMJaYothb/P+jsx5hhRLEXRoRrt3Djwe+wxGfm8fPWpfMtPO3xhH4X1hTT4GtA07fgnSCQSiUQikXxDSA+c5KxnRMIIHpvxGJNSJ7GvcR9vFb3F/+36P9ZUrGFb3TZGJY7iz+f/mRRbCr8a/yv+vfNfbHc5WBIu5t7SFTy6+VHC0TBPb3ua300RJWs1TeP9Q+/z501/ptHfyDmWZG6OGYln5JXcuuJWntjyBCEF4iJRlrXshdZ9jE0aS7oxnfHJ40m0JHL/2vtpC7WR58rjqdlPMcA+4AjbzXoz951zH5xzH3xwD5Q9JQqtmJ3Mz5tPnDmOqQOm9v4G6Awi384ax6UDv8Mz257l2bIPOW/Kr06bZN2+EI6G2VK7hYPNB5k6YCql7lIe2fQImc5Mbh59M0ublvL00qdJtCQSjAQ50HyALFcWoxNH83bR2zT4uwS4TtGR7kgn05FJcWsx9b56XCYXmY5MRiaMJN2RjtPoJKpFCUVDhKNhvGEvnqAHs96M0+jEaXKCBjXeGvSqHpfJRSQaIRQNYdQZxY9qREMjHA0TjoY759rp3kn1nmpC0ZD4iYQ6H3uCHpoDzZh0JpwmJy6jC4veQkSL4A66aQ40oygKRtWISWfqvFYkGsEf8ZNkTSLZmkw4GiYQCXT+hKIhHEYHFr2FRl8jwWgQi95CW6iNJn8TFr0Fi95CIBLAH/bjj/iZnj69l9+IRCKRSCSSU4EUcJKzHkVRmJ01G4BxyeNItaXy5NYncRqdPDTtIeblzuushnT98Ou5fvj1HNz0DD/Y9yJ3rLyDREsik1Mns2jfIq4dci25Mbm8vPtlHtn0CCMTRvLcnOcYHDcYEJ4eo2pkUdEiHAY7vxh6FQ/sfgGA28bcBqUirHPBkAUsLlrMLaNv4cpBV/aoNHVM5jwo2hfozYAIBz0v/by+vQnT/hPMTgyOVG5oaeFBg56/FfyNO8bdcdJFXDga5qPij7DoLUxMmYjdaMcf9rO3aS9rK9eyvnI9ybZkRsSPoN5fT1lrGaXuUsw6M7kxuSRYEjCoBio8FZS5yyhzl+EL+whFQgSjwR7XynBksLFqI6vKVgEwLmkc1W3VqIrKpNRJ7KzfyfM7nmdiykR+nf9rGv2NtARbCEVCFLcWU+ouZUjcEFJsKbQEWtjfvJ+XCl8irIVP6ntyVDYcucuoGrEZbLhMrs6Gq56Qp/O4XtELryoQjAQJRoIEIoHOBqd6VS8qnPYTq96KP+InqkVRUDDrzZh1ZjIdmWQiQ20lEolEIvk6kQJOIumGqqjcOuZWvqj4gjsn3EmyLfmo43In3szjGeO594t7uW/KfQyJH8KqslXcufpOLsm5hCe2PsEFmRfw1+l/RafqOs/rEC3/v707j5KrLPM4/n1q6U4n3SSdFSYdSAIBSYSExeiBhAkiElDJjGzxCILCRERcz4zgMON4XFDkOKMI4wqKihNHHTSjgKxxIBIISwIJIdCEELKQrbPQ9N79zB/v7aS66epUSHdXvcnvc849fevtW7d+datST56+t+5dtGERM2pmcta0K/jGql9SVVbFmUecyaK1iwCYd/w85h0/b9/Cp7PhRCq8hYbr5I/unj2vNcvKQTXctvw2NjVs4rIpl3FM9TFYcjbO2h21PLj2QZZtXcaLz7xIylLUNdWxvWk7dU111DXVMbR8KGcecSbLty7n/rX3M23UNGaNm0UmlWH+8/NZWbdy9+NlU1navX13c3DsiGNZ8toS7n75brKpLDVVNYyrGkdzWzOPrH+E7U3bafd2Rg8ezbiqccwYO4OqsirSlmbqqKlMHDaRh9c9TCaV4YKjL2BH8w7uWn0XmQ0ZLn7vxV2etruzvXk71eXVBTeqLe0todFr3kkmlSGbypJJZRicGcyQ7BCa2pvY1bKLXc27cJzRg0fT4R1sb9pONp0la1laO0Kz2dzejGFd1pNNZVny2BJmnjqTsnQZ2VSWbCpL2tI9Zuzck5a2NOXp8jct4+5drrtT11THlsYtlKXCnrnydDnlmXIylmFXyy4a28IF3svSZTS2NTIkO4TydPnuvY1lqbIuj7Fw4cKCtpuIiIj0DTVwIt3MOWoOc46as9fl3nHoO7jnvHt2375+xvXcsOQGbnr6Jo6pPobrZ1zfpXnrNLNmJos2LGJWzSyqyqq4Zvo1VA+qJpsu7Bolverh8fZ5FZWj+VcfwbDjzuanK37Kn1b/aXcT0dDWAIRDDCtTlTz+dLjWXEWmguryaoYPGs7IipG8susVvrr4qwxKD+K0mtNYtmUZD69/GAjXqrnxb29kxKARPL35aRpaG8ims7yt+m1MHT2VkRUjcXe2NW2jurz6TdvQ3Wnztl6v6dJ5mQSA0YNHc9nbL2Phlodg/VPw0gPhe3/HX4SZMXzQ8D13rN8Cq/4Eax+DSWfC2z8YLvdQtxqmzgXCxd97uyhqNp2lqqyKsZVju4yPHjy6wFcAajO1jKwYWdCymVSGTCr/R7mZdXlvjagYkfdirN339FZkKnbPpyxFebq8oEwiIiLSf9TAifSR0w8/nZk1M3l0w6NMGTkl72GPHzjyA+xs3sm7D383ABcec+FAxty7yjFYw1Y+feKnuWTyJdz3yn1sqN9AS0cL1eXVjK0cyyl/cwpLFy9l+qnTgTf/x9/dqd1Ry6iKUQwbNIwO72DjGxtxd0YNHrW7Eeg8qUp3Zpa3gTEzspaFlgZoqYfKHhqjtpbwu8FJc9bayOTnboS/LNqzzIan4e3nw9YXwgXWd6yFOz8OjdshOwSW/QoWfTdcaB2g+XWY/g/7sCFFRERE+p4aOJE+lEll9vq9s0PKDuGqaVcNUKK3YMio3U1L9aDqXhvMfE2qmTGpetLu2ylLvWmP1H554V744+egYRuccyOccHG4kDrAtpfgjgtg+8sw8XQYcRS8upjRW5bBrH8Oh4s+8h1YfAs89oOu6x1zHHzkDzB6Cjz87bDMjM/D5pVw9zWQyoRr/FX1fGjtAc8d2lvDnt4+2NsrIiIi+04NnIh0VTkmHErYX9xhzSOQLoPDjg/XoWveBYNHhqagpT7s7Wru/LkrjKXLwvTU7bB6IYx6GwyfAAuuhvv/DVLZcHH1HWtDo/Wuq2Dl/8L6J6BiOCsmf4Eps64JGWZfDxNnQXsLjDgS1i4OjzN9HmSTwwZnXQN/+4XQGDa/Dj97H/zxs2EaMipcAD07GPA9WVvqQ47soLCeTEX4bmK6DCwFuzaEPXzV46Hq0DDWsA3qN4XHTGUgnWVafSOsGRHum8omPzNhPQAdbVBeFaY3tkJrQ7jwe0db2J7eEZZPpUN+9zDWObU1h+XamyFTHk58kxkEHe3Q0RrW094W5tuaoLUxTC1vgLeDpUP+GZ8DJiEiIiIDRw2ciHRVOQpaXg+HKJbt5eyXHR2hQejpBCBNO2H9k7BlVWhmKqqh/BBY8hN4/o/7kW8MnPlVeOfHQ5PyxG2w+bmwZ6h+MxwyFmZ/A4ZPhLO+vvtuW7qfbOPo9+6ZH31sz4/V+bzKq+CKB2HjMlj7KGx5Hna8EhohCJduqB4ftldHe2h2Ohuf9lZo3RmaomGHw2FTw97B154NzVBFdcgKSePUir/REuZbG0MT1d45tYRMqUzS3L4eHjs7OGzvdDYcNmqppBlrT5q5pJGzVJhSGRg6NjRt7S1JzpawXKZ8T+OYSofXLlsRHqOzKW1rhF0boeowaHjrL6WIiIjsOzVwItJVZXJ44INfC//pf+HPYc/PhJkw4TQ44hSoqKa6bil85yoYdgSc+z1o2hEOvaw8NDQ5S24N/9HvLl0eLnkw/EjYtDzszRo0NOyJ6mjfs2cpdyqrDA1GQx0celzYw9VpoL6Xls5AzUlh6mfLFi5k1qxZ/f44fWLTwmInEBEROaiogRORrmqmh++NPfb9cKjchJlhL86TP9vznbGK4UxtrAtN2OYVcHO3psZScNyF4Uo/FoYAAA6ASURBVMyNY6aEvUeNdaEBGz4h7IkCOPb9+5ZtxJH7/fREREREYlZQA2dms4HvAmngJ+7+zW6//zxwBdAGbAE+5u6vJL9rB55NFl3r7uf2UXYR6Q+jjoZPPRnO5NjRtucwyrZmWPcErFsC29ewZmsD4y/+LjTugCU/hpFHh71zb2xNDik8out6h/bhSUxESkgBNbIc+DlwErANuMjd15jZeGAlsCpZdLG7XzlQuUVEJE57beDMLA3cApwJrAOWmNkCd38uZ7GngZPdvcHMPgF8C7go+V2ju0/r49wi0t8yZUBZzu1yGH9qmIA1CxcyvvP7UWd8ac9ynXvXRA4CBdbIy4Ht7n6Umc0FbmBPjXxJNVJERPZFqoBlpgO17r7a3VuA+UCXqxy7+0Pu3vlV9sVATd/GFBERKUl7rZHJ7duT+d8CZ5j1dOYfERGRvTN3730Bs/OB2e5+RXL7EuCd7n51nuVvBl5z968lt9uApYTDK7/p7r/Pc795wDyAMWPGnDR//vy39owS9fX1VFZW7tc6BkpMWSGuvDFlhbjyxpQV4sp7MGU9/fTTn3T3k/sw0oAqpEaa2fJkmXXJ7ZeAdwKVwArgBWAX8C/u/nAPj3HQ1keIK29MWSGuvDFlhbjyxpQV4srbbzXS3XudgPMJx/R33r4EuDnPshcT9sCV54yNTX5OBNYAR+7tMU866STfXw899NB+r2OgxJTVPa68MWV1jytvTFnd48p7MGUFnvC91IRSngqpkcByoCbn9kvASKAcGJGMnQS8ChzS2+MdbPXRPa68MWV1jytvTFnd48obU1b3uPL2V40s5BDK9cC4nNs1yVgXZvYe4DrgXHdvzmkQ1yc/VwMLgRMKeEwREZEYFFIjdy9jZhlgKLDN3ZvdfRuAuz9JaOyO7vfEIiIStUIauCXAJDObYGZlwFxgQe4CZnYC8ENC87Y5Z7w6OfsWZjYSOBXI/WK3iIhIzPZaI5Pblybz5wMPurub2ajkJCiY2URgErB6gHKLiEik9noWSndvM7OrgT8TTpF8m7uvMLOvEHbrLQBuJBzL/5vke9mdlws4FvihmXUQmsVvetczc4mIiESrwBp5K/ALM6sF6ghNHsBpwFfMrBXoAK5097qBfxYiIhKTgq4D5+53AXd1G/tSzvx78tzvr8Bx+xNQRESklBVQI5uAC3q43++A3/V7QBEROaAUcgiliIiIiIiIlAA1cCIiIiIiIpFQAyciIiIiIhIJNXAiIiIiIiKRUAMnIiIiIiISCTVwIiIiIiIikVADJyIiIiIiEgk1cCIiIiIiIpFQAyciIiIiIhIJNXAiIiIiIiKRUAMnIiIiIiISCTVwIiIiIiIikVADJyIiIiIiEgk1cCIiIiIiIpFQAyciIiIiIhIJNXAiIiIiIiKRUAMnIiIiIiISCTVwIiIiIiIikVADJyIiIiIiEgk1cCIiIiIiIpFQAyciIiIiIhIJNXAiIiIiIiKRUAMnIiIiIiISCTVwIiIiIiIikVADJyIiIiIiEgk1cCIiIiIiIpFQAyciIiIiIhIJNXAiIiIiIiKRUAMnIiIiIiISCTVwIiIiIiIikVADJyIiIiIiEomCGjgzm21mq8ys1syu7eH35Wb26+T3j5nZ+JzffTEZX2VmZ/VddBERkeJTjRQRkYG01wbOzNLALcDZwGTgQ2Y2udtilwPb3f0o4D+AG5L7TgbmAlOA2cB/JusTERGJnmqkiIgMtEL2wE0Hat19tbu3APOBOd2WmQPcnsz/FjjDzCwZn+/uze7+MlCbrE9ERORAoBopIiIDqpAGbizwas7tdclYj8u4exuwExhR4H1FRERipRopIiIDKlPsAJ3MbB4wL7lZb2ar9nOVI4Gt+7mOgRJTVogrb0xZIa68MWWFuPIeTFmP6KsgB6qDvD5CXHljygpx5Y0pK8SVN6asEFfefqmRhTRw64FxObdrkrGelllnZhlgKLCtwPsC4O4/An5UQJ6CmNkT7n5yX62vP8WUFeLKG1NWiCtvTFkhrrzKGpV+r5EHc32EuPLGlBXiyhtTVogrb0xZIa68/ZW1kEMolwCTzGyCmZURvnC9oNsyC4BLk/nzgQfd3ZPxuckZuCYAk4DH+ya6iIhI0alGiojIgNrrHjh3bzOzq4E/A2ngNndfYWZfAZ5w9wXArcAvzKwWqCMUMJLl/ht4DmgDPunu7f30XERERAaUaqSIiAy0gr4D5+53AXd1G/tSznwTcEGe+34d+Pp+ZHyr+uxwkwEQU1aIK29MWSGuvDFlhbjyKmtEIqyRsb1mMeWNKSvElTemrBBX3piyQlx5+yWrhaM4REREREREpNQV8h04ERERERERKQEHXANnZrPNbJWZ1ZrZtcXO052ZjTOzh8zsOTNbYWafSca/bGbrzWxpMp1T7KwAZrbGzJ5NMj2RjA03s/vM7MXkZ3WxcwKY2TE522+pme0ys8+WyrY1s9vMbLOZLc8Z63FbWnBT8j5+xsxOLJG8N5rZ80mmO81sWDI+3swac7bxD0oga97X3cy+mGzbVWZ21kBm7SXvr3OyrjGzpcl4sbdtvs+skn3vSn6lXCNjq48QT40s9fqYZIymRsZUH3vJW5I1UvWxQO5+wEyEL5C/BEwEyoBlwORi5+qW8TDgxGS+CngBmAx8GfjHYufrIe8aYGS3sW8B1ybz1wI3FDtnnvfCa4TrZ5TEtgVOA04Elu9tWwLnAHcDBrwLeKxE8r4XyCTzN+TkHZ+7XIlk7fF1T/69LQPKgQnJZ0a62Hm7/f7bwJdKZNvm+8wq2feupryvZUnXyNjqY5IzuhpZivUxyRVNjYypPvaStyRrpOpjYdOBtgduOlDr7qvdvQWYD8wpcqYu3H2juz+VzL8OrATGFjfVPpsD3J7M3w78XRGz5HMG8JK7v1LsIJ3c/f8IZ6DLlW9bzgF+7sFiYJiZHTYwSYOe8rr7ve7eltxcTLhuVdHl2bb5zAHmu3uzu78M1BI+OwZMb3nNzIALgf8ayEz59PKZVbLvXcmrpGvkAVIfofRrZMnVR4irRsZUHyGuGqn6WJgDrYEbC7yac3sdJfzhb2bjgROAx5Khq5NdqreVwiEXCQfuNbMnzWxeMjbG3Tcm868BY4oTrVdz6foPvBS3LeTfljG8lz9G+EtSpwlm9rSZ/cXMZhYrVDc9ve6lvm1nApvc/cWcsZLYtt0+s2J+7x6sonltIqmPEGeNjKU+QryfMzHUR4ivRqo+Jg60Bi4aZlYJ/A74rLvvAr4PHAlMAzYSdhGXghnufiJwNvBJMzst95ce9gmX1KlMLVxM91zgN8lQqW7bLkpxW+ZjZtcRrlt1RzK0ETjc3U8APg/8yswOKVa+RBSvew8+RNf/XJXEtu3hM2u3mN67Uvoiqo8QWY2MtT5C6W3LfCKpjxDRa59D9TFxoDVw64FxObdrkrGSYmZZwgt9h7v/D4C7b3L3dnfvAH7MAB/SlY+7r09+bgbuJOTa1LnLN/m5uXgJe3Q28JS7b4LS3baJfNuyZN/LZnYZ8H7gw8kHE8mhFtuS+ScJx8wfXbSQ9Pq6l/K2zQAfBH7dOVYK27anzywifO9K6b82MdVHiLJGxlQfIbLPmVjqY5Ilqhqp+tjVgdbALQEmmdmE5K9Mc4EFRc7URXL87q3ASnf/95zx3GNg/x5Y3v2+A83MhphZVec84Qu6ywnb9NJksUuBPxQnYV5d/kJTits2R75tuQD4SHLGoncBO3N2xxeNmc0GvgCc6+4NOeOjzCydzE8EJgGri5Nyd6Z8r/sCYK6ZlZvZBELWxwc6Xx7vAZ5393WdA8Xetvk+s4jsvStAidfImOojRFsjY6qPENHnTEz1MckSW41UfczlRTwrTn9MhDO8vEDowq8rdp4e8s0g7Ep9BliaTOcAvwCeTcYXAIeVQNaJhDMRLQNWdG5PYATwAPAicD8wvNhZczIPAbYBQ3PGSmLbEormRqCVcNzz5fm2JeEMRbck7+NngZNLJG8t4fjtzvfuD5Jlz0veI0uBp4APlEDWvK87cF2ybVcBZ5fCtk3GfwZc2W3ZYm/bfJ9ZJfve1dTr61myNTKm+pjkjapGlnJ9TLJEUyNjqo+95C3JGqn6WNhkyQpFRERERESkxB1oh1CKiIiIiIgcsNTAiYiIiIiIREINnIiIiIiISCTUwImIiIiIiERCDZyIiIiIiEgk1MCJ9AEzazezpTnTtX247vFmVmrX5hERESmIaqRI38oUO4DIAaLR3acVO4SIiEgJUo0U6UPaAyfSj8xsjZl9y8yeNbPHzeyoZHy8mT1oZs+Y2QNmdngyPsbM7jSzZcl0SrKqtJn92MxWmNm9ZlaRLP9pM3suWc/8Ij1NERGRfaYaKfLWqIET6RsV3Q4PuSjndzvd/TjgZuA7ydj3gNvd/XjgDuCmZPwm4C/uPhU4EViRjE8CbnH3KcAO4Lxk/FrghGQ9V/bXkxMREdkPqpEifcjcvdgZRKJnZvXuXtnD+Brg3e6+2syywGvuPsLMtgKHuXtrMr7R3Uea2Ragxt2bc9YxHrjP3Sclt68Bsu7+NTO7B6gHfg/83t3r+/mpioiI7BPVSJG+pT1wIv3P88zvi+ac+Xb2fH/1fcAthL9ELjEzfa9VRERiohopso/UwIn0v4tyfj6azP8VmJvMfxh4OJl/APgEgJmlzWxovpWaWQoY5+4PAdcAQ4E3/YVTRESkhKlGiuwj/SVCpG9UmNnSnNv3uHvnaZKrzewZwl8IP5SMfQr4qZn9E7AF+Ggy/hngR2Z2OeGviJ8ANuZ5zDTwy6SAGXCTu+/os2ckIiLSN1QjRfqQvgMn0o+S4/tPdvetxc4iIiJSSlQjRd4aHUIpIiIiIiISCe2BExERERERiYT2wImIiIiIiERCDZyIiIiIiEgk1MCJiIiIiIhEQg2ciIiIiIhIJNTAiYiIiIiIREINnIiIiIiISCT+H9Kdpr8I4SSgAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zjepj31fVNww"
      },
      "source": [
        "### decomposition_rank = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq3bNGTuDGIm"
      },
      "source": [
        "#### Model without clipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ0P4VJ6Li7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50cbce18-92ac-4fb4-f21e-531e3621e3ef"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(\n",
        "    input_shape, conv_layer = functions.ConvDecomposed2D, decomposition_rank=1)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d (ConvDecompos (None, 32, 32, 16)   44          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 32, 32, 16)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_1 (ConvDecomp (None, 32, 32, 16)   57          activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 32, 32, 16)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_2 (ConvDecomp (None, 32, 32, 16)   57          activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 32, 32, 16)   0           activation_31[0][0]              \n",
            "                                                                 batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 32, 32, 16)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_3 (ConvDecomp (None, 32, 32, 16)   57          activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 32, 32, 16)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_4 (ConvDecomp (None, 32, 32, 16)   57          activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 32, 32, 16)   0           activation_33[0][0]              \n",
            "                                                                 batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 32, 32, 16)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_5 (ConvDecomp (None, 32, 32, 16)   57          activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 32, 32, 16)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_6 (ConvDecomp (None, 32, 32, 16)   57          activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 32, 32, 16)   0           activation_35[0][0]              \n",
            "                                                                 batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 32, 32, 16)   0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_7 (ConvDecomp (None, 32, 32, 16)   57          activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 32, 32, 16)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_8 (ConvDecomp (None, 32, 32, 16)   57          activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 32, 32, 16)   0           activation_37[0][0]              \n",
            "                                                                 batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 32, 32, 16)   0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_9 (ConvDecomp (None, 32, 32, 16)   57          activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 32, 32, 16)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_10 (ConvDecom (None, 32, 32, 16)   57          activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 32, 32, 16)   0           activation_39[0][0]              \n",
            "                                                                 batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 32, 32, 16)   0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_11 (ConvDecom (None, 16, 16, 32)   89          activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 16, 16, 32)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_12 (ConvDecom (None, 16, 16, 32)   105         activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_13 (ConvDecom (None, 16, 16, 32)   81          activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 16, 16, 32)   0           conv_decomposed2d_13[0][0]       \n",
            "                                                                 batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 16, 16, 32)   0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_14 (ConvDecom (None, 16, 16, 32)   105         activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 16, 16, 32)   0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_15 (ConvDecom (None, 16, 16, 32)   105         activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 16, 16, 32)   0           activation_43[0][0]              \n",
            "                                                                 batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 16, 16, 32)   0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_16 (ConvDecom (None, 16, 16, 32)   105         activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 16, 16, 32)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_17 (ConvDecom (None, 16, 16, 32)   105         activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 16, 16, 32)   0           activation_45[0][0]              \n",
            "                                                                 batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 16, 16, 32)   0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_18 (ConvDecom (None, 16, 16, 32)   105         activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 16, 16, 32)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_19 (ConvDecom (None, 16, 16, 32)   105         activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 16, 16, 32)   0           activation_47[0][0]              \n",
            "                                                                 batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 16, 16, 32)   0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_20 (ConvDecom (None, 16, 16, 32)   105         activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 16, 16, 32)   0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_21 (ConvDecom (None, 16, 16, 32)   105         activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 16, 16, 32)   0           activation_49[0][0]              \n",
            "                                                                 batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 32)   0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_22 (ConvDecom (None, 8, 8, 64)     169         activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_23 (ConvDecom (None, 8, 8, 64)     201         activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_24 (ConvDecom (None, 8, 8, 64)     161         activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 8, 8, 64)     0           conv_decomposed2d_24[0][0]       \n",
            "                                                                 batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 8, 8, 64)     0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_25 (ConvDecom (None, 8, 8, 64)     201         activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 8, 8, 64)     0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_26 (ConvDecom (None, 8, 8, 64)     201         activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 8, 8, 64)     0           activation_53[0][0]              \n",
            "                                                                 batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 8, 8, 64)     0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_27 (ConvDecom (None, 8, 8, 64)     201         activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_27[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 8, 8, 64)     0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_28 (ConvDecom (None, 8, 8, 64)     201         activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 8, 8, 64)     0           activation_55[0][0]              \n",
            "                                                                 batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 8, 8, 64)     0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_29 (ConvDecom (None, 8, 8, 64)     201         activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 8, 8, 64)     0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_30 (ConvDecom (None, 8, 8, 64)     201         activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_30[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 8, 8, 64)     0           activation_57[0][0]              \n",
            "                                                                 batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 8, 8, 64)     0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_31 (ConvDecom (None, 8, 8, 64)     201         activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_31[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 8, 8, 64)     0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_32 (ConvDecom (None, 8, 8, 64)     201         activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_32[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 8, 8, 64)     0           activation_59[0][0]              \n",
            "                                                                 batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 8, 8, 64)     0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 9,062\n",
            "Trainable params: 6,790\n",
            "Non-trainable params: 2,272\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMHS184LtygX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf00a16-9477-4a2d-b259-681b0fd5e6cc"
      },
      "source": [
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'trainHistoryDict', steps_per_epoch=100, batch_size=100,\n",
        "                       epochs=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Epoch 1/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 16s 92ms/step - loss: 10.8550 - acc: 0.1040 - val_loss: 3.0238 - val_acc: 0.0999\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.09990, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 2.5438 - acc: 0.1425 - val_loss: 2.7135 - val_acc: 0.0948\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.09990\n",
            "Epoch 3/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.4509 - acc: 0.1508 - val_loss: 2.6739 - val_acc: 0.1015\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.09990 to 0.10150, saving model to /content/saved_models/cifar10_ResNet32v1_model.003.h5\n",
            "Epoch 4/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.3849 - acc: 0.1678 - val_loss: 2.5002 - val_acc: 0.1228\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.10150 to 0.12280, saving model to /content/saved_models/cifar10_ResNet32v1_model.004.h5\n",
            "Epoch 5/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3196 - acc: 0.1940 - val_loss: 2.3694 - val_acc: 0.1386\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.12280 to 0.13860, saving model to /content/saved_models/cifar10_ResNet32v1_model.005.h5\n",
            "Epoch 6/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.2801 - acc: 0.1865 - val_loss: 2.4598 - val_acc: 0.1369\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.13860\n",
            "Epoch 7/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.2390 - acc: 0.2022 - val_loss: 2.4299 - val_acc: 0.1599\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.13860 to 0.15990, saving model to /content/saved_models/cifar10_ResNet32v1_model.007.h5\n",
            "Epoch 8/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.1939 - acc: 0.2308 - val_loss: 2.4209 - val_acc: 0.1315\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.15990\n",
            "Epoch 9/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 2.1662 - acc: 0.2215 - val_loss: 2.3542 - val_acc: 0.1378\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.15990\n",
            "Epoch 10/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 2.1244 - acc: 0.2423 - val_loss: 2.2426 - val_acc: 0.1552\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.15990\n",
            "Epoch 11/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 2.1020 - acc: 0.2422 - val_loss: 2.3812 - val_acc: 0.1424\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.15990\n",
            "Epoch 12/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.0798 - acc: 0.2458 - val_loss: 2.2224 - val_acc: 0.1886\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.15990 to 0.18860, saving model to /content/saved_models/cifar10_ResNet32v1_model.012.h5\n",
            "Epoch 13/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.0548 - acc: 0.2512 - val_loss: 2.1576 - val_acc: 0.1995\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.18860 to 0.19950, saving model to /content/saved_models/cifar10_ResNet32v1_model.013.h5\n",
            "Epoch 14/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.0365 - acc: 0.2557 - val_loss: 2.2415 - val_acc: 0.1977\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.19950\n",
            "Epoch 15/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.0261 - acc: 0.2471 - val_loss: 2.2587 - val_acc: 0.2057\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.19950 to 0.20570, saving model to /content/saved_models/cifar10_ResNet32v1_model.015.h5\n",
            "Epoch 16/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.0003 - acc: 0.2610 - val_loss: 2.6846 - val_acc: 0.1773\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.20570\n",
            "Epoch 17/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.0080 - acc: 0.2537 - val_loss: 2.0438 - val_acc: 0.2487\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.20570 to 0.24870, saving model to /content/saved_models/cifar10_ResNet32v1_model.017.h5\n",
            "Epoch 18/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.0256 - acc: 0.2526 - val_loss: 2.2173 - val_acc: 0.1900\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.24870\n",
            "Epoch 19/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.9887 - acc: 0.2499 - val_loss: 2.2787 - val_acc: 0.1720\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.24870\n",
            "Epoch 20/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.9831 - acc: 0.2681 - val_loss: 2.1008 - val_acc: 0.2180\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.24870\n",
            "Epoch 21/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.9636 - acc: 0.2635 - val_loss: 2.2536 - val_acc: 0.1944\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.24870\n",
            "Epoch 22/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.9618 - acc: 0.2567 - val_loss: 2.1541 - val_acc: 0.2092\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.24870\n",
            "Epoch 23/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.9526 - acc: 0.2712 - val_loss: 2.3585 - val_acc: 0.1891\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.24870\n",
            "Epoch 24/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.9652 - acc: 0.2520 - val_loss: 2.6322 - val_acc: 0.1602\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.24870\n",
            "Epoch 25/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 1.9347 - acc: 0.2773 - val_loss: 2.3239 - val_acc: 0.1844\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.24870\n",
            "Epoch 26/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.9379 - acc: 0.2751 - val_loss: 2.4803 - val_acc: 0.1810\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.24870\n",
            "Epoch 27/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 1.9301 - acc: 0.2748 - val_loss: 2.5407 - val_acc: 0.1666\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.24870\n",
            "Epoch 28/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 1.9161 - acc: 0.2824 - val_loss: 2.2551 - val_acc: 0.1967\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.24870\n",
            "Epoch 29/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.9269 - acc: 0.2881 - val_loss: 2.3321 - val_acc: 0.1937\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.24870\n",
            "Epoch 30/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.9256 - acc: 0.2850 - val_loss: 2.4732 - val_acc: 0.1700\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.24870\n",
            "Epoch 31/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.9246 - acc: 0.2854 - val_loss: 4.4213 - val_acc: 0.1401\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.24870\n",
            "Epoch 32/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 1.9112 - acc: 0.2758 - val_loss: 2.3861 - val_acc: 0.1985\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.24870\n",
            "Epoch 33/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.9031 - acc: 0.2880 - val_loss: 2.3293 - val_acc: 0.2207\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.24870\n",
            "Epoch 34/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.9181 - acc: 0.2808 - val_loss: 2.6759 - val_acc: 0.1698\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.24870\n",
            "Epoch 35/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.9192 - acc: 0.2937 - val_loss: 2.3519 - val_acc: 0.1968\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.24870\n",
            "Epoch 36/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8855 - acc: 0.3000 - val_loss: 2.1894 - val_acc: 0.2076\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.24870\n",
            "Epoch 37/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8795 - acc: 0.3098 - val_loss: 2.4264 - val_acc: 0.1775\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.24870\n",
            "Epoch 38/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.8850 - acc: 0.2986 - val_loss: 2.6810 - val_acc: 0.1669\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.24870\n",
            "Epoch 39/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.8859 - acc: 0.3016 - val_loss: 2.5965 - val_acc: 0.1877\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.24870\n",
            "Epoch 40/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.8907 - acc: 0.3068 - val_loss: 2.3752 - val_acc: 0.2238\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.24870\n",
            "Epoch 41/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8810 - acc: 0.3070 - val_loss: 2.2787 - val_acc: 0.2056\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.24870\n",
            "Epoch 42/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8580 - acc: 0.3104 - val_loss: 3.1729 - val_acc: 0.1243\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.24870\n",
            "Epoch 43/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.8582 - acc: 0.3195 - val_loss: 2.1177 - val_acc: 0.2292\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.24870\n",
            "Epoch 44/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8877 - acc: 0.2990 - val_loss: 2.0442 - val_acc: 0.2381\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.24870\n",
            "Epoch 45/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8721 - acc: 0.3197 - val_loss: 2.0544 - val_acc: 0.2690\n",
            "\n",
            "Epoch 00045: val_acc improved from 0.24870 to 0.26900, saving model to /content/saved_models/cifar10_ResNet32v1_model.045.h5\n",
            "Epoch 46/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8815 - acc: 0.3111 - val_loss: 4.0308 - val_acc: 0.1417\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.26900\n",
            "Epoch 47/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8561 - acc: 0.3152 - val_loss: 2.0352 - val_acc: 0.2512\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.26900\n",
            "Epoch 48/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8513 - acc: 0.3268 - val_loss: 2.7917 - val_acc: 0.1676\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.26900\n",
            "Epoch 49/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.8519 - acc: 0.3173 - val_loss: 3.6536 - val_acc: 0.1464\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.26900\n",
            "Epoch 50/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.8597 - acc: 0.3143 - val_loss: 4.1774 - val_acc: 0.1754\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.26900\n",
            "Epoch 51/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.8450 - acc: 0.3192 - val_loss: 2.3016 - val_acc: 0.2549\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.26900\n",
            "Epoch 52/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.8506 - acc: 0.3270 - val_loss: 2.2667 - val_acc: 0.2523\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.26900\n",
            "Epoch 53/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8357 - acc: 0.3294 - val_loss: 2.8292 - val_acc: 0.1594\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.26900\n",
            "Epoch 54/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.8485 - acc: 0.3232 - val_loss: 2.3146 - val_acc: 0.2101\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.26900\n",
            "Epoch 55/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.8328 - acc: 0.3374 - val_loss: 2.2551 - val_acc: 0.2328\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.26900\n",
            "Epoch 56/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.8281 - acc: 0.3289 - val_loss: 2.0946 - val_acc: 0.2433\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.26900\n",
            "Epoch 57/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.8322 - acc: 0.3326 - val_loss: 2.1360 - val_acc: 0.2774\n",
            "\n",
            "Epoch 00057: val_acc improved from 0.26900 to 0.27740, saving model to /content/saved_models/cifar10_ResNet32v1_model.057.h5\n",
            "Epoch 58/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8209 - acc: 0.3396 - val_loss: 2.1443 - val_acc: 0.2537\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.27740\n",
            "Epoch 59/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8471 - acc: 0.3387 - val_loss: 2.0798 - val_acc: 0.2544\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.27740\n",
            "Epoch 60/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8263 - acc: 0.3290 - val_loss: 1.9904 - val_acc: 0.2901\n",
            "\n",
            "Epoch 00060: val_acc improved from 0.27740 to 0.29010, saving model to /content/saved_models/cifar10_ResNet32v1_model.060.h5\n",
            "Epoch 61/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8457 - acc: 0.3293 - val_loss: 2.6094 - val_acc: 0.1979\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.29010\n",
            "Epoch 62/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8153 - acc: 0.3357 - val_loss: 1.9425 - val_acc: 0.2969\n",
            "\n",
            "Epoch 00062: val_acc improved from 0.29010 to 0.29690, saving model to /content/saved_models/cifar10_ResNet32v1_model.062.h5\n",
            "Epoch 63/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.8029 - acc: 0.3313 - val_loss: 2.4408 - val_acc: 0.2039\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.29690\n",
            "Epoch 64/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.8307 - acc: 0.3246 - val_loss: 3.0091 - val_acc: 0.2185\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.29690\n",
            "Epoch 65/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8172 - acc: 0.3354 - val_loss: 1.8545 - val_acc: 0.3134\n",
            "\n",
            "Epoch 00065: val_acc improved from 0.29690 to 0.31340, saving model to /content/saved_models/cifar10_ResNet32v1_model.065.h5\n",
            "Epoch 66/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.7936 - acc: 0.3447 - val_loss: 1.9346 - val_acc: 0.2931\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.31340\n",
            "Epoch 67/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.8109 - acc: 0.3395 - val_loss: 2.3403 - val_acc: 0.2282\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.31340\n",
            "Epoch 68/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8329 - acc: 0.3314 - val_loss: 2.2369 - val_acc: 0.2255\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.31340\n",
            "Epoch 69/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.8179 - acc: 0.3424 - val_loss: 2.1046 - val_acc: 0.2563\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.31340\n",
            "Epoch 70/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8096 - acc: 0.3523 - val_loss: 2.2883 - val_acc: 0.2076\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.31340\n",
            "Epoch 71/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.8213 - acc: 0.3263 - val_loss: 2.7631 - val_acc: 0.1648\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.31340\n",
            "Epoch 72/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.8187 - acc: 0.3450 - val_loss: 2.7963 - val_acc: 0.1620\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.31340\n",
            "Epoch 73/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.8028 - acc: 0.3463 - val_loss: 1.9341 - val_acc: 0.2943\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.31340\n",
            "Epoch 74/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7951 - acc: 0.3435 - val_loss: 2.5973 - val_acc: 0.1832\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.31340\n",
            "Epoch 75/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.8141 - acc: 0.3468 - val_loss: 2.0306 - val_acc: 0.2757\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.31340\n",
            "Epoch 76/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.7917 - acc: 0.3507 - val_loss: 1.9484 - val_acc: 0.2787\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.31340\n",
            "Epoch 77/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.7896 - acc: 0.3553 - val_loss: 2.3890 - val_acc: 0.2322\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.31340\n",
            "Epoch 78/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.7846 - acc: 0.3596 - val_loss: 2.2881 - val_acc: 0.2225\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.31340\n",
            "Epoch 79/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.8035 - acc: 0.3549 - val_loss: 2.7114 - val_acc: 0.1732\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.31340\n",
            "Epoch 80/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7800 - acc: 0.3484 - val_loss: 2.1107 - val_acc: 0.2673\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.31340\n",
            "Epoch 81/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.7918 - acc: 0.3535 - val_loss: 2.2976 - val_acc: 0.2613\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.31340\n",
            "Epoch 82/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7655 - acc: 0.3600 - val_loss: 2.1589 - val_acc: 0.2361\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.31340\n",
            "Epoch 83/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7716 - acc: 0.3653 - val_loss: 2.2554 - val_acc: 0.2322\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.31340\n",
            "Epoch 84/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7793 - acc: 0.3658 - val_loss: 2.0197 - val_acc: 0.2875\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.31340\n",
            "Epoch 85/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7772 - acc: 0.3487 - val_loss: 2.2700 - val_acc: 0.2384\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.31340\n",
            "Epoch 86/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7672 - acc: 0.3544 - val_loss: 2.1833 - val_acc: 0.2463\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.31340\n",
            "Epoch 87/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7605 - acc: 0.3771 - val_loss: 1.9639 - val_acc: 0.2917\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.31340\n",
            "Epoch 88/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.7682 - acc: 0.3511 - val_loss: 2.1633 - val_acc: 0.2454\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.31340\n",
            "Epoch 89/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7776 - acc: 0.3626 - val_loss: 2.4560 - val_acc: 0.1781\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.31340\n",
            "Epoch 90/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.7628 - acc: 0.3666 - val_loss: 2.2757 - val_acc: 0.2426\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.31340\n",
            "Epoch 91/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7383 - acc: 0.3742 - val_loss: 2.8079 - val_acc: 0.1594\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.31340\n",
            "Epoch 92/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7478 - acc: 0.3632 - val_loss: 1.8579 - val_acc: 0.3195\n",
            "\n",
            "Epoch 00092: val_acc improved from 0.31340 to 0.31950, saving model to /content/saved_models/cifar10_ResNet32v1_model.092.h5\n",
            "Epoch 93/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7530 - acc: 0.3700 - val_loss: 2.0591 - val_acc: 0.2540\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.31950\n",
            "Epoch 94/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7378 - acc: 0.3755 - val_loss: 1.9699 - val_acc: 0.3036\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.31950\n",
            "Epoch 95/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7538 - acc: 0.3597 - val_loss: 1.9957 - val_acc: 0.3029\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.31950\n",
            "Epoch 96/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.7497 - acc: 0.3655 - val_loss: 2.2270 - val_acc: 0.2297\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.31950\n",
            "Epoch 97/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7567 - acc: 0.3582 - val_loss: 2.1432 - val_acc: 0.2590\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.31950\n",
            "Epoch 98/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7612 - acc: 0.3668 - val_loss: 2.1729 - val_acc: 0.2726\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.31950\n",
            "Epoch 99/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7618 - acc: 0.3629 - val_loss: 1.9748 - val_acc: 0.3028\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.31950\n",
            "Epoch 100/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7133 - acc: 0.3803 - val_loss: 2.0729 - val_acc: 0.2652\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.31950\n",
            "Epoch 101/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7322 - acc: 0.3739 - val_loss: 2.2023 - val_acc: 0.2341\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.31950\n",
            "Epoch 102/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7422 - acc: 0.3688 - val_loss: 1.9676 - val_acc: 0.3079\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.31950\n",
            "Epoch 103/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7215 - acc: 0.3862 - val_loss: 2.2008 - val_acc: 0.2238\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.31950\n",
            "Epoch 104/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7223 - acc: 0.3781 - val_loss: 2.1341 - val_acc: 0.3013\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.31950\n",
            "Epoch 105/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7205 - acc: 0.3839 - val_loss: 1.9802 - val_acc: 0.3070\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.31950\n",
            "Epoch 106/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.7370 - acc: 0.3791 - val_loss: 2.2324 - val_acc: 0.2620\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.31950\n",
            "Epoch 107/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7334 - acc: 0.3786 - val_loss: 2.1602 - val_acc: 0.2450\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.31950\n",
            "Epoch 108/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7210 - acc: 0.3797 - val_loss: 2.4709 - val_acc: 0.2636\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.31950\n",
            "Epoch 109/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7386 - acc: 0.3698 - val_loss: 2.1043 - val_acc: 0.2748\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.31950\n",
            "Epoch 110/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7353 - acc: 0.3738 - val_loss: 1.8259 - val_acc: 0.3447\n",
            "\n",
            "Epoch 00110: val_acc improved from 0.31950 to 0.34470, saving model to /content/saved_models/cifar10_ResNet32v1_model.110.h5\n",
            "Epoch 111/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7240 - acc: 0.3841 - val_loss: 1.8149 - val_acc: 0.3366\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.34470\n",
            "Epoch 112/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7042 - acc: 0.3853 - val_loss: 2.4866 - val_acc: 0.1916\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.34470\n",
            "Epoch 113/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7314 - acc: 0.3759 - val_loss: 2.6699 - val_acc: 0.2073\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.34470\n",
            "Epoch 114/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7375 - acc: 0.3796 - val_loss: 2.3823 - val_acc: 0.2485\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.34470\n",
            "Epoch 115/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7255 - acc: 0.3856 - val_loss: 1.9757 - val_acc: 0.2889\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.34470\n",
            "Epoch 116/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7188 - acc: 0.3927 - val_loss: 1.9489 - val_acc: 0.3143\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.34470\n",
            "Epoch 117/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7152 - acc: 0.3866 - val_loss: 2.0891 - val_acc: 0.2990\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.34470\n",
            "Epoch 118/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7343 - acc: 0.3841 - val_loss: 1.9165 - val_acc: 0.3345\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.34470\n",
            "Epoch 119/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6990 - acc: 0.4011 - val_loss: 2.1953 - val_acc: 0.2502\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.34470\n",
            "Epoch 120/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7220 - acc: 0.3836 - val_loss: 1.8869 - val_acc: 0.3330\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.34470\n",
            "Epoch 121/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7159 - acc: 0.3813 - val_loss: 2.2871 - val_acc: 0.2027\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.34470\n",
            "Epoch 122/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.7094 - acc: 0.3856 - val_loss: 1.8774 - val_acc: 0.3324\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.34470\n",
            "Epoch 123/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.7151 - acc: 0.3897 - val_loss: 1.7567 - val_acc: 0.3713\n",
            "\n",
            "Epoch 00123: val_acc improved from 0.34470 to 0.37130, saving model to /content/saved_models/cifar10_ResNet32v1_model.123.h5\n",
            "Epoch 124/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7134 - acc: 0.3881 - val_loss: 1.8929 - val_acc: 0.3184\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.37130\n",
            "Epoch 125/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7166 - acc: 0.3866 - val_loss: 2.8037 - val_acc: 0.1967\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.37130\n",
            "Epoch 126/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6749 - acc: 0.4033 - val_loss: 1.8737 - val_acc: 0.3283\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.37130\n",
            "Epoch 127/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6729 - acc: 0.4049 - val_loss: 1.8186 - val_acc: 0.3428\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.37130\n",
            "Epoch 128/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.7011 - acc: 0.3854 - val_loss: 2.4810 - val_acc: 0.2516\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.37130\n",
            "Epoch 129/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.6904 - acc: 0.3953 - val_loss: 1.8842 - val_acc: 0.3151\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.37130\n",
            "Epoch 130/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.7000 - acc: 0.3863 - val_loss: 2.3171 - val_acc: 0.2554\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.37130\n",
            "Epoch 131/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.7017 - acc: 0.3910 - val_loss: 1.7016 - val_acc: 0.3940\n",
            "\n",
            "Epoch 00131: val_acc improved from 0.37130 to 0.39400, saving model to /content/saved_models/cifar10_ResNet32v1_model.131.h5\n",
            "Epoch 132/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.6954 - acc: 0.3945 - val_loss: 2.0749 - val_acc: 0.2720\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.39400\n",
            "Epoch 133/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6882 - acc: 0.3925 - val_loss: 2.0763 - val_acc: 0.2880\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.39400\n",
            "Epoch 134/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6908 - acc: 0.4029 - val_loss: 2.2702 - val_acc: 0.2488\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.39400\n",
            "Epoch 135/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.6688 - acc: 0.3947 - val_loss: 2.2097 - val_acc: 0.2667\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.39400\n",
            "Epoch 136/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6826 - acc: 0.3968 - val_loss: 1.8718 - val_acc: 0.3260\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.39400\n",
            "Epoch 137/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6908 - acc: 0.4049 - val_loss: 1.8449 - val_acc: 0.3441\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.39400\n",
            "Epoch 138/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.6763 - acc: 0.4006 - val_loss: 2.0258 - val_acc: 0.3011\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.39400\n",
            "Epoch 139/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6970 - acc: 0.3961 - val_loss: 2.1708 - val_acc: 0.3046\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.39400\n",
            "Epoch 140/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6848 - acc: 0.3981 - val_loss: 1.9697 - val_acc: 0.3138\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.39400\n",
            "Epoch 141/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7085 - acc: 0.3942 - val_loss: 2.2298 - val_acc: 0.2447\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.39400\n",
            "Epoch 142/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6844 - acc: 0.4008 - val_loss: 2.1301 - val_acc: 0.2718\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.39400\n",
            "Epoch 143/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6597 - acc: 0.4053 - val_loss: 2.0710 - val_acc: 0.3061\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.39400\n",
            "Epoch 144/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6459 - acc: 0.4054 - val_loss: 1.9099 - val_acc: 0.3340\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.39400\n",
            "Epoch 145/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6685 - acc: 0.3925 - val_loss: 2.0290 - val_acc: 0.2999\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.39400\n",
            "Epoch 146/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6825 - acc: 0.4018 - val_loss: 1.9040 - val_acc: 0.3228\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.39400\n",
            "Epoch 147/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6600 - acc: 0.4122 - val_loss: 1.9716 - val_acc: 0.3235\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.39400\n",
            "Epoch 148/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6462 - acc: 0.4085 - val_loss: 2.3321 - val_acc: 0.2466\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.39400\n",
            "Epoch 149/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6564 - acc: 0.4144 - val_loss: 1.8332 - val_acc: 0.3288\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.39400\n",
            "Epoch 150/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6881 - acc: 0.3924 - val_loss: 2.1310 - val_acc: 0.3059\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.39400\n",
            "Epoch 151/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6628 - acc: 0.4029 - val_loss: 2.1428 - val_acc: 0.2839\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.39400\n",
            "Epoch 152/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6622 - acc: 0.4076 - val_loss: 2.1511 - val_acc: 0.2948\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.39400\n",
            "Epoch 153/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6560 - acc: 0.4117 - val_loss: 2.0114 - val_acc: 0.3066\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.39400\n",
            "Epoch 154/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.6561 - acc: 0.3995 - val_loss: 2.0680 - val_acc: 0.2939\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.39400\n",
            "Epoch 155/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6485 - acc: 0.4127 - val_loss: 1.8220 - val_acc: 0.3485\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.39400\n",
            "Epoch 156/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6518 - acc: 0.4096 - val_loss: 1.9350 - val_acc: 0.3262\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.39400\n",
            "Epoch 157/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6387 - acc: 0.4114 - val_loss: 1.8565 - val_acc: 0.3274\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.39400\n",
            "Epoch 158/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6404 - acc: 0.4190 - val_loss: 1.9984 - val_acc: 0.3188\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.39400\n",
            "Epoch 159/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6272 - acc: 0.4241 - val_loss: 2.5714 - val_acc: 0.2509\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.39400\n",
            "Epoch 160/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6183 - acc: 0.4128 - val_loss: 2.2010 - val_acc: 0.2928\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.39400\n",
            "Epoch 161/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6278 - acc: 0.4292 - val_loss: 3.0300 - val_acc: 0.2048\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.39400\n",
            "Epoch 162/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6298 - acc: 0.4216 - val_loss: 1.8659 - val_acc: 0.3440\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.39400\n",
            "Epoch 163/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6241 - acc: 0.4160 - val_loss: 2.1077 - val_acc: 0.2635\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.39400\n",
            "Epoch 164/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6281 - acc: 0.4185 - val_loss: 1.7194 - val_acc: 0.3737\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.39400\n",
            "Epoch 165/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6436 - acc: 0.4175 - val_loss: 1.7618 - val_acc: 0.3616\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.39400\n",
            "Epoch 166/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6168 - acc: 0.4274 - val_loss: 1.8806 - val_acc: 0.3359\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.39400\n",
            "Epoch 167/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6163 - acc: 0.4242 - val_loss: 2.6944 - val_acc: 0.2344\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.39400\n",
            "Epoch 168/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6285 - acc: 0.4218 - val_loss: 1.9962 - val_acc: 0.3159\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.39400\n",
            "Epoch 169/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6081 - acc: 0.4201 - val_loss: 2.0338 - val_acc: 0.3150\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.39400\n",
            "Epoch 170/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6314 - acc: 0.4199 - val_loss: 1.9179 - val_acc: 0.3440\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.39400\n",
            "Epoch 171/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.6108 - acc: 0.4300 - val_loss: 2.6631 - val_acc: 0.2630\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.39400\n",
            "Epoch 172/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.6098 - acc: 0.4356 - val_loss: 1.8642 - val_acc: 0.3451\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.39400\n",
            "Epoch 173/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6174 - acc: 0.4320 - val_loss: 2.1627 - val_acc: 0.2679\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.39400\n",
            "Epoch 174/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5999 - acc: 0.4323 - val_loss: 2.4436 - val_acc: 0.2897\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.39400\n",
            "Epoch 175/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6046 - acc: 0.4293 - val_loss: 1.7111 - val_acc: 0.3965\n",
            "\n",
            "Epoch 00175: val_acc improved from 0.39400 to 0.39650, saving model to /content/saved_models/cifar10_ResNet32v1_model.175.h5\n",
            "Epoch 176/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6152 - acc: 0.4216 - val_loss: 2.3741 - val_acc: 0.2795\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.39650\n",
            "Epoch 177/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6151 - acc: 0.4353 - val_loss: 4.0986 - val_acc: 0.1727\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.39650\n",
            "Epoch 178/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6001 - acc: 0.4326 - val_loss: 1.9916 - val_acc: 0.3285\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.39650\n",
            "Epoch 179/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5979 - acc: 0.4276 - val_loss: 2.4332 - val_acc: 0.2346\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.39650\n",
            "Epoch 180/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6014 - acc: 0.4331 - val_loss: 3.6641 - val_acc: 0.1926\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.39650\n",
            "Epoch 181/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6155 - acc: 0.4306 - val_loss: 2.0652 - val_acc: 0.3131\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.39650\n",
            "Epoch 182/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6018 - acc: 0.4325 - val_loss: 1.7621 - val_acc: 0.3636\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.39650\n",
            "Epoch 183/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5884 - acc: 0.4335 - val_loss: 2.5719 - val_acc: 0.2361\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.39650\n",
            "Epoch 184/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6002 - acc: 0.4365 - val_loss: 3.3704 - val_acc: 0.2114\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.39650\n",
            "Epoch 185/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5762 - acc: 0.4443 - val_loss: 1.8315 - val_acc: 0.3640\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.39650\n",
            "Epoch 186/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5661 - acc: 0.4404 - val_loss: 1.8097 - val_acc: 0.3684\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.39650\n",
            "Epoch 187/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.5851 - acc: 0.4367 - val_loss: 2.4158 - val_acc: 0.2573\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.39650\n",
            "Epoch 188/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5893 - acc: 0.4362 - val_loss: 1.6520 - val_acc: 0.4062\n",
            "\n",
            "Epoch 00188: val_acc improved from 0.39650 to 0.40620, saving model to /content/saved_models/cifar10_ResNet32v1_model.188.h5\n",
            "Epoch 189/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5691 - acc: 0.4449 - val_loss: 1.7652 - val_acc: 0.3642\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.40620\n",
            "Epoch 190/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5894 - acc: 0.4261 - val_loss: 1.8654 - val_acc: 0.3520\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.40620\n",
            "Epoch 191/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5715 - acc: 0.4536 - val_loss: 2.6621 - val_acc: 0.2461\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.40620\n",
            "Epoch 192/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5889 - acc: 0.4379 - val_loss: 1.9953 - val_acc: 0.3097\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.40620\n",
            "Epoch 193/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5770 - acc: 0.4460 - val_loss: 2.0163 - val_acc: 0.3217\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.40620\n",
            "Epoch 194/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5970 - acc: 0.4363 - val_loss: 1.8936 - val_acc: 0.3553\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.40620\n",
            "Epoch 195/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5674 - acc: 0.4435 - val_loss: 1.8579 - val_acc: 0.3444\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.40620\n",
            "Epoch 196/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5852 - acc: 0.4323 - val_loss: 2.8154 - val_acc: 0.2226\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.40620\n",
            "Epoch 197/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5776 - acc: 0.4412 - val_loss: 3.1486 - val_acc: 0.1901\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.40620\n",
            "Epoch 198/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5770 - acc: 0.4417 - val_loss: 1.7834 - val_acc: 0.3783\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.40620\n",
            "Epoch 199/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5652 - acc: 0.4453 - val_loss: 1.9038 - val_acc: 0.3514\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.40620\n",
            "Epoch 200/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5692 - acc: 0.4463 - val_loss: 2.5829 - val_acc: 0.2260\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.40620\n",
            "Epoch 201/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5710 - acc: 0.4395 - val_loss: 2.1645 - val_acc: 0.3246\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.40620\n",
            "Epoch 202/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5677 - acc: 0.4389 - val_loss: 1.8899 - val_acc: 0.3419\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.40620\n",
            "Epoch 203/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.5677 - acc: 0.4381 - val_loss: 1.9987 - val_acc: 0.3395\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.40620\n",
            "Epoch 204/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5473 - acc: 0.4546 - val_loss: 4.2715 - val_acc: 0.1564\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.40620\n",
            "Epoch 205/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5641 - acc: 0.4433 - val_loss: 1.8829 - val_acc: 0.3266\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.40620\n",
            "Epoch 206/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5685 - acc: 0.4415 - val_loss: 1.6127 - val_acc: 0.4266\n",
            "\n",
            "Epoch 00206: val_acc improved from 0.40620 to 0.42660, saving model to /content/saved_models/cifar10_ResNet32v1_model.206.h5\n",
            "Epoch 207/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5638 - acc: 0.4434 - val_loss: 1.8039 - val_acc: 0.3649\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.42660\n",
            "Epoch 208/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5306 - acc: 0.4548 - val_loss: 1.7441 - val_acc: 0.3721\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.42660\n",
            "Epoch 209/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5615 - acc: 0.4518 - val_loss: 1.7016 - val_acc: 0.3929\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.42660\n",
            "Epoch 210/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5688 - acc: 0.4402 - val_loss: 1.9387 - val_acc: 0.3472\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.42660\n",
            "Epoch 211/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5613 - acc: 0.4506 - val_loss: 1.9678 - val_acc: 0.3307\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.42660\n",
            "Epoch 212/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5703 - acc: 0.4444 - val_loss: 1.8617 - val_acc: 0.3629\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.42660\n",
            "Epoch 213/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5743 - acc: 0.4376 - val_loss: 1.8156 - val_acc: 0.3615\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.42660\n",
            "Epoch 214/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5765 - acc: 0.4445 - val_loss: 1.7981 - val_acc: 0.3590\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.42660\n",
            "Epoch 215/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5545 - acc: 0.4536 - val_loss: 1.9514 - val_acc: 0.3262\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.42660\n",
            "Epoch 216/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5085 - acc: 0.4652 - val_loss: 3.1653 - val_acc: 0.2104\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.42660\n",
            "Epoch 217/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5553 - acc: 0.4446 - val_loss: 1.8498 - val_acc: 0.3493\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.42660\n",
            "Epoch 218/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5500 - acc: 0.4492 - val_loss: 1.9493 - val_acc: 0.3402\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.42660\n",
            "Epoch 219/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.5763 - acc: 0.4437 - val_loss: 1.8875 - val_acc: 0.3647\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.42660\n",
            "Epoch 220/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.5530 - acc: 0.4444 - val_loss: 1.6876 - val_acc: 0.4106\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.42660\n",
            "Epoch 221/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5529 - acc: 0.4475 - val_loss: 3.0085 - val_acc: 0.2272\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.42660\n",
            "Epoch 222/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5383 - acc: 0.4496 - val_loss: 1.8812 - val_acc: 0.3735\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.42660\n",
            "Epoch 223/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5370 - acc: 0.4438 - val_loss: 1.9188 - val_acc: 0.3512\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.42660\n",
            "Epoch 224/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5409 - acc: 0.4520 - val_loss: 2.8238 - val_acc: 0.2112\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.42660\n",
            "Epoch 225/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5538 - acc: 0.4415 - val_loss: 4.3006 - val_acc: 0.1776\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.42660\n",
            "Epoch 226/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.5723 - acc: 0.4446 - val_loss: 1.7671 - val_acc: 0.4007\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.42660\n",
            "Epoch 227/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5560 - acc: 0.4416 - val_loss: 3.0228 - val_acc: 0.1914\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.42660\n",
            "Epoch 228/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5398 - acc: 0.4510 - val_loss: 2.2908 - val_acc: 0.3137\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.42660\n",
            "Epoch 229/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5494 - acc: 0.4562 - val_loss: 1.6840 - val_acc: 0.4054\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.42660\n",
            "Epoch 230/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.5319 - acc: 0.4659 - val_loss: 1.9660 - val_acc: 0.3315\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.42660\n",
            "Epoch 231/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5306 - acc: 0.4643 - val_loss: 1.8379 - val_acc: 0.3591\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.42660\n",
            "Epoch 232/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.5060 - acc: 0.4705 - val_loss: 2.3671 - val_acc: 0.2594\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.42660\n",
            "Epoch 233/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.5490 - acc: 0.4437 - val_loss: 1.9961 - val_acc: 0.3315\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.42660\n",
            "Epoch 234/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5445 - acc: 0.4530 - val_loss: 1.7936 - val_acc: 0.3707\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.42660\n",
            "Epoch 235/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.5401 - acc: 0.4555 - val_loss: 1.9374 - val_acc: 0.3406\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.42660\n",
            "Epoch 236/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.5528 - acc: 0.4535 - val_loss: 1.8662 - val_acc: 0.3813\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.42660\n",
            "Epoch 237/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5307 - acc: 0.4610 - val_loss: 1.7790 - val_acc: 0.3764\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.42660\n",
            "Epoch 238/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5248 - acc: 0.4584 - val_loss: 1.7035 - val_acc: 0.3931\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.42660\n",
            "Epoch 239/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4953 - acc: 0.4683 - val_loss: 2.0599 - val_acc: 0.3163\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.42660\n",
            "Epoch 240/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5333 - acc: 0.4571 - val_loss: 1.9238 - val_acc: 0.3422\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.42660\n",
            "Epoch 241/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5032 - acc: 0.4691 - val_loss: 2.0704 - val_acc: 0.3158\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.42660\n",
            "Epoch 242/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5007 - acc: 0.4679 - val_loss: 2.1419 - val_acc: 0.3148\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.42660\n",
            "Epoch 243/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5182 - acc: 0.4637 - val_loss: 2.3679 - val_acc: 0.3030\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.42660\n",
            "Epoch 244/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5223 - acc: 0.4532 - val_loss: 1.8225 - val_acc: 0.3554\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.42660\n",
            "Epoch 245/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5367 - acc: 0.4575 - val_loss: 1.7934 - val_acc: 0.3792\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.42660\n",
            "Epoch 246/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5184 - acc: 0.4668 - val_loss: 2.0330 - val_acc: 0.3375\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.42660\n",
            "Epoch 247/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5167 - acc: 0.4638 - val_loss: 1.6749 - val_acc: 0.4169\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.42660\n",
            "Epoch 248/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5344 - acc: 0.4547 - val_loss: 1.7684 - val_acc: 0.3823\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.42660\n",
            "Epoch 249/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5166 - acc: 0.4631 - val_loss: 2.3952 - val_acc: 0.2881\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.42660\n",
            "Epoch 250/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5255 - acc: 0.4482 - val_loss: 1.6970 - val_acc: 0.4050\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.42660\n",
            "Epoch 251/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.5088 - acc: 0.4681 - val_loss: 2.0760 - val_acc: 0.3484\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.42660\n",
            "Epoch 252/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.5272 - acc: 0.4627 - val_loss: 1.6417 - val_acc: 0.4176\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.42660\n",
            "Epoch 253/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5126 - acc: 0.4627 - val_loss: 1.9209 - val_acc: 0.3476\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.42660\n",
            "Epoch 254/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5081 - acc: 0.4647 - val_loss: 2.5137 - val_acc: 0.2655\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.42660\n",
            "Epoch 255/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5028 - acc: 0.4659 - val_loss: 2.2166 - val_acc: 0.3312\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.42660\n",
            "Epoch 256/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4887 - acc: 0.4703 - val_loss: 1.6899 - val_acc: 0.4211\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.42660\n",
            "Epoch 257/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5087 - acc: 0.4674 - val_loss: 1.8599 - val_acc: 0.3430\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.42660\n",
            "Epoch 258/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4925 - acc: 0.4733 - val_loss: 1.7418 - val_acc: 0.3959\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.42660\n",
            "Epoch 259/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5173 - acc: 0.4661 - val_loss: 2.0913 - val_acc: 0.3133\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.42660\n",
            "Epoch 260/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5061 - acc: 0.4719 - val_loss: 1.9196 - val_acc: 0.3728\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.42660\n",
            "Epoch 261/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4929 - acc: 0.4676 - val_loss: 1.5770 - val_acc: 0.4383\n",
            "\n",
            "Epoch 00261: val_acc improved from 0.42660 to 0.43830, saving model to /content/saved_models/cifar10_ResNet32v1_model.261.h5\n",
            "Epoch 262/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4870 - acc: 0.4852 - val_loss: 2.0507 - val_acc: 0.3458\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.43830\n",
            "Epoch 263/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.5037 - acc: 0.4679 - val_loss: 2.1368 - val_acc: 0.3245\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.43830\n",
            "Epoch 264/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4912 - acc: 0.4712 - val_loss: 2.1326 - val_acc: 0.3473\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.43830\n",
            "Epoch 265/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4884 - acc: 0.4723 - val_loss: 1.7228 - val_acc: 0.3923\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.43830\n",
            "Epoch 266/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4802 - acc: 0.4774 - val_loss: 1.7638 - val_acc: 0.3871\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.43830\n",
            "Epoch 267/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4795 - acc: 0.4741 - val_loss: 1.7912 - val_acc: 0.3824\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.43830\n",
            "Epoch 268/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.5178 - acc: 0.4724 - val_loss: 1.7810 - val_acc: 0.3701\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.43830\n",
            "Epoch 269/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.5233 - acc: 0.4695 - val_loss: 1.9271 - val_acc: 0.3407\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.43830\n",
            "Epoch 270/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4920 - acc: 0.4696 - val_loss: 1.8093 - val_acc: 0.3860\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.43830\n",
            "Epoch 271/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4970 - acc: 0.4712 - val_loss: 1.6198 - val_acc: 0.4225\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.43830\n",
            "Epoch 272/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4852 - acc: 0.4711 - val_loss: 2.1408 - val_acc: 0.3097\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.43830\n",
            "Epoch 273/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.5021 - acc: 0.4730 - val_loss: 2.4606 - val_acc: 0.2616\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.43830\n",
            "Epoch 274/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4753 - acc: 0.4710 - val_loss: 2.1247 - val_acc: 0.3547\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.43830\n",
            "Epoch 275/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.5243 - acc: 0.4660 - val_loss: 1.9142 - val_acc: 0.3784\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.43830\n",
            "Epoch 276/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4989 - acc: 0.4661 - val_loss: 2.9974 - val_acc: 0.2411\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.43830\n",
            "Epoch 277/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4862 - acc: 0.4725 - val_loss: 1.6440 - val_acc: 0.4158\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.43830\n",
            "Epoch 278/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4761 - acc: 0.4756 - val_loss: 1.5834 - val_acc: 0.4282\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.43830\n",
            "Epoch 279/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.5022 - acc: 0.4696 - val_loss: 1.7960 - val_acc: 0.3891\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.43830\n",
            "Epoch 280/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5111 - acc: 0.4617 - val_loss: 1.7581 - val_acc: 0.3868\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.43830\n",
            "Epoch 281/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.5046 - acc: 0.4654 - val_loss: 1.8310 - val_acc: 0.3713\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.43830\n",
            "Epoch 282/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4895 - acc: 0.4686 - val_loss: 1.8434 - val_acc: 0.3530\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.43830\n",
            "Epoch 283/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4685 - acc: 0.4814 - val_loss: 2.0360 - val_acc: 0.3573\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.43830\n",
            "Epoch 284/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5103 - acc: 0.4607 - val_loss: 2.1644 - val_acc: 0.3130\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.43830\n",
            "Epoch 285/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4986 - acc: 0.4652 - val_loss: 2.3755 - val_acc: 0.2525\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.43830\n",
            "Epoch 286/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4628 - acc: 0.4829 - val_loss: 1.8802 - val_acc: 0.3699\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.43830\n",
            "Epoch 287/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.5107 - acc: 0.4659 - val_loss: 1.6112 - val_acc: 0.4314\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.43830\n",
            "Epoch 288/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4752 - acc: 0.4739 - val_loss: 2.4097 - val_acc: 0.2624\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.43830\n",
            "Epoch 289/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4819 - acc: 0.4724 - val_loss: 1.7271 - val_acc: 0.4068\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.43830\n",
            "Epoch 290/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4869 - acc: 0.4809 - val_loss: 1.7730 - val_acc: 0.3834\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.43830\n",
            "Epoch 291/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4944 - acc: 0.4690 - val_loss: 2.0041 - val_acc: 0.3508\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.43830\n",
            "Epoch 292/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4976 - acc: 0.4761 - val_loss: 1.7214 - val_acc: 0.3851\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.43830\n",
            "Epoch 293/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4999 - acc: 0.4688 - val_loss: 2.3999 - val_acc: 0.3026\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.43830\n",
            "Epoch 294/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4697 - acc: 0.4791 - val_loss: 2.0012 - val_acc: 0.3478\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.43830\n",
            "Epoch 295/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4981 - acc: 0.4619 - val_loss: 3.0715 - val_acc: 0.1792\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.43830\n",
            "Epoch 296/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4742 - acc: 0.4829 - val_loss: 2.0538 - val_acc: 0.3425\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.43830\n",
            "Epoch 297/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4847 - acc: 0.4716 - val_loss: 2.1111 - val_acc: 0.3239\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.43830\n",
            "Epoch 298/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4858 - acc: 0.4737 - val_loss: 1.9413 - val_acc: 0.3488\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.43830\n",
            "Epoch 299/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.5075 - acc: 0.4658 - val_loss: 1.7762 - val_acc: 0.3822\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.43830\n",
            "Epoch 300/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4936 - acc: 0.4661 - val_loss: 1.7699 - val_acc: 0.3855\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.43830\n",
            "Epoch 301/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4886 - acc: 0.4697 - val_loss: 1.6899 - val_acc: 0.3981\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.43830\n",
            "Epoch 302/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4760 - acc: 0.4695 - val_loss: 2.2231 - val_acc: 0.2974\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.43830\n",
            "Epoch 303/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4847 - acc: 0.4765 - val_loss: 1.8168 - val_acc: 0.3721\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.43830\n",
            "Epoch 304/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4907 - acc: 0.4718 - val_loss: 2.5389 - val_acc: 0.3184\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.43830\n",
            "Epoch 305/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4929 - acc: 0.4640 - val_loss: 1.7655 - val_acc: 0.3933\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.43830\n",
            "Epoch 306/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4723 - acc: 0.4777 - val_loss: 2.7301 - val_acc: 0.2655\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.43830\n",
            "Epoch 307/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4631 - acc: 0.4774 - val_loss: 1.8091 - val_acc: 0.3733\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.43830\n",
            "Epoch 308/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4601 - acc: 0.4773 - val_loss: 1.9708 - val_acc: 0.3307\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.43830\n",
            "Epoch 309/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4892 - acc: 0.4765 - val_loss: 1.7737 - val_acc: 0.3983\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.43830\n",
            "Epoch 310/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4741 - acc: 0.4855 - val_loss: 1.6472 - val_acc: 0.4175\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.43830\n",
            "Epoch 311/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4837 - acc: 0.4739 - val_loss: 1.9196 - val_acc: 0.3697\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.43830\n",
            "Epoch 312/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4690 - acc: 0.4839 - val_loss: 2.3020 - val_acc: 0.3065\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.43830\n",
            "Epoch 313/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4679 - acc: 0.4752 - val_loss: 1.7933 - val_acc: 0.3978\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.43830\n",
            "Epoch 314/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4740 - acc: 0.4657 - val_loss: 1.8720 - val_acc: 0.3602\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.43830\n",
            "Epoch 315/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4743 - acc: 0.4789 - val_loss: 1.9909 - val_acc: 0.3377\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.43830\n",
            "Epoch 316/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4981 - acc: 0.4641 - val_loss: 1.7655 - val_acc: 0.4075\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.43830\n",
            "Epoch 317/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4779 - acc: 0.4855 - val_loss: 1.7965 - val_acc: 0.3500\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.43830\n",
            "Epoch 318/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4963 - acc: 0.4757 - val_loss: 1.9509 - val_acc: 0.3232\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.43830\n",
            "Epoch 319/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4826 - acc: 0.4724 - val_loss: 2.3946 - val_acc: 0.2928\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.43830\n",
            "Epoch 320/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4862 - acc: 0.4673 - val_loss: 1.6470 - val_acc: 0.4297\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.43830\n",
            "Epoch 321/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4705 - acc: 0.4799 - val_loss: 2.1150 - val_acc: 0.3596\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.43830\n",
            "Epoch 322/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4468 - acc: 0.4920 - val_loss: 1.7070 - val_acc: 0.4073\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.43830\n",
            "Epoch 323/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4645 - acc: 0.4830 - val_loss: 2.4349 - val_acc: 0.2649\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.43830\n",
            "Epoch 324/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4651 - acc: 0.4838 - val_loss: 2.1355 - val_acc: 0.2921\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.43830\n",
            "Epoch 325/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4495 - acc: 0.4935 - val_loss: 2.2887 - val_acc: 0.3236\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.43830\n",
            "Epoch 326/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4901 - acc: 0.4718 - val_loss: 3.8229 - val_acc: 0.1769\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.43830\n",
            "Epoch 327/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4712 - acc: 0.4759 - val_loss: 2.8266 - val_acc: 0.2490\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.43830\n",
            "Epoch 328/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4739 - acc: 0.4822 - val_loss: 2.6548 - val_acc: 0.2928\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.43830\n",
            "Epoch 329/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4678 - acc: 0.4875 - val_loss: 1.6983 - val_acc: 0.4148\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.43830\n",
            "Epoch 330/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4780 - acc: 0.4760 - val_loss: 1.8678 - val_acc: 0.3592\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.43830\n",
            "Epoch 331/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4752 - acc: 0.4808 - val_loss: 2.5401 - val_acc: 0.2925\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.43830\n",
            "Epoch 332/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4899 - acc: 0.4757 - val_loss: 2.3900 - val_acc: 0.2587\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.43830\n",
            "Epoch 333/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4477 - acc: 0.4756 - val_loss: 5.4919 - val_acc: 0.1430\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.43830\n",
            "Epoch 334/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4448 - acc: 0.4889 - val_loss: 2.2177 - val_acc: 0.2967\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.43830\n",
            "Epoch 335/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4459 - acc: 0.4863 - val_loss: 1.7985 - val_acc: 0.3998\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.43830\n",
            "Epoch 336/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4503 - acc: 0.4815 - val_loss: 1.7394 - val_acc: 0.4139\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.43830\n",
            "Epoch 337/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4767 - acc: 0.4683 - val_loss: 2.2439 - val_acc: 0.2783\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.43830\n",
            "Epoch 338/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4419 - acc: 0.4891 - val_loss: 2.3629 - val_acc: 0.3130\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.43830\n",
            "Epoch 339/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4447 - acc: 0.4869 - val_loss: 1.7612 - val_acc: 0.3884\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.43830\n",
            "Epoch 340/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4726 - acc: 0.4799 - val_loss: 6.0330 - val_acc: 0.1193\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.43830\n",
            "Epoch 341/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4640 - acc: 0.4729 - val_loss: 3.8114 - val_acc: 0.1778\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.43830\n",
            "Epoch 342/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4721 - acc: 0.4869 - val_loss: 1.5941 - val_acc: 0.4434\n",
            "\n",
            "Epoch 00342: val_acc improved from 0.43830 to 0.44340, saving model to /content/saved_models/cifar10_ResNet32v1_model.342.h5\n",
            "Epoch 343/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4704 - acc: 0.4746 - val_loss: 1.9321 - val_acc: 0.3273\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.44340\n",
            "Epoch 344/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4761 - acc: 0.4733 - val_loss: 1.9216 - val_acc: 0.3326\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.44340\n",
            "Epoch 345/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4892 - acc: 0.4678 - val_loss: 1.9018 - val_acc: 0.3489\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.44340\n",
            "Epoch 346/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4792 - acc: 0.4761 - val_loss: 2.7111 - val_acc: 0.2575\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.44340\n",
            "Epoch 347/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4513 - acc: 0.4856 - val_loss: 2.9026 - val_acc: 0.2185\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.44340\n",
            "Epoch 348/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4923 - acc: 0.4708 - val_loss: 2.0457 - val_acc: 0.3496\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.44340\n",
            "Epoch 349/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4527 - acc: 0.4859 - val_loss: 2.1464 - val_acc: 0.2973\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.44340\n",
            "Epoch 350/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4756 - acc: 0.4811 - val_loss: 1.8152 - val_acc: 0.3819\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.44340\n",
            "Epoch 351/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4369 - acc: 0.4872 - val_loss: 1.8505 - val_acc: 0.3843\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.44340\n",
            "Epoch 352/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4431 - acc: 0.4895 - val_loss: 2.2957 - val_acc: 0.2804\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.44340\n",
            "Epoch 353/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4607 - acc: 0.4753 - val_loss: 3.7532 - val_acc: 0.2318\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.44340\n",
            "Epoch 354/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4539 - acc: 0.4909 - val_loss: 3.2221 - val_acc: 0.2246\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.44340\n",
            "Epoch 355/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4480 - acc: 0.4842 - val_loss: 1.6382 - val_acc: 0.4348\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.44340\n",
            "Epoch 356/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4499 - acc: 0.4849 - val_loss: 1.7412 - val_acc: 0.4244\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.44340\n",
            "Epoch 357/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4602 - acc: 0.4795 - val_loss: 1.5971 - val_acc: 0.4412\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.44340\n",
            "Epoch 358/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4550 - acc: 0.4799 - val_loss: 2.5869 - val_acc: 0.2623\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.44340\n",
            "Epoch 359/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4467 - acc: 0.4840 - val_loss: 1.8668 - val_acc: 0.3689\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.44340\n",
            "Epoch 360/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4545 - acc: 0.4858 - val_loss: 1.8752 - val_acc: 0.3595\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.44340\n",
            "Epoch 361/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4578 - acc: 0.4907 - val_loss: 2.1152 - val_acc: 0.3297\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.44340\n",
            "Epoch 362/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4739 - acc: 0.4806 - val_loss: 2.2661 - val_acc: 0.2803\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.44340\n",
            "Epoch 363/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4394 - acc: 0.4916 - val_loss: 1.5020 - val_acc: 0.4780\n",
            "\n",
            "Epoch 00363: val_acc improved from 0.44340 to 0.47800, saving model to /content/saved_models/cifar10_ResNet32v1_model.363.h5\n",
            "Epoch 364/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4322 - acc: 0.4886 - val_loss: 1.8941 - val_acc: 0.3793\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.47800\n",
            "Epoch 365/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4429 - acc: 0.4900 - val_loss: 1.8416 - val_acc: 0.3989\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.47800\n",
            "Epoch 366/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4529 - acc: 0.4866 - val_loss: 1.8920 - val_acc: 0.3619\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.47800\n",
            "Epoch 367/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4589 - acc: 0.4874 - val_loss: 1.6863 - val_acc: 0.4306\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.47800\n",
            "Epoch 368/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4717 - acc: 0.4830 - val_loss: 1.7273 - val_acc: 0.4007\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.47800\n",
            "Epoch 369/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4595 - acc: 0.4793 - val_loss: 1.5410 - val_acc: 0.4362\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.47800\n",
            "Epoch 370/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4634 - acc: 0.4793 - val_loss: 2.6592 - val_acc: 0.2866\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.47800\n",
            "Epoch 371/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4580 - acc: 0.4814 - val_loss: 1.6349 - val_acc: 0.4318\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.47800\n",
            "Epoch 372/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4500 - acc: 0.4905 - val_loss: 2.0259 - val_acc: 0.3392\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.47800\n",
            "Epoch 373/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4707 - acc: 0.4768 - val_loss: 1.8354 - val_acc: 0.3757\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.47800\n",
            "Epoch 374/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4638 - acc: 0.4778 - val_loss: 1.9837 - val_acc: 0.3593\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.47800\n",
            "Epoch 375/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4579 - acc: 0.4818 - val_loss: 2.3714 - val_acc: 0.2938\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.47800\n",
            "Epoch 376/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4718 - acc: 0.4810 - val_loss: 1.9477 - val_acc: 0.3393\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.47800\n",
            "Epoch 377/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4364 - acc: 0.4892 - val_loss: 2.6025 - val_acc: 0.2437\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.47800\n",
            "Epoch 378/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4428 - acc: 0.4890 - val_loss: 1.7210 - val_acc: 0.3919\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.47800\n",
            "Epoch 379/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4535 - acc: 0.4837 - val_loss: 1.9298 - val_acc: 0.3318\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.47800\n",
            "Epoch 380/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4529 - acc: 0.4898 - val_loss: 2.2553 - val_acc: 0.2981\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.47800\n",
            "Epoch 381/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4293 - acc: 0.4938 - val_loss: 1.9446 - val_acc: 0.3627\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.47800\n",
            "Epoch 382/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4410 - acc: 0.4889 - val_loss: 1.6781 - val_acc: 0.4173\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.47800\n",
            "Epoch 383/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4493 - acc: 0.4927 - val_loss: 1.7867 - val_acc: 0.4100\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.47800\n",
            "Epoch 384/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4616 - acc: 0.4863 - val_loss: 2.4230 - val_acc: 0.2688\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.47800\n",
            "Epoch 385/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4687 - acc: 0.4772 - val_loss: 1.9080 - val_acc: 0.3471\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.47800\n",
            "Epoch 386/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4559 - acc: 0.4852 - val_loss: 2.8055 - val_acc: 0.2414\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.47800\n",
            "Epoch 387/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4487 - acc: 0.4804 - val_loss: 2.1184 - val_acc: 0.2975\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.47800\n",
            "Epoch 388/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4303 - acc: 0.4965 - val_loss: 2.5366 - val_acc: 0.2734\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.47800\n",
            "Epoch 389/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4627 - acc: 0.4847 - val_loss: 2.8391 - val_acc: 0.2651\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.47800\n",
            "Epoch 390/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4577 - acc: 0.4796 - val_loss: 1.7493 - val_acc: 0.4021\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.47800\n",
            "Epoch 391/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4451 - acc: 0.4861 - val_loss: 4.0172 - val_acc: 0.1864\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.47800\n",
            "Epoch 392/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4477 - acc: 0.4820 - val_loss: 2.6081 - val_acc: 0.2777\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.47800\n",
            "Epoch 393/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4563 - acc: 0.4833 - val_loss: 2.3790 - val_acc: 0.2791\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.47800\n",
            "Epoch 394/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4464 - acc: 0.5000 - val_loss: 3.6278 - val_acc: 0.1885\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.47800\n",
            "Epoch 395/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4528 - acc: 0.4824 - val_loss: 1.7396 - val_acc: 0.4134\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.47800\n",
            "Epoch 396/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4187 - acc: 0.4931 - val_loss: 1.5443 - val_acc: 0.4401\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.47800\n",
            "Epoch 397/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4673 - acc: 0.4858 - val_loss: 2.2675 - val_acc: 0.3019\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.47800\n",
            "Epoch 398/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4299 - acc: 0.4932 - val_loss: 1.7233 - val_acc: 0.3906\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.47800\n",
            "Epoch 399/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4399 - acc: 0.4964 - val_loss: 2.3570 - val_acc: 0.2977\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.47800\n",
            "Epoch 400/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4454 - acc: 0.4845 - val_loss: 2.6687 - val_acc: 0.2960\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.47800\n",
            "Epoch 401/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4413 - acc: 0.4824 - val_loss: 2.4479 - val_acc: 0.2776\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.47800\n",
            "Epoch 402/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4266 - acc: 0.4923 - val_loss: 1.4409 - val_acc: 0.4872\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.47800 to 0.48720, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4189 - acc: 0.4965 - val_loss: 1.4385 - val_acc: 0.4917\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.48720 to 0.49170, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4485 - acc: 0.4878 - val_loss: 1.4393 - val_acc: 0.4909\n",
            "\n",
            "Epoch 00404: val_acc did not improve from 0.49170\n",
            "Epoch 405/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4315 - acc: 0.4989 - val_loss: 1.4533 - val_acc: 0.4844\n",
            "\n",
            "Epoch 00405: val_acc did not improve from 0.49170\n",
            "Epoch 406/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4157 - acc: 0.4968 - val_loss: 1.4389 - val_acc: 0.4904\n",
            "\n",
            "Epoch 00406: val_acc did not improve from 0.49170\n",
            "Epoch 407/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4334 - acc: 0.4930 - val_loss: 1.4447 - val_acc: 0.4846\n",
            "\n",
            "Epoch 00407: val_acc did not improve from 0.49170\n",
            "Epoch 408/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4208 - acc: 0.4998 - val_loss: 1.4522 - val_acc: 0.4864\n",
            "\n",
            "Epoch 00408: val_acc did not improve from 0.49170\n",
            "Epoch 409/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4347 - acc: 0.4959 - val_loss: 1.4467 - val_acc: 0.4913\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.49170\n",
            "Epoch 410/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4068 - acc: 0.4982 - val_loss: 1.4733 - val_acc: 0.4778\n",
            "\n",
            "Epoch 00410: val_acc did not improve from 0.49170\n",
            "Epoch 411/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4244 - acc: 0.5033 - val_loss: 1.5425 - val_acc: 0.4564\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.49170\n",
            "Epoch 412/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4015 - acc: 0.5162 - val_loss: 1.4419 - val_acc: 0.4879\n",
            "\n",
            "Epoch 00412: val_acc did not improve from 0.49170\n",
            "Epoch 413/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4348 - acc: 0.4951 - val_loss: 1.4313 - val_acc: 0.4913\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.49170\n",
            "Epoch 414/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3941 - acc: 0.5057 - val_loss: 1.4699 - val_acc: 0.4792\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.49170\n",
            "Epoch 415/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4082 - acc: 0.5008 - val_loss: 1.4861 - val_acc: 0.4765\n",
            "\n",
            "Epoch 00415: val_acc did not improve from 0.49170\n",
            "Epoch 416/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4362 - acc: 0.4931 - val_loss: 1.5145 - val_acc: 0.4629\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.49170\n",
            "Epoch 417/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4361 - acc: 0.4858 - val_loss: 1.4506 - val_acc: 0.4868\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.49170\n",
            "Epoch 418/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4326 - acc: 0.4909 - val_loss: 1.4420 - val_acc: 0.4889\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.49170\n",
            "Epoch 419/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4224 - acc: 0.5012 - val_loss: 1.4882 - val_acc: 0.4726\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.49170\n",
            "Epoch 420/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4273 - acc: 0.4985 - val_loss: 1.4587 - val_acc: 0.4837\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.49170\n",
            "Epoch 421/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4186 - acc: 0.4930 - val_loss: 1.4601 - val_acc: 0.4836\n",
            "\n",
            "Epoch 00421: val_acc did not improve from 0.49170\n",
            "Epoch 422/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4155 - acc: 0.4967 - val_loss: 1.4600 - val_acc: 0.4803\n",
            "\n",
            "Epoch 00422: val_acc did not improve from 0.49170\n",
            "Epoch 423/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4134 - acc: 0.4957 - val_loss: 1.4441 - val_acc: 0.4882\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.49170\n",
            "Epoch 424/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4221 - acc: 0.5018 - val_loss: 1.4657 - val_acc: 0.4808\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.49170\n",
            "Epoch 425/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4163 - acc: 0.4985 - val_loss: 1.5124 - val_acc: 0.4651\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.49170\n",
            "Epoch 426/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4161 - acc: 0.5032 - val_loss: 1.4980 - val_acc: 0.4716\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.49170\n",
            "Epoch 427/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4268 - acc: 0.4903 - val_loss: 1.4442 - val_acc: 0.4894\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.49170\n",
            "Epoch 428/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4218 - acc: 0.5065 - val_loss: 1.4582 - val_acc: 0.4807\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.49170\n",
            "Epoch 429/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4247 - acc: 0.4889 - val_loss: 1.4688 - val_acc: 0.4783\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.49170\n",
            "Epoch 430/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4231 - acc: 0.5016 - val_loss: 1.4560 - val_acc: 0.4865\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.49170\n",
            "Epoch 431/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4216 - acc: 0.4905 - val_loss: 1.4317 - val_acc: 0.4916\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.49170\n",
            "Epoch 432/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4293 - acc: 0.4916 - val_loss: 1.4860 - val_acc: 0.4713\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.49170\n",
            "Epoch 433/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4120 - acc: 0.4958 - val_loss: 1.5199 - val_acc: 0.4628\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.49170\n",
            "Epoch 434/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4254 - acc: 0.4953 - val_loss: 1.4496 - val_acc: 0.4921\n",
            "\n",
            "Epoch 00434: val_acc improved from 0.49170 to 0.49210, saving model to /content/saved_models/cifar10_ResNet32v1_model.434.h5\n",
            "Epoch 435/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4221 - acc: 0.4975 - val_loss: 1.4749 - val_acc: 0.4810\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.49210\n",
            "Epoch 436/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4215 - acc: 0.4995 - val_loss: 1.5111 - val_acc: 0.4656\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.49210\n",
            "Epoch 437/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4013 - acc: 0.5110 - val_loss: 1.5055 - val_acc: 0.4668\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.49210\n",
            "Epoch 438/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4483 - acc: 0.4831 - val_loss: 1.4940 - val_acc: 0.4813\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.49210\n",
            "Epoch 439/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4249 - acc: 0.4997 - val_loss: 1.4951 - val_acc: 0.4747\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.49210\n",
            "Epoch 440/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4317 - acc: 0.4873 - val_loss: 1.4919 - val_acc: 0.4724\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.49210\n",
            "Epoch 441/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4271 - acc: 0.4873 - val_loss: 1.5022 - val_acc: 0.4685\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.49210\n",
            "Epoch 442/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4289 - acc: 0.4817 - val_loss: 1.5443 - val_acc: 0.4580\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.49210\n",
            "Epoch 443/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4004 - acc: 0.5034 - val_loss: 1.5362 - val_acc: 0.4611\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.49210\n",
            "Epoch 444/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4221 - acc: 0.5025 - val_loss: 1.4958 - val_acc: 0.4661\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.49210\n",
            "Epoch 445/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4105 - acc: 0.5113 - val_loss: 1.4298 - val_acc: 0.4942\n",
            "\n",
            "Epoch 00445: val_acc improved from 0.49210 to 0.49420, saving model to /content/saved_models/cifar10_ResNet32v1_model.445.h5\n",
            "Epoch 446/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4166 - acc: 0.4998 - val_loss: 1.4384 - val_acc: 0.4860\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.49420\n",
            "Epoch 447/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4352 - acc: 0.4950 - val_loss: 1.4342 - val_acc: 0.4866\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.49420\n",
            "Epoch 448/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4029 - acc: 0.5060 - val_loss: 1.4866 - val_acc: 0.4738\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.49420\n",
            "Epoch 449/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4321 - acc: 0.4936 - val_loss: 1.4270 - val_acc: 0.4917\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.49420\n",
            "Epoch 450/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4208 - acc: 0.4888 - val_loss: 1.4711 - val_acc: 0.4744\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.49420\n",
            "Epoch 451/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4262 - acc: 0.4980 - val_loss: 1.5550 - val_acc: 0.4506\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.49420\n",
            "Epoch 452/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4014 - acc: 0.5017 - val_loss: 1.5416 - val_acc: 0.4540\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.49420\n",
            "Epoch 453/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4380 - acc: 0.4967 - val_loss: 1.4203 - val_acc: 0.4964\n",
            "\n",
            "Epoch 00453: val_acc improved from 0.49420 to 0.49640, saving model to /content/saved_models/cifar10_ResNet32v1_model.453.h5\n",
            "Epoch 454/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4198 - acc: 0.4926 - val_loss: 1.5751 - val_acc: 0.4473\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.49640\n",
            "Epoch 455/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4331 - acc: 0.4843 - val_loss: 1.4534 - val_acc: 0.4879\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.49640\n",
            "Epoch 456/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4247 - acc: 0.4945 - val_loss: 1.4679 - val_acc: 0.4789\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.49640\n",
            "Epoch 457/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4197 - acc: 0.5014 - val_loss: 1.4517 - val_acc: 0.4843\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.49640\n",
            "Epoch 458/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4203 - acc: 0.4952 - val_loss: 1.4358 - val_acc: 0.4918\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.49640\n",
            "Epoch 459/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4366 - acc: 0.4968 - val_loss: 1.4028 - val_acc: 0.4970\n",
            "\n",
            "Epoch 00459: val_acc improved from 0.49640 to 0.49700, saving model to /content/saved_models/cifar10_ResNet32v1_model.459.h5\n",
            "Epoch 460/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3910 - acc: 0.5071 - val_loss: 1.4511 - val_acc: 0.4811\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.49700\n",
            "Epoch 461/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4094 - acc: 0.5043 - val_loss: 1.5319 - val_acc: 0.4535\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.49700\n",
            "Epoch 462/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4107 - acc: 0.5025 - val_loss: 1.5297 - val_acc: 0.4612\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.49700\n",
            "Epoch 463/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4491 - acc: 0.4897 - val_loss: 1.4578 - val_acc: 0.4791\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.49700\n",
            "Epoch 464/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4269 - acc: 0.4943 - val_loss: 1.5914 - val_acc: 0.4371\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.49700\n",
            "Epoch 465/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4351 - acc: 0.4952 - val_loss: 1.5246 - val_acc: 0.4609\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.49700\n",
            "Epoch 466/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4389 - acc: 0.4926 - val_loss: 1.5577 - val_acc: 0.4467\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.49700\n",
            "Epoch 467/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4126 - acc: 0.4973 - val_loss: 1.4882 - val_acc: 0.4736\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.49700\n",
            "Epoch 468/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4157 - acc: 0.5027 - val_loss: 1.5231 - val_acc: 0.4618\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.49700\n",
            "Epoch 469/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4259 - acc: 0.4954 - val_loss: 1.5825 - val_acc: 0.4558\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.49700\n",
            "Epoch 470/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4170 - acc: 0.5003 - val_loss: 1.4198 - val_acc: 0.4951\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.49700\n",
            "Epoch 471/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4154 - acc: 0.4950 - val_loss: 1.4463 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.49700\n",
            "Epoch 472/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4281 - acc: 0.4951 - val_loss: 1.5257 - val_acc: 0.4590\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.49700\n",
            "Epoch 473/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4269 - acc: 0.5002 - val_loss: 1.4499 - val_acc: 0.4835\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.49700\n",
            "Epoch 474/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4165 - acc: 0.5010 - val_loss: 1.4745 - val_acc: 0.4754\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.49700\n",
            "Epoch 475/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4171 - acc: 0.4956 - val_loss: 1.5431 - val_acc: 0.4566\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.49700\n",
            "Epoch 476/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3927 - acc: 0.5139 - val_loss: 1.4864 - val_acc: 0.4719\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.49700\n",
            "Epoch 477/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4159 - acc: 0.5019 - val_loss: 1.4884 - val_acc: 0.4700\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.49700\n",
            "Epoch 478/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4122 - acc: 0.5022 - val_loss: 1.4673 - val_acc: 0.4777\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.49700\n",
            "Epoch 479/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4073 - acc: 0.4964 - val_loss: 1.4664 - val_acc: 0.4766\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.49700\n",
            "Epoch 480/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4338 - acc: 0.4964 - val_loss: 1.4549 - val_acc: 0.4815\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.49700\n",
            "Epoch 481/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4293 - acc: 0.4955 - val_loss: 1.5071 - val_acc: 0.4646\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.49700\n",
            "Epoch 482/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4193 - acc: 0.4930 - val_loss: 1.5037 - val_acc: 0.4751\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.49700\n",
            "Epoch 483/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4335 - acc: 0.4949 - val_loss: 1.5272 - val_acc: 0.4608\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.49700\n",
            "Epoch 484/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4379 - acc: 0.4943 - val_loss: 1.4947 - val_acc: 0.4722\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.49700\n",
            "Epoch 485/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3967 - acc: 0.4984 - val_loss: 1.4694 - val_acc: 0.4792\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.49700\n",
            "Epoch 486/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4284 - acc: 0.4908 - val_loss: 1.5889 - val_acc: 0.4422\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.49700\n",
            "Epoch 487/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4088 - acc: 0.5004 - val_loss: 1.4307 - val_acc: 0.4880\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.49700\n",
            "Epoch 488/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4288 - acc: 0.4974 - val_loss: 1.4852 - val_acc: 0.4742\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.49700\n",
            "Epoch 489/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4202 - acc: 0.5004 - val_loss: 1.4955 - val_acc: 0.4731\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.49700\n",
            "Epoch 490/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4320 - acc: 0.4966 - val_loss: 1.4779 - val_acc: 0.4764\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.49700\n",
            "Epoch 491/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4320 - acc: 0.4945 - val_loss: 1.4408 - val_acc: 0.4853\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.49700\n",
            "Epoch 492/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3977 - acc: 0.4972 - val_loss: 1.4160 - val_acc: 0.4989\n",
            "\n",
            "Epoch 00492: val_acc improved from 0.49700 to 0.49890, saving model to /content/saved_models/cifar10_ResNet32v1_model.492.h5\n",
            "Epoch 493/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4349 - acc: 0.4945 - val_loss: 1.4306 - val_acc: 0.4905\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.49890\n",
            "Epoch 494/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4359 - acc: 0.4942 - val_loss: 1.4352 - val_acc: 0.4877\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.49890\n",
            "Epoch 495/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4133 - acc: 0.4972 - val_loss: 1.5413 - val_acc: 0.4562\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.49890\n",
            "Epoch 496/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4292 - acc: 0.4911 - val_loss: 1.5055 - val_acc: 0.4688\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.49890\n",
            "Epoch 497/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4319 - acc: 0.4924 - val_loss: 1.5115 - val_acc: 0.4618\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.49890\n",
            "Epoch 498/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4041 - acc: 0.5061 - val_loss: 1.4710 - val_acc: 0.4832\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.49890\n",
            "Epoch 499/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4124 - acc: 0.4941 - val_loss: 1.4447 - val_acc: 0.4892\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.49890\n",
            "Epoch 500/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4156 - acc: 0.5044 - val_loss: 1.4721 - val_acc: 0.4795\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.49890\n",
            "Epoch 501/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3985 - acc: 0.5034 - val_loss: 1.4977 - val_acc: 0.4737\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.49890\n",
            "Epoch 502/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4317 - acc: 0.4936 - val_loss: 1.4578 - val_acc: 0.4817\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.49890\n",
            "Epoch 503/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3923 - acc: 0.5025 - val_loss: 1.5402 - val_acc: 0.4586\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.49890\n",
            "Epoch 504/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4252 - acc: 0.4942 - val_loss: 1.5073 - val_acc: 0.4751\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.49890\n",
            "Epoch 505/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4146 - acc: 0.5109 - val_loss: 1.4281 - val_acc: 0.4926\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.49890\n",
            "Epoch 506/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4195 - acc: 0.4958 - val_loss: 1.4599 - val_acc: 0.4750\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.49890\n",
            "Epoch 507/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4179 - acc: 0.5009 - val_loss: 1.4631 - val_acc: 0.4811\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.49890\n",
            "Epoch 508/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4088 - acc: 0.5008 - val_loss: 1.5452 - val_acc: 0.4652\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.49890\n",
            "Epoch 509/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4302 - acc: 0.4882 - val_loss: 1.6586 - val_acc: 0.4302\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.49890\n",
            "Epoch 510/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4158 - acc: 0.4965 - val_loss: 1.5984 - val_acc: 0.4390\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.49890\n",
            "Epoch 511/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4065 - acc: 0.5073 - val_loss: 1.6285 - val_acc: 0.4321\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.49890\n",
            "Epoch 512/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4174 - acc: 0.4946 - val_loss: 1.4502 - val_acc: 0.4888\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.49890\n",
            "Epoch 513/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4119 - acc: 0.5001 - val_loss: 1.4371 - val_acc: 0.4825\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.49890\n",
            "Epoch 514/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3998 - acc: 0.5042 - val_loss: 1.4705 - val_acc: 0.4833\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.49890\n",
            "Epoch 515/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4160 - acc: 0.4920 - val_loss: 1.4626 - val_acc: 0.4811\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.49890\n",
            "Epoch 516/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4108 - acc: 0.5007 - val_loss: 1.4797 - val_acc: 0.4756\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.49890\n",
            "Epoch 517/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4323 - acc: 0.4953 - val_loss: 1.4930 - val_acc: 0.4676\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.49890\n",
            "Epoch 518/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4333 - acc: 0.4890 - val_loss: 1.4736 - val_acc: 0.4795\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.49890\n",
            "Epoch 519/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4219 - acc: 0.5025 - val_loss: 1.5445 - val_acc: 0.4531\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.49890\n",
            "Epoch 520/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4241 - acc: 0.4974 - val_loss: 1.4652 - val_acc: 0.4800\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.49890\n",
            "Epoch 521/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4212 - acc: 0.4953 - val_loss: 1.4370 - val_acc: 0.4893\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.49890\n",
            "Epoch 522/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4090 - acc: 0.5026 - val_loss: 1.5092 - val_acc: 0.4672\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.49890\n",
            "Epoch 523/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4351 - acc: 0.4966 - val_loss: 1.4888 - val_acc: 0.4739\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.49890\n",
            "Epoch 524/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4308 - acc: 0.4984 - val_loss: 1.5109 - val_acc: 0.4697\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.49890\n",
            "Epoch 525/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4146 - acc: 0.4917 - val_loss: 1.4345 - val_acc: 0.4844\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.49890\n",
            "Epoch 526/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4132 - acc: 0.4925 - val_loss: 1.4792 - val_acc: 0.4741\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.49890\n",
            "Epoch 527/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4007 - acc: 0.5069 - val_loss: 1.4397 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.49890\n",
            "Epoch 528/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4195 - acc: 0.5036 - val_loss: 1.4853 - val_acc: 0.4771\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.49890\n",
            "Epoch 529/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4157 - acc: 0.4961 - val_loss: 1.5211 - val_acc: 0.4631\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.49890\n",
            "Epoch 530/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4153 - acc: 0.4987 - val_loss: 1.4299 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.49890\n",
            "Epoch 531/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4102 - acc: 0.4957 - val_loss: 1.4295 - val_acc: 0.4933\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.49890\n",
            "Epoch 532/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4140 - acc: 0.5080 - val_loss: 1.4794 - val_acc: 0.4718\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.49890\n",
            "Epoch 533/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4195 - acc: 0.4967 - val_loss: 1.4649 - val_acc: 0.4815\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.49890\n",
            "Epoch 534/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4314 - acc: 0.4911 - val_loss: 1.4475 - val_acc: 0.4871\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.49890\n",
            "Epoch 535/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4179 - acc: 0.4957 - val_loss: 1.4227 - val_acc: 0.4928\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.49890\n",
            "Epoch 536/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4439 - acc: 0.4874 - val_loss: 1.4692 - val_acc: 0.4781\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.49890\n",
            "Epoch 537/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4258 - acc: 0.4958 - val_loss: 1.4442 - val_acc: 0.4851\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.49890\n",
            "Epoch 538/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4429 - acc: 0.4883 - val_loss: 1.4429 - val_acc: 0.4893\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.49890\n",
            "Epoch 539/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4036 - acc: 0.4979 - val_loss: 1.4729 - val_acc: 0.4787\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.49890\n",
            "Epoch 540/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4179 - acc: 0.4980 - val_loss: 1.4453 - val_acc: 0.4886\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.49890\n",
            "Epoch 541/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4088 - acc: 0.5012 - val_loss: 1.4682 - val_acc: 0.4821\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.49890\n",
            "Epoch 542/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4029 - acc: 0.5035 - val_loss: 1.5213 - val_acc: 0.4631\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.49890\n",
            "Epoch 543/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4214 - acc: 0.5036 - val_loss: 1.4846 - val_acc: 0.4702\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.49890\n",
            "Epoch 544/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4132 - acc: 0.5052 - val_loss: 1.4913 - val_acc: 0.4706\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.49890\n",
            "Epoch 545/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4135 - acc: 0.4999 - val_loss: 1.4041 - val_acc: 0.5021\n",
            "\n",
            "Epoch 00545: val_acc improved from 0.49890 to 0.50210, saving model to /content/saved_models/cifar10_ResNet32v1_model.545.h5\n",
            "Epoch 546/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4111 - acc: 0.4998 - val_loss: 1.4652 - val_acc: 0.4842\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.50210\n",
            "Epoch 547/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3933 - acc: 0.5043 - val_loss: 1.5364 - val_acc: 0.4558\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.50210\n",
            "Epoch 548/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4175 - acc: 0.4980 - val_loss: 1.6157 - val_acc: 0.4411\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.50210\n",
            "Epoch 549/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4013 - acc: 0.4980 - val_loss: 1.5094 - val_acc: 0.4674\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.50210\n",
            "Epoch 550/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4141 - acc: 0.4988 - val_loss: 1.4842 - val_acc: 0.4706\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.50210\n",
            "Epoch 551/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4316 - acc: 0.4931 - val_loss: 1.5502 - val_acc: 0.4518\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.50210\n",
            "Epoch 552/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4140 - acc: 0.4932 - val_loss: 1.4870 - val_acc: 0.4664\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.50210\n",
            "Epoch 553/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4317 - acc: 0.4839 - val_loss: 1.5658 - val_acc: 0.4542\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.50210\n",
            "Epoch 554/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4195 - acc: 0.4913 - val_loss: 1.5072 - val_acc: 0.4674\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.50210\n",
            "Epoch 555/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4062 - acc: 0.5039 - val_loss: 1.4323 - val_acc: 0.4880\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.50210\n",
            "Epoch 556/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4047 - acc: 0.5116 - val_loss: 1.4492 - val_acc: 0.4884\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.50210\n",
            "Epoch 557/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4130 - acc: 0.5083 - val_loss: 1.4145 - val_acc: 0.5008\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.50210\n",
            "Epoch 558/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4261 - acc: 0.4959 - val_loss: 1.4273 - val_acc: 0.4949\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.50210\n",
            "Epoch 559/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4305 - acc: 0.5016 - val_loss: 1.5448 - val_acc: 0.4526\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.50210\n",
            "Epoch 560/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4127 - acc: 0.5024 - val_loss: 1.5339 - val_acc: 0.4533\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.50210\n",
            "Epoch 561/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4384 - acc: 0.4868 - val_loss: 1.4967 - val_acc: 0.4743\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.50210\n",
            "Epoch 562/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4005 - acc: 0.5054 - val_loss: 1.4337 - val_acc: 0.4893\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.50210\n",
            "Epoch 563/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4061 - acc: 0.5016 - val_loss: 1.4954 - val_acc: 0.4735\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.50210\n",
            "Epoch 564/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4389 - acc: 0.4822 - val_loss: 1.4872 - val_acc: 0.4752\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.50210\n",
            "Epoch 565/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4408 - acc: 0.4935 - val_loss: 1.4759 - val_acc: 0.4776\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.50210\n",
            "Epoch 566/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3958 - acc: 0.5042 - val_loss: 1.7184 - val_acc: 0.4039\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.50210\n",
            "Epoch 567/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4158 - acc: 0.4941 - val_loss: 1.5587 - val_acc: 0.4522\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.50210\n",
            "Epoch 568/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4303 - acc: 0.4846 - val_loss: 1.4700 - val_acc: 0.4847\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.50210\n",
            "Epoch 569/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4190 - acc: 0.4934 - val_loss: 1.5087 - val_acc: 0.4652\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.50210\n",
            "Epoch 570/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4147 - acc: 0.4984 - val_loss: 1.4717 - val_acc: 0.4795\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.50210\n",
            "Epoch 571/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4311 - acc: 0.4868 - val_loss: 1.4361 - val_acc: 0.4887\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.50210\n",
            "Epoch 572/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4312 - acc: 0.4971 - val_loss: 1.4891 - val_acc: 0.4712\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.50210\n",
            "Epoch 573/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.4146 - acc: 0.4920 - val_loss: 1.4751 - val_acc: 0.4788\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.50210\n",
            "Epoch 574/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.3934 - acc: 0.5020 - val_loss: 1.5225 - val_acc: 0.4647\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.50210\n",
            "Epoch 575/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4318 - acc: 0.4936 - val_loss: 1.4122 - val_acc: 0.5004\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.50210\n",
            "Epoch 576/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4280 - acc: 0.4981 - val_loss: 1.4512 - val_acc: 0.4864\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.50210\n",
            "Epoch 577/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4021 - acc: 0.5057 - val_loss: 1.5826 - val_acc: 0.4472\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.50210\n",
            "Epoch 578/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4187 - acc: 0.4937 - val_loss: 1.4705 - val_acc: 0.4804\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.50210\n",
            "Epoch 579/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4284 - acc: 0.4887 - val_loss: 1.4422 - val_acc: 0.4863\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.50210\n",
            "Epoch 580/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4145 - acc: 0.4947 - val_loss: 1.4511 - val_acc: 0.4800\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.50210\n",
            "Epoch 581/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4110 - acc: 0.4924 - val_loss: 1.4371 - val_acc: 0.4951\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.50210\n",
            "Epoch 582/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4116 - acc: 0.4994 - val_loss: 1.4866 - val_acc: 0.4728\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.50210\n",
            "Epoch 583/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4092 - acc: 0.5031 - val_loss: 1.4851 - val_acc: 0.4751\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.50210\n",
            "Epoch 584/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4091 - acc: 0.4978 - val_loss: 1.5146 - val_acc: 0.4639\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.50210\n",
            "Epoch 585/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4124 - acc: 0.4995 - val_loss: 1.4865 - val_acc: 0.4741\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.50210\n",
            "Epoch 586/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4214 - acc: 0.4919 - val_loss: 1.5429 - val_acc: 0.4590\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.50210\n",
            "Epoch 587/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4367 - acc: 0.4942 - val_loss: 1.5442 - val_acc: 0.4597\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.50210\n",
            "Epoch 588/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4128 - acc: 0.5062 - val_loss: 1.5097 - val_acc: 0.4661\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.50210\n",
            "Epoch 589/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4176 - acc: 0.5016 - val_loss: 1.4869 - val_acc: 0.4708\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.50210\n",
            "Epoch 590/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4080 - acc: 0.5059 - val_loss: 1.4563 - val_acc: 0.4847\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.50210\n",
            "Epoch 591/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4097 - acc: 0.5063 - val_loss: 1.5858 - val_acc: 0.4418\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.50210\n",
            "Epoch 592/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4234 - acc: 0.4823 - val_loss: 1.4440 - val_acc: 0.4882\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.50210\n",
            "Epoch 593/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.3909 - acc: 0.5061 - val_loss: 1.4526 - val_acc: 0.4828\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.50210\n",
            "Epoch 594/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4277 - acc: 0.4993 - val_loss: 1.5998 - val_acc: 0.4392\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.50210\n",
            "Epoch 595/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4194 - acc: 0.4962 - val_loss: 1.4603 - val_acc: 0.4789\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.50210\n",
            "Epoch 596/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4204 - acc: 0.4913 - val_loss: 1.5008 - val_acc: 0.4639\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.50210\n",
            "Epoch 597/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4248 - acc: 0.5006 - val_loss: 1.4445 - val_acc: 0.4873\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.50210\n",
            "Epoch 598/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3965 - acc: 0.5016 - val_loss: 1.4716 - val_acc: 0.4771\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.50210\n",
            "Epoch 599/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4149 - acc: 0.4998 - val_loss: 1.4975 - val_acc: 0.4659\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.50210\n",
            "Epoch 600/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4317 - acc: 0.4826 - val_loss: 1.4559 - val_acc: 0.4812\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.50210\n",
            "Epoch 601/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4242 - acc: 0.4902 - val_loss: 1.4475 - val_acc: 0.4845\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.50210\n",
            "Epoch 602/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4290 - acc: 0.4955 - val_loss: 1.4331 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00602: val_acc did not improve from 0.50210\n",
            "Epoch 603/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4246 - acc: 0.4963 - val_loss: 1.4408 - val_acc: 0.4882\n",
            "\n",
            "Epoch 00603: val_acc did not improve from 0.50210\n",
            "Epoch 604/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4319 - acc: 0.4906 - val_loss: 1.4402 - val_acc: 0.4886\n",
            "\n",
            "Epoch 00604: val_acc did not improve from 0.50210\n",
            "Epoch 605/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4097 - acc: 0.4974 - val_loss: 1.4432 - val_acc: 0.4882\n",
            "\n",
            "Epoch 00605: val_acc did not improve from 0.50210\n",
            "Epoch 606/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4261 - acc: 0.4864 - val_loss: 1.4322 - val_acc: 0.4891\n",
            "\n",
            "Epoch 00606: val_acc did not improve from 0.50210\n",
            "Epoch 607/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4512 - acc: 0.4864 - val_loss: 1.4261 - val_acc: 0.4914\n",
            "\n",
            "Epoch 00607: val_acc did not improve from 0.50210\n",
            "Epoch 608/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4125 - acc: 0.5037 - val_loss: 1.4332 - val_acc: 0.4894\n",
            "\n",
            "Epoch 00608: val_acc did not improve from 0.50210\n",
            "Epoch 609/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4324 - acc: 0.5003 - val_loss: 1.4320 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00609: val_acc did not improve from 0.50210\n",
            "Epoch 610/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4083 - acc: 0.4955 - val_loss: 1.4318 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00610: val_acc did not improve from 0.50210\n",
            "Epoch 611/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3880 - acc: 0.5053 - val_loss: 1.4387 - val_acc: 0.4880\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.50210\n",
            "Epoch 612/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4131 - acc: 0.4990 - val_loss: 1.4316 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00612: val_acc did not improve from 0.50210\n",
            "Epoch 613/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4169 - acc: 0.4969 - val_loss: 1.4294 - val_acc: 0.4930\n",
            "\n",
            "Epoch 00613: val_acc did not improve from 0.50210\n",
            "Epoch 614/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4192 - acc: 0.4969 - val_loss: 1.4360 - val_acc: 0.4894\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.50210\n",
            "Epoch 615/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4058 - acc: 0.4943 - val_loss: 1.4426 - val_acc: 0.4868\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.50210\n",
            "Epoch 616/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4328 - acc: 0.4929 - val_loss: 1.4271 - val_acc: 0.4915\n",
            "\n",
            "Epoch 00616: val_acc did not improve from 0.50210\n",
            "Epoch 617/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4132 - acc: 0.4961 - val_loss: 1.4340 - val_acc: 0.4906\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.50210\n",
            "Epoch 618/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4421 - acc: 0.4847 - val_loss: 1.4332 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00618: val_acc did not improve from 0.50210\n",
            "Epoch 619/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4149 - acc: 0.5001 - val_loss: 1.4389 - val_acc: 0.4887\n",
            "\n",
            "Epoch 00619: val_acc did not improve from 0.50210\n",
            "Epoch 620/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4144 - acc: 0.4975 - val_loss: 1.4340 - val_acc: 0.4908\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.50210\n",
            "Epoch 621/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4016 - acc: 0.5007 - val_loss: 1.4393 - val_acc: 0.4885\n",
            "\n",
            "Epoch 00621: val_acc did not improve from 0.50210\n",
            "Epoch 622/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4204 - acc: 0.5009 - val_loss: 1.4304 - val_acc: 0.4911\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.50210\n",
            "Epoch 623/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4121 - acc: 0.5080 - val_loss: 1.4306 - val_acc: 0.4909\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.50210\n",
            "Epoch 624/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4275 - acc: 0.4948 - val_loss: 1.4322 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.50210\n",
            "Epoch 625/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.3957 - acc: 0.5048 - val_loss: 1.4320 - val_acc: 0.4906\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.50210\n",
            "Epoch 626/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4207 - acc: 0.4979 - val_loss: 1.4480 - val_acc: 0.4864\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.50210\n",
            "Epoch 627/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4038 - acc: 0.5003 - val_loss: 1.4412 - val_acc: 0.4874\n",
            "\n",
            "Epoch 00627: val_acc did not improve from 0.50210\n",
            "Epoch 628/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4064 - acc: 0.4988 - val_loss: 1.4359 - val_acc: 0.4909\n",
            "\n",
            "Epoch 00628: val_acc did not improve from 0.50210\n",
            "Epoch 629/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4192 - acc: 0.4986 - val_loss: 1.4349 - val_acc: 0.4898\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.50210\n",
            "Epoch 630/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3980 - acc: 0.5085 - val_loss: 1.4443 - val_acc: 0.4874\n",
            "\n",
            "Epoch 00630: val_acc did not improve from 0.50210\n",
            "Epoch 631/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.3976 - acc: 0.4989 - val_loss: 1.4342 - val_acc: 0.4922\n",
            "\n",
            "Epoch 00631: val_acc did not improve from 0.50210\n",
            "Epoch 632/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.3969 - acc: 0.5027 - val_loss: 1.4433 - val_acc: 0.4884\n",
            "\n",
            "Epoch 00632: val_acc did not improve from 0.50210\n",
            "Epoch 633/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4236 - acc: 0.4908 - val_loss: 1.4493 - val_acc: 0.4870\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.50210\n",
            "Epoch 634/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4520 - acc: 0.4910 - val_loss: 1.4461 - val_acc: 0.4867\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.50210\n",
            "Epoch 635/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4291 - acc: 0.4902 - val_loss: 1.4365 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.50210\n",
            "Epoch 636/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4145 - acc: 0.4996 - val_loss: 1.4323 - val_acc: 0.4911\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.50210\n",
            "Epoch 637/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4248 - acc: 0.4982 - val_loss: 1.4351 - val_acc: 0.4884\n",
            "\n",
            "Epoch 00637: val_acc did not improve from 0.50210\n",
            "Epoch 638/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4022 - acc: 0.4967 - val_loss: 1.4308 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.50210\n",
            "Epoch 639/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3858 - acc: 0.5029 - val_loss: 1.4379 - val_acc: 0.4890\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.50210\n",
            "Epoch 640/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4253 - acc: 0.5036 - val_loss: 1.4259 - val_acc: 0.4926\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.50210\n",
            "Epoch 641/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4011 - acc: 0.5058 - val_loss: 1.4358 - val_acc: 0.4914\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.50210\n",
            "Epoch 642/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4295 - acc: 0.4987 - val_loss: 1.4345 - val_acc: 0.4888\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.50210\n",
            "Epoch 643/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4224 - acc: 0.4966 - val_loss: 1.4317 - val_acc: 0.4892\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.50210\n",
            "Epoch 644/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4211 - acc: 0.5008 - val_loss: 1.4409 - val_acc: 0.4880\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.50210\n",
            "Epoch 645/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4247 - acc: 0.4941 - val_loss: 1.4438 - val_acc: 0.4883\n",
            "\n",
            "Epoch 00645: val_acc did not improve from 0.50210\n",
            "Epoch 646/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.4114 - acc: 0.5068 - val_loss: 1.4315 - val_acc: 0.4898\n",
            "\n",
            "Epoch 00646: val_acc did not improve from 0.50210\n",
            "Epoch 647/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4392 - acc: 0.4901 - val_loss: 1.4329 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00647: val_acc did not improve from 0.50210\n",
            "Epoch 648/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4017 - acc: 0.5068 - val_loss: 1.4358 - val_acc: 0.4893\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.50210\n",
            "Epoch 649/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4292 - acc: 0.4915 - val_loss: 1.4361 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.50210\n",
            "Epoch 650/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4096 - acc: 0.5014 - val_loss: 1.4297 - val_acc: 0.4923\n",
            "\n",
            "Epoch 00650: val_acc did not improve from 0.50210\n",
            "Epoch 651/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4104 - acc: 0.5040 - val_loss: 1.4398 - val_acc: 0.4889\n",
            "\n",
            "Epoch 00651: val_acc did not improve from 0.50210\n",
            "Epoch 652/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4008 - acc: 0.5104 - val_loss: 1.4316 - val_acc: 0.4911\n",
            "\n",
            "Epoch 00652: val_acc did not improve from 0.50210\n",
            "Epoch 653/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4238 - acc: 0.4962 - val_loss: 1.4304 - val_acc: 0.4915\n",
            "\n",
            "Epoch 00653: val_acc did not improve from 0.50210\n",
            "Epoch 654/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4306 - acc: 0.4993 - val_loss: 1.4304 - val_acc: 0.4914\n",
            "\n",
            "Epoch 00654: val_acc did not improve from 0.50210\n",
            "Epoch 655/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4099 - acc: 0.5096 - val_loss: 1.4342 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00655: val_acc did not improve from 0.50210\n",
            "Epoch 656/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4192 - acc: 0.5023 - val_loss: 1.4368 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00656: val_acc did not improve from 0.50210\n",
            "Epoch 657/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4031 - acc: 0.5112 - val_loss: 1.4339 - val_acc: 0.4905\n",
            "\n",
            "Epoch 00657: val_acc did not improve from 0.50210\n",
            "Epoch 658/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.3993 - acc: 0.5098 - val_loss: 1.4296 - val_acc: 0.4908\n",
            "\n",
            "Epoch 00658: val_acc did not improve from 0.50210\n",
            "Epoch 659/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3950 - acc: 0.5022 - val_loss: 1.4350 - val_acc: 0.4898\n",
            "\n",
            "Epoch 00659: val_acc did not improve from 0.50210\n",
            "Epoch 660/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4171 - acc: 0.4957 - val_loss: 1.4291 - val_acc: 0.4915\n",
            "\n",
            "Epoch 00660: val_acc did not improve from 0.50210\n",
            "Epoch 661/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4004 - acc: 0.5051 - val_loss: 1.4351 - val_acc: 0.4906\n",
            "\n",
            "Epoch 00661: val_acc did not improve from 0.50210\n",
            "Epoch 662/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4388 - acc: 0.4900 - val_loss: 1.4402 - val_acc: 0.4888\n",
            "\n",
            "Epoch 00662: val_acc did not improve from 0.50210\n",
            "Epoch 663/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4108 - acc: 0.5050 - val_loss: 1.4462 - val_acc: 0.4872\n",
            "\n",
            "Epoch 00663: val_acc did not improve from 0.50210\n",
            "Epoch 664/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4285 - acc: 0.4931 - val_loss: 1.4388 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00664: val_acc did not improve from 0.50210\n",
            "Epoch 665/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4063 - acc: 0.5000 - val_loss: 1.4426 - val_acc: 0.4889\n",
            "\n",
            "Epoch 00665: val_acc did not improve from 0.50210\n",
            "Epoch 666/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4151 - acc: 0.5034 - val_loss: 1.4386 - val_acc: 0.4899\n",
            "\n",
            "Epoch 00666: val_acc did not improve from 0.50210\n",
            "Epoch 667/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4529 - acc: 0.4870 - val_loss: 1.4415 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00667: val_acc did not improve from 0.50210\n",
            "Epoch 668/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4242 - acc: 0.4913 - val_loss: 1.4486 - val_acc: 0.4856\n",
            "\n",
            "Epoch 00668: val_acc did not improve from 0.50210\n",
            "Epoch 669/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4209 - acc: 0.4958 - val_loss: 1.4321 - val_acc: 0.4919\n",
            "\n",
            "Epoch 00669: val_acc did not improve from 0.50210\n",
            "Epoch 670/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4047 - acc: 0.5021 - val_loss: 1.4300 - val_acc: 0.4926\n",
            "\n",
            "Epoch 00670: val_acc did not improve from 0.50210\n",
            "Epoch 671/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4243 - acc: 0.4953 - val_loss: 1.4416 - val_acc: 0.4893\n",
            "\n",
            "Epoch 00671: val_acc did not improve from 0.50210\n",
            "Epoch 672/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4095 - acc: 0.4987 - val_loss: 1.4304 - val_acc: 0.4917\n",
            "\n",
            "Epoch 00672: val_acc did not improve from 0.50210\n",
            "Epoch 673/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4156 - acc: 0.5019 - val_loss: 1.4330 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00673: val_acc did not improve from 0.50210\n",
            "Epoch 674/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.3820 - acc: 0.5127 - val_loss: 1.4447 - val_acc: 0.4873\n",
            "\n",
            "Epoch 00674: val_acc did not improve from 0.50210\n",
            "Epoch 675/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.3969 - acc: 0.5089 - val_loss: 1.4374 - val_acc: 0.4891\n",
            "\n",
            "Epoch 00675: val_acc did not improve from 0.50210\n",
            "Epoch 676/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4204 - acc: 0.4925 - val_loss: 1.4328 - val_acc: 0.4923\n",
            "\n",
            "Epoch 00676: val_acc did not improve from 0.50210\n",
            "Epoch 677/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.3953 - acc: 0.5046 - val_loss: 1.4395 - val_acc: 0.4881\n",
            "\n",
            "Epoch 00677: val_acc did not improve from 0.50210\n",
            "Epoch 678/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4123 - acc: 0.5051 - val_loss: 1.4265 - val_acc: 0.4922\n",
            "\n",
            "Epoch 00678: val_acc did not improve from 0.50210\n",
            "Epoch 679/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4078 - acc: 0.5096 - val_loss: 1.4281 - val_acc: 0.4921\n",
            "\n",
            "Epoch 00679: val_acc did not improve from 0.50210\n",
            "Epoch 680/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4164 - acc: 0.4969 - val_loss: 1.4301 - val_acc: 0.4904\n",
            "\n",
            "Epoch 00680: val_acc did not improve from 0.50210\n",
            "Epoch 681/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4120 - acc: 0.4945 - val_loss: 1.4341 - val_acc: 0.4904\n",
            "\n",
            "Epoch 00681: val_acc did not improve from 0.50210\n",
            "Epoch 682/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3921 - acc: 0.5034 - val_loss: 1.4391 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00682: val_acc did not improve from 0.50210\n",
            "Epoch 683/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4070 - acc: 0.5082 - val_loss: 1.4472 - val_acc: 0.4879\n",
            "\n",
            "Epoch 00683: val_acc did not improve from 0.50210\n",
            "Epoch 684/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3990 - acc: 0.5099 - val_loss: 1.4355 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00684: val_acc did not improve from 0.50210\n",
            "Epoch 685/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4491 - acc: 0.4868 - val_loss: 1.4330 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00685: val_acc did not improve from 0.50210\n",
            "Epoch 686/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4236 - acc: 0.4959 - val_loss: 1.4365 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00686: val_acc did not improve from 0.50210\n",
            "Epoch 687/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4190 - acc: 0.4967 - val_loss: 1.4345 - val_acc: 0.4905\n",
            "\n",
            "Epoch 00687: val_acc did not improve from 0.50210\n",
            "Epoch 688/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4267 - acc: 0.5008 - val_loss: 1.4333 - val_acc: 0.4911\n",
            "\n",
            "Epoch 00688: val_acc did not improve from 0.50210\n",
            "Epoch 689/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4290 - acc: 0.4987 - val_loss: 1.4328 - val_acc: 0.4915\n",
            "\n",
            "Epoch 00689: val_acc did not improve from 0.50210\n",
            "Epoch 690/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.4074 - acc: 0.5012 - val_loss: 1.4367 - val_acc: 0.4906\n",
            "\n",
            "Epoch 00690: val_acc did not improve from 0.50210\n",
            "Epoch 691/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4108 - acc: 0.4966 - val_loss: 1.4273 - val_acc: 0.4926\n",
            "\n",
            "Epoch 00691: val_acc did not improve from 0.50210\n",
            "Epoch 692/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4140 - acc: 0.5070 - val_loss: 1.4328 - val_acc: 0.4911\n",
            "\n",
            "Epoch 00692: val_acc did not improve from 0.50210\n",
            "Epoch 693/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4071 - acc: 0.4992 - val_loss: 1.4413 - val_acc: 0.4892\n",
            "\n",
            "Epoch 00693: val_acc did not improve from 0.50210\n",
            "Epoch 694/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3882 - acc: 0.5070 - val_loss: 1.4400 - val_acc: 0.4895\n",
            "\n",
            "Epoch 00694: val_acc did not improve from 0.50210\n",
            "Epoch 695/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4196 - acc: 0.4986 - val_loss: 1.4385 - val_acc: 0.4880\n",
            "\n",
            "Epoch 00695: val_acc did not improve from 0.50210\n",
            "Epoch 696/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3942 - acc: 0.5024 - val_loss: 1.4378 - val_acc: 0.4893\n",
            "\n",
            "Epoch 00696: val_acc did not improve from 0.50210\n",
            "Epoch 697/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4311 - acc: 0.4840 - val_loss: 1.4343 - val_acc: 0.4899\n",
            "\n",
            "Epoch 00697: val_acc did not improve from 0.50210\n",
            "Epoch 698/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4003 - acc: 0.4993 - val_loss: 1.4411 - val_acc: 0.4875\n",
            "\n",
            "Epoch 00698: val_acc did not improve from 0.50210\n",
            "Epoch 699/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4290 - acc: 0.5020 - val_loss: 1.4335 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00699: val_acc did not improve from 0.50210\n",
            "Epoch 700/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4024 - acc: 0.5104 - val_loss: 1.4365 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00700: val_acc did not improve from 0.50210\n",
            "Epoch 701/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4135 - acc: 0.5047 - val_loss: 1.4403 - val_acc: 0.4888\n",
            "\n",
            "Epoch 00701: val_acc did not improve from 0.50210\n",
            "Epoch 702/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4083 - acc: 0.5087 - val_loss: 1.4431 - val_acc: 0.4879\n",
            "\n",
            "Epoch 00702: val_acc did not improve from 0.50210\n",
            "Epoch 703/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4020 - acc: 0.5069 - val_loss: 1.4423 - val_acc: 0.4865\n",
            "\n",
            "Epoch 00703: val_acc did not improve from 0.50210\n",
            "Epoch 704/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4353 - acc: 0.4907 - val_loss: 1.4452 - val_acc: 0.4885\n",
            "\n",
            "Epoch 00704: val_acc did not improve from 0.50210\n",
            "Epoch 705/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4130 - acc: 0.5003 - val_loss: 1.4418 - val_acc: 0.4880\n",
            "\n",
            "Epoch 00705: val_acc did not improve from 0.50210\n",
            "Epoch 706/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4044 - acc: 0.5018 - val_loss: 1.4319 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00706: val_acc did not improve from 0.50210\n",
            "Epoch 707/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4023 - acc: 0.5036 - val_loss: 1.4257 - val_acc: 0.4924\n",
            "\n",
            "Epoch 00707: val_acc did not improve from 0.50210\n",
            "Epoch 708/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4083 - acc: 0.5021 - val_loss: 1.4304 - val_acc: 0.4914\n",
            "\n",
            "Epoch 00708: val_acc did not improve from 0.50210\n",
            "Epoch 709/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4165 - acc: 0.4995 - val_loss: 1.4285 - val_acc: 0.4921\n",
            "\n",
            "Epoch 00709: val_acc did not improve from 0.50210\n",
            "Epoch 710/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4307 - acc: 0.4952 - val_loss: 1.4338 - val_acc: 0.4895\n",
            "\n",
            "Epoch 00710: val_acc did not improve from 0.50210\n",
            "Epoch 711/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4182 - acc: 0.4997 - val_loss: 1.4331 - val_acc: 0.4910\n",
            "\n",
            "Epoch 00711: val_acc did not improve from 0.50210\n",
            "Epoch 712/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3896 - acc: 0.5061 - val_loss: 1.4384 - val_acc: 0.4910\n",
            "\n",
            "Epoch 00712: val_acc did not improve from 0.50210\n",
            "Epoch 713/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4117 - acc: 0.5026 - val_loss: 1.4292 - val_acc: 0.4929\n",
            "\n",
            "Epoch 00713: val_acc did not improve from 0.50210\n",
            "Epoch 714/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3958 - acc: 0.4989 - val_loss: 1.4311 - val_acc: 0.4913\n",
            "\n",
            "Epoch 00714: val_acc did not improve from 0.50210\n",
            "Epoch 715/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4321 - acc: 0.4884 - val_loss: 1.4338 - val_acc: 0.4917\n",
            "\n",
            "Epoch 00715: val_acc did not improve from 0.50210\n",
            "Epoch 716/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4083 - acc: 0.5004 - val_loss: 1.4424 - val_acc: 0.4882\n",
            "\n",
            "Epoch 00716: val_acc did not improve from 0.50210\n",
            "Epoch 717/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4097 - acc: 0.4990 - val_loss: 1.4373 - val_acc: 0.4879\n",
            "\n",
            "Epoch 00717: val_acc did not improve from 0.50210\n",
            "Epoch 718/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4175 - acc: 0.4993 - val_loss: 1.4350 - val_acc: 0.4898\n",
            "\n",
            "Epoch 00718: val_acc did not improve from 0.50210\n",
            "Epoch 719/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4048 - acc: 0.5039 - val_loss: 1.4458 - val_acc: 0.4874\n",
            "\n",
            "Epoch 00719: val_acc did not improve from 0.50210\n",
            "Epoch 720/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4288 - acc: 0.4963 - val_loss: 1.4323 - val_acc: 0.4925\n",
            "\n",
            "Epoch 00720: val_acc did not improve from 0.50210\n",
            "Epoch 721/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4104 - acc: 0.5067 - val_loss: 1.4416 - val_acc: 0.4879\n",
            "\n",
            "Epoch 00721: val_acc did not improve from 0.50210\n",
            "Epoch 722/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4032 - acc: 0.5060 - val_loss: 1.4315 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00722: val_acc did not improve from 0.50210\n",
            "Epoch 723/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4414 - acc: 0.4910 - val_loss: 1.4316 - val_acc: 0.4910\n",
            "\n",
            "Epoch 00723: val_acc did not improve from 0.50210\n",
            "Epoch 724/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4284 - acc: 0.4916 - val_loss: 1.4332 - val_acc: 0.4920\n",
            "\n",
            "Epoch 00724: val_acc did not improve from 0.50210\n",
            "Epoch 725/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4081 - acc: 0.4984 - val_loss: 1.4446 - val_acc: 0.4881\n",
            "\n",
            "Epoch 00725: val_acc did not improve from 0.50210\n",
            "Epoch 726/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4186 - acc: 0.5026 - val_loss: 1.4373 - val_acc: 0.4891\n",
            "\n",
            "Epoch 00726: val_acc did not improve from 0.50210\n",
            "Epoch 727/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4376 - acc: 0.4864 - val_loss: 1.4407 - val_acc: 0.4887\n",
            "\n",
            "Epoch 00727: val_acc did not improve from 0.50210\n",
            "Epoch 728/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3849 - acc: 0.5058 - val_loss: 1.4401 - val_acc: 0.4885\n",
            "\n",
            "Epoch 00728: val_acc did not improve from 0.50210\n",
            "Epoch 729/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4054 - acc: 0.5010 - val_loss: 1.4384 - val_acc: 0.4892\n",
            "\n",
            "Epoch 00729: val_acc did not improve from 0.50210\n",
            "Epoch 730/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4058 - acc: 0.5008 - val_loss: 1.4524 - val_acc: 0.4851\n",
            "\n",
            "Epoch 00730: val_acc did not improve from 0.50210\n",
            "Epoch 731/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4170 - acc: 0.4968 - val_loss: 1.4407 - val_acc: 0.4887\n",
            "\n",
            "Epoch 00731: val_acc did not improve from 0.50210\n",
            "Epoch 732/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4105 - acc: 0.4929 - val_loss: 1.4273 - val_acc: 0.4930\n",
            "\n",
            "Epoch 00732: val_acc did not improve from 0.50210\n",
            "Epoch 733/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4416 - acc: 0.4909 - val_loss: 1.4353 - val_acc: 0.4893\n",
            "\n",
            "Epoch 00733: val_acc did not improve from 0.50210\n",
            "Epoch 734/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.4203 - acc: 0.4988 - val_loss: 1.4291 - val_acc: 0.4915\n",
            "\n",
            "Epoch 00734: val_acc did not improve from 0.50210\n",
            "Epoch 735/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4247 - acc: 0.4967 - val_loss: 1.4409 - val_acc: 0.4891\n",
            "\n",
            "Epoch 00735: val_acc did not improve from 0.50210\n",
            "Epoch 736/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4086 - acc: 0.4995 - val_loss: 1.4308 - val_acc: 0.4919\n",
            "\n",
            "Epoch 00736: val_acc did not improve from 0.50210\n",
            "Epoch 737/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4222 - acc: 0.4901 - val_loss: 1.4367 - val_acc: 0.4898\n",
            "\n",
            "Epoch 00737: val_acc did not improve from 0.50210\n",
            "Epoch 738/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4276 - acc: 0.4890 - val_loss: 1.4348 - val_acc: 0.4921\n",
            "\n",
            "Epoch 00738: val_acc did not improve from 0.50210\n",
            "Epoch 739/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4209 - acc: 0.5043 - val_loss: 1.4363 - val_acc: 0.4890\n",
            "\n",
            "Epoch 00739: val_acc did not improve from 0.50210\n",
            "Epoch 740/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4249 - acc: 0.4956 - val_loss: 1.4317 - val_acc: 0.4909\n",
            "\n",
            "Epoch 00740: val_acc did not improve from 0.50210\n",
            "Epoch 741/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.3986 - acc: 0.5106 - val_loss: 1.4390 - val_acc: 0.4890\n",
            "\n",
            "Epoch 00741: val_acc did not improve from 0.50210\n",
            "Epoch 742/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.4044 - acc: 0.4962 - val_loss: 1.4469 - val_acc: 0.4859\n",
            "\n",
            "Epoch 00742: val_acc did not improve from 0.50210\n",
            "Epoch 743/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.4262 - acc: 0.5000 - val_loss: 1.4455 - val_acc: 0.4869\n",
            "\n",
            "Epoch 00743: val_acc did not improve from 0.50210\n",
            "Epoch 744/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.3951 - acc: 0.4992 - val_loss: 1.4490 - val_acc: 0.4847\n",
            "\n",
            "Epoch 00744: val_acc did not improve from 0.50210\n",
            "Epoch 745/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.3887 - acc: 0.5029 - val_loss: 1.4312 - val_acc: 0.4917\n",
            "\n",
            "Epoch 00745: val_acc did not improve from 0.50210\n",
            "Epoch 746/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4184 - acc: 0.4996 - val_loss: 1.4423 - val_acc: 0.4879\n",
            "\n",
            "Epoch 00746: val_acc did not improve from 0.50210\n",
            "Epoch 747/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4143 - acc: 0.5014 - val_loss: 1.4394 - val_acc: 0.4888\n",
            "\n",
            "Epoch 00747: val_acc did not improve from 0.50210\n",
            "Epoch 748/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.4049 - acc: 0.5105 - val_loss: 1.4324 - val_acc: 0.4911\n",
            "\n",
            "Epoch 00748: val_acc did not improve from 0.50210\n",
            "Epoch 749/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.4168 - acc: 0.5019 - val_loss: 1.4404 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00749: val_acc did not improve from 0.50210\n",
            "Epoch 750/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.4085 - acc: 0.4993 - val_loss: 1.4340 - val_acc: 0.4915\n",
            "\n",
            "Epoch 00750: val_acc did not improve from 0.50210\n",
            "Epoch 751/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.3972 - acc: 0.5052 - val_loss: 1.4293 - val_acc: 0.4924\n",
            "\n",
            "Epoch 00751: val_acc did not improve from 0.50210\n",
            "Epoch 752/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4034 - acc: 0.5092 - val_loss: 1.4267 - val_acc: 0.4932\n",
            "\n",
            "Epoch 00752: val_acc did not improve from 0.50210\n",
            "Epoch 753/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4227 - acc: 0.4914 - val_loss: 1.4412 - val_acc: 0.4879\n",
            "\n",
            "Epoch 00753: val_acc did not improve from 0.50210\n",
            "Epoch 754/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4115 - acc: 0.4999 - val_loss: 1.4417 - val_acc: 0.4878\n",
            "\n",
            "Epoch 00754: val_acc did not improve from 0.50210\n",
            "Epoch 755/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4014 - acc: 0.4935 - val_loss: 1.4371 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00755: val_acc did not improve from 0.50210\n",
            "Epoch 756/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4419 - acc: 0.4948 - val_loss: 1.4348 - val_acc: 0.4909\n",
            "\n",
            "Epoch 00756: val_acc did not improve from 0.50210\n",
            "Epoch 757/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4163 - acc: 0.4936 - val_loss: 1.4425 - val_acc: 0.4873\n",
            "\n",
            "Epoch 00757: val_acc did not improve from 0.50210\n",
            "Epoch 758/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4080 - acc: 0.4975 - val_loss: 1.4414 - val_acc: 0.4877\n",
            "\n",
            "Epoch 00758: val_acc did not improve from 0.50210\n",
            "Epoch 759/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4241 - acc: 0.4983 - val_loss: 1.4436 - val_acc: 0.4873\n",
            "\n",
            "Epoch 00759: val_acc did not improve from 0.50210\n",
            "Epoch 760/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4412 - acc: 0.4903 - val_loss: 1.4477 - val_acc: 0.4866\n",
            "\n",
            "Epoch 00760: val_acc did not improve from 0.50210\n",
            "Epoch 761/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4063 - acc: 0.5060 - val_loss: 1.4378 - val_acc: 0.4892\n",
            "\n",
            "Epoch 00761: val_acc did not improve from 0.50210\n",
            "Epoch 762/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.4063 - acc: 0.5061 - val_loss: 1.4326 - val_acc: 0.4913\n",
            "\n",
            "Epoch 00762: val_acc did not improve from 0.50210\n",
            "Epoch 763/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.4336 - acc: 0.4984 - val_loss: 1.4289 - val_acc: 0.4924\n",
            "\n",
            "Epoch 00763: val_acc did not improve from 0.50210\n",
            "Epoch 764/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3899 - acc: 0.5047 - val_loss: 1.4438 - val_acc: 0.4883\n",
            "\n",
            "Epoch 00764: val_acc did not improve from 0.50210\n",
            "Epoch 765/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4230 - acc: 0.4957 - val_loss: 1.4392 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00765: val_acc did not improve from 0.50210\n",
            "Epoch 766/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4117 - acc: 0.4976 - val_loss: 1.4440 - val_acc: 0.4887\n",
            "\n",
            "Epoch 00766: val_acc did not improve from 0.50210\n",
            "Epoch 767/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4124 - acc: 0.5000 - val_loss: 1.4317 - val_acc: 0.4920\n",
            "\n",
            "Epoch 00767: val_acc did not improve from 0.50210\n",
            "Epoch 768/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4425 - acc: 0.4870 - val_loss: 1.4419 - val_acc: 0.4882\n",
            "\n",
            "Epoch 00768: val_acc did not improve from 0.50210\n",
            "Epoch 769/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3978 - acc: 0.4988 - val_loss: 1.4444 - val_acc: 0.4881\n",
            "\n",
            "Epoch 00769: val_acc did not improve from 0.50210\n",
            "Epoch 770/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4379 - acc: 0.4959 - val_loss: 1.4362 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00770: val_acc did not improve from 0.50210\n",
            "Epoch 771/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4196 - acc: 0.4971 - val_loss: 1.4469 - val_acc: 0.4874\n",
            "\n",
            "Epoch 00771: val_acc did not improve from 0.50210\n",
            "Epoch 772/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4089 - acc: 0.5066 - val_loss: 1.4346 - val_acc: 0.4913\n",
            "\n",
            "Epoch 00772: val_acc did not improve from 0.50210\n",
            "Epoch 773/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4205 - acc: 0.4953 - val_loss: 1.4290 - val_acc: 0.4928\n",
            "\n",
            "Epoch 00773: val_acc did not improve from 0.50210\n",
            "Epoch 774/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4227 - acc: 0.4989 - val_loss: 1.4458 - val_acc: 0.4884\n",
            "\n",
            "Epoch 00774: val_acc did not improve from 0.50210\n",
            "Epoch 775/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4004 - acc: 0.5106 - val_loss: 1.4366 - val_acc: 0.4917\n",
            "\n",
            "Epoch 00775: val_acc did not improve from 0.50210\n",
            "Epoch 776/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4166 - acc: 0.5077 - val_loss: 1.4375 - val_acc: 0.4893\n",
            "\n",
            "Epoch 00776: val_acc did not improve from 0.50210\n",
            "Epoch 777/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.4128 - acc: 0.4963 - val_loss: 1.4334 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00777: val_acc did not improve from 0.50210\n",
            "Epoch 778/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4114 - acc: 0.4929 - val_loss: 1.4399 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00778: val_acc did not improve from 0.50210\n",
            "Epoch 779/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4300 - acc: 0.4889 - val_loss: 1.4334 - val_acc: 0.4925\n",
            "\n",
            "Epoch 00779: val_acc did not improve from 0.50210\n",
            "Epoch 780/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4186 - acc: 0.4966 - val_loss: 1.4361 - val_acc: 0.4905\n",
            "\n",
            "Epoch 00780: val_acc did not improve from 0.50210\n",
            "Epoch 781/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4140 - acc: 0.5049 - val_loss: 1.4389 - val_acc: 0.4894\n",
            "\n",
            "Epoch 00781: val_acc did not improve from 0.50210\n",
            "Epoch 782/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4080 - acc: 0.5004 - val_loss: 1.4377 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00782: val_acc did not improve from 0.50210\n",
            "Epoch 783/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3997 - acc: 0.5166 - val_loss: 1.4420 - val_acc: 0.4878\n",
            "\n",
            "Epoch 00783: val_acc did not improve from 0.50210\n",
            "Epoch 784/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4388 - acc: 0.4895 - val_loss: 1.4384 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00784: val_acc did not improve from 0.50210\n",
            "Epoch 785/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4105 - acc: 0.5101 - val_loss: 1.4401 - val_acc: 0.4895\n",
            "\n",
            "Epoch 00785: val_acc did not improve from 0.50210\n",
            "Epoch 786/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4155 - acc: 0.4995 - val_loss: 1.4298 - val_acc: 0.4921\n",
            "\n",
            "Epoch 00786: val_acc did not improve from 0.50210\n",
            "Epoch 787/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4187 - acc: 0.4943 - val_loss: 1.4369 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00787: val_acc did not improve from 0.50210\n",
            "Epoch 788/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4041 - acc: 0.5060 - val_loss: 1.4414 - val_acc: 0.4891\n",
            "\n",
            "Epoch 00788: val_acc did not improve from 0.50210\n",
            "Epoch 789/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4138 - acc: 0.5025 - val_loss: 1.4328 - val_acc: 0.4922\n",
            "\n",
            "Epoch 00789: val_acc did not improve from 0.50210\n",
            "Epoch 790/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4108 - acc: 0.5058 - val_loss: 1.4355 - val_acc: 0.4920\n",
            "\n",
            "Epoch 00790: val_acc did not improve from 0.50210\n",
            "Epoch 791/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.4238 - acc: 0.4940 - val_loss: 1.4453 - val_acc: 0.4880\n",
            "\n",
            "Epoch 00791: val_acc did not improve from 0.50210\n",
            "Epoch 792/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4116 - acc: 0.5006 - val_loss: 1.4405 - val_acc: 0.4886\n",
            "\n",
            "Epoch 00792: val_acc did not improve from 0.50210\n",
            "Epoch 793/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4060 - acc: 0.4943 - val_loss: 1.4337 - val_acc: 0.4913\n",
            "\n",
            "Epoch 00793: val_acc did not improve from 0.50210\n",
            "Epoch 794/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4240 - acc: 0.4957 - val_loss: 1.4355 - val_acc: 0.4895\n",
            "\n",
            "Epoch 00794: val_acc did not improve from 0.50210\n",
            "Epoch 795/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4366 - acc: 0.4880 - val_loss: 1.4393 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00795: val_acc did not improve from 0.50210\n",
            "Epoch 796/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3914 - acc: 0.5079 - val_loss: 1.4313 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00796: val_acc did not improve from 0.50210\n",
            "Epoch 797/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4130 - acc: 0.4973 - val_loss: 1.4342 - val_acc: 0.4899\n",
            "\n",
            "Epoch 00797: val_acc did not improve from 0.50210\n",
            "Epoch 798/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4260 - acc: 0.4999 - val_loss: 1.4365 - val_acc: 0.4904\n",
            "\n",
            "Epoch 00798: val_acc did not improve from 0.50210\n",
            "Epoch 799/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.3964 - acc: 0.5069 - val_loss: 1.4395 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00799: val_acc did not improve from 0.50210\n",
            "Epoch 800/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4402 - acc: 0.4913 - val_loss: 1.4402 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00800: val_acc did not improve from 0.50210\n",
            "Epoch 801/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.4240 - acc: 0.4933 - val_loss: 1.4286 - val_acc: 0.4928\n",
            "\n",
            "Epoch 00801: val_acc did not improve from 0.50210\n",
            "Epoch 802/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4083 - acc: 0.5036 - val_loss: 1.4327 - val_acc: 0.4913\n",
            "\n",
            "Epoch 00802: val_acc did not improve from 0.50210\n",
            "Epoch 803/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4249 - acc: 0.5057 - val_loss: 1.4323 - val_acc: 0.4912\n",
            "\n",
            "Epoch 00803: val_acc did not improve from 0.50210\n",
            "Epoch 804/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4203 - acc: 0.4960 - val_loss: 1.4324 - val_acc: 0.4913\n",
            "\n",
            "Epoch 00804: val_acc did not improve from 0.50210\n",
            "Epoch 805/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.4140 - acc: 0.4981 - val_loss: 1.4344 - val_acc: 0.4908\n",
            "\n",
            "Epoch 00805: val_acc did not improve from 0.50210\n",
            "Epoch 806/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.4330 - acc: 0.4957 - val_loss: 1.4335 - val_acc: 0.4913\n",
            "\n",
            "Epoch 00806: val_acc did not improve from 0.50210\n",
            "Epoch 807/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4023 - acc: 0.5052 - val_loss: 1.4358 - val_acc: 0.4917\n",
            "\n",
            "Epoch 00807: val_acc did not improve from 0.50210\n",
            "Epoch 808/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4056 - acc: 0.5001 - val_loss: 1.4325 - val_acc: 0.4916\n",
            "\n",
            "Epoch 00808: val_acc did not improve from 0.50210\n",
            "Epoch 809/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4187 - acc: 0.4947 - val_loss: 1.4336 - val_acc: 0.4905\n",
            "\n",
            "Epoch 00809: val_acc did not improve from 0.50210\n",
            "Epoch 810/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.4079 - acc: 0.5020 - val_loss: 1.4337 - val_acc: 0.4916\n",
            "\n",
            "Epoch 00810: val_acc did not improve from 0.50210\n",
            "Epoch 811/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3809 - acc: 0.5205 - val_loss: 1.4332 - val_acc: 0.4911\n",
            "\n",
            "Epoch 00811: val_acc did not improve from 0.50210\n",
            "Epoch 812/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4249 - acc: 0.4911 - val_loss: 1.4354 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00812: val_acc did not improve from 0.50210\n",
            "Epoch 813/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3970 - acc: 0.5121 - val_loss: 1.4370 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00813: val_acc did not improve from 0.50210\n",
            "Epoch 814/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4120 - acc: 0.4974 - val_loss: 1.4348 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00814: val_acc did not improve from 0.50210\n",
            "Epoch 815/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4338 - acc: 0.4906 - val_loss: 1.4330 - val_acc: 0.4912\n",
            "\n",
            "Epoch 00815: val_acc did not improve from 0.50210\n",
            "Epoch 816/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4224 - acc: 0.4983 - val_loss: 1.4324 - val_acc: 0.4911\n",
            "\n",
            "Epoch 00816: val_acc did not improve from 0.50210\n",
            "Epoch 817/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4114 - acc: 0.4998 - val_loss: 1.4354 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00817: val_acc did not improve from 0.50210\n",
            "Epoch 818/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4074 - acc: 0.5082 - val_loss: 1.4376 - val_acc: 0.4899\n",
            "\n",
            "Epoch 00818: val_acc did not improve from 0.50210\n",
            "Epoch 819/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4127 - acc: 0.5060 - val_loss: 1.4373 - val_acc: 0.4906\n",
            "\n",
            "Epoch 00819: val_acc did not improve from 0.50210\n",
            "Epoch 820/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.4170 - acc: 0.5058 - val_loss: 1.4390 - val_acc: 0.4895\n",
            "\n",
            "Epoch 00820: val_acc did not improve from 0.50210\n",
            "Epoch 821/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4113 - acc: 0.4963 - val_loss: 1.4365 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00821: val_acc did not improve from 0.50210\n",
            "Epoch 822/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.4029 - acc: 0.5036 - val_loss: 1.4317 - val_acc: 0.4911\n",
            "\n",
            "Epoch 00822: val_acc did not improve from 0.50210\n",
            "Epoch 823/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4050 - acc: 0.5034 - val_loss: 1.4327 - val_acc: 0.4916\n",
            "\n",
            "Epoch 00823: val_acc did not improve from 0.50210\n",
            "Epoch 824/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4408 - acc: 0.4867 - val_loss: 1.4327 - val_acc: 0.4913\n",
            "\n",
            "Epoch 00824: val_acc did not improve from 0.50210\n",
            "Epoch 825/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.4138 - acc: 0.4963 - val_loss: 1.4344 - val_acc: 0.4906\n",
            "\n",
            "Epoch 00825: val_acc did not improve from 0.50210\n",
            "Epoch 826/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4090 - acc: 0.4948 - val_loss: 1.4340 - val_acc: 0.4908\n",
            "\n",
            "Epoch 00826: val_acc did not improve from 0.50210\n",
            "Epoch 827/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4053 - acc: 0.4982 - val_loss: 1.4341 - val_acc: 0.4909\n",
            "\n",
            "Epoch 00827: val_acc did not improve from 0.50210\n",
            "Epoch 828/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4231 - acc: 0.5016 - val_loss: 1.4332 - val_acc: 0.4910\n",
            "\n",
            "Epoch 00828: val_acc did not improve from 0.50210\n",
            "Epoch 829/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4128 - acc: 0.5052 - val_loss: 1.4339 - val_acc: 0.4917\n",
            "\n",
            "Epoch 00829: val_acc did not improve from 0.50210\n",
            "Epoch 830/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4275 - acc: 0.4964 - val_loss: 1.4334 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00830: val_acc did not improve from 0.50210\n",
            "Epoch 831/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4015 - acc: 0.5069 - val_loss: 1.4337 - val_acc: 0.4912\n",
            "\n",
            "Epoch 00831: val_acc did not improve from 0.50210\n",
            "Epoch 832/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4234 - acc: 0.4921 - val_loss: 1.4333 - val_acc: 0.4909\n",
            "\n",
            "Epoch 00832: val_acc did not improve from 0.50210\n",
            "Epoch 833/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4260 - acc: 0.4938 - val_loss: 1.4345 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00833: val_acc did not improve from 0.50210\n",
            "Epoch 834/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.4274 - acc: 0.4937 - val_loss: 1.4364 - val_acc: 0.4898\n",
            "\n",
            "Epoch 00834: val_acc did not improve from 0.50210\n",
            "Epoch 835/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4176 - acc: 0.5048 - val_loss: 1.4349 - val_acc: 0.4908\n",
            "\n",
            "Epoch 00835: val_acc did not improve from 0.50210\n",
            "Epoch 836/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4315 - acc: 0.5068 - val_loss: 1.4311 - val_acc: 0.4909\n",
            "\n",
            "Epoch 00836: val_acc did not improve from 0.50210\n",
            "Epoch 837/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4365 - acc: 0.4885 - val_loss: 1.4343 - val_acc: 0.4909\n",
            "\n",
            "Epoch 00837: val_acc did not improve from 0.50210\n",
            "Epoch 838/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.4073 - acc: 0.5010 - val_loss: 1.4341 - val_acc: 0.4906\n",
            "\n",
            "Epoch 00838: val_acc did not improve from 0.50210\n",
            "Epoch 839/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4267 - acc: 0.4911 - val_loss: 1.4364 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00839: val_acc did not improve from 0.50210\n",
            "Epoch 840/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4202 - acc: 0.5070 - val_loss: 1.4367 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00840: val_acc did not improve from 0.50210\n",
            "Epoch 841/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4166 - acc: 0.4939 - val_loss: 1.4361 - val_acc: 0.4904\n",
            "\n",
            "Epoch 00841: val_acc did not improve from 0.50210\n",
            "Epoch 842/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3957 - acc: 0.5042 - val_loss: 1.4347 - val_acc: 0.4908\n",
            "\n",
            "Epoch 00842: val_acc did not improve from 0.50210\n",
            "Epoch 843/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4073 - acc: 0.5009 - val_loss: 1.4338 - val_acc: 0.4906\n",
            "\n",
            "Epoch 00843: val_acc did not improve from 0.50210\n",
            "Epoch 844/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.3947 - acc: 0.5042 - val_loss: 1.4350 - val_acc: 0.4912\n",
            "\n",
            "Epoch 00844: val_acc did not improve from 0.50210\n",
            "Epoch 845/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4114 - acc: 0.5018 - val_loss: 1.4361 - val_acc: 0.4904\n",
            "\n",
            "Epoch 00845: val_acc did not improve from 0.50210\n",
            "Epoch 846/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4171 - acc: 0.4889 - val_loss: 1.4375 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00846: val_acc did not improve from 0.50210\n",
            "Epoch 847/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4055 - acc: 0.5024 - val_loss: 1.4343 - val_acc: 0.4905\n",
            "\n",
            "Epoch 00847: val_acc did not improve from 0.50210\n",
            "Epoch 848/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4231 - acc: 0.5007 - val_loss: 1.4350 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00848: val_acc did not improve from 0.50210\n",
            "Epoch 849/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4055 - acc: 0.5075 - val_loss: 1.4366 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00849: val_acc did not improve from 0.50210\n",
            "Epoch 850/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4072 - acc: 0.5030 - val_loss: 1.4341 - val_acc: 0.4909\n",
            "\n",
            "Epoch 00850: val_acc did not improve from 0.50210\n",
            "Epoch 851/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4244 - acc: 0.4928 - val_loss: 1.4349 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00851: val_acc did not improve from 0.50210\n",
            "Epoch 852/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3977 - acc: 0.5062 - val_loss: 1.4355 - val_acc: 0.4899\n",
            "\n",
            "Epoch 00852: val_acc did not improve from 0.50210\n",
            "Epoch 853/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4473 - acc: 0.4895 - val_loss: 1.4336 - val_acc: 0.4909\n",
            "\n",
            "Epoch 00853: val_acc did not improve from 0.50210\n",
            "Epoch 854/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4164 - acc: 0.5000 - val_loss: 1.4354 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00854: val_acc did not improve from 0.50210\n",
            "Epoch 855/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4116 - acc: 0.5036 - val_loss: 1.4340 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00855: val_acc did not improve from 0.50210\n",
            "Epoch 856/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4033 - acc: 0.5019 - val_loss: 1.4358 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00856: val_acc did not improve from 0.50210\n",
            "Epoch 857/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4183 - acc: 0.5084 - val_loss: 1.4337 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00857: val_acc did not improve from 0.50210\n",
            "Epoch 858/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4226 - acc: 0.4971 - val_loss: 1.4375 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00858: val_acc did not improve from 0.50210\n",
            "Epoch 859/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3844 - acc: 0.5083 - val_loss: 1.4365 - val_acc: 0.4904\n",
            "\n",
            "Epoch 00859: val_acc did not improve from 0.50210\n",
            "Epoch 860/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4093 - acc: 0.5009 - val_loss: 1.4359 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00860: val_acc did not improve from 0.50210\n",
            "Epoch 861/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4231 - acc: 0.4980 - val_loss: 1.4353 - val_acc: 0.4899\n",
            "\n",
            "Epoch 00861: val_acc did not improve from 0.50210\n",
            "Epoch 862/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4006 - acc: 0.5034 - val_loss: 1.4361 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00862: val_acc did not improve from 0.50210\n",
            "Epoch 863/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.4195 - acc: 0.5009 - val_loss: 1.4351 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00863: val_acc did not improve from 0.50210\n",
            "Epoch 864/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4196 - acc: 0.5112 - val_loss: 1.4377 - val_acc: 0.4888\n",
            "\n",
            "Epoch 00864: val_acc did not improve from 0.50210\n",
            "Epoch 865/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3959 - acc: 0.5074 - val_loss: 1.4347 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00865: val_acc did not improve from 0.50210\n",
            "Epoch 866/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4200 - acc: 0.4982 - val_loss: 1.4336 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00866: val_acc did not improve from 0.50210\n",
            "Epoch 867/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3874 - acc: 0.5100 - val_loss: 1.4369 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00867: val_acc did not improve from 0.50210\n",
            "Epoch 868/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4070 - acc: 0.4963 - val_loss: 1.4341 - val_acc: 0.4905\n",
            "\n",
            "Epoch 00868: val_acc did not improve from 0.50210\n",
            "Epoch 869/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.4164 - acc: 0.5014 - val_loss: 1.4341 - val_acc: 0.4905\n",
            "\n",
            "Epoch 00869: val_acc did not improve from 0.50210\n",
            "Epoch 870/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4192 - acc: 0.5006 - val_loss: 1.4336 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00870: val_acc did not improve from 0.50210\n",
            "Epoch 871/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4414 - acc: 0.4824 - val_loss: 1.4331 - val_acc: 0.4911\n",
            "\n",
            "Epoch 00871: val_acc did not improve from 0.50210\n",
            "Epoch 872/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3972 - acc: 0.5010 - val_loss: 1.4353 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00872: val_acc did not improve from 0.50210\n",
            "Epoch 873/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4051 - acc: 0.5011 - val_loss: 1.4382 - val_acc: 0.4895\n",
            "\n",
            "Epoch 00873: val_acc did not improve from 0.50210\n",
            "Epoch 874/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4109 - acc: 0.5071 - val_loss: 1.4346 - val_acc: 0.4914\n",
            "\n",
            "Epoch 00874: val_acc did not improve from 0.50210\n",
            "Epoch 875/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4291 - acc: 0.4909 - val_loss: 1.4359 - val_acc: 0.4898\n",
            "\n",
            "Epoch 00875: val_acc did not improve from 0.50210\n",
            "Epoch 876/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4049 - acc: 0.5044 - val_loss: 1.4358 - val_acc: 0.4898\n",
            "\n",
            "Epoch 00876: val_acc did not improve from 0.50210\n",
            "Epoch 877/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.4059 - acc: 0.5031 - val_loss: 1.4356 - val_acc: 0.4908\n",
            "\n",
            "Epoch 00877: val_acc did not improve from 0.50210\n",
            "Epoch 878/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4030 - acc: 0.5103 - val_loss: 1.4348 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00878: val_acc did not improve from 0.50210\n",
            "Epoch 879/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4194 - acc: 0.4992 - val_loss: 1.4340 - val_acc: 0.4909\n",
            "\n",
            "Epoch 00879: val_acc did not improve from 0.50210\n",
            "Epoch 880/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3761 - acc: 0.5131 - val_loss: 1.4342 - val_acc: 0.4914\n",
            "\n",
            "Epoch 00880: val_acc did not improve from 0.50210\n",
            "Epoch 881/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4150 - acc: 0.4986 - val_loss: 1.4350 - val_acc: 0.4911\n",
            "\n",
            "Epoch 00881: val_acc did not improve from 0.50210\n",
            "Epoch 882/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4031 - acc: 0.5062 - val_loss: 1.4340 - val_acc: 0.4911\n",
            "\n",
            "Epoch 00882: val_acc did not improve from 0.50210\n",
            "Epoch 883/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4300 - acc: 0.4924 - val_loss: 1.4343 - val_acc: 0.4914\n",
            "\n",
            "Epoch 00883: val_acc did not improve from 0.50210\n",
            "Epoch 884/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3959 - acc: 0.5126 - val_loss: 1.4339 - val_acc: 0.4908\n",
            "\n",
            "Epoch 00884: val_acc did not improve from 0.50210\n",
            "Epoch 885/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4105 - acc: 0.5056 - val_loss: 1.4320 - val_acc: 0.4909\n",
            "\n",
            "Epoch 00885: val_acc did not improve from 0.50210\n",
            "Epoch 886/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.3940 - acc: 0.4975 - val_loss: 1.4334 - val_acc: 0.4910\n",
            "\n",
            "Epoch 00886: val_acc did not improve from 0.50210\n",
            "Epoch 887/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4367 - acc: 0.4923 - val_loss: 1.4337 - val_acc: 0.4916\n",
            "\n",
            "Epoch 00887: val_acc did not improve from 0.50210\n",
            "Epoch 888/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4030 - acc: 0.4999 - val_loss: 1.4331 - val_acc: 0.4911\n",
            "\n",
            "Epoch 00888: val_acc did not improve from 0.50210\n",
            "Epoch 889/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4179 - acc: 0.4896 - val_loss: 1.4328 - val_acc: 0.4918\n",
            "\n",
            "Epoch 00889: val_acc did not improve from 0.50210\n",
            "Epoch 890/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4002 - acc: 0.5107 - val_loss: 1.4353 - val_acc: 0.4911\n",
            "\n",
            "Epoch 00890: val_acc did not improve from 0.50210\n",
            "Epoch 891/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.4030 - acc: 0.5000 - val_loss: 1.4365 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00891: val_acc did not improve from 0.50210\n",
            "Epoch 892/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.3960 - acc: 0.5095 - val_loss: 1.4369 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00892: val_acc did not improve from 0.50210\n",
            "Epoch 893/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3922 - acc: 0.4971 - val_loss: 1.4353 - val_acc: 0.4908\n",
            "\n",
            "Epoch 00893: val_acc did not improve from 0.50210\n",
            "Epoch 894/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4271 - acc: 0.4950 - val_loss: 1.4350 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00894: val_acc did not improve from 0.50210\n",
            "Epoch 895/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4183 - acc: 0.4980 - val_loss: 1.4361 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00895: val_acc did not improve from 0.50210\n",
            "Epoch 896/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4196 - acc: 0.5060 - val_loss: 1.4379 - val_acc: 0.4905\n",
            "\n",
            "Epoch 00896: val_acc did not improve from 0.50210\n",
            "Epoch 897/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4003 - acc: 0.5111 - val_loss: 1.4375 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00897: val_acc did not improve from 0.50210\n",
            "Epoch 898/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4074 - acc: 0.5068 - val_loss: 1.4359 - val_acc: 0.4904\n",
            "\n",
            "Epoch 00898: val_acc did not improve from 0.50210\n",
            "Epoch 899/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4143 - acc: 0.4904 - val_loss: 1.4331 - val_acc: 0.4906\n",
            "\n",
            "Epoch 00899: val_acc did not improve from 0.50210\n",
            "Epoch 900/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4330 - acc: 0.4885 - val_loss: 1.4348 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00900: val_acc did not improve from 0.50210\n",
            "Epoch 901/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4017 - acc: 0.5046 - val_loss: 1.4345 - val_acc: 0.4909\n",
            "\n",
            "Epoch 00901: val_acc did not improve from 0.50210\n",
            "Epoch 902/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4096 - acc: 0.5013 - val_loss: 1.4336 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00902: val_acc did not improve from 0.50210\n",
            "Epoch 903/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3856 - acc: 0.5127 - val_loss: 1.4357 - val_acc: 0.4904\n",
            "\n",
            "Epoch 00903: val_acc did not improve from 0.50210\n",
            "Epoch 904/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4009 - acc: 0.5020 - val_loss: 1.4343 - val_acc: 0.4905\n",
            "\n",
            "Epoch 00904: val_acc did not improve from 0.50210\n",
            "Epoch 905/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4082 - acc: 0.5027 - val_loss: 1.4347 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00905: val_acc did not improve from 0.50210\n",
            "Epoch 906/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4304 - acc: 0.4913 - val_loss: 1.4354 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00906: val_acc did not improve from 0.50210\n",
            "Epoch 907/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4179 - acc: 0.4961 - val_loss: 1.4346 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00907: val_acc did not improve from 0.50210\n",
            "Epoch 908/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4008 - acc: 0.4999 - val_loss: 1.4356 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00908: val_acc did not improve from 0.50210\n",
            "Epoch 909/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4152 - acc: 0.5093 - val_loss: 1.4357 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00909: val_acc did not improve from 0.50210\n",
            "Epoch 910/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4324 - acc: 0.4965 - val_loss: 1.4359 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00910: val_acc did not improve from 0.50210\n",
            "Epoch 911/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4148 - acc: 0.4976 - val_loss: 1.4362 - val_acc: 0.4906\n",
            "\n",
            "Epoch 00911: val_acc did not improve from 0.50210\n",
            "Epoch 912/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4261 - acc: 0.4959 - val_loss: 1.4343 - val_acc: 0.4908\n",
            "\n",
            "Epoch 00912: val_acc did not improve from 0.50210\n",
            "Epoch 913/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3991 - acc: 0.5047 - val_loss: 1.4332 - val_acc: 0.4912\n",
            "\n",
            "Epoch 00913: val_acc did not improve from 0.50210\n",
            "Epoch 914/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4336 - acc: 0.4902 - val_loss: 1.4356 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00914: val_acc did not improve from 0.50210\n",
            "Epoch 915/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4061 - acc: 0.5025 - val_loss: 1.4352 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00915: val_acc did not improve from 0.50210\n",
            "Epoch 916/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4237 - acc: 0.4952 - val_loss: 1.4361 - val_acc: 0.4895\n",
            "\n",
            "Epoch 00916: val_acc did not improve from 0.50210\n",
            "Epoch 917/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4132 - acc: 0.4922 - val_loss: 1.4371 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00917: val_acc did not improve from 0.50210\n",
            "Epoch 918/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4030 - acc: 0.5037 - val_loss: 1.4352 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00918: val_acc did not improve from 0.50210\n",
            "Epoch 919/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4183 - acc: 0.4997 - val_loss: 1.4371 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00919: val_acc did not improve from 0.50210\n",
            "Epoch 920/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4277 - acc: 0.4968 - val_loss: 1.4368 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00920: val_acc did not improve from 0.50210\n",
            "Epoch 921/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4227 - acc: 0.4979 - val_loss: 1.4373 - val_acc: 0.4895\n",
            "\n",
            "Epoch 00921: val_acc did not improve from 0.50210\n",
            "Epoch 922/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4183 - acc: 0.4928 - val_loss: 1.4390 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00922: val_acc did not improve from 0.50210\n",
            "Epoch 923/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4106 - acc: 0.4951 - val_loss: 1.4374 - val_acc: 0.4892\n",
            "\n",
            "Epoch 00923: val_acc did not improve from 0.50210\n",
            "Epoch 924/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4211 - acc: 0.4934 - val_loss: 1.4348 - val_acc: 0.4905\n",
            "\n",
            "Epoch 00924: val_acc did not improve from 0.50210\n",
            "Epoch 925/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4196 - acc: 0.4941 - val_loss: 1.4358 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00925: val_acc did not improve from 0.50210\n",
            "Epoch 926/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4211 - acc: 0.5023 - val_loss: 1.4359 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00926: val_acc did not improve from 0.50210\n",
            "Epoch 927/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4217 - acc: 0.4898 - val_loss: 1.4350 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00927: val_acc did not improve from 0.50210\n",
            "Epoch 928/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3959 - acc: 0.4985 - val_loss: 1.4365 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00928: val_acc did not improve from 0.50210\n",
            "Epoch 929/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4265 - acc: 0.4932 - val_loss: 1.4354 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00929: val_acc did not improve from 0.50210\n",
            "Epoch 930/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4069 - acc: 0.5064 - val_loss: 1.4363 - val_acc: 0.4898\n",
            "\n",
            "Epoch 00930: val_acc did not improve from 0.50210\n",
            "Epoch 931/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4099 - acc: 0.4964 - val_loss: 1.4352 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00931: val_acc did not improve from 0.50210\n",
            "Epoch 932/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4175 - acc: 0.5026 - val_loss: 1.4360 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00932: val_acc did not improve from 0.50210\n",
            "Epoch 933/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4013 - acc: 0.5024 - val_loss: 1.4332 - val_acc: 0.4911\n",
            "\n",
            "Epoch 00933: val_acc did not improve from 0.50210\n",
            "Epoch 934/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4452 - acc: 0.4887 - val_loss: 1.4351 - val_acc: 0.4898\n",
            "\n",
            "Epoch 00934: val_acc did not improve from 0.50210\n",
            "Epoch 935/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4161 - acc: 0.4985 - val_loss: 1.4339 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00935: val_acc did not improve from 0.50210\n",
            "Epoch 936/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4095 - acc: 0.5000 - val_loss: 1.4356 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00936: val_acc did not improve from 0.50210\n",
            "Epoch 937/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4081 - acc: 0.4975 - val_loss: 1.4372 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00937: val_acc did not improve from 0.50210\n",
            "Epoch 938/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4142 - acc: 0.5014 - val_loss: 1.4357 - val_acc: 0.4904\n",
            "\n",
            "Epoch 00938: val_acc did not improve from 0.50210\n",
            "Epoch 939/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4085 - acc: 0.4950 - val_loss: 1.4351 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00939: val_acc did not improve from 0.50210\n",
            "Epoch 940/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4019 - acc: 0.5062 - val_loss: 1.4378 - val_acc: 0.4892\n",
            "\n",
            "Epoch 00940: val_acc did not improve from 0.50210\n",
            "Epoch 941/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.3856 - acc: 0.5091 - val_loss: 1.4354 - val_acc: 0.4906\n",
            "\n",
            "Epoch 00941: val_acc did not improve from 0.50210\n",
            "Epoch 942/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4003 - acc: 0.5112 - val_loss: 1.4355 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00942: val_acc did not improve from 0.50210\n",
            "Epoch 943/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4243 - acc: 0.5023 - val_loss: 1.4356 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00943: val_acc did not improve from 0.50210\n",
            "Epoch 944/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.4177 - acc: 0.4972 - val_loss: 1.4354 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00944: val_acc did not improve from 0.50210\n",
            "Epoch 945/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.4113 - acc: 0.4922 - val_loss: 1.4343 - val_acc: 0.4905\n",
            "\n",
            "Epoch 00945: val_acc did not improve from 0.50210\n",
            "Epoch 946/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.4110 - acc: 0.4964 - val_loss: 1.4363 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00946: val_acc did not improve from 0.50210\n",
            "Epoch 947/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.4164 - acc: 0.5005 - val_loss: 1.4365 - val_acc: 0.4893\n",
            "\n",
            "Epoch 00947: val_acc did not improve from 0.50210\n",
            "Epoch 948/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.3900 - acc: 0.5152 - val_loss: 1.4341 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00948: val_acc did not improve from 0.50210\n",
            "Epoch 949/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4156 - acc: 0.4971 - val_loss: 1.4358 - val_acc: 0.4894\n",
            "\n",
            "Epoch 00949: val_acc did not improve from 0.50210\n",
            "Epoch 950/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3878 - acc: 0.5013 - val_loss: 1.4370 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00950: val_acc did not improve from 0.50210\n",
            "Epoch 951/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4170 - acc: 0.4953 - val_loss: 1.4360 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00951: val_acc did not improve from 0.50210\n",
            "Epoch 952/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4244 - acc: 0.4997 - val_loss: 1.4357 - val_acc: 0.4904\n",
            "\n",
            "Epoch 00952: val_acc did not improve from 0.50210\n",
            "Epoch 953/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4233 - acc: 0.5037 - val_loss: 1.4360 - val_acc: 0.4892\n",
            "\n",
            "Epoch 00953: val_acc did not improve from 0.50210\n",
            "Epoch 954/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.4193 - acc: 0.5000 - val_loss: 1.4353 - val_acc: 0.4891\n",
            "\n",
            "Epoch 00954: val_acc did not improve from 0.50210\n",
            "Epoch 955/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.4053 - acc: 0.5095 - val_loss: 1.4359 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00955: val_acc did not improve from 0.50210\n",
            "Epoch 956/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4085 - acc: 0.4937 - val_loss: 1.4348 - val_acc: 0.4904\n",
            "\n",
            "Epoch 00956: val_acc did not improve from 0.50210\n",
            "Epoch 957/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4064 - acc: 0.4971 - val_loss: 1.4356 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00957: val_acc did not improve from 0.50210\n",
            "Epoch 958/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.4174 - acc: 0.4911 - val_loss: 1.4380 - val_acc: 0.4895\n",
            "\n",
            "Epoch 00958: val_acc did not improve from 0.50210\n",
            "Epoch 959/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.4099 - acc: 0.5019 - val_loss: 1.4380 - val_acc: 0.4884\n",
            "\n",
            "Epoch 00959: val_acc did not improve from 0.50210\n",
            "Epoch 960/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.4042 - acc: 0.5017 - val_loss: 1.4361 - val_acc: 0.4898\n",
            "\n",
            "Epoch 00960: val_acc did not improve from 0.50210\n",
            "Epoch 961/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.3996 - acc: 0.5095 - val_loss: 1.4381 - val_acc: 0.4892\n",
            "\n",
            "Epoch 00961: val_acc did not improve from 0.50210\n",
            "Epoch 962/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.3818 - acc: 0.5147 - val_loss: 1.4355 - val_acc: 0.4904\n",
            "\n",
            "Epoch 00962: val_acc did not improve from 0.50210\n",
            "Epoch 963/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.4209 - acc: 0.4975 - val_loss: 1.4353 - val_acc: 0.4899\n",
            "\n",
            "Epoch 00963: val_acc did not improve from 0.50210\n",
            "Epoch 964/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4240 - acc: 0.4908 - val_loss: 1.4389 - val_acc: 0.4891\n",
            "\n",
            "Epoch 00964: val_acc did not improve from 0.50210\n",
            "Epoch 965/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4372 - acc: 0.4941 - val_loss: 1.4374 - val_acc: 0.4894\n",
            "\n",
            "Epoch 00965: val_acc did not improve from 0.50210\n",
            "Epoch 966/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4250 - acc: 0.4975 - val_loss: 1.4358 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00966: val_acc did not improve from 0.50210\n",
            "Epoch 967/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3949 - acc: 0.5149 - val_loss: 1.4368 - val_acc: 0.4898\n",
            "\n",
            "Epoch 00967: val_acc did not improve from 0.50210\n",
            "Epoch 968/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4140 - acc: 0.5078 - val_loss: 1.4370 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00968: val_acc did not improve from 0.50210\n",
            "Epoch 969/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4086 - acc: 0.5051 - val_loss: 1.4359 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00969: val_acc did not improve from 0.50210\n",
            "Epoch 970/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.3993 - acc: 0.5023 - val_loss: 1.4351 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00970: val_acc did not improve from 0.50210\n",
            "Epoch 971/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4236 - acc: 0.4992 - val_loss: 1.4343 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00971: val_acc did not improve from 0.50210\n",
            "Epoch 972/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.4338 - acc: 0.4946 - val_loss: 1.4364 - val_acc: 0.4894\n",
            "\n",
            "Epoch 00972: val_acc did not improve from 0.50210\n",
            "Epoch 973/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4200 - acc: 0.4973 - val_loss: 1.4356 - val_acc: 0.4898\n",
            "\n",
            "Epoch 00973: val_acc did not improve from 0.50210\n",
            "Epoch 974/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.4230 - acc: 0.5061 - val_loss: 1.4376 - val_acc: 0.4892\n",
            "\n",
            "Epoch 00974: val_acc did not improve from 0.50210\n",
            "Epoch 975/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4168 - acc: 0.4924 - val_loss: 1.4360 - val_acc: 0.4895\n",
            "\n",
            "Epoch 00975: val_acc did not improve from 0.50210\n",
            "Epoch 976/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4105 - acc: 0.5036 - val_loss: 1.4374 - val_acc: 0.4889\n",
            "\n",
            "Epoch 00976: val_acc did not improve from 0.50210\n",
            "Epoch 977/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4146 - acc: 0.5053 - val_loss: 1.4388 - val_acc: 0.4895\n",
            "\n",
            "Epoch 00977: val_acc did not improve from 0.50210\n",
            "Epoch 978/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3949 - acc: 0.5084 - val_loss: 1.4366 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00978: val_acc did not improve from 0.50210\n",
            "Epoch 979/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4348 - acc: 0.4877 - val_loss: 1.4362 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00979: val_acc did not improve from 0.50210\n",
            "Epoch 980/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4301 - acc: 0.4932 - val_loss: 1.4363 - val_acc: 0.4898\n",
            "\n",
            "Epoch 00980: val_acc did not improve from 0.50210\n",
            "Epoch 981/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4184 - acc: 0.5036 - val_loss: 1.4360 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00981: val_acc did not improve from 0.50210\n",
            "Epoch 982/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4316 - acc: 0.4999 - val_loss: 1.4339 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00982: val_acc did not improve from 0.50210\n",
            "Epoch 983/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4203 - acc: 0.4973 - val_loss: 1.4337 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00983: val_acc did not improve from 0.50210\n",
            "Epoch 984/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4369 - acc: 0.4934 - val_loss: 1.4363 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00984: val_acc did not improve from 0.50210\n",
            "Epoch 985/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4111 - acc: 0.5006 - val_loss: 1.4361 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00985: val_acc did not improve from 0.50210\n",
            "Epoch 986/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.3996 - acc: 0.5111 - val_loss: 1.4346 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00986: val_acc did not improve from 0.50210\n",
            "Epoch 987/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4101 - acc: 0.4974 - val_loss: 1.4350 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00987: val_acc did not improve from 0.50210\n",
            "Epoch 988/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4289 - acc: 0.4989 - val_loss: 1.4341 - val_acc: 0.4906\n",
            "\n",
            "Epoch 00988: val_acc did not improve from 0.50210\n",
            "Epoch 989/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.3949 - acc: 0.5046 - val_loss: 1.4346 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00989: val_acc did not improve from 0.50210\n",
            "Epoch 990/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4072 - acc: 0.4961 - val_loss: 1.4351 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00990: val_acc did not improve from 0.50210\n",
            "Epoch 991/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4339 - acc: 0.4985 - val_loss: 1.4350 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00991: val_acc did not improve from 0.50210\n",
            "Epoch 992/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4179 - acc: 0.4993 - val_loss: 1.4373 - val_acc: 0.4889\n",
            "\n",
            "Epoch 00992: val_acc did not improve from 0.50210\n",
            "Epoch 993/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4184 - acc: 0.4996 - val_loss: 1.4366 - val_acc: 0.4892\n",
            "\n",
            "Epoch 00993: val_acc did not improve from 0.50210\n",
            "Epoch 994/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4220 - acc: 0.5038 - val_loss: 1.4355 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00994: val_acc did not improve from 0.50210\n",
            "Epoch 995/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4220 - acc: 0.5014 - val_loss: 1.4366 - val_acc: 0.4893\n",
            "\n",
            "Epoch 00995: val_acc did not improve from 0.50210\n",
            "Epoch 996/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4019 - acc: 0.5035 - val_loss: 1.4347 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00996: val_acc did not improve from 0.50210\n",
            "Epoch 997/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3975 - acc: 0.5060 - val_loss: 1.4347 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00997: val_acc did not improve from 0.50210\n",
            "Epoch 998/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4239 - acc: 0.5044 - val_loss: 1.4327 - val_acc: 0.4908\n",
            "\n",
            "Epoch 00998: val_acc did not improve from 0.50210\n",
            "Epoch 999/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4196 - acc: 0.4989 - val_loss: 1.4332 - val_acc: 0.4907\n",
            "\n",
            "Epoch 00999: val_acc did not improve from 0.50210\n",
            "Epoch 1000/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4159 - acc: 0.5024 - val_loss: 1.4359 - val_acc: 0.4896\n",
            "\n",
            "Epoch 01000: val_acc did not improve from 0.50210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "ZNjo2H9wVsEl",
        "outputId": "362f6c50-a40e-4d4e-d747-d532edd59bcf"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('trainHistoryDict', \"rb\"))\n",
        "functions.plot_loss_acc(history, 4, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dccMqpCHe6hz",
        "outputId": "afe996a9-2080-4728-b1ca-651813c6dd2f"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4896000027656555"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQMh7IJuYITD",
        "outputId": "a52518b8-5ec4-45a8-f0a4-8c829ea6a457"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5103999972343445"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO9ydg0YT2e2"
      },
      "source": [
        "#### Model with clipping to 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51_MIl3rT6wF",
        "outputId": "bbcfdf44-56fa-4091-deed-ed8f5f5594be"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(\n",
        "    input_shape, conv_layer = functions.ConvDecomposed2D, decomposition_rank=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzzSqCDQFgjJ",
        "outputId": "f64bc0e2-052e-49b8-8e66-c1171181bf79"
      },
      "source": [
        "callbacks = functions.standard_callbacks(model_type) + [functions.Clipping(0.5)]\n",
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'trainHistoryDict_clip_05', steps_per_epoch=100, epochs=1000,\n",
        "                       batch_size=100,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Epoch 1/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 49s 100ms/step - loss: 5.7928 - acc: 0.1196 - val_loss: 2.7750 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.10000, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.2915 - acc: 0.1333 - val_loss: 2.3377 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.10000\n",
            "Epoch 3/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.1409 - acc: 0.1727 - val_loss: 2.3374 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.10000\n",
            "Epoch 4/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.0435 - acc: 0.2170 - val_loss: 2.3484 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.10000\n",
            "Epoch 5/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.9752 - acc: 0.2424 - val_loss: 2.3856 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.10000\n",
            "Epoch 6/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.9456 - acc: 0.2572 - val_loss: 2.4495 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.10000\n",
            "Epoch 7/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.9381 - acc: 0.2581 - val_loss: 2.5090 - val_acc: 0.1001\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.10000 to 0.10010, saving model to /content/saved_models/cifar10_ResNet32v1_model.007.h5\n",
            "Epoch 8/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.8938 - acc: 0.2788 - val_loss: 2.6133 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.10010\n",
            "Epoch 9/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.9213 - acc: 0.2631 - val_loss: 2.7632 - val_acc: 0.1045\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.10010 to 0.10450, saving model to /content/saved_models/cifar10_ResNet32v1_model.009.h5\n",
            "Epoch 10/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.9001 - acc: 0.2873 - val_loss: 2.7163 - val_acc: 0.1351\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.10450 to 0.13510, saving model to /content/saved_models/cifar10_ResNet32v1_model.010.h5\n",
            "Epoch 11/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.8889 - acc: 0.2740 - val_loss: 2.6021 - val_acc: 0.1175\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.13510\n",
            "Epoch 12/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.8920 - acc: 0.2851 - val_loss: 2.8601 - val_acc: 0.1291\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.13510\n",
            "Epoch 13/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.8624 - acc: 0.2983 - val_loss: 3.7328 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.13510\n",
            "Epoch 14/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.8552 - acc: 0.3019 - val_loss: 2.3927 - val_acc: 0.1381\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.13510 to 0.13810, saving model to /content/saved_models/cifar10_ResNet32v1_model.014.h5\n",
            "Epoch 15/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.8589 - acc: 0.3021 - val_loss: 2.6124 - val_acc: 0.1489\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.13810 to 0.14890, saving model to /content/saved_models/cifar10_ResNet32v1_model.015.h5\n",
            "Epoch 16/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.8440 - acc: 0.3025 - val_loss: 2.9564 - val_acc: 0.1911\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.14890 to 0.19110, saving model to /content/saved_models/cifar10_ResNet32v1_model.016.h5\n",
            "Epoch 17/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.8382 - acc: 0.3121 - val_loss: 2.2816 - val_acc: 0.2067\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.19110 to 0.20670, saving model to /content/saved_models/cifar10_ResNet32v1_model.017.h5\n",
            "Epoch 18/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.8274 - acc: 0.3091 - val_loss: 2.6251 - val_acc: 0.1721\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.20670\n",
            "Epoch 19/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.8389 - acc: 0.3018 - val_loss: 3.2171 - val_acc: 0.1757\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.20670\n",
            "Epoch 20/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.8231 - acc: 0.3232 - val_loss: 2.1867 - val_acc: 0.2190\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.20670 to 0.21900, saving model to /content/saved_models/cifar10_ResNet32v1_model.020.h5\n",
            "Epoch 21/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7951 - acc: 0.3199 - val_loss: 2.1007 - val_acc: 0.2412\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.21900 to 0.24120, saving model to /content/saved_models/cifar10_ResNet32v1_model.021.h5\n",
            "Epoch 22/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7894 - acc: 0.3276 - val_loss: 2.3361 - val_acc: 0.1906\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.24120\n",
            "Epoch 23/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.8171 - acc: 0.3235 - val_loss: 2.4927 - val_acc: 0.1910\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.24120\n",
            "Epoch 24/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7774 - acc: 0.3285 - val_loss: 2.6103 - val_acc: 0.1617\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.24120\n",
            "Epoch 25/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7910 - acc: 0.3289 - val_loss: 2.6709 - val_acc: 0.1562\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.24120\n",
            "Epoch 26/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7917 - acc: 0.3263 - val_loss: 2.8746 - val_acc: 0.1499\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.24120\n",
            "Epoch 27/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7840 - acc: 0.3282 - val_loss: 2.2799 - val_acc: 0.2191\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.24120\n",
            "Epoch 28/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7858 - acc: 0.3295 - val_loss: 3.1183 - val_acc: 0.1330\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.24120\n",
            "Epoch 29/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7863 - acc: 0.3263 - val_loss: 3.8158 - val_acc: 0.1035\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.24120\n",
            "Epoch 30/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7808 - acc: 0.3415 - val_loss: 1.9417 - val_acc: 0.2868\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.24120 to 0.28680, saving model to /content/saved_models/cifar10_ResNet32v1_model.030.h5\n",
            "Epoch 31/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7604 - acc: 0.3462 - val_loss: 2.0569 - val_acc: 0.2502\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.28680\n",
            "Epoch 32/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7843 - acc: 0.3354 - val_loss: 2.8407 - val_acc: 0.1617\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.28680\n",
            "Epoch 33/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.7644 - acc: 0.3442 - val_loss: 2.9844 - val_acc: 0.1267\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.28680\n",
            "Epoch 34/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7600 - acc: 0.3319 - val_loss: 2.8137 - val_acc: 0.1554\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.28680\n",
            "Epoch 35/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.7558 - acc: 0.3458 - val_loss: 1.8874 - val_acc: 0.3108\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.28680 to 0.31080, saving model to /content/saved_models/cifar10_ResNet32v1_model.035.h5\n",
            "Epoch 36/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.7602 - acc: 0.3501 - val_loss: 2.1724 - val_acc: 0.2477\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.31080\n",
            "Epoch 37/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.7698 - acc: 0.3446 - val_loss: 3.0336 - val_acc: 0.1588\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.31080\n",
            "Epoch 38/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7667 - acc: 0.3457 - val_loss: 1.7493 - val_acc: 0.3532\n",
            "\n",
            "Epoch 00038: val_acc improved from 0.31080 to 0.35320, saving model to /content/saved_models/cifar10_ResNet32v1_model.038.h5\n",
            "Epoch 39/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.7497 - acc: 0.3410 - val_loss: 2.5867 - val_acc: 0.1916\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.35320\n",
            "Epoch 40/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7332 - acc: 0.3646 - val_loss: 2.0789 - val_acc: 0.2487\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.35320\n",
            "Epoch 41/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7287 - acc: 0.3550 - val_loss: 2.7602 - val_acc: 0.1612\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.35320\n",
            "Epoch 42/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7379 - acc: 0.3480 - val_loss: 2.9116 - val_acc: 0.1132\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.35320\n",
            "Epoch 43/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.7351 - acc: 0.3548 - val_loss: 4.1288 - val_acc: 0.1089\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.35320\n",
            "Epoch 44/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7280 - acc: 0.3571 - val_loss: 2.2435 - val_acc: 0.1867\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.35320\n",
            "Epoch 45/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.7361 - acc: 0.3494 - val_loss: 3.6447 - val_acc: 0.1390\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.35320\n",
            "Epoch 46/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.7210 - acc: 0.3622 - val_loss: 3.5815 - val_acc: 0.1414\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.35320\n",
            "Epoch 47/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7023 - acc: 0.3645 - val_loss: 1.9437 - val_acc: 0.2934\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.35320\n",
            "Epoch 48/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7157 - acc: 0.3620 - val_loss: 2.4303 - val_acc: 0.1891\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.35320\n",
            "Epoch 49/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7245 - acc: 0.3605 - val_loss: 4.1670 - val_acc: 0.1982\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.35320\n",
            "Epoch 50/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6979 - acc: 0.3708 - val_loss: 3.6770 - val_acc: 0.2295\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.35320\n",
            "Epoch 51/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6992 - acc: 0.3774 - val_loss: 2.3552 - val_acc: 0.2064\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.35320\n",
            "Epoch 52/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6846 - acc: 0.3795 - val_loss: 2.6091 - val_acc: 0.2419\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.35320\n",
            "Epoch 53/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6940 - acc: 0.3699 - val_loss: 2.2648 - val_acc: 0.2502\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.35320\n",
            "Epoch 54/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6860 - acc: 0.3805 - val_loss: 3.0210 - val_acc: 0.1595\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.35320\n",
            "Epoch 55/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6875 - acc: 0.3697 - val_loss: 2.5841 - val_acc: 0.1827\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.35320\n",
            "Epoch 56/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6887 - acc: 0.3735 - val_loss: 1.8369 - val_acc: 0.3413\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.35320\n",
            "Epoch 57/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6825 - acc: 0.3781 - val_loss: 3.7565 - val_acc: 0.1628\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.35320\n",
            "Epoch 58/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6754 - acc: 0.3835 - val_loss: 3.1382 - val_acc: 0.1824\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.35320\n",
            "Epoch 59/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6663 - acc: 0.3819 - val_loss: 2.7741 - val_acc: 0.2115\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.35320\n",
            "Epoch 60/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6628 - acc: 0.3894 - val_loss: 2.7227 - val_acc: 0.1799\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.35320\n",
            "Epoch 61/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6538 - acc: 0.3832 - val_loss: 2.6436 - val_acc: 0.2048\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.35320\n",
            "Epoch 62/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6801 - acc: 0.3804 - val_loss: 2.6379 - val_acc: 0.1882\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.35320\n",
            "Epoch 63/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6441 - acc: 0.3934 - val_loss: 2.5217 - val_acc: 0.2150\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.35320\n",
            "Epoch 64/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6603 - acc: 0.3881 - val_loss: 2.1529 - val_acc: 0.2142\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.35320\n",
            "Epoch 65/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6648 - acc: 0.3986 - val_loss: 2.7184 - val_acc: 0.1902\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.35320\n",
            "Epoch 66/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6497 - acc: 0.3969 - val_loss: 3.3788 - val_acc: 0.1208\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.35320\n",
            "Epoch 67/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6359 - acc: 0.3980 - val_loss: 3.6050 - val_acc: 0.1538\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.35320\n",
            "Epoch 68/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6426 - acc: 0.4022 - val_loss: 2.6191 - val_acc: 0.2044\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.35320\n",
            "Epoch 69/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6451 - acc: 0.3930 - val_loss: 2.1081 - val_acc: 0.2750\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.35320\n",
            "Epoch 70/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6521 - acc: 0.3963 - val_loss: 1.9961 - val_acc: 0.2919\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.35320\n",
            "Epoch 71/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6147 - acc: 0.4022 - val_loss: 2.5098 - val_acc: 0.1843\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.35320\n",
            "Epoch 72/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6192 - acc: 0.4009 - val_loss: 1.9691 - val_acc: 0.2913\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.35320\n",
            "Epoch 73/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6388 - acc: 0.3935 - val_loss: 6.2219 - val_acc: 0.1271\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.35320\n",
            "Epoch 74/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6179 - acc: 0.4044 - val_loss: 3.2877 - val_acc: 0.1912\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.35320\n",
            "Epoch 75/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6028 - acc: 0.4178 - val_loss: 2.7939 - val_acc: 0.2172\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.35320\n",
            "Epoch 76/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6083 - acc: 0.4149 - val_loss: 3.0069 - val_acc: 0.1898\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.35320\n",
            "Epoch 77/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6323 - acc: 0.4053 - val_loss: 3.8648 - val_acc: 0.1590\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.35320\n",
            "Epoch 78/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6034 - acc: 0.4128 - val_loss: 2.3246 - val_acc: 0.2251\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.35320\n",
            "Epoch 79/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6064 - acc: 0.4106 - val_loss: 2.8780 - val_acc: 0.2236\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.35320\n",
            "Epoch 80/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5694 - acc: 0.4389 - val_loss: 2.1886 - val_acc: 0.2658\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.35320\n",
            "Epoch 81/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6014 - acc: 0.4082 - val_loss: 2.0034 - val_acc: 0.2966\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.35320\n",
            "Epoch 82/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6040 - acc: 0.4083 - val_loss: 1.7455 - val_acc: 0.3545\n",
            "\n",
            "Epoch 00082: val_acc improved from 0.35320 to 0.35450, saving model to /content/saved_models/cifar10_ResNet32v1_model.082.h5\n",
            "Epoch 83/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5906 - acc: 0.4215 - val_loss: 1.8633 - val_acc: 0.3136\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.35450\n",
            "Epoch 84/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5888 - acc: 0.4243 - val_loss: 3.4898 - val_acc: 0.1841\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.35450\n",
            "Epoch 85/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5706 - acc: 0.4285 - val_loss: 1.8655 - val_acc: 0.3205\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.35450\n",
            "Epoch 86/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5812 - acc: 0.4194 - val_loss: 8.0354 - val_acc: 0.1297\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.35450\n",
            "Epoch 87/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5836 - acc: 0.4237 - val_loss: 2.7992 - val_acc: 0.2110\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.35450\n",
            "Epoch 88/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5697 - acc: 0.4378 - val_loss: 4.0339 - val_acc: 0.1947\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.35450\n",
            "Epoch 89/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5619 - acc: 0.4294 - val_loss: 1.7819 - val_acc: 0.3602\n",
            "\n",
            "Epoch 00089: val_acc improved from 0.35450 to 0.36020, saving model to /content/saved_models/cifar10_ResNet32v1_model.089.h5\n",
            "Epoch 90/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5621 - acc: 0.4273 - val_loss: 4.9079 - val_acc: 0.2063\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.36020\n",
            "Epoch 91/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5681 - acc: 0.4297 - val_loss: 4.5419 - val_acc: 0.1952\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.36020\n",
            "Epoch 92/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5626 - acc: 0.4303 - val_loss: 2.1349 - val_acc: 0.3169\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.36020\n",
            "Epoch 93/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5731 - acc: 0.4251 - val_loss: 9.3711 - val_acc: 0.1295\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.36020\n",
            "Epoch 94/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5819 - acc: 0.4252 - val_loss: 1.7949 - val_acc: 0.3461\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.36020\n",
            "Epoch 95/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5558 - acc: 0.4297 - val_loss: 2.4471 - val_acc: 0.2349\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.36020\n",
            "Epoch 96/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5776 - acc: 0.4365 - val_loss: 1.7408 - val_acc: 0.3648\n",
            "\n",
            "Epoch 00096: val_acc improved from 0.36020 to 0.36480, saving model to /content/saved_models/cifar10_ResNet32v1_model.096.h5\n",
            "Epoch 97/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5438 - acc: 0.4425 - val_loss: 2.7217 - val_acc: 0.2367\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.36480\n",
            "Epoch 98/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5248 - acc: 0.4451 - val_loss: 2.6163 - val_acc: 0.2212\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.36480\n",
            "Epoch 99/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5388 - acc: 0.4470 - val_loss: 2.7338 - val_acc: 0.2623\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.36480\n",
            "Epoch 100/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5365 - acc: 0.4440 - val_loss: 3.7498 - val_acc: 0.2084\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.36480\n",
            "Epoch 101/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5560 - acc: 0.4318 - val_loss: 2.8981 - val_acc: 0.1838\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.36480\n",
            "Epoch 102/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5407 - acc: 0.4431 - val_loss: 3.3054 - val_acc: 0.1810\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.36480\n",
            "Epoch 103/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5339 - acc: 0.4563 - val_loss: 3.1068 - val_acc: 0.2004\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.36480\n",
            "Epoch 104/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5541 - acc: 0.4410 - val_loss: 2.7736 - val_acc: 0.2474\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.36480\n",
            "Epoch 105/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5413 - acc: 0.4396 - val_loss: 3.1661 - val_acc: 0.1378\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.36480\n",
            "Epoch 106/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5592 - acc: 0.4298 - val_loss: 2.5121 - val_acc: 0.2317\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.36480\n",
            "Epoch 107/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5385 - acc: 0.4413 - val_loss: 2.4331 - val_acc: 0.2542\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.36480\n",
            "Epoch 108/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5410 - acc: 0.4417 - val_loss: 2.8406 - val_acc: 0.1655\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.36480\n",
            "Epoch 109/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5196 - acc: 0.4536 - val_loss: 2.7886 - val_acc: 0.2367\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.36480\n",
            "Epoch 110/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5287 - acc: 0.4431 - val_loss: 1.9949 - val_acc: 0.3452\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.36480\n",
            "Epoch 111/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5058 - acc: 0.4469 - val_loss: 2.1260 - val_acc: 0.2864\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.36480\n",
            "Epoch 112/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5142 - acc: 0.4521 - val_loss: 2.3906 - val_acc: 0.2453\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.36480\n",
            "Epoch 113/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5261 - acc: 0.4517 - val_loss: 1.8055 - val_acc: 0.3698\n",
            "\n",
            "Epoch 00113: val_acc improved from 0.36480 to 0.36980, saving model to /content/saved_models/cifar10_ResNet32v1_model.113.h5\n",
            "Epoch 114/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5201 - acc: 0.4512 - val_loss: 2.0448 - val_acc: 0.2826\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.36980\n",
            "Epoch 115/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5324 - acc: 0.4440 - val_loss: 2.4200 - val_acc: 0.2575\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.36980\n",
            "Epoch 116/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5078 - acc: 0.4508 - val_loss: 5.4567 - val_acc: 0.1015\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.36980\n",
            "Epoch 117/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4978 - acc: 0.4589 - val_loss: 3.5583 - val_acc: 0.1565\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.36980\n",
            "Epoch 118/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5011 - acc: 0.4515 - val_loss: 1.7831 - val_acc: 0.3627\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.36980\n",
            "Epoch 119/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5350 - acc: 0.4482 - val_loss: 2.6931 - val_acc: 0.1616\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.36980\n",
            "Epoch 120/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5242 - acc: 0.4425 - val_loss: 1.6192 - val_acc: 0.4133\n",
            "\n",
            "Epoch 00120: val_acc improved from 0.36980 to 0.41330, saving model to /content/saved_models/cifar10_ResNet32v1_model.120.h5\n",
            "Epoch 121/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5049 - acc: 0.4594 - val_loss: 3.2988 - val_acc: 0.1808\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.41330\n",
            "Epoch 122/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5219 - acc: 0.4460 - val_loss: 2.0100 - val_acc: 0.3495\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.41330\n",
            "Epoch 123/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5034 - acc: 0.4616 - val_loss: 1.8941 - val_acc: 0.3224\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.41330\n",
            "Epoch 124/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.4987 - acc: 0.4556 - val_loss: 3.0245 - val_acc: 0.1559\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.41330\n",
            "Epoch 125/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5098 - acc: 0.4610 - val_loss: 3.2492 - val_acc: 0.1491\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.41330\n",
            "Epoch 126/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4817 - acc: 0.4653 - val_loss: 2.7795 - val_acc: 0.1922\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.41330\n",
            "Epoch 127/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5042 - acc: 0.4727 - val_loss: 1.9817 - val_acc: 0.3154\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.41330\n",
            "Epoch 128/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4983 - acc: 0.4547 - val_loss: 2.4010 - val_acc: 0.2160\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.41330\n",
            "Epoch 129/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5044 - acc: 0.4592 - val_loss: 2.7519 - val_acc: 0.2138\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.41330\n",
            "Epoch 130/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.5091 - acc: 0.4586 - val_loss: 4.1206 - val_acc: 0.1854\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.41330\n",
            "Epoch 131/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4881 - acc: 0.4705 - val_loss: 3.3824 - val_acc: 0.1865\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.41330\n",
            "Epoch 132/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4851 - acc: 0.4611 - val_loss: 4.2604 - val_acc: 0.1686\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.41330\n",
            "Epoch 133/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4849 - acc: 0.4706 - val_loss: 2.6607 - val_acc: 0.1974\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.41330\n",
            "Epoch 134/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4929 - acc: 0.4625 - val_loss: 2.3038 - val_acc: 0.2334\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.41330\n",
            "Epoch 135/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4592 - acc: 0.4785 - val_loss: 2.6489 - val_acc: 0.1983\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.41330\n",
            "Epoch 136/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4601 - acc: 0.4713 - val_loss: 1.9268 - val_acc: 0.3209\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.41330\n",
            "Epoch 137/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4853 - acc: 0.4653 - val_loss: 1.6984 - val_acc: 0.3960\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.41330\n",
            "Epoch 138/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4912 - acc: 0.4677 - val_loss: 2.2595 - val_acc: 0.2404\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.41330\n",
            "Epoch 139/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4889 - acc: 0.4604 - val_loss: 3.9823 - val_acc: 0.1724\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.41330\n",
            "Epoch 140/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.5008 - acc: 0.4664 - val_loss: 1.9169 - val_acc: 0.3357\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.41330\n",
            "Epoch 141/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4732 - acc: 0.4719 - val_loss: 2.0489 - val_acc: 0.2894\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.41330\n",
            "Epoch 142/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4755 - acc: 0.4682 - val_loss: 2.5415 - val_acc: 0.2783\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.41330\n",
            "Epoch 143/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4797 - acc: 0.4654 - val_loss: 2.6831 - val_acc: 0.2771\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.41330\n",
            "Epoch 144/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4693 - acc: 0.4797 - val_loss: 1.6477 - val_acc: 0.4101\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.41330\n",
            "Epoch 145/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.4687 - acc: 0.4766 - val_loss: 2.2698 - val_acc: 0.3212\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.41330\n",
            "Epoch 146/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4645 - acc: 0.4760 - val_loss: 2.1277 - val_acc: 0.2858\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.41330\n",
            "Epoch 147/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4603 - acc: 0.4739 - val_loss: 2.6259 - val_acc: 0.1914\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.41330\n",
            "Epoch 148/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4677 - acc: 0.4789 - val_loss: 2.4436 - val_acc: 0.3026\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.41330\n",
            "Epoch 149/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4491 - acc: 0.4740 - val_loss: 1.5724 - val_acc: 0.4422\n",
            "\n",
            "Epoch 00149: val_acc improved from 0.41330 to 0.44220, saving model to /content/saved_models/cifar10_ResNet32v1_model.149.h5\n",
            "Epoch 150/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4629 - acc: 0.4771 - val_loss: 1.6233 - val_acc: 0.4204\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.44220\n",
            "Epoch 151/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4615 - acc: 0.4765 - val_loss: 2.3299 - val_acc: 0.2806\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.44220\n",
            "Epoch 152/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4705 - acc: 0.4689 - val_loss: 1.7078 - val_acc: 0.4040\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.44220\n",
            "Epoch 153/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.4815 - acc: 0.4615 - val_loss: 2.0399 - val_acc: 0.3023\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.44220\n",
            "Epoch 154/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4627 - acc: 0.4721 - val_loss: 2.2459 - val_acc: 0.2685\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.44220\n",
            "Epoch 155/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4913 - acc: 0.4654 - val_loss: 1.8841 - val_acc: 0.3462\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.44220\n",
            "Epoch 156/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4839 - acc: 0.4670 - val_loss: 1.9129 - val_acc: 0.3490\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.44220\n",
            "Epoch 157/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4510 - acc: 0.4976 - val_loss: 2.5070 - val_acc: 0.2586\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.44220\n",
            "Epoch 158/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4693 - acc: 0.4763 - val_loss: 1.8789 - val_acc: 0.3487\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.44220\n",
            "Epoch 159/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4774 - acc: 0.4719 - val_loss: 3.0257 - val_acc: 0.1698\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.44220\n",
            "Epoch 160/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4789 - acc: 0.4800 - val_loss: 2.5041 - val_acc: 0.2216\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.44220\n",
            "Epoch 161/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4831 - acc: 0.4720 - val_loss: 2.5687 - val_acc: 0.2513\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.44220\n",
            "Epoch 162/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4779 - acc: 0.4721 - val_loss: 2.0685 - val_acc: 0.2840\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.44220\n",
            "Epoch 163/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4588 - acc: 0.4760 - val_loss: 2.4461 - val_acc: 0.2524\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.44220\n",
            "Epoch 164/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4458 - acc: 0.4833 - val_loss: 3.3248 - val_acc: 0.2460\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.44220\n",
            "Epoch 165/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4597 - acc: 0.4748 - val_loss: 4.6047 - val_acc: 0.1758\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.44220\n",
            "Epoch 166/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4667 - acc: 0.4779 - val_loss: 1.7939 - val_acc: 0.3672\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.44220\n",
            "Epoch 167/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4388 - acc: 0.4851 - val_loss: 1.9571 - val_acc: 0.3223\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.44220\n",
            "Epoch 168/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4507 - acc: 0.4763 - val_loss: 1.7146 - val_acc: 0.3963\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.44220\n",
            "Epoch 169/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4440 - acc: 0.4869 - val_loss: 1.8264 - val_acc: 0.3939\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.44220\n",
            "Epoch 170/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4420 - acc: 0.4798 - val_loss: 2.3948 - val_acc: 0.3076\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.44220\n",
            "Epoch 171/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4571 - acc: 0.4810 - val_loss: 3.0588 - val_acc: 0.2495\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.44220\n",
            "Epoch 172/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4269 - acc: 0.4896 - val_loss: 1.7499 - val_acc: 0.3896\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.44220\n",
            "Epoch 173/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4529 - acc: 0.4811 - val_loss: 2.9212 - val_acc: 0.1852\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.44220\n",
            "Epoch 174/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4400 - acc: 0.4820 - val_loss: 1.6779 - val_acc: 0.4010\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.44220\n",
            "Epoch 175/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4644 - acc: 0.4772 - val_loss: 3.4061 - val_acc: 0.1688\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.44220\n",
            "Epoch 176/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4459 - acc: 0.4748 - val_loss: 3.2330 - val_acc: 0.1803\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.44220\n",
            "Epoch 177/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4648 - acc: 0.4803 - val_loss: 3.0529 - val_acc: 0.2397\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.44220\n",
            "Epoch 178/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4467 - acc: 0.4847 - val_loss: 2.5089 - val_acc: 0.2949\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.44220\n",
            "Epoch 179/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4285 - acc: 0.4898 - val_loss: 3.4492 - val_acc: 0.1718\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.44220\n",
            "Epoch 180/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4330 - acc: 0.4863 - val_loss: 1.8963 - val_acc: 0.3420\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.44220\n",
            "Epoch 181/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4255 - acc: 0.4974 - val_loss: 1.8247 - val_acc: 0.3643\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.44220\n",
            "Epoch 182/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4581 - acc: 0.4866 - val_loss: 2.6782 - val_acc: 0.1965\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.44220\n",
            "Epoch 183/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4365 - acc: 0.4942 - val_loss: 1.5741 - val_acc: 0.4573\n",
            "\n",
            "Epoch 00183: val_acc improved from 0.44220 to 0.45730, saving model to /content/saved_models/cifar10_ResNet32v1_model.183.h5\n",
            "Epoch 184/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4461 - acc: 0.4806 - val_loss: 4.2969 - val_acc: 0.1660\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.45730\n",
            "Epoch 185/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4567 - acc: 0.4759 - val_loss: 2.9116 - val_acc: 0.2620\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.45730\n",
            "Epoch 186/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4441 - acc: 0.4865 - val_loss: 2.0854 - val_acc: 0.3138\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.45730\n",
            "Epoch 187/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4425 - acc: 0.4840 - val_loss: 1.7853 - val_acc: 0.3672\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.45730\n",
            "Epoch 188/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4356 - acc: 0.4894 - val_loss: 2.1375 - val_acc: 0.3353\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.45730\n",
            "Epoch 189/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4478 - acc: 0.4872 - val_loss: 1.7429 - val_acc: 0.3798\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.45730\n",
            "Epoch 190/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4355 - acc: 0.4906 - val_loss: 3.7346 - val_acc: 0.1609\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.45730\n",
            "Epoch 191/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4169 - acc: 0.4962 - val_loss: 3.5035 - val_acc: 0.1871\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.45730\n",
            "Epoch 192/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4315 - acc: 0.4983 - val_loss: 3.0790 - val_acc: 0.2177\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.45730\n",
            "Epoch 193/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4121 - acc: 0.5075 - val_loss: 2.3923 - val_acc: 0.2225\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.45730\n",
            "Epoch 194/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4372 - acc: 0.4803 - val_loss: 2.2531 - val_acc: 0.2898\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.45730\n",
            "Epoch 195/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4442 - acc: 0.4811 - val_loss: 1.8326 - val_acc: 0.3618\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.45730\n",
            "Epoch 196/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4521 - acc: 0.4859 - val_loss: 1.8106 - val_acc: 0.3893\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.45730\n",
            "Epoch 197/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4330 - acc: 0.4895 - val_loss: 2.9871 - val_acc: 0.2182\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.45730\n",
            "Epoch 198/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4428 - acc: 0.4888 - val_loss: 1.6860 - val_acc: 0.4084\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.45730\n",
            "Epoch 199/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4299 - acc: 0.4874 - val_loss: 2.3280 - val_acc: 0.3417\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.45730\n",
            "Epoch 200/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4448 - acc: 0.4919 - val_loss: 1.7350 - val_acc: 0.4005\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.45730\n",
            "Epoch 201/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4287 - acc: 0.4909 - val_loss: 1.9031 - val_acc: 0.3325\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.45730\n",
            "Epoch 202/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.3893 - acc: 0.5103 - val_loss: 2.6381 - val_acc: 0.2679\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.45730\n",
            "Epoch 203/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4090 - acc: 0.5021 - val_loss: 1.5348 - val_acc: 0.4545\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.45730\n",
            "Epoch 204/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.3883 - acc: 0.5059 - val_loss: 1.6113 - val_acc: 0.4223\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.45730\n",
            "Epoch 205/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4155 - acc: 0.4976 - val_loss: 2.7604 - val_acc: 0.2282\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.45730\n",
            "Epoch 206/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4288 - acc: 0.4879 - val_loss: 2.4719 - val_acc: 0.2586\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.45730\n",
            "Epoch 207/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4111 - acc: 0.4998 - val_loss: 4.2897 - val_acc: 0.1255\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.45730\n",
            "Epoch 208/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4151 - acc: 0.4926 - val_loss: 1.9223 - val_acc: 0.3586\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.45730\n",
            "Epoch 209/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4337 - acc: 0.4893 - val_loss: 1.9436 - val_acc: 0.3705\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.45730\n",
            "Epoch 210/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4197 - acc: 0.4951 - val_loss: 3.4494 - val_acc: 0.1890\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.45730\n",
            "Epoch 211/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4408 - acc: 0.4876 - val_loss: 1.9859 - val_acc: 0.3630\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.45730\n",
            "Epoch 212/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4040 - acc: 0.5011 - val_loss: 3.6932 - val_acc: 0.2250\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.45730\n",
            "Epoch 213/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4275 - acc: 0.4972 - val_loss: 2.0719 - val_acc: 0.3032\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.45730\n",
            "Epoch 214/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4208 - acc: 0.5000 - val_loss: 6.3134 - val_acc: 0.1015\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.45730\n",
            "Epoch 215/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3948 - acc: 0.4998 - val_loss: 4.2459 - val_acc: 0.1229\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.45730\n",
            "Epoch 216/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4035 - acc: 0.4959 - val_loss: 2.8265 - val_acc: 0.2140\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.45730\n",
            "Epoch 217/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4216 - acc: 0.4971 - val_loss: 2.2347 - val_acc: 0.2975\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.45730\n",
            "Epoch 218/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4032 - acc: 0.5028 - val_loss: 1.5340 - val_acc: 0.4592\n",
            "\n",
            "Epoch 00218: val_acc improved from 0.45730 to 0.45920, saving model to /content/saved_models/cifar10_ResNet32v1_model.218.h5\n",
            "Epoch 219/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4238 - acc: 0.4941 - val_loss: 2.3263 - val_acc: 0.2520\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.45920\n",
            "Epoch 220/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4076 - acc: 0.4944 - val_loss: 2.0285 - val_acc: 0.3286\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.45920\n",
            "Epoch 221/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3951 - acc: 0.5038 - val_loss: 1.7166 - val_acc: 0.4022\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.45920\n",
            "Epoch 222/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3864 - acc: 0.5079 - val_loss: 1.9215 - val_acc: 0.3752\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.45920\n",
            "Epoch 223/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4031 - acc: 0.4974 - val_loss: 1.7721 - val_acc: 0.4083\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.45920\n",
            "Epoch 224/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4225 - acc: 0.5010 - val_loss: 1.7563 - val_acc: 0.3716\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.45920\n",
            "Epoch 225/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4006 - acc: 0.5009 - val_loss: 2.1987 - val_acc: 0.3005\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.45920\n",
            "Epoch 226/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3902 - acc: 0.5047 - val_loss: 3.0905 - val_acc: 0.2514\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.45920\n",
            "Epoch 227/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4095 - acc: 0.5040 - val_loss: 2.6889 - val_acc: 0.2419\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.45920\n",
            "Epoch 228/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.3983 - acc: 0.5067 - val_loss: 7.0652 - val_acc: 0.1031\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.45920\n",
            "Epoch 229/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3949 - acc: 0.4993 - val_loss: 4.1677 - val_acc: 0.2179\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.45920\n",
            "Epoch 230/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4128 - acc: 0.4918 - val_loss: 4.0688 - val_acc: 0.1515\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.45920\n",
            "Epoch 231/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4102 - acc: 0.4998 - val_loss: 2.5846 - val_acc: 0.2610\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.45920\n",
            "Epoch 232/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4232 - acc: 0.4982 - val_loss: 1.7232 - val_acc: 0.3955\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.45920\n",
            "Epoch 233/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3987 - acc: 0.5013 - val_loss: 4.4199 - val_acc: 0.1545\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.45920\n",
            "Epoch 234/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3996 - acc: 0.5029 - val_loss: 3.0566 - val_acc: 0.2085\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.45920\n",
            "Epoch 235/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4015 - acc: 0.5018 - val_loss: 1.8939 - val_acc: 0.3842\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.45920\n",
            "Epoch 236/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4092 - acc: 0.5020 - val_loss: 1.6760 - val_acc: 0.4087\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.45920\n",
            "Epoch 237/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4132 - acc: 0.4990 - val_loss: 2.7862 - val_acc: 0.2672\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.45920\n",
            "Epoch 238/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4020 - acc: 0.5010 - val_loss: 2.4881 - val_acc: 0.2673\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.45920\n",
            "Epoch 239/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3825 - acc: 0.5089 - val_loss: 3.1962 - val_acc: 0.2386\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.45920\n",
            "Epoch 240/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3893 - acc: 0.5108 - val_loss: 1.5316 - val_acc: 0.4474\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.45920\n",
            "Epoch 241/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4199 - acc: 0.4956 - val_loss: 1.5430 - val_acc: 0.4581\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.45920\n",
            "Epoch 242/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4125 - acc: 0.4967 - val_loss: 2.0526 - val_acc: 0.3551\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.45920\n",
            "Epoch 243/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3696 - acc: 0.5144 - val_loss: 6.1687 - val_acc: 0.1993\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.45920\n",
            "Epoch 244/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4059 - acc: 0.5076 - val_loss: 2.9164 - val_acc: 0.2334\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.45920\n",
            "Epoch 245/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4036 - acc: 0.4985 - val_loss: 2.6121 - val_acc: 0.3131\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.45920\n",
            "Epoch 246/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3913 - acc: 0.5051 - val_loss: 3.7949 - val_acc: 0.2225\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.45920\n",
            "Epoch 247/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3984 - acc: 0.5040 - val_loss: 4.9273 - val_acc: 0.1220\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.45920\n",
            "Epoch 248/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.3698 - acc: 0.5145 - val_loss: 4.0028 - val_acc: 0.2034\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.45920\n",
            "Epoch 249/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3927 - acc: 0.5099 - val_loss: 1.6300 - val_acc: 0.4318\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.45920\n",
            "Epoch 250/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3803 - acc: 0.5117 - val_loss: 1.5784 - val_acc: 0.4490\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.45920\n",
            "Epoch 251/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3812 - acc: 0.4994 - val_loss: 2.3071 - val_acc: 0.2836\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.45920\n",
            "Epoch 252/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3758 - acc: 0.5134 - val_loss: 2.0363 - val_acc: 0.3182\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.45920\n",
            "Epoch 253/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3885 - acc: 0.5157 - val_loss: 2.9038 - val_acc: 0.2142\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.45920\n",
            "Epoch 254/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3968 - acc: 0.4970 - val_loss: 2.0925 - val_acc: 0.3191\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.45920\n",
            "Epoch 255/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3810 - acc: 0.5143 - val_loss: 2.0408 - val_acc: 0.3300\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.45920\n",
            "Epoch 256/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3972 - acc: 0.5008 - val_loss: 4.5989 - val_acc: 0.1402\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.45920\n",
            "Epoch 257/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3424 - acc: 0.5308 - val_loss: 2.3911 - val_acc: 0.2704\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.45920\n",
            "Epoch 258/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3955 - acc: 0.5097 - val_loss: 3.3914 - val_acc: 0.1807\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.45920\n",
            "Epoch 259/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3740 - acc: 0.5244 - val_loss: 3.0875 - val_acc: 0.1915\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.45920\n",
            "Epoch 260/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4036 - acc: 0.4943 - val_loss: 2.5967 - val_acc: 0.2822\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.45920\n",
            "Epoch 261/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3770 - acc: 0.5121 - val_loss: 2.2322 - val_acc: 0.3198\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.45920\n",
            "Epoch 262/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3793 - acc: 0.5061 - val_loss: 1.5291 - val_acc: 0.4441\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.45920\n",
            "Epoch 263/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.3885 - acc: 0.5000 - val_loss: 4.8322 - val_acc: 0.1556\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.45920\n",
            "Epoch 264/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3891 - acc: 0.5085 - val_loss: 1.6326 - val_acc: 0.4303\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.45920\n",
            "Epoch 265/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3879 - acc: 0.5064 - val_loss: 1.5601 - val_acc: 0.4484\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.45920\n",
            "Epoch 266/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3732 - acc: 0.5130 - val_loss: 2.6178 - val_acc: 0.2519\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.45920\n",
            "Epoch 267/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4119 - acc: 0.4973 - val_loss: 1.7219 - val_acc: 0.3907\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.45920\n",
            "Epoch 268/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3897 - acc: 0.5111 - val_loss: 1.7508 - val_acc: 0.4080\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.45920\n",
            "Epoch 269/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4103 - acc: 0.5026 - val_loss: 1.7351 - val_acc: 0.4004\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.45920\n",
            "Epoch 270/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4043 - acc: 0.5038 - val_loss: 2.1345 - val_acc: 0.3191\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.45920\n",
            "Epoch 271/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3866 - acc: 0.5118 - val_loss: 1.8221 - val_acc: 0.3696\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.45920\n",
            "Epoch 272/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3843 - acc: 0.5045 - val_loss: 1.6073 - val_acc: 0.4339\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.45920\n",
            "Epoch 273/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3842 - acc: 0.5087 - val_loss: 2.8923 - val_acc: 0.2649\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.45920\n",
            "Epoch 274/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3493 - acc: 0.5284 - val_loss: 1.8571 - val_acc: 0.3388\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.45920\n",
            "Epoch 275/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3708 - acc: 0.5184 - val_loss: 2.9123 - val_acc: 0.2189\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.45920\n",
            "Epoch 276/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.3899 - acc: 0.5062 - val_loss: 1.7034 - val_acc: 0.4072\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.45920\n",
            "Epoch 277/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.3552 - acc: 0.5227 - val_loss: 2.2424 - val_acc: 0.3165\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.45920\n",
            "Epoch 278/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3857 - acc: 0.5050 - val_loss: 2.1656 - val_acc: 0.2996\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.45920\n",
            "Epoch 279/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3773 - acc: 0.5117 - val_loss: 3.5237 - val_acc: 0.2094\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.45920\n",
            "Epoch 280/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3937 - acc: 0.5076 - val_loss: 2.2074 - val_acc: 0.2883\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.45920\n",
            "Epoch 281/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3836 - acc: 0.5130 - val_loss: 2.5883 - val_acc: 0.2674\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.45920\n",
            "Epoch 282/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3786 - acc: 0.5174 - val_loss: 1.7985 - val_acc: 0.3971\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.45920\n",
            "Epoch 283/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3804 - acc: 0.5230 - val_loss: 3.2498 - val_acc: 0.2265\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.45920\n",
            "Epoch 284/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3597 - acc: 0.5210 - val_loss: 3.4932 - val_acc: 0.1605\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.45920\n",
            "Epoch 285/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3588 - acc: 0.5149 - val_loss: 1.9569 - val_acc: 0.3199\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.45920\n",
            "Epoch 286/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3463 - acc: 0.5237 - val_loss: 2.3763 - val_acc: 0.2732\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.45920\n",
            "Epoch 287/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3661 - acc: 0.5241 - val_loss: 3.0400 - val_acc: 0.2078\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.45920\n",
            "Epoch 288/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.3651 - acc: 0.5185 - val_loss: 2.5895 - val_acc: 0.3159\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.45920\n",
            "Epoch 289/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3752 - acc: 0.5143 - val_loss: 2.8565 - val_acc: 0.2101\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.45920\n",
            "Epoch 290/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3755 - acc: 0.5093 - val_loss: 3.3261 - val_acc: 0.2322\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.45920\n",
            "Epoch 291/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3754 - acc: 0.5210 - val_loss: 1.6372 - val_acc: 0.4280\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.45920\n",
            "Epoch 292/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3684 - acc: 0.5164 - val_loss: 3.9257 - val_acc: 0.1824\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.45920\n",
            "Epoch 293/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3871 - acc: 0.5131 - val_loss: 2.4938 - val_acc: 0.3172\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.45920\n",
            "Epoch 294/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3621 - acc: 0.5183 - val_loss: 4.0029 - val_acc: 0.1841\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.45920\n",
            "Epoch 295/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3672 - acc: 0.5130 - val_loss: 4.4021 - val_acc: 0.1633\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.45920\n",
            "Epoch 296/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3781 - acc: 0.5176 - val_loss: 3.7397 - val_acc: 0.1528\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.45920\n",
            "Epoch 297/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3687 - acc: 0.5127 - val_loss: 3.6189 - val_acc: 0.1882\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.45920\n",
            "Epoch 298/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3831 - acc: 0.5131 - val_loss: 2.5317 - val_acc: 0.2454\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.45920\n",
            "Epoch 299/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3896 - acc: 0.5117 - val_loss: 1.7422 - val_acc: 0.3908\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.45920\n",
            "Epoch 300/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.3682 - acc: 0.5201 - val_loss: 1.9594 - val_acc: 0.3292\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.45920\n",
            "Epoch 301/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3944 - acc: 0.5110 - val_loss: 1.4777 - val_acc: 0.4800\n",
            "\n",
            "Epoch 00301: val_acc improved from 0.45920 to 0.48000, saving model to /content/saved_models/cifar10_ResNet32v1_model.301.h5\n",
            "Epoch 302/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3656 - acc: 0.5126 - val_loss: 2.3144 - val_acc: 0.3041\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.48000\n",
            "Epoch 303/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3572 - acc: 0.5217 - val_loss: 3.0461 - val_acc: 0.2051\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.48000\n",
            "Epoch 304/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4030 - acc: 0.5029 - val_loss: 1.7896 - val_acc: 0.3629\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.48000\n",
            "Epoch 305/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3661 - acc: 0.5156 - val_loss: 1.8468 - val_acc: 0.3992\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.48000\n",
            "Epoch 306/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3507 - acc: 0.5278 - val_loss: 1.6727 - val_acc: 0.4127\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.48000\n",
            "Epoch 307/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3757 - acc: 0.5204 - val_loss: 1.5343 - val_acc: 0.4669\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.48000\n",
            "Epoch 308/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3651 - acc: 0.5167 - val_loss: 1.8466 - val_acc: 0.3809\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.48000\n",
            "Epoch 309/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3576 - acc: 0.5209 - val_loss: 1.4537 - val_acc: 0.4886\n",
            "\n",
            "Epoch 00309: val_acc improved from 0.48000 to 0.48860, saving model to /content/saved_models/cifar10_ResNet32v1_model.309.h5\n",
            "Epoch 310/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3811 - acc: 0.5078 - val_loss: 4.4592 - val_acc: 0.1722\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.48860\n",
            "Epoch 311/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.3559 - acc: 0.5230 - val_loss: 2.0400 - val_acc: 0.3310\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.48860\n",
            "Epoch 312/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3677 - acc: 0.5167 - val_loss: 2.2945 - val_acc: 0.3396\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.48860\n",
            "Epoch 313/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3548 - acc: 0.5187 - val_loss: 1.5893 - val_acc: 0.4559\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.48860\n",
            "Epoch 314/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3568 - acc: 0.5226 - val_loss: 1.8341 - val_acc: 0.3865\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.48860\n",
            "Epoch 315/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3625 - acc: 0.5235 - val_loss: 2.9621 - val_acc: 0.2317\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.48860\n",
            "Epoch 316/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3600 - acc: 0.5150 - val_loss: 6.0550 - val_acc: 0.1711\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.48860\n",
            "Epoch 317/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3766 - acc: 0.5089 - val_loss: 1.9320 - val_acc: 0.3802\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.48860\n",
            "Epoch 318/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3479 - acc: 0.5225 - val_loss: 1.9263 - val_acc: 0.3889\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.48860\n",
            "Epoch 319/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3526 - acc: 0.5095 - val_loss: 3.5180 - val_acc: 0.2099\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.48860\n",
            "Epoch 320/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3636 - acc: 0.5164 - val_loss: 2.4929 - val_acc: 0.3184\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.48860\n",
            "Epoch 321/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3517 - acc: 0.5279 - val_loss: 2.0576 - val_acc: 0.3297\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.48860\n",
            "Epoch 322/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3546 - acc: 0.5218 - val_loss: 2.3457 - val_acc: 0.3479\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.48860\n",
            "Epoch 323/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3821 - acc: 0.5121 - val_loss: 2.0919 - val_acc: 0.3204\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.48860\n",
            "Epoch 324/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3715 - acc: 0.5148 - val_loss: 2.5990 - val_acc: 0.2933\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.48860\n",
            "Epoch 325/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3704 - acc: 0.5144 - val_loss: 4.4942 - val_acc: 0.2279\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.48860\n",
            "Epoch 326/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3802 - acc: 0.5088 - val_loss: 1.9138 - val_acc: 0.3669\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.48860\n",
            "Epoch 327/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3521 - acc: 0.5261 - val_loss: 1.7068 - val_acc: 0.4027\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.48860\n",
            "Epoch 328/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3235 - acc: 0.5398 - val_loss: 2.8298 - val_acc: 0.2817\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.48860\n",
            "Epoch 329/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3472 - acc: 0.5187 - val_loss: 2.9452 - val_acc: 0.3047\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.48860\n",
            "Epoch 330/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3391 - acc: 0.5293 - val_loss: 1.7853 - val_acc: 0.4108\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.48860\n",
            "Epoch 331/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3348 - acc: 0.5355 - val_loss: 4.9011 - val_acc: 0.2486\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.48860\n",
            "Epoch 332/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3609 - acc: 0.5197 - val_loss: 1.7466 - val_acc: 0.3983\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.48860\n",
            "Epoch 333/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3676 - acc: 0.5269 - val_loss: 3.2566 - val_acc: 0.2812\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.48860\n",
            "Epoch 334/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3552 - acc: 0.5219 - val_loss: 5.0083 - val_acc: 0.2055\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.48860\n",
            "Epoch 335/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3277 - acc: 0.5296 - val_loss: 2.2964 - val_acc: 0.3071\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.48860\n",
            "Epoch 336/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3416 - acc: 0.5306 - val_loss: 2.4648 - val_acc: 0.2960\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.48860\n",
            "Epoch 337/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3637 - acc: 0.5265 - val_loss: 2.9455 - val_acc: 0.2296\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.48860\n",
            "Epoch 338/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3280 - acc: 0.5320 - val_loss: 3.2546 - val_acc: 0.2628\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.48860\n",
            "Epoch 339/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3528 - acc: 0.5315 - val_loss: 1.7654 - val_acc: 0.4043\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.48860\n",
            "Epoch 340/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3566 - acc: 0.5182 - val_loss: 2.7752 - val_acc: 0.2439\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.48860\n",
            "Epoch 341/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3617 - acc: 0.5107 - val_loss: 1.4924 - val_acc: 0.4721\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.48860\n",
            "Epoch 342/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3857 - acc: 0.5163 - val_loss: 2.6200 - val_acc: 0.2562\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.48860\n",
            "Epoch 343/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3426 - acc: 0.5353 - val_loss: 1.4407 - val_acc: 0.4925\n",
            "\n",
            "Epoch 00343: val_acc improved from 0.48860 to 0.49250, saving model to /content/saved_models/cifar10_ResNet32v1_model.343.h5\n",
            "Epoch 344/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3533 - acc: 0.5281 - val_loss: 2.1459 - val_acc: 0.3818\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.49250\n",
            "Epoch 345/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3569 - acc: 0.5348 - val_loss: 1.7187 - val_acc: 0.4408\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.49250\n",
            "Epoch 346/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3584 - acc: 0.5162 - val_loss: 2.3171 - val_acc: 0.2898\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.49250\n",
            "Epoch 347/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3368 - acc: 0.5397 - val_loss: 2.8003 - val_acc: 0.2743\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.49250\n",
            "Epoch 348/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3535 - acc: 0.5282 - val_loss: 2.8391 - val_acc: 0.3155\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.49250\n",
            "Epoch 349/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3570 - acc: 0.5249 - val_loss: 1.5333 - val_acc: 0.4556\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.49250\n",
            "Epoch 350/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3330 - acc: 0.5395 - val_loss: 4.0580 - val_acc: 0.1453\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.49250\n",
            "Epoch 351/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3585 - acc: 0.5264 - val_loss: 2.3649 - val_acc: 0.3123\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.49250\n",
            "Epoch 352/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3594 - acc: 0.5250 - val_loss: 2.1497 - val_acc: 0.3539\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.49250\n",
            "Epoch 353/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3528 - acc: 0.5141 - val_loss: 2.1715 - val_acc: 0.3836\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.49250\n",
            "Epoch 354/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3591 - acc: 0.5279 - val_loss: 2.1812 - val_acc: 0.3500\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.49250\n",
            "Epoch 355/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3367 - acc: 0.5305 - val_loss: 2.0179 - val_acc: 0.3164\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.49250\n",
            "Epoch 356/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3579 - acc: 0.5194 - val_loss: 3.9441 - val_acc: 0.2126\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.49250\n",
            "Epoch 357/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3376 - acc: 0.5372 - val_loss: 3.6838 - val_acc: 0.3134\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.49250\n",
            "Epoch 358/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3565 - acc: 0.5208 - val_loss: 1.9696 - val_acc: 0.3810\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.49250\n",
            "Epoch 359/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3724 - acc: 0.5184 - val_loss: 1.5875 - val_acc: 0.4409\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.49250\n",
            "Epoch 360/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3225 - acc: 0.5341 - val_loss: 1.6496 - val_acc: 0.4525\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.49250\n",
            "Epoch 361/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3645 - acc: 0.5244 - val_loss: 2.7537 - val_acc: 0.2915\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.49250\n",
            "Epoch 362/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3365 - acc: 0.5342 - val_loss: 3.0736 - val_acc: 0.2477\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.49250\n",
            "Epoch 363/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3424 - acc: 0.5299 - val_loss: 2.0718 - val_acc: 0.2939\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.49250\n",
            "Epoch 364/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3427 - acc: 0.5210 - val_loss: 2.0044 - val_acc: 0.3153\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.49250\n",
            "Epoch 365/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3574 - acc: 0.5234 - val_loss: 1.5599 - val_acc: 0.4632\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.49250\n",
            "Epoch 366/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3509 - acc: 0.5329 - val_loss: 4.4000 - val_acc: 0.1749\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.49250\n",
            "Epoch 367/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3299 - acc: 0.5233 - val_loss: 5.5089 - val_acc: 0.1412\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.49250\n",
            "Epoch 368/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3326 - acc: 0.5342 - val_loss: 5.5971 - val_acc: 0.1396\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.49250\n",
            "Epoch 369/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3445 - acc: 0.5236 - val_loss: 4.2752 - val_acc: 0.1698\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.49250\n",
            "Epoch 370/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3608 - acc: 0.5271 - val_loss: 1.8916 - val_acc: 0.3518\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.49250\n",
            "Epoch 371/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3253 - acc: 0.5329 - val_loss: 2.6604 - val_acc: 0.2672\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.49250\n",
            "Epoch 372/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3301 - acc: 0.5378 - val_loss: 3.8409 - val_acc: 0.2065\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.49250\n",
            "Epoch 373/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3756 - acc: 0.5190 - val_loss: 2.3984 - val_acc: 0.2717\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.49250\n",
            "Epoch 374/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3503 - acc: 0.5271 - val_loss: 2.9162 - val_acc: 0.2143\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.49250\n",
            "Epoch 375/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3320 - acc: 0.5337 - val_loss: 1.6171 - val_acc: 0.4472\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.49250\n",
            "Epoch 376/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3347 - acc: 0.5224 - val_loss: 1.7517 - val_acc: 0.3944\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.49250\n",
            "Epoch 377/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3409 - acc: 0.5269 - val_loss: 1.6605 - val_acc: 0.4276\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.49250\n",
            "Epoch 378/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3260 - acc: 0.5365 - val_loss: 1.6934 - val_acc: 0.4380\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.49250\n",
            "Epoch 379/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3261 - acc: 0.5398 - val_loss: 2.6212 - val_acc: 0.2610\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.49250\n",
            "Epoch 380/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3406 - acc: 0.5248 - val_loss: 1.7322 - val_acc: 0.4096\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.49250\n",
            "Epoch 381/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3225 - acc: 0.5318 - val_loss: 2.2469 - val_acc: 0.3018\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.49250\n",
            "Epoch 382/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3527 - acc: 0.5229 - val_loss: 2.0932 - val_acc: 0.3463\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.49250\n",
            "Epoch 383/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3346 - acc: 0.5317 - val_loss: 3.8677 - val_acc: 0.2589\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.49250\n",
            "Epoch 384/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3325 - acc: 0.5310 - val_loss: 2.3757 - val_acc: 0.3231\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.49250\n",
            "Epoch 385/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3466 - acc: 0.5287 - val_loss: 6.8492 - val_acc: 0.1479\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.49250\n",
            "Epoch 386/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3363 - acc: 0.5280 - val_loss: 4.8091 - val_acc: 0.2580\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.49250\n",
            "Epoch 387/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3567 - acc: 0.5281 - val_loss: 2.4152 - val_acc: 0.3424\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.49250\n",
            "Epoch 388/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3384 - acc: 0.5246 - val_loss: 1.6392 - val_acc: 0.4520\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.49250\n",
            "Epoch 389/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3207 - acc: 0.5339 - val_loss: 3.6324 - val_acc: 0.2110\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.49250\n",
            "Epoch 390/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3504 - acc: 0.5297 - val_loss: 2.1325 - val_acc: 0.2956\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.49250\n",
            "Epoch 391/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3342 - acc: 0.5332 - val_loss: 1.8095 - val_acc: 0.4174\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.49250\n",
            "Epoch 392/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3243 - acc: 0.5325 - val_loss: 2.8525 - val_acc: 0.2961\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.49250\n",
            "Epoch 393/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3138 - acc: 0.5346 - val_loss: 2.6249 - val_acc: 0.3047\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.49250\n",
            "Epoch 394/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3269 - acc: 0.5297 - val_loss: 1.7586 - val_acc: 0.4151\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.49250\n",
            "Epoch 395/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3180 - acc: 0.5393 - val_loss: 3.9040 - val_acc: 0.1887\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.49250\n",
            "Epoch 396/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3381 - acc: 0.5246 - val_loss: 1.8814 - val_acc: 0.3824\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.49250\n",
            "Epoch 397/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3404 - acc: 0.5231 - val_loss: 1.6016 - val_acc: 0.4494\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.49250\n",
            "Epoch 398/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3342 - acc: 0.5353 - val_loss: 3.2612 - val_acc: 0.1889\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.49250\n",
            "Epoch 399/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3387 - acc: 0.5367 - val_loss: 2.3102 - val_acc: 0.3155\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.49250\n",
            "Epoch 400/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3312 - acc: 0.5312 - val_loss: 2.2117 - val_acc: 0.2920\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.49250\n",
            "Epoch 401/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3369 - acc: 0.5271 - val_loss: 1.4211 - val_acc: 0.5045\n",
            "\n",
            "Epoch 00401: val_acc improved from 0.49250 to 0.50450, saving model to /content/saved_models/cifar10_ResNet32v1_model.401.h5\n",
            "Epoch 402/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3142 - acc: 0.5325 - val_loss: 1.3886 - val_acc: 0.5117\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.50450 to 0.51170, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.2983 - acc: 0.5507 - val_loss: 1.2992 - val_acc: 0.5460\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.51170 to 0.54600, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3072 - acc: 0.5435 - val_loss: 1.3644 - val_acc: 0.5218\n",
            "\n",
            "Epoch 00404: val_acc did not improve from 0.54600\n",
            "Epoch 405/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.2990 - acc: 0.5507 - val_loss: 1.2832 - val_acc: 0.5489\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.54600 to 0.54890, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3174 - acc: 0.5359 - val_loss: 1.2737 - val_acc: 0.5561\n",
            "\n",
            "Epoch 00406: val_acc improved from 0.54890 to 0.55610, saving model to /content/saved_models/cifar10_ResNet32v1_model.406.h5\n",
            "Epoch 407/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3035 - acc: 0.5440 - val_loss: 1.3046 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00407: val_acc did not improve from 0.55610\n",
            "Epoch 408/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2989 - acc: 0.5453 - val_loss: 1.3464 - val_acc: 0.5312\n",
            "\n",
            "Epoch 00408: val_acc did not improve from 0.55610\n",
            "Epoch 409/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3117 - acc: 0.5424 - val_loss: 1.2906 - val_acc: 0.5473\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.55610\n",
            "Epoch 410/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.2927 - acc: 0.5441 - val_loss: 1.3120 - val_acc: 0.5440\n",
            "\n",
            "Epoch 00410: val_acc did not improve from 0.55610\n",
            "Epoch 411/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2912 - acc: 0.5434 - val_loss: 1.3091 - val_acc: 0.5444\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.55610\n",
            "Epoch 412/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3116 - acc: 0.5336 - val_loss: 1.2900 - val_acc: 0.5478\n",
            "\n",
            "Epoch 00412: val_acc did not improve from 0.55610\n",
            "Epoch 413/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2893 - acc: 0.5484 - val_loss: 1.2674 - val_acc: 0.5553\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.55610\n",
            "Epoch 414/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3062 - acc: 0.5373 - val_loss: 1.2828 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.55610\n",
            "Epoch 415/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2926 - acc: 0.5456 - val_loss: 1.3268 - val_acc: 0.5372\n",
            "\n",
            "Epoch 00415: val_acc did not improve from 0.55610\n",
            "Epoch 416/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3070 - acc: 0.5396 - val_loss: 1.3171 - val_acc: 0.5394\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.55610\n",
            "Epoch 417/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3080 - acc: 0.5433 - val_loss: 1.2735 - val_acc: 0.5506\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.55610\n",
            "Epoch 418/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3060 - acc: 0.5415 - val_loss: 1.2945 - val_acc: 0.5463\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.55610\n",
            "Epoch 419/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3045 - acc: 0.5423 - val_loss: 1.2921 - val_acc: 0.5479\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.55610\n",
            "Epoch 420/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3044 - acc: 0.5423 - val_loss: 1.3864 - val_acc: 0.5224\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.55610\n",
            "Epoch 421/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2883 - acc: 0.5459 - val_loss: 1.2937 - val_acc: 0.5453\n",
            "\n",
            "Epoch 00421: val_acc did not improve from 0.55610\n",
            "Epoch 422/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3068 - acc: 0.5390 - val_loss: 1.3228 - val_acc: 0.5359\n",
            "\n",
            "Epoch 00422: val_acc did not improve from 0.55610\n",
            "Epoch 423/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.2957 - acc: 0.5469 - val_loss: 1.3263 - val_acc: 0.5392\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.55610\n",
            "Epoch 424/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3135 - acc: 0.5298 - val_loss: 1.3802 - val_acc: 0.5224\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.55610\n",
            "Epoch 425/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2965 - acc: 0.5457 - val_loss: 1.3259 - val_acc: 0.5375\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.55610\n",
            "Epoch 426/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2951 - acc: 0.5490 - val_loss: 1.2973 - val_acc: 0.5457\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.55610\n",
            "Epoch 427/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3048 - acc: 0.5456 - val_loss: 1.3292 - val_acc: 0.5360\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.55610\n",
            "Epoch 428/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.2980 - acc: 0.5490 - val_loss: 1.2979 - val_acc: 0.5483\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.55610\n",
            "Epoch 429/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3207 - acc: 0.5373 - val_loss: 1.3020 - val_acc: 0.5410\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.55610\n",
            "Epoch 430/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3105 - acc: 0.5383 - val_loss: 1.2850 - val_acc: 0.5502\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.55610\n",
            "Epoch 431/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.2726 - acc: 0.5477 - val_loss: 1.2995 - val_acc: 0.5402\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.55610\n",
            "Epoch 432/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3351 - acc: 0.5303 - val_loss: 1.4870 - val_acc: 0.4886\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.55610\n",
            "Epoch 433/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3332 - acc: 0.5392 - val_loss: 1.4424 - val_acc: 0.4960\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.55610\n",
            "Epoch 434/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.2854 - acc: 0.5445 - val_loss: 1.3007 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00434: val_acc did not improve from 0.55610\n",
            "Epoch 435/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3011 - acc: 0.5451 - val_loss: 1.3061 - val_acc: 0.5376\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.55610\n",
            "Epoch 436/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3165 - acc: 0.5453 - val_loss: 1.3437 - val_acc: 0.5328\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.55610\n",
            "Epoch 437/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3047 - acc: 0.5487 - val_loss: 1.2948 - val_acc: 0.5456\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.55610\n",
            "Epoch 438/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2953 - acc: 0.5494 - val_loss: 1.3046 - val_acc: 0.5435\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.55610\n",
            "Epoch 439/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3084 - acc: 0.5400 - val_loss: 1.3620 - val_acc: 0.5257\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.55610\n",
            "Epoch 440/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3150 - acc: 0.5369 - val_loss: 1.3853 - val_acc: 0.5222\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.55610\n",
            "Epoch 441/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.2889 - acc: 0.5469 - val_loss: 1.3338 - val_acc: 0.5335\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.55610\n",
            "Epoch 442/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2668 - acc: 0.5523 - val_loss: 1.3987 - val_acc: 0.5146\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.55610\n",
            "Epoch 443/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3003 - acc: 0.5479 - val_loss: 1.3456 - val_acc: 0.5288\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.55610\n",
            "Epoch 444/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.2811 - acc: 0.5573 - val_loss: 1.2986 - val_acc: 0.5474\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.55610\n",
            "Epoch 445/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3035 - acc: 0.5540 - val_loss: 1.4492 - val_acc: 0.5044\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.55610\n",
            "Epoch 446/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.2980 - acc: 0.5518 - val_loss: 1.3633 - val_acc: 0.5305\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.55610\n",
            "Epoch 447/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3026 - acc: 0.5389 - val_loss: 1.2809 - val_acc: 0.5491\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.55610\n",
            "Epoch 448/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2944 - acc: 0.5477 - val_loss: 1.3320 - val_acc: 0.5402\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.55610\n",
            "Epoch 449/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.2700 - acc: 0.5564 - val_loss: 1.2874 - val_acc: 0.5504\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.55610\n",
            "Epoch 450/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2813 - acc: 0.5500 - val_loss: 1.2830 - val_acc: 0.5462\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.55610\n",
            "Epoch 451/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3077 - acc: 0.5354 - val_loss: 1.3213 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.55610\n",
            "Epoch 452/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2625 - acc: 0.5602 - val_loss: 1.3126 - val_acc: 0.5405\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.55610\n",
            "Epoch 453/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.2858 - acc: 0.5407 - val_loss: 1.3099 - val_acc: 0.5405\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.55610\n",
            "Epoch 454/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3107 - acc: 0.5376 - val_loss: 1.2947 - val_acc: 0.5482\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.55610\n",
            "Epoch 455/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2983 - acc: 0.5461 - val_loss: 1.3217 - val_acc: 0.5393\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.55610\n",
            "Epoch 456/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3011 - acc: 0.5457 - val_loss: 1.3068 - val_acc: 0.5424\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.55610\n",
            "Epoch 457/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2835 - acc: 0.5500 - val_loss: 1.2604 - val_acc: 0.5579\n",
            "\n",
            "Epoch 00457: val_acc improved from 0.55610 to 0.55790, saving model to /content/saved_models/cifar10_ResNet32v1_model.457.h5\n",
            "Epoch 458/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.2848 - acc: 0.5558 - val_loss: 1.2901 - val_acc: 0.5450\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.55790\n",
            "Epoch 459/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2901 - acc: 0.5457 - val_loss: 1.2798 - val_acc: 0.5531\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.55790\n",
            "Epoch 460/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2687 - acc: 0.5479 - val_loss: 1.2998 - val_acc: 0.5434\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.55790\n",
            "Epoch 461/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.2949 - acc: 0.5488 - val_loss: 1.3181 - val_acc: 0.5387\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.55790\n",
            "Epoch 462/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2894 - acc: 0.5438 - val_loss: 1.2756 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.55790\n",
            "Epoch 463/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.2584 - acc: 0.5573 - val_loss: 1.2705 - val_acc: 0.5560\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.55790\n",
            "Epoch 464/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.2928 - acc: 0.5468 - val_loss: 1.3874 - val_acc: 0.5136\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.55790\n",
            "Epoch 465/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3141 - acc: 0.5374 - val_loss: 1.2879 - val_acc: 0.5498\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.55790\n",
            "Epoch 466/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3084 - acc: 0.5383 - val_loss: 1.3027 - val_acc: 0.5470\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.55790\n",
            "Epoch 467/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3007 - acc: 0.5457 - val_loss: 1.2955 - val_acc: 0.5445\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.55790\n",
            "Epoch 468/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3075 - acc: 0.5415 - val_loss: 1.2905 - val_acc: 0.5479\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.55790\n",
            "Epoch 469/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3016 - acc: 0.5519 - val_loss: 1.3102 - val_acc: 0.5426\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.55790\n",
            "Epoch 470/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3011 - acc: 0.5518 - val_loss: 1.2995 - val_acc: 0.5448\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.55790\n",
            "Epoch 471/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3078 - acc: 0.5409 - val_loss: 1.3086 - val_acc: 0.5375\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.55790\n",
            "Epoch 472/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2994 - acc: 0.5331 - val_loss: 1.2816 - val_acc: 0.5535\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.55790\n",
            "Epoch 473/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.2904 - acc: 0.5525 - val_loss: 1.2985 - val_acc: 0.5428\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.55790\n",
            "Epoch 474/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3020 - acc: 0.5420 - val_loss: 1.3319 - val_acc: 0.5293\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.55790\n",
            "Epoch 475/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3176 - acc: 0.5314 - val_loss: 1.2818 - val_acc: 0.5472\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.55790\n",
            "Epoch 476/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.2856 - acc: 0.5472 - val_loss: 1.2789 - val_acc: 0.5573\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.55790\n",
            "Epoch 477/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3059 - acc: 0.5427 - val_loss: 1.3300 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.55790\n",
            "Epoch 478/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.2779 - acc: 0.5511 - val_loss: 1.3827 - val_acc: 0.5293\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.55790\n",
            "Epoch 479/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2987 - acc: 0.5426 - val_loss: 1.3833 - val_acc: 0.5232\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.55790\n",
            "Epoch 480/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3157 - acc: 0.5375 - val_loss: 1.3082 - val_acc: 0.5397\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.55790\n",
            "Epoch 481/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2805 - acc: 0.5486 - val_loss: 1.3442 - val_acc: 0.5275\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.55790\n",
            "Epoch 482/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3221 - acc: 0.5407 - val_loss: 1.3280 - val_acc: 0.5391\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.55790\n",
            "Epoch 483/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2797 - acc: 0.5498 - val_loss: 1.3005 - val_acc: 0.5453\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.55790\n",
            "Epoch 484/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2907 - acc: 0.5413 - val_loss: 1.3171 - val_acc: 0.5453\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.55790\n",
            "Epoch 485/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.2761 - acc: 0.5480 - val_loss: 1.2838 - val_acc: 0.5494\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.55790\n",
            "Epoch 486/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2903 - acc: 0.5400 - val_loss: 1.3601 - val_acc: 0.5279\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.55790\n",
            "Epoch 487/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.2939 - acc: 0.5428 - val_loss: 1.3334 - val_acc: 0.5352\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.55790\n",
            "Epoch 488/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2482 - acc: 0.5690 - val_loss: 1.2883 - val_acc: 0.5473\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.55790\n",
            "Epoch 489/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.2967 - acc: 0.5407 - val_loss: 1.3245 - val_acc: 0.5345\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.55790\n",
            "Epoch 490/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2946 - acc: 0.5451 - val_loss: 1.2800 - val_acc: 0.5525\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.55790\n",
            "Epoch 491/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2999 - acc: 0.5453 - val_loss: 1.2984 - val_acc: 0.5475\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.55790\n",
            "Epoch 492/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3081 - acc: 0.5367 - val_loss: 1.2677 - val_acc: 0.5563\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.55790\n",
            "Epoch 493/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2944 - acc: 0.5497 - val_loss: 1.2760 - val_acc: 0.5546\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.55790\n",
            "Epoch 494/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3101 - acc: 0.5436 - val_loss: 1.2808 - val_acc: 0.5491\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.55790\n",
            "Epoch 495/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2927 - acc: 0.5441 - val_loss: 1.2627 - val_acc: 0.5565\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.55790\n",
            "Epoch 496/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2952 - acc: 0.5459 - val_loss: 1.2919 - val_acc: 0.5473\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.55790\n",
            "Epoch 497/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3021 - acc: 0.5421 - val_loss: 1.3199 - val_acc: 0.5381\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.55790\n",
            "Epoch 498/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.2883 - acc: 0.5500 - val_loss: 1.2710 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.55790\n",
            "Epoch 499/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2955 - acc: 0.5424 - val_loss: 1.2779 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.55790\n",
            "Epoch 500/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3139 - acc: 0.5434 - val_loss: 1.3808 - val_acc: 0.5224\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.55790\n",
            "Epoch 501/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3204 - acc: 0.5396 - val_loss: 1.3967 - val_acc: 0.5158\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.55790\n",
            "Epoch 502/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.2835 - acc: 0.5531 - val_loss: 1.3109 - val_acc: 0.5415\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.55790\n",
            "Epoch 503/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2831 - acc: 0.5498 - val_loss: 1.3263 - val_acc: 0.5374\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.55790\n",
            "Epoch 504/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.3056 - acc: 0.5456 - val_loss: 1.2681 - val_acc: 0.5574\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.55790\n",
            "Epoch 505/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2806 - acc: 0.5482 - val_loss: 1.2685 - val_acc: 0.5582\n",
            "\n",
            "Epoch 00505: val_acc improved from 0.55790 to 0.55820, saving model to /content/saved_models/cifar10_ResNet32v1_model.505.h5\n",
            "Epoch 506/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2988 - acc: 0.5516 - val_loss: 1.3023 - val_acc: 0.5441\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.55820\n",
            "Epoch 507/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3119 - acc: 0.5363 - val_loss: 1.3322 - val_acc: 0.5296\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.55820\n",
            "Epoch 508/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2990 - acc: 0.5491 - val_loss: 1.3052 - val_acc: 0.5405\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.55820\n",
            "Epoch 509/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3029 - acc: 0.5494 - val_loss: 1.4606 - val_acc: 0.5004\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.55820\n",
            "Epoch 510/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2821 - acc: 0.5609 - val_loss: 1.4000 - val_acc: 0.5202\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.55820\n",
            "Epoch 511/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.2916 - acc: 0.5445 - val_loss: 1.3061 - val_acc: 0.5389\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.55820\n",
            "Epoch 512/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2817 - acc: 0.5439 - val_loss: 1.2843 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.55820\n",
            "Epoch 513/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3005 - acc: 0.5450 - val_loss: 1.2661 - val_acc: 0.5549\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.55820\n",
            "Epoch 514/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3003 - acc: 0.5408 - val_loss: 1.2969 - val_acc: 0.5498\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.55820\n",
            "Epoch 515/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.2879 - acc: 0.5519 - val_loss: 1.2978 - val_acc: 0.5438\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.55820\n",
            "Epoch 516/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2793 - acc: 0.5521 - val_loss: 1.3341 - val_acc: 0.5359\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.55820\n",
            "Epoch 517/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2878 - acc: 0.5403 - val_loss: 1.2953 - val_acc: 0.5457\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.55820\n",
            "Epoch 518/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3009 - acc: 0.5489 - val_loss: 1.3271 - val_acc: 0.5357\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.55820\n",
            "Epoch 519/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3063 - acc: 0.5432 - val_loss: 1.4129 - val_acc: 0.5139\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.55820\n",
            "Epoch 520/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3013 - acc: 0.5433 - val_loss: 1.3046 - val_acc: 0.5447\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.55820\n",
            "Epoch 521/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2757 - acc: 0.5528 - val_loss: 1.3195 - val_acc: 0.5372\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.55820\n",
            "Epoch 522/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2874 - acc: 0.5460 - val_loss: 1.3475 - val_acc: 0.5249\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.55820\n",
            "Epoch 523/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2790 - acc: 0.5499 - val_loss: 1.2988 - val_acc: 0.5487\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.55820\n",
            "Epoch 524/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3161 - acc: 0.5415 - val_loss: 1.3005 - val_acc: 0.5468\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.55820\n",
            "Epoch 525/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2999 - acc: 0.5479 - val_loss: 1.3067 - val_acc: 0.5377\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.55820\n",
            "Epoch 526/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2929 - acc: 0.5512 - val_loss: 1.3489 - val_acc: 0.5341\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.55820\n",
            "Epoch 527/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2883 - acc: 0.5501 - val_loss: 1.3427 - val_acc: 0.5298\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.55820\n",
            "Epoch 528/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3038 - acc: 0.5500 - val_loss: 1.3223 - val_acc: 0.5374\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.55820\n",
            "Epoch 529/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3003 - acc: 0.5495 - val_loss: 1.3898 - val_acc: 0.5245\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.55820\n",
            "Epoch 530/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2756 - acc: 0.5577 - val_loss: 1.3122 - val_acc: 0.5437\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.55820\n",
            "Epoch 531/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2918 - acc: 0.5439 - val_loss: 1.2656 - val_acc: 0.5554\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.55820\n",
            "Epoch 532/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2798 - acc: 0.5604 - val_loss: 1.3169 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.55820\n",
            "Epoch 533/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2958 - acc: 0.5453 - val_loss: 1.3042 - val_acc: 0.5445\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.55820\n",
            "Epoch 534/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3003 - acc: 0.5455 - val_loss: 1.3031 - val_acc: 0.5473\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.55820\n",
            "Epoch 535/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2639 - acc: 0.5543 - val_loss: 1.3235 - val_acc: 0.5378\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.55820\n",
            "Epoch 536/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3151 - acc: 0.5380 - val_loss: 1.2835 - val_acc: 0.5535\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.55820\n",
            "Epoch 537/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2787 - acc: 0.5405 - val_loss: 1.2726 - val_acc: 0.5555\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.55820\n",
            "Epoch 538/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2837 - acc: 0.5558 - val_loss: 1.2986 - val_acc: 0.5407\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.55820\n",
            "Epoch 539/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2936 - acc: 0.5541 - val_loss: 1.3386 - val_acc: 0.5315\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.55820\n",
            "Epoch 540/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2659 - acc: 0.5506 - val_loss: 1.3782 - val_acc: 0.5199\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.55820\n",
            "Epoch 541/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2467 - acc: 0.5649 - val_loss: 1.4069 - val_acc: 0.5192\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.55820\n",
            "Epoch 542/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2958 - acc: 0.5437 - val_loss: 1.3303 - val_acc: 0.5272\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.55820\n",
            "Epoch 543/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2839 - acc: 0.5502 - val_loss: 1.2982 - val_acc: 0.5424\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.55820\n",
            "Epoch 544/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3035 - acc: 0.5427 - val_loss: 1.2936 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.55820\n",
            "Epoch 545/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2921 - acc: 0.5554 - val_loss: 1.3295 - val_acc: 0.5400\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.55820\n",
            "Epoch 546/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2988 - acc: 0.5440 - val_loss: 1.3364 - val_acc: 0.5419\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.55820\n",
            "Epoch 547/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2934 - acc: 0.5428 - val_loss: 1.3923 - val_acc: 0.5190\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.55820\n",
            "Epoch 548/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2942 - acc: 0.5494 - val_loss: 1.3814 - val_acc: 0.5267\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.55820\n",
            "Epoch 549/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2815 - acc: 0.5421 - val_loss: 1.2916 - val_acc: 0.5417\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.55820\n",
            "Epoch 550/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3152 - acc: 0.5362 - val_loss: 1.2895 - val_acc: 0.5508\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.55820\n",
            "Epoch 551/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2677 - acc: 0.5567 - val_loss: 1.4284 - val_acc: 0.5166\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.55820\n",
            "Epoch 552/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2773 - acc: 0.5500 - val_loss: 1.3425 - val_acc: 0.5380\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.55820\n",
            "Epoch 553/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3013 - acc: 0.5470 - val_loss: 1.3259 - val_acc: 0.5353\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.55820\n",
            "Epoch 554/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3004 - acc: 0.5475 - val_loss: 1.3605 - val_acc: 0.5298\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.55820\n",
            "Epoch 555/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2801 - acc: 0.5478 - val_loss: 1.3321 - val_acc: 0.5352\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.55820\n",
            "Epoch 556/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2976 - acc: 0.5432 - val_loss: 1.4097 - val_acc: 0.5209\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.55820\n",
            "Epoch 557/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2991 - acc: 0.5411 - val_loss: 1.3526 - val_acc: 0.5311\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.55820\n",
            "Epoch 558/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2873 - acc: 0.5449 - val_loss: 1.3235 - val_acc: 0.5382\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.55820\n",
            "Epoch 559/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3007 - acc: 0.5396 - val_loss: 1.4307 - val_acc: 0.5083\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.55820\n",
            "Epoch 560/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3164 - acc: 0.5493 - val_loss: 1.2991 - val_acc: 0.5449\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.55820\n",
            "Epoch 561/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3035 - acc: 0.5445 - val_loss: 1.3218 - val_acc: 0.5365\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.55820\n",
            "Epoch 562/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2780 - acc: 0.5588 - val_loss: 1.2953 - val_acc: 0.5479\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.55820\n",
            "Epoch 563/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2976 - acc: 0.5459 - val_loss: 1.3525 - val_acc: 0.5275\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.55820\n",
            "Epoch 564/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2923 - acc: 0.5522 - val_loss: 1.3380 - val_acc: 0.5352\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.55820\n",
            "Epoch 565/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2663 - acc: 0.5523 - val_loss: 1.2760 - val_acc: 0.5542\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.55820\n",
            "Epoch 566/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3123 - acc: 0.5450 - val_loss: 1.3148 - val_acc: 0.5386\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.55820\n",
            "Epoch 567/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2757 - acc: 0.5478 - val_loss: 1.3356 - val_acc: 0.5397\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.55820\n",
            "Epoch 568/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2884 - acc: 0.5482 - val_loss: 1.3087 - val_acc: 0.5462\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.55820\n",
            "Epoch 569/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2940 - acc: 0.5426 - val_loss: 1.2821 - val_acc: 0.5495\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.55820\n",
            "Epoch 570/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2732 - acc: 0.5568 - val_loss: 1.3235 - val_acc: 0.5384\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.55820\n",
            "Epoch 571/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2846 - acc: 0.5560 - val_loss: 1.3506 - val_acc: 0.5184\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.55820\n",
            "Epoch 572/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3039 - acc: 0.5409 - val_loss: 1.3320 - val_acc: 0.5361\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.55820\n",
            "Epoch 573/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2946 - acc: 0.5526 - val_loss: 1.3082 - val_acc: 0.5442\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.55820\n",
            "Epoch 574/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2871 - acc: 0.5455 - val_loss: 1.4334 - val_acc: 0.5107\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.55820\n",
            "Epoch 575/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3063 - acc: 0.5455 - val_loss: 1.3361 - val_acc: 0.5340\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.55820\n",
            "Epoch 576/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3017 - acc: 0.5362 - val_loss: 1.3474 - val_acc: 0.5329\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.55820\n",
            "Epoch 577/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2685 - acc: 0.5581 - val_loss: 1.2649 - val_acc: 0.5586\n",
            "\n",
            "Epoch 00577: val_acc improved from 0.55820 to 0.55860, saving model to /content/saved_models/cifar10_ResNet32v1_model.577.h5\n",
            "Epoch 578/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2904 - acc: 0.5453 - val_loss: 1.2675 - val_acc: 0.5596\n",
            "\n",
            "Epoch 00578: val_acc improved from 0.55860 to 0.55960, saving model to /content/saved_models/cifar10_ResNet32v1_model.578.h5\n",
            "Epoch 579/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2854 - acc: 0.5475 - val_loss: 1.3048 - val_acc: 0.5358\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.55960\n",
            "Epoch 580/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2869 - acc: 0.5494 - val_loss: 1.3915 - val_acc: 0.5141\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.55960\n",
            "Epoch 581/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.2665 - acc: 0.5524 - val_loss: 1.3274 - val_acc: 0.5318\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.55960\n",
            "Epoch 582/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2843 - acc: 0.5589 - val_loss: 1.2784 - val_acc: 0.5513\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.55960\n",
            "Epoch 583/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2825 - acc: 0.5511 - val_loss: 1.3085 - val_acc: 0.5381\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.55960\n",
            "Epoch 584/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2815 - acc: 0.5524 - val_loss: 1.3727 - val_acc: 0.5304\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.55960\n",
            "Epoch 585/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3038 - acc: 0.5437 - val_loss: 1.3626 - val_acc: 0.5292\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.55960\n",
            "Epoch 586/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2708 - acc: 0.5581 - val_loss: 1.3067 - val_acc: 0.5452\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.55960\n",
            "Epoch 587/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3013 - acc: 0.5484 - val_loss: 1.3489 - val_acc: 0.5352\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.55960\n",
            "Epoch 588/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2664 - acc: 0.5561 - val_loss: 1.3028 - val_acc: 0.5409\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.55960\n",
            "Epoch 589/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2811 - acc: 0.5473 - val_loss: 1.3472 - val_acc: 0.5354\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.55960\n",
            "Epoch 590/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2842 - acc: 0.5541 - val_loss: 1.2776 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.55960\n",
            "Epoch 591/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.2797 - acc: 0.5535 - val_loss: 1.2611 - val_acc: 0.5604\n",
            "\n",
            "Epoch 00591: val_acc improved from 0.55960 to 0.56040, saving model to /content/saved_models/cifar10_ResNet32v1_model.591.h5\n",
            "Epoch 592/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2825 - acc: 0.5511 - val_loss: 1.3165 - val_acc: 0.5347\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.56040\n",
            "Epoch 593/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2693 - acc: 0.5605 - val_loss: 1.3185 - val_acc: 0.5435\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.56040\n",
            "Epoch 594/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2760 - acc: 0.5418 - val_loss: 1.3063 - val_acc: 0.5426\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.56040\n",
            "Epoch 595/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2800 - acc: 0.5519 - val_loss: 1.3055 - val_acc: 0.5427\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.56040\n",
            "Epoch 596/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2731 - acc: 0.5505 - val_loss: 1.2995 - val_acc: 0.5479\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.56040\n",
            "Epoch 597/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2860 - acc: 0.5428 - val_loss: 1.2550 - val_acc: 0.5601\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.56040\n",
            "Epoch 598/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.2962 - acc: 0.5550 - val_loss: 1.3562 - val_acc: 0.5325\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.56040\n",
            "Epoch 599/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2690 - acc: 0.5509 - val_loss: 1.3485 - val_acc: 0.5246\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.56040\n",
            "Epoch 600/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.2788 - acc: 0.5480 - val_loss: 1.3165 - val_acc: 0.5408\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.56040\n",
            "Epoch 601/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2908 - acc: 0.5437 - val_loss: 1.3210 - val_acc: 0.5436\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.56040\n",
            "Epoch 602/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2796 - acc: 0.5566 - val_loss: 1.2776 - val_acc: 0.5530\n",
            "\n",
            "Epoch 00602: val_acc did not improve from 0.56040\n",
            "Epoch 603/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2894 - acc: 0.5505 - val_loss: 1.2804 - val_acc: 0.5509\n",
            "\n",
            "Epoch 00603: val_acc did not improve from 0.56040\n",
            "Epoch 604/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2865 - acc: 0.5490 - val_loss: 1.2761 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00604: val_acc did not improve from 0.56040\n",
            "Epoch 605/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2718 - acc: 0.5500 - val_loss: 1.2714 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00605: val_acc did not improve from 0.56040\n",
            "Epoch 606/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2596 - acc: 0.5575 - val_loss: 1.2815 - val_acc: 0.5504\n",
            "\n",
            "Epoch 00606: val_acc did not improve from 0.56040\n",
            "Epoch 607/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2715 - acc: 0.5545 - val_loss: 1.2850 - val_acc: 0.5488\n",
            "\n",
            "Epoch 00607: val_acc did not improve from 0.56040\n",
            "Epoch 608/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2884 - acc: 0.5542 - val_loss: 1.2772 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00608: val_acc did not improve from 0.56040\n",
            "Epoch 609/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.2979 - acc: 0.5460 - val_loss: 1.2861 - val_acc: 0.5512\n",
            "\n",
            "Epoch 00609: val_acc did not improve from 0.56040\n",
            "Epoch 610/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2824 - acc: 0.5525 - val_loss: 1.2798 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00610: val_acc did not improve from 0.56040\n",
            "Epoch 611/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.2870 - acc: 0.5547 - val_loss: 1.2736 - val_acc: 0.5530\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.56040\n",
            "Epoch 612/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2855 - acc: 0.5488 - val_loss: 1.2730 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00612: val_acc did not improve from 0.56040\n",
            "Epoch 613/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2954 - acc: 0.5387 - val_loss: 1.2770 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00613: val_acc did not improve from 0.56040\n",
            "Epoch 614/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2789 - acc: 0.5607 - val_loss: 1.2737 - val_acc: 0.5508\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.56040\n",
            "Epoch 615/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3000 - acc: 0.5545 - val_loss: 1.2795 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.56040\n",
            "Epoch 616/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2862 - acc: 0.5518 - val_loss: 1.2843 - val_acc: 0.5525\n",
            "\n",
            "Epoch 00616: val_acc did not improve from 0.56040\n",
            "Epoch 617/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.2682 - acc: 0.5539 - val_loss: 1.2797 - val_acc: 0.5513\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.56040\n",
            "Epoch 618/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2782 - acc: 0.5451 - val_loss: 1.2801 - val_acc: 0.5507\n",
            "\n",
            "Epoch 00618: val_acc did not improve from 0.56040\n",
            "Epoch 619/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3204 - acc: 0.5366 - val_loss: 1.2877 - val_acc: 0.5499\n",
            "\n",
            "Epoch 00619: val_acc did not improve from 0.56040\n",
            "Epoch 620/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.3027 - acc: 0.5469 - val_loss: 1.2784 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.56040\n",
            "Epoch 621/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2812 - acc: 0.5526 - val_loss: 1.2776 - val_acc: 0.5483\n",
            "\n",
            "Epoch 00621: val_acc did not improve from 0.56040\n",
            "Epoch 622/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.2717 - acc: 0.5524 - val_loss: 1.2775 - val_acc: 0.5496\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.56040\n",
            "Epoch 623/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2789 - acc: 0.5608 - val_loss: 1.2805 - val_acc: 0.5506\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.56040\n",
            "Epoch 624/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.2674 - acc: 0.5528 - val_loss: 1.2734 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.56040\n",
            "Epoch 625/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2825 - acc: 0.5402 - val_loss: 1.2815 - val_acc: 0.5506\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.56040\n",
            "Epoch 626/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.2847 - acc: 0.5534 - val_loss: 1.2723 - val_acc: 0.5536\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.56040\n",
            "Epoch 627/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3020 - acc: 0.5468 - val_loss: 1.2820 - val_acc: 0.5514\n",
            "\n",
            "Epoch 00627: val_acc did not improve from 0.56040\n",
            "Epoch 628/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2747 - acc: 0.5519 - val_loss: 1.2910 - val_acc: 0.5489\n",
            "\n",
            "Epoch 00628: val_acc did not improve from 0.56040\n",
            "Epoch 629/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.2991 - acc: 0.5501 - val_loss: 1.2878 - val_acc: 0.5482\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.56040\n",
            "Epoch 630/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2929 - acc: 0.5439 - val_loss: 1.2780 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00630: val_acc did not improve from 0.56040\n",
            "Epoch 631/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.2920 - acc: 0.5365 - val_loss: 1.2840 - val_acc: 0.5501\n",
            "\n",
            "Epoch 00631: val_acc did not improve from 0.56040\n",
            "Epoch 632/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3026 - acc: 0.5415 - val_loss: 1.2800 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00632: val_acc did not improve from 0.56040\n",
            "Epoch 633/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.2831 - acc: 0.5548 - val_loss: 1.2871 - val_acc: 0.5498\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.56040\n",
            "Epoch 634/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3022 - acc: 0.5406 - val_loss: 1.2904 - val_acc: 0.5488\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.56040\n",
            "Epoch 635/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2766 - acc: 0.5508 - val_loss: 1.2829 - val_acc: 0.5501\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.56040\n",
            "Epoch 636/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2916 - acc: 0.5502 - val_loss: 1.2790 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.56040\n",
            "Epoch 637/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2474 - acc: 0.5591 - val_loss: 1.2807 - val_acc: 0.5514\n",
            "\n",
            "Epoch 00637: val_acc did not improve from 0.56040\n",
            "Epoch 638/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.2762 - acc: 0.5606 - val_loss: 1.2820 - val_acc: 0.5511\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.56040\n",
            "Epoch 639/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2870 - acc: 0.5561 - val_loss: 1.2711 - val_acc: 0.5530\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.56040\n",
            "Epoch 640/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.2744 - acc: 0.5551 - val_loss: 1.2795 - val_acc: 0.5512\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.56040\n",
            "Epoch 641/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2918 - acc: 0.5484 - val_loss: 1.2856 - val_acc: 0.5491\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.56040\n",
            "Epoch 642/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2727 - acc: 0.5520 - val_loss: 1.2738 - val_acc: 0.5511\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.56040\n",
            "Epoch 643/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.2795 - acc: 0.5564 - val_loss: 1.2851 - val_acc: 0.5513\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.56040\n",
            "Epoch 644/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3140 - acc: 0.5394 - val_loss: 1.2752 - val_acc: 0.5550\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.56040\n",
            "Epoch 645/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.2884 - acc: 0.5469 - val_loss: 1.2763 - val_acc: 0.5533\n",
            "\n",
            "Epoch 00645: val_acc did not improve from 0.56040\n",
            "Epoch 646/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2779 - acc: 0.5534 - val_loss: 1.2777 - val_acc: 0.5557\n",
            "\n",
            "Epoch 00646: val_acc did not improve from 0.56040\n",
            "Epoch 647/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.2882 - acc: 0.5535 - val_loss: 1.2797 - val_acc: 0.5517\n",
            "\n",
            "Epoch 00647: val_acc did not improve from 0.56040\n",
            "Epoch 648/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3088 - acc: 0.5330 - val_loss: 1.2806 - val_acc: 0.5503\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.56040\n",
            "Epoch 649/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2923 - acc: 0.5379 - val_loss: 1.2833 - val_acc: 0.5497\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.56040\n",
            "Epoch 650/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2725 - acc: 0.5597 - val_loss: 1.2738 - val_acc: 0.5530\n",
            "\n",
            "Epoch 00650: val_acc did not improve from 0.56040\n",
            "Epoch 651/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2677 - acc: 0.5552 - val_loss: 1.2801 - val_acc: 0.5540\n",
            "\n",
            "Epoch 00651: val_acc did not improve from 0.56040\n",
            "Epoch 652/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.2918 - acc: 0.5388 - val_loss: 1.2820 - val_acc: 0.5493\n",
            "\n",
            "Epoch 00652: val_acc did not improve from 0.56040\n",
            "Epoch 653/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2904 - acc: 0.5461 - val_loss: 1.2762 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00653: val_acc did not improve from 0.56040\n",
            "Epoch 654/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.2922 - acc: 0.5492 - val_loss: 1.2718 - val_acc: 0.5549\n",
            "\n",
            "Epoch 00654: val_acc did not improve from 0.56040\n",
            "Epoch 655/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2863 - acc: 0.5435 - val_loss: 1.2752 - val_acc: 0.5528\n",
            "\n",
            "Epoch 00655: val_acc did not improve from 0.56040\n",
            "Epoch 656/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.2851 - acc: 0.5495 - val_loss: 1.2795 - val_acc: 0.5506\n",
            "\n",
            "Epoch 00656: val_acc did not improve from 0.56040\n",
            "Epoch 657/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2894 - acc: 0.5501 - val_loss: 1.2874 - val_acc: 0.5488\n",
            "\n",
            "Epoch 00657: val_acc did not improve from 0.56040\n",
            "Epoch 658/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2812 - acc: 0.5472 - val_loss: 1.2738 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00658: val_acc did not improve from 0.56040\n",
            "Epoch 659/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.2824 - acc: 0.5478 - val_loss: 1.2833 - val_acc: 0.5509\n",
            "\n",
            "Epoch 00659: val_acc did not improve from 0.56040\n",
            "Epoch 660/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2951 - acc: 0.5471 - val_loss: 1.2747 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00660: val_acc did not improve from 0.56040\n",
            "Epoch 661/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.2779 - acc: 0.5488 - val_loss: 1.2770 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00661: val_acc did not improve from 0.56040\n",
            "Epoch 662/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2884 - acc: 0.5533 - val_loss: 1.2806 - val_acc: 0.5513\n",
            "\n",
            "Epoch 00662: val_acc did not improve from 0.56040\n",
            "Epoch 663/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2846 - acc: 0.5410 - val_loss: 1.2949 - val_acc: 0.5493\n",
            "\n",
            "Epoch 00663: val_acc did not improve from 0.56040\n",
            "Epoch 664/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.2783 - acc: 0.5589 - val_loss: 1.2765 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00664: val_acc did not improve from 0.56040\n",
            "Epoch 665/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2858 - acc: 0.5578 - val_loss: 1.2828 - val_acc: 0.5504\n",
            "\n",
            "Epoch 00665: val_acc did not improve from 0.56040\n",
            "Epoch 666/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.2972 - acc: 0.5441 - val_loss: 1.2803 - val_acc: 0.5508\n",
            "\n",
            "Epoch 00666: val_acc did not improve from 0.56040\n",
            "Epoch 667/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2657 - acc: 0.5534 - val_loss: 1.2847 - val_acc: 0.5506\n",
            "\n",
            "Epoch 00667: val_acc did not improve from 0.56040\n",
            "Epoch 668/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3002 - acc: 0.5482 - val_loss: 1.2740 - val_acc: 0.5535\n",
            "\n",
            "Epoch 00668: val_acc did not improve from 0.56040\n",
            "Epoch 669/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.2868 - acc: 0.5506 - val_loss: 1.2738 - val_acc: 0.5517\n",
            "\n",
            "Epoch 00669: val_acc did not improve from 0.56040\n",
            "Epoch 670/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2825 - acc: 0.5586 - val_loss: 1.2763 - val_acc: 0.5508\n",
            "\n",
            "Epoch 00670: val_acc did not improve from 0.56040\n",
            "Epoch 671/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.3233 - acc: 0.5405 - val_loss: 1.2833 - val_acc: 0.5514\n",
            "\n",
            "Epoch 00671: val_acc did not improve from 0.56040\n",
            "Epoch 672/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2501 - acc: 0.5620 - val_loss: 1.2800 - val_acc: 0.5513\n",
            "\n",
            "Epoch 00672: val_acc did not improve from 0.56040\n",
            "Epoch 673/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.2699 - acc: 0.5556 - val_loss: 1.2774 - val_acc: 0.5512\n",
            "\n",
            "Epoch 00673: val_acc did not improve from 0.56040\n",
            "Epoch 674/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2849 - acc: 0.5480 - val_loss: 1.2790 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00674: val_acc did not improve from 0.56040\n",
            "Epoch 675/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3009 - acc: 0.5498 - val_loss: 1.2818 - val_acc: 0.5512\n",
            "\n",
            "Epoch 00675: val_acc did not improve from 0.56040\n",
            "Epoch 676/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.2956 - acc: 0.5516 - val_loss: 1.2738 - val_acc: 0.5534\n",
            "\n",
            "Epoch 00676: val_acc did not improve from 0.56040\n",
            "Epoch 677/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2672 - acc: 0.5563 - val_loss: 1.2753 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00677: val_acc did not improve from 0.56040\n",
            "Epoch 678/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3018 - acc: 0.5497 - val_loss: 1.2715 - val_acc: 0.5533\n",
            "\n",
            "Epoch 00678: val_acc did not improve from 0.56040\n",
            "Epoch 679/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.2633 - acc: 0.5536 - val_loss: 1.2792 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00679: val_acc did not improve from 0.56040\n",
            "Epoch 680/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2850 - acc: 0.5509 - val_loss: 1.2759 - val_acc: 0.5525\n",
            "\n",
            "Epoch 00680: val_acc did not improve from 0.56040\n",
            "Epoch 681/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.2807 - acc: 0.5446 - val_loss: 1.2800 - val_acc: 0.5516\n",
            "\n",
            "Epoch 00681: val_acc did not improve from 0.56040\n",
            "Epoch 682/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2700 - acc: 0.5641 - val_loss: 1.2806 - val_acc: 0.5532\n",
            "\n",
            "Epoch 00682: val_acc did not improve from 0.56040\n",
            "Epoch 683/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2621 - acc: 0.5538 - val_loss: 1.2866 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00683: val_acc did not improve from 0.56040\n",
            "Epoch 684/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2726 - acc: 0.5435 - val_loss: 1.2796 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00684: val_acc did not improve from 0.56040\n",
            "Epoch 685/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2827 - acc: 0.5453 - val_loss: 1.2807 - val_acc: 0.5528\n",
            "\n",
            "Epoch 00685: val_acc did not improve from 0.56040\n",
            "Epoch 686/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.3048 - acc: 0.5452 - val_loss: 1.2880 - val_acc: 0.5462\n",
            "\n",
            "Epoch 00686: val_acc did not improve from 0.56040\n",
            "Epoch 687/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2897 - acc: 0.5529 - val_loss: 1.2767 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00687: val_acc did not improve from 0.56040\n",
            "Epoch 688/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2853 - acc: 0.5382 - val_loss: 1.2777 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00688: val_acc did not improve from 0.56040\n",
            "Epoch 689/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.2844 - acc: 0.5505 - val_loss: 1.2853 - val_acc: 0.5507\n",
            "\n",
            "Epoch 00689: val_acc did not improve from 0.56040\n",
            "Epoch 690/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2686 - acc: 0.5577 - val_loss: 1.2796 - val_acc: 0.5528\n",
            "\n",
            "Epoch 00690: val_acc did not improve from 0.56040\n",
            "Epoch 691/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.2768 - acc: 0.5530 - val_loss: 1.2720 - val_acc: 0.5541\n",
            "\n",
            "Epoch 00691: val_acc did not improve from 0.56040\n",
            "Epoch 692/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3084 - acc: 0.5364 - val_loss: 1.2805 - val_acc: 0.5505\n",
            "\n",
            "Epoch 00692: val_acc did not improve from 0.56040\n",
            "Epoch 693/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2714 - acc: 0.5482 - val_loss: 1.2740 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00693: val_acc did not improve from 0.56040\n",
            "Epoch 694/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2921 - acc: 0.5505 - val_loss: 1.2782 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00694: val_acc did not improve from 0.56040\n",
            "Epoch 695/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2739 - acc: 0.5573 - val_loss: 1.2870 - val_acc: 0.5479\n",
            "\n",
            "Epoch 00695: val_acc did not improve from 0.56040\n",
            "Epoch 696/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.3049 - acc: 0.5482 - val_loss: 1.2779 - val_acc: 0.5509\n",
            "\n",
            "Epoch 00696: val_acc did not improve from 0.56040\n",
            "Epoch 697/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2677 - acc: 0.5587 - val_loss: 1.2842 - val_acc: 0.5511\n",
            "\n",
            "Epoch 00697: val_acc did not improve from 0.56040\n",
            "Epoch 698/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2928 - acc: 0.5468 - val_loss: 1.2787 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00698: val_acc did not improve from 0.56040\n",
            "Epoch 699/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.2585 - acc: 0.5539 - val_loss: 1.2844 - val_acc: 0.5499\n",
            "\n",
            "Epoch 00699: val_acc did not improve from 0.56040\n",
            "Epoch 700/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2808 - acc: 0.5537 - val_loss: 1.2857 - val_acc: 0.5483\n",
            "\n",
            "Epoch 00700: val_acc did not improve from 0.56040\n",
            "Epoch 701/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2962 - acc: 0.5386 - val_loss: 1.2996 - val_acc: 0.5455\n",
            "\n",
            "Epoch 00701: val_acc did not improve from 0.56040\n",
            "Epoch 702/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2730 - acc: 0.5515 - val_loss: 1.2851 - val_acc: 0.5513\n",
            "\n",
            "Epoch 00702: val_acc did not improve from 0.56040\n",
            "Epoch 703/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2811 - acc: 0.5460 - val_loss: 1.2749 - val_acc: 0.5536\n",
            "\n",
            "Epoch 00703: val_acc did not improve from 0.56040\n",
            "Epoch 704/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.2728 - acc: 0.5505 - val_loss: 1.2929 - val_acc: 0.5493\n",
            "\n",
            "Epoch 00704: val_acc did not improve from 0.56040\n",
            "Epoch 705/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2940 - acc: 0.5381 - val_loss: 1.2850 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00705: val_acc did not improve from 0.56040\n",
            "Epoch 706/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2687 - acc: 0.5472 - val_loss: 1.2759 - val_acc: 0.5536\n",
            "\n",
            "Epoch 00706: val_acc did not improve from 0.56040\n",
            "Epoch 707/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.2792 - acc: 0.5496 - val_loss: 1.2740 - val_acc: 0.5528\n",
            "\n",
            "Epoch 00707: val_acc did not improve from 0.56040\n",
            "Epoch 708/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2769 - acc: 0.5551 - val_loss: 1.2724 - val_acc: 0.5539\n",
            "\n",
            "Epoch 00708: val_acc did not improve from 0.56040\n",
            "Epoch 709/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2988 - acc: 0.5497 - val_loss: 1.2875 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00709: val_acc did not improve from 0.56040\n",
            "Epoch 710/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2800 - acc: 0.5509 - val_loss: 1.2817 - val_acc: 0.5497\n",
            "\n",
            "Epoch 00710: val_acc did not improve from 0.56040\n",
            "Epoch 711/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2708 - acc: 0.5500 - val_loss: 1.2892 - val_acc: 0.5484\n",
            "\n",
            "Epoch 00711: val_acc did not improve from 0.56040\n",
            "Epoch 712/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2625 - acc: 0.5638 - val_loss: 1.2810 - val_acc: 0.5495\n",
            "\n",
            "Epoch 00712: val_acc did not improve from 0.56040\n",
            "Epoch 713/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2731 - acc: 0.5611 - val_loss: 1.2829 - val_acc: 0.5502\n",
            "\n",
            "Epoch 00713: val_acc did not improve from 0.56040\n",
            "Epoch 714/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2877 - acc: 0.5425 - val_loss: 1.2872 - val_acc: 0.5485\n",
            "\n",
            "Epoch 00714: val_acc did not improve from 0.56040\n",
            "Epoch 715/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2925 - acc: 0.5506 - val_loss: 1.2795 - val_acc: 0.5506\n",
            "\n",
            "Epoch 00715: val_acc did not improve from 0.56040\n",
            "Epoch 716/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2851 - acc: 0.5594 - val_loss: 1.2785 - val_acc: 0.5511\n",
            "\n",
            "Epoch 00716: val_acc did not improve from 0.56040\n",
            "Epoch 717/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2749 - acc: 0.5543 - val_loss: 1.2824 - val_acc: 0.5502\n",
            "\n",
            "Epoch 00717: val_acc did not improve from 0.56040\n",
            "Epoch 718/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2680 - acc: 0.5524 - val_loss: 1.2793 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00718: val_acc did not improve from 0.56040\n",
            "Epoch 719/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2831 - acc: 0.5491 - val_loss: 1.2860 - val_acc: 0.5511\n",
            "\n",
            "Epoch 00719: val_acc did not improve from 0.56040\n",
            "Epoch 720/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2766 - acc: 0.5541 - val_loss: 1.2836 - val_acc: 0.5511\n",
            "\n",
            "Epoch 00720: val_acc did not improve from 0.56040\n",
            "Epoch 721/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2707 - acc: 0.5570 - val_loss: 1.2709 - val_acc: 0.5548\n",
            "\n",
            "Epoch 00721: val_acc did not improve from 0.56040\n",
            "Epoch 722/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2851 - acc: 0.5481 - val_loss: 1.2862 - val_acc: 0.5512\n",
            "\n",
            "Epoch 00722: val_acc did not improve from 0.56040\n",
            "Epoch 723/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2498 - acc: 0.5714 - val_loss: 1.2782 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00723: val_acc did not improve from 0.56040\n",
            "Epoch 724/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.2688 - acc: 0.5525 - val_loss: 1.2921 - val_acc: 0.5489\n",
            "\n",
            "Epoch 00724: val_acc did not improve from 0.56040\n",
            "Epoch 725/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2663 - acc: 0.5624 - val_loss: 1.2779 - val_acc: 0.5513\n",
            "\n",
            "Epoch 00725: val_acc did not improve from 0.56040\n",
            "Epoch 726/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2864 - acc: 0.5434 - val_loss: 1.2870 - val_acc: 0.5499\n",
            "\n",
            "Epoch 00726: val_acc did not improve from 0.56040\n",
            "Epoch 727/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2888 - acc: 0.5430 - val_loss: 1.2764 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00727: val_acc did not improve from 0.56040\n",
            "Epoch 728/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2947 - acc: 0.5518 - val_loss: 1.2872 - val_acc: 0.5502\n",
            "\n",
            "Epoch 00728: val_acc did not improve from 0.56040\n",
            "Epoch 729/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2846 - acc: 0.5495 - val_loss: 1.2920 - val_acc: 0.5485\n",
            "\n",
            "Epoch 00729: val_acc did not improve from 0.56040\n",
            "Epoch 730/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2978 - acc: 0.5440 - val_loss: 1.2809 - val_acc: 0.5514\n",
            "\n",
            "Epoch 00730: val_acc did not improve from 0.56040\n",
            "Epoch 731/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3001 - acc: 0.5445 - val_loss: 1.2878 - val_acc: 0.5478\n",
            "\n",
            "Epoch 00731: val_acc did not improve from 0.56040\n",
            "Epoch 732/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2950 - acc: 0.5466 - val_loss: 1.2856 - val_acc: 0.5496\n",
            "\n",
            "Epoch 00732: val_acc did not improve from 0.56040\n",
            "Epoch 733/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2887 - acc: 0.5476 - val_loss: 1.2846 - val_acc: 0.5504\n",
            "\n",
            "Epoch 00733: val_acc did not improve from 0.56040\n",
            "Epoch 734/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.2836 - acc: 0.5561 - val_loss: 1.2782 - val_acc: 0.5532\n",
            "\n",
            "Epoch 00734: val_acc did not improve from 0.56040\n",
            "Epoch 735/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2644 - acc: 0.5494 - val_loss: 1.2859 - val_acc: 0.5489\n",
            "\n",
            "Epoch 00735: val_acc did not improve from 0.56040\n",
            "Epoch 736/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2856 - acc: 0.5518 - val_loss: 1.2712 - val_acc: 0.5540\n",
            "\n",
            "Epoch 00736: val_acc did not improve from 0.56040\n",
            "Epoch 737/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2937 - acc: 0.5455 - val_loss: 1.2831 - val_acc: 0.5512\n",
            "\n",
            "Epoch 00737: val_acc did not improve from 0.56040\n",
            "Epoch 738/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2685 - acc: 0.5529 - val_loss: 1.2705 - val_acc: 0.5539\n",
            "\n",
            "Epoch 00738: val_acc did not improve from 0.56040\n",
            "Epoch 739/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3038 - acc: 0.5473 - val_loss: 1.2836 - val_acc: 0.5498\n",
            "\n",
            "Epoch 00739: val_acc did not improve from 0.56040\n",
            "Epoch 740/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.3022 - acc: 0.5406 - val_loss: 1.2757 - val_acc: 0.5514\n",
            "\n",
            "Epoch 00740: val_acc did not improve from 0.56040\n",
            "Epoch 741/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2996 - acc: 0.5471 - val_loss: 1.2726 - val_acc: 0.5538\n",
            "\n",
            "Epoch 00741: val_acc did not improve from 0.56040\n",
            "Epoch 742/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2763 - acc: 0.5496 - val_loss: 1.2811 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00742: val_acc did not improve from 0.56040\n",
            "Epoch 743/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.3142 - acc: 0.5422 - val_loss: 1.2716 - val_acc: 0.5543\n",
            "\n",
            "Epoch 00743: val_acc did not improve from 0.56040\n",
            "Epoch 744/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2766 - acc: 0.5554 - val_loss: 1.2901 - val_acc: 0.5511\n",
            "\n",
            "Epoch 00744: val_acc did not improve from 0.56040\n",
            "Epoch 745/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.3058 - acc: 0.5418 - val_loss: 1.2792 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00745: val_acc did not improve from 0.56040\n",
            "Epoch 746/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2999 - acc: 0.5374 - val_loss: 1.2880 - val_acc: 0.5501\n",
            "\n",
            "Epoch 00746: val_acc did not improve from 0.56040\n",
            "Epoch 747/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3105 - acc: 0.5380 - val_loss: 1.2858 - val_acc: 0.5489\n",
            "\n",
            "Epoch 00747: val_acc did not improve from 0.56040\n",
            "Epoch 748/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.2962 - acc: 0.5500 - val_loss: 1.2866 - val_acc: 0.5507\n",
            "\n",
            "Epoch 00748: val_acc did not improve from 0.56040\n",
            "Epoch 749/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2824 - acc: 0.5470 - val_loss: 1.2826 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00749: val_acc did not improve from 0.56040\n",
            "Epoch 750/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2944 - acc: 0.5497 - val_loss: 1.2828 - val_acc: 0.5508\n",
            "\n",
            "Epoch 00750: val_acc did not improve from 0.56040\n",
            "Epoch 751/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.3121 - acc: 0.5484 - val_loss: 1.2938 - val_acc: 0.5476\n",
            "\n",
            "Epoch 00751: val_acc did not improve from 0.56040\n",
            "Epoch 752/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2830 - acc: 0.5592 - val_loss: 1.2874 - val_acc: 0.5492\n",
            "\n",
            "Epoch 00752: val_acc did not improve from 0.56040\n",
            "Epoch 753/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2892 - acc: 0.5457 - val_loss: 1.2797 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00753: val_acc did not improve from 0.56040\n",
            "Epoch 754/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.2825 - acc: 0.5522 - val_loss: 1.2821 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00754: val_acc did not improve from 0.56040\n",
            "Epoch 755/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2603 - acc: 0.5617 - val_loss: 1.2968 - val_acc: 0.5485\n",
            "\n",
            "Epoch 00755: val_acc did not improve from 0.56040\n",
            "Epoch 756/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.3049 - acc: 0.5451 - val_loss: 1.2813 - val_acc: 0.5513\n",
            "\n",
            "Epoch 00756: val_acc did not improve from 0.56040\n",
            "Epoch 757/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3021 - acc: 0.5456 - val_loss: 1.2790 - val_acc: 0.5538\n",
            "\n",
            "Epoch 00757: val_acc did not improve from 0.56040\n",
            "Epoch 758/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2853 - acc: 0.5575 - val_loss: 1.2804 - val_acc: 0.5525\n",
            "\n",
            "Epoch 00758: val_acc did not improve from 0.56040\n",
            "Epoch 759/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2802 - acc: 0.5513 - val_loss: 1.2719 - val_acc: 0.5552\n",
            "\n",
            "Epoch 00759: val_acc did not improve from 0.56040\n",
            "Epoch 760/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2914 - acc: 0.5493 - val_loss: 1.2753 - val_acc: 0.5536\n",
            "\n",
            "Epoch 00760: val_acc did not improve from 0.56040\n",
            "Epoch 761/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2625 - acc: 0.5641 - val_loss: 1.2772 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00761: val_acc did not improve from 0.56040\n",
            "Epoch 762/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.2779 - acc: 0.5569 - val_loss: 1.2737 - val_acc: 0.5551\n",
            "\n",
            "Epoch 00762: val_acc did not improve from 0.56040\n",
            "Epoch 763/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3036 - acc: 0.5407 - val_loss: 1.2714 - val_acc: 0.5542\n",
            "\n",
            "Epoch 00763: val_acc did not improve from 0.56040\n",
            "Epoch 764/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2599 - acc: 0.5578 - val_loss: 1.2873 - val_acc: 0.5490\n",
            "\n",
            "Epoch 00764: val_acc did not improve from 0.56040\n",
            "Epoch 765/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.2679 - acc: 0.5522 - val_loss: 1.2820 - val_acc: 0.5516\n",
            "\n",
            "Epoch 00765: val_acc did not improve from 0.56040\n",
            "Epoch 766/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2983 - acc: 0.5479 - val_loss: 1.2789 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00766: val_acc did not improve from 0.56040\n",
            "Epoch 767/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2733 - acc: 0.5494 - val_loss: 1.2877 - val_acc: 0.5495\n",
            "\n",
            "Epoch 00767: val_acc did not improve from 0.56040\n",
            "Epoch 768/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.2915 - acc: 0.5424 - val_loss: 1.2862 - val_acc: 0.5479\n",
            "\n",
            "Epoch 00768: val_acc did not improve from 0.56040\n",
            "Epoch 769/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2913 - acc: 0.5450 - val_loss: 1.2829 - val_acc: 0.5484\n",
            "\n",
            "Epoch 00769: val_acc did not improve from 0.56040\n",
            "Epoch 770/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2877 - acc: 0.5521 - val_loss: 1.2725 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00770: val_acc did not improve from 0.56040\n",
            "Epoch 771/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.2885 - acc: 0.5450 - val_loss: 1.2727 - val_acc: 0.5536\n",
            "\n",
            "Epoch 00771: val_acc did not improve from 0.56040\n",
            "Epoch 772/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2627 - acc: 0.5579 - val_loss: 1.2764 - val_acc: 0.5537\n",
            "\n",
            "Epoch 00772: val_acc did not improve from 0.56040\n",
            "Epoch 773/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.2985 - acc: 0.5474 - val_loss: 1.2855 - val_acc: 0.5509\n",
            "\n",
            "Epoch 00773: val_acc did not improve from 0.56040\n",
            "Epoch 774/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2667 - acc: 0.5508 - val_loss: 1.2894 - val_acc: 0.5488\n",
            "\n",
            "Epoch 00774: val_acc did not improve from 0.56040\n",
            "Epoch 775/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2691 - acc: 0.5563 - val_loss: 1.2823 - val_acc: 0.5516\n",
            "\n",
            "Epoch 00775: val_acc did not improve from 0.56040\n",
            "Epoch 776/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.2932 - acc: 0.5491 - val_loss: 1.2732 - val_acc: 0.5551\n",
            "\n",
            "Epoch 00776: val_acc did not improve from 0.56040\n",
            "Epoch 777/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2855 - acc: 0.5453 - val_loss: 1.2813 - val_acc: 0.5512\n",
            "\n",
            "Epoch 00777: val_acc did not improve from 0.56040\n",
            "Epoch 778/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2930 - acc: 0.5520 - val_loss: 1.2767 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00778: val_acc did not improve from 0.56040\n",
            "Epoch 779/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.3030 - acc: 0.5420 - val_loss: 1.2773 - val_acc: 0.5505\n",
            "\n",
            "Epoch 00779: val_acc did not improve from 0.56040\n",
            "Epoch 780/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2977 - acc: 0.5461 - val_loss: 1.2813 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00780: val_acc did not improve from 0.56040\n",
            "Epoch 781/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2786 - acc: 0.5638 - val_loss: 1.2888 - val_acc: 0.5499\n",
            "\n",
            "Epoch 00781: val_acc did not improve from 0.56040\n",
            "Epoch 782/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.3086 - acc: 0.5400 - val_loss: 1.2757 - val_acc: 0.5512\n",
            "\n",
            "Epoch 00782: val_acc did not improve from 0.56040\n",
            "Epoch 783/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2754 - acc: 0.5539 - val_loss: 1.2796 - val_acc: 0.5516\n",
            "\n",
            "Epoch 00783: val_acc did not improve from 0.56040\n",
            "Epoch 784/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2829 - acc: 0.5650 - val_loss: 1.2770 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00784: val_acc did not improve from 0.56040\n",
            "Epoch 785/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.2693 - acc: 0.5624 - val_loss: 1.2787 - val_acc: 0.5530\n",
            "\n",
            "Epoch 00785: val_acc did not improve from 0.56040\n",
            "Epoch 786/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2999 - acc: 0.5521 - val_loss: 1.2758 - val_acc: 0.5541\n",
            "\n",
            "Epoch 00786: val_acc did not improve from 0.56040\n",
            "Epoch 787/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2902 - acc: 0.5396 - val_loss: 1.2761 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00787: val_acc did not improve from 0.56040\n",
            "Epoch 788/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.2682 - acc: 0.5509 - val_loss: 1.2745 - val_acc: 0.5540\n",
            "\n",
            "Epoch 00788: val_acc did not improve from 0.56040\n",
            "Epoch 789/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3043 - acc: 0.5448 - val_loss: 1.2796 - val_acc: 0.5514\n",
            "\n",
            "Epoch 00789: val_acc did not improve from 0.56040\n",
            "Epoch 790/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2823 - acc: 0.5487 - val_loss: 1.2811 - val_acc: 0.5517\n",
            "\n",
            "Epoch 00790: val_acc did not improve from 0.56040\n",
            "Epoch 791/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.2719 - acc: 0.5484 - val_loss: 1.2800 - val_acc: 0.5514\n",
            "\n",
            "Epoch 00791: val_acc did not improve from 0.56040\n",
            "Epoch 792/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2712 - acc: 0.5555 - val_loss: 1.2849 - val_acc: 0.5512\n",
            "\n",
            "Epoch 00792: val_acc did not improve from 0.56040\n",
            "Epoch 793/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2859 - acc: 0.5464 - val_loss: 1.2745 - val_acc: 0.5533\n",
            "\n",
            "Epoch 00793: val_acc did not improve from 0.56040\n",
            "Epoch 794/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.2628 - acc: 0.5494 - val_loss: 1.2724 - val_acc: 0.5535\n",
            "\n",
            "Epoch 00794: val_acc did not improve from 0.56040\n",
            "Epoch 795/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2660 - acc: 0.5532 - val_loss: 1.2777 - val_acc: 0.5542\n",
            "\n",
            "Epoch 00795: val_acc did not improve from 0.56040\n",
            "Epoch 796/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2790 - acc: 0.5453 - val_loss: 1.2714 - val_acc: 0.5538\n",
            "\n",
            "Epoch 00796: val_acc did not improve from 0.56040\n",
            "Epoch 797/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.2892 - acc: 0.5557 - val_loss: 1.2776 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00797: val_acc did not improve from 0.56040\n",
            "Epoch 798/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2752 - acc: 0.5460 - val_loss: 1.2820 - val_acc: 0.5517\n",
            "\n",
            "Epoch 00798: val_acc did not improve from 0.56040\n",
            "Epoch 799/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2610 - acc: 0.5522 - val_loss: 1.2808 - val_acc: 0.5517\n",
            "\n",
            "Epoch 00799: val_acc did not improve from 0.56040\n",
            "Epoch 800/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.2865 - acc: 0.5439 - val_loss: 1.2796 - val_acc: 0.5502\n",
            "\n",
            "Epoch 00800: val_acc did not improve from 0.56040\n",
            "Epoch 801/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2910 - acc: 0.5439 - val_loss: 1.2729 - val_acc: 0.5553\n",
            "\n",
            "Epoch 00801: val_acc did not improve from 0.56040\n",
            "Epoch 802/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3044 - acc: 0.5470 - val_loss: 1.2740 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00802: val_acc did not improve from 0.56040\n",
            "Epoch 803/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 1.2856 - acc: 0.5369 - val_loss: 1.2776 - val_acc: 0.5530\n",
            "\n",
            "Epoch 00803: val_acc did not improve from 0.56040\n",
            "Epoch 804/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2717 - acc: 0.5534 - val_loss: 1.2775 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00804: val_acc did not improve from 0.56040\n",
            "Epoch 805/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3078 - acc: 0.5306 - val_loss: 1.2807 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00805: val_acc did not improve from 0.56040\n",
            "Epoch 806/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.2651 - acc: 0.5548 - val_loss: 1.2822 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00806: val_acc did not improve from 0.56040\n",
            "Epoch 807/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2686 - acc: 0.5508 - val_loss: 1.2802 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00807: val_acc did not improve from 0.56040\n",
            "Epoch 808/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2632 - acc: 0.5539 - val_loss: 1.2822 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00808: val_acc did not improve from 0.56040\n",
            "Epoch 809/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 1.2889 - acc: 0.5489 - val_loss: 1.2815 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00809: val_acc did not improve from 0.56040\n",
            "Epoch 810/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2849 - acc: 0.5441 - val_loss: 1.2798 - val_acc: 0.5514\n",
            "\n",
            "Epoch 00810: val_acc did not improve from 0.56040\n",
            "Epoch 811/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2928 - acc: 0.5476 - val_loss: 1.2805 - val_acc: 0.5525\n",
            "\n",
            "Epoch 00811: val_acc did not improve from 0.56040\n",
            "Epoch 812/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.2905 - acc: 0.5530 - val_loss: 1.2805 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00812: val_acc did not improve from 0.56040\n",
            "Epoch 813/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2683 - acc: 0.5666 - val_loss: 1.2798 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00813: val_acc did not improve from 0.56040\n",
            "Epoch 814/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2614 - acc: 0.5587 - val_loss: 1.2784 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00814: val_acc did not improve from 0.56040\n",
            "Epoch 815/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.3129 - acc: 0.5427 - val_loss: 1.2780 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00815: val_acc did not improve from 0.56040\n",
            "Epoch 816/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2598 - acc: 0.5600 - val_loss: 1.2773 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00816: val_acc did not improve from 0.56040\n",
            "Epoch 817/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2945 - acc: 0.5456 - val_loss: 1.2805 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00817: val_acc did not improve from 0.56040\n",
            "Epoch 818/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.2963 - acc: 0.5449 - val_loss: 1.2795 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00818: val_acc did not improve from 0.56040\n",
            "Epoch 819/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2953 - acc: 0.5466 - val_loss: 1.2809 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00819: val_acc did not improve from 0.56040\n",
            "Epoch 820/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2773 - acc: 0.5491 - val_loss: 1.2773 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00820: val_acc did not improve from 0.56040\n",
            "Epoch 821/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2867 - acc: 0.5385 - val_loss: 1.2782 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00821: val_acc did not improve from 0.56040\n",
            "Epoch 822/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2834 - acc: 0.5589 - val_loss: 1.2782 - val_acc: 0.5528\n",
            "\n",
            "Epoch 00822: val_acc did not improve from 0.56040\n",
            "Epoch 823/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2842 - acc: 0.5488 - val_loss: 1.2780 - val_acc: 0.5534\n",
            "\n",
            "Epoch 00823: val_acc did not improve from 0.56040\n",
            "Epoch 824/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.2787 - acc: 0.5574 - val_loss: 1.2786 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00824: val_acc did not improve from 0.56040\n",
            "Epoch 825/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2750 - acc: 0.5569 - val_loss: 1.2800 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00825: val_acc did not improve from 0.56040\n",
            "Epoch 826/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2878 - acc: 0.5431 - val_loss: 1.2785 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00826: val_acc did not improve from 0.56040\n",
            "Epoch 827/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2830 - acc: 0.5494 - val_loss: 1.2758 - val_acc: 0.5532\n",
            "\n",
            "Epoch 00827: val_acc did not improve from 0.56040\n",
            "Epoch 828/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2755 - acc: 0.5556 - val_loss: 1.2772 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00828: val_acc did not improve from 0.56040\n",
            "Epoch 829/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2740 - acc: 0.5622 - val_loss: 1.2778 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00829: val_acc did not improve from 0.56040\n",
            "Epoch 830/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.3082 - acc: 0.5435 - val_loss: 1.2784 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00830: val_acc did not improve from 0.56040\n",
            "Epoch 831/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2676 - acc: 0.5558 - val_loss: 1.2785 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00831: val_acc did not improve from 0.56040\n",
            "Epoch 832/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2761 - acc: 0.5562 - val_loss: 1.2800 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00832: val_acc did not improve from 0.56040\n",
            "Epoch 833/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2887 - acc: 0.5467 - val_loss: 1.2814 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00833: val_acc did not improve from 0.56040\n",
            "Epoch 834/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 1.2800 - acc: 0.5529 - val_loss: 1.2816 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00834: val_acc did not improve from 0.56040\n",
            "Epoch 835/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2588 - acc: 0.5538 - val_loss: 1.2798 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00835: val_acc did not improve from 0.56040\n",
            "Epoch 836/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3067 - acc: 0.5453 - val_loss: 1.2806 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00836: val_acc did not improve from 0.56040\n",
            "Epoch 837/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 1.2749 - acc: 0.5465 - val_loss: 1.2791 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00837: val_acc did not improve from 0.56040\n",
            "Epoch 838/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2794 - acc: 0.5532 - val_loss: 1.2800 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00838: val_acc did not improve from 0.56040\n",
            "Epoch 839/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2623 - acc: 0.5610 - val_loss: 1.2782 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00839: val_acc did not improve from 0.56040\n",
            "Epoch 840/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.2872 - acc: 0.5514 - val_loss: 1.2806 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00840: val_acc did not improve from 0.56040\n",
            "Epoch 841/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2846 - acc: 0.5452 - val_loss: 1.2780 - val_acc: 0.5528\n",
            "\n",
            "Epoch 00841: val_acc did not improve from 0.56040\n",
            "Epoch 842/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3077 - acc: 0.5527 - val_loss: 1.2777 - val_acc: 0.5525\n",
            "\n",
            "Epoch 00842: val_acc did not improve from 0.56040\n",
            "Epoch 843/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.2975 - acc: 0.5446 - val_loss: 1.2776 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00843: val_acc did not improve from 0.56040\n",
            "Epoch 844/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2858 - acc: 0.5562 - val_loss: 1.2793 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00844: val_acc did not improve from 0.56040\n",
            "Epoch 845/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2694 - acc: 0.5561 - val_loss: 1.2804 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00845: val_acc did not improve from 0.56040\n",
            "Epoch 846/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2896 - acc: 0.5428 - val_loss: 1.2815 - val_acc: 0.5515\n",
            "\n",
            "Epoch 00846: val_acc did not improve from 0.56040\n",
            "Epoch 847/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.2761 - acc: 0.5511 - val_loss: 1.2808 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00847: val_acc did not improve from 0.56040\n",
            "Epoch 848/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2799 - acc: 0.5515 - val_loss: 1.2803 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00848: val_acc did not improve from 0.56040\n",
            "Epoch 849/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2693 - acc: 0.5539 - val_loss: 1.2795 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00849: val_acc did not improve from 0.56040\n",
            "Epoch 850/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.2623 - acc: 0.5598 - val_loss: 1.2794 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00850: val_acc did not improve from 0.56040\n",
            "Epoch 851/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2582 - acc: 0.5575 - val_loss: 1.2785 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00851: val_acc did not improve from 0.56040\n",
            "Epoch 852/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2893 - acc: 0.5535 - val_loss: 1.2795 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00852: val_acc did not improve from 0.56040\n",
            "Epoch 853/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.2923 - acc: 0.5505 - val_loss: 1.2797 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00853: val_acc did not improve from 0.56040\n",
            "Epoch 854/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3024 - acc: 0.5403 - val_loss: 1.2808 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00854: val_acc did not improve from 0.56040\n",
            "Epoch 855/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2991 - acc: 0.5481 - val_loss: 1.2807 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00855: val_acc did not improve from 0.56040\n",
            "Epoch 856/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.2788 - acc: 0.5552 - val_loss: 1.2800 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00856: val_acc did not improve from 0.56040\n",
            "Epoch 857/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3051 - acc: 0.5449 - val_loss: 1.2803 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00857: val_acc did not improve from 0.56040\n",
            "Epoch 858/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2820 - acc: 0.5528 - val_loss: 1.2809 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00858: val_acc did not improve from 0.56040\n",
            "Epoch 859/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2779 - acc: 0.5581 - val_loss: 1.2803 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00859: val_acc did not improve from 0.56040\n",
            "Epoch 860/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.3025 - acc: 0.5444 - val_loss: 1.2789 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00860: val_acc did not improve from 0.56040\n",
            "Epoch 861/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3158 - acc: 0.5351 - val_loss: 1.2817 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00861: val_acc did not improve from 0.56040\n",
            "Epoch 862/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2811 - acc: 0.5579 - val_loss: 1.2825 - val_acc: 0.5510\n",
            "\n",
            "Epoch 00862: val_acc did not improve from 0.56040\n",
            "Epoch 863/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.2703 - acc: 0.5528 - val_loss: 1.2793 - val_acc: 0.5515\n",
            "\n",
            "Epoch 00863: val_acc did not improve from 0.56040\n",
            "Epoch 864/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2705 - acc: 0.5551 - val_loss: 1.2776 - val_acc: 0.5530\n",
            "\n",
            "Epoch 00864: val_acc did not improve from 0.56040\n",
            "Epoch 865/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2912 - acc: 0.5540 - val_loss: 1.2776 - val_acc: 0.5525\n",
            "\n",
            "Epoch 00865: val_acc did not improve from 0.56040\n",
            "Epoch 866/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2828 - acc: 0.5405 - val_loss: 1.2792 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00866: val_acc did not improve from 0.56040\n",
            "Epoch 867/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.2950 - acc: 0.5465 - val_loss: 1.2791 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00867: val_acc did not improve from 0.56040\n",
            "Epoch 868/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2852 - acc: 0.5513 - val_loss: 1.2804 - val_acc: 0.5517\n",
            "\n",
            "Epoch 00868: val_acc did not improve from 0.56040\n",
            "Epoch 869/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2538 - acc: 0.5651 - val_loss: 1.2803 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00869: val_acc did not improve from 0.56040\n",
            "Epoch 870/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.2876 - acc: 0.5444 - val_loss: 1.2799 - val_acc: 0.5534\n",
            "\n",
            "Epoch 00870: val_acc did not improve from 0.56040\n",
            "Epoch 871/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2593 - acc: 0.5646 - val_loss: 1.2785 - val_acc: 0.5533\n",
            "\n",
            "Epoch 00871: val_acc did not improve from 0.56040\n",
            "Epoch 872/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2957 - acc: 0.5425 - val_loss: 1.2780 - val_acc: 0.5533\n",
            "\n",
            "Epoch 00872: val_acc did not improve from 0.56040\n",
            "Epoch 873/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.2662 - acc: 0.5556 - val_loss: 1.2811 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00873: val_acc did not improve from 0.56040\n",
            "Epoch 874/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2719 - acc: 0.5529 - val_loss: 1.2801 - val_acc: 0.5528\n",
            "\n",
            "Epoch 00874: val_acc did not improve from 0.56040\n",
            "Epoch 875/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2898 - acc: 0.5521 - val_loss: 1.2792 - val_acc: 0.5531\n",
            "\n",
            "Epoch 00875: val_acc did not improve from 0.56040\n",
            "Epoch 876/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2944 - acc: 0.5509 - val_loss: 1.2791 - val_acc: 0.5531\n",
            "\n",
            "Epoch 00876: val_acc did not improve from 0.56040\n",
            "Epoch 877/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.2817 - acc: 0.5550 - val_loss: 1.2786 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00877: val_acc did not improve from 0.56040\n",
            "Epoch 878/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3018 - acc: 0.5473 - val_loss: 1.2788 - val_acc: 0.5528\n",
            "\n",
            "Epoch 00878: val_acc did not improve from 0.56040\n",
            "Epoch 879/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2759 - acc: 0.5470 - val_loss: 1.2806 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00879: val_acc did not improve from 0.56040\n",
            "Epoch 880/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.2520 - acc: 0.5628 - val_loss: 1.2816 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00880: val_acc did not improve from 0.56040\n",
            "Epoch 881/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2936 - acc: 0.5440 - val_loss: 1.2798 - val_acc: 0.5517\n",
            "\n",
            "Epoch 00881: val_acc did not improve from 0.56040\n",
            "Epoch 882/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2908 - acc: 0.5445 - val_loss: 1.2789 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00882: val_acc did not improve from 0.56040\n",
            "Epoch 883/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2718 - acc: 0.5547 - val_loss: 1.2797 - val_acc: 0.5525\n",
            "\n",
            "Epoch 00883: val_acc did not improve from 0.56040\n",
            "Epoch 884/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.2751 - acc: 0.5478 - val_loss: 1.2795 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00884: val_acc did not improve from 0.56040\n",
            "Epoch 885/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2726 - acc: 0.5546 - val_loss: 1.2811 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00885: val_acc did not improve from 0.56040\n",
            "Epoch 886/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2935 - acc: 0.5525 - val_loss: 1.2796 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00886: val_acc did not improve from 0.56040\n",
            "Epoch 887/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 1.2955 - acc: 0.5458 - val_loss: 1.2811 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00887: val_acc did not improve from 0.56040\n",
            "Epoch 888/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2953 - acc: 0.5525 - val_loss: 1.2779 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00888: val_acc did not improve from 0.56040\n",
            "Epoch 889/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2545 - acc: 0.5528 - val_loss: 1.2799 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00889: val_acc did not improve from 0.56040\n",
            "Epoch 890/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2790 - acc: 0.5592 - val_loss: 1.2793 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00890: val_acc did not improve from 0.56040\n",
            "Epoch 891/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 1.2932 - acc: 0.5453 - val_loss: 1.2786 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00891: val_acc did not improve from 0.56040\n",
            "Epoch 892/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3066 - acc: 0.5473 - val_loss: 1.2796 - val_acc: 0.5528\n",
            "\n",
            "Epoch 00892: val_acc did not improve from 0.56040\n",
            "Epoch 893/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2992 - acc: 0.5412 - val_loss: 1.2801 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00893: val_acc did not improve from 0.56040\n",
            "Epoch 894/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.2786 - acc: 0.5485 - val_loss: 1.2794 - val_acc: 0.5525\n",
            "\n",
            "Epoch 00894: val_acc did not improve from 0.56040\n",
            "Epoch 895/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2666 - acc: 0.5555 - val_loss: 1.2801 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00895: val_acc did not improve from 0.56040\n",
            "Epoch 896/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2947 - acc: 0.5463 - val_loss: 1.2801 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00896: val_acc did not improve from 0.56040\n",
            "Epoch 897/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2957 - acc: 0.5471 - val_loss: 1.2799 - val_acc: 0.5528\n",
            "\n",
            "Epoch 00897: val_acc did not improve from 0.56040\n",
            "Epoch 898/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 1.2745 - acc: 0.5514 - val_loss: 1.2797 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00898: val_acc did not improve from 0.56040\n",
            "Epoch 899/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2889 - acc: 0.5519 - val_loss: 1.2791 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00899: val_acc did not improve from 0.56040\n",
            "Epoch 900/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2784 - acc: 0.5515 - val_loss: 1.2800 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00900: val_acc did not improve from 0.56040\n",
            "Epoch 901/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.3027 - acc: 0.5446 - val_loss: 1.2808 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00901: val_acc did not improve from 0.56040\n",
            "Epoch 902/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2841 - acc: 0.5446 - val_loss: 1.2798 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00902: val_acc did not improve from 0.56040\n",
            "Epoch 903/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2817 - acc: 0.5562 - val_loss: 1.2792 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00903: val_acc did not improve from 0.56040\n",
            "Epoch 904/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2789 - acc: 0.5593 - val_loss: 1.2813 - val_acc: 0.5525\n",
            "\n",
            "Epoch 00904: val_acc did not improve from 0.56040\n",
            "Epoch 905/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.2739 - acc: 0.5499 - val_loss: 1.2783 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00905: val_acc did not improve from 0.56040\n",
            "Epoch 906/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2806 - acc: 0.5514 - val_loss: 1.2796 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00906: val_acc did not improve from 0.56040\n",
            "Epoch 907/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3012 - acc: 0.5445 - val_loss: 1.2773 - val_acc: 0.5525\n",
            "\n",
            "Epoch 00907: val_acc did not improve from 0.56040\n",
            "Epoch 908/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.2892 - acc: 0.5531 - val_loss: 1.2778 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00908: val_acc did not improve from 0.56040\n",
            "Epoch 909/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2774 - acc: 0.5500 - val_loss: 1.2773 - val_acc: 0.5531\n",
            "\n",
            "Epoch 00909: val_acc did not improve from 0.56040\n",
            "Epoch 910/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2699 - acc: 0.5536 - val_loss: 1.2802 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00910: val_acc did not improve from 0.56040\n",
            "Epoch 911/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2786 - acc: 0.5526 - val_loss: 1.2794 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00911: val_acc did not improve from 0.56040\n",
            "Epoch 912/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.2791 - acc: 0.5501 - val_loss: 1.2782 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00912: val_acc did not improve from 0.56040\n",
            "Epoch 913/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2829 - acc: 0.5530 - val_loss: 1.2820 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00913: val_acc did not improve from 0.56040\n",
            "Epoch 914/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2671 - acc: 0.5574 - val_loss: 1.2797 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00914: val_acc did not improve from 0.56040\n",
            "Epoch 915/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 1.2956 - acc: 0.5514 - val_loss: 1.2795 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00915: val_acc did not improve from 0.56040\n",
            "Epoch 916/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2854 - acc: 0.5500 - val_loss: 1.2815 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00916: val_acc did not improve from 0.56040\n",
            "Epoch 917/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2624 - acc: 0.5587 - val_loss: 1.2831 - val_acc: 0.5509\n",
            "\n",
            "Epoch 00917: val_acc did not improve from 0.56040\n",
            "Epoch 918/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2737 - acc: 0.5491 - val_loss: 1.2811 - val_acc: 0.5516\n",
            "\n",
            "Epoch 00918: val_acc did not improve from 0.56040\n",
            "Epoch 919/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 1.2731 - acc: 0.5658 - val_loss: 1.2793 - val_acc: 0.5532\n",
            "\n",
            "Epoch 00919: val_acc did not improve from 0.56040\n",
            "Epoch 920/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2861 - acc: 0.5521 - val_loss: 1.2782 - val_acc: 0.5530\n",
            "\n",
            "Epoch 00920: val_acc did not improve from 0.56040\n",
            "Epoch 921/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2837 - acc: 0.5521 - val_loss: 1.2791 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00921: val_acc did not improve from 0.56040\n",
            "Epoch 922/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.2722 - acc: 0.5630 - val_loss: 1.2784 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00922: val_acc did not improve from 0.56040\n",
            "Epoch 923/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3163 - acc: 0.5421 - val_loss: 1.2816 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00923: val_acc did not improve from 0.56040\n",
            "Epoch 924/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2948 - acc: 0.5508 - val_loss: 1.2820 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00924: val_acc did not improve from 0.56040\n",
            "Epoch 925/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2519 - acc: 0.5629 - val_loss: 1.2811 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00925: val_acc did not improve from 0.56040\n",
            "Epoch 926/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 1.2868 - acc: 0.5509 - val_loss: 1.2820 - val_acc: 0.5513\n",
            "\n",
            "Epoch 00926: val_acc did not improve from 0.56040\n",
            "Epoch 927/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2702 - acc: 0.5499 - val_loss: 1.2780 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00927: val_acc did not improve from 0.56040\n",
            "Epoch 928/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2690 - acc: 0.5614 - val_loss: 1.2813 - val_acc: 0.5514\n",
            "\n",
            "Epoch 00928: val_acc did not improve from 0.56040\n",
            "Epoch 929/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 1.2632 - acc: 0.5547 - val_loss: 1.2820 - val_acc: 0.5509\n",
            "\n",
            "Epoch 00929: val_acc did not improve from 0.56040\n",
            "Epoch 930/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2820 - acc: 0.5508 - val_loss: 1.2815 - val_acc: 0.5515\n",
            "\n",
            "Epoch 00930: val_acc did not improve from 0.56040\n",
            "Epoch 931/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2702 - acc: 0.5551 - val_loss: 1.2813 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00931: val_acc did not improve from 0.56040\n",
            "Epoch 932/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.2784 - acc: 0.5454 - val_loss: 1.2796 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00932: val_acc did not improve from 0.56040\n",
            "Epoch 933/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2836 - acc: 0.5457 - val_loss: 1.2795 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00933: val_acc did not improve from 0.56040\n",
            "Epoch 934/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2751 - acc: 0.5499 - val_loss: 1.2793 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00934: val_acc did not improve from 0.56040\n",
            "Epoch 935/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2885 - acc: 0.5471 - val_loss: 1.2798 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00935: val_acc did not improve from 0.56040\n",
            "Epoch 936/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 1.3009 - acc: 0.5349 - val_loss: 1.2801 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00936: val_acc did not improve from 0.56040\n",
            "Epoch 937/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3055 - acc: 0.5492 - val_loss: 1.2790 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00937: val_acc did not improve from 0.56040\n",
            "Epoch 938/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2891 - acc: 0.5442 - val_loss: 1.2807 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00938: val_acc did not improve from 0.56040\n",
            "Epoch 939/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.2829 - acc: 0.5587 - val_loss: 1.2794 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00939: val_acc did not improve from 0.56040\n",
            "Epoch 940/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2732 - acc: 0.5510 - val_loss: 1.2783 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00940: val_acc did not improve from 0.56040\n",
            "Epoch 941/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2885 - acc: 0.5506 - val_loss: 1.2800 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00941: val_acc did not improve from 0.56040\n",
            "Epoch 942/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2951 - acc: 0.5424 - val_loss: 1.2782 - val_acc: 0.5533\n",
            "\n",
            "Epoch 00942: val_acc did not improve from 0.56040\n",
            "Epoch 943/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.3051 - acc: 0.5433 - val_loss: 1.2791 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00943: val_acc did not improve from 0.56040\n",
            "Epoch 944/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2892 - acc: 0.5446 - val_loss: 1.2787 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00944: val_acc did not improve from 0.56040\n",
            "Epoch 945/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2753 - acc: 0.5450 - val_loss: 1.2805 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00945: val_acc did not improve from 0.56040\n",
            "Epoch 946/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.2798 - acc: 0.5492 - val_loss: 1.2799 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00946: val_acc did not improve from 0.56040\n",
            "Epoch 947/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2618 - acc: 0.5645 - val_loss: 1.2791 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00947: val_acc did not improve from 0.56040\n",
            "Epoch 948/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2678 - acc: 0.5509 - val_loss: 1.2789 - val_acc: 0.5525\n",
            "\n",
            "Epoch 00948: val_acc did not improve from 0.56040\n",
            "Epoch 949/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2728 - acc: 0.5577 - val_loss: 1.2779 - val_acc: 0.5530\n",
            "\n",
            "Epoch 00949: val_acc did not improve from 0.56040\n",
            "Epoch 950/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.2809 - acc: 0.5477 - val_loss: 1.2803 - val_acc: 0.5515\n",
            "\n",
            "Epoch 00950: val_acc did not improve from 0.56040\n",
            "Epoch 951/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2753 - acc: 0.5537 - val_loss: 1.2774 - val_acc: 0.5538\n",
            "\n",
            "Epoch 00951: val_acc did not improve from 0.56040\n",
            "Epoch 952/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2755 - acc: 0.5479 - val_loss: 1.2787 - val_acc: 0.5528\n",
            "\n",
            "Epoch 00952: val_acc did not improve from 0.56040\n",
            "Epoch 953/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 1.2758 - acc: 0.5439 - val_loss: 1.2790 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00953: val_acc did not improve from 0.56040\n",
            "Epoch 954/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2971 - acc: 0.5364 - val_loss: 1.2800 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00954: val_acc did not improve from 0.56040\n",
            "Epoch 955/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2635 - acc: 0.5557 - val_loss: 1.2786 - val_acc: 0.5531\n",
            "\n",
            "Epoch 00955: val_acc did not improve from 0.56040\n",
            "Epoch 956/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2825 - acc: 0.5534 - val_loss: 1.2802 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00956: val_acc did not improve from 0.56040\n",
            "Epoch 957/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 1.2916 - acc: 0.5469 - val_loss: 1.2800 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00957: val_acc did not improve from 0.56040\n",
            "Epoch 958/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2821 - acc: 0.5533 - val_loss: 1.2800 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00958: val_acc did not improve from 0.56040\n",
            "Epoch 959/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3264 - acc: 0.5310 - val_loss: 1.2802 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00959: val_acc did not improve from 0.56040\n",
            "Epoch 960/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 1.2997 - acc: 0.5475 - val_loss: 1.2789 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00960: val_acc did not improve from 0.56040\n",
            "Epoch 961/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3033 - acc: 0.5525 - val_loss: 1.2771 - val_acc: 0.5534\n",
            "\n",
            "Epoch 00961: val_acc did not improve from 0.56040\n",
            "Epoch 962/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2809 - acc: 0.5429 - val_loss: 1.2799 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00962: val_acc did not improve from 0.56040\n",
            "Epoch 963/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2836 - acc: 0.5564 - val_loss: 1.2806 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00963: val_acc did not improve from 0.56040\n",
            "Epoch 964/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 1.2779 - acc: 0.5479 - val_loss: 1.2794 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00964: val_acc did not improve from 0.56040\n",
            "Epoch 965/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2968 - acc: 0.5489 - val_loss: 1.2789 - val_acc: 0.5531\n",
            "\n",
            "Epoch 00965: val_acc did not improve from 0.56040\n",
            "Epoch 966/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2960 - acc: 0.5449 - val_loss: 1.2788 - val_acc: 0.5517\n",
            "\n",
            "Epoch 00966: val_acc did not improve from 0.56040\n",
            "Epoch 967/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.2846 - acc: 0.5481 - val_loss: 1.2798 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00967: val_acc did not improve from 0.56040\n",
            "Epoch 968/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2792 - acc: 0.5495 - val_loss: 1.2787 - val_acc: 0.5531\n",
            "\n",
            "Epoch 00968: val_acc did not improve from 0.56040\n",
            "Epoch 969/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2839 - acc: 0.5463 - val_loss: 1.2792 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00969: val_acc did not improve from 0.56040\n",
            "Epoch 970/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2880 - acc: 0.5501 - val_loss: 1.2801 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00970: val_acc did not improve from 0.56040\n",
            "Epoch 971/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 1.2997 - acc: 0.5514 - val_loss: 1.2812 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00971: val_acc did not improve from 0.56040\n",
            "Epoch 972/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2966 - acc: 0.5407 - val_loss: 1.2803 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00972: val_acc did not improve from 0.56040\n",
            "Epoch 973/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2718 - acc: 0.5522 - val_loss: 1.2788 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00973: val_acc did not improve from 0.56040\n",
            "Epoch 974/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.2829 - acc: 0.5515 - val_loss: 1.2794 - val_acc: 0.5530\n",
            "\n",
            "Epoch 00974: val_acc did not improve from 0.56040\n",
            "Epoch 975/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2530 - acc: 0.5569 - val_loss: 1.2798 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00975: val_acc did not improve from 0.56040\n",
            "Epoch 976/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3034 - acc: 0.5453 - val_loss: 1.2806 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00976: val_acc did not improve from 0.56040\n",
            "Epoch 977/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2793 - acc: 0.5570 - val_loss: 1.2802 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00977: val_acc did not improve from 0.56040\n",
            "Epoch 978/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 1.2956 - acc: 0.5497 - val_loss: 1.2796 - val_acc: 0.5531\n",
            "\n",
            "Epoch 00978: val_acc did not improve from 0.56040\n",
            "Epoch 979/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.2482 - acc: 0.5662 - val_loss: 1.2796 - val_acc: 0.5517\n",
            "\n",
            "Epoch 00979: val_acc did not improve from 0.56040\n",
            "Epoch 980/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.2871 - acc: 0.5504 - val_loss: 1.2795 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00980: val_acc did not improve from 0.56040\n",
            "Epoch 981/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 1.3032 - acc: 0.5460 - val_loss: 1.2806 - val_acc: 0.5514\n",
            "\n",
            "Epoch 00981: val_acc did not improve from 0.56040\n",
            "Epoch 982/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.2867 - acc: 0.5518 - val_loss: 1.2821 - val_acc: 0.5528\n",
            "\n",
            "Epoch 00982: val_acc did not improve from 0.56040\n",
            "Epoch 983/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.2904 - acc: 0.5525 - val_loss: 1.2794 - val_acc: 0.5525\n",
            "\n",
            "Epoch 00983: val_acc did not improve from 0.56040\n",
            "Epoch 984/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.2765 - acc: 0.5536 - val_loss: 1.2794 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00984: val_acc did not improve from 0.56040\n",
            "Epoch 985/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 1.2622 - acc: 0.5500 - val_loss: 1.2797 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00985: val_acc did not improve from 0.56040\n",
            "Epoch 986/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.2742 - acc: 0.5487 - val_loss: 1.2786 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00986: val_acc did not improve from 0.56040\n",
            "Epoch 987/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.2892 - acc: 0.5514 - val_loss: 1.2813 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00987: val_acc did not improve from 0.56040\n",
            "Epoch 988/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 1.2940 - acc: 0.5490 - val_loss: 1.2796 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00988: val_acc did not improve from 0.56040\n",
            "Epoch 989/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.2871 - acc: 0.5516 - val_loss: 1.2776 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00989: val_acc did not improve from 0.56040\n",
            "Epoch 990/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 1.3038 - acc: 0.5444 - val_loss: 1.2790 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00990: val_acc did not improve from 0.56040\n",
            "Epoch 991/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 1.2802 - acc: 0.5581 - val_loss: 1.2780 - val_acc: 0.5532\n",
            "\n",
            "Epoch 00991: val_acc did not improve from 0.56040\n",
            "Epoch 992/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 12s 119ms/step - loss: 1.2924 - acc: 0.5551 - val_loss: 1.2789 - val_acc: 0.5537\n",
            "\n",
            "Epoch 00992: val_acc did not improve from 0.56040\n",
            "Epoch 993/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.2892 - acc: 0.5529 - val_loss: 1.2773 - val_acc: 0.5525\n",
            "\n",
            "Epoch 00993: val_acc did not improve from 0.56040\n",
            "Epoch 994/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 1.3012 - acc: 0.5453 - val_loss: 1.2782 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00994: val_acc did not improve from 0.56040\n",
            "Epoch 995/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 1.2669 - acc: 0.5596 - val_loss: 1.2780 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00995: val_acc did not improve from 0.56040\n",
            "Epoch 996/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.2948 - acc: 0.5465 - val_loss: 1.2791 - val_acc: 0.5515\n",
            "\n",
            "Epoch 00996: val_acc did not improve from 0.56040\n",
            "Epoch 997/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 1.2742 - acc: 0.5547 - val_loss: 1.2812 - val_acc: 0.5515\n",
            "\n",
            "Epoch 00997: val_acc did not improve from 0.56040\n",
            "Epoch 998/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.2762 - acc: 0.5551 - val_loss: 1.2782 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00998: val_acc did not improve from 0.56040\n",
            "Epoch 999/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 115ms/step - loss: 1.2815 - acc: 0.5577 - val_loss: 1.2787 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00999: val_acc did not improve from 0.56040\n",
            "Epoch 1000/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.2849 - acc: 0.5510 - val_loss: 1.2803 - val_acc: 0.5517\n",
            "\n",
            "Epoch 01000: val_acc did not improve from 0.56040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "ULxHLRqRFnsh",
        "outputId": "5322bd2c-e4de-4562-cef1-50b73428c6d6"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('trainHistoryDict_clip_05', \"rb\"))\n",
        "functions.plot_loss_acc(history, 4, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYTjxBSYDD6A",
        "outputId": "5e8272a5-5570-49cc-fc6f-1c5c5c099b23"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5516999959945679"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IVPweW2FrJM",
        "outputId": "804f3885-b582-48ef-fe23-cd86b18b68ed"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44830000400543213"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgRj4CpUqu7P"
      },
      "source": [
        "#### Model with clipping to 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN70VdR8q2hC",
        "outputId": "98ebc21b-6549-4532-ef02-9f0cfb7251cf"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(\n",
        "    input_shape, conv_layer = functions.ConvDecomposed2D, decomposition_rank=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tJ3MiY5q_OW",
        "outputId": "3cdb79a1-1620-48c4-c64f-6468ce1e3dc7"
      },
      "source": [
        "callbacks = functions.standard_callbacks(model_type) + [functions.Clipping(1)]\n",
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'trainHistoryDict_clip_1', steps_per_epoch=100, epochs=500,\n",
        "                       batch_size=100,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 57s 193ms/step - loss: 3.1949 - acc: 0.1217 - val_loss: 2.6224 - val_acc: 0.1080\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.10800, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 2.2874 - acc: 0.1331 - val_loss: 2.3819 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.10800\n",
            "Epoch 3/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 2.1845 - acc: 0.1830 - val_loss: 2.3803 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.10800\n",
            "Epoch 4/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 2.1460 - acc: 0.1859 - val_loss: 2.4163 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.10800\n",
            "Epoch 5/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 2.0721 - acc: 0.2222 - val_loss: 2.5130 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.10800\n",
            "Epoch 6/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 2.0063 - acc: 0.2469 - val_loss: 2.8666 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.10800\n",
            "Epoch 7/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.9693 - acc: 0.2528 - val_loss: 3.4335 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.10800\n",
            "Epoch 8/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.9631 - acc: 0.2590 - val_loss: 2.7732 - val_acc: 0.1447\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.10800 to 0.14470, saving model to /content/saved_models/cifar10_ResNet32v1_model.008.h5\n",
            "Epoch 9/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.9337 - acc: 0.2755 - val_loss: 2.4250 - val_acc: 0.1570\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.14470 to 0.15700, saving model to /content/saved_models/cifar10_ResNet32v1_model.009.h5\n",
            "Epoch 10/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.9424 - acc: 0.2681 - val_loss: 1.9591 - val_acc: 0.2596\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.15700 to 0.25960, saving model to /content/saved_models/cifar10_ResNet32v1_model.010.h5\n",
            "Epoch 11/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.9165 - acc: 0.2772 - val_loss: 2.1015 - val_acc: 0.2564\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.25960\n",
            "Epoch 12/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.9041 - acc: 0.2842 - val_loss: 1.9363 - val_acc: 0.2720\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.25960 to 0.27200, saving model to /content/saved_models/cifar10_ResNet32v1_model.012.h5\n",
            "Epoch 13/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.9081 - acc: 0.2902 - val_loss: 2.3308 - val_acc: 0.1813\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.27200\n",
            "Epoch 14/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.8973 - acc: 0.3038 - val_loss: 2.0821 - val_acc: 0.2737\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.27200 to 0.27370, saving model to /content/saved_models/cifar10_ResNet32v1_model.014.h5\n",
            "Epoch 15/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.8950 - acc: 0.2937 - val_loss: 1.9470 - val_acc: 0.2694\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.27370\n",
            "Epoch 16/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.8795 - acc: 0.3008 - val_loss: 2.0299 - val_acc: 0.2448\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.27370\n",
            "Epoch 17/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.8518 - acc: 0.3121 - val_loss: 1.8958 - val_acc: 0.2853\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.27370 to 0.28530, saving model to /content/saved_models/cifar10_ResNet32v1_model.017.h5\n",
            "Epoch 18/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.8806 - acc: 0.2927 - val_loss: 2.1990 - val_acc: 0.2343\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.28530\n",
            "Epoch 19/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.8729 - acc: 0.3045 - val_loss: 1.9165 - val_acc: 0.2827\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.28530\n",
            "Epoch 20/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.8499 - acc: 0.3143 - val_loss: 2.1791 - val_acc: 0.2246\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.28530\n",
            "Epoch 21/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.8474 - acc: 0.3094 - val_loss: 1.9008 - val_acc: 0.2968\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.28530 to 0.29680, saving model to /content/saved_models/cifar10_ResNet32v1_model.021.h5\n",
            "Epoch 22/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.8594 - acc: 0.2975 - val_loss: 2.1193 - val_acc: 0.2411\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.29680\n",
            "Epoch 23/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.8212 - acc: 0.3235 - val_loss: 2.2568 - val_acc: 0.2260\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.29680\n",
            "Epoch 24/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.8194 - acc: 0.3251 - val_loss: 1.9423 - val_acc: 0.3014\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.29680 to 0.30140, saving model to /content/saved_models/cifar10_ResNet32v1_model.024.h5\n",
            "Epoch 25/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.8303 - acc: 0.3255 - val_loss: 2.1499 - val_acc: 0.2589\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.30140\n",
            "Epoch 26/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.8032 - acc: 0.3145 - val_loss: 1.8401 - val_acc: 0.3161\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.30140 to 0.31610, saving model to /content/saved_models/cifar10_ResNet32v1_model.026.h5\n",
            "Epoch 27/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.8144 - acc: 0.3246 - val_loss: 1.9717 - val_acc: 0.3021\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.31610\n",
            "Epoch 28/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.7812 - acc: 0.3411 - val_loss: 1.9662 - val_acc: 0.2806\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.31610\n",
            "Epoch 29/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.7690 - acc: 0.3457 - val_loss: 1.8747 - val_acc: 0.3049\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.31610\n",
            "Epoch 30/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.7700 - acc: 0.3445 - val_loss: 2.3284 - val_acc: 0.1970\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.31610\n",
            "Epoch 31/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.7533 - acc: 0.3530 - val_loss: 1.8026 - val_acc: 0.3352\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.31610 to 0.33520, saving model to /content/saved_models/cifar10_ResNet32v1_model.031.h5\n",
            "Epoch 32/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.7394 - acc: 0.3435 - val_loss: 1.9508 - val_acc: 0.3179\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.33520\n",
            "Epoch 33/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.7524 - acc: 0.3615 - val_loss: 1.9671 - val_acc: 0.2784\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.33520\n",
            "Epoch 34/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.7568 - acc: 0.3602 - val_loss: 1.8428 - val_acc: 0.3313\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.33520\n",
            "Epoch 35/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.7262 - acc: 0.3731 - val_loss: 1.8783 - val_acc: 0.3274\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.33520\n",
            "Epoch 36/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.7418 - acc: 0.3570 - val_loss: 1.7339 - val_acc: 0.3593\n",
            "\n",
            "Epoch 00036: val_acc improved from 0.33520 to 0.35930, saving model to /content/saved_models/cifar10_ResNet32v1_model.036.h5\n",
            "Epoch 37/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.7039 - acc: 0.3753 - val_loss: 2.0762 - val_acc: 0.2645\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.35930\n",
            "Epoch 38/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.7233 - acc: 0.3646 - val_loss: 2.0877 - val_acc: 0.2959\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.35930\n",
            "Epoch 39/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.7038 - acc: 0.3828 - val_loss: 2.1595 - val_acc: 0.2697\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.35930\n",
            "Epoch 40/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.7024 - acc: 0.3672 - val_loss: 2.9136 - val_acc: 0.2066\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.35930\n",
            "Epoch 41/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.7270 - acc: 0.3638 - val_loss: 2.0495 - val_acc: 0.3183\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.35930\n",
            "Epoch 42/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.6899 - acc: 0.3800 - val_loss: 1.8603 - val_acc: 0.3163\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.35930\n",
            "Epoch 43/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.6904 - acc: 0.3807 - val_loss: 1.9330 - val_acc: 0.3151\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.35930\n",
            "Epoch 44/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.6987 - acc: 0.3775 - val_loss: 2.5067 - val_acc: 0.2323\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.35930\n",
            "Epoch 45/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 16s 165ms/step - loss: 1.6770 - acc: 0.3741 - val_loss: 1.7824 - val_acc: 0.3246\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.35930\n",
            "Epoch 46/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.6745 - acc: 0.3816 - val_loss: 1.8270 - val_acc: 0.3301\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.35930\n",
            "Epoch 47/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 165ms/step - loss: 1.6531 - acc: 0.3908 - val_loss: 1.7830 - val_acc: 0.3445\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.35930\n",
            "Epoch 48/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.6555 - acc: 0.3996 - val_loss: 1.9192 - val_acc: 0.3151\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.35930\n",
            "Epoch 49/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.6484 - acc: 0.3945 - val_loss: 2.0469 - val_acc: 0.2918\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.35930\n",
            "Epoch 50/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 165ms/step - loss: 1.6221 - acc: 0.4111 - val_loss: 2.0604 - val_acc: 0.2954\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.35930\n",
            "Epoch 51/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 16s 165ms/step - loss: 1.6356 - acc: 0.3966 - val_loss: 1.6496 - val_acc: 0.3975\n",
            "\n",
            "Epoch 00051: val_acc improved from 0.35930 to 0.39750, saving model to /content/saved_models/cifar10_ResNet32v1_model.051.h5\n",
            "Epoch 52/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.6363 - acc: 0.4000 - val_loss: 1.6962 - val_acc: 0.3733\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.39750\n",
            "Epoch 53/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.6473 - acc: 0.3976 - val_loss: 2.9981 - val_acc: 0.1983\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.39750\n",
            "Epoch 54/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.6594 - acc: 0.3942 - val_loss: 1.6783 - val_acc: 0.3823\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.39750\n",
            "Epoch 55/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.6163 - acc: 0.4140 - val_loss: 1.6792 - val_acc: 0.3768\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.39750\n",
            "Epoch 56/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.6257 - acc: 0.4041 - val_loss: 1.9262 - val_acc: 0.3206\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.39750\n",
            "Epoch 57/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.6221 - acc: 0.4044 - val_loss: 1.6729 - val_acc: 0.3688\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.39750\n",
            "Epoch 58/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.6068 - acc: 0.4098 - val_loss: 1.7752 - val_acc: 0.3663\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.39750\n",
            "Epoch 59/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.5984 - acc: 0.4120 - val_loss: 2.0536 - val_acc: 0.2883\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.39750\n",
            "Epoch 60/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.6185 - acc: 0.4066 - val_loss: 1.7995 - val_acc: 0.3294\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.39750\n",
            "Epoch 61/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.5952 - acc: 0.4123 - val_loss: 1.7316 - val_acc: 0.3686\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.39750\n",
            "Epoch 62/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.5944 - acc: 0.4147 - val_loss: 1.7636 - val_acc: 0.3649\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.39750\n",
            "Epoch 63/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 1.6142 - acc: 0.4123 - val_loss: 1.7805 - val_acc: 0.3629\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.39750\n",
            "Epoch 64/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.5861 - acc: 0.4199 - val_loss: 1.6882 - val_acc: 0.3793\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.39750\n",
            "Epoch 65/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.6066 - acc: 0.4060 - val_loss: 2.1434 - val_acc: 0.3034\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.39750\n",
            "Epoch 66/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.5894 - acc: 0.4194 - val_loss: 1.7745 - val_acc: 0.3721\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.39750\n",
            "Epoch 67/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.5741 - acc: 0.4301 - val_loss: 1.8797 - val_acc: 0.3430\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.39750\n",
            "Epoch 68/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.6027 - acc: 0.4164 - val_loss: 1.7140 - val_acc: 0.3764\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.39750\n",
            "Epoch 69/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.5805 - acc: 0.4206 - val_loss: 1.5948 - val_acc: 0.4182\n",
            "\n",
            "Epoch 00069: val_acc improved from 0.39750 to 0.41820, saving model to /content/saved_models/cifar10_ResNet32v1_model.069.h5\n",
            "Epoch 70/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.5989 - acc: 0.4164 - val_loss: 1.9887 - val_acc: 0.3154\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.41820\n",
            "Epoch 71/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 1.5858 - acc: 0.4285 - val_loss: 1.9621 - val_acc: 0.3187\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.41820\n",
            "Epoch 72/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.5663 - acc: 0.4311 - val_loss: 2.1822 - val_acc: 0.2854\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.41820\n",
            "Epoch 73/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 1.5722 - acc: 0.4249 - val_loss: 1.7976 - val_acc: 0.3501\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.41820\n",
            "Epoch 74/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.5481 - acc: 0.4350 - val_loss: 2.1848 - val_acc: 0.2761\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.41820\n",
            "Epoch 75/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.5938 - acc: 0.4243 - val_loss: 1.6657 - val_acc: 0.3814\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.41820\n",
            "Epoch 76/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.5831 - acc: 0.4336 - val_loss: 1.7180 - val_acc: 0.3759\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.41820\n",
            "Epoch 77/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.5483 - acc: 0.4357 - val_loss: 1.7735 - val_acc: 0.3484\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.41820\n",
            "Epoch 78/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.5514 - acc: 0.4242 - val_loss: 1.7139 - val_acc: 0.3958\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.41820\n",
            "Epoch 79/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.5558 - acc: 0.4393 - val_loss: 1.7055 - val_acc: 0.3845\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.41820\n",
            "Epoch 80/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.5527 - acc: 0.4353 - val_loss: 1.6360 - val_acc: 0.4133\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.41820\n",
            "Epoch 81/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.5476 - acc: 0.4328 - val_loss: 1.6265 - val_acc: 0.4115\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.41820\n",
            "Epoch 82/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.5485 - acc: 0.4418 - val_loss: 1.7753 - val_acc: 0.3584\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.41820\n",
            "Epoch 83/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.5522 - acc: 0.4367 - val_loss: 1.7876 - val_acc: 0.3488\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.41820\n",
            "Epoch 84/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.5567 - acc: 0.4281 - val_loss: 1.6517 - val_acc: 0.3844\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.41820\n",
            "Epoch 85/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.5561 - acc: 0.4382 - val_loss: 1.6257 - val_acc: 0.3988\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.41820\n",
            "Epoch 86/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.5714 - acc: 0.4317 - val_loss: 1.9287 - val_acc: 0.3271\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.41820\n",
            "Epoch 87/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.5589 - acc: 0.4327 - val_loss: 1.7844 - val_acc: 0.3436\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.41820\n",
            "Epoch 88/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.5375 - acc: 0.4405 - val_loss: 1.8129 - val_acc: 0.3485\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.41820\n",
            "Epoch 89/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.5502 - acc: 0.4308 - val_loss: 2.0212 - val_acc: 0.3455\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.41820\n",
            "Epoch 90/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.5451 - acc: 0.4440 - val_loss: 1.8334 - val_acc: 0.3463\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.41820\n",
            "Epoch 91/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.5368 - acc: 0.4366 - val_loss: 2.6365 - val_acc: 0.2671\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.41820\n",
            "Epoch 92/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.5434 - acc: 0.4414 - val_loss: 2.6427 - val_acc: 0.2355\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.41820\n",
            "Epoch 93/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 1.5460 - acc: 0.4377 - val_loss: 1.6358 - val_acc: 0.4000\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.41820\n",
            "Epoch 94/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.5474 - acc: 0.4331 - val_loss: 1.7236 - val_acc: 0.3927\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.41820\n",
            "Epoch 95/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.5429 - acc: 0.4418 - val_loss: 1.7874 - val_acc: 0.3632\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.41820\n",
            "Epoch 96/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5480 - acc: 0.4320 - val_loss: 2.1988 - val_acc: 0.3121\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.41820\n",
            "Epoch 97/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5366 - acc: 0.4378 - val_loss: 2.1460 - val_acc: 0.3026\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.41820\n",
            "Epoch 98/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5482 - acc: 0.4441 - val_loss: 1.5196 - val_acc: 0.4495\n",
            "\n",
            "Epoch 00098: val_acc improved from 0.41820 to 0.44950, saving model to /content/saved_models/cifar10_ResNet32v1_model.098.h5\n",
            "Epoch 99/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5401 - acc: 0.4319 - val_loss: 1.8008 - val_acc: 0.3668\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.44950\n",
            "Epoch 100/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5203 - acc: 0.4474 - val_loss: 1.7295 - val_acc: 0.3824\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.44950\n",
            "Epoch 101/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5347 - acc: 0.4502 - val_loss: 2.0059 - val_acc: 0.3384\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.44950\n",
            "Epoch 102/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5366 - acc: 0.4379 - val_loss: 2.9016 - val_acc: 0.2514\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.44950\n",
            "Epoch 103/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5265 - acc: 0.4405 - val_loss: 2.2950 - val_acc: 0.2863\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.44950\n",
            "Epoch 104/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5404 - acc: 0.4420 - val_loss: 1.6175 - val_acc: 0.4159\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.44950\n",
            "Epoch 105/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5120 - acc: 0.4555 - val_loss: 1.9424 - val_acc: 0.3179\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.44950\n",
            "Epoch 106/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5266 - acc: 0.4384 - val_loss: 1.6528 - val_acc: 0.4047\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.44950\n",
            "Epoch 107/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5479 - acc: 0.4460 - val_loss: 3.0455 - val_acc: 0.2152\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.44950\n",
            "Epoch 108/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5526 - acc: 0.4402 - val_loss: 1.5747 - val_acc: 0.4257\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.44950\n",
            "Epoch 109/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.5046 - acc: 0.4642 - val_loss: 1.7499 - val_acc: 0.3976\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.44950\n",
            "Epoch 110/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5272 - acc: 0.4487 - val_loss: 1.6449 - val_acc: 0.4056\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.44950\n",
            "Epoch 111/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5412 - acc: 0.4499 - val_loss: 1.6116 - val_acc: 0.4298\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.44950\n",
            "Epoch 112/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5164 - acc: 0.4480 - val_loss: 1.5404 - val_acc: 0.4540\n",
            "\n",
            "Epoch 00112: val_acc improved from 0.44950 to 0.45400, saving model to /content/saved_models/cifar10_ResNet32v1_model.112.h5\n",
            "Epoch 113/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 165ms/step - loss: 1.5120 - acc: 0.4449 - val_loss: 1.5595 - val_acc: 0.4430\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.45400\n",
            "Epoch 114/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5333 - acc: 0.4426 - val_loss: 1.6264 - val_acc: 0.4053\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.45400\n",
            "Epoch 115/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5078 - acc: 0.4491 - val_loss: 2.0959 - val_acc: 0.3285\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.45400\n",
            "Epoch 116/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5100 - acc: 0.4509 - val_loss: 1.5141 - val_acc: 0.4455\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.45400\n",
            "Epoch 117/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5312 - acc: 0.4488 - val_loss: 1.6702 - val_acc: 0.3974\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.45400\n",
            "Epoch 118/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5005 - acc: 0.4607 - val_loss: 1.7610 - val_acc: 0.3659\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.45400\n",
            "Epoch 119/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5113 - acc: 0.4470 - val_loss: 1.7756 - val_acc: 0.3796\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.45400\n",
            "Epoch 120/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5111 - acc: 0.4530 - val_loss: 1.6863 - val_acc: 0.4080\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.45400\n",
            "Epoch 121/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5068 - acc: 0.4574 - val_loss: 1.8725 - val_acc: 0.3313\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.45400\n",
            "Epoch 122/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5255 - acc: 0.4475 - val_loss: 1.6766 - val_acc: 0.4073\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.45400\n",
            "Epoch 123/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5067 - acc: 0.4448 - val_loss: 1.6045 - val_acc: 0.4204\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.45400\n",
            "Epoch 124/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5011 - acc: 0.4570 - val_loss: 1.6125 - val_acc: 0.4225\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.45400\n",
            "Epoch 125/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5120 - acc: 0.4568 - val_loss: 2.1845 - val_acc: 0.3075\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.45400\n",
            "Epoch 126/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 165ms/step - loss: 1.5114 - acc: 0.4475 - val_loss: 1.6878 - val_acc: 0.4003\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.45400\n",
            "Epoch 127/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4994 - acc: 0.4638 - val_loss: 1.8295 - val_acc: 0.3776\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.45400\n",
            "Epoch 128/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4968 - acc: 0.4592 - val_loss: 1.6050 - val_acc: 0.4227\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.45400\n",
            "Epoch 129/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4967 - acc: 0.4551 - val_loss: 1.6195 - val_acc: 0.4143\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.45400\n",
            "Epoch 130/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5260 - acc: 0.4509 - val_loss: 1.5594 - val_acc: 0.4293\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.45400\n",
            "Epoch 131/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4945 - acc: 0.4608 - val_loss: 1.6133 - val_acc: 0.4086\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.45400\n",
            "Epoch 132/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5151 - acc: 0.4511 - val_loss: 1.6545 - val_acc: 0.4090\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.45400\n",
            "Epoch 133/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4965 - acc: 0.4586 - val_loss: 1.8263 - val_acc: 0.3666\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.45400\n",
            "Epoch 134/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5063 - acc: 0.4469 - val_loss: 1.9406 - val_acc: 0.3730\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.45400\n",
            "Epoch 135/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4960 - acc: 0.4638 - val_loss: 1.6196 - val_acc: 0.4231\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.45400\n",
            "Epoch 136/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4885 - acc: 0.4679 - val_loss: 2.1501 - val_acc: 0.3432\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.45400\n",
            "Epoch 137/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5051 - acc: 0.4531 - val_loss: 1.6217 - val_acc: 0.4129\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.45400\n",
            "Epoch 138/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4915 - acc: 0.4693 - val_loss: 1.5491 - val_acc: 0.4412\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.45400\n",
            "Epoch 139/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4933 - acc: 0.4676 - val_loss: 1.5689 - val_acc: 0.4437\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.45400\n",
            "Epoch 140/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4994 - acc: 0.4612 - val_loss: 2.3028 - val_acc: 0.2893\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.45400\n",
            "Epoch 141/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4806 - acc: 0.4624 - val_loss: 1.5866 - val_acc: 0.4355\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.45400\n",
            "Epoch 142/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5109 - acc: 0.4417 - val_loss: 1.9367 - val_acc: 0.3574\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.45400\n",
            "Epoch 143/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4859 - acc: 0.4691 - val_loss: 3.3716 - val_acc: 0.2424\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.45400\n",
            "Epoch 144/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4585 - acc: 0.4727 - val_loss: 1.7074 - val_acc: 0.4071\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.45400\n",
            "Epoch 145/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4835 - acc: 0.4643 - val_loss: 1.7545 - val_acc: 0.4002\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.45400\n",
            "Epoch 146/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4702 - acc: 0.4723 - val_loss: 1.5438 - val_acc: 0.4472\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.45400\n",
            "Epoch 147/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5017 - acc: 0.4564 - val_loss: 2.3051 - val_acc: 0.3052\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.45400\n",
            "Epoch 148/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5095 - acc: 0.4572 - val_loss: 1.7075 - val_acc: 0.4045\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.45400\n",
            "Epoch 149/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4840 - acc: 0.4617 - val_loss: 4.2134 - val_acc: 0.2283\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.45400\n",
            "Epoch 150/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4967 - acc: 0.4513 - val_loss: 1.8350 - val_acc: 0.3977\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.45400\n",
            "Epoch 151/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5021 - acc: 0.4560 - val_loss: 1.9055 - val_acc: 0.3600\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.45400\n",
            "Epoch 152/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4993 - acc: 0.4623 - val_loss: 1.5581 - val_acc: 0.4436\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.45400\n",
            "Epoch 153/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4964 - acc: 0.4510 - val_loss: 1.5525 - val_acc: 0.4482\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.45400\n",
            "Epoch 154/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4821 - acc: 0.4603 - val_loss: 1.6240 - val_acc: 0.4199\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.45400\n",
            "Epoch 155/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5133 - acc: 0.4521 - val_loss: 1.6511 - val_acc: 0.4063\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.45400\n",
            "Epoch 156/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4893 - acc: 0.4546 - val_loss: 1.7399 - val_acc: 0.3773\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.45400\n",
            "Epoch 157/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4887 - acc: 0.4625 - val_loss: 1.8563 - val_acc: 0.3766\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.45400\n",
            "Epoch 158/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.5173 - acc: 0.4507 - val_loss: 2.0223 - val_acc: 0.3330\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.45400\n",
            "Epoch 159/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 165ms/step - loss: 1.4863 - acc: 0.4715 - val_loss: 1.9720 - val_acc: 0.3565\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.45400\n",
            "Epoch 160/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5127 - acc: 0.4564 - val_loss: 1.7199 - val_acc: 0.3932\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.45400\n",
            "Epoch 161/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5015 - acc: 0.4593 - val_loss: 1.8837 - val_acc: 0.3643\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.45400\n",
            "Epoch 162/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4644 - acc: 0.4708 - val_loss: 1.5536 - val_acc: 0.4343\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.45400\n",
            "Epoch 163/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4779 - acc: 0.4646 - val_loss: 1.9408 - val_acc: 0.3683\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.45400\n",
            "Epoch 164/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.5045 - acc: 0.4521 - val_loss: 1.8504 - val_acc: 0.3622\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.45400\n",
            "Epoch 165/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4748 - acc: 0.4714 - val_loss: 2.3576 - val_acc: 0.3165\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.45400\n",
            "Epoch 166/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4936 - acc: 0.4637 - val_loss: 1.8437 - val_acc: 0.3642\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.45400\n",
            "Epoch 167/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4904 - acc: 0.4641 - val_loss: 1.5799 - val_acc: 0.4339\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.45400\n",
            "Epoch 168/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4757 - acc: 0.4790 - val_loss: 1.5048 - val_acc: 0.4556\n",
            "\n",
            "Epoch 00168: val_acc improved from 0.45400 to 0.45560, saving model to /content/saved_models/cifar10_ResNet32v1_model.168.h5\n",
            "Epoch 169/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4838 - acc: 0.4567 - val_loss: 1.9769 - val_acc: 0.3494\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.45560\n",
            "Epoch 170/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4514 - acc: 0.4817 - val_loss: 1.6866 - val_acc: 0.3929\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.45560\n",
            "Epoch 171/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4666 - acc: 0.4775 - val_loss: 1.5355 - val_acc: 0.4371\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.45560\n",
            "Epoch 172/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4731 - acc: 0.4774 - val_loss: 2.0032 - val_acc: 0.3623\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.45560\n",
            "Epoch 173/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4757 - acc: 0.4727 - val_loss: 1.8381 - val_acc: 0.3501\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.45560\n",
            "Epoch 174/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4660 - acc: 0.4670 - val_loss: 1.4979 - val_acc: 0.4618\n",
            "\n",
            "Epoch 00174: val_acc improved from 0.45560 to 0.46180, saving model to /content/saved_models/cifar10_ResNet32v1_model.174.h5\n",
            "Epoch 175/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4638 - acc: 0.4746 - val_loss: 1.6365 - val_acc: 0.4075\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.46180\n",
            "Epoch 176/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4802 - acc: 0.4721 - val_loss: 1.7326 - val_acc: 0.3907\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.46180\n",
            "Epoch 177/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4695 - acc: 0.4768 - val_loss: 1.7550 - val_acc: 0.3991\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.46180\n",
            "Epoch 178/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4809 - acc: 0.4702 - val_loss: 1.6047 - val_acc: 0.4115\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.46180\n",
            "Epoch 179/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4765 - acc: 0.4692 - val_loss: 1.8550 - val_acc: 0.3471\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.46180\n",
            "Epoch 180/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4805 - acc: 0.4646 - val_loss: 1.5042 - val_acc: 0.4612\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.46180\n",
            "Epoch 181/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4771 - acc: 0.4735 - val_loss: 1.6204 - val_acc: 0.4137\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.46180\n",
            "Epoch 182/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4831 - acc: 0.4584 - val_loss: 1.4949 - val_acc: 0.4592\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.46180\n",
            "Epoch 183/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4413 - acc: 0.4837 - val_loss: 1.7683 - val_acc: 0.3855\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.46180\n",
            "Epoch 184/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4822 - acc: 0.4627 - val_loss: 1.6763 - val_acc: 0.3966\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.46180\n",
            "Epoch 185/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4772 - acc: 0.4620 - val_loss: 1.5925 - val_acc: 0.4329\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.46180\n",
            "Epoch 186/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4611 - acc: 0.4799 - val_loss: 1.7208 - val_acc: 0.3952\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.46180\n",
            "Epoch 187/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4552 - acc: 0.4888 - val_loss: 1.8125 - val_acc: 0.3515\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.46180\n",
            "Epoch 188/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4541 - acc: 0.4717 - val_loss: 1.4935 - val_acc: 0.4690\n",
            "\n",
            "Epoch 00188: val_acc improved from 0.46180 to 0.46900, saving model to /content/saved_models/cifar10_ResNet32v1_model.188.h5\n",
            "Epoch 189/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4620 - acc: 0.4798 - val_loss: 2.4484 - val_acc: 0.2869\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.46900\n",
            "Epoch 190/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4722 - acc: 0.4682 - val_loss: 2.8347 - val_acc: 0.2624\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.46900\n",
            "Epoch 191/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4624 - acc: 0.4723 - val_loss: 1.5674 - val_acc: 0.4283\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.46900\n",
            "Epoch 192/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4669 - acc: 0.4636 - val_loss: 1.9484 - val_acc: 0.3651\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.46900\n",
            "Epoch 193/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4556 - acc: 0.4809 - val_loss: 1.6855 - val_acc: 0.4016\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.46900\n",
            "Epoch 194/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4666 - acc: 0.4708 - val_loss: 1.5824 - val_acc: 0.4305\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.46900\n",
            "Epoch 195/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4496 - acc: 0.4782 - val_loss: 1.6693 - val_acc: 0.4223\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.46900\n",
            "Epoch 196/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4553 - acc: 0.4786 - val_loss: 2.1590 - val_acc: 0.2579\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.46900\n",
            "Epoch 197/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4857 - acc: 0.4658 - val_loss: 2.0296 - val_acc: 0.3531\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.46900\n",
            "Epoch 198/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4809 - acc: 0.4610 - val_loss: 2.9606 - val_acc: 0.2644\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.46900\n",
            "Epoch 199/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4572 - acc: 0.4861 - val_loss: 1.6163 - val_acc: 0.4374\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.46900\n",
            "Epoch 200/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4400 - acc: 0.4793 - val_loss: 1.5155 - val_acc: 0.4543\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.46900\n",
            "Epoch 201/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4442 - acc: 0.4806 - val_loss: 2.0471 - val_acc: 0.3503\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.46900\n",
            "Epoch 202/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4405 - acc: 0.4878 - val_loss: 1.5968 - val_acc: 0.4205\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.46900\n",
            "Epoch 203/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.4512 - acc: 0.4783 - val_loss: 1.5914 - val_acc: 0.4320\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.46900\n",
            "Epoch 204/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4482 - acc: 0.4777 - val_loss: 1.5308 - val_acc: 0.4551\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.46900\n",
            "Epoch 205/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4439 - acc: 0.4859 - val_loss: 1.6058 - val_acc: 0.4314\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.46900\n",
            "Epoch 206/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4694 - acc: 0.4684 - val_loss: 1.6018 - val_acc: 0.4253\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.46900\n",
            "Epoch 207/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4539 - acc: 0.4795 - val_loss: 1.6233 - val_acc: 0.4207\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.46900\n",
            "Epoch 208/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4655 - acc: 0.4762 - val_loss: 1.8735 - val_acc: 0.3757\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.46900\n",
            "Epoch 209/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4512 - acc: 0.4836 - val_loss: 1.9027 - val_acc: 0.3622\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.46900\n",
            "Epoch 210/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4548 - acc: 0.4727 - val_loss: 1.4954 - val_acc: 0.4612\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.46900\n",
            "Epoch 211/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4528 - acc: 0.4828 - val_loss: 1.5335 - val_acc: 0.4481\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.46900\n",
            "Epoch 212/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4379 - acc: 0.4834 - val_loss: 1.5158 - val_acc: 0.4541\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.46900\n",
            "Epoch 213/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4537 - acc: 0.4710 - val_loss: 1.6157 - val_acc: 0.4195\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.46900\n",
            "Epoch 214/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4520 - acc: 0.4752 - val_loss: 2.2249 - val_acc: 0.3321\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.46900\n",
            "Epoch 215/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4670 - acc: 0.4729 - val_loss: 1.4576 - val_acc: 0.4722\n",
            "\n",
            "Epoch 00215: val_acc improved from 0.46900 to 0.47220, saving model to /content/saved_models/cifar10_ResNet32v1_model.215.h5\n",
            "Epoch 216/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4366 - acc: 0.4826 - val_loss: 2.4791 - val_acc: 0.2980\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.47220\n",
            "Epoch 217/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4409 - acc: 0.4872 - val_loss: 1.9238 - val_acc: 0.3650\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.47220\n",
            "Epoch 218/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4351 - acc: 0.4826 - val_loss: 1.9934 - val_acc: 0.3573\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.47220\n",
            "Epoch 219/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4492 - acc: 0.4828 - val_loss: 2.6258 - val_acc: 0.3107\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.47220\n",
            "Epoch 220/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4720 - acc: 0.4727 - val_loss: 1.5758 - val_acc: 0.4420\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.47220\n",
            "Epoch 221/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4571 - acc: 0.4847 - val_loss: 1.5555 - val_acc: 0.4449\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.47220\n",
            "Epoch 222/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4500 - acc: 0.4809 - val_loss: 1.5676 - val_acc: 0.4406\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.47220\n",
            "Epoch 223/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4534 - acc: 0.4862 - val_loss: 1.4581 - val_acc: 0.4785\n",
            "\n",
            "Epoch 00223: val_acc improved from 0.47220 to 0.47850, saving model to /content/saved_models/cifar10_ResNet32v1_model.223.h5\n",
            "Epoch 224/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4403 - acc: 0.4761 - val_loss: 1.8681 - val_acc: 0.3785\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.47850\n",
            "Epoch 225/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4416 - acc: 0.4773 - val_loss: 1.4874 - val_acc: 0.4621\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.47850\n",
            "Epoch 226/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4267 - acc: 0.4894 - val_loss: 1.5376 - val_acc: 0.4400\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.47850\n",
            "Epoch 227/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4341 - acc: 0.4818 - val_loss: 2.3189 - val_acc: 0.3211\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.47850\n",
            "Epoch 228/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4327 - acc: 0.4777 - val_loss: 1.6786 - val_acc: 0.4233\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.47850\n",
            "Epoch 229/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4407 - acc: 0.4847 - val_loss: 1.5545 - val_acc: 0.4344\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.47850\n",
            "Epoch 230/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4131 - acc: 0.4927 - val_loss: 1.9994 - val_acc: 0.3699\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.47850\n",
            "Epoch 231/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4428 - acc: 0.4822 - val_loss: 1.6862 - val_acc: 0.4185\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.47850\n",
            "Epoch 232/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4503 - acc: 0.4827 - val_loss: 1.7436 - val_acc: 0.3974\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.47850\n",
            "Epoch 233/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4587 - acc: 0.4771 - val_loss: 1.8862 - val_acc: 0.3951\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.47850\n",
            "Epoch 234/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4452 - acc: 0.4867 - val_loss: 1.7763 - val_acc: 0.3869\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.47850\n",
            "Epoch 235/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4568 - acc: 0.4721 - val_loss: 1.4919 - val_acc: 0.4563\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.47850\n",
            "Epoch 236/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4258 - acc: 0.4868 - val_loss: 1.8991 - val_acc: 0.3764\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.47850\n",
            "Epoch 237/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4583 - acc: 0.4813 - val_loss: 1.8258 - val_acc: 0.3864\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.47850\n",
            "Epoch 238/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4393 - acc: 0.4946 - val_loss: 1.6758 - val_acc: 0.4299\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.47850\n",
            "Epoch 239/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4338 - acc: 0.4877 - val_loss: 1.8842 - val_acc: 0.3917\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.47850\n",
            "Epoch 240/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4592 - acc: 0.4762 - val_loss: 2.0792 - val_acc: 0.3519\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.47850\n",
            "Epoch 241/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4492 - acc: 0.4781 - val_loss: 1.6701 - val_acc: 0.4272\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.47850\n",
            "Epoch 242/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4538 - acc: 0.4761 - val_loss: 1.4418 - val_acc: 0.4845\n",
            "\n",
            "Epoch 00242: val_acc improved from 0.47850 to 0.48450, saving model to /content/saved_models/cifar10_ResNet32v1_model.242.h5\n",
            "Epoch 243/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4237 - acc: 0.4863 - val_loss: 1.5329 - val_acc: 0.4574\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.48450\n",
            "Epoch 244/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4387 - acc: 0.4806 - val_loss: 2.8155 - val_acc: 0.2955\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.48450\n",
            "Epoch 245/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4194 - acc: 0.4891 - val_loss: 1.6469 - val_acc: 0.4340\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.48450\n",
            "Epoch 246/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4509 - acc: 0.4893 - val_loss: 1.9080 - val_acc: 0.3867\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.48450\n",
            "Epoch 247/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4463 - acc: 0.4759 - val_loss: 1.6206 - val_acc: 0.4161\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.48450\n",
            "Epoch 248/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4436 - acc: 0.4785 - val_loss: 1.6234 - val_acc: 0.4150\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.48450\n",
            "Epoch 249/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4484 - acc: 0.4759 - val_loss: 2.4546 - val_acc: 0.2918\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.48450\n",
            "Epoch 250/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4521 - acc: 0.4653 - val_loss: 1.7610 - val_acc: 0.3889\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.48450\n",
            "Epoch 251/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4359 - acc: 0.4780 - val_loss: 1.7710 - val_acc: 0.3984\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.48450\n",
            "Epoch 252/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4324 - acc: 0.4867 - val_loss: 1.6204 - val_acc: 0.4265\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.48450\n",
            "Epoch 253/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4115 - acc: 0.4976 - val_loss: 1.7596 - val_acc: 0.3530\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.48450\n",
            "Epoch 254/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4200 - acc: 0.4922 - val_loss: 1.6709 - val_acc: 0.4044\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.48450\n",
            "Epoch 255/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4299 - acc: 0.4873 - val_loss: 1.4979 - val_acc: 0.4672\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.48450\n",
            "Epoch 256/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4329 - acc: 0.4843 - val_loss: 1.9483 - val_acc: 0.3703\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.48450\n",
            "Epoch 257/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4276 - acc: 0.4891 - val_loss: 1.6480 - val_acc: 0.4350\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.48450\n",
            "Epoch 258/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4492 - acc: 0.4864 - val_loss: 1.7522 - val_acc: 0.3924\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.48450\n",
            "Epoch 259/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4337 - acc: 0.4964 - val_loss: 1.8087 - val_acc: 0.3805\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.48450\n",
            "Epoch 260/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4392 - acc: 0.4907 - val_loss: 1.7064 - val_acc: 0.4172\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.48450\n",
            "Epoch 261/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4419 - acc: 0.4872 - val_loss: 1.6072 - val_acc: 0.4218\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.48450\n",
            "Epoch 262/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4402 - acc: 0.4833 - val_loss: 2.3675 - val_acc: 0.3163\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.48450\n",
            "Epoch 263/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4282 - acc: 0.4868 - val_loss: 1.5850 - val_acc: 0.4212\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.48450\n",
            "Epoch 264/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4426 - acc: 0.4788 - val_loss: 1.8394 - val_acc: 0.3451\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.48450\n",
            "Epoch 265/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4242 - acc: 0.4871 - val_loss: 1.6488 - val_acc: 0.4122\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.48450\n",
            "Epoch 266/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4300 - acc: 0.4896 - val_loss: 1.5266 - val_acc: 0.4497\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.48450\n",
            "Epoch 267/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4377 - acc: 0.4810 - val_loss: 1.6703 - val_acc: 0.4228\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.48450\n",
            "Epoch 268/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4193 - acc: 0.4900 - val_loss: 1.5296 - val_acc: 0.4598\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.48450\n",
            "Epoch 269/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4466 - acc: 0.4803 - val_loss: 2.2882 - val_acc: 0.3310\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.48450\n",
            "Epoch 270/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4349 - acc: 0.4856 - val_loss: 1.9457 - val_acc: 0.3808\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.48450\n",
            "Epoch 271/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.4389 - acc: 0.4864 - val_loss: 1.9255 - val_acc: 0.3806\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.48450\n",
            "Epoch 272/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.4232 - acc: 0.4893 - val_loss: 2.8572 - val_acc: 0.2755\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.48450\n",
            "Epoch 273/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4076 - acc: 0.4996 - val_loss: 1.9423 - val_acc: 0.3632\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.48450\n",
            "Epoch 274/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4178 - acc: 0.4854 - val_loss: 1.8714 - val_acc: 0.3957\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.48450\n",
            "Epoch 275/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4084 - acc: 0.5003 - val_loss: 1.7662 - val_acc: 0.3659\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.48450\n",
            "Epoch 276/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4370 - acc: 0.4795 - val_loss: 1.9423 - val_acc: 0.3776\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.48450\n",
            "Epoch 277/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4242 - acc: 0.4923 - val_loss: 1.6815 - val_acc: 0.4235\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.48450\n",
            "Epoch 278/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4053 - acc: 0.4928 - val_loss: 1.6410 - val_acc: 0.4314\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.48450\n",
            "Epoch 279/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4533 - acc: 0.4748 - val_loss: 1.4941 - val_acc: 0.4633\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.48450\n",
            "Epoch 280/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3945 - acc: 0.5102 - val_loss: 1.7690 - val_acc: 0.3930\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.48450\n",
            "Epoch 281/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4117 - acc: 0.4883 - val_loss: 1.7219 - val_acc: 0.4049\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.48450\n",
            "Epoch 282/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4164 - acc: 0.4909 - val_loss: 1.5549 - val_acc: 0.4397\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.48450\n",
            "Epoch 283/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4245 - acc: 0.4890 - val_loss: 1.5567 - val_acc: 0.4522\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.48450\n",
            "Epoch 284/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.4253 - acc: 0.4867 - val_loss: 1.8049 - val_acc: 0.3784\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.48450\n",
            "Epoch 285/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4108 - acc: 0.4970 - val_loss: 1.6027 - val_acc: 0.4416\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.48450\n",
            "Epoch 286/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4399 - acc: 0.4904 - val_loss: 2.5527 - val_acc: 0.2152\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.48450\n",
            "Epoch 287/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4203 - acc: 0.4964 - val_loss: 1.4899 - val_acc: 0.4644\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.48450\n",
            "Epoch 288/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4276 - acc: 0.4787 - val_loss: 1.5206 - val_acc: 0.4578\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.48450\n",
            "Epoch 289/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4152 - acc: 0.4935 - val_loss: 1.5031 - val_acc: 0.4630\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.48450\n",
            "Epoch 290/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4435 - acc: 0.4765 - val_loss: 1.6459 - val_acc: 0.4416\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.48450\n",
            "Epoch 291/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4364 - acc: 0.4926 - val_loss: 1.8796 - val_acc: 0.3846\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.48450\n",
            "Epoch 292/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4404 - acc: 0.4886 - val_loss: 1.8160 - val_acc: 0.3552\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.48450\n",
            "Epoch 293/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4307 - acc: 0.4902 - val_loss: 1.7364 - val_acc: 0.3980\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.48450\n",
            "Epoch 294/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4228 - acc: 0.4954 - val_loss: 1.8471 - val_acc: 0.3941\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.48450\n",
            "Epoch 295/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4153 - acc: 0.4951 - val_loss: 1.5191 - val_acc: 0.4505\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.48450\n",
            "Epoch 296/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4075 - acc: 0.4931 - val_loss: 2.3811 - val_acc: 0.3137\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.48450\n",
            "Epoch 297/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4043 - acc: 0.4961 - val_loss: 1.5926 - val_acc: 0.4340\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.48450\n",
            "Epoch 298/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3949 - acc: 0.4916 - val_loss: 1.7047 - val_acc: 0.4013\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.48450\n",
            "Epoch 299/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4187 - acc: 0.4980 - val_loss: 1.6780 - val_acc: 0.4331\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.48450\n",
            "Epoch 300/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4146 - acc: 0.4932 - val_loss: 2.3787 - val_acc: 0.2914\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.48450\n",
            "Epoch 301/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.4165 - acc: 0.4883 - val_loss: 2.3733 - val_acc: 0.3196\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.48450\n",
            "Epoch 302/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4200 - acc: 0.4928 - val_loss: 1.8081 - val_acc: 0.4039\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.48450\n",
            "Epoch 303/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.4018 - acc: 0.4992 - val_loss: 1.4994 - val_acc: 0.4742\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.48450\n",
            "Epoch 304/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4278 - acc: 0.4792 - val_loss: 1.5210 - val_acc: 0.4594\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.48450\n",
            "Epoch 305/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4308 - acc: 0.4883 - val_loss: 1.4969 - val_acc: 0.4641\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.48450\n",
            "Epoch 306/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3941 - acc: 0.5026 - val_loss: 1.7111 - val_acc: 0.3852\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.48450\n",
            "Epoch 307/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4228 - acc: 0.4934 - val_loss: 1.5924 - val_acc: 0.4374\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.48450\n",
            "Epoch 308/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4041 - acc: 0.4960 - val_loss: 1.4603 - val_acc: 0.4845\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.48450\n",
            "Epoch 309/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4197 - acc: 0.4995 - val_loss: 1.4789 - val_acc: 0.4743\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.48450\n",
            "Epoch 310/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4156 - acc: 0.4948 - val_loss: 1.8186 - val_acc: 0.4054\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.48450\n",
            "Epoch 311/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4110 - acc: 0.4948 - val_loss: 2.4959 - val_acc: 0.3084\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.48450\n",
            "Epoch 312/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4092 - acc: 0.4945 - val_loss: 1.9273 - val_acc: 0.3816\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.48450\n",
            "Epoch 313/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4082 - acc: 0.4901 - val_loss: 1.8919 - val_acc: 0.3564\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.48450\n",
            "Epoch 314/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3949 - acc: 0.5049 - val_loss: 1.6073 - val_acc: 0.4416\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.48450\n",
            "Epoch 315/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4276 - acc: 0.4866 - val_loss: 1.6199 - val_acc: 0.4116\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.48450\n",
            "Epoch 316/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4153 - acc: 0.4905 - val_loss: 1.6498 - val_acc: 0.4185\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.48450\n",
            "Epoch 317/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3881 - acc: 0.5029 - val_loss: 3.3936 - val_acc: 0.2467\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.48450\n",
            "Epoch 318/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4231 - acc: 0.4893 - val_loss: 1.7213 - val_acc: 0.4278\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.48450\n",
            "Epoch 319/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4132 - acc: 0.4981 - val_loss: 1.5219 - val_acc: 0.4678\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.48450\n",
            "Epoch 320/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4181 - acc: 0.4917 - val_loss: 2.1902 - val_acc: 0.3088\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.48450\n",
            "Epoch 321/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4095 - acc: 0.5007 - val_loss: 2.4441 - val_acc: 0.3214\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.48450\n",
            "Epoch 322/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4298 - acc: 0.4921 - val_loss: 1.4314 - val_acc: 0.4909\n",
            "\n",
            "Epoch 00322: val_acc improved from 0.48450 to 0.49090, saving model to /content/saved_models/cifar10_ResNet32v1_model.322.h5\n",
            "Epoch 323/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4230 - acc: 0.4985 - val_loss: 1.5568 - val_acc: 0.4302\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.49090\n",
            "Epoch 324/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3968 - acc: 0.5043 - val_loss: 2.0413 - val_acc: 0.3465\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.49090\n",
            "Epoch 325/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4350 - acc: 0.4844 - val_loss: 1.4705 - val_acc: 0.4837\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.49090\n",
            "Epoch 326/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4104 - acc: 0.4937 - val_loss: 1.5565 - val_acc: 0.4704\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.49090\n",
            "Epoch 327/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4176 - acc: 0.4969 - val_loss: 1.6671 - val_acc: 0.4201\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.49090\n",
            "Epoch 328/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4114 - acc: 0.5006 - val_loss: 1.5376 - val_acc: 0.4616\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.49090\n",
            "Epoch 329/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.3976 - acc: 0.5057 - val_loss: 1.6409 - val_acc: 0.4477\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.49090\n",
            "Epoch 330/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4095 - acc: 0.4938 - val_loss: 1.6971 - val_acc: 0.4309\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.49090\n",
            "Epoch 331/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.3947 - acc: 0.4962 - val_loss: 1.6642 - val_acc: 0.4329\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.49090\n",
            "Epoch 332/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4161 - acc: 0.5008 - val_loss: 1.7535 - val_acc: 0.3844\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.49090\n",
            "Epoch 333/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4042 - acc: 0.4955 - val_loss: 1.4779 - val_acc: 0.4721\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.49090\n",
            "Epoch 334/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.3884 - acc: 0.5131 - val_loss: 1.5813 - val_acc: 0.4349\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.49090\n",
            "Epoch 335/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4161 - acc: 0.4912 - val_loss: 1.5975 - val_acc: 0.4447\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.49090\n",
            "Epoch 336/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4128 - acc: 0.4988 - val_loss: 1.6454 - val_acc: 0.4364\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.49090\n",
            "Epoch 337/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4239 - acc: 0.4912 - val_loss: 1.6253 - val_acc: 0.4322\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.49090\n",
            "Epoch 338/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3821 - acc: 0.5053 - val_loss: 1.7347 - val_acc: 0.4187\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.49090\n",
            "Epoch 339/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4165 - acc: 0.4928 - val_loss: 1.4859 - val_acc: 0.4711\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.49090\n",
            "Epoch 340/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4116 - acc: 0.4981 - val_loss: 3.1328 - val_acc: 0.2814\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.49090\n",
            "Epoch 341/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3992 - acc: 0.4965 - val_loss: 1.4131 - val_acc: 0.5055\n",
            "\n",
            "Epoch 00341: val_acc improved from 0.49090 to 0.50550, saving model to /content/saved_models/cifar10_ResNet32v1_model.341.h5\n",
            "Epoch 342/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3773 - acc: 0.5109 - val_loss: 2.0164 - val_acc: 0.3739\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.50550\n",
            "Epoch 343/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3988 - acc: 0.5056 - val_loss: 1.9358 - val_acc: 0.3548\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.50550\n",
            "Epoch 344/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4095 - acc: 0.4949 - val_loss: 1.6293 - val_acc: 0.4144\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.50550\n",
            "Epoch 345/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4342 - acc: 0.4885 - val_loss: 1.4863 - val_acc: 0.4711\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.50550\n",
            "Epoch 346/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4145 - acc: 0.4956 - val_loss: 1.8022 - val_acc: 0.4136\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.50550\n",
            "Epoch 347/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3905 - acc: 0.5102 - val_loss: 2.7324 - val_acc: 0.2938\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.50550\n",
            "Epoch 348/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.3933 - acc: 0.5047 - val_loss: 1.6888 - val_acc: 0.4472\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.50550\n",
            "Epoch 349/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4207 - acc: 0.4878 - val_loss: 3.2726 - val_acc: 0.2649\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.50550\n",
            "Epoch 350/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4117 - acc: 0.4961 - val_loss: 1.7685 - val_acc: 0.3948\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.50550\n",
            "Epoch 351/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4035 - acc: 0.4964 - val_loss: 1.6227 - val_acc: 0.4474\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.50550\n",
            "Epoch 352/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4191 - acc: 0.5038 - val_loss: 1.6261 - val_acc: 0.4257\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.50550\n",
            "Epoch 353/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4047 - acc: 0.4947 - val_loss: 1.6870 - val_acc: 0.4362\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.50550\n",
            "Epoch 354/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4241 - acc: 0.4956 - val_loss: 1.6969 - val_acc: 0.4290\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.50550\n",
            "Epoch 355/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4139 - acc: 0.4896 - val_loss: 1.8985 - val_acc: 0.3862\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.50550\n",
            "Epoch 356/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4103 - acc: 0.4929 - val_loss: 2.0938 - val_acc: 0.3862\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.50550\n",
            "Epoch 357/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4046 - acc: 0.4997 - val_loss: 1.5506 - val_acc: 0.4540\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.50550\n",
            "Epoch 358/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.3884 - acc: 0.5064 - val_loss: 1.6671 - val_acc: 0.4142\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.50550\n",
            "Epoch 359/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.3775 - acc: 0.5052 - val_loss: 1.4745 - val_acc: 0.4712\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.50550\n",
            "Epoch 360/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4027 - acc: 0.5017 - val_loss: 1.5281 - val_acc: 0.4481\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.50550\n",
            "Epoch 361/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.3838 - acc: 0.5021 - val_loss: 1.4609 - val_acc: 0.4776\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.50550\n",
            "Epoch 362/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.4134 - acc: 0.4961 - val_loss: 1.7025 - val_acc: 0.4154\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.50550\n",
            "Epoch 363/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.4015 - acc: 0.5016 - val_loss: 1.7255 - val_acc: 0.3899\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.50550\n",
            "Epoch 364/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.3848 - acc: 0.5091 - val_loss: 1.7385 - val_acc: 0.3913\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.50550\n",
            "Epoch 365/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3934 - acc: 0.5021 - val_loss: 1.6052 - val_acc: 0.4254\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.50550\n",
            "Epoch 366/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3842 - acc: 0.4958 - val_loss: 1.4704 - val_acc: 0.4716\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.50550\n",
            "Epoch 367/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4113 - acc: 0.4963 - val_loss: 1.7382 - val_acc: 0.4150\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.50550\n",
            "Epoch 368/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.3738 - acc: 0.5090 - val_loss: 1.9553 - val_acc: 0.3976\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.50550\n",
            "Epoch 369/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3993 - acc: 0.4942 - val_loss: 2.1522 - val_acc: 0.3452\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.50550\n",
            "Epoch 370/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4134 - acc: 0.4923 - val_loss: 1.7634 - val_acc: 0.3816\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.50550\n",
            "Epoch 371/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3823 - acc: 0.5115 - val_loss: 1.5295 - val_acc: 0.4608\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.50550\n",
            "Epoch 372/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4210 - acc: 0.4991 - val_loss: 1.8145 - val_acc: 0.3729\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.50550\n",
            "Epoch 373/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3943 - acc: 0.5133 - val_loss: 1.7582 - val_acc: 0.4029\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.50550\n",
            "Epoch 374/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3630 - acc: 0.5111 - val_loss: 1.4163 - val_acc: 0.4920\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.50550\n",
            "Epoch 375/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4094 - acc: 0.4932 - val_loss: 1.4980 - val_acc: 0.4770\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.50550\n",
            "Epoch 376/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4085 - acc: 0.4973 - val_loss: 1.7557 - val_acc: 0.4293\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.50550\n",
            "Epoch 377/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3898 - acc: 0.5028 - val_loss: 1.4759 - val_acc: 0.4750\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.50550\n",
            "Epoch 378/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.3978 - acc: 0.4964 - val_loss: 1.9211 - val_acc: 0.3981\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.50550\n",
            "Epoch 379/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4159 - acc: 0.4951 - val_loss: 1.6759 - val_acc: 0.4372\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.50550\n",
            "Epoch 380/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4051 - acc: 0.4998 - val_loss: 1.4752 - val_acc: 0.4708\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.50550\n",
            "Epoch 381/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4003 - acc: 0.4977 - val_loss: 2.5085 - val_acc: 0.3300\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.50550\n",
            "Epoch 382/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.4054 - acc: 0.5009 - val_loss: 1.4349 - val_acc: 0.4845\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.50550\n",
            "Epoch 383/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4113 - acc: 0.4912 - val_loss: 1.8564 - val_acc: 0.3395\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.50550\n",
            "Epoch 384/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3987 - acc: 0.5018 - val_loss: 1.8668 - val_acc: 0.4000\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.50550\n",
            "Epoch 385/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3860 - acc: 0.5117 - val_loss: 2.3786 - val_acc: 0.3358\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.50550\n",
            "Epoch 386/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3929 - acc: 0.5006 - val_loss: 1.7591 - val_acc: 0.4147\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.50550\n",
            "Epoch 387/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3852 - acc: 0.5077 - val_loss: 1.9423 - val_acc: 0.3946\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.50550\n",
            "Epoch 388/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4043 - acc: 0.5080 - val_loss: 1.8530 - val_acc: 0.3698\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.50550\n",
            "Epoch 389/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4155 - acc: 0.5012 - val_loss: 2.7967 - val_acc: 0.2757\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.50550\n",
            "Epoch 390/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3754 - acc: 0.5115 - val_loss: 1.6813 - val_acc: 0.4303\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.50550\n",
            "Epoch 391/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3789 - acc: 0.5066 - val_loss: 1.8333 - val_acc: 0.3911\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.50550\n",
            "Epoch 392/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3671 - acc: 0.5127 - val_loss: 1.5459 - val_acc: 0.4560\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.50550\n",
            "Epoch 393/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3812 - acc: 0.5114 - val_loss: 1.6059 - val_acc: 0.4390\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.50550\n",
            "Epoch 394/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3949 - acc: 0.5098 - val_loss: 1.4624 - val_acc: 0.4872\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.50550\n",
            "Epoch 395/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.3950 - acc: 0.4964 - val_loss: 1.7468 - val_acc: 0.4189\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.50550\n",
            "Epoch 396/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4060 - acc: 0.5012 - val_loss: 1.6664 - val_acc: 0.4097\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.50550\n",
            "Epoch 397/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.4044 - acc: 0.5009 - val_loss: 1.8189 - val_acc: 0.3586\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.50550\n",
            "Epoch 398/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3939 - acc: 0.5058 - val_loss: 1.6311 - val_acc: 0.4302\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.50550\n",
            "Epoch 399/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3862 - acc: 0.5047 - val_loss: 1.5049 - val_acc: 0.4725\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.50550\n",
            "Epoch 400/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.4030 - acc: 0.5019 - val_loss: 1.5932 - val_acc: 0.4468\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.50550\n",
            "Epoch 401/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3671 - acc: 0.5146 - val_loss: 1.5414 - val_acc: 0.4505\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.50550\n",
            "Epoch 402/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.4065 - acc: 0.5098 - val_loss: 1.3783 - val_acc: 0.5107\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.50550 to 0.51070, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3747 - acc: 0.5091 - val_loss: 1.3686 - val_acc: 0.5158\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.51070 to 0.51580, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3881 - acc: 0.5070 - val_loss: 1.3891 - val_acc: 0.5067\n",
            "\n",
            "Epoch 00404: val_acc did not improve from 0.51580\n",
            "Epoch 405/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3706 - acc: 0.5227 - val_loss: 1.3414 - val_acc: 0.5239\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.51580 to 0.52390, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3936 - acc: 0.5055 - val_loss: 1.4121 - val_acc: 0.5043\n",
            "\n",
            "Epoch 00406: val_acc did not improve from 0.52390\n",
            "Epoch 407/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3727 - acc: 0.5075 - val_loss: 1.3375 - val_acc: 0.5294\n",
            "\n",
            "Epoch 00407: val_acc improved from 0.52390 to 0.52940, saving model to /content/saved_models/cifar10_ResNet32v1_model.407.h5\n",
            "Epoch 408/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.3661 - acc: 0.5108 - val_loss: 1.3391 - val_acc: 0.5266\n",
            "\n",
            "Epoch 00408: val_acc did not improve from 0.52940\n",
            "Epoch 409/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3916 - acc: 0.5012 - val_loss: 1.3516 - val_acc: 0.5211\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.52940\n",
            "Epoch 410/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3707 - acc: 0.5136 - val_loss: 1.4451 - val_acc: 0.4931\n",
            "\n",
            "Epoch 00410: val_acc did not improve from 0.52940\n",
            "Epoch 411/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3858 - acc: 0.5108 - val_loss: 1.4166 - val_acc: 0.5037\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.52940\n",
            "Epoch 412/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3609 - acc: 0.5165 - val_loss: 1.3408 - val_acc: 0.5286\n",
            "\n",
            "Epoch 00412: val_acc did not improve from 0.52940\n",
            "Epoch 413/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3510 - acc: 0.5125 - val_loss: 1.3660 - val_acc: 0.5185\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.52940\n",
            "Epoch 414/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3634 - acc: 0.5178 - val_loss: 1.3412 - val_acc: 0.5211\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.52940\n",
            "Epoch 415/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3705 - acc: 0.5132 - val_loss: 1.4017 - val_acc: 0.5042\n",
            "\n",
            "Epoch 00415: val_acc did not improve from 0.52940\n",
            "Epoch 416/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3591 - acc: 0.5171 - val_loss: 1.3268 - val_acc: 0.5283\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.52940\n",
            "Epoch 417/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3550 - acc: 0.5157 - val_loss: 1.3818 - val_acc: 0.5130\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.52940\n",
            "Epoch 418/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3794 - acc: 0.5092 - val_loss: 1.3437 - val_acc: 0.5269\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.52940\n",
            "Epoch 419/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3659 - acc: 0.5178 - val_loss: 1.3647 - val_acc: 0.5131\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.52940\n",
            "Epoch 420/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.3655 - acc: 0.5184 - val_loss: 1.3662 - val_acc: 0.5164\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.52940\n",
            "Epoch 421/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.3456 - acc: 0.5175 - val_loss: 1.4105 - val_acc: 0.5014\n",
            "\n",
            "Epoch 00421: val_acc did not improve from 0.52940\n",
            "Epoch 422/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.3502 - acc: 0.5221 - val_loss: 1.3718 - val_acc: 0.5164\n",
            "\n",
            "Epoch 00422: val_acc did not improve from 0.52940\n",
            "Epoch 423/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3326 - acc: 0.5228 - val_loss: 1.3531 - val_acc: 0.5181\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.52940\n",
            "Epoch 424/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3796 - acc: 0.5064 - val_loss: 1.3854 - val_acc: 0.5147\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.52940\n",
            "Epoch 425/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3743 - acc: 0.5084 - val_loss: 1.4880 - val_acc: 0.4834\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.52940\n",
            "Epoch 426/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3551 - acc: 0.5114 - val_loss: 1.3787 - val_acc: 0.5120\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.52940\n",
            "Epoch 427/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3421 - acc: 0.5136 - val_loss: 1.3706 - val_acc: 0.5133\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.52940\n",
            "Epoch 428/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3573 - acc: 0.5195 - val_loss: 1.3215 - val_acc: 0.5307\n",
            "\n",
            "Epoch 00428: val_acc improved from 0.52940 to 0.53070, saving model to /content/saved_models/cifar10_ResNet32v1_model.428.h5\n",
            "Epoch 429/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3626 - acc: 0.5285 - val_loss: 1.3312 - val_acc: 0.5259\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.53070\n",
            "Epoch 430/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3582 - acc: 0.5112 - val_loss: 1.3304 - val_acc: 0.5288\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.53070\n",
            "Epoch 431/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.3492 - acc: 0.5231 - val_loss: 1.4713 - val_acc: 0.4884\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.53070\n",
            "Epoch 432/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.3618 - acc: 0.5163 - val_loss: 1.3638 - val_acc: 0.5178\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.53070\n",
            "Epoch 433/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3619 - acc: 0.5131 - val_loss: 1.4884 - val_acc: 0.4835\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.53070\n",
            "Epoch 434/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3546 - acc: 0.5244 - val_loss: 1.3748 - val_acc: 0.5145\n",
            "\n",
            "Epoch 00434: val_acc did not improve from 0.53070\n",
            "Epoch 435/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3679 - acc: 0.5075 - val_loss: 1.3869 - val_acc: 0.5102\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.53070\n",
            "Epoch 436/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3429 - acc: 0.5159 - val_loss: 1.3415 - val_acc: 0.5242\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.53070\n",
            "Epoch 437/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3727 - acc: 0.5086 - val_loss: 1.3842 - val_acc: 0.5132\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.53070\n",
            "Epoch 438/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3592 - acc: 0.5180 - val_loss: 1.3251 - val_acc: 0.5285\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.53070\n",
            "Epoch 439/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3623 - acc: 0.5144 - val_loss: 1.5243 - val_acc: 0.4725\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.53070\n",
            "Epoch 440/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3521 - acc: 0.5140 - val_loss: 1.3700 - val_acc: 0.5174\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.53070\n",
            "Epoch 441/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3675 - acc: 0.5208 - val_loss: 1.3254 - val_acc: 0.5290\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.53070\n",
            "Epoch 442/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3522 - acc: 0.5211 - val_loss: 1.3600 - val_acc: 0.5173\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.53070\n",
            "Epoch 443/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.3389 - acc: 0.5246 - val_loss: 1.3601 - val_acc: 0.5164\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.53070\n",
            "Epoch 444/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3678 - acc: 0.5121 - val_loss: 1.4040 - val_acc: 0.5014\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.53070\n",
            "Epoch 445/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3642 - acc: 0.5140 - val_loss: 1.3212 - val_acc: 0.5323\n",
            "\n",
            "Epoch 00445: val_acc improved from 0.53070 to 0.53230, saving model to /content/saved_models/cifar10_ResNet32v1_model.445.h5\n",
            "Epoch 446/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3511 - acc: 0.5229 - val_loss: 1.4389 - val_acc: 0.4983\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.53230\n",
            "Epoch 447/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3931 - acc: 0.5110 - val_loss: 1.3616 - val_acc: 0.5147\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.53230\n",
            "Epoch 448/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3464 - acc: 0.5308 - val_loss: 1.3326 - val_acc: 0.5284\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.53230\n",
            "Epoch 449/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.3610 - acc: 0.5161 - val_loss: 1.3394 - val_acc: 0.5232\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.53230\n",
            "Epoch 450/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3698 - acc: 0.5177 - val_loss: 1.3344 - val_acc: 0.5258\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.53230\n",
            "Epoch 451/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3571 - acc: 0.5203 - val_loss: 1.3405 - val_acc: 0.5222\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.53230\n",
            "Epoch 452/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3384 - acc: 0.5363 - val_loss: 1.3243 - val_acc: 0.5289\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.53230\n",
            "Epoch 453/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3675 - acc: 0.5182 - val_loss: 1.3531 - val_acc: 0.5211\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.53230\n",
            "Epoch 454/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3771 - acc: 0.5101 - val_loss: 1.4085 - val_acc: 0.5059\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.53230\n",
            "Epoch 455/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3634 - acc: 0.5115 - val_loss: 1.3377 - val_acc: 0.5247\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.53230\n",
            "Epoch 456/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3595 - acc: 0.5216 - val_loss: 1.3733 - val_acc: 0.5131\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.53230\n",
            "Epoch 457/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3679 - acc: 0.5038 - val_loss: 1.3877 - val_acc: 0.5123\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.53230\n",
            "Epoch 458/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3398 - acc: 0.5256 - val_loss: 1.3859 - val_acc: 0.5098\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.53230\n",
            "Epoch 459/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3746 - acc: 0.5158 - val_loss: 1.4172 - val_acc: 0.5040\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.53230\n",
            "Epoch 460/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3726 - acc: 0.5117 - val_loss: 1.3948 - val_acc: 0.5078\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.53230\n",
            "Epoch 461/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3664 - acc: 0.5200 - val_loss: 1.3769 - val_acc: 0.5131\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.53230\n",
            "Epoch 462/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.3639 - acc: 0.5148 - val_loss: 1.3624 - val_acc: 0.5152\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.53230\n",
            "Epoch 463/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.3613 - acc: 0.5153 - val_loss: 1.3732 - val_acc: 0.5132\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.53230\n",
            "Epoch 464/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3602 - acc: 0.5185 - val_loss: 1.3302 - val_acc: 0.5305\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.53230\n",
            "Epoch 465/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3669 - acc: 0.5176 - val_loss: 1.3585 - val_acc: 0.5185\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.53230\n",
            "Epoch 466/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3561 - acc: 0.5133 - val_loss: 1.5115 - val_acc: 0.4761\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.53230\n",
            "Epoch 467/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3688 - acc: 0.5205 - val_loss: 1.3398 - val_acc: 0.5253\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.53230\n",
            "Epoch 468/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3730 - acc: 0.5117 - val_loss: 1.3255 - val_acc: 0.5286\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.53230\n",
            "Epoch 469/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3406 - acc: 0.5241 - val_loss: 1.3320 - val_acc: 0.5285\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.53230\n",
            "Epoch 470/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3585 - acc: 0.5224 - val_loss: 1.3589 - val_acc: 0.5196\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.53230\n",
            "Epoch 471/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3778 - acc: 0.5213 - val_loss: 1.3367 - val_acc: 0.5261\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.53230\n",
            "Epoch 472/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3544 - acc: 0.5244 - val_loss: 1.3405 - val_acc: 0.5246\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.53230\n",
            "Epoch 473/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3692 - acc: 0.5138 - val_loss: 1.3591 - val_acc: 0.5199\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.53230\n",
            "Epoch 474/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3579 - acc: 0.5295 - val_loss: 1.3481 - val_acc: 0.5212\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.53230\n",
            "Epoch 475/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.3676 - acc: 0.5118 - val_loss: 1.3616 - val_acc: 0.5172\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.53230\n",
            "Epoch 476/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.3421 - acc: 0.5238 - val_loss: 1.3482 - val_acc: 0.5229\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.53230\n",
            "Epoch 477/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3501 - acc: 0.5132 - val_loss: 1.3565 - val_acc: 0.5187\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.53230\n",
            "Epoch 478/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3642 - acc: 0.5204 - val_loss: 1.3563 - val_acc: 0.5198\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.53230\n",
            "Epoch 479/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.3694 - acc: 0.5149 - val_loss: 1.3381 - val_acc: 0.5241\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.53230\n",
            "Epoch 480/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3506 - acc: 0.5278 - val_loss: 1.3456 - val_acc: 0.5227\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.53230\n",
            "Epoch 481/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3600 - acc: 0.5179 - val_loss: 1.3425 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.53230\n",
            "Epoch 482/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.3607 - acc: 0.5165 - val_loss: 1.3495 - val_acc: 0.5221\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.53230\n",
            "Epoch 483/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3779 - acc: 0.5107 - val_loss: 1.3447 - val_acc: 0.5236\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.53230\n",
            "Epoch 484/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3679 - acc: 0.5097 - val_loss: 1.3538 - val_acc: 0.5202\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.53230\n",
            "Epoch 485/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3441 - acc: 0.5242 - val_loss: 1.3571 - val_acc: 0.5191\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.53230\n",
            "Epoch 486/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3695 - acc: 0.5166 - val_loss: 1.3470 - val_acc: 0.5224\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.53230\n",
            "Epoch 487/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.3701 - acc: 0.5164 - val_loss: 1.3599 - val_acc: 0.5193\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.53230\n",
            "Epoch 488/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3364 - acc: 0.5280 - val_loss: 1.3443 - val_acc: 0.5239\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.53230\n",
            "Epoch 489/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3714 - acc: 0.5130 - val_loss: 1.3343 - val_acc: 0.5260\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.53230\n",
            "Epoch 490/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.3545 - acc: 0.5255 - val_loss: 1.3452 - val_acc: 0.5222\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.53230\n",
            "Epoch 491/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.3584 - acc: 0.5169 - val_loss: 1.3538 - val_acc: 0.5183\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.53230\n",
            "Epoch 492/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3554 - acc: 0.5169 - val_loss: 1.3389 - val_acc: 0.5242\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.53230\n",
            "Epoch 493/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3339 - acc: 0.5180 - val_loss: 1.3500 - val_acc: 0.5191\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.53230\n",
            "Epoch 494/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3673 - acc: 0.5173 - val_loss: 1.3540 - val_acc: 0.5181\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.53230\n",
            "Epoch 495/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3787 - acc: 0.5154 - val_loss: 1.3549 - val_acc: 0.5198\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.53230\n",
            "Epoch 496/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3443 - acc: 0.5243 - val_loss: 1.3598 - val_acc: 0.5164\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.53230\n",
            "Epoch 497/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.3567 - acc: 0.5203 - val_loss: 1.3652 - val_acc: 0.5160\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.53230\n",
            "Epoch 498/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 1.3703 - acc: 0.5161 - val_loss: 1.3423 - val_acc: 0.5237\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.53230\n",
            "Epoch 499/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.3621 - acc: 0.5181 - val_loss: 1.3439 - val_acc: 0.5230\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.53230\n",
            "Epoch 500/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.3571 - acc: 0.5149 - val_loss: 1.3563 - val_acc: 0.5183\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.53230\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "oVi24Ibw_vdw",
        "outputId": "3c1ee894-8076-4138-c7e3-6ab481a9a712"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('trainHistoryDict_clip_1', \"rb\"))\n",
        "functions.plot_loss_acc(history, 4, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfJB4PaZ_z14",
        "outputId": "4984738a-a89b-48e3-d54a-608f917e39ab"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.48170000314712524"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "DvhNaoCl4Fl2",
        "outputId": "6b0e5203-448a-4cb6-8a7f-28a205f73ccd"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('trainHistoryDict_clip_1', \"rb\"))\n",
        "functions.plot_loss_acc(history, 4, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9Iv6TyI4MPF",
        "outputId": "13384354-74f2-48a2-8eda-1515eae70f52"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5221000015735626"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJiW0sKS4Tgp"
      },
      "source": [
        "#### Plotting final graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "Uep0tPcFpcuW",
        "outputId": "3bbf97c0-674f-47dc-f80f-b21ed152ca42"
      },
      "source": [
        "plot_final_graph(third=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "G6pbHgsL4ZTv",
        "outputId": "8d765d83-de40-4b06-c473-8ff35915a094"
      },
      "source": [
        "plot_final_graph()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OncKssgHYeJq"
      },
      "source": [
        "### decomposition_rank = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULvNrL4qYhnd"
      },
      "source": [
        "#### Model without clipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4dSbROWYj7q",
        "outputId": "94e9ddd5-ef0e-471a-f125-36728dfa6ffe"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(\n",
        "    input_shape, conv_layer = functions.ConvDecomposed2D, decomposition_rank=10)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_33 (ConvDecom (None, 32, 32, 16)   455         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_33[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 32, 32, 16)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_34 (ConvDecom (None, 32, 32, 16)   1236        activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_34[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 32, 32, 16)   0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_35 (ConvDecom (None, 32, 32, 16)   1236        activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_35[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 32, 32, 16)   0           activation_62[0][0]              \n",
            "                                                                 batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 32, 32, 16)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_36 (ConvDecom (None, 32, 32, 16)   1236        activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_36[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 32, 32, 16)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_37 (ConvDecom (None, 32, 32, 16)   1236        activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_37[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 32, 32, 16)   0           activation_64[0][0]              \n",
            "                                                                 batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 32, 32, 16)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_38 (ConvDecom (None, 32, 32, 16)   1236        activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_38[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 32, 32, 16)   0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_39 (ConvDecom (None, 32, 32, 16)   1236        activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_39[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 32, 32, 16)   0           activation_66[0][0]              \n",
            "                                                                 batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 32, 32, 16)   0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_40 (ConvDecom (None, 32, 32, 16)   1236        activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_40[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 32, 32, 16)   0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_41 (ConvDecom (None, 32, 32, 16)   1236        activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_41[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 32, 32, 16)   0           activation_68[0][0]              \n",
            "                                                                 batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 32, 32, 16)   0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_42 (ConvDecom (None, 32, 32, 16)   1236        activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_42[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 32, 32, 16)   0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_43 (ConvDecom (None, 32, 32, 16)   1236        activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_43[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 32, 32, 16)   0           activation_70[0][0]              \n",
            "                                                                 batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 32, 32, 16)   0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_44 (ConvDecom (None, 16, 16, 32)   1412        activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_44[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 16, 16, 32)   0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_45 (ConvDecom (None, 16, 16, 32)   1572        activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_46 (ConvDecom (None, 16, 16, 32)   612         activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_45[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 16, 16, 32)   0           conv_decomposed2d_46[0][0]       \n",
            "                                                                 batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 16, 16, 32)   0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_47 (ConvDecom (None, 16, 16, 32)   1572        activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_47[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 16, 16, 32)   0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_48 (ConvDecom (None, 16, 16, 32)   1572        activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_48[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 16, 16, 32)   0           activation_74[0][0]              \n",
            "                                                                 batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 16, 16, 32)   0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_49 (ConvDecom (None, 16, 16, 32)   1572        activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_49[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 16, 16, 32)   0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_50 (ConvDecom (None, 16, 16, 32)   1572        activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_50[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 16, 16, 32)   0           activation_76[0][0]              \n",
            "                                                                 batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 16, 16, 32)   0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_51 (ConvDecom (None, 16, 16, 32)   1572        activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_51[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 16, 16, 32)   0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_52 (ConvDecom (None, 16, 16, 32)   1572        activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_52[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 16, 16, 32)   0           activation_78[0][0]              \n",
            "                                                                 batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 16, 16, 32)   0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_53 (ConvDecom (None, 16, 16, 32)   1572        activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_53[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 16, 16, 32)   0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_54 (ConvDecom (None, 16, 16, 32)   1572        activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_54[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 16, 16, 32)   0           activation_80[0][0]              \n",
            "                                                                 batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 16, 16, 32)   0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_55 (ConvDecom (None, 8, 8, 64)     1924        activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_55[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 64)     0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_56 (ConvDecom (None, 8, 8, 64)     2244        activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_57 (ConvDecom (None, 8, 8, 64)     1124        activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_56[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 8, 8, 64)     0           conv_decomposed2d_57[0][0]       \n",
            "                                                                 batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 64)     0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_58 (ConvDecom (None, 8, 8, 64)     2244        activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_58[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 64)     0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_59 (ConvDecom (None, 8, 8, 64)     2244        activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_59[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 8, 8, 64)     0           activation_84[0][0]              \n",
            "                                                                 batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 64)     0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_60 (ConvDecom (None, 8, 8, 64)     2244        activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_60[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 64)     0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_61 (ConvDecom (None, 8, 8, 64)     2244        activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_61[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 8, 8, 64)     0           activation_86[0][0]              \n",
            "                                                                 batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 64)     0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_62 (ConvDecom (None, 8, 8, 64)     2244        activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_62[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 64)     0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_63 (ConvDecom (None, 8, 8, 64)     2244        activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_63[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 8, 8, 64)     0           activation_88[0][0]              \n",
            "                                                                 batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 64)     0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_64 (ConvDecom (None, 8, 8, 64)     2244        activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_64[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 64)     0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_65 (ConvDecom (None, 8, 8, 64)     2244        activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_65[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 8, 8, 64)     0           activation_90[0][0]              \n",
            "                                                                 batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 64)     0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 1, 1, 64)     0           activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 64)           0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           650         flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 57,425\n",
            "Trainable params: 55,153\n",
            "Non-trainable params: 2,272\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIMAAXsrYt1-",
        "outputId": "553b3da1-dbad-459d-d13c-de787a5b2099"
      },
      "source": [
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'R_10_trainHistoryDict', steps_per_epoch=100, batch_size=100,\n",
        "                       epochs=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 17s 104ms/step - loss: 4.6892 - acc: 0.1496 - val_loss: 2.6677 - val_acc: 0.1744\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.17440, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.2539 - acc: 0.2909 - val_loss: 2.4542 - val_acc: 0.2234\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.17440 to 0.22340, saving model to /content/saved_models/cifar10_ResNet32v1_model.002.h5\n",
            "Epoch 3/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.1281 - acc: 0.3480 - val_loss: 2.4055 - val_acc: 0.2761\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.22340 to 0.27610, saving model to /content/saved_models/cifar10_ResNet32v1_model.003.h5\n",
            "Epoch 4/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.0601 - acc: 0.3784 - val_loss: 2.0855 - val_acc: 0.3685\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.27610 to 0.36850, saving model to /content/saved_models/cifar10_ResNet32v1_model.004.h5\n",
            "Epoch 5/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.9732 - acc: 0.4077 - val_loss: 2.4167 - val_acc: 0.2927\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.36850\n",
            "Epoch 6/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.9237 - acc: 0.4166 - val_loss: 2.0650 - val_acc: 0.3771\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.36850 to 0.37710, saving model to /content/saved_models/cifar10_ResNet32v1_model.006.h5\n",
            "Epoch 7/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.8560 - acc: 0.4445 - val_loss: 2.0894 - val_acc: 0.3898\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.37710 to 0.38980, saving model to /content/saved_models/cifar10_ResNet32v1_model.007.h5\n",
            "Epoch 8/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.8200 - acc: 0.4619 - val_loss: 2.0779 - val_acc: 0.3844\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.38980\n",
            "Epoch 9/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.8141 - acc: 0.4670 - val_loss: 1.8990 - val_acc: 0.4429\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.38980 to 0.44290, saving model to /content/saved_models/cifar10_ResNet32v1_model.009.h5\n",
            "Epoch 10/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7847 - acc: 0.4630 - val_loss: 2.1200 - val_acc: 0.4045\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.44290\n",
            "Epoch 11/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7275 - acc: 0.4940 - val_loss: 1.8171 - val_acc: 0.4560\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.44290 to 0.45600, saving model to /content/saved_models/cifar10_ResNet32v1_model.011.h5\n",
            "Epoch 12/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.7224 - acc: 0.4905 - val_loss: 1.8139 - val_acc: 0.4670\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.45600 to 0.46700, saving model to /content/saved_models/cifar10_ResNet32v1_model.012.h5\n",
            "Epoch 13/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.7319 - acc: 0.4839 - val_loss: 1.7749 - val_acc: 0.4721\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.46700 to 0.47210, saving model to /content/saved_models/cifar10_ResNet32v1_model.013.h5\n",
            "Epoch 14/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6723 - acc: 0.5141 - val_loss: 1.7427 - val_acc: 0.4849\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.47210 to 0.48490, saving model to /content/saved_models/cifar10_ResNet32v1_model.014.h5\n",
            "Epoch 15/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.6306 - acc: 0.5177 - val_loss: 1.8349 - val_acc: 0.4696\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.48490\n",
            "Epoch 16/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.6250 - acc: 0.5279 - val_loss: 1.8475 - val_acc: 0.4490\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.48490\n",
            "Epoch 17/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5804 - acc: 0.5394 - val_loss: 1.8475 - val_acc: 0.4650\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.48490\n",
            "Epoch 18/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.5552 - acc: 0.5546 - val_loss: 1.7043 - val_acc: 0.4893\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.48490 to 0.48930, saving model to /content/saved_models/cifar10_ResNet32v1_model.018.h5\n",
            "Epoch 19/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.5290 - acc: 0.5551 - val_loss: 1.6224 - val_acc: 0.5345\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.48930 to 0.53450, saving model to /content/saved_models/cifar10_ResNet32v1_model.019.h5\n",
            "Epoch 20/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.4922 - acc: 0.5730 - val_loss: 1.6802 - val_acc: 0.5033\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.53450\n",
            "Epoch 21/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.4884 - acc: 0.5740 - val_loss: 1.6393 - val_acc: 0.5164\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.53450\n",
            "Epoch 22/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.4539 - acc: 0.5959 - val_loss: 1.7628 - val_acc: 0.4824\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.53450\n",
            "Epoch 23/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.4189 - acc: 0.6034 - val_loss: 1.5208 - val_acc: 0.5604\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.53450 to 0.56040, saving model to /content/saved_models/cifar10_ResNet32v1_model.023.h5\n",
            "Epoch 24/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.4160 - acc: 0.5990 - val_loss: 2.2316 - val_acc: 0.4490\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.56040\n",
            "Epoch 25/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.3946 - acc: 0.6106 - val_loss: 1.6797 - val_acc: 0.5046\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.56040\n",
            "Epoch 26/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.3690 - acc: 0.6166 - val_loss: 1.6582 - val_acc: 0.5279\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.56040\n",
            "Epoch 27/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.3912 - acc: 0.6072 - val_loss: 1.5631 - val_acc: 0.5504\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.56040\n",
            "Epoch 28/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.3469 - acc: 0.6303 - val_loss: 1.4895 - val_acc: 0.5687\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.56040 to 0.56870, saving model to /content/saved_models/cifar10_ResNet32v1_model.028.h5\n",
            "Epoch 29/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.3433 - acc: 0.6246 - val_loss: 1.4021 - val_acc: 0.5988\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.56870 to 0.59880, saving model to /content/saved_models/cifar10_ResNet32v1_model.029.h5\n",
            "Epoch 30/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.3263 - acc: 0.6257 - val_loss: 1.8704 - val_acc: 0.4938\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.59880\n",
            "Epoch 31/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.3144 - acc: 0.6260 - val_loss: 1.7151 - val_acc: 0.5009\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.59880\n",
            "Epoch 32/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.2964 - acc: 0.6378 - val_loss: 1.6461 - val_acc: 0.5597\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.59880\n",
            "Epoch 33/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.2749 - acc: 0.6455 - val_loss: 1.5448 - val_acc: 0.5579\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.59880\n",
            "Epoch 34/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.2700 - acc: 0.6400 - val_loss: 1.3951 - val_acc: 0.6080\n",
            "\n",
            "Epoch 00034: val_acc improved from 0.59880 to 0.60800, saving model to /content/saved_models/cifar10_ResNet32v1_model.034.h5\n",
            "Epoch 35/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.2563 - acc: 0.6551 - val_loss: 1.5287 - val_acc: 0.5657\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.60800\n",
            "Epoch 36/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.2601 - acc: 0.6401 - val_loss: 1.3558 - val_acc: 0.6144\n",
            "\n",
            "Epoch 00036: val_acc improved from 0.60800 to 0.61440, saving model to /content/saved_models/cifar10_ResNet32v1_model.036.h5\n",
            "Epoch 37/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.2502 - acc: 0.6644 - val_loss: 1.4445 - val_acc: 0.5882\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.61440\n",
            "Epoch 38/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.2594 - acc: 0.6494 - val_loss: 1.4252 - val_acc: 0.6074\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.61440\n",
            "Epoch 39/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.2325 - acc: 0.6583 - val_loss: 1.3400 - val_acc: 0.6230\n",
            "\n",
            "Epoch 00039: val_acc improved from 0.61440 to 0.62300, saving model to /content/saved_models/cifar10_ResNet32v1_model.039.h5\n",
            "Epoch 40/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.1839 - acc: 0.6786 - val_loss: 1.5919 - val_acc: 0.5626\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.62300\n",
            "Epoch 41/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.1955 - acc: 0.6719 - val_loss: 1.5839 - val_acc: 0.5661\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.62300\n",
            "Epoch 42/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.1735 - acc: 0.6769 - val_loss: 1.2027 - val_acc: 0.6701\n",
            "\n",
            "Epoch 00042: val_acc improved from 0.62300 to 0.67010, saving model to /content/saved_models/cifar10_ResNet32v1_model.042.h5\n",
            "Epoch 43/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.1581 - acc: 0.6830 - val_loss: 1.4205 - val_acc: 0.6112\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.67010\n",
            "Epoch 44/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.1705 - acc: 0.6795 - val_loss: 1.3144 - val_acc: 0.6325\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.67010\n",
            "Epoch 45/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.1574 - acc: 0.6885 - val_loss: 1.4297 - val_acc: 0.5966\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.67010\n",
            "Epoch 46/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.1560 - acc: 0.6749 - val_loss: 1.2612 - val_acc: 0.6528\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.67010\n",
            "Epoch 47/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.1399 - acc: 0.6893 - val_loss: 1.4250 - val_acc: 0.6068\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.67010\n",
            "Epoch 48/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.1069 - acc: 0.7015 - val_loss: 1.4828 - val_acc: 0.6091\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.67010\n",
            "Epoch 49/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.1118 - acc: 0.7041 - val_loss: 1.5666 - val_acc: 0.6062\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.67010\n",
            "Epoch 50/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.1143 - acc: 0.6982 - val_loss: 1.3787 - val_acc: 0.6254\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.67010\n",
            "Epoch 51/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.0944 - acc: 0.7069 - val_loss: 1.4467 - val_acc: 0.6190\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.67010\n",
            "Epoch 52/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.0811 - acc: 0.7069 - val_loss: 1.3746 - val_acc: 0.6314\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.67010\n",
            "Epoch 53/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.0699 - acc: 0.7165 - val_loss: 1.5184 - val_acc: 0.5901\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.67010\n",
            "Epoch 54/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.0683 - acc: 0.7162 - val_loss: 1.2347 - val_acc: 0.6692\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.67010\n",
            "Epoch 55/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.0750 - acc: 0.7112 - val_loss: 1.3663 - val_acc: 0.6294\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.67010\n",
            "Epoch 56/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.0772 - acc: 0.7144 - val_loss: 1.2222 - val_acc: 0.6603\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.67010\n",
            "Epoch 57/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.0688 - acc: 0.7130 - val_loss: 1.1050 - val_acc: 0.7007\n",
            "\n",
            "Epoch 00057: val_acc improved from 0.67010 to 0.70070, saving model to /content/saved_models/cifar10_ResNet32v1_model.057.h5\n",
            "Epoch 58/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.0755 - acc: 0.7093 - val_loss: 1.3177 - val_acc: 0.6494\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.70070\n",
            "Epoch 59/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.0504 - acc: 0.7184 - val_loss: 1.3689 - val_acc: 0.6333\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.70070\n",
            "Epoch 60/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.0319 - acc: 0.7230 - val_loss: 1.9814 - val_acc: 0.5264\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.70070\n",
            "Epoch 61/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.0295 - acc: 0.7234 - val_loss: 1.2470 - val_acc: 0.6573\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.70070\n",
            "Epoch 62/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.0402 - acc: 0.7163 - val_loss: 1.1954 - val_acc: 0.6701\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.70070\n",
            "Epoch 63/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.0403 - acc: 0.7227 - val_loss: 1.1188 - val_acc: 0.6920\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.70070\n",
            "Epoch 64/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.0207 - acc: 0.7336 - val_loss: 1.0442 - val_acc: 0.7196\n",
            "\n",
            "Epoch 00064: val_acc improved from 0.70070 to 0.71960, saving model to /content/saved_models/cifar10_ResNet32v1_model.064.h5\n",
            "Epoch 65/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.0201 - acc: 0.7256 - val_loss: 1.3388 - val_acc: 0.6462\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.71960\n",
            "Epoch 66/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.0019 - acc: 0.7296 - val_loss: 1.1248 - val_acc: 0.6850\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.71960\n",
            "Epoch 67/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.9996 - acc: 0.7334 - val_loss: 1.1138 - val_acc: 0.6994\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.71960\n",
            "Epoch 68/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.9825 - acc: 0.7384 - val_loss: 1.4015 - val_acc: 0.6199\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.71960\n",
            "Epoch 69/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.0015 - acc: 0.7277 - val_loss: 1.1241 - val_acc: 0.6910\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.71960\n",
            "Epoch 70/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.9450 - acc: 0.7514 - val_loss: 1.3785 - val_acc: 0.6093\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.71960\n",
            "Epoch 71/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.9760 - acc: 0.7438 - val_loss: 1.2656 - val_acc: 0.6649\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.71960\n",
            "Epoch 72/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.9778 - acc: 0.7416 - val_loss: 1.4467 - val_acc: 0.6371\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.71960\n",
            "Epoch 73/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.9336 - acc: 0.7512 - val_loss: 1.2922 - val_acc: 0.6488\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.71960\n",
            "Epoch 74/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.9590 - acc: 0.7456 - val_loss: 1.5094 - val_acc: 0.6080\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.71960\n",
            "Epoch 75/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.9546 - acc: 0.7496 - val_loss: 1.4558 - val_acc: 0.5971\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.71960\n",
            "Epoch 76/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.9652 - acc: 0.7463 - val_loss: 1.3333 - val_acc: 0.6534\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.71960\n",
            "Epoch 77/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.9307 - acc: 0.7504 - val_loss: 1.3687 - val_acc: 0.6398\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.71960\n",
            "Epoch 78/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.9445 - acc: 0.7430 - val_loss: 1.2168 - val_acc: 0.6771\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.71960\n",
            "Epoch 79/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.9576 - acc: 0.7505 - val_loss: 1.6090 - val_acc: 0.5929\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.71960\n",
            "Epoch 80/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.9169 - acc: 0.7578 - val_loss: 1.3185 - val_acc: 0.6322\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.71960\n",
            "Epoch 81/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.9220 - acc: 0.7512 - val_loss: 1.3572 - val_acc: 0.6545\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.71960\n",
            "Epoch 82/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.9095 - acc: 0.7604 - val_loss: 1.1932 - val_acc: 0.6787\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.71960\n",
            "Epoch 83/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.9127 - acc: 0.7595 - val_loss: 1.0717 - val_acc: 0.7055\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.71960\n",
            "Epoch 84/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.9139 - acc: 0.7609 - val_loss: 1.0411 - val_acc: 0.7207\n",
            "\n",
            "Epoch 00084: val_acc improved from 0.71960 to 0.72070, saving model to /content/saved_models/cifar10_ResNet32v1_model.084.h5\n",
            "Epoch 85/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8908 - acc: 0.7670 - val_loss: 1.1788 - val_acc: 0.6856\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.72070\n",
            "Epoch 86/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.9153 - acc: 0.7543 - val_loss: 1.1304 - val_acc: 0.7000\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.72070\n",
            "Epoch 87/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.9190 - acc: 0.7579 - val_loss: 1.0780 - val_acc: 0.7163\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.72070\n",
            "Epoch 88/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.9031 - acc: 0.7704 - val_loss: 1.0862 - val_acc: 0.7082\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.72070\n",
            "Epoch 89/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.8878 - acc: 0.7711 - val_loss: 1.0450 - val_acc: 0.7152\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.72070\n",
            "Epoch 90/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.8940 - acc: 0.7609 - val_loss: 1.1449 - val_acc: 0.6983\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.72070\n",
            "Epoch 91/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.9148 - acc: 0.7567 - val_loss: 1.1791 - val_acc: 0.6857\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.72070\n",
            "Epoch 92/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8747 - acc: 0.7663 - val_loss: 1.0208 - val_acc: 0.7267\n",
            "\n",
            "Epoch 00092: val_acc improved from 0.72070 to 0.72670, saving model to /content/saved_models/cifar10_ResNet32v1_model.092.h5\n",
            "Epoch 93/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8914 - acc: 0.7742 - val_loss: 1.1948 - val_acc: 0.6769\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.72670\n",
            "Epoch 94/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.8749 - acc: 0.7676 - val_loss: 1.1344 - val_acc: 0.7066\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.72670\n",
            "Epoch 95/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8968 - acc: 0.7608 - val_loss: 1.0852 - val_acc: 0.7041\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.72670\n",
            "Epoch 96/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.8660 - acc: 0.7666 - val_loss: 0.9750 - val_acc: 0.7365\n",
            "\n",
            "Epoch 00096: val_acc improved from 0.72670 to 0.73650, saving model to /content/saved_models/cifar10_ResNet32v1_model.096.h5\n",
            "Epoch 97/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.8612 - acc: 0.7739 - val_loss: 1.2479 - val_acc: 0.6693\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.73650\n",
            "Epoch 98/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.8514 - acc: 0.7786 - val_loss: 1.0512 - val_acc: 0.7180\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.73650\n",
            "Epoch 99/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.8523 - acc: 0.7813 - val_loss: 0.9621 - val_acc: 0.7501\n",
            "\n",
            "Epoch 00099: val_acc improved from 0.73650 to 0.75010, saving model to /content/saved_models/cifar10_ResNet32v1_model.099.h5\n",
            "Epoch 100/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.8548 - acc: 0.7720 - val_loss: 1.2377 - val_acc: 0.6853\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.75010\n",
            "Epoch 101/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.8451 - acc: 0.7780 - val_loss: 0.9688 - val_acc: 0.7349\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.75010\n",
            "Epoch 102/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.8436 - acc: 0.7793 - val_loss: 1.0362 - val_acc: 0.7228\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.75010\n",
            "Epoch 103/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.8408 - acc: 0.7826 - val_loss: 1.0710 - val_acc: 0.7093\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.75010\n",
            "Epoch 104/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.8213 - acc: 0.7842 - val_loss: 1.0421 - val_acc: 0.7242\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.75010\n",
            "Epoch 105/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.8361 - acc: 0.7824 - val_loss: 1.0435 - val_acc: 0.7225\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.75010\n",
            "Epoch 106/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.8349 - acc: 0.7853 - val_loss: 1.6035 - val_acc: 0.5870\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.75010\n",
            "Epoch 107/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.8614 - acc: 0.7706 - val_loss: 1.0051 - val_acc: 0.7293\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.75010\n",
            "Epoch 108/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.8458 - acc: 0.7784 - val_loss: 1.2288 - val_acc: 0.6881\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.75010\n",
            "Epoch 109/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.8317 - acc: 0.7796 - val_loss: 1.5038 - val_acc: 0.6080\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.75010\n",
            "Epoch 110/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.8361 - acc: 0.7802 - val_loss: 0.9691 - val_acc: 0.7441\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.75010\n",
            "Epoch 111/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.8266 - acc: 0.7864 - val_loss: 0.9945 - val_acc: 0.7414\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.75010\n",
            "Epoch 112/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.8147 - acc: 0.7862 - val_loss: 1.1166 - val_acc: 0.7045\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.75010\n",
            "Epoch 113/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.8164 - acc: 0.7750 - val_loss: 0.9966 - val_acc: 0.7292\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.75010\n",
            "Epoch 114/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.7936 - acc: 0.7910 - val_loss: 0.9842 - val_acc: 0.7433\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.75010\n",
            "Epoch 115/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.8242 - acc: 0.7747 - val_loss: 0.9537 - val_acc: 0.7442\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.75010\n",
            "Epoch 116/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7974 - acc: 0.7951 - val_loss: 1.0757 - val_acc: 0.7095\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.75010\n",
            "Epoch 117/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.8034 - acc: 0.7888 - val_loss: 0.9740 - val_acc: 0.7386\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.75010\n",
            "Epoch 118/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.8020 - acc: 0.7870 - val_loss: 1.0093 - val_acc: 0.7257\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.75010\n",
            "Epoch 119/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.8161 - acc: 0.7851 - val_loss: 1.0357 - val_acc: 0.7272\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.75010\n",
            "Epoch 120/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7833 - acc: 0.7956 - val_loss: 0.9963 - val_acc: 0.7352\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.75010\n",
            "Epoch 121/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.8003 - acc: 0.7911 - val_loss: 0.9166 - val_acc: 0.7577\n",
            "\n",
            "Epoch 00121: val_acc improved from 0.75010 to 0.75770, saving model to /content/saved_models/cifar10_ResNet32v1_model.121.h5\n",
            "Epoch 122/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7786 - acc: 0.7944 - val_loss: 1.1097 - val_acc: 0.7096\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.75770\n",
            "Epoch 123/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7946 - acc: 0.7936 - val_loss: 1.2389 - val_acc: 0.6742\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.75770\n",
            "Epoch 124/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7660 - acc: 0.8002 - val_loss: 0.9072 - val_acc: 0.7632\n",
            "\n",
            "Epoch 00124: val_acc improved from 0.75770 to 0.76320, saving model to /content/saved_models/cifar10_ResNet32v1_model.124.h5\n",
            "Epoch 125/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.7782 - acc: 0.7990 - val_loss: 1.0608 - val_acc: 0.7193\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.76320\n",
            "Epoch 126/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.7880 - acc: 0.7877 - val_loss: 0.9498 - val_acc: 0.7440\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.76320\n",
            "Epoch 127/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7772 - acc: 0.8001 - val_loss: 1.2113 - val_acc: 0.6901\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.76320\n",
            "Epoch 128/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7506 - acc: 0.8102 - val_loss: 0.9775 - val_acc: 0.7448\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.76320\n",
            "Epoch 129/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7976 - acc: 0.7888 - val_loss: 1.2235 - val_acc: 0.6679\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.76320\n",
            "Epoch 130/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7602 - acc: 0.8047 - val_loss: 0.9003 - val_acc: 0.7567\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.76320\n",
            "Epoch 131/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7542 - acc: 0.8011 - val_loss: 1.3044 - val_acc: 0.6734\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.76320\n",
            "Epoch 132/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7926 - acc: 0.7858 - val_loss: 1.2276 - val_acc: 0.6714\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.76320\n",
            "Epoch 133/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7688 - acc: 0.7909 - val_loss: 1.2478 - val_acc: 0.6790\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.76320\n",
            "Epoch 134/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7498 - acc: 0.8030 - val_loss: 1.0680 - val_acc: 0.7306\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.76320\n",
            "Epoch 135/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7555 - acc: 0.8058 - val_loss: 1.0401 - val_acc: 0.7257\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.76320\n",
            "Epoch 136/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7495 - acc: 0.8018 - val_loss: 0.8601 - val_acc: 0.7696\n",
            "\n",
            "Epoch 00136: val_acc improved from 0.76320 to 0.76960, saving model to /content/saved_models/cifar10_ResNet32v1_model.136.h5\n",
            "Epoch 137/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7669 - acc: 0.8003 - val_loss: 0.9695 - val_acc: 0.7424\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.76960\n",
            "Epoch 138/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7496 - acc: 0.8011 - val_loss: 0.9523 - val_acc: 0.7466\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.76960\n",
            "Epoch 139/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7526 - acc: 0.8042 - val_loss: 1.0006 - val_acc: 0.7297\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.76960\n",
            "Epoch 140/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7369 - acc: 0.8081 - val_loss: 0.9471 - val_acc: 0.7458\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.76960\n",
            "Epoch 141/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7382 - acc: 0.8120 - val_loss: 0.9001 - val_acc: 0.7648\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.76960\n",
            "Epoch 142/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7488 - acc: 0.8069 - val_loss: 0.8187 - val_acc: 0.7809\n",
            "\n",
            "Epoch 00142: val_acc improved from 0.76960 to 0.78090, saving model to /content/saved_models/cifar10_ResNet32v1_model.142.h5\n",
            "Epoch 143/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7494 - acc: 0.8060 - val_loss: 1.3327 - val_acc: 0.6487\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.78090\n",
            "Epoch 144/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7318 - acc: 0.8042 - val_loss: 1.0004 - val_acc: 0.7363\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.78090\n",
            "Epoch 145/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7361 - acc: 0.8071 - val_loss: 0.9628 - val_acc: 0.7422\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.78090\n",
            "Epoch 146/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7019 - acc: 0.8175 - val_loss: 0.8252 - val_acc: 0.7796\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.78090\n",
            "Epoch 147/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7199 - acc: 0.8144 - val_loss: 0.9414 - val_acc: 0.7496\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.78090\n",
            "Epoch 148/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7553 - acc: 0.7955 - val_loss: 1.1297 - val_acc: 0.6984\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.78090\n",
            "Epoch 149/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7473 - acc: 0.8049 - val_loss: 1.1288 - val_acc: 0.7048\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.78090\n",
            "Epoch 150/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7257 - acc: 0.8122 - val_loss: 1.0760 - val_acc: 0.7100\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.78090\n",
            "Epoch 151/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.7270 - acc: 0.8137 - val_loss: 1.0199 - val_acc: 0.7386\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.78090\n",
            "Epoch 152/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7431 - acc: 0.7978 - val_loss: 0.8212 - val_acc: 0.7831\n",
            "\n",
            "Epoch 00152: val_acc improved from 0.78090 to 0.78310, saving model to /content/saved_models/cifar10_ResNet32v1_model.152.h5\n",
            "Epoch 153/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.7353 - acc: 0.8011 - val_loss: 1.1465 - val_acc: 0.6991\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.78310\n",
            "Epoch 154/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.7158 - acc: 0.8117 - val_loss: 0.8245 - val_acc: 0.7834\n",
            "\n",
            "Epoch 00154: val_acc improved from 0.78310 to 0.78340, saving model to /content/saved_models/cifar10_ResNet32v1_model.154.h5\n",
            "Epoch 155/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.7371 - acc: 0.8082 - val_loss: 0.8850 - val_acc: 0.7594\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.78340\n",
            "Epoch 156/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.7186 - acc: 0.8117 - val_loss: 1.0361 - val_acc: 0.7109\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.78340\n",
            "Epoch 157/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.7469 - acc: 0.8047 - val_loss: 1.4074 - val_acc: 0.6510\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.78340\n",
            "Epoch 158/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.7217 - acc: 0.8173 - val_loss: 0.9348 - val_acc: 0.7527\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.78340\n",
            "Epoch 159/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7227 - acc: 0.8070 - val_loss: 1.0698 - val_acc: 0.7138\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.78340\n",
            "Epoch 160/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.7168 - acc: 0.8019 - val_loss: 1.2270 - val_acc: 0.7013\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.78340\n",
            "Epoch 161/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.7043 - acc: 0.8117 - val_loss: 0.9437 - val_acc: 0.7475\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.78340\n",
            "Epoch 162/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7075 - acc: 0.8124 - val_loss: 0.9944 - val_acc: 0.7479\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.78340\n",
            "Epoch 163/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7122 - acc: 0.8165 - val_loss: 0.9328 - val_acc: 0.7596\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.78340\n",
            "Epoch 164/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.7134 - acc: 0.8099 - val_loss: 0.8431 - val_acc: 0.7731\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.78340\n",
            "Epoch 165/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6971 - acc: 0.8132 - val_loss: 0.8545 - val_acc: 0.7739\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.78340\n",
            "Epoch 166/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.7190 - acc: 0.8140 - val_loss: 0.9612 - val_acc: 0.7420\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.78340\n",
            "Epoch 167/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7028 - acc: 0.8149 - val_loss: 0.7810 - val_acc: 0.7926\n",
            "\n",
            "Epoch 00167: val_acc improved from 0.78340 to 0.79260, saving model to /content/saved_models/cifar10_ResNet32v1_model.167.h5\n",
            "Epoch 168/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6918 - acc: 0.8194 - val_loss: 0.8549 - val_acc: 0.7747\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.79260\n",
            "Epoch 169/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6975 - acc: 0.8225 - val_loss: 0.8388 - val_acc: 0.7751\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.79260\n",
            "Epoch 170/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6838 - acc: 0.8177 - val_loss: 1.0083 - val_acc: 0.7440\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.79260\n",
            "Epoch 171/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.7158 - acc: 0.8079 - val_loss: 0.9626 - val_acc: 0.7406\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.79260\n",
            "Epoch 172/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6718 - acc: 0.8246 - val_loss: 0.8689 - val_acc: 0.7712\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.79260\n",
            "Epoch 173/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6823 - acc: 0.8231 - val_loss: 1.0689 - val_acc: 0.7286\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.79260\n",
            "Epoch 174/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.6804 - acc: 0.8256 - val_loss: 1.1209 - val_acc: 0.7108\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.79260\n",
            "Epoch 175/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6868 - acc: 0.8161 - val_loss: 0.8181 - val_acc: 0.7778\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.79260\n",
            "Epoch 176/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.7121 - acc: 0.8142 - val_loss: 0.8412 - val_acc: 0.7809\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.79260\n",
            "Epoch 177/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6801 - acc: 0.8211 - val_loss: 0.8381 - val_acc: 0.7831\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.79260\n",
            "Epoch 178/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.7159 - acc: 0.8097 - val_loss: 0.8588 - val_acc: 0.7680\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.79260\n",
            "Epoch 179/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6693 - acc: 0.8221 - val_loss: 0.8574 - val_acc: 0.7676\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.79260\n",
            "Epoch 180/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6577 - acc: 0.8325 - val_loss: 0.9087 - val_acc: 0.7529\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.79260\n",
            "Epoch 181/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6671 - acc: 0.8303 - val_loss: 0.9698 - val_acc: 0.7413\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.79260\n",
            "Epoch 182/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6671 - acc: 0.8212 - val_loss: 1.7149 - val_acc: 0.6216\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.79260\n",
            "Epoch 183/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6900 - acc: 0.8171 - val_loss: 1.0719 - val_acc: 0.7254\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.79260\n",
            "Epoch 184/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6785 - acc: 0.8207 - val_loss: 0.8377 - val_acc: 0.7808\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.79260\n",
            "Epoch 185/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6794 - acc: 0.8236 - val_loss: 1.0133 - val_acc: 0.7390\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.79260\n",
            "Epoch 186/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6974 - acc: 0.8170 - val_loss: 1.0266 - val_acc: 0.7464\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.79260\n",
            "Epoch 187/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6680 - acc: 0.8236 - val_loss: 0.8697 - val_acc: 0.7638\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.79260\n",
            "Epoch 188/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6736 - acc: 0.8241 - val_loss: 1.0066 - val_acc: 0.7308\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.79260\n",
            "Epoch 189/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6703 - acc: 0.8233 - val_loss: 0.9047 - val_acc: 0.7534\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.79260\n",
            "Epoch 190/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6594 - acc: 0.8287 - val_loss: 0.7906 - val_acc: 0.7956\n",
            "\n",
            "Epoch 00190: val_acc improved from 0.79260 to 0.79560, saving model to /content/saved_models/cifar10_ResNet32v1_model.190.h5\n",
            "Epoch 191/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6791 - acc: 0.8229 - val_loss: 1.2150 - val_acc: 0.6829\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.79560\n",
            "Epoch 192/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6613 - acc: 0.8268 - val_loss: 0.9093 - val_acc: 0.7472\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.79560\n",
            "Epoch 193/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6835 - acc: 0.8203 - val_loss: 0.7656 - val_acc: 0.7954\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.79560\n",
            "Epoch 194/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6717 - acc: 0.8190 - val_loss: 0.8222 - val_acc: 0.7837\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.79560\n",
            "Epoch 195/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6465 - acc: 0.8274 - val_loss: 0.7988 - val_acc: 0.7894\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.79560\n",
            "Epoch 196/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6565 - acc: 0.8247 - val_loss: 0.9308 - val_acc: 0.7468\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.79560\n",
            "Epoch 197/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6638 - acc: 0.8275 - val_loss: 0.8598 - val_acc: 0.7796\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.79560\n",
            "Epoch 198/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6577 - acc: 0.8232 - val_loss: 0.8878 - val_acc: 0.7640\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.79560\n",
            "Epoch 199/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6546 - acc: 0.8263 - val_loss: 1.0451 - val_acc: 0.7299\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.79560\n",
            "Epoch 200/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6622 - acc: 0.8237 - val_loss: 0.9619 - val_acc: 0.7501\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.79560\n",
            "Epoch 201/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6647 - acc: 0.8204 - val_loss: 0.7889 - val_acc: 0.7958\n",
            "\n",
            "Epoch 00201: val_acc improved from 0.79560 to 0.79580, saving model to /content/saved_models/cifar10_ResNet32v1_model.201.h5\n",
            "Epoch 202/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6682 - acc: 0.8220 - val_loss: 0.8821 - val_acc: 0.7671\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.79580\n",
            "Epoch 203/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6619 - acc: 0.8207 - val_loss: 1.0347 - val_acc: 0.7351\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.79580\n",
            "Epoch 204/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6756 - acc: 0.8203 - val_loss: 0.8665 - val_acc: 0.7751\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.79580\n",
            "Epoch 205/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6522 - acc: 0.8344 - val_loss: 0.9552 - val_acc: 0.7459\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.79580\n",
            "Epoch 206/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6362 - acc: 0.8348 - val_loss: 0.9762 - val_acc: 0.7383\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.79580\n",
            "Epoch 207/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6573 - acc: 0.8303 - val_loss: 0.8030 - val_acc: 0.7891\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.79580\n",
            "Epoch 208/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6218 - acc: 0.8412 - val_loss: 0.7724 - val_acc: 0.7944\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.79580\n",
            "Epoch 209/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6364 - acc: 0.8358 - val_loss: 0.8759 - val_acc: 0.7675\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.79580\n",
            "Epoch 210/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6357 - acc: 0.8367 - val_loss: 0.8787 - val_acc: 0.7618\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.79580\n",
            "Epoch 211/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6567 - acc: 0.8268 - val_loss: 1.3137 - val_acc: 0.6829\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.79580\n",
            "Epoch 212/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6464 - acc: 0.8305 - val_loss: 0.7902 - val_acc: 0.7878\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.79580\n",
            "Epoch 213/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6311 - acc: 0.8372 - val_loss: 0.8198 - val_acc: 0.7794\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.79580\n",
            "Epoch 214/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6194 - acc: 0.8415 - val_loss: 0.8314 - val_acc: 0.7748\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.79580\n",
            "Epoch 215/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6428 - acc: 0.8322 - val_loss: 0.7949 - val_acc: 0.7883\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.79580\n",
            "Epoch 216/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6670 - acc: 0.8183 - val_loss: 0.7725 - val_acc: 0.7995\n",
            "\n",
            "Epoch 00216: val_acc improved from 0.79580 to 0.79950, saving model to /content/saved_models/cifar10_ResNet32v1_model.216.h5\n",
            "Epoch 217/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6200 - acc: 0.8409 - val_loss: 0.7773 - val_acc: 0.7951\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.79950\n",
            "Epoch 218/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6134 - acc: 0.8364 - val_loss: 0.9395 - val_acc: 0.7597\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.79950\n",
            "Epoch 219/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6255 - acc: 0.8347 - val_loss: 0.8982 - val_acc: 0.7763\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.79950\n",
            "Epoch 220/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.6351 - acc: 0.8383 - val_loss: 0.8749 - val_acc: 0.7643\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.79950\n",
            "Epoch 221/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6461 - acc: 0.8266 - val_loss: 1.4421 - val_acc: 0.6620\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.79950\n",
            "Epoch 222/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6210 - acc: 0.8369 - val_loss: 0.9243 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.79950\n",
            "Epoch 223/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6410 - acc: 0.8314 - val_loss: 0.9828 - val_acc: 0.7377\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.79950\n",
            "Epoch 224/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6267 - acc: 0.8339 - val_loss: 1.0791 - val_acc: 0.7175\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.79950\n",
            "Epoch 225/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6147 - acc: 0.8400 - val_loss: 0.8727 - val_acc: 0.7683\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.79950\n",
            "Epoch 226/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6288 - acc: 0.8357 - val_loss: 0.9782 - val_acc: 0.7481\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.79950\n",
            "Epoch 227/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6267 - acc: 0.8402 - val_loss: 0.7541 - val_acc: 0.7976\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.79950\n",
            "Epoch 228/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6117 - acc: 0.8405 - val_loss: 0.9640 - val_acc: 0.7585\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.79950\n",
            "Epoch 229/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6145 - acc: 0.8399 - val_loss: 1.0709 - val_acc: 0.7238\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.79950\n",
            "Epoch 230/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.6412 - acc: 0.8349 - val_loss: 0.8582 - val_acc: 0.7700\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.79950\n",
            "Epoch 231/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6386 - acc: 0.8374 - val_loss: 0.8157 - val_acc: 0.7789\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.79950\n",
            "Epoch 232/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6058 - acc: 0.8432 - val_loss: 0.7489 - val_acc: 0.8007\n",
            "\n",
            "Epoch 00232: val_acc improved from 0.79950 to 0.80070, saving model to /content/saved_models/cifar10_ResNet32v1_model.232.h5\n",
            "Epoch 233/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6058 - acc: 0.8424 - val_loss: 1.0076 - val_acc: 0.7475\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.80070\n",
            "Epoch 234/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.6193 - acc: 0.8398 - val_loss: 0.9422 - val_acc: 0.7439\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.80070\n",
            "Epoch 235/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.6102 - acc: 0.8448 - val_loss: 0.7052 - val_acc: 0.8135\n",
            "\n",
            "Epoch 00235: val_acc improved from 0.80070 to 0.81350, saving model to /content/saved_models/cifar10_ResNet32v1_model.235.h5\n",
            "Epoch 236/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6151 - acc: 0.8435 - val_loss: 0.9188 - val_acc: 0.7608\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.81350\n",
            "Epoch 237/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6131 - acc: 0.8413 - val_loss: 0.8766 - val_acc: 0.7688\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.81350\n",
            "Epoch 238/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6048 - acc: 0.8471 - val_loss: 0.8229 - val_acc: 0.7790\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.81350\n",
            "Epoch 239/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6172 - acc: 0.8419 - val_loss: 0.9037 - val_acc: 0.7624\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.81350\n",
            "Epoch 240/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6168 - acc: 0.8400 - val_loss: 0.8842 - val_acc: 0.7725\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.81350\n",
            "Epoch 241/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6076 - acc: 0.8434 - val_loss: 0.9483 - val_acc: 0.7537\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.81350\n",
            "Epoch 242/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6251 - acc: 0.8358 - val_loss: 0.9598 - val_acc: 0.7423\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.81350\n",
            "Epoch 243/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5983 - acc: 0.8505 - val_loss: 0.8411 - val_acc: 0.7748\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.81350\n",
            "Epoch 244/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6241 - acc: 0.8301 - val_loss: 0.7964 - val_acc: 0.7899\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.81350\n",
            "Epoch 245/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6136 - acc: 0.8413 - val_loss: 0.8693 - val_acc: 0.7628\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.81350\n",
            "Epoch 246/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6143 - acc: 0.8388 - val_loss: 0.8775 - val_acc: 0.7776\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.81350\n",
            "Epoch 247/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5966 - acc: 0.8470 - val_loss: 0.8712 - val_acc: 0.7697\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.81350\n",
            "Epoch 248/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6185 - acc: 0.8380 - val_loss: 0.8511 - val_acc: 0.7700\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.81350\n",
            "Epoch 249/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6110 - acc: 0.8346 - val_loss: 1.0005 - val_acc: 0.7407\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.81350\n",
            "Epoch 250/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6027 - acc: 0.8398 - val_loss: 0.7791 - val_acc: 0.7988\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.81350\n",
            "Epoch 251/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5911 - acc: 0.8487 - val_loss: 0.9232 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.81350\n",
            "Epoch 252/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5997 - acc: 0.8461 - val_loss: 0.7794 - val_acc: 0.7969\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.81350\n",
            "Epoch 253/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6078 - acc: 0.8367 - val_loss: 0.8845 - val_acc: 0.7671\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.81350\n",
            "Epoch 254/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5876 - acc: 0.8477 - val_loss: 0.7689 - val_acc: 0.7994\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.81350\n",
            "Epoch 255/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5979 - acc: 0.8485 - val_loss: 0.8982 - val_acc: 0.7607\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.81350\n",
            "Epoch 256/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5787 - acc: 0.8453 - val_loss: 0.7454 - val_acc: 0.8069\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.81350\n",
            "Epoch 257/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5762 - acc: 0.8559 - val_loss: 0.8449 - val_acc: 0.7749\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.81350\n",
            "Epoch 258/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.6001 - acc: 0.8423 - val_loss: 0.8723 - val_acc: 0.7720\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.81350\n",
            "Epoch 259/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5943 - acc: 0.8451 - val_loss: 0.7761 - val_acc: 0.7909\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.81350\n",
            "Epoch 260/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6036 - acc: 0.8461 - val_loss: 0.8631 - val_acc: 0.7758\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.81350\n",
            "Epoch 261/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5922 - acc: 0.8498 - val_loss: 0.8021 - val_acc: 0.7858\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.81350\n",
            "Epoch 262/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5898 - acc: 0.8510 - val_loss: 0.8934 - val_acc: 0.7637\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.81350\n",
            "Epoch 263/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5888 - acc: 0.8466 - val_loss: 1.0904 - val_acc: 0.7158\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.81350\n",
            "Epoch 264/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6009 - acc: 0.8476 - val_loss: 0.9663 - val_acc: 0.7319\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.81350\n",
            "Epoch 265/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5977 - acc: 0.8449 - val_loss: 0.7776 - val_acc: 0.7928\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.81350\n",
            "Epoch 266/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6035 - acc: 0.8418 - val_loss: 0.7971 - val_acc: 0.7854\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.81350\n",
            "Epoch 267/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.6122 - acc: 0.8338 - val_loss: 0.8935 - val_acc: 0.7674\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.81350\n",
            "Epoch 268/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5758 - acc: 0.8482 - val_loss: 0.7350 - val_acc: 0.8096\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.81350\n",
            "Epoch 269/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.6051 - acc: 0.8389 - val_loss: 0.8074 - val_acc: 0.7704\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.81350\n",
            "Epoch 270/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6020 - acc: 0.8390 - val_loss: 0.8881 - val_acc: 0.7615\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.81350\n",
            "Epoch 271/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5756 - acc: 0.8520 - val_loss: 0.6999 - val_acc: 0.8121\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.81350\n",
            "Epoch 272/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5998 - acc: 0.8411 - val_loss: 0.8237 - val_acc: 0.7755\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.81350\n",
            "Epoch 273/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5764 - acc: 0.8514 - val_loss: 0.7415 - val_acc: 0.8040\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.81350\n",
            "Epoch 274/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5870 - acc: 0.8455 - val_loss: 0.8023 - val_acc: 0.7922\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.81350\n",
            "Epoch 275/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5601 - acc: 0.8585 - val_loss: 0.8085 - val_acc: 0.7888\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.81350\n",
            "Epoch 276/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5664 - acc: 0.8522 - val_loss: 0.8735 - val_acc: 0.7655\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.81350\n",
            "Epoch 277/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5851 - acc: 0.8371 - val_loss: 0.8623 - val_acc: 0.7726\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.81350\n",
            "Epoch 278/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5743 - acc: 0.8511 - val_loss: 1.0530 - val_acc: 0.7193\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.81350\n",
            "Epoch 279/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5775 - acc: 0.8483 - val_loss: 0.7202 - val_acc: 0.8084\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.81350\n",
            "Epoch 280/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5963 - acc: 0.8457 - val_loss: 0.8584 - val_acc: 0.7792\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.81350\n",
            "Epoch 281/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5799 - acc: 0.8529 - val_loss: 0.8088 - val_acc: 0.7933\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.81350\n",
            "Epoch 282/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5837 - acc: 0.8444 - val_loss: 1.2038 - val_acc: 0.6943\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.81350\n",
            "Epoch 283/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5677 - acc: 0.8572 - val_loss: 0.7875 - val_acc: 0.7933\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.81350\n",
            "Epoch 284/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5905 - acc: 0.8443 - val_loss: 1.1664 - val_acc: 0.7080\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.81350\n",
            "Epoch 285/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5684 - acc: 0.8513 - val_loss: 0.7821 - val_acc: 0.7949\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.81350\n",
            "Epoch 286/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.6059 - acc: 0.8420 - val_loss: 0.7268 - val_acc: 0.8064\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.81350\n",
            "Epoch 287/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5730 - acc: 0.8577 - val_loss: 0.8869 - val_acc: 0.7655\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.81350\n",
            "Epoch 288/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5725 - acc: 0.8504 - val_loss: 0.7589 - val_acc: 0.7924\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.81350\n",
            "Epoch 289/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5744 - acc: 0.8506 - val_loss: 0.9747 - val_acc: 0.7540\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.81350\n",
            "Epoch 290/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5675 - acc: 0.8516 - val_loss: 0.7929 - val_acc: 0.7858\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.81350\n",
            "Epoch 291/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5978 - acc: 0.8364 - val_loss: 1.0055 - val_acc: 0.7295\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.81350\n",
            "Epoch 292/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5651 - acc: 0.8513 - val_loss: 0.8224 - val_acc: 0.7778\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.81350\n",
            "Epoch 293/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5587 - acc: 0.8538 - val_loss: 0.8413 - val_acc: 0.7752\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.81350\n",
            "Epoch 294/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5775 - acc: 0.8480 - val_loss: 0.7038 - val_acc: 0.8176\n",
            "\n",
            "Epoch 00294: val_acc improved from 0.81350 to 0.81760, saving model to /content/saved_models/cifar10_ResNet32v1_model.294.h5\n",
            "Epoch 295/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5643 - acc: 0.8514 - val_loss: 1.0558 - val_acc: 0.7224\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.81760\n",
            "Epoch 296/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5836 - acc: 0.8452 - val_loss: 0.7880 - val_acc: 0.7874\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.81760\n",
            "Epoch 297/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5596 - acc: 0.8523 - val_loss: 1.0522 - val_acc: 0.7341\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.81760\n",
            "Epoch 298/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5792 - acc: 0.8504 - val_loss: 0.7841 - val_acc: 0.7998\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.81760\n",
            "Epoch 299/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5740 - acc: 0.8490 - val_loss: 0.8357 - val_acc: 0.7723\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.81760\n",
            "Epoch 300/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5599 - acc: 0.8509 - val_loss: 0.8203 - val_acc: 0.7864\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.81760\n",
            "Epoch 301/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5840 - acc: 0.8438 - val_loss: 0.9117 - val_acc: 0.7689\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.81760\n",
            "Epoch 302/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5641 - acc: 0.8511 - val_loss: 0.8056 - val_acc: 0.7862\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.81760\n",
            "Epoch 303/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5745 - acc: 0.8479 - val_loss: 0.7356 - val_acc: 0.8031\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.81760\n",
            "Epoch 304/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5588 - acc: 0.8563 - val_loss: 0.9465 - val_acc: 0.7567\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.81760\n",
            "Epoch 305/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5754 - acc: 0.8538 - val_loss: 0.8050 - val_acc: 0.7856\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.81760\n",
            "Epoch 306/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5861 - acc: 0.8498 - val_loss: 0.6757 - val_acc: 0.8204\n",
            "\n",
            "Epoch 00306: val_acc improved from 0.81760 to 0.82040, saving model to /content/saved_models/cifar10_ResNet32v1_model.306.h5\n",
            "Epoch 307/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5575 - acc: 0.8568 - val_loss: 0.9120 - val_acc: 0.7629\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.82040\n",
            "Epoch 308/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5712 - acc: 0.8500 - val_loss: 0.8467 - val_acc: 0.7740\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.82040\n",
            "Epoch 309/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5736 - acc: 0.8601 - val_loss: 0.8889 - val_acc: 0.7696\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.82040\n",
            "Epoch 310/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5554 - acc: 0.8615 - val_loss: 0.7818 - val_acc: 0.7854\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.82040\n",
            "Epoch 311/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5634 - acc: 0.8542 - val_loss: 0.7110 - val_acc: 0.8123\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.82040\n",
            "Epoch 312/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5625 - acc: 0.8542 - val_loss: 0.8159 - val_acc: 0.7877\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.82040\n",
            "Epoch 313/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5392 - acc: 0.8592 - val_loss: 0.9696 - val_acc: 0.7504\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.82040\n",
            "Epoch 314/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5732 - acc: 0.8480 - val_loss: 0.8902 - val_acc: 0.7677\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.82040\n",
            "Epoch 315/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5699 - acc: 0.8490 - val_loss: 0.7790 - val_acc: 0.7991\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.82040\n",
            "Epoch 316/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5478 - acc: 0.8651 - val_loss: 0.9665 - val_acc: 0.7365\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.82040\n",
            "Epoch 317/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5564 - acc: 0.8569 - val_loss: 0.7488 - val_acc: 0.7985\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.82040\n",
            "Epoch 318/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5462 - acc: 0.8610 - val_loss: 0.6906 - val_acc: 0.8255\n",
            "\n",
            "Epoch 00318: val_acc improved from 0.82040 to 0.82550, saving model to /content/saved_models/cifar10_ResNet32v1_model.318.h5\n",
            "Epoch 319/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5546 - acc: 0.8572 - val_loss: 0.9559 - val_acc: 0.7477\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.82550\n",
            "Epoch 320/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5484 - acc: 0.8632 - val_loss: 0.8089 - val_acc: 0.7755\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.82550\n",
            "Epoch 321/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5698 - acc: 0.8470 - val_loss: 1.0192 - val_acc: 0.7450\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.82550\n",
            "Epoch 322/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5429 - acc: 0.8560 - val_loss: 1.1879 - val_acc: 0.7171\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.82550\n",
            "Epoch 323/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5539 - acc: 0.8549 - val_loss: 0.7787 - val_acc: 0.7932\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.82550\n",
            "Epoch 324/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5671 - acc: 0.8508 - val_loss: 0.7596 - val_acc: 0.7980\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.82550\n",
            "Epoch 325/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5520 - acc: 0.8564 - val_loss: 0.8410 - val_acc: 0.7748\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.82550\n",
            "Epoch 326/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5445 - acc: 0.8595 - val_loss: 0.7985 - val_acc: 0.7860\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.82550\n",
            "Epoch 327/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5413 - acc: 0.8586 - val_loss: 0.9653 - val_acc: 0.7485\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.82550\n",
            "Epoch 328/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5632 - acc: 0.8537 - val_loss: 0.7724 - val_acc: 0.7924\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.82550\n",
            "Epoch 329/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5300 - acc: 0.8614 - val_loss: 1.0435 - val_acc: 0.7200\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.82550\n",
            "Epoch 330/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5628 - acc: 0.8535 - val_loss: 0.8391 - val_acc: 0.7801\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.82550\n",
            "Epoch 331/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5519 - acc: 0.8579 - val_loss: 1.2307 - val_acc: 0.6985\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.82550\n",
            "Epoch 332/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5534 - acc: 0.8536 - val_loss: 0.7883 - val_acc: 0.7924\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.82550\n",
            "Epoch 333/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5486 - acc: 0.8593 - val_loss: 0.8035 - val_acc: 0.7854\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.82550\n",
            "Epoch 334/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5518 - acc: 0.8533 - val_loss: 0.7793 - val_acc: 0.7971\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.82550\n",
            "Epoch 335/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5380 - acc: 0.8634 - val_loss: 0.6981 - val_acc: 0.8167\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.82550\n",
            "Epoch 336/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.5514 - acc: 0.8531 - val_loss: 1.0665 - val_acc: 0.7318\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.82550\n",
            "Epoch 337/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5455 - acc: 0.8602 - val_loss: 0.8293 - val_acc: 0.7683\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.82550\n",
            "Epoch 338/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5553 - acc: 0.8550 - val_loss: 0.7319 - val_acc: 0.7986\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.82550\n",
            "Epoch 339/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5415 - acc: 0.8593 - val_loss: 1.0229 - val_acc: 0.7564\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.82550\n",
            "Epoch 340/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5329 - acc: 0.8601 - val_loss: 0.6891 - val_acc: 0.8202\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.82550\n",
            "Epoch 341/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5399 - acc: 0.8594 - val_loss: 0.7861 - val_acc: 0.7808\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.82550\n",
            "Epoch 342/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5298 - acc: 0.8645 - val_loss: 0.8885 - val_acc: 0.7690\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.82550\n",
            "Epoch 343/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5305 - acc: 0.8588 - val_loss: 0.9778 - val_acc: 0.7408\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.82550\n",
            "Epoch 344/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5364 - acc: 0.8592 - val_loss: 0.8463 - val_acc: 0.7694\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.82550\n",
            "Epoch 345/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5498 - acc: 0.8526 - val_loss: 0.9477 - val_acc: 0.7425\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.82550\n",
            "Epoch 346/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5207 - acc: 0.8687 - val_loss: 0.9485 - val_acc: 0.7477\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.82550\n",
            "Epoch 347/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5388 - acc: 0.8573 - val_loss: 1.1993 - val_acc: 0.6985\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.82550\n",
            "Epoch 348/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5624 - acc: 0.8498 - val_loss: 0.7220 - val_acc: 0.8064\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.82550\n",
            "Epoch 349/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5292 - acc: 0.8650 - val_loss: 0.7530 - val_acc: 0.7990\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.82550\n",
            "Epoch 350/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5249 - acc: 0.8587 - val_loss: 0.8027 - val_acc: 0.7854\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.82550\n",
            "Epoch 351/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5320 - acc: 0.8598 - val_loss: 0.7058 - val_acc: 0.8116\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.82550\n",
            "Epoch 352/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5404 - acc: 0.8615 - val_loss: 0.8919 - val_acc: 0.7704\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.82550\n",
            "Epoch 353/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5376 - acc: 0.8564 - val_loss: 0.8963 - val_acc: 0.7623\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.82550\n",
            "Epoch 354/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5425 - acc: 0.8558 - val_loss: 0.7871 - val_acc: 0.7897\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.82550\n",
            "Epoch 355/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5411 - acc: 0.8591 - val_loss: 0.6969 - val_acc: 0.8153\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.82550\n",
            "Epoch 356/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5377 - acc: 0.8578 - val_loss: 0.8324 - val_acc: 0.7845\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.82550\n",
            "Epoch 357/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5276 - acc: 0.8664 - val_loss: 0.6848 - val_acc: 0.8130\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.82550\n",
            "Epoch 358/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5460 - acc: 0.8575 - val_loss: 0.8959 - val_acc: 0.7689\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.82550\n",
            "Epoch 359/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5359 - acc: 0.8604 - val_loss: 0.7736 - val_acc: 0.8013\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.82550\n",
            "Epoch 360/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5378 - acc: 0.8606 - val_loss: 0.9683 - val_acc: 0.7505\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.82550\n",
            "Epoch 361/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5549 - acc: 0.8516 - val_loss: 0.7114 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.82550\n",
            "Epoch 362/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5345 - acc: 0.8559 - val_loss: 0.8732 - val_acc: 0.7671\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.82550\n",
            "Epoch 363/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5356 - acc: 0.8605 - val_loss: 0.7907 - val_acc: 0.7965\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.82550\n",
            "Epoch 364/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5194 - acc: 0.8646 - val_loss: 0.8011 - val_acc: 0.7877\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.82550\n",
            "Epoch 365/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5304 - acc: 0.8636 - val_loss: 0.8485 - val_acc: 0.7742\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.82550\n",
            "Epoch 366/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5477 - acc: 0.8573 - val_loss: 0.7953 - val_acc: 0.7857\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.82550\n",
            "Epoch 367/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5274 - acc: 0.8615 - val_loss: 0.9380 - val_acc: 0.7683\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.82550\n",
            "Epoch 368/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5509 - acc: 0.8544 - val_loss: 0.7207 - val_acc: 0.8104\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.82550\n",
            "Epoch 369/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5091 - acc: 0.8728 - val_loss: 0.9622 - val_acc: 0.7417\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.82550\n",
            "Epoch 370/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5177 - acc: 0.8679 - val_loss: 0.6908 - val_acc: 0.8142\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.82550\n",
            "Epoch 371/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5395 - acc: 0.8612 - val_loss: 0.8201 - val_acc: 0.7827\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.82550\n",
            "Epoch 372/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5384 - acc: 0.8576 - val_loss: 0.7511 - val_acc: 0.7965\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.82550\n",
            "Epoch 373/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5551 - acc: 0.8541 - val_loss: 0.9332 - val_acc: 0.7703\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.82550\n",
            "Epoch 374/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5623 - acc: 0.8527 - val_loss: 0.6964 - val_acc: 0.8170\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.82550\n",
            "Epoch 375/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5233 - acc: 0.8655 - val_loss: 0.8374 - val_acc: 0.7775\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.82550\n",
            "Epoch 376/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5293 - acc: 0.8636 - val_loss: 1.0428 - val_acc: 0.7308\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.82550\n",
            "Epoch 377/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5338 - acc: 0.8613 - val_loss: 0.7336 - val_acc: 0.8066\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.82550\n",
            "Epoch 378/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5380 - acc: 0.8571 - val_loss: 0.6561 - val_acc: 0.8235\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.82550\n",
            "Epoch 379/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5356 - acc: 0.8603 - val_loss: 0.8243 - val_acc: 0.7848\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.82550\n",
            "Epoch 380/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5333 - acc: 0.8623 - val_loss: 0.8817 - val_acc: 0.7540\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.82550\n",
            "Epoch 381/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5257 - acc: 0.8641 - val_loss: 0.9058 - val_acc: 0.7697\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.82550\n",
            "Epoch 382/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5230 - acc: 0.8626 - val_loss: 0.7317 - val_acc: 0.8122\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.82550\n",
            "Epoch 383/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5222 - acc: 0.8638 - val_loss: 0.6662 - val_acc: 0.8206\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.82550\n",
            "Epoch 384/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5223 - acc: 0.8641 - val_loss: 0.7465 - val_acc: 0.8050\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.82550\n",
            "Epoch 385/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.5405 - acc: 0.8647 - val_loss: 0.8807 - val_acc: 0.7619\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.82550\n",
            "Epoch 386/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.5413 - acc: 0.8598 - val_loss: 0.8976 - val_acc: 0.7647\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.82550\n",
            "Epoch 387/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5153 - acc: 0.8644 - val_loss: 0.6572 - val_acc: 0.8278\n",
            "\n",
            "Epoch 00387: val_acc improved from 0.82550 to 0.82780, saving model to /content/saved_models/cifar10_ResNet32v1_model.387.h5\n",
            "Epoch 388/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5393 - acc: 0.8597 - val_loss: 0.8662 - val_acc: 0.7757\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.82780\n",
            "Epoch 389/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5173 - acc: 0.8632 - val_loss: 0.6655 - val_acc: 0.8258\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.82780\n",
            "Epoch 390/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5148 - acc: 0.8684 - val_loss: 0.7245 - val_acc: 0.8124\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.82780\n",
            "Epoch 391/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5379 - acc: 0.8616 - val_loss: 0.7531 - val_acc: 0.8040\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.82780\n",
            "Epoch 392/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5243 - acc: 0.8598 - val_loss: 1.1267 - val_acc: 0.7069\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.82780\n",
            "Epoch 393/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5341 - acc: 0.8612 - val_loss: 0.8448 - val_acc: 0.7900\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.82780\n",
            "Epoch 394/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5232 - acc: 0.8669 - val_loss: 0.8184 - val_acc: 0.7941\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.82780\n",
            "Epoch 395/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5241 - acc: 0.8663 - val_loss: 0.8464 - val_acc: 0.7803\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.82780\n",
            "Epoch 396/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.5198 - acc: 0.8639 - val_loss: 0.7246 - val_acc: 0.8072\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.82780\n",
            "Epoch 397/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5035 - acc: 0.8667 - val_loss: 0.7959 - val_acc: 0.7826\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.82780\n",
            "Epoch 398/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5031 - acc: 0.8671 - val_loss: 0.7723 - val_acc: 0.7964\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.82780\n",
            "Epoch 399/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5128 - acc: 0.8667 - val_loss: 0.7545 - val_acc: 0.7946\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.82780\n",
            "Epoch 400/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.5291 - acc: 0.8612 - val_loss: 0.7197 - val_acc: 0.8019\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.82780\n",
            "Epoch 401/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5207 - acc: 0.8670 - val_loss: 0.6962 - val_acc: 0.8200\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.82780\n",
            "Epoch 402/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5226 - acc: 0.8671 - val_loss: 0.5747 - val_acc: 0.8533\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.82780 to 0.85330, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4690 - acc: 0.8814 - val_loss: 0.5764 - val_acc: 0.8531\n",
            "\n",
            "Epoch 00403: val_acc did not improve from 0.85330\n",
            "Epoch 404/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4627 - acc: 0.8886 - val_loss: 0.5651 - val_acc: 0.8541\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.85330 to 0.85410, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4505 - acc: 0.8891 - val_loss: 0.5668 - val_acc: 0.8548\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.85410 to 0.85480, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4490 - acc: 0.8880 - val_loss: 0.5691 - val_acc: 0.8550\n",
            "\n",
            "Epoch 00406: val_acc improved from 0.85480 to 0.85500, saving model to /content/saved_models/cifar10_ResNet32v1_model.406.h5\n",
            "Epoch 407/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4512 - acc: 0.8920 - val_loss: 0.5677 - val_acc: 0.8546\n",
            "\n",
            "Epoch 00407: val_acc did not improve from 0.85500\n",
            "Epoch 408/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4627 - acc: 0.8869 - val_loss: 0.5530 - val_acc: 0.8585\n",
            "\n",
            "Epoch 00408: val_acc improved from 0.85500 to 0.85850, saving model to /content/saved_models/cifar10_ResNet32v1_model.408.h5\n",
            "Epoch 409/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4450 - acc: 0.8891 - val_loss: 0.5675 - val_acc: 0.8561\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.85850\n",
            "Epoch 410/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4394 - acc: 0.8920 - val_loss: 0.5799 - val_acc: 0.8482\n",
            "\n",
            "Epoch 00410: val_acc did not improve from 0.85850\n",
            "Epoch 411/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4555 - acc: 0.8907 - val_loss: 0.5449 - val_acc: 0.8637\n",
            "\n",
            "Epoch 00411: val_acc improved from 0.85850 to 0.86370, saving model to /content/saved_models/cifar10_ResNet32v1_model.411.h5\n",
            "Epoch 412/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4369 - acc: 0.8969 - val_loss: 0.5551 - val_acc: 0.8587\n",
            "\n",
            "Epoch 00412: val_acc did not improve from 0.86370\n",
            "Epoch 413/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4300 - acc: 0.8983 - val_loss: 0.5639 - val_acc: 0.8574\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.86370\n",
            "Epoch 414/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4233 - acc: 0.8969 - val_loss: 0.5446 - val_acc: 0.8622\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.86370\n",
            "Epoch 415/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4318 - acc: 0.8995 - val_loss: 0.5573 - val_acc: 0.8608\n",
            "\n",
            "Epoch 00415: val_acc did not improve from 0.86370\n",
            "Epoch 416/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4444 - acc: 0.8911 - val_loss: 0.5638 - val_acc: 0.8559\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.86370\n",
            "Epoch 417/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4371 - acc: 0.8910 - val_loss: 0.5508 - val_acc: 0.8604\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.86370\n",
            "Epoch 418/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4494 - acc: 0.8894 - val_loss: 0.5552 - val_acc: 0.8605\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.86370\n",
            "Epoch 419/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4285 - acc: 0.8951 - val_loss: 0.5477 - val_acc: 0.8587\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.86370\n",
            "Epoch 420/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4274 - acc: 0.8975 - val_loss: 0.5487 - val_acc: 0.8607\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.86370\n",
            "Epoch 421/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4112 - acc: 0.9031 - val_loss: 0.5431 - val_acc: 0.8615\n",
            "\n",
            "Epoch 00421: val_acc did not improve from 0.86370\n",
            "Epoch 422/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4293 - acc: 0.9007 - val_loss: 0.5370 - val_acc: 0.8660\n",
            "\n",
            "Epoch 00422: val_acc improved from 0.86370 to 0.86600, saving model to /content/saved_models/cifar10_ResNet32v1_model.422.h5\n",
            "Epoch 423/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4194 - acc: 0.9070 - val_loss: 0.5388 - val_acc: 0.8655\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.86600\n",
            "Epoch 424/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4071 - acc: 0.9010 - val_loss: 0.5414 - val_acc: 0.8603\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.86600\n",
            "Epoch 425/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4315 - acc: 0.8983 - val_loss: 0.5474 - val_acc: 0.8621\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.86600\n",
            "Epoch 426/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4184 - acc: 0.8992 - val_loss: 0.5529 - val_acc: 0.8593\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.86600\n",
            "Epoch 427/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4207 - acc: 0.8994 - val_loss: 0.5751 - val_acc: 0.8522\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.86600\n",
            "Epoch 428/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4142 - acc: 0.9002 - val_loss: 0.5495 - val_acc: 0.8616\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.86600\n",
            "Epoch 429/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4265 - acc: 0.8948 - val_loss: 0.5445 - val_acc: 0.8660\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.86600\n",
            "Epoch 430/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4150 - acc: 0.8999 - val_loss: 0.5425 - val_acc: 0.8637\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.86600\n",
            "Epoch 431/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4339 - acc: 0.8963 - val_loss: 0.5382 - val_acc: 0.8664\n",
            "\n",
            "Epoch 00431: val_acc improved from 0.86600 to 0.86640, saving model to /content/saved_models/cifar10_ResNet32v1_model.431.h5\n",
            "Epoch 432/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4276 - acc: 0.8929 - val_loss: 0.5491 - val_acc: 0.8608\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.86640\n",
            "Epoch 433/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4298 - acc: 0.8982 - val_loss: 0.5460 - val_acc: 0.8638\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.86640\n",
            "Epoch 434/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4100 - acc: 0.9040 - val_loss: 0.5465 - val_acc: 0.8615\n",
            "\n",
            "Epoch 00434: val_acc did not improve from 0.86640\n",
            "Epoch 435/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4230 - acc: 0.8950 - val_loss: 0.5613 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.86640\n",
            "Epoch 436/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4168 - acc: 0.9030 - val_loss: 0.5471 - val_acc: 0.8604\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.86640\n",
            "Epoch 437/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4058 - acc: 0.9079 - val_loss: 0.5571 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.86640\n",
            "Epoch 438/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4012 - acc: 0.9028 - val_loss: 0.5571 - val_acc: 0.8602\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.86640\n",
            "Epoch 439/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4103 - acc: 0.9050 - val_loss: 0.5513 - val_acc: 0.8613\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.86640\n",
            "Epoch 440/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4144 - acc: 0.9010 - val_loss: 0.5633 - val_acc: 0.8599\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.86640\n",
            "Epoch 441/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4130 - acc: 0.9035 - val_loss: 0.5457 - val_acc: 0.8643\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.86640\n",
            "Epoch 442/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4126 - acc: 0.9014 - val_loss: 0.5604 - val_acc: 0.8564\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.86640\n",
            "Epoch 443/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4098 - acc: 0.9034 - val_loss: 0.5580 - val_acc: 0.8586\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.86640\n",
            "Epoch 444/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4270 - acc: 0.8975 - val_loss: 0.5408 - val_acc: 0.8631\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.86640\n",
            "Epoch 445/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4086 - acc: 0.8999 - val_loss: 0.5403 - val_acc: 0.8639\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.86640\n",
            "Epoch 446/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4080 - acc: 0.9032 - val_loss: 0.5461 - val_acc: 0.8642\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.86640\n",
            "Epoch 447/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4209 - acc: 0.8999 - val_loss: 0.5582 - val_acc: 0.8584\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.86640\n",
            "Epoch 448/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4117 - acc: 0.9021 - val_loss: 0.5600 - val_acc: 0.8587\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.86640\n",
            "Epoch 449/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4299 - acc: 0.8964 - val_loss: 0.5613 - val_acc: 0.8572\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.86640\n",
            "Epoch 450/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4183 - acc: 0.8970 - val_loss: 0.5465 - val_acc: 0.8639\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.86640\n",
            "Epoch 451/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4106 - acc: 0.9057 - val_loss: 0.5642 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.86640\n",
            "Epoch 452/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4067 - acc: 0.9009 - val_loss: 0.5657 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.86640\n",
            "Epoch 453/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4200 - acc: 0.9009 - val_loss: 0.5630 - val_acc: 0.8565\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.86640\n",
            "Epoch 454/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4108 - acc: 0.9011 - val_loss: 0.5624 - val_acc: 0.8582\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.86640\n",
            "Epoch 455/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4070 - acc: 0.9038 - val_loss: 0.5470 - val_acc: 0.8602\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.86640\n",
            "Epoch 456/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4172 - acc: 0.8999 - val_loss: 0.5343 - val_acc: 0.8659\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.86640\n",
            "Epoch 457/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4227 - acc: 0.8929 - val_loss: 0.5585 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.86640\n",
            "Epoch 458/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4000 - acc: 0.9063 - val_loss: 0.5476 - val_acc: 0.8632\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.86640\n",
            "Epoch 459/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4261 - acc: 0.8996 - val_loss: 0.5622 - val_acc: 0.8589\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.86640\n",
            "Epoch 460/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4084 - acc: 0.9005 - val_loss: 0.5483 - val_acc: 0.8602\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.86640\n",
            "Epoch 461/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4355 - acc: 0.8935 - val_loss: 0.5304 - val_acc: 0.8669\n",
            "\n",
            "Epoch 00461: val_acc improved from 0.86640 to 0.86690, saving model to /content/saved_models/cifar10_ResNet32v1_model.461.h5\n",
            "Epoch 462/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4150 - acc: 0.8971 - val_loss: 0.5593 - val_acc: 0.8603\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.86690\n",
            "Epoch 463/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4277 - acc: 0.8954 - val_loss: 0.5569 - val_acc: 0.8586\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.86690\n",
            "Epoch 464/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3879 - acc: 0.9124 - val_loss: 0.5487 - val_acc: 0.8583\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.86690\n",
            "Epoch 465/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4032 - acc: 0.9049 - val_loss: 0.5396 - val_acc: 0.8639\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.86690\n",
            "Epoch 466/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4109 - acc: 0.9016 - val_loss: 0.5459 - val_acc: 0.8612\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.86690\n",
            "Epoch 467/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4162 - acc: 0.9039 - val_loss: 0.5440 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.86690\n",
            "Epoch 468/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4107 - acc: 0.9037 - val_loss: 0.5433 - val_acc: 0.8631\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.86690\n",
            "Epoch 469/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4114 - acc: 0.9009 - val_loss: 0.5596 - val_acc: 0.8599\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.86690\n",
            "Epoch 470/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4183 - acc: 0.8979 - val_loss: 0.5462 - val_acc: 0.8621\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.86690\n",
            "Epoch 471/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4040 - acc: 0.9064 - val_loss: 0.5628 - val_acc: 0.8613\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.86690\n",
            "Epoch 472/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4186 - acc: 0.8950 - val_loss: 0.5690 - val_acc: 0.8561\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.86690\n",
            "Epoch 473/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4183 - acc: 0.9006 - val_loss: 0.5466 - val_acc: 0.8634\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.86690\n",
            "Epoch 474/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4130 - acc: 0.9013 - val_loss: 0.5663 - val_acc: 0.8590\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.86690\n",
            "Epoch 475/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.3997 - acc: 0.9049 - val_loss: 0.5492 - val_acc: 0.8603\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.86690\n",
            "Epoch 476/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.3984 - acc: 0.8993 - val_loss: 0.5486 - val_acc: 0.8628\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.86690\n",
            "Epoch 477/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4123 - acc: 0.9013 - val_loss: 0.5660 - val_acc: 0.8576\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.86690\n",
            "Epoch 478/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.3953 - acc: 0.9036 - val_loss: 0.5429 - val_acc: 0.8670\n",
            "\n",
            "Epoch 00478: val_acc improved from 0.86690 to 0.86700, saving model to /content/saved_models/cifar10_ResNet32v1_model.478.h5\n",
            "Epoch 479/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4127 - acc: 0.8961 - val_loss: 0.5474 - val_acc: 0.8636\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.86700\n",
            "Epoch 480/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4018 - acc: 0.9030 - val_loss: 0.5524 - val_acc: 0.8617\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.86700\n",
            "Epoch 481/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.3998 - acc: 0.9021 - val_loss: 0.5501 - val_acc: 0.8631\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.86700\n",
            "Epoch 482/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4039 - acc: 0.9014 - val_loss: 0.5389 - val_acc: 0.8659\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.86700\n",
            "Epoch 483/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.4114 - acc: 0.8992 - val_loss: 0.5444 - val_acc: 0.8628\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.86700\n",
            "Epoch 484/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.3979 - acc: 0.9051 - val_loss: 0.5757 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.86700\n",
            "Epoch 485/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4130 - acc: 0.9003 - val_loss: 0.5509 - val_acc: 0.8628\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.86700\n",
            "Epoch 486/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4099 - acc: 0.8994 - val_loss: 0.5374 - val_acc: 0.8654\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.86700\n",
            "Epoch 487/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.3964 - acc: 0.9047 - val_loss: 0.5436 - val_acc: 0.8638\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.86700\n",
            "Epoch 488/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4061 - acc: 0.9013 - val_loss: 0.5513 - val_acc: 0.8616\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.86700\n",
            "Epoch 489/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.4006 - acc: 0.9047 - val_loss: 0.5473 - val_acc: 0.8646\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.86700\n",
            "Epoch 490/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4127 - acc: 0.8995 - val_loss: 0.5493 - val_acc: 0.8608\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.86700\n",
            "Epoch 491/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.3914 - acc: 0.9075 - val_loss: 0.5538 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.86700\n",
            "Epoch 492/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.4176 - acc: 0.8990 - val_loss: 0.5547 - val_acc: 0.8631\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.86700\n",
            "Epoch 493/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.4104 - acc: 0.8999 - val_loss: 0.5598 - val_acc: 0.8588\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.86700\n",
            "Epoch 494/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4038 - acc: 0.9040 - val_loss: 0.5461 - val_acc: 0.8614\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.86700\n",
            "Epoch 495/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.4063 - acc: 0.9020 - val_loss: 0.5461 - val_acc: 0.8645\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.86700\n",
            "Epoch 496/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.3929 - acc: 0.9099 - val_loss: 0.5574 - val_acc: 0.8613\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.86700\n",
            "Epoch 497/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3986 - acc: 0.9075 - val_loss: 0.5948 - val_acc: 0.8522\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.86700\n",
            "Epoch 498/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.4014 - acc: 0.9058 - val_loss: 0.5388 - val_acc: 0.8657\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.86700\n",
            "Epoch 499/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4032 - acc: 0.9042 - val_loss: 0.5441 - val_acc: 0.8626\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.86700\n",
            "Epoch 500/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3967 - acc: 0.9103 - val_loss: 0.5616 - val_acc: 0.8624\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.86700\n",
            "Epoch 501/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3993 - acc: 0.9078 - val_loss: 0.5689 - val_acc: 0.8604\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.86700\n",
            "Epoch 502/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3800 - acc: 0.9105 - val_loss: 0.5560 - val_acc: 0.8602\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.86700\n",
            "Epoch 503/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3918 - acc: 0.9085 - val_loss: 0.5469 - val_acc: 0.8621\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.86700\n",
            "Epoch 504/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4122 - acc: 0.9022 - val_loss: 0.5582 - val_acc: 0.8615\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.86700\n",
            "Epoch 505/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.4258 - acc: 0.8933 - val_loss: 0.5421 - val_acc: 0.8655\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.86700\n",
            "Epoch 506/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3986 - acc: 0.9049 - val_loss: 0.5815 - val_acc: 0.8524\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.86700\n",
            "Epoch 507/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4020 - acc: 0.9034 - val_loss: 0.5469 - val_acc: 0.8653\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.86700\n",
            "Epoch 508/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3994 - acc: 0.9052 - val_loss: 0.5407 - val_acc: 0.8629\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.86700\n",
            "Epoch 509/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.4170 - acc: 0.8979 - val_loss: 0.5487 - val_acc: 0.8620\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.86700\n",
            "Epoch 510/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3898 - acc: 0.9119 - val_loss: 0.5464 - val_acc: 0.8623\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.86700\n",
            "Epoch 511/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3993 - acc: 0.8999 - val_loss: 0.5495 - val_acc: 0.8626\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.86700\n",
            "Epoch 512/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4059 - acc: 0.8980 - val_loss: 0.5527 - val_acc: 0.8631\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.86700\n",
            "Epoch 513/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3913 - acc: 0.9076 - val_loss: 0.5520 - val_acc: 0.8611\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.86700\n",
            "Epoch 514/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3824 - acc: 0.9150 - val_loss: 0.5529 - val_acc: 0.8641\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.86700\n",
            "Epoch 515/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3950 - acc: 0.9071 - val_loss: 0.5528 - val_acc: 0.8625\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.86700\n",
            "Epoch 516/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3900 - acc: 0.9067 - val_loss: 0.5464 - val_acc: 0.8625\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.86700\n",
            "Epoch 517/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3896 - acc: 0.9154 - val_loss: 0.5508 - val_acc: 0.8618\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.86700\n",
            "Epoch 518/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3943 - acc: 0.9033 - val_loss: 0.5356 - val_acc: 0.8663\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.86700\n",
            "Epoch 519/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3943 - acc: 0.9087 - val_loss: 0.5399 - val_acc: 0.8660\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.86700\n",
            "Epoch 520/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3862 - acc: 0.9111 - val_loss: 0.5602 - val_acc: 0.8609\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.86700\n",
            "Epoch 521/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4024 - acc: 0.8997 - val_loss: 0.5337 - val_acc: 0.8673\n",
            "\n",
            "Epoch 00521: val_acc improved from 0.86700 to 0.86730, saving model to /content/saved_models/cifar10_ResNet32v1_model.521.h5\n",
            "Epoch 522/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4046 - acc: 0.9058 - val_loss: 0.5466 - val_acc: 0.8630\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.86730\n",
            "Epoch 523/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3772 - acc: 0.9122 - val_loss: 0.5531 - val_acc: 0.8643\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.86730\n",
            "Epoch 524/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3831 - acc: 0.9107 - val_loss: 0.5490 - val_acc: 0.8652\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.86730\n",
            "Epoch 525/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4051 - acc: 0.8999 - val_loss: 0.5756 - val_acc: 0.8549\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.86730\n",
            "Epoch 526/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3821 - acc: 0.9119 - val_loss: 0.5506 - val_acc: 0.8641\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.86730\n",
            "Epoch 527/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3857 - acc: 0.9114 - val_loss: 0.5499 - val_acc: 0.8627\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.86730\n",
            "Epoch 528/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3849 - acc: 0.9087 - val_loss: 0.5474 - val_acc: 0.8640\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.86730\n",
            "Epoch 529/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3886 - acc: 0.9089 - val_loss: 0.5437 - val_acc: 0.8672\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.86730\n",
            "Epoch 530/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3996 - acc: 0.9041 - val_loss: 0.5389 - val_acc: 0.8645\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.86730\n",
            "Epoch 531/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4098 - acc: 0.9038 - val_loss: 0.5372 - val_acc: 0.8665\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.86730\n",
            "Epoch 532/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3960 - acc: 0.9065 - val_loss: 0.5467 - val_acc: 0.8651\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.86730\n",
            "Epoch 533/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3896 - acc: 0.9072 - val_loss: 0.5554 - val_acc: 0.8621\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.86730\n",
            "Epoch 534/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3816 - acc: 0.9112 - val_loss: 0.5578 - val_acc: 0.8641\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.86730\n",
            "Epoch 535/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3765 - acc: 0.9121 - val_loss: 0.5562 - val_acc: 0.8589\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.86730\n",
            "Epoch 536/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4125 - acc: 0.9025 - val_loss: 0.5449 - val_acc: 0.8656\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.86730\n",
            "Epoch 537/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3863 - acc: 0.9066 - val_loss: 0.5633 - val_acc: 0.8587\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.86730\n",
            "Epoch 538/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4026 - acc: 0.9027 - val_loss: 0.5385 - val_acc: 0.8627\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.86730\n",
            "Epoch 539/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3938 - acc: 0.9058 - val_loss: 0.5585 - val_acc: 0.8617\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.86730\n",
            "Epoch 540/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4042 - acc: 0.9024 - val_loss: 0.5619 - val_acc: 0.8588\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.86730\n",
            "Epoch 541/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3811 - acc: 0.9079 - val_loss: 0.5418 - val_acc: 0.8689\n",
            "\n",
            "Epoch 00541: val_acc improved from 0.86730 to 0.86890, saving model to /content/saved_models/cifar10_ResNet32v1_model.541.h5\n",
            "Epoch 542/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3795 - acc: 0.9103 - val_loss: 0.5660 - val_acc: 0.8596\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.86890\n",
            "Epoch 543/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3872 - acc: 0.9103 - val_loss: 0.5457 - val_acc: 0.8653\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.86890\n",
            "Epoch 544/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4062 - acc: 0.9077 - val_loss: 0.5493 - val_acc: 0.8614\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.86890\n",
            "Epoch 545/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3924 - acc: 0.9103 - val_loss: 0.5532 - val_acc: 0.8622\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.86890\n",
            "Epoch 546/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.3814 - acc: 0.9074 - val_loss: 0.5397 - val_acc: 0.8641\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.86890\n",
            "Epoch 547/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.3886 - acc: 0.9082 - val_loss: 0.5400 - val_acc: 0.8656\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.86890\n",
            "Epoch 548/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3763 - acc: 0.9124 - val_loss: 0.5456 - val_acc: 0.8654\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.86890\n",
            "Epoch 549/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3979 - acc: 0.8989 - val_loss: 0.5467 - val_acc: 0.8640\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.86890\n",
            "Epoch 550/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3739 - acc: 0.9141 - val_loss: 0.5710 - val_acc: 0.8578\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.86890\n",
            "Epoch 551/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3832 - acc: 0.9081 - val_loss: 0.5544 - val_acc: 0.8640\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.86890\n",
            "Epoch 552/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4005 - acc: 0.9012 - val_loss: 0.5435 - val_acc: 0.8650\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.86890\n",
            "Epoch 553/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4073 - acc: 0.9050 - val_loss: 0.5545 - val_acc: 0.8595\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.86890\n",
            "Epoch 554/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3881 - acc: 0.9055 - val_loss: 0.5394 - val_acc: 0.8654\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.86890\n",
            "Epoch 555/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4080 - acc: 0.9008 - val_loss: 0.5427 - val_acc: 0.8665\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.86890\n",
            "Epoch 556/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.3785 - acc: 0.9144 - val_loss: 0.5481 - val_acc: 0.8639\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.86890\n",
            "Epoch 557/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3950 - acc: 0.9038 - val_loss: 0.5457 - val_acc: 0.8637\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.86890\n",
            "Epoch 558/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3991 - acc: 0.9046 - val_loss: 0.5386 - val_acc: 0.8669\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.86890\n",
            "Epoch 559/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3968 - acc: 0.9065 - val_loss: 0.5442 - val_acc: 0.8643\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.86890\n",
            "Epoch 560/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3835 - acc: 0.9102 - val_loss: 0.5691 - val_acc: 0.8563\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.86890\n",
            "Epoch 561/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3823 - acc: 0.9088 - val_loss: 0.5459 - val_acc: 0.8630\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.86890\n",
            "Epoch 562/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3897 - acc: 0.9108 - val_loss: 0.5491 - val_acc: 0.8649\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.86890\n",
            "Epoch 563/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4044 - acc: 0.9033 - val_loss: 0.5379 - val_acc: 0.8656\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.86890\n",
            "Epoch 564/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3972 - acc: 0.9039 - val_loss: 0.5862 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.86890\n",
            "Epoch 565/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4005 - acc: 0.9029 - val_loss: 0.5524 - val_acc: 0.8624\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.86890\n",
            "Epoch 566/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3952 - acc: 0.9069 - val_loss: 0.5642 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.86890\n",
            "Epoch 567/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3911 - acc: 0.9091 - val_loss: 0.5405 - val_acc: 0.8634\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.86890\n",
            "Epoch 568/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3874 - acc: 0.9062 - val_loss: 0.5319 - val_acc: 0.8689\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.86890\n",
            "Epoch 569/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3782 - acc: 0.9132 - val_loss: 0.5444 - val_acc: 0.8648\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.86890\n",
            "Epoch 570/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3958 - acc: 0.9012 - val_loss: 0.5555 - val_acc: 0.8609\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.86890\n",
            "Epoch 571/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3983 - acc: 0.9006 - val_loss: 0.5575 - val_acc: 0.8592\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.86890\n",
            "Epoch 572/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3893 - acc: 0.9079 - val_loss: 0.5483 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.86890\n",
            "Epoch 573/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3989 - acc: 0.9088 - val_loss: 0.5476 - val_acc: 0.8629\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.86890\n",
            "Epoch 574/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3896 - acc: 0.9073 - val_loss: 0.5367 - val_acc: 0.8654\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.86890\n",
            "Epoch 575/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3905 - acc: 0.9025 - val_loss: 0.5291 - val_acc: 0.8649\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.86890\n",
            "Epoch 576/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3836 - acc: 0.9100 - val_loss: 0.5344 - val_acc: 0.8674\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.86890\n",
            "Epoch 577/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3948 - acc: 0.9014 - val_loss: 0.5362 - val_acc: 0.8665\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.86890\n",
            "Epoch 578/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3900 - acc: 0.9058 - val_loss: 0.5361 - val_acc: 0.8671\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.86890\n",
            "Epoch 579/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3867 - acc: 0.9073 - val_loss: 0.5450 - val_acc: 0.8635\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.86890\n",
            "Epoch 580/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3820 - acc: 0.9101 - val_loss: 0.5831 - val_acc: 0.8536\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.86890\n",
            "Epoch 581/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3940 - acc: 0.9054 - val_loss: 0.5416 - val_acc: 0.8638\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.86890\n",
            "Epoch 582/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3767 - acc: 0.9111 - val_loss: 0.5557 - val_acc: 0.8646\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.86890\n",
            "Epoch 583/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3606 - acc: 0.9179 - val_loss: 0.5427 - val_acc: 0.8655\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.86890\n",
            "Epoch 584/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3913 - acc: 0.9085 - val_loss: 0.5425 - val_acc: 0.8655\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.86890\n",
            "Epoch 585/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3820 - acc: 0.9096 - val_loss: 0.5330 - val_acc: 0.8692\n",
            "\n",
            "Epoch 00585: val_acc improved from 0.86890 to 0.86920, saving model to /content/saved_models/cifar10_ResNet32v1_model.585.h5\n",
            "Epoch 586/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.4037 - acc: 0.8997 - val_loss: 0.5670 - val_acc: 0.8576\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.86920\n",
            "Epoch 587/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3761 - acc: 0.9083 - val_loss: 0.5523 - val_acc: 0.8630\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.86920\n",
            "Epoch 588/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3916 - acc: 0.9031 - val_loss: 0.5347 - val_acc: 0.8653\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.86920\n",
            "Epoch 589/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3849 - acc: 0.9090 - val_loss: 0.5428 - val_acc: 0.8618\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.86920\n",
            "Epoch 590/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3907 - acc: 0.9093 - val_loss: 0.5497 - val_acc: 0.8641\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.86920\n",
            "Epoch 591/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.3831 - acc: 0.9074 - val_loss: 0.5578 - val_acc: 0.8600\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.86920\n",
            "Epoch 592/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3865 - acc: 0.9065 - val_loss: 0.5439 - val_acc: 0.8644\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.86920\n",
            "Epoch 593/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3768 - acc: 0.9099 - val_loss: 0.5541 - val_acc: 0.8624\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.86920\n",
            "Epoch 594/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3815 - acc: 0.9086 - val_loss: 0.5586 - val_acc: 0.8583\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.86920\n",
            "Epoch 595/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3721 - acc: 0.9133 - val_loss: 0.5563 - val_acc: 0.8610\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.86920\n",
            "Epoch 596/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4025 - acc: 0.8995 - val_loss: 0.5596 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.86920\n",
            "Epoch 597/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3818 - acc: 0.9058 - val_loss: 0.5528 - val_acc: 0.8603\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.86920\n",
            "Epoch 598/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3776 - acc: 0.9130 - val_loss: 0.5476 - val_acc: 0.8657\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.86920\n",
            "Epoch 599/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3806 - acc: 0.9067 - val_loss: 0.5529 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.86920\n",
            "Epoch 600/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3885 - acc: 0.9062 - val_loss: 0.5537 - val_acc: 0.8649\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.86920\n",
            "Epoch 601/1000\n",
            "Learning rate:  0.0001\n",
            " 72/100 [====================>.........] - ETA: 1s - loss: 0.3790 - acc: 0.9037"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "Oc2AMbVWiRd2",
        "outputId": "68493db2-47b7-40b3-c965-cf92697aa446"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('R_10_trainHistoryDict', \"rb\"))\n",
        "functions.plot_loss_acc(history, 4, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4m7N9mKyQCj",
        "outputId": "5d5ec2da-757a-46cd-a2d1-4e5c012a104f"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13679999113082886"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "W6rihzPXgrmk",
        "outputId": "b25faad7-6b77-4877-9f44-5421e3f37ffd"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('R_10_trainHistoryDict', \"rb\"))\n",
        "functions.plot_loss_acc(history, 4, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXrcbT5Sgy70",
        "outputId": "04969bb5-9cd1-415b-abed-6421e6803e52"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19609999656677246"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHouYL-KnawQ"
      },
      "source": [
        "#### Model with clipping to 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jiu6AXYlnZU1",
        "outputId": "5b0b7ba1-6e03-4760-d432-0e9b98375d14"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(\n",
        "    input_shape, conv_layer = functions.ConvDecomposed2D, decomposition_rank=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjUY8RUenf6I",
        "outputId": "f3c059c8-2bd0-4265-cf3e-51b8da477d9b"
      },
      "source": [
        "callbacks = functions.standard_callbacks(model_type) + [functions.Clipping(0.5)]\n",
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'R_10_trainHistoryDict_clip_05', steps_per_epoch=100,\n",
        "                       batch_size=100, epochs=500,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 49s 101ms/step - loss: 4.8202 - acc: 0.1309 - val_loss: 10.7019 - val_acc: 0.1046\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.10460, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 2.1939 - acc: 0.1986 - val_loss: 2.3995 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.10460\n",
            "Epoch 3/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.8520 - acc: 0.3308 - val_loss: 2.4127 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.10460\n",
            "Epoch 4/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.7193 - acc: 0.3862 - val_loss: 2.5158 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.10460\n",
            "Epoch 5/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.6631 - acc: 0.4039 - val_loss: 2.8510 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.10460\n",
            "Epoch 6/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.6056 - acc: 0.4297 - val_loss: 3.3480 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.10460\n",
            "Epoch 7/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.5243 - acc: 0.4642 - val_loss: 3.0504 - val_acc: 0.1115\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.10460 to 0.11150, saving model to /content/saved_models/cifar10_ResNet32v1_model.007.h5\n",
            "Epoch 8/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.4974 - acc: 0.4790 - val_loss: 1.5990 - val_acc: 0.4541\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.11150 to 0.45410, saving model to /content/saved_models/cifar10_ResNet32v1_model.008.h5\n",
            "Epoch 9/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4653 - acc: 0.4876 - val_loss: 1.8396 - val_acc: 0.3931\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.45410\n",
            "Epoch 10/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4123 - acc: 0.5016 - val_loss: 3.3709 - val_acc: 0.2693\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.45410\n",
            "Epoch 11/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.4023 - acc: 0.5177 - val_loss: 2.4009 - val_acc: 0.3769\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.45410\n",
            "Epoch 12/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.3232 - acc: 0.5514 - val_loss: 1.9533 - val_acc: 0.4132\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.45410\n",
            "Epoch 13/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.2948 - acc: 0.5569 - val_loss: 2.4385 - val_acc: 0.3670\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.45410\n",
            "Epoch 14/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.2699 - acc: 0.5733 - val_loss: 3.7462 - val_acc: 0.3003\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.45410\n",
            "Epoch 15/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.2521 - acc: 0.5701 - val_loss: 4.1610 - val_acc: 0.2915\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.45410\n",
            "Epoch 16/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.2015 - acc: 0.5930 - val_loss: 2.4023 - val_acc: 0.4021\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.45410\n",
            "Epoch 17/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.1962 - acc: 0.5989 - val_loss: 3.4275 - val_acc: 0.3593\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.45410\n",
            "Epoch 18/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.1465 - acc: 0.6142 - val_loss: 2.1139 - val_acc: 0.4248\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.45410\n",
            "Epoch 19/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.1158 - acc: 0.6284 - val_loss: 2.0379 - val_acc: 0.4520\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.45410\n",
            "Epoch 20/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.1267 - acc: 0.6216 - val_loss: 1.9196 - val_acc: 0.4747\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.45410 to 0.47470, saving model to /content/saved_models/cifar10_ResNet32v1_model.020.h5\n",
            "Epoch 21/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.0879 - acc: 0.6455 - val_loss: 1.6880 - val_acc: 0.5215\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.47470 to 0.52150, saving model to /content/saved_models/cifar10_ResNet32v1_model.021.h5\n",
            "Epoch 22/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.0823 - acc: 0.6463 - val_loss: 1.5496 - val_acc: 0.5383\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.52150 to 0.53830, saving model to /content/saved_models/cifar10_ResNet32v1_model.022.h5\n",
            "Epoch 23/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.0519 - acc: 0.6494 - val_loss: 2.5672 - val_acc: 0.3933\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.53830\n",
            "Epoch 24/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.0400 - acc: 0.6653 - val_loss: 1.9450 - val_acc: 0.4568\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.53830\n",
            "Epoch 25/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.0022 - acc: 0.6764 - val_loss: 2.7733 - val_acc: 0.4126\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.53830\n",
            "Epoch 26/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.0260 - acc: 0.6641 - val_loss: 2.1407 - val_acc: 0.4857\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.53830\n",
            "Epoch 27/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 1.0136 - acc: 0.6638 - val_loss: 1.5518 - val_acc: 0.5704\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.53830 to 0.57040, saving model to /content/saved_models/cifar10_ResNet32v1_model.027.h5\n",
            "Epoch 28/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.9892 - acc: 0.6739 - val_loss: 1.5664 - val_acc: 0.5501\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.57040\n",
            "Epoch 29/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.9748 - acc: 0.6830 - val_loss: 1.7351 - val_acc: 0.5198\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.57040\n",
            "Epoch 30/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.9796 - acc: 0.6860 - val_loss: 1.7322 - val_acc: 0.5353\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.57040\n",
            "Epoch 31/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.9855 - acc: 0.6877 - val_loss: 2.1566 - val_acc: 0.4762\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.57040\n",
            "Epoch 32/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.9716 - acc: 0.6859 - val_loss: 2.3911 - val_acc: 0.4558\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.57040\n",
            "Epoch 33/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.9543 - acc: 0.6808 - val_loss: 1.9668 - val_acc: 0.5150\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.57040\n",
            "Epoch 34/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.9278 - acc: 0.7007 - val_loss: 1.1858 - val_acc: 0.6197\n",
            "\n",
            "Epoch 00034: val_acc improved from 0.57040 to 0.61970, saving model to /content/saved_models/cifar10_ResNet32v1_model.034.h5\n",
            "Epoch 35/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.9537 - acc: 0.6879 - val_loss: 2.3428 - val_acc: 0.4213\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.61970\n",
            "Epoch 36/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.9335 - acc: 0.6962 - val_loss: 1.9702 - val_acc: 0.4887\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.61970\n",
            "Epoch 37/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.9258 - acc: 0.6914 - val_loss: 2.1038 - val_acc: 0.4909\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.61970\n",
            "Epoch 38/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.9348 - acc: 0.6959 - val_loss: 3.5150 - val_acc: 0.3379\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.61970\n",
            "Epoch 39/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.9111 - acc: 0.7027 - val_loss: 1.7428 - val_acc: 0.5339\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.61970\n",
            "Epoch 40/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.9024 - acc: 0.7115 - val_loss: 1.5858 - val_acc: 0.5625\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.61970\n",
            "Epoch 41/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.8971 - acc: 0.7106 - val_loss: 1.6750 - val_acc: 0.5195\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.61970\n",
            "Epoch 42/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.8884 - acc: 0.7169 - val_loss: 1.3806 - val_acc: 0.5898\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.61970\n",
            "Epoch 43/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.8766 - acc: 0.7209 - val_loss: 4.5017 - val_acc: 0.2987\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.61970\n",
            "Epoch 44/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.8549 - acc: 0.7250 - val_loss: 1.4211 - val_acc: 0.5976\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.61970\n",
            "Epoch 45/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.8724 - acc: 0.7178 - val_loss: 1.6104 - val_acc: 0.5509\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.61970\n",
            "Epoch 46/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.8549 - acc: 0.7230 - val_loss: 2.8293 - val_acc: 0.3843\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.61970\n",
            "Epoch 47/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.8851 - acc: 0.7144 - val_loss: 2.4656 - val_acc: 0.4239\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.61970\n",
            "Epoch 48/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.8436 - acc: 0.7247 - val_loss: 1.4328 - val_acc: 0.5842\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.61970\n",
            "Epoch 49/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.8454 - acc: 0.7263 - val_loss: 1.1954 - val_acc: 0.6347\n",
            "\n",
            "Epoch 00049: val_acc improved from 0.61970 to 0.63470, saving model to /content/saved_models/cifar10_ResNet32v1_model.049.h5\n",
            "Epoch 50/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.8433 - acc: 0.7292 - val_loss: 2.3264 - val_acc: 0.4389\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.63470\n",
            "Epoch 51/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.8247 - acc: 0.7333 - val_loss: 1.8723 - val_acc: 0.5016\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.63470\n",
            "Epoch 52/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.8700 - acc: 0.7205 - val_loss: 4.8323 - val_acc: 0.3542\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.63470\n",
            "Epoch 53/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.8271 - acc: 0.7353 - val_loss: 1.1458 - val_acc: 0.6490\n",
            "\n",
            "Epoch 00053: val_acc improved from 0.63470 to 0.64900, saving model to /content/saved_models/cifar10_ResNet32v1_model.053.h5\n",
            "Epoch 54/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.8327 - acc: 0.7374 - val_loss: 1.1143 - val_acc: 0.6618\n",
            "\n",
            "Epoch 00054: val_acc improved from 0.64900 to 0.66180, saving model to /content/saved_models/cifar10_ResNet32v1_model.054.h5\n",
            "Epoch 55/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.8269 - acc: 0.7426 - val_loss: 1.5419 - val_acc: 0.5693\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.66180\n",
            "Epoch 56/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.8271 - acc: 0.7321 - val_loss: 2.0411 - val_acc: 0.4747\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.66180\n",
            "Epoch 57/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.8583 - acc: 0.7221 - val_loss: 1.8839 - val_acc: 0.5164\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.66180\n",
            "Epoch 58/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.8120 - acc: 0.7419 - val_loss: 1.3486 - val_acc: 0.6213\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.66180\n",
            "Epoch 59/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.8055 - acc: 0.7411 - val_loss: 1.3065 - val_acc: 0.6191\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.66180\n",
            "Epoch 60/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.8210 - acc: 0.7385 - val_loss: 2.9676 - val_acc: 0.3792\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.66180\n",
            "Epoch 61/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.8243 - acc: 0.7345 - val_loss: 1.5615 - val_acc: 0.5805\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.66180\n",
            "Epoch 62/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.8214 - acc: 0.7348 - val_loss: 1.7006 - val_acc: 0.5499\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.66180\n",
            "Epoch 63/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7735 - acc: 0.7492 - val_loss: 1.6446 - val_acc: 0.5620\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.66180\n",
            "Epoch 64/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.7950 - acc: 0.7505 - val_loss: 2.1825 - val_acc: 0.4812\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.66180\n",
            "Epoch 65/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7992 - acc: 0.7506 - val_loss: 2.5915 - val_acc: 0.4252\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.66180\n",
            "Epoch 66/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7883 - acc: 0.7544 - val_loss: 2.0287 - val_acc: 0.5185\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.66180\n",
            "Epoch 67/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.7696 - acc: 0.7594 - val_loss: 0.9445 - val_acc: 0.6969\n",
            "\n",
            "Epoch 00067: val_acc improved from 0.66180 to 0.69690, saving model to /content/saved_models/cifar10_ResNet32v1_model.067.h5\n",
            "Epoch 68/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7759 - acc: 0.7530 - val_loss: 1.7678 - val_acc: 0.5540\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.69690\n",
            "Epoch 69/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7885 - acc: 0.7493 - val_loss: 2.1348 - val_acc: 0.4775\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.69690\n",
            "Epoch 70/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7957 - acc: 0.7503 - val_loss: 3.0866 - val_acc: 0.3840\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.69690\n",
            "Epoch 71/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7809 - acc: 0.7480 - val_loss: 1.4331 - val_acc: 0.5704\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.69690\n",
            "Epoch 72/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7743 - acc: 0.7530 - val_loss: 1.4331 - val_acc: 0.5994\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.69690\n",
            "Epoch 73/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7745 - acc: 0.7573 - val_loss: 1.8242 - val_acc: 0.5363\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.69690\n",
            "Epoch 74/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7574 - acc: 0.7619 - val_loss: 1.9246 - val_acc: 0.5159\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.69690\n",
            "Epoch 75/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.7704 - acc: 0.7576 - val_loss: 1.3762 - val_acc: 0.6150\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.69690\n",
            "Epoch 76/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7843 - acc: 0.7539 - val_loss: 3.6070 - val_acc: 0.3133\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.69690\n",
            "Epoch 77/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.7483 - acc: 0.7583 - val_loss: 2.2045 - val_acc: 0.4881\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.69690\n",
            "Epoch 78/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7736 - acc: 0.7540 - val_loss: 1.7976 - val_acc: 0.5514\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.69690\n",
            "Epoch 79/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.7513 - acc: 0.7610 - val_loss: 1.6078 - val_acc: 0.5770\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.69690\n",
            "Epoch 80/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7462 - acc: 0.7652 - val_loss: 2.0412 - val_acc: 0.5178\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.69690\n",
            "Epoch 81/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7575 - acc: 0.7611 - val_loss: 1.3398 - val_acc: 0.6358\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.69690\n",
            "Epoch 82/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7445 - acc: 0.7689 - val_loss: 2.0073 - val_acc: 0.5320\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.69690\n",
            "Epoch 83/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7541 - acc: 0.7601 - val_loss: 3.0186 - val_acc: 0.3962\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.69690\n",
            "Epoch 84/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7718 - acc: 0.7571 - val_loss: 2.2707 - val_acc: 0.4572\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.69690\n",
            "Epoch 85/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7372 - acc: 0.7640 - val_loss: 1.9628 - val_acc: 0.5632\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.69690\n",
            "Epoch 86/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7755 - acc: 0.7603 - val_loss: 1.2707 - val_acc: 0.6300\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.69690\n",
            "Epoch 87/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7363 - acc: 0.7712 - val_loss: 1.9229 - val_acc: 0.5362\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.69690\n",
            "Epoch 88/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7388 - acc: 0.7765 - val_loss: 1.0981 - val_acc: 0.6708\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.69690\n",
            "Epoch 89/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7429 - acc: 0.7641 - val_loss: 1.4719 - val_acc: 0.5925\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.69690\n",
            "Epoch 90/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7467 - acc: 0.7626 - val_loss: 1.2275 - val_acc: 0.6240\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.69690\n",
            "Epoch 91/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.7052 - acc: 0.7818 - val_loss: 1.1989 - val_acc: 0.6442\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.69690\n",
            "Epoch 92/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7402 - acc: 0.7654 - val_loss: 2.0438 - val_acc: 0.5056\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.69690\n",
            "Epoch 93/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7383 - acc: 0.7696 - val_loss: 1.0893 - val_acc: 0.6783\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.69690\n",
            "Epoch 94/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7296 - acc: 0.7723 - val_loss: 1.5871 - val_acc: 0.5449\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.69690\n",
            "Epoch 95/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7337 - acc: 0.7643 - val_loss: 1.4744 - val_acc: 0.6147\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.69690\n",
            "Epoch 96/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.7040 - acc: 0.7790 - val_loss: 1.3964 - val_acc: 0.6465\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.69690\n",
            "Epoch 97/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.7516 - acc: 0.7587 - val_loss: 2.7038 - val_acc: 0.4237\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.69690\n",
            "Epoch 98/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7041 - acc: 0.7775 - val_loss: 2.8374 - val_acc: 0.4445\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.69690\n",
            "Epoch 99/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7325 - acc: 0.7632 - val_loss: 1.2147 - val_acc: 0.6463\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.69690\n",
            "Epoch 100/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.7225 - acc: 0.7679 - val_loss: 4.9725 - val_acc: 0.3331\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.69690\n",
            "Epoch 101/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.7072 - acc: 0.7774 - val_loss: 1.3532 - val_acc: 0.5998\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.69690\n",
            "Epoch 102/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7426 - acc: 0.7712 - val_loss: 1.1258 - val_acc: 0.6691\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.69690\n",
            "Epoch 103/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.7004 - acc: 0.7766 - val_loss: 1.1293 - val_acc: 0.6593\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.69690\n",
            "Epoch 104/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7265 - acc: 0.7749 - val_loss: 1.7116 - val_acc: 0.5837\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.69690\n",
            "Epoch 105/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7196 - acc: 0.7758 - val_loss: 1.6966 - val_acc: 0.5484\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.69690\n",
            "Epoch 106/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6935 - acc: 0.7813 - val_loss: 1.1662 - val_acc: 0.6539\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.69690\n",
            "Epoch 107/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7241 - acc: 0.7715 - val_loss: 2.6451 - val_acc: 0.4633\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.69690\n",
            "Epoch 108/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.7046 - acc: 0.7801 - val_loss: 1.5127 - val_acc: 0.5798\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.69690\n",
            "Epoch 109/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.7138 - acc: 0.7778 - val_loss: 1.6250 - val_acc: 0.5814\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.69690\n",
            "Epoch 110/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7232 - acc: 0.7726 - val_loss: 2.3422 - val_acc: 0.5074\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.69690\n",
            "Epoch 111/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7068 - acc: 0.7790 - val_loss: 1.0660 - val_acc: 0.6894\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.69690\n",
            "Epoch 112/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7132 - acc: 0.7770 - val_loss: 1.2129 - val_acc: 0.6506\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.69690\n",
            "Epoch 113/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7015 - acc: 0.7856 - val_loss: 1.9422 - val_acc: 0.5118\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.69690\n",
            "Epoch 114/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.7047 - acc: 0.7768 - val_loss: 1.3330 - val_acc: 0.6249\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.69690\n",
            "Epoch 115/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6815 - acc: 0.7848 - val_loss: 1.2684 - val_acc: 0.6429\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.69690\n",
            "Epoch 116/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7005 - acc: 0.7904 - val_loss: 2.8617 - val_acc: 0.4032\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.69690\n",
            "Epoch 117/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7262 - acc: 0.7707 - val_loss: 1.2780 - val_acc: 0.6217\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.69690\n",
            "Epoch 118/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.7046 - acc: 0.7826 - val_loss: 1.2966 - val_acc: 0.6229\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.69690\n",
            "Epoch 119/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6984 - acc: 0.7799 - val_loss: 1.5171 - val_acc: 0.6172\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.69690\n",
            "Epoch 120/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6788 - acc: 0.7840 - val_loss: 1.1326 - val_acc: 0.6819\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.69690\n",
            "Epoch 121/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7132 - acc: 0.7776 - val_loss: 1.0364 - val_acc: 0.6886\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.69690\n",
            "Epoch 122/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6936 - acc: 0.7845 - val_loss: 1.1347 - val_acc: 0.6633\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.69690\n",
            "Epoch 123/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6995 - acc: 0.7832 - val_loss: 1.7116 - val_acc: 0.5728\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.69690\n",
            "Epoch 124/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6896 - acc: 0.7885 - val_loss: 1.4386 - val_acc: 0.5956\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.69690\n",
            "Epoch 125/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6960 - acc: 0.7801 - val_loss: 1.2566 - val_acc: 0.6384\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.69690\n",
            "Epoch 126/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6815 - acc: 0.7843 - val_loss: 1.5340 - val_acc: 0.6112\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.69690\n",
            "Epoch 127/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7167 - acc: 0.7771 - val_loss: 1.2752 - val_acc: 0.6418\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.69690\n",
            "Epoch 128/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6805 - acc: 0.8002 - val_loss: 1.7017 - val_acc: 0.5707\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.69690\n",
            "Epoch 129/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6944 - acc: 0.7882 - val_loss: 1.4893 - val_acc: 0.6127\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.69690\n",
            "Epoch 130/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6873 - acc: 0.7907 - val_loss: 1.7367 - val_acc: 0.5572\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.69690\n",
            "Epoch 131/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6905 - acc: 0.7774 - val_loss: 2.0678 - val_acc: 0.5082\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.69690\n",
            "Epoch 132/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6912 - acc: 0.7853 - val_loss: 2.7666 - val_acc: 0.4329\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.69690\n",
            "Epoch 133/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6942 - acc: 0.7777 - val_loss: 1.7279 - val_acc: 0.5424\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.69690\n",
            "Epoch 134/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6613 - acc: 0.7895 - val_loss: 1.3569 - val_acc: 0.6177\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.69690\n",
            "Epoch 135/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6495 - acc: 0.8013 - val_loss: 0.9600 - val_acc: 0.7088\n",
            "\n",
            "Epoch 00135: val_acc improved from 0.69690 to 0.70880, saving model to /content/saved_models/cifar10_ResNet32v1_model.135.h5\n",
            "Epoch 136/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7164 - acc: 0.7720 - val_loss: 0.9837 - val_acc: 0.7093\n",
            "\n",
            "Epoch 00136: val_acc improved from 0.70880 to 0.70930, saving model to /content/saved_models/cifar10_ResNet32v1_model.136.h5\n",
            "Epoch 137/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6631 - acc: 0.7971 - val_loss: 2.3452 - val_acc: 0.4537\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.70930\n",
            "Epoch 138/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6748 - acc: 0.7925 - val_loss: 1.4050 - val_acc: 0.6095\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.70930\n",
            "Epoch 139/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6838 - acc: 0.7877 - val_loss: 1.3912 - val_acc: 0.6137\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.70930\n",
            "Epoch 140/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6768 - acc: 0.7862 - val_loss: 1.7180 - val_acc: 0.5721\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.70930\n",
            "Epoch 141/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6797 - acc: 0.7909 - val_loss: 0.8851 - val_acc: 0.7363\n",
            "\n",
            "Epoch 00141: val_acc improved from 0.70930 to 0.73630, saving model to /content/saved_models/cifar10_ResNet32v1_model.141.h5\n",
            "Epoch 142/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6582 - acc: 0.7957 - val_loss: 2.1844 - val_acc: 0.4950\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.73630\n",
            "Epoch 143/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6736 - acc: 0.7810 - val_loss: 1.4381 - val_acc: 0.6335\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.73630\n",
            "Epoch 144/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6729 - acc: 0.7887 - val_loss: 1.5959 - val_acc: 0.5713\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.73630\n",
            "Epoch 145/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6950 - acc: 0.7882 - val_loss: 1.5922 - val_acc: 0.6203\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.73630\n",
            "Epoch 146/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6982 - acc: 0.7856 - val_loss: 1.0973 - val_acc: 0.6847\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.73630\n",
            "Epoch 147/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6877 - acc: 0.7851 - val_loss: 1.0514 - val_acc: 0.6939\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.73630\n",
            "Epoch 148/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6628 - acc: 0.7916 - val_loss: 1.7136 - val_acc: 0.5494\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.73630\n",
            "Epoch 149/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6765 - acc: 0.7863 - val_loss: 1.1100 - val_acc: 0.7042\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.73630\n",
            "Epoch 150/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6734 - acc: 0.7919 - val_loss: 1.5948 - val_acc: 0.5590\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.73630\n",
            "Epoch 151/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6495 - acc: 0.7952 - val_loss: 2.6863 - val_acc: 0.4807\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.73630\n",
            "Epoch 152/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6830 - acc: 0.7923 - val_loss: 1.6090 - val_acc: 0.5954\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.73630\n",
            "Epoch 153/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6788 - acc: 0.7865 - val_loss: 0.9778 - val_acc: 0.7095\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.73630\n",
            "Epoch 154/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6696 - acc: 0.7977 - val_loss: 1.2369 - val_acc: 0.6430\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.73630\n",
            "Epoch 155/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6732 - acc: 0.7897 - val_loss: 1.8315 - val_acc: 0.5567\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.73630\n",
            "Epoch 156/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6734 - acc: 0.7865 - val_loss: 2.0179 - val_acc: 0.5268\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.73630\n",
            "Epoch 157/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6708 - acc: 0.7896 - val_loss: 1.4700 - val_acc: 0.6069\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.73630\n",
            "Epoch 158/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6579 - acc: 0.7976 - val_loss: 1.9013 - val_acc: 0.5206\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.73630\n",
            "Epoch 159/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6736 - acc: 0.7887 - val_loss: 1.4540 - val_acc: 0.6366\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.73630\n",
            "Epoch 160/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6722 - acc: 0.7918 - val_loss: 1.0664 - val_acc: 0.6842\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.73630\n",
            "Epoch 161/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6441 - acc: 0.7966 - val_loss: 1.6834 - val_acc: 0.5748\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.73630\n",
            "Epoch 162/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6622 - acc: 0.7981 - val_loss: 0.9244 - val_acc: 0.7234\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.73630\n",
            "Epoch 163/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6271 - acc: 0.8091 - val_loss: 5.4435 - val_acc: 0.2869\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.73630\n",
            "Epoch 164/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6347 - acc: 0.8077 - val_loss: 1.5533 - val_acc: 0.5911\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.73630\n",
            "Epoch 165/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6660 - acc: 0.7925 - val_loss: 1.1110 - val_acc: 0.6673\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.73630\n",
            "Epoch 166/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6661 - acc: 0.8001 - val_loss: 1.5822 - val_acc: 0.5829\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.73630\n",
            "Epoch 167/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6671 - acc: 0.7960 - val_loss: 1.7296 - val_acc: 0.5585\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.73630\n",
            "Epoch 168/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6699 - acc: 0.7950 - val_loss: 1.3403 - val_acc: 0.6210\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.73630\n",
            "Epoch 169/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6370 - acc: 0.8063 - val_loss: 1.4565 - val_acc: 0.6157\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.73630\n",
            "Epoch 170/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6419 - acc: 0.8009 - val_loss: 2.2199 - val_acc: 0.5171\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.73630\n",
            "Epoch 171/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6585 - acc: 0.7939 - val_loss: 1.4081 - val_acc: 0.6285\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.73630\n",
            "Epoch 172/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6635 - acc: 0.7944 - val_loss: 2.1342 - val_acc: 0.5360\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.73630\n",
            "Epoch 173/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6438 - acc: 0.8045 - val_loss: 2.0110 - val_acc: 0.5289\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.73630\n",
            "Epoch 174/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6566 - acc: 0.7965 - val_loss: 1.4564 - val_acc: 0.6120\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.73630\n",
            "Epoch 175/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6331 - acc: 0.8058 - val_loss: 1.3530 - val_acc: 0.6420\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.73630\n",
            "Epoch 176/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6396 - acc: 0.7975 - val_loss: 1.0871 - val_acc: 0.6467\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.73630\n",
            "Epoch 177/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6479 - acc: 0.7991 - val_loss: 1.2070 - val_acc: 0.6681\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.73630\n",
            "Epoch 178/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6440 - acc: 0.8011 - val_loss: 1.0346 - val_acc: 0.6997\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.73630\n",
            "Epoch 179/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6527 - acc: 0.7980 - val_loss: 6.8840 - val_acc: 0.3045\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.73630\n",
            "Epoch 180/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6491 - acc: 0.8006 - val_loss: 1.8407 - val_acc: 0.5663\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.73630\n",
            "Epoch 181/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6471 - acc: 0.8017 - val_loss: 1.5715 - val_acc: 0.6144\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.73630\n",
            "Epoch 182/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6629 - acc: 0.7903 - val_loss: 2.0177 - val_acc: 0.5163\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.73630\n",
            "Epoch 183/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6674 - acc: 0.7987 - val_loss: 1.3990 - val_acc: 0.6237\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.73630\n",
            "Epoch 184/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6355 - acc: 0.8036 - val_loss: 2.1093 - val_acc: 0.5263\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.73630\n",
            "Epoch 185/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6464 - acc: 0.8006 - val_loss: 2.4522 - val_acc: 0.4305\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.73630\n",
            "Epoch 186/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6539 - acc: 0.7966 - val_loss: 1.4073 - val_acc: 0.6381\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.73630\n",
            "Epoch 187/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6421 - acc: 0.7978 - val_loss: 1.1420 - val_acc: 0.6784\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.73630\n",
            "Epoch 188/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6557 - acc: 0.7957 - val_loss: 1.2766 - val_acc: 0.6376\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.73630\n",
            "Epoch 189/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6383 - acc: 0.8083 - val_loss: 1.7025 - val_acc: 0.5989\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.73630\n",
            "Epoch 190/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6399 - acc: 0.7978 - val_loss: 0.9287 - val_acc: 0.7271\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.73630\n",
            "Epoch 191/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6486 - acc: 0.7902 - val_loss: 2.4689 - val_acc: 0.5122\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.73630\n",
            "Epoch 192/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6421 - acc: 0.8004 - val_loss: 1.3987 - val_acc: 0.6079\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.73630\n",
            "Epoch 193/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6455 - acc: 0.8013 - val_loss: 1.0653 - val_acc: 0.6851\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.73630\n",
            "Epoch 194/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6553 - acc: 0.7964 - val_loss: 0.9797 - val_acc: 0.7015\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.73630\n",
            "Epoch 195/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6269 - acc: 0.8046 - val_loss: 0.9196 - val_acc: 0.7285\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.73630\n",
            "Epoch 196/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6341 - acc: 0.8004 - val_loss: 1.2114 - val_acc: 0.6646\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.73630\n",
            "Epoch 197/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6223 - acc: 0.8086 - val_loss: 1.2234 - val_acc: 0.6731\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.73630\n",
            "Epoch 198/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6126 - acc: 0.8093 - val_loss: 1.0353 - val_acc: 0.7020\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.73630\n",
            "Epoch 199/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6251 - acc: 0.8088 - val_loss: 1.9188 - val_acc: 0.5505\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.73630\n",
            "Epoch 200/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6253 - acc: 0.8114 - val_loss: 1.5642 - val_acc: 0.6149\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.73630\n",
            "Epoch 201/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6374 - acc: 0.8089 - val_loss: 1.8784 - val_acc: 0.5747\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.73630\n",
            "Epoch 202/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6650 - acc: 0.7959 - val_loss: 1.8481 - val_acc: 0.5279\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.73630\n",
            "Epoch 203/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6527 - acc: 0.7941 - val_loss: 1.4393 - val_acc: 0.6105\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.73630\n",
            "Epoch 204/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6299 - acc: 0.7994 - val_loss: 1.3977 - val_acc: 0.6273\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.73630\n",
            "Epoch 205/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6235 - acc: 0.8079 - val_loss: 1.4655 - val_acc: 0.5953\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.73630\n",
            "Epoch 206/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6467 - acc: 0.8028 - val_loss: 2.4827 - val_acc: 0.4914\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.73630\n",
            "Epoch 207/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6427 - acc: 0.8009 - val_loss: 2.0057 - val_acc: 0.5192\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.73630\n",
            "Epoch 208/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6490 - acc: 0.8002 - val_loss: 1.5016 - val_acc: 0.5563\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.73630\n",
            "Epoch 209/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6295 - acc: 0.7968 - val_loss: 0.9066 - val_acc: 0.7247\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.73630\n",
            "Epoch 210/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6374 - acc: 0.8004 - val_loss: 1.2065 - val_acc: 0.6704\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.73630\n",
            "Epoch 211/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6372 - acc: 0.8049 - val_loss: 3.2582 - val_acc: 0.4238\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.73630\n",
            "Epoch 212/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6557 - acc: 0.7955 - val_loss: 1.3521 - val_acc: 0.6239\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.73630\n",
            "Epoch 213/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6167 - acc: 0.8098 - val_loss: 1.9210 - val_acc: 0.5875\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.73630\n",
            "Epoch 214/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6358 - acc: 0.8033 - val_loss: 1.1338 - val_acc: 0.6843\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.73630\n",
            "Epoch 215/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6080 - acc: 0.8141 - val_loss: 1.6919 - val_acc: 0.6030\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.73630\n",
            "Epoch 216/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6379 - acc: 0.8061 - val_loss: 1.4471 - val_acc: 0.5936\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.73630\n",
            "Epoch 217/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6284 - acc: 0.8066 - val_loss: 1.2135 - val_acc: 0.6578\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.73630\n",
            "Epoch 218/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6333 - acc: 0.8069 - val_loss: 1.4659 - val_acc: 0.6100\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.73630\n",
            "Epoch 219/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6251 - acc: 0.8065 - val_loss: 1.9928 - val_acc: 0.5459\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.73630\n",
            "Epoch 220/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6015 - acc: 0.8160 - val_loss: 1.0610 - val_acc: 0.6980\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.73630\n",
            "Epoch 221/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6251 - acc: 0.8121 - val_loss: 1.4891 - val_acc: 0.6191\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.73630\n",
            "Epoch 222/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6219 - acc: 0.8075 - val_loss: 1.7992 - val_acc: 0.5620\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.73630\n",
            "Epoch 223/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6221 - acc: 0.8069 - val_loss: 1.0434 - val_acc: 0.7180\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.73630\n",
            "Epoch 224/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6289 - acc: 0.8093 - val_loss: 1.6647 - val_acc: 0.6099\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.73630\n",
            "Epoch 225/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6404 - acc: 0.8039 - val_loss: 2.1450 - val_acc: 0.4760\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.73630\n",
            "Epoch 226/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6207 - acc: 0.8034 - val_loss: 1.6200 - val_acc: 0.5833\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.73630\n",
            "Epoch 227/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6325 - acc: 0.8070 - val_loss: 1.3427 - val_acc: 0.6463\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.73630\n",
            "Epoch 228/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6566 - acc: 0.7976 - val_loss: 0.9711 - val_acc: 0.7191\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.73630\n",
            "Epoch 229/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6334 - acc: 0.8053 - val_loss: 1.2127 - val_acc: 0.6494\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.73630\n",
            "Epoch 230/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5947 - acc: 0.8181 - val_loss: 2.6441 - val_acc: 0.4620\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.73630\n",
            "Epoch 231/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6406 - acc: 0.7998 - val_loss: 1.0205 - val_acc: 0.6893\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.73630\n",
            "Epoch 232/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6222 - acc: 0.8096 - val_loss: 3.4423 - val_acc: 0.4332\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.73630\n",
            "Epoch 233/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6280 - acc: 0.8020 - val_loss: 1.1974 - val_acc: 0.6771\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.73630\n",
            "Epoch 234/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6041 - acc: 0.8143 - val_loss: 1.6070 - val_acc: 0.6282\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.73630\n",
            "Epoch 235/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6187 - acc: 0.8072 - val_loss: 1.0063 - val_acc: 0.7067\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.73630\n",
            "Epoch 236/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6256 - acc: 0.8010 - val_loss: 1.0609 - val_acc: 0.6901\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.73630\n",
            "Epoch 237/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6289 - acc: 0.8095 - val_loss: 0.9974 - val_acc: 0.7148\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.73630\n",
            "Epoch 238/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5954 - acc: 0.8157 - val_loss: 1.6920 - val_acc: 0.5991\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.73630\n",
            "Epoch 239/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6175 - acc: 0.8065 - val_loss: 0.9998 - val_acc: 0.7097\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.73630\n",
            "Epoch 240/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6242 - acc: 0.8091 - val_loss: 0.9536 - val_acc: 0.7217\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.73630\n",
            "Epoch 241/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6180 - acc: 0.8077 - val_loss: 1.1568 - val_acc: 0.6870\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.73630\n",
            "Epoch 242/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6217 - acc: 0.8113 - val_loss: 1.1909 - val_acc: 0.6467\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.73630\n",
            "Epoch 243/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6103 - acc: 0.8129 - val_loss: 2.1052 - val_acc: 0.5082\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.73630\n",
            "Epoch 244/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6204 - acc: 0.8038 - val_loss: 0.9155 - val_acc: 0.7185\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.73630\n",
            "Epoch 245/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6273 - acc: 0.8039 - val_loss: 1.2268 - val_acc: 0.6672\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.73630\n",
            "Epoch 246/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6049 - acc: 0.8149 - val_loss: 1.2767 - val_acc: 0.6485\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.73630\n",
            "Epoch 247/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6005 - acc: 0.8126 - val_loss: 1.4073 - val_acc: 0.5976\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.73630\n",
            "Epoch 248/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.5981 - acc: 0.8142 - val_loss: 1.1083 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.73630\n",
            "Epoch 249/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6307 - acc: 0.8060 - val_loss: 1.0896 - val_acc: 0.6813\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.73630\n",
            "Epoch 250/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5905 - acc: 0.8155 - val_loss: 1.2452 - val_acc: 0.6594\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.73630\n",
            "Epoch 251/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6159 - acc: 0.8065 - val_loss: 1.5654 - val_acc: 0.6219\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.73630\n",
            "Epoch 252/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6056 - acc: 0.8176 - val_loss: 1.3492 - val_acc: 0.6528\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.73630\n",
            "Epoch 253/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5888 - acc: 0.8196 - val_loss: 2.0965 - val_acc: 0.4956\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.73630\n",
            "Epoch 254/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5893 - acc: 0.8225 - val_loss: 1.0029 - val_acc: 0.6916\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.73630\n",
            "Epoch 255/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6069 - acc: 0.8113 - val_loss: 1.1625 - val_acc: 0.6479\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.73630\n",
            "Epoch 256/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.5992 - acc: 0.8125 - val_loss: 1.2067 - val_acc: 0.6861\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.73630\n",
            "Epoch 257/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6223 - acc: 0.8114 - val_loss: 1.6963 - val_acc: 0.5909\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.73630\n",
            "Epoch 258/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6250 - acc: 0.8107 - val_loss: 1.1222 - val_acc: 0.6955\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.73630\n",
            "Epoch 259/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5979 - acc: 0.8154 - val_loss: 1.2373 - val_acc: 0.6440\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.73630\n",
            "Epoch 260/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5915 - acc: 0.8188 - val_loss: 1.4753 - val_acc: 0.6233\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.73630\n",
            "Epoch 261/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5964 - acc: 0.8177 - val_loss: 2.1054 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.73630\n",
            "Epoch 262/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6068 - acc: 0.8136 - val_loss: 1.1927 - val_acc: 0.6540\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.73630\n",
            "Epoch 263/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6135 - acc: 0.8125 - val_loss: 1.0016 - val_acc: 0.7070\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.73630\n",
            "Epoch 264/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6054 - acc: 0.8139 - val_loss: 3.6156 - val_acc: 0.4172\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.73630\n",
            "Epoch 265/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6110 - acc: 0.8130 - val_loss: 1.5558 - val_acc: 0.5874\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.73630\n",
            "Epoch 266/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5911 - acc: 0.8209 - val_loss: 0.8599 - val_acc: 0.7415\n",
            "\n",
            "Epoch 00266: val_acc improved from 0.73630 to 0.74150, saving model to /content/saved_models/cifar10_ResNet32v1_model.266.h5\n",
            "Epoch 267/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5909 - acc: 0.8191 - val_loss: 1.5292 - val_acc: 0.6335\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.74150\n",
            "Epoch 268/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6259 - acc: 0.8087 - val_loss: 1.2404 - val_acc: 0.6649\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.74150\n",
            "Epoch 269/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5970 - acc: 0.8194 - val_loss: 1.3546 - val_acc: 0.6169\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.74150\n",
            "Epoch 270/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5991 - acc: 0.8151 - val_loss: 1.2049 - val_acc: 0.6401\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.74150\n",
            "Epoch 271/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6109 - acc: 0.8111 - val_loss: 1.3485 - val_acc: 0.6580\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.74150\n",
            "Epoch 272/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6005 - acc: 0.8216 - val_loss: 1.2050 - val_acc: 0.6382\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.74150\n",
            "Epoch 273/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5962 - acc: 0.8159 - val_loss: 1.4807 - val_acc: 0.5960\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.74150\n",
            "Epoch 274/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6052 - acc: 0.8145 - val_loss: 1.3805 - val_acc: 0.6211\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.74150\n",
            "Epoch 275/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5877 - acc: 0.8194 - val_loss: 0.9606 - val_acc: 0.7107\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.74150\n",
            "Epoch 276/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5941 - acc: 0.8170 - val_loss: 1.9418 - val_acc: 0.5588\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.74150\n",
            "Epoch 277/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5896 - acc: 0.8176 - val_loss: 1.2217 - val_acc: 0.6626\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.74150\n",
            "Epoch 278/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6056 - acc: 0.8128 - val_loss: 1.4639 - val_acc: 0.6305\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.74150\n",
            "Epoch 279/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5828 - acc: 0.8270 - val_loss: 1.1933 - val_acc: 0.6655\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.74150\n",
            "Epoch 280/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5909 - acc: 0.8235 - val_loss: 1.6408 - val_acc: 0.5863\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.74150\n",
            "Epoch 281/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5897 - acc: 0.8227 - val_loss: 1.1831 - val_acc: 0.6776\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.74150\n",
            "Epoch 282/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5958 - acc: 0.8144 - val_loss: 1.7185 - val_acc: 0.6081\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.74150\n",
            "Epoch 283/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5943 - acc: 0.8225 - val_loss: 2.9176 - val_acc: 0.4799\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.74150\n",
            "Epoch 284/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5985 - acc: 0.8156 - val_loss: 0.9277 - val_acc: 0.7244\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.74150\n",
            "Epoch 285/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5954 - acc: 0.8097 - val_loss: 2.0021 - val_acc: 0.5386\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.74150\n",
            "Epoch 286/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6061 - acc: 0.8156 - val_loss: 1.9792 - val_acc: 0.5581\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.74150\n",
            "Epoch 287/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6075 - acc: 0.8187 - val_loss: 1.0917 - val_acc: 0.6884\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.74150\n",
            "Epoch 288/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5986 - acc: 0.8148 - val_loss: 1.2998 - val_acc: 0.6481\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.74150\n",
            "Epoch 289/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5886 - acc: 0.8224 - val_loss: 1.5243 - val_acc: 0.6114\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.74150\n",
            "Epoch 290/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5790 - acc: 0.8236 - val_loss: 2.3214 - val_acc: 0.5122\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.74150\n",
            "Epoch 291/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6177 - acc: 0.8036 - val_loss: 1.4429 - val_acc: 0.6574\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.74150\n",
            "Epoch 292/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5918 - acc: 0.8218 - val_loss: 1.3841 - val_acc: 0.6471\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.74150\n",
            "Epoch 293/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6055 - acc: 0.8183 - val_loss: 1.2460 - val_acc: 0.6636\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.74150\n",
            "Epoch 294/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5988 - acc: 0.8102 - val_loss: 1.1063 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.74150\n",
            "Epoch 295/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5917 - acc: 0.8273 - val_loss: 1.9275 - val_acc: 0.5324\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.74150\n",
            "Epoch 296/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5838 - acc: 0.8272 - val_loss: 1.3748 - val_acc: 0.6359\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.74150\n",
            "Epoch 297/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5872 - acc: 0.8210 - val_loss: 2.6116 - val_acc: 0.4839\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.74150\n",
            "Epoch 298/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6008 - acc: 0.8177 - val_loss: 1.4466 - val_acc: 0.6084\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.74150\n",
            "Epoch 299/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5705 - acc: 0.8194 - val_loss: 1.0862 - val_acc: 0.6878\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.74150\n",
            "Epoch 300/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5827 - acc: 0.8215 - val_loss: 1.2028 - val_acc: 0.6678\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.74150\n",
            "Epoch 301/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5666 - acc: 0.8289 - val_loss: 1.3552 - val_acc: 0.6305\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.74150\n",
            "Epoch 302/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6086 - acc: 0.8110 - val_loss: 1.4869 - val_acc: 0.6265\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.74150\n",
            "Epoch 303/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5748 - acc: 0.8259 - val_loss: 1.0449 - val_acc: 0.7007\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.74150\n",
            "Epoch 304/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5789 - acc: 0.8227 - val_loss: 1.5080 - val_acc: 0.5848\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.74150\n",
            "Epoch 305/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6010 - acc: 0.8152 - val_loss: 1.3392 - val_acc: 0.6494\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.74150\n",
            "Epoch 306/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5989 - acc: 0.8185 - val_loss: 1.2779 - val_acc: 0.6757\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.74150\n",
            "Epoch 307/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5801 - acc: 0.8246 - val_loss: 0.9843 - val_acc: 0.7067\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.74150\n",
            "Epoch 308/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6141 - acc: 0.8144 - val_loss: 1.3397 - val_acc: 0.6473\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.74150\n",
            "Epoch 309/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5854 - acc: 0.8228 - val_loss: 1.2896 - val_acc: 0.6560\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.74150\n",
            "Epoch 310/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6021 - acc: 0.8202 - val_loss: 3.2672 - val_acc: 0.4183\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.74150\n",
            "Epoch 311/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5925 - acc: 0.8237 - val_loss: 1.5097 - val_acc: 0.6498\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.74150\n",
            "Epoch 312/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5899 - acc: 0.8242 - val_loss: 1.1355 - val_acc: 0.6844\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.74150\n",
            "Epoch 313/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5932 - acc: 0.8194 - val_loss: 0.8587 - val_acc: 0.7328\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.74150\n",
            "Epoch 314/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5862 - acc: 0.8216 - val_loss: 2.8904 - val_acc: 0.4997\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.74150\n",
            "Epoch 315/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5845 - acc: 0.8216 - val_loss: 0.9906 - val_acc: 0.7014\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.74150\n",
            "Epoch 316/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6091 - acc: 0.8168 - val_loss: 1.0132 - val_acc: 0.7117\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.74150\n",
            "Epoch 317/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5691 - acc: 0.8294 - val_loss: 1.3495 - val_acc: 0.6322\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.74150\n",
            "Epoch 318/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6177 - acc: 0.8131 - val_loss: 1.4833 - val_acc: 0.6175\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.74150\n",
            "Epoch 319/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5799 - acc: 0.8219 - val_loss: 1.3021 - val_acc: 0.6401\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.74150\n",
            "Epoch 320/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5945 - acc: 0.8200 - val_loss: 1.3669 - val_acc: 0.6421\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.74150\n",
            "Epoch 321/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5660 - acc: 0.8251 - val_loss: 1.1981 - val_acc: 0.6577\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.74150\n",
            "Epoch 322/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5785 - acc: 0.8206 - val_loss: 0.8706 - val_acc: 0.7633\n",
            "\n",
            "Epoch 00322: val_acc improved from 0.74150 to 0.76330, saving model to /content/saved_models/cifar10_ResNet32v1_model.322.h5\n",
            "Epoch 323/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5667 - acc: 0.8266 - val_loss: 0.9738 - val_acc: 0.7314\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.76330\n",
            "Epoch 324/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5979 - acc: 0.8160 - val_loss: 1.0978 - val_acc: 0.6933\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.76330\n",
            "Epoch 325/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5686 - acc: 0.8286 - val_loss: 1.3012 - val_acc: 0.6317\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.76330\n",
            "Epoch 326/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5853 - acc: 0.8243 - val_loss: 1.3848 - val_acc: 0.6345\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.76330\n",
            "Epoch 327/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5837 - acc: 0.8220 - val_loss: 1.1615 - val_acc: 0.6651\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.76330\n",
            "Epoch 328/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5919 - acc: 0.8186 - val_loss: 1.6587 - val_acc: 0.5853\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.76330\n",
            "Epoch 329/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5787 - acc: 0.8261 - val_loss: 0.9449 - val_acc: 0.7334\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.76330\n",
            "Epoch 330/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5802 - acc: 0.8277 - val_loss: 1.2303 - val_acc: 0.6515\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.76330\n",
            "Epoch 331/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5840 - acc: 0.8188 - val_loss: 1.2401 - val_acc: 0.6830\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.76330\n",
            "Epoch 332/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5834 - acc: 0.8157 - val_loss: 1.9483 - val_acc: 0.5376\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.76330\n",
            "Epoch 333/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5757 - acc: 0.8260 - val_loss: 1.2245 - val_acc: 0.6716\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.76330\n",
            "Epoch 334/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5659 - acc: 0.8229 - val_loss: 2.1995 - val_acc: 0.4978\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.76330\n",
            "Epoch 335/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5837 - acc: 0.8253 - val_loss: 1.2355 - val_acc: 0.6349\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.76330\n",
            "Epoch 336/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5751 - acc: 0.8298 - val_loss: 1.1238 - val_acc: 0.6634\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.76330\n",
            "Epoch 337/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5959 - acc: 0.8155 - val_loss: 1.2000 - val_acc: 0.6894\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.76330\n",
            "Epoch 338/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5578 - acc: 0.8324 - val_loss: 1.7356 - val_acc: 0.6152\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.76330\n",
            "Epoch 339/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5681 - acc: 0.8294 - val_loss: 1.2497 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.76330\n",
            "Epoch 340/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5758 - acc: 0.8253 - val_loss: 1.6533 - val_acc: 0.6158\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.76330\n",
            "Epoch 341/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5759 - acc: 0.8259 - val_loss: 1.0698 - val_acc: 0.7042\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.76330\n",
            "Epoch 342/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5884 - acc: 0.8266 - val_loss: 1.7280 - val_acc: 0.5671\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.76330\n",
            "Epoch 343/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5962 - acc: 0.8215 - val_loss: 1.8342 - val_acc: 0.5475\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.76330\n",
            "Epoch 344/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5558 - acc: 0.8265 - val_loss: 1.6309 - val_acc: 0.5792\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.76330\n",
            "Epoch 345/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5825 - acc: 0.8237 - val_loss: 1.0433 - val_acc: 0.7042\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.76330\n",
            "Epoch 346/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5836 - acc: 0.8189 - val_loss: 2.9661 - val_acc: 0.4769\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.76330\n",
            "Epoch 347/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5513 - acc: 0.8308 - val_loss: 1.1590 - val_acc: 0.6856\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.76330\n",
            "Epoch 348/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5675 - acc: 0.8282 - val_loss: 1.4453 - val_acc: 0.6213\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.76330\n",
            "Epoch 349/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5860 - acc: 0.8161 - val_loss: 0.9113 - val_acc: 0.7257\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.76330\n",
            "Epoch 350/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5905 - acc: 0.8194 - val_loss: 1.4143 - val_acc: 0.6140\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.76330\n",
            "Epoch 351/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5662 - acc: 0.8230 - val_loss: 0.8091 - val_acc: 0.7534\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.76330\n",
            "Epoch 352/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5888 - acc: 0.8213 - val_loss: 1.3331 - val_acc: 0.6276\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.76330\n",
            "Epoch 353/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5598 - acc: 0.8302 - val_loss: 1.5710 - val_acc: 0.5797\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.76330\n",
            "Epoch 354/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5665 - acc: 0.8266 - val_loss: 1.4449 - val_acc: 0.6006\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.76330\n",
            "Epoch 355/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5751 - acc: 0.8223 - val_loss: 2.1495 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.76330\n",
            "Epoch 356/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5623 - acc: 0.8301 - val_loss: 1.1597 - val_acc: 0.6631\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.76330\n",
            "Epoch 357/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5770 - acc: 0.8280 - val_loss: 1.3286 - val_acc: 0.6697\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.76330\n",
            "Epoch 358/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5959 - acc: 0.8202 - val_loss: 1.4786 - val_acc: 0.6219\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.76330\n",
            "Epoch 359/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5787 - acc: 0.8244 - val_loss: 1.0562 - val_acc: 0.6898\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.76330\n",
            "Epoch 360/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5703 - acc: 0.8277 - val_loss: 0.9544 - val_acc: 0.7218\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.76330\n",
            "Epoch 361/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5620 - acc: 0.8267 - val_loss: 1.2114 - val_acc: 0.6737\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.76330\n",
            "Epoch 362/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5766 - acc: 0.8241 - val_loss: 1.1448 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.76330\n",
            "Epoch 363/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5764 - acc: 0.8213 - val_loss: 1.4708 - val_acc: 0.6061\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.76330\n",
            "Epoch 364/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5728 - acc: 0.8285 - val_loss: 1.2230 - val_acc: 0.6649\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.76330\n",
            "Epoch 365/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5816 - acc: 0.8276 - val_loss: 0.9084 - val_acc: 0.7418\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.76330\n",
            "Epoch 366/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5706 - acc: 0.8254 - val_loss: 1.9106 - val_acc: 0.5620\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.76330\n",
            "Epoch 367/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5653 - acc: 0.8310 - val_loss: 0.7696 - val_acc: 0.7706\n",
            "\n",
            "Epoch 00367: val_acc improved from 0.76330 to 0.77060, saving model to /content/saved_models/cifar10_ResNet32v1_model.367.h5\n",
            "Epoch 368/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5680 - acc: 0.8263 - val_loss: 1.1954 - val_acc: 0.6653\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.77060\n",
            "Epoch 369/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5682 - acc: 0.8255 - val_loss: 1.2925 - val_acc: 0.6629\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.77060\n",
            "Epoch 370/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5719 - acc: 0.8232 - val_loss: 3.0131 - val_acc: 0.4590\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.77060\n",
            "Epoch 371/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5842 - acc: 0.8248 - val_loss: 1.0550 - val_acc: 0.6950\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.77060\n",
            "Epoch 372/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5620 - acc: 0.8289 - val_loss: 2.1970 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.77060\n",
            "Epoch 373/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5524 - acc: 0.8323 - val_loss: 1.6916 - val_acc: 0.5560\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.77060\n",
            "Epoch 374/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5389 - acc: 0.8409 - val_loss: 0.7982 - val_acc: 0.7564\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.77060\n",
            "Epoch 375/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5745 - acc: 0.8255 - val_loss: 1.7990 - val_acc: 0.6152\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.77060\n",
            "Epoch 376/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5593 - acc: 0.8282 - val_loss: 1.3570 - val_acc: 0.6814\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.77060\n",
            "Epoch 377/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5626 - acc: 0.8256 - val_loss: 1.5421 - val_acc: 0.6206\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.77060\n",
            "Epoch 378/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5702 - acc: 0.8286 - val_loss: 0.9349 - val_acc: 0.7352\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.77060\n",
            "Epoch 379/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5687 - acc: 0.8277 - val_loss: 1.2408 - val_acc: 0.6678\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.77060\n",
            "Epoch 380/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5747 - acc: 0.8248 - val_loss: 0.8388 - val_acc: 0.7546\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.77060\n",
            "Epoch 381/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5755 - acc: 0.8252 - val_loss: 0.9832 - val_acc: 0.7046\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.77060\n",
            "Epoch 382/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5496 - acc: 0.8308 - val_loss: 1.2023 - val_acc: 0.6571\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.77060\n",
            "Epoch 383/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5758 - acc: 0.8241 - val_loss: 1.9496 - val_acc: 0.5560\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.77060\n",
            "Epoch 384/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5603 - acc: 0.8284 - val_loss: 1.3728 - val_acc: 0.6358\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.77060\n",
            "Epoch 385/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5674 - acc: 0.8277 - val_loss: 2.4807 - val_acc: 0.4663\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.77060\n",
            "Epoch 386/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5730 - acc: 0.8197 - val_loss: 1.1999 - val_acc: 0.6813\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.77060\n",
            "Epoch 387/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5546 - acc: 0.8292 - val_loss: 1.1673 - val_acc: 0.6619\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.77060\n",
            "Epoch 388/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5530 - acc: 0.8340 - val_loss: 1.1352 - val_acc: 0.6959\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.77060\n",
            "Epoch 389/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5504 - acc: 0.8317 - val_loss: 0.9871 - val_acc: 0.7018\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.77060\n",
            "Epoch 390/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5872 - acc: 0.8136 - val_loss: 1.0554 - val_acc: 0.6802\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.77060\n",
            "Epoch 391/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5297 - acc: 0.8394 - val_loss: 1.3163 - val_acc: 0.6449\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.77060\n",
            "Epoch 392/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5522 - acc: 0.8325 - val_loss: 1.2080 - val_acc: 0.6880\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.77060\n",
            "Epoch 393/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5928 - acc: 0.8138 - val_loss: 1.4351 - val_acc: 0.6247\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.77060\n",
            "Epoch 394/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5495 - acc: 0.8299 - val_loss: 1.2922 - val_acc: 0.6415\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.77060\n",
            "Epoch 395/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5511 - acc: 0.8345 - val_loss: 1.9779 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.77060\n",
            "Epoch 396/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5709 - acc: 0.8308 - val_loss: 1.3028 - val_acc: 0.6518\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.77060\n",
            "Epoch 397/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5386 - acc: 0.8332 - val_loss: 1.2858 - val_acc: 0.6650\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.77060\n",
            "Epoch 398/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5597 - acc: 0.8349 - val_loss: 1.5365 - val_acc: 0.6148\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.77060\n",
            "Epoch 399/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5372 - acc: 0.8424 - val_loss: 1.6833 - val_acc: 0.6203\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.77060\n",
            "Epoch 400/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5673 - acc: 0.8199 - val_loss: 0.8707 - val_acc: 0.7343\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.77060\n",
            "Epoch 401/500\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5493 - acc: 0.8360 - val_loss: 2.0480 - val_acc: 0.5637\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.77060\n",
            "Epoch 402/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5168 - acc: 0.8452 - val_loss: 0.5605 - val_acc: 0.8271\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.77060 to 0.82710, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4333 - acc: 0.8759 - val_loss: 0.5095 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.82710 to 0.84380, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4609 - acc: 0.8661 - val_loss: 0.5252 - val_acc: 0.8414\n",
            "\n",
            "Epoch 00404: val_acc did not improve from 0.84380\n",
            "Epoch 405/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4304 - acc: 0.8755 - val_loss: 0.5012 - val_acc: 0.8477\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.84380 to 0.84770, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4225 - acc: 0.8822 - val_loss: 0.5429 - val_acc: 0.8331\n",
            "\n",
            "Epoch 00406: val_acc did not improve from 0.84770\n",
            "Epoch 407/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4238 - acc: 0.8813 - val_loss: 0.5130 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00407: val_acc did not improve from 0.84770\n",
            "Epoch 408/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4237 - acc: 0.8833 - val_loss: 0.4861 - val_acc: 0.8568\n",
            "\n",
            "Epoch 00408: val_acc improved from 0.84770 to 0.85680, saving model to /content/saved_models/cifar10_ResNet32v1_model.408.h5\n",
            "Epoch 409/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.4201 - acc: 0.8822 - val_loss: 0.5026 - val_acc: 0.8488\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.85680\n",
            "Epoch 410/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4095 - acc: 0.8820 - val_loss: 0.5021 - val_acc: 0.8512\n",
            "\n",
            "Epoch 00410: val_acc did not improve from 0.85680\n",
            "Epoch 411/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3975 - acc: 0.8847 - val_loss: 0.4933 - val_acc: 0.8544\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.85680\n",
            "Epoch 412/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4186 - acc: 0.8780 - val_loss: 0.4907 - val_acc: 0.8533\n",
            "\n",
            "Epoch 00412: val_acc did not improve from 0.85680\n",
            "Epoch 413/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4060 - acc: 0.8870 - val_loss: 0.5017 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.85680\n",
            "Epoch 414/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3844 - acc: 0.8945 - val_loss: 0.4922 - val_acc: 0.8518\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.85680\n",
            "Epoch 415/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4099 - acc: 0.8835 - val_loss: 0.5002 - val_acc: 0.8529\n",
            "\n",
            "Epoch 00415: val_acc did not improve from 0.85680\n",
            "Epoch 416/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4055 - acc: 0.8851 - val_loss: 0.4861 - val_acc: 0.8566\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.85680\n",
            "Epoch 417/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4092 - acc: 0.8818 - val_loss: 0.5074 - val_acc: 0.8506\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.85680\n",
            "Epoch 418/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3999 - acc: 0.8844 - val_loss: 0.5139 - val_acc: 0.8484\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.85680\n",
            "Epoch 419/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3985 - acc: 0.8866 - val_loss: 0.4725 - val_acc: 0.8602\n",
            "\n",
            "Epoch 00419: val_acc improved from 0.85680 to 0.86020, saving model to /content/saved_models/cifar10_ResNet32v1_model.419.h5\n",
            "Epoch 420/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3884 - acc: 0.8850 - val_loss: 0.5424 - val_acc: 0.8413\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.86020\n",
            "Epoch 421/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3891 - acc: 0.8891 - val_loss: 0.4870 - val_acc: 0.8550\n",
            "\n",
            "Epoch 00421: val_acc did not improve from 0.86020\n",
            "Epoch 422/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3986 - acc: 0.8841 - val_loss: 0.4699 - val_acc: 0.8615\n",
            "\n",
            "Epoch 00422: val_acc improved from 0.86020 to 0.86150, saving model to /content/saved_models/cifar10_ResNet32v1_model.422.h5\n",
            "Epoch 423/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4019 - acc: 0.8824 - val_loss: 0.4940 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.86150\n",
            "Epoch 424/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3958 - acc: 0.8880 - val_loss: 0.4973 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.86150\n",
            "Epoch 425/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4004 - acc: 0.8864 - val_loss: 0.4659 - val_acc: 0.8616\n",
            "\n",
            "Epoch 00425: val_acc improved from 0.86150 to 0.86160, saving model to /content/saved_models/cifar10_ResNet32v1_model.425.h5\n",
            "Epoch 426/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3807 - acc: 0.8963 - val_loss: 0.4806 - val_acc: 0.8564\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.86160\n",
            "Epoch 427/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3986 - acc: 0.8839 - val_loss: 0.5113 - val_acc: 0.8510\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.86160\n",
            "Epoch 428/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3825 - acc: 0.8891 - val_loss: 0.4739 - val_acc: 0.8596\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.86160\n",
            "Epoch 429/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3828 - acc: 0.8928 - val_loss: 0.4814 - val_acc: 0.8571\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.86160\n",
            "Epoch 430/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3923 - acc: 0.8914 - val_loss: 0.4766 - val_acc: 0.8584\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.86160\n",
            "Epoch 431/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3798 - acc: 0.8910 - val_loss: 0.5033 - val_acc: 0.8523\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.86160\n",
            "Epoch 432/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3894 - acc: 0.8897 - val_loss: 0.4927 - val_acc: 0.8550\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.86160\n",
            "Epoch 433/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3975 - acc: 0.8847 - val_loss: 0.4913 - val_acc: 0.8570\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.86160\n",
            "Epoch 434/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4047 - acc: 0.8788 - val_loss: 0.4962 - val_acc: 0.8550\n",
            "\n",
            "Epoch 00434: val_acc did not improve from 0.86160\n",
            "Epoch 435/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3795 - acc: 0.8930 - val_loss: 0.4689 - val_acc: 0.8627\n",
            "\n",
            "Epoch 00435: val_acc improved from 0.86160 to 0.86270, saving model to /content/saved_models/cifar10_ResNet32v1_model.435.h5\n",
            "Epoch 436/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3891 - acc: 0.8884 - val_loss: 0.5099 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.86270\n",
            "Epoch 437/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3892 - acc: 0.8875 - val_loss: 0.5054 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.86270\n",
            "Epoch 438/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3809 - acc: 0.8915 - val_loss: 0.4952 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.86270\n",
            "Epoch 439/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3781 - acc: 0.8957 - val_loss: 0.4832 - val_acc: 0.8614\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.86270\n",
            "Epoch 440/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3850 - acc: 0.8886 - val_loss: 0.4914 - val_acc: 0.8573\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.86270\n",
            "Epoch 441/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3758 - acc: 0.8945 - val_loss: 0.4867 - val_acc: 0.8577\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.86270\n",
            "Epoch 442/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3931 - acc: 0.8925 - val_loss: 0.4746 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.86270\n",
            "Epoch 443/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3714 - acc: 0.8945 - val_loss: 0.4863 - val_acc: 0.8587\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.86270\n",
            "Epoch 444/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3840 - acc: 0.8875 - val_loss: 0.4597 - val_acc: 0.8649\n",
            "\n",
            "Epoch 00444: val_acc improved from 0.86270 to 0.86490, saving model to /content/saved_models/cifar10_ResNet32v1_model.444.h5\n",
            "Epoch 445/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3828 - acc: 0.8895 - val_loss: 0.5414 - val_acc: 0.8466\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.86490\n",
            "Epoch 446/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3650 - acc: 0.8988 - val_loss: 0.4964 - val_acc: 0.8571\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.86490\n",
            "Epoch 447/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3773 - acc: 0.8948 - val_loss: 0.4910 - val_acc: 0.8590\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.86490\n",
            "Epoch 448/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3790 - acc: 0.8935 - val_loss: 0.4799 - val_acc: 0.8595\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.86490\n",
            "Epoch 449/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3687 - acc: 0.8936 - val_loss: 0.4575 - val_acc: 0.8664\n",
            "\n",
            "Epoch 00449: val_acc improved from 0.86490 to 0.86640, saving model to /content/saved_models/cifar10_ResNet32v1_model.449.h5\n",
            "Epoch 450/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3636 - acc: 0.8984 - val_loss: 0.4868 - val_acc: 0.8607\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.86640\n",
            "Epoch 451/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3857 - acc: 0.8911 - val_loss: 0.5157 - val_acc: 0.8507\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.86640\n",
            "Epoch 452/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3827 - acc: 0.8936 - val_loss: 0.4641 - val_acc: 0.8620\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.86640\n",
            "Epoch 453/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3734 - acc: 0.8957 - val_loss: 0.4776 - val_acc: 0.8614\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.86640\n",
            "Epoch 454/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3824 - acc: 0.8920 - val_loss: 0.4749 - val_acc: 0.8604\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.86640\n",
            "Epoch 455/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3633 - acc: 0.8980 - val_loss: 0.4700 - val_acc: 0.8634\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.86640\n",
            "Epoch 456/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3673 - acc: 0.9002 - val_loss: 0.5143 - val_acc: 0.8507\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.86640\n",
            "Epoch 457/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3771 - acc: 0.8929 - val_loss: 0.4754 - val_acc: 0.8617\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.86640\n",
            "Epoch 458/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3703 - acc: 0.8954 - val_loss: 0.5333 - val_acc: 0.8452\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.86640\n",
            "Epoch 459/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3787 - acc: 0.8905 - val_loss: 0.4812 - val_acc: 0.8596\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.86640\n",
            "Epoch 460/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3716 - acc: 0.8914 - val_loss: 0.4800 - val_acc: 0.8575\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.86640\n",
            "Epoch 461/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3729 - acc: 0.8899 - val_loss: 0.4881 - val_acc: 0.8561\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.86640\n",
            "Epoch 462/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3574 - acc: 0.9019 - val_loss: 0.4748 - val_acc: 0.8628\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.86640\n",
            "Epoch 463/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3633 - acc: 0.9016 - val_loss: 0.4951 - val_acc: 0.8548\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.86640\n",
            "Epoch 464/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3529 - acc: 0.9042 - val_loss: 0.4674 - val_acc: 0.8624\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.86640\n",
            "Epoch 465/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3647 - acc: 0.8979 - val_loss: 0.4711 - val_acc: 0.8614\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.86640\n",
            "Epoch 466/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3560 - acc: 0.9005 - val_loss: 0.5064 - val_acc: 0.8517\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.86640\n",
            "Epoch 467/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3558 - acc: 0.8958 - val_loss: 0.4663 - val_acc: 0.8642\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.86640\n",
            "Epoch 468/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3705 - acc: 0.8946 - val_loss: 0.4731 - val_acc: 0.8605\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.86640\n",
            "Epoch 469/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3571 - acc: 0.9026 - val_loss: 0.4848 - val_acc: 0.8604\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.86640\n",
            "Epoch 470/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3665 - acc: 0.8987 - val_loss: 0.4794 - val_acc: 0.8623\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.86640\n",
            "Epoch 471/500\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3729 - acc: 0.8960 - val_loss: 0.5074 - val_acc: 0.8499\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.86640\n",
            "Epoch 472/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3626 - acc: 0.8945 - val_loss: 0.4733 - val_acc: 0.8613\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.86640\n",
            "Epoch 473/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3614 - acc: 0.8993 - val_loss: 0.4603 - val_acc: 0.8674\n",
            "\n",
            "Epoch 00473: val_acc improved from 0.86640 to 0.86740, saving model to /content/saved_models/cifar10_ResNet32v1_model.473.h5\n",
            "Epoch 474/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3399 - acc: 0.9092 - val_loss: 0.4575 - val_acc: 0.8692\n",
            "\n",
            "Epoch 00474: val_acc improved from 0.86740 to 0.86920, saving model to /content/saved_models/cifar10_ResNet32v1_model.474.h5\n",
            "Epoch 475/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3533 - acc: 0.9032 - val_loss: 0.4593 - val_acc: 0.8676\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.86920\n",
            "Epoch 476/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3380 - acc: 0.9083 - val_loss: 0.4511 - val_acc: 0.8702\n",
            "\n",
            "Epoch 00476: val_acc improved from 0.86920 to 0.87020, saving model to /content/saved_models/cifar10_ResNet32v1_model.476.h5\n",
            "Epoch 477/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3498 - acc: 0.9022 - val_loss: 0.4540 - val_acc: 0.8688\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.87020\n",
            "Epoch 478/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3568 - acc: 0.9014 - val_loss: 0.4553 - val_acc: 0.8677\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.87020\n",
            "Epoch 479/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3504 - acc: 0.9037 - val_loss: 0.4528 - val_acc: 0.8686\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.87020\n",
            "Epoch 480/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3503 - acc: 0.9002 - val_loss: 0.4546 - val_acc: 0.8682\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.87020\n",
            "Epoch 481/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3435 - acc: 0.9039 - val_loss: 0.4510 - val_acc: 0.8692\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.87020\n",
            "Epoch 482/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3452 - acc: 0.9066 - val_loss: 0.4494 - val_acc: 0.8698\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.87020\n",
            "Epoch 483/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3443 - acc: 0.9013 - val_loss: 0.4507 - val_acc: 0.8698\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.87020\n",
            "Epoch 484/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3656 - acc: 0.9004 - val_loss: 0.4501 - val_acc: 0.8685\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.87020\n",
            "Epoch 485/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.3463 - acc: 0.9031 - val_loss: 0.4516 - val_acc: 0.8694\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.87020\n",
            "Epoch 486/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3564 - acc: 0.9020 - val_loss: 0.4478 - val_acc: 0.8695\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.87020\n",
            "Epoch 487/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3540 - acc: 0.9034 - val_loss: 0.4505 - val_acc: 0.8693\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.87020\n",
            "Epoch 488/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3442 - acc: 0.9033 - val_loss: 0.4503 - val_acc: 0.8691\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.87020\n",
            "Epoch 489/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.3511 - acc: 0.9052 - val_loss: 0.4530 - val_acc: 0.8673\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.87020\n",
            "Epoch 490/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3379 - acc: 0.9069 - val_loss: 0.4547 - val_acc: 0.8675\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.87020\n",
            "Epoch 491/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3483 - acc: 0.9024 - val_loss: 0.4520 - val_acc: 0.8700\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.87020\n",
            "Epoch 492/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3617 - acc: 0.9021 - val_loss: 0.4524 - val_acc: 0.8694\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.87020\n",
            "Epoch 493/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3544 - acc: 0.9038 - val_loss: 0.4523 - val_acc: 0.8695\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.87020\n",
            "Epoch 494/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3497 - acc: 0.9031 - val_loss: 0.4498 - val_acc: 0.8704\n",
            "\n",
            "Epoch 00494: val_acc improved from 0.87020 to 0.87040, saving model to /content/saved_models/cifar10_ResNet32v1_model.494.h5\n",
            "Epoch 495/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3406 - acc: 0.9093 - val_loss: 0.4496 - val_acc: 0.8693\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.87040\n",
            "Epoch 496/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.3428 - acc: 0.9007 - val_loss: 0.4498 - val_acc: 0.8695\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.87040\n",
            "Epoch 497/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3421 - acc: 0.9089 - val_loss: 0.4532 - val_acc: 0.8689\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.87040\n",
            "Epoch 498/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3502 - acc: 0.9063 - val_loss: 0.4510 - val_acc: 0.8702\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.87040\n",
            "Epoch 499/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3537 - acc: 0.9059 - val_loss: 0.4483 - val_acc: 0.8696\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.87040\n",
            "Epoch 500/500\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3431 - acc: 0.9036 - val_loss: 0.4498 - val_acc: 0.8700\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.87040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "bOlV0M-cnuBC",
        "outputId": "ccde3679-59ce-45ca-dcac-9b816e2daeb4"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('R_10_trainHistoryDict_clip_05', \"rb\"))\n",
        "functions.plot_loss_acc(history, 4, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtv_MFbSn0Mf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad2a157-f754-445c-96e5-a857e709d5df"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12999999523162842"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "QGNeJvE6yKkp",
        "outputId": "e264ae75-1b37-49f9-80ea-b659df34082e"
      },
      "source": [
        "plot_final_graph(\"R_10_\", False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgQrXQb3y90i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "compress_first_TT_experiments",
      "provenance": [],
      "collapsed_sections": [
        "Q2gf23x1rHE7",
        "FUSAJEF5zZCK",
        "aZVJDAmRzfzc",
        "EBFMbHvLIf5g",
        "4cP6RpFPvdW8",
        "SYsweyOS3wPM",
        "Zjepj31fVNww",
        "Xq3bNGTuDGIm",
        "FO9ydg0YT2e2",
        "KgRj4CpUqu7P",
        "jJiW0sKS4Tgp",
        "aPvHJjYAfVq8",
        "zCygJmhBfcNw",
        "cDiiZG682ca2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WhiteTeaDragon/SingularValues/blob/main/TT/compress_first_TT_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFqGu4P1VFlm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e92b5c5a-47c7-4bba-e692-086f069714e1"
      },
      "source": [
        "!pip install tensorflow-determinism"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-determinism\n",
            "  Downloading https://files.pythonhosted.org/packages/76/56/79d74f25b326d8719753172496abc524980fa67d1d98bb247021376e370a/tensorflow-determinism-0.3.0.tar.gz\n",
            "Building wheels for collected packages: tensorflow-determinism\n",
            "  Building wheel for tensorflow-determinism (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-determinism: filename=tensorflow_determinism-0.3.0-cp37-none-any.whl size=9158 sha256=a8182f0d01351ca7784562b6b184547f4ed9be01d0df6ee7e5f9057e655d3c05\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/c3/18/13959a90d3e0d10182a99866d6ff4d0119e9daed6ce014b54c\n",
            "Successfully built tensorflow-determinism\n",
            "Installing collected packages: tensorflow-determinism\n",
            "Successfully installed tensorflow-determinism-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "praf7vwRHu5P"
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWOFa_uBGS8u"
      },
      "source": [
        "import functions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWn7MN-iaAXi",
        "outputId": "0ef97565-a237-40d7-ef59-89533bd44b6c"
      },
      "source": [
        "import importlib\n",
        "importlib.reload(functions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'functions' from '/content/functions.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfKVz1MXUZc1"
      },
      "source": [
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "SEED = 123\n",
        "os.environ['PYTHONHASHSEED']=str(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PBmtSgLffdr"
      },
      "source": [
        "Время на обучение у разных моделей может отличаться -- это происходит из-за того, что они обучались в разных сессиях Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwqz2XLi4WU7"
      },
      "source": [
        "def plot_final_graph(addition=\"\", third=True, ylim_loss=4, ylim_error=1):\n",
        "    history_no_clipping = pickle.load(open(addition + 'trainHistoryDict', \"rb\"))\n",
        "    history_05 = pickle.load(open(addition + 'trainHistoryDict_clip_05', \"rb\"))\n",
        "    if third:\n",
        "        history_1 = pickle.load(open(addition + 'trainHistoryDict_clip_1', \"rb\"))\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
        "    axs[0].grid(True)\n",
        "    axs[1].grid(True)\n",
        "    max_len = len(history_no_clipping['val_loss'])\n",
        "    axs[0].plot(history_no_clipping['val_loss'][4:max_len:5], label='no clipping')\n",
        "    axs[0].plot(history_05['val_loss'][4:max_len:5], label='0.5')\n",
        "    if third:\n",
        "        axs[0].plot(history_1['val_loss'][4:max_len:5], label='1')\n",
        "    axs[0].set_title('Loss')\n",
        "    axs[0].set_xlabel('Epochs')\n",
        "    axs[0].set_ylim(0, ylim_loss)\n",
        "    axs[1].plot(1 - np.array(history_no_clipping['val_acc'][4:max_len:5]), label='no clipping')\n",
        "    axs[1].plot(1 - np.array(history_05['val_acc'][4:max_len:5]), label='0.5')\n",
        "    if third:\n",
        "        axs[1].plot(1 - np.array(history_1['val_acc'][4:max_len:5]), label='1')\n",
        "    axs[1].set_title('Error')\n",
        "    axs[1].set_xlabel('Epochs')\n",
        "    axs[1].set_ylim(0, ylim_error)\n",
        "    axs[0].legend(loc='best')\n",
        "    axs[1].legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2gf23x1rHE7"
      },
      "source": [
        "### Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceD49furq4ux",
        "outputId": "aa0d159a-cd6a-4ded-c94c-bd8f69e2f4c9"
      },
      "source": [
        "num_classes = 10\n",
        "\n",
        "# load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# if subtract pixel mean is enabled\n",
        "x_train_mean = np.mean(x_train, axis=0)\n",
        "x_train -= x_train_mean\n",
        "x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# convert class vectors to binary class matrices.\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUSAJEF5zZCK"
      },
      "source": [
        "### Without decomposition & compress_first = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZVJDAmRzfzc"
      },
      "source": [
        "#### Model without clipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYSrjJb-1409",
        "outputId": "b18f0dc7-492b-4200-ff01-7fc9dd39afa0"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(input_shape)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 16)   2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 16)   0           activation[0][0]                 \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 16)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 16)   0           activation_2[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 16)   0           activation_4[0][0]               \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 16)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 16)   2320        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 16)   0           activation_6[0][0]               \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 16)   2320        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 32, 32, 16)   0           activation_8[0][0]               \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 16)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   4640        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 32)   544         activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 32)   0           conv2d_13[0][0]                  \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 32)   9248        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 32)   128         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 32)   0           activation_12[0][0]              \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 32)   9248        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 32)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 16, 16, 32)   0           activation_14[0][0]              \n",
            "                                                                 batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 32)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 32)   9248        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 32)   128         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 16, 16, 32)   0           activation_16[0][0]              \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 32)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 32)   9248        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 32)   128         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 32)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 32)   9248        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 16, 16, 32)   0           activation_18[0][0]              \n",
            "                                                                 batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 8, 64)     18496       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 64)     256         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8, 8, 64)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 8, 8, 64)     36928       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 8, 8, 64)     2112        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 8, 8, 64)     256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 8, 64)     0           conv2d_24[0][0]                  \n",
            "                                                                 batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 8, 64)     0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 8, 8, 64)     36928       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 8, 8, 64)     256         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 8, 8, 64)     0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 8, 8, 64)     36928       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 8, 8, 64)     256         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 8, 8, 64)     0           activation_22[0][0]              \n",
            "                                                                 batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 8, 8, 64)     0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 64)     36928       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 8, 8, 64)     256         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 8, 8, 64)     0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 64)     36928       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 8, 64)     0           activation_24[0][0]              \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 64)     0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 64)     36928       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 64)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 64)     36928       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 8, 8, 64)     0           activation_26[0][0]              \n",
            "                                                                 batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 64)     0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 64)     36928       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 64)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 64)     36928       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 8, 8, 64)     0           activation_28[0][0]              \n",
            "                                                                 batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 64)     0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 64)     0           activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 64)           0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           650         flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 470,218\n",
            "Trainable params: 467,946\n",
            "Non-trainable params: 2,272\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjID6DOf2F36",
        "outputId": "1efd5543-d1db-4765-ecc0-15b1005b7b44"
      },
      "source": [
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'simple_trainHistoryDict', steps_per_epoch=100,\n",
        "                       batch_size=100, epochs=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Epoch 1/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 41s 83ms/step - loss: 2.7917 - acc: 0.2219 - val_loss: 2.3573 - val_acc: 0.2291\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.22910, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.8881 - acc: 0.3917 - val_loss: 2.0455 - val_acc: 0.3656\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.22910 to 0.36560, saving model to /content/saved_models/cifar10_ResNet32v1_model.002.h5\n",
            "Epoch 3/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.7052 - acc: 0.4599 - val_loss: 2.1614 - val_acc: 0.3371\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.36560\n",
            "Epoch 4/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.6138 - acc: 0.5131 - val_loss: 1.8819 - val_acc: 0.4220\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.36560 to 0.42200, saving model to /content/saved_models/cifar10_ResNet32v1_model.004.h5\n",
            "Epoch 5/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.5030 - acc: 0.5427 - val_loss: 1.5544 - val_acc: 0.5389\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.42200 to 0.53890, saving model to /content/saved_models/cifar10_ResNet32v1_model.005.h5\n",
            "Epoch 6/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.4443 - acc: 0.5735 - val_loss: 2.3545 - val_acc: 0.3883\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.53890\n",
            "Epoch 7/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.3409 - acc: 0.6062 - val_loss: 1.8422 - val_acc: 0.4894\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.53890\n",
            "Epoch 8/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.2782 - acc: 0.6317 - val_loss: 2.1510 - val_acc: 0.4281\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.53890\n",
            "Epoch 9/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.2750 - acc: 0.6320 - val_loss: 2.0645 - val_acc: 0.4674\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.53890\n",
            "Epoch 10/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.2217 - acc: 0.6419 - val_loss: 1.6657 - val_acc: 0.5276\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.53890\n",
            "Epoch 11/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.1674 - acc: 0.6763 - val_loss: 1.5014 - val_acc: 0.5551\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.53890 to 0.55510, saving model to /content/saved_models/cifar10_ResNet32v1_model.011.h5\n",
            "Epoch 12/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.1179 - acc: 0.6789 - val_loss: 1.9582 - val_acc: 0.5055\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.55510\n",
            "Epoch 13/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.0905 - acc: 0.6958 - val_loss: 1.7686 - val_acc: 0.5308\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.55510\n",
            "Epoch 14/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.0857 - acc: 0.7006 - val_loss: 2.2155 - val_acc: 0.4995\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.55510\n",
            "Epoch 15/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.0401 - acc: 0.7178 - val_loss: 1.2924 - val_acc: 0.6301\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.55510 to 0.63010, saving model to /content/saved_models/cifar10_ResNet32v1_model.015.h5\n",
            "Epoch 16/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.0120 - acc: 0.7213 - val_loss: 1.0936 - val_acc: 0.6955\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.63010 to 0.69550, saving model to /content/saved_models/cifar10_ResNet32v1_model.016.h5\n",
            "Epoch 17/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.9839 - acc: 0.7299 - val_loss: 1.2644 - val_acc: 0.6521\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.69550\n",
            "Epoch 18/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9804 - acc: 0.7338 - val_loss: 1.4880 - val_acc: 0.5987\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.69550\n",
            "Epoch 19/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.9635 - acc: 0.7352 - val_loss: 1.5609 - val_acc: 0.5911\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.69550\n",
            "Epoch 20/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9496 - acc: 0.7411 - val_loss: 1.2798 - val_acc: 0.6422\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.69550\n",
            "Epoch 21/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.9427 - acc: 0.7443 - val_loss: 1.3395 - val_acc: 0.6167\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.69550\n",
            "Epoch 22/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.9248 - acc: 0.7502 - val_loss: 1.1253 - val_acc: 0.6956\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.69550 to 0.69560, saving model to /content/saved_models/cifar10_ResNet32v1_model.022.h5\n",
            "Epoch 23/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.9006 - acc: 0.7614 - val_loss: 1.3942 - val_acc: 0.6477\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.69560\n",
            "Epoch 24/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9245 - acc: 0.7488 - val_loss: 1.2264 - val_acc: 0.6819\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.69560\n",
            "Epoch 25/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8584 - acc: 0.7723 - val_loss: 2.2518 - val_acc: 0.5116\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.69560\n",
            "Epoch 26/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8688 - acc: 0.7654 - val_loss: 1.9974 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.69560\n",
            "Epoch 27/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8264 - acc: 0.7894 - val_loss: 1.0888 - val_acc: 0.7157\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.69560 to 0.71570, saving model to /content/saved_models/cifar10_ResNet32v1_model.027.h5\n",
            "Epoch 28/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8369 - acc: 0.7831 - val_loss: 1.0199 - val_acc: 0.7212\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.71570 to 0.72120, saving model to /content/saved_models/cifar10_ResNet32v1_model.028.h5\n",
            "Epoch 29/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8358 - acc: 0.7797 - val_loss: 1.1612 - val_acc: 0.6783\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.72120\n",
            "Epoch 30/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.8279 - acc: 0.7840 - val_loss: 1.5258 - val_acc: 0.6003\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.72120\n",
            "Epoch 31/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8344 - acc: 0.7854 - val_loss: 1.3518 - val_acc: 0.6287\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.72120\n",
            "Epoch 32/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8262 - acc: 0.7791 - val_loss: 1.2475 - val_acc: 0.6609\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.72120\n",
            "Epoch 33/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8167 - acc: 0.7864 - val_loss: 1.1745 - val_acc: 0.6987\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.72120\n",
            "Epoch 34/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7594 - acc: 0.8101 - val_loss: 0.9930 - val_acc: 0.7396\n",
            "\n",
            "Epoch 00034: val_acc improved from 0.72120 to 0.73960, saving model to /content/saved_models/cifar10_ResNet32v1_model.034.h5\n",
            "Epoch 35/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7827 - acc: 0.8033 - val_loss: 0.9648 - val_acc: 0.7471\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.73960 to 0.74710, saving model to /content/saved_models/cifar10_ResNet32v1_model.035.h5\n",
            "Epoch 36/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.7772 - acc: 0.7983 - val_loss: 1.2062 - val_acc: 0.6843\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.74710\n",
            "Epoch 37/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7632 - acc: 0.8054 - val_loss: 1.0416 - val_acc: 0.7114\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.74710\n",
            "Epoch 38/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.7672 - acc: 0.8077 - val_loss: 0.9819 - val_acc: 0.7333\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.74710\n",
            "Epoch 39/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7513 - acc: 0.8055 - val_loss: 1.0230 - val_acc: 0.7176\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.74710\n",
            "Epoch 40/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7381 - acc: 0.8110 - val_loss: 0.9133 - val_acc: 0.7546\n",
            "\n",
            "Epoch 00040: val_acc improved from 0.74710 to 0.75460, saving model to /content/saved_models/cifar10_ResNet32v1_model.040.h5\n",
            "Epoch 41/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7403 - acc: 0.8142 - val_loss: 1.0525 - val_acc: 0.7259\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.75460\n",
            "Epoch 42/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7462 - acc: 0.8073 - val_loss: 0.9765 - val_acc: 0.7513\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.75460\n",
            "Epoch 43/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7166 - acc: 0.8170 - val_loss: 1.1618 - val_acc: 0.6971\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.75460\n",
            "Epoch 44/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7271 - acc: 0.8185 - val_loss: 1.1486 - val_acc: 0.7115\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.75460\n",
            "Epoch 45/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6986 - acc: 0.8225 - val_loss: 1.0484 - val_acc: 0.7133\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.75460\n",
            "Epoch 46/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.7148 - acc: 0.8224 - val_loss: 0.9758 - val_acc: 0.7404\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.75460\n",
            "Epoch 47/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7076 - acc: 0.8225 - val_loss: 1.1730 - val_acc: 0.7137\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.75460\n",
            "Epoch 48/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6986 - acc: 0.8315 - val_loss: 0.9340 - val_acc: 0.7537\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.75460\n",
            "Epoch 49/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6911 - acc: 0.8283 - val_loss: 0.9484 - val_acc: 0.7501\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.75460\n",
            "Epoch 50/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6969 - acc: 0.8259 - val_loss: 1.1239 - val_acc: 0.6992\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.75460\n",
            "Epoch 51/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6651 - acc: 0.8352 - val_loss: 1.0633 - val_acc: 0.7376\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.75460\n",
            "Epoch 52/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6918 - acc: 0.8290 - val_loss: 1.7289 - val_acc: 0.5983\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.75460\n",
            "Epoch 53/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.7092 - acc: 0.8220 - val_loss: 0.9287 - val_acc: 0.7595\n",
            "\n",
            "Epoch 00053: val_acc improved from 0.75460 to 0.75950, saving model to /content/saved_models/cifar10_ResNet32v1_model.053.h5\n",
            "Epoch 54/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6614 - acc: 0.8382 - val_loss: 0.8823 - val_acc: 0.7569\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.75950\n",
            "Epoch 55/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6732 - acc: 0.8315 - val_loss: 0.9849 - val_acc: 0.7507\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.75950\n",
            "Epoch 56/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6568 - acc: 0.8379 - val_loss: 1.0759 - val_acc: 0.7228\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.75950\n",
            "Epoch 57/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6423 - acc: 0.8436 - val_loss: 0.7996 - val_acc: 0.7952\n",
            "\n",
            "Epoch 00057: val_acc improved from 0.75950 to 0.79520, saving model to /content/saved_models/cifar10_ResNet32v1_model.057.h5\n",
            "Epoch 58/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6656 - acc: 0.8365 - val_loss: 1.1049 - val_acc: 0.7299\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.79520\n",
            "Epoch 59/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6688 - acc: 0.8321 - val_loss: 1.1031 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.79520\n",
            "Epoch 60/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6562 - acc: 0.8358 - val_loss: 0.9279 - val_acc: 0.7509\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.79520\n",
            "Epoch 61/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6351 - acc: 0.8459 - val_loss: 0.8573 - val_acc: 0.7828\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.79520\n",
            "Epoch 62/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6722 - acc: 0.8383 - val_loss: 0.8526 - val_acc: 0.7857\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.79520\n",
            "Epoch 63/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6282 - acc: 0.8525 - val_loss: 1.1547 - val_acc: 0.7238\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.79520\n",
            "Epoch 64/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6216 - acc: 0.8509 - val_loss: 1.2750 - val_acc: 0.6902\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.79520\n",
            "Epoch 65/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6225 - acc: 0.8452 - val_loss: 0.9463 - val_acc: 0.7652\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.79520\n",
            "Epoch 66/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6105 - acc: 0.8559 - val_loss: 1.0440 - val_acc: 0.7389\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.79520\n",
            "Epoch 67/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6377 - acc: 0.8429 - val_loss: 0.9184 - val_acc: 0.7619\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.79520\n",
            "Epoch 68/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6319 - acc: 0.8482 - val_loss: 0.9735 - val_acc: 0.7557\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.79520\n",
            "Epoch 69/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6197 - acc: 0.8514 - val_loss: 0.9155 - val_acc: 0.7615\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.79520\n",
            "Epoch 70/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6120 - acc: 0.8591 - val_loss: 0.7543 - val_acc: 0.8140\n",
            "\n",
            "Epoch 00070: val_acc improved from 0.79520 to 0.81400, saving model to /content/saved_models/cifar10_ResNet32v1_model.070.h5\n",
            "Epoch 71/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5971 - acc: 0.8611 - val_loss: 0.8425 - val_acc: 0.7731\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.81400\n",
            "Epoch 72/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6074 - acc: 0.8568 - val_loss: 0.8468 - val_acc: 0.7850\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.81400\n",
            "Epoch 73/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5760 - acc: 0.8677 - val_loss: 0.8759 - val_acc: 0.7760\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.81400\n",
            "Epoch 74/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6146 - acc: 0.8532 - val_loss: 0.8554 - val_acc: 0.7742\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.81400\n",
            "Epoch 75/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6088 - acc: 0.8545 - val_loss: 0.8282 - val_acc: 0.7934\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.81400\n",
            "Epoch 76/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5966 - acc: 0.8554 - val_loss: 0.9090 - val_acc: 0.7688\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.81400\n",
            "Epoch 77/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5903 - acc: 0.8648 - val_loss: 0.7742 - val_acc: 0.8100\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.81400\n",
            "Epoch 78/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5912 - acc: 0.8579 - val_loss: 0.8025 - val_acc: 0.7937\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.81400\n",
            "Epoch 79/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5773 - acc: 0.8680 - val_loss: 0.9038 - val_acc: 0.7771\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.81400\n",
            "Epoch 80/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.5794 - acc: 0.8671 - val_loss: 1.0124 - val_acc: 0.7430\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.81400\n",
            "Epoch 81/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5986 - acc: 0.8608 - val_loss: 0.8916 - val_acc: 0.7776\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.81400\n",
            "Epoch 82/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5762 - acc: 0.8732 - val_loss: 0.7365 - val_acc: 0.8209\n",
            "\n",
            "Epoch 00082: val_acc improved from 0.81400 to 0.82090, saving model to /content/saved_models/cifar10_ResNet32v1_model.082.h5\n",
            "Epoch 83/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5882 - acc: 0.8599 - val_loss: 1.0098 - val_acc: 0.7403\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.82090\n",
            "Epoch 84/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5827 - acc: 0.8684 - val_loss: 0.9415 - val_acc: 0.7613\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.82090\n",
            "Epoch 85/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5644 - acc: 0.8680 - val_loss: 0.8748 - val_acc: 0.7851\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.82090\n",
            "Epoch 86/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5539 - acc: 0.8719 - val_loss: 0.9657 - val_acc: 0.7689\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.82090\n",
            "Epoch 87/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5804 - acc: 0.8656 - val_loss: 0.9822 - val_acc: 0.7619\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.82090\n",
            "Epoch 88/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5751 - acc: 0.8674 - val_loss: 0.9051 - val_acc: 0.7776\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.82090\n",
            "Epoch 89/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5549 - acc: 0.8748 - val_loss: 0.8442 - val_acc: 0.7955\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.82090\n",
            "Epoch 90/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5683 - acc: 0.8692 - val_loss: 1.1180 - val_acc: 0.7201\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.82090\n",
            "Epoch 91/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5652 - acc: 0.8732 - val_loss: 1.1057 - val_acc: 0.7166\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.82090\n",
            "Epoch 92/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5621 - acc: 0.8713 - val_loss: 0.9378 - val_acc: 0.7802\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.82090\n",
            "Epoch 93/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5689 - acc: 0.8691 - val_loss: 0.7497 - val_acc: 0.8035\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.82090\n",
            "Epoch 94/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5688 - acc: 0.8698 - val_loss: 1.3253 - val_acc: 0.7030\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.82090\n",
            "Epoch 95/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5558 - acc: 0.8699 - val_loss: 0.8225 - val_acc: 0.7998\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.82090\n",
            "Epoch 96/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5746 - acc: 0.8657 - val_loss: 1.3325 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.82090\n",
            "Epoch 97/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5341 - acc: 0.8841 - val_loss: 0.9161 - val_acc: 0.7655\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.82090\n",
            "Epoch 98/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5373 - acc: 0.8822 - val_loss: 1.0970 - val_acc: 0.7383\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.82090\n",
            "Epoch 99/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5248 - acc: 0.8869 - val_loss: 0.9046 - val_acc: 0.7894\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.82090\n",
            "Epoch 100/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5588 - acc: 0.8760 - val_loss: 1.0311 - val_acc: 0.7412\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.82090\n",
            "Epoch 101/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5630 - acc: 0.8715 - val_loss: 0.8098 - val_acc: 0.8020\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.82090\n",
            "Epoch 102/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5373 - acc: 0.8823 - val_loss: 0.7706 - val_acc: 0.8120\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.82090\n",
            "Epoch 103/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5653 - acc: 0.8721 - val_loss: 1.3472 - val_acc: 0.6967\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.82090\n",
            "Epoch 104/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5269 - acc: 0.8829 - val_loss: 0.8820 - val_acc: 0.7846\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.82090\n",
            "Epoch 105/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5453 - acc: 0.8758 - val_loss: 1.2220 - val_acc: 0.7181\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.82090\n",
            "Epoch 106/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5362 - acc: 0.8845 - val_loss: 0.8292 - val_acc: 0.7927\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.82090\n",
            "Epoch 107/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5491 - acc: 0.8788 - val_loss: 0.7816 - val_acc: 0.8091\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.82090\n",
            "Epoch 108/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5050 - acc: 0.8957 - val_loss: 0.9262 - val_acc: 0.7885\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.82090\n",
            "Epoch 109/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5302 - acc: 0.8863 - val_loss: 0.7075 - val_acc: 0.8296\n",
            "\n",
            "Epoch 00109: val_acc improved from 0.82090 to 0.82960, saving model to /content/saved_models/cifar10_ResNet32v1_model.109.h5\n",
            "Epoch 110/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5297 - acc: 0.8836 - val_loss: 0.7696 - val_acc: 0.8230\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.82960\n",
            "Epoch 111/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5269 - acc: 0.8808 - val_loss: 0.8664 - val_acc: 0.7837\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.82960\n",
            "Epoch 112/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5254 - acc: 0.8888 - val_loss: 0.7935 - val_acc: 0.8070\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.82960\n",
            "Epoch 113/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5228 - acc: 0.8916 - val_loss: 0.9615 - val_acc: 0.7609\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.82960\n",
            "Epoch 114/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5223 - acc: 0.8847 - val_loss: 0.8401 - val_acc: 0.7914\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.82960\n",
            "Epoch 115/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5179 - acc: 0.8894 - val_loss: 0.9835 - val_acc: 0.7684\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.82960\n",
            "Epoch 116/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5260 - acc: 0.8790 - val_loss: 0.9361 - val_acc: 0.7727\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.82960\n",
            "Epoch 117/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5447 - acc: 0.8812 - val_loss: 0.8277 - val_acc: 0.7964\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.82960\n",
            "Epoch 118/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5195 - acc: 0.8837 - val_loss: 0.8952 - val_acc: 0.7940\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.82960\n",
            "Epoch 119/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5145 - acc: 0.8891 - val_loss: 0.9242 - val_acc: 0.7765\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.82960\n",
            "Epoch 120/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5411 - acc: 0.8795 - val_loss: 0.8581 - val_acc: 0.7855\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.82960\n",
            "Epoch 121/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4897 - acc: 0.8982 - val_loss: 0.8325 - val_acc: 0.7953\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.82960\n",
            "Epoch 122/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5198 - acc: 0.8849 - val_loss: 0.9437 - val_acc: 0.7736\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.82960\n",
            "Epoch 123/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5209 - acc: 0.8873 - val_loss: 0.6966 - val_acc: 0.8291\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.82960\n",
            "Epoch 124/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4914 - acc: 0.8961 - val_loss: 0.8602 - val_acc: 0.7831\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.82960\n",
            "Epoch 125/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4789 - acc: 0.9040 - val_loss: 0.9890 - val_acc: 0.7588\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.82960\n",
            "Epoch 126/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5059 - acc: 0.8934 - val_loss: 1.1877 - val_acc: 0.7301\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.82960\n",
            "Epoch 127/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5032 - acc: 0.8927 - val_loss: 0.7272 - val_acc: 0.8276\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.82960\n",
            "Epoch 128/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5057 - acc: 0.8890 - val_loss: 0.8406 - val_acc: 0.7930\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.82960\n",
            "Epoch 129/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5083 - acc: 0.8893 - val_loss: 0.9669 - val_acc: 0.7580\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.82960\n",
            "Epoch 130/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5065 - acc: 0.8937 - val_loss: 0.9088 - val_acc: 0.7781\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.82960\n",
            "Epoch 131/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4956 - acc: 0.8935 - val_loss: 0.8971 - val_acc: 0.7866\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.82960\n",
            "Epoch 132/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5186 - acc: 0.8900 - val_loss: 1.0260 - val_acc: 0.7619\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.82960\n",
            "Epoch 133/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4906 - acc: 0.8940 - val_loss: 1.0400 - val_acc: 0.7622\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.82960\n",
            "Epoch 134/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.4809 - acc: 0.9007 - val_loss: 1.0715 - val_acc: 0.7609\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.82960\n",
            "Epoch 135/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4914 - acc: 0.8949 - val_loss: 0.7459 - val_acc: 0.8255\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.82960\n",
            "Epoch 136/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5035 - acc: 0.8890 - val_loss: 0.7743 - val_acc: 0.8150\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.82960\n",
            "Epoch 137/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4865 - acc: 0.9008 - val_loss: 0.7608 - val_acc: 0.8164\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.82960\n",
            "Epoch 138/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4812 - acc: 0.8983 - val_loss: 0.9314 - val_acc: 0.7780\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.82960\n",
            "Epoch 139/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5142 - acc: 0.8911 - val_loss: 0.8120 - val_acc: 0.8020\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.82960\n",
            "Epoch 140/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5089 - acc: 0.8908 - val_loss: 0.7798 - val_acc: 0.8084\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.82960\n",
            "Epoch 141/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4779 - acc: 0.9021 - val_loss: 0.9337 - val_acc: 0.7783\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.82960\n",
            "Epoch 142/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4869 - acc: 0.8981 - val_loss: 0.8430 - val_acc: 0.8041\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.82960\n",
            "Epoch 143/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4882 - acc: 0.8990 - val_loss: 0.8237 - val_acc: 0.8087\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.82960\n",
            "Epoch 144/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4785 - acc: 0.9018 - val_loss: 0.9233 - val_acc: 0.7832\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.82960\n",
            "Epoch 145/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4765 - acc: 0.9002 - val_loss: 1.1600 - val_acc: 0.7402\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.82960\n",
            "Epoch 146/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4901 - acc: 0.8928 - val_loss: 0.7021 - val_acc: 0.8317\n",
            "\n",
            "Epoch 00146: val_acc improved from 0.82960 to 0.83170, saving model to /content/saved_models/cifar10_ResNet32v1_model.146.h5\n",
            "Epoch 147/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4995 - acc: 0.8913 - val_loss: 0.7749 - val_acc: 0.8172\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.83170\n",
            "Epoch 148/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4732 - acc: 0.9042 - val_loss: 0.7311 - val_acc: 0.8245\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.83170\n",
            "Epoch 149/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4961 - acc: 0.8947 - val_loss: 0.8270 - val_acc: 0.8012\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.83170\n",
            "Epoch 150/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4734 - acc: 0.9026 - val_loss: 0.7302 - val_acc: 0.8274\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.83170\n",
            "Epoch 151/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4731 - acc: 0.9017 - val_loss: 0.8536 - val_acc: 0.7943\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.83170\n",
            "Epoch 152/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4983 - acc: 0.8927 - val_loss: 0.7299 - val_acc: 0.8291\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.83170\n",
            "Epoch 153/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4778 - acc: 0.9010 - val_loss: 0.8402 - val_acc: 0.7999\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.83170\n",
            "Epoch 154/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4681 - acc: 0.9032 - val_loss: 0.7196 - val_acc: 0.8288\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.83170\n",
            "Epoch 155/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4692 - acc: 0.9029 - val_loss: 0.8495 - val_acc: 0.8062\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.83170\n",
            "Epoch 156/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4677 - acc: 0.9046 - val_loss: 0.8068 - val_acc: 0.8127\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.83170\n",
            "Epoch 157/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4790 - acc: 0.8996 - val_loss: 0.9271 - val_acc: 0.7934\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.83170\n",
            "Epoch 158/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4873 - acc: 0.8995 - val_loss: 0.7201 - val_acc: 0.8386\n",
            "\n",
            "Epoch 00158: val_acc improved from 0.83170 to 0.83860, saving model to /content/saved_models/cifar10_ResNet32v1_model.158.h5\n",
            "Epoch 159/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4977 - acc: 0.8962 - val_loss: 0.7495 - val_acc: 0.8277\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.83860\n",
            "Epoch 160/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4959 - acc: 0.8978 - val_loss: 0.8236 - val_acc: 0.7985\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.83860\n",
            "Epoch 161/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4538 - acc: 0.9088 - val_loss: 0.8986 - val_acc: 0.7990\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.83860\n",
            "Epoch 162/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4625 - acc: 0.9080 - val_loss: 0.8518 - val_acc: 0.7915\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.83860\n",
            "Epoch 163/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4642 - acc: 0.9046 - val_loss: 0.9348 - val_acc: 0.7882\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.83860\n",
            "Epoch 164/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4658 - acc: 0.9070 - val_loss: 1.0637 - val_acc: 0.7704\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.83860\n",
            "Epoch 165/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4677 - acc: 0.9071 - val_loss: 0.8199 - val_acc: 0.8084\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.83860\n",
            "Epoch 166/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4765 - acc: 0.9042 - val_loss: 0.8807 - val_acc: 0.8067\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.83860\n",
            "Epoch 167/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4673 - acc: 0.9040 - val_loss: 0.7487 - val_acc: 0.8218\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.83860\n",
            "Epoch 168/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4513 - acc: 0.9088 - val_loss: 0.7737 - val_acc: 0.8245\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.83860\n",
            "Epoch 169/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4581 - acc: 0.9126 - val_loss: 0.7371 - val_acc: 0.8291\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.83860\n",
            "Epoch 170/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4495 - acc: 0.9091 - val_loss: 0.8816 - val_acc: 0.8043\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.83860\n",
            "Epoch 171/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4701 - acc: 0.9044 - val_loss: 0.6588 - val_acc: 0.8497\n",
            "\n",
            "Epoch 00171: val_acc improved from 0.83860 to 0.84970, saving model to /content/saved_models/cifar10_ResNet32v1_model.171.h5\n",
            "Epoch 172/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4610 - acc: 0.9040 - val_loss: 0.7604 - val_acc: 0.8282\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.84970\n",
            "Epoch 173/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4544 - acc: 0.9085 - val_loss: 0.8683 - val_acc: 0.8029\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.84970\n",
            "Epoch 174/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4669 - acc: 0.9134 - val_loss: 0.8301 - val_acc: 0.8103\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.84970\n",
            "Epoch 175/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4806 - acc: 0.9014 - val_loss: 0.7030 - val_acc: 0.8351\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.84970\n",
            "Epoch 176/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4697 - acc: 0.9025 - val_loss: 0.8812 - val_acc: 0.7968\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.84970\n",
            "Epoch 177/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4681 - acc: 0.9033 - val_loss: 0.8154 - val_acc: 0.8079\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.84970\n",
            "Epoch 178/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4693 - acc: 0.9051 - val_loss: 0.8587 - val_acc: 0.8034\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.84970\n",
            "Epoch 179/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4426 - acc: 0.9138 - val_loss: 0.9660 - val_acc: 0.7787\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.84970\n",
            "Epoch 180/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4440 - acc: 0.9144 - val_loss: 0.9526 - val_acc: 0.7892\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.84970\n",
            "Epoch 181/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4419 - acc: 0.9126 - val_loss: 0.7180 - val_acc: 0.8328\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.84970\n",
            "Epoch 182/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4610 - acc: 0.9087 - val_loss: 0.7263 - val_acc: 0.8292\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.84970\n",
            "Epoch 183/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4705 - acc: 0.9043 - val_loss: 0.8446 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.84970\n",
            "Epoch 184/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4466 - acc: 0.9106 - val_loss: 0.7262 - val_acc: 0.8328\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.84970\n",
            "Epoch 185/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4609 - acc: 0.9112 - val_loss: 0.6703 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00185: val_acc improved from 0.84970 to 0.85000, saving model to /content/saved_models/cifar10_ResNet32v1_model.185.h5\n",
            "Epoch 186/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4387 - acc: 0.9123 - val_loss: 0.8192 - val_acc: 0.8144\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.85000\n",
            "Epoch 187/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4553 - acc: 0.9111 - val_loss: 1.0692 - val_acc: 0.7623\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.85000\n",
            "Epoch 188/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4572 - acc: 0.9108 - val_loss: 0.8220 - val_acc: 0.8052\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.85000\n",
            "Epoch 189/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4495 - acc: 0.9137 - val_loss: 0.7167 - val_acc: 0.8391\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.85000\n",
            "Epoch 190/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4503 - acc: 0.9089 - val_loss: 0.8382 - val_acc: 0.8042\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.85000\n",
            "Epoch 191/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4474 - acc: 0.9151 - val_loss: 0.6204 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00191: val_acc improved from 0.85000 to 0.85810, saving model to /content/saved_models/cifar10_ResNet32v1_model.191.h5\n",
            "Epoch 192/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4498 - acc: 0.9143 - val_loss: 0.8123 - val_acc: 0.8079\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.85810\n",
            "Epoch 193/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4365 - acc: 0.9165 - val_loss: 0.6374 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00193: val_acc improved from 0.85810 to 0.86010, saving model to /content/saved_models/cifar10_ResNet32v1_model.193.h5\n",
            "Epoch 194/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4471 - acc: 0.9134 - val_loss: 0.6900 - val_acc: 0.8460\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.86010\n",
            "Epoch 195/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4484 - acc: 0.9120 - val_loss: 0.8432 - val_acc: 0.8099\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.86010\n",
            "Epoch 196/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4501 - acc: 0.9057 - val_loss: 0.7940 - val_acc: 0.8231\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.86010\n",
            "Epoch 197/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4460 - acc: 0.9086 - val_loss: 0.7361 - val_acc: 0.8226\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.86010\n",
            "Epoch 198/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4447 - acc: 0.9131 - val_loss: 0.7736 - val_acc: 0.8182\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.86010\n",
            "Epoch 199/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4606 - acc: 0.9075 - val_loss: 0.7063 - val_acc: 0.8369\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.86010\n",
            "Epoch 200/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4434 - acc: 0.9110 - val_loss: 0.7136 - val_acc: 0.8332\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.86010\n",
            "Epoch 201/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4494 - acc: 0.9067 - val_loss: 0.7989 - val_acc: 0.8190\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.86010\n",
            "Epoch 202/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4424 - acc: 0.9131 - val_loss: 0.7216 - val_acc: 0.8392\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.86010\n",
            "Epoch 203/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4397 - acc: 0.9100 - val_loss: 0.7417 - val_acc: 0.8380\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.86010\n",
            "Epoch 204/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4593 - acc: 0.9071 - val_loss: 0.7866 - val_acc: 0.8113\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.86010\n",
            "Epoch 205/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4590 - acc: 0.9113 - val_loss: 0.8348 - val_acc: 0.7975\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.86010\n",
            "Epoch 206/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4383 - acc: 0.9119 - val_loss: 1.0811 - val_acc: 0.7607\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.86010\n",
            "Epoch 207/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4593 - acc: 0.9031 - val_loss: 0.8669 - val_acc: 0.7993\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.86010\n",
            "Epoch 208/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4427 - acc: 0.9110 - val_loss: 0.7251 - val_acc: 0.8355\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.86010\n",
            "Epoch 209/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4531 - acc: 0.9112 - val_loss: 0.6023 - val_acc: 0.8655\n",
            "\n",
            "Epoch 00209: val_acc improved from 0.86010 to 0.86550, saving model to /content/saved_models/cifar10_ResNet32v1_model.209.h5\n",
            "Epoch 210/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4415 - acc: 0.9203 - val_loss: 0.6972 - val_acc: 0.8403\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.86550\n",
            "Epoch 211/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4659 - acc: 0.9029 - val_loss: 0.6098 - val_acc: 0.8633\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.86550\n",
            "Epoch 212/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4302 - acc: 0.9149 - val_loss: 0.7294 - val_acc: 0.8327\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.86550\n",
            "Epoch 213/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4279 - acc: 0.9198 - val_loss: 0.7086 - val_acc: 0.8465\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.86550\n",
            "Epoch 214/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4285 - acc: 0.9154 - val_loss: 0.7279 - val_acc: 0.8394\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.86550\n",
            "Epoch 215/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4193 - acc: 0.9224 - val_loss: 0.7462 - val_acc: 0.8335\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.86550\n",
            "Epoch 216/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4281 - acc: 0.9153 - val_loss: 0.7239 - val_acc: 0.8391\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.86550\n",
            "Epoch 217/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4456 - acc: 0.9100 - val_loss: 0.8837 - val_acc: 0.8055\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.86550\n",
            "Epoch 218/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4479 - acc: 0.9143 - val_loss: 0.7663 - val_acc: 0.8259\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.86550\n",
            "Epoch 219/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4367 - acc: 0.9168 - val_loss: 0.7876 - val_acc: 0.8261\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.86550\n",
            "Epoch 220/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4143 - acc: 0.9267 - val_loss: 0.6897 - val_acc: 0.8408\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.86550\n",
            "Epoch 221/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4466 - acc: 0.9133 - val_loss: 1.0710 - val_acc: 0.7682\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.86550\n",
            "Epoch 222/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4437 - acc: 0.9121 - val_loss: 1.0323 - val_acc: 0.7762\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.86550\n",
            "Epoch 223/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4357 - acc: 0.9167 - val_loss: 0.7241 - val_acc: 0.8345\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.86550\n",
            "Epoch 224/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4350 - acc: 0.9209 - val_loss: 1.1035 - val_acc: 0.7658\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.86550\n",
            "Epoch 225/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4199 - acc: 0.9222 - val_loss: 0.6989 - val_acc: 0.8348\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.86550\n",
            "Epoch 226/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4383 - acc: 0.9162 - val_loss: 0.9680 - val_acc: 0.7969\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.86550\n",
            "Epoch 227/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4209 - acc: 0.9233 - val_loss: 0.7857 - val_acc: 0.8209\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.86550\n",
            "Epoch 228/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4177 - acc: 0.9246 - val_loss: 0.8170 - val_acc: 0.8146\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.86550\n",
            "Epoch 229/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4326 - acc: 0.9155 - val_loss: 0.8537 - val_acc: 0.8159\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.86550\n",
            "Epoch 230/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4303 - acc: 0.9205 - val_loss: 0.6620 - val_acc: 0.8585\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.86550\n",
            "Epoch 231/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4255 - acc: 0.9204 - val_loss: 0.6730 - val_acc: 0.8485\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.86550\n",
            "Epoch 232/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4182 - acc: 0.9226 - val_loss: 0.9119 - val_acc: 0.7989\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.86550\n",
            "Epoch 233/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4563 - acc: 0.9088 - val_loss: 0.8876 - val_acc: 0.8038\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.86550\n",
            "Epoch 234/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4277 - acc: 0.9195 - val_loss: 0.8444 - val_acc: 0.8043\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.86550\n",
            "Epoch 235/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4420 - acc: 0.9117 - val_loss: 0.6828 - val_acc: 0.8419\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.86550\n",
            "Epoch 236/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4291 - acc: 0.9182 - val_loss: 1.0152 - val_acc: 0.7731\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.86550\n",
            "Epoch 237/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4258 - acc: 0.9204 - val_loss: 0.7825 - val_acc: 0.8184\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.86550\n",
            "Epoch 238/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4218 - acc: 0.9190 - val_loss: 0.8518 - val_acc: 0.8235\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.86550\n",
            "Epoch 239/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4398 - acc: 0.9141 - val_loss: 0.6856 - val_acc: 0.8474\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.86550\n",
            "Epoch 240/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4159 - acc: 0.9224 - val_loss: 0.6561 - val_acc: 0.8541\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.86550\n",
            "Epoch 241/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4400 - acc: 0.9137 - val_loss: 0.8374 - val_acc: 0.8102\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.86550\n",
            "Epoch 242/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4258 - acc: 0.9191 - val_loss: 0.6482 - val_acc: 0.8538\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.86550\n",
            "Epoch 243/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4199 - acc: 0.9204 - val_loss: 0.7434 - val_acc: 0.8358\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.86550\n",
            "Epoch 244/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4353 - acc: 0.9118 - val_loss: 0.8859 - val_acc: 0.7981\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.86550\n",
            "Epoch 245/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4211 - acc: 0.9212 - val_loss: 0.7258 - val_acc: 0.8387\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.86550\n",
            "Epoch 246/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4151 - acc: 0.9219 - val_loss: 0.7559 - val_acc: 0.8278\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.86550\n",
            "Epoch 247/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4248 - acc: 0.9230 - val_loss: 1.0486 - val_acc: 0.7895\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.86550\n",
            "Epoch 248/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4077 - acc: 0.9270 - val_loss: 0.7507 - val_acc: 0.8370\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.86550\n",
            "Epoch 249/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4250 - acc: 0.9222 - val_loss: 0.8364 - val_acc: 0.8136\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.86550\n",
            "Epoch 250/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4193 - acc: 0.9211 - val_loss: 0.6665 - val_acc: 0.8502\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.86550\n",
            "Epoch 251/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4284 - acc: 0.9177 - val_loss: 0.6926 - val_acc: 0.8426\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.86550\n",
            "Epoch 252/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4220 - acc: 0.9218 - val_loss: 0.7518 - val_acc: 0.8228\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.86550\n",
            "Epoch 253/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4452 - acc: 0.9135 - val_loss: 0.6986 - val_acc: 0.8528\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.86550\n",
            "Epoch 254/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4274 - acc: 0.9178 - val_loss: 0.7380 - val_acc: 0.8436\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.86550\n",
            "Epoch 255/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4267 - acc: 0.9178 - val_loss: 0.8221 - val_acc: 0.8115\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.86550\n",
            "Epoch 256/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4229 - acc: 0.9203 - val_loss: 0.7467 - val_acc: 0.8365\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.86550\n",
            "Epoch 257/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4163 - acc: 0.9224 - val_loss: 0.6297 - val_acc: 0.8641\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.86550\n",
            "Epoch 258/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4078 - acc: 0.9276 - val_loss: 0.9440 - val_acc: 0.7851\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.86550\n",
            "Epoch 259/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4297 - acc: 0.9146 - val_loss: 0.7340 - val_acc: 0.8426\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.86550\n",
            "Epoch 260/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4127 - acc: 0.9217 - val_loss: 0.8861 - val_acc: 0.8107\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.86550\n",
            "Epoch 261/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4294 - acc: 0.9183 - val_loss: 0.7869 - val_acc: 0.8248\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.86550\n",
            "Epoch 262/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4129 - acc: 0.9248 - val_loss: 0.8131 - val_acc: 0.8160\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.86550\n",
            "Epoch 263/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4113 - acc: 0.9243 - val_loss: 0.9338 - val_acc: 0.8025\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.86550\n",
            "Epoch 264/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4060 - acc: 0.9274 - val_loss: 0.6378 - val_acc: 0.8582\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.86550\n",
            "Epoch 265/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4265 - acc: 0.9205 - val_loss: 0.7049 - val_acc: 0.8459\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.86550\n",
            "Epoch 266/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4258 - acc: 0.9196 - val_loss: 0.9061 - val_acc: 0.7979\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.86550\n",
            "Epoch 267/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4216 - acc: 0.9210 - val_loss: 0.8370 - val_acc: 0.8155\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.86550\n",
            "Epoch 268/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4209 - acc: 0.9209 - val_loss: 0.9583 - val_acc: 0.7982\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.86550\n",
            "Epoch 269/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4204 - acc: 0.9198 - val_loss: 0.8543 - val_acc: 0.8028\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.86550\n",
            "Epoch 270/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4099 - acc: 0.9235 - val_loss: 0.8079 - val_acc: 0.8212\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.86550\n",
            "Epoch 271/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4248 - acc: 0.9201 - val_loss: 0.7229 - val_acc: 0.8410\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.86550\n",
            "Epoch 272/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4199 - acc: 0.9193 - val_loss: 0.6114 - val_acc: 0.8690\n",
            "\n",
            "Epoch 00272: val_acc improved from 0.86550 to 0.86900, saving model to /content/saved_models/cifar10_ResNet32v1_model.272.h5\n",
            "Epoch 273/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4211 - acc: 0.9191 - val_loss: 0.8919 - val_acc: 0.7899\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.86900\n",
            "Epoch 274/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4062 - acc: 0.9273 - val_loss: 0.6616 - val_acc: 0.8579\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.86900\n",
            "Epoch 275/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4137 - acc: 0.9248 - val_loss: 0.6413 - val_acc: 0.8604\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.86900\n",
            "Epoch 276/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4093 - acc: 0.9234 - val_loss: 0.7534 - val_acc: 0.8334\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.86900\n",
            "Epoch 277/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4209 - acc: 0.9231 - val_loss: 0.9096 - val_acc: 0.8024\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.86900\n",
            "Epoch 278/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4131 - acc: 0.9240 - val_loss: 0.7036 - val_acc: 0.8453\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.86900\n",
            "Epoch 279/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4039 - acc: 0.9259 - val_loss: 0.6245 - val_acc: 0.8635\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.86900\n",
            "Epoch 280/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4256 - acc: 0.9222 - val_loss: 0.6674 - val_acc: 0.8481\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.86900\n",
            "Epoch 281/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4053 - acc: 0.9273 - val_loss: 0.7677 - val_acc: 0.8260\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.86900\n",
            "Epoch 282/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4122 - acc: 0.9267 - val_loss: 0.7833 - val_acc: 0.8266\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.86900\n",
            "Epoch 283/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4147 - acc: 0.9209 - val_loss: 0.8242 - val_acc: 0.8152\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.86900\n",
            "Epoch 284/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4052 - acc: 0.9254 - val_loss: 0.6536 - val_acc: 0.8626\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.86900\n",
            "Epoch 285/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4244 - acc: 0.9199 - val_loss: 0.8916 - val_acc: 0.8071\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.86900\n",
            "Epoch 286/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4033 - acc: 0.9260 - val_loss: 0.6169 - val_acc: 0.8680\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.86900\n",
            "Epoch 287/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3905 - acc: 0.9354 - val_loss: 0.7379 - val_acc: 0.8289\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.86900\n",
            "Epoch 288/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4108 - acc: 0.9282 - val_loss: 0.7330 - val_acc: 0.8370\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.86900\n",
            "Epoch 289/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4220 - acc: 0.9227 - val_loss: 0.8740 - val_acc: 0.8187\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.86900\n",
            "Epoch 290/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3964 - acc: 0.9316 - val_loss: 0.8740 - val_acc: 0.8039\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.86900\n",
            "Epoch 291/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4302 - acc: 0.9166 - val_loss: 0.8048 - val_acc: 0.8341\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.86900\n",
            "Epoch 292/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4063 - acc: 0.9241 - val_loss: 0.6558 - val_acc: 0.8621\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.86900\n",
            "Epoch 293/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4190 - acc: 0.9212 - val_loss: 0.7952 - val_acc: 0.8353\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.86900\n",
            "Epoch 294/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4065 - acc: 0.9286 - val_loss: 0.9838 - val_acc: 0.7820\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.86900\n",
            "Epoch 295/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4098 - acc: 0.9282 - val_loss: 0.8247 - val_acc: 0.8179\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.86900\n",
            "Epoch 296/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4102 - acc: 0.9252 - val_loss: 0.6500 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.86900\n",
            "Epoch 297/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3929 - acc: 0.9299 - val_loss: 0.6600 - val_acc: 0.8557\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.86900\n",
            "Epoch 298/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4218 - acc: 0.9193 - val_loss: 0.6776 - val_acc: 0.8573\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.86900\n",
            "Epoch 299/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4293 - acc: 0.9166 - val_loss: 0.7496 - val_acc: 0.8328\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.86900\n",
            "Epoch 300/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3890 - acc: 0.9317 - val_loss: 0.7389 - val_acc: 0.8335\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.86900\n",
            "Epoch 301/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4018 - acc: 0.9297 - val_loss: 0.7384 - val_acc: 0.8349\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.86900\n",
            "Epoch 302/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4055 - acc: 0.9265 - val_loss: 0.7357 - val_acc: 0.8402\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.86900\n",
            "Epoch 303/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4211 - acc: 0.9225 - val_loss: 0.5812 - val_acc: 0.8761\n",
            "\n",
            "Epoch 00303: val_acc improved from 0.86900 to 0.87610, saving model to /content/saved_models/cifar10_ResNet32v1_model.303.h5\n",
            "Epoch 304/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3940 - acc: 0.9309 - val_loss: 0.6540 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.87610\n",
            "Epoch 305/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4045 - acc: 0.9252 - val_loss: 0.8987 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.87610\n",
            "Epoch 306/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4109 - acc: 0.9262 - val_loss: 0.9759 - val_acc: 0.7995\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.87610\n",
            "Epoch 307/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4194 - acc: 0.9228 - val_loss: 0.7730 - val_acc: 0.8303\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.87610\n",
            "Epoch 308/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4288 - acc: 0.9192 - val_loss: 0.8661 - val_acc: 0.8134\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.87610\n",
            "Epoch 309/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4032 - acc: 0.9238 - val_loss: 0.7824 - val_acc: 0.8243\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.87610\n",
            "Epoch 310/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4014 - acc: 0.9280 - val_loss: 0.6714 - val_acc: 0.8483\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.87610\n",
            "Epoch 311/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3916 - acc: 0.9319 - val_loss: 0.6655 - val_acc: 0.8570\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.87610\n",
            "Epoch 312/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4062 - acc: 0.9296 - val_loss: 0.7274 - val_acc: 0.8394\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.87610\n",
            "Epoch 313/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3995 - acc: 0.9283 - val_loss: 0.8081 - val_acc: 0.8247\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.87610\n",
            "Epoch 314/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4084 - acc: 0.9260 - val_loss: 0.6616 - val_acc: 0.8569\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.87610\n",
            "Epoch 315/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4286 - acc: 0.9202 - val_loss: 0.6767 - val_acc: 0.8519\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.87610\n",
            "Epoch 316/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4058 - acc: 0.9233 - val_loss: 0.7170 - val_acc: 0.8390\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.87610\n",
            "Epoch 317/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4041 - acc: 0.9268 - val_loss: 0.7393 - val_acc: 0.8402\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.87610\n",
            "Epoch 318/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4051 - acc: 0.9244 - val_loss: 0.7704 - val_acc: 0.8386\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.87610\n",
            "Epoch 319/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3993 - acc: 0.9303 - val_loss: 0.7250 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.87610\n",
            "Epoch 320/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3967 - acc: 0.9294 - val_loss: 0.6212 - val_acc: 0.8671\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.87610\n",
            "Epoch 321/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4090 - acc: 0.9271 - val_loss: 0.7982 - val_acc: 0.8268\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.87610\n",
            "Epoch 322/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4062 - acc: 0.9286 - val_loss: 1.0962 - val_acc: 0.7685\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.87610\n",
            "Epoch 323/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4119 - acc: 0.9212 - val_loss: 0.7772 - val_acc: 0.8372\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.87610\n",
            "Epoch 324/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3956 - acc: 0.9279 - val_loss: 0.7862 - val_acc: 0.8282\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.87610\n",
            "Epoch 325/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3934 - acc: 0.9316 - val_loss: 0.6037 - val_acc: 0.8733\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.87610\n",
            "Epoch 326/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4120 - acc: 0.9258 - val_loss: 0.6404 - val_acc: 0.8621\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.87610\n",
            "Epoch 327/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4028 - acc: 0.9275 - val_loss: 0.6496 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.87610\n",
            "Epoch 328/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3904 - acc: 0.9321 - val_loss: 0.7076 - val_acc: 0.8561\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.87610\n",
            "Epoch 329/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3965 - acc: 0.9279 - val_loss: 0.9304 - val_acc: 0.8078\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.87610\n",
            "Epoch 330/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4102 - acc: 0.9238 - val_loss: 0.7075 - val_acc: 0.8351\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.87610\n",
            "Epoch 331/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3874 - acc: 0.9345 - val_loss: 0.6343 - val_acc: 0.8608\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.87610\n",
            "Epoch 332/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4024 - acc: 0.9275 - val_loss: 0.8051 - val_acc: 0.8257\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.87610\n",
            "Epoch 333/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3974 - acc: 0.9274 - val_loss: 0.6907 - val_acc: 0.8527\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.87610\n",
            "Epoch 334/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4089 - acc: 0.9235 - val_loss: 0.6992 - val_acc: 0.8460\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.87610\n",
            "Epoch 335/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3878 - acc: 0.9308 - val_loss: 0.8030 - val_acc: 0.8258\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.87610\n",
            "Epoch 336/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4027 - acc: 0.9302 - val_loss: 0.6839 - val_acc: 0.8459\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.87610\n",
            "Epoch 337/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3942 - acc: 0.9292 - val_loss: 0.9495 - val_acc: 0.8070\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.87610\n",
            "Epoch 338/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3972 - acc: 0.9277 - val_loss: 0.8858 - val_acc: 0.8087\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.87610\n",
            "Epoch 339/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4033 - acc: 0.9250 - val_loss: 0.7892 - val_acc: 0.8279\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.87610\n",
            "Epoch 340/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4085 - acc: 0.9278 - val_loss: 0.6984 - val_acc: 0.8452\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.87610\n",
            "Epoch 341/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3877 - acc: 0.9334 - val_loss: 0.7476 - val_acc: 0.8340\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.87610\n",
            "Epoch 342/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4124 - acc: 0.9227 - val_loss: 0.5957 - val_acc: 0.8746\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.87610\n",
            "Epoch 343/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3835 - acc: 0.9338 - val_loss: 0.6549 - val_acc: 0.8647\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.87610\n",
            "Epoch 344/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3840 - acc: 0.9348 - val_loss: 0.6656 - val_acc: 0.8564\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.87610\n",
            "Epoch 345/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3928 - acc: 0.9344 - val_loss: 0.8340 - val_acc: 0.8188\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.87610\n",
            "Epoch 346/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3858 - acc: 0.9328 - val_loss: 0.9548 - val_acc: 0.7966\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.87610\n",
            "Epoch 347/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3900 - acc: 0.9336 - val_loss: 0.6740 - val_acc: 0.8579\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.87610\n",
            "Epoch 348/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3869 - acc: 0.9326 - val_loss: 0.6302 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.87610\n",
            "Epoch 349/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4021 - acc: 0.9307 - val_loss: 0.6634 - val_acc: 0.8610\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.87610\n",
            "Epoch 350/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3923 - acc: 0.9352 - val_loss: 0.9078 - val_acc: 0.7977\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.87610\n",
            "Epoch 351/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4107 - acc: 0.9233 - val_loss: 0.7160 - val_acc: 0.8532\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.87610\n",
            "Epoch 352/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4034 - acc: 0.9261 - val_loss: 0.8320 - val_acc: 0.8162\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.87610\n",
            "Epoch 353/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3990 - acc: 0.9253 - val_loss: 0.7263 - val_acc: 0.8394\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.87610\n",
            "Epoch 354/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3888 - acc: 0.9346 - val_loss: 0.6705 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.87610\n",
            "Epoch 355/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3903 - acc: 0.9281 - val_loss: 0.9279 - val_acc: 0.8021\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.87610\n",
            "Epoch 356/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3859 - acc: 0.9307 - val_loss: 0.9692 - val_acc: 0.7914\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.87610\n",
            "Epoch 357/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3984 - acc: 0.9289 - val_loss: 0.6689 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.87610\n",
            "Epoch 358/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3836 - acc: 0.9345 - val_loss: 0.6116 - val_acc: 0.8653\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.87610\n",
            "Epoch 359/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3920 - acc: 0.9290 - val_loss: 0.8064 - val_acc: 0.8290\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.87610\n",
            "Epoch 360/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3975 - acc: 0.9303 - val_loss: 0.9404 - val_acc: 0.8059\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.87610\n",
            "Epoch 361/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3826 - acc: 0.9348 - val_loss: 0.7362 - val_acc: 0.8415\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.87610\n",
            "Epoch 362/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3835 - acc: 0.9349 - val_loss: 0.7913 - val_acc: 0.8265\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.87610\n",
            "Epoch 363/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4075 - acc: 0.9226 - val_loss: 0.6932 - val_acc: 0.8446\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.87610\n",
            "Epoch 364/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4175 - acc: 0.9244 - val_loss: 0.6743 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.87610\n",
            "Epoch 365/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3941 - acc: 0.9283 - val_loss: 0.6941 - val_acc: 0.8541\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.87610\n",
            "Epoch 366/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3858 - acc: 0.9325 - val_loss: 0.7486 - val_acc: 0.8320\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.87610\n",
            "Epoch 367/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4006 - acc: 0.9300 - val_loss: 0.7177 - val_acc: 0.8468\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.87610\n",
            "Epoch 368/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3900 - acc: 0.9329 - val_loss: 0.6551 - val_acc: 0.8657\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.87610\n",
            "Epoch 369/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3763 - acc: 0.9356 - val_loss: 0.6471 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.87610\n",
            "Epoch 370/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3754 - acc: 0.9374 - val_loss: 0.8011 - val_acc: 0.8410\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.87610\n",
            "Epoch 371/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3758 - acc: 0.9354 - val_loss: 0.8980 - val_acc: 0.8016\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.87610\n",
            "Epoch 372/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3899 - acc: 0.9300 - val_loss: 0.9133 - val_acc: 0.8018\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.87610\n",
            "Epoch 373/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3807 - acc: 0.9351 - val_loss: 0.7631 - val_acc: 0.8254\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.87610\n",
            "Epoch 374/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3905 - acc: 0.9301 - val_loss: 0.6738 - val_acc: 0.8633\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.87610\n",
            "Epoch 375/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3924 - acc: 0.9285 - val_loss: 0.5876 - val_acc: 0.8767\n",
            "\n",
            "Epoch 00375: val_acc improved from 0.87610 to 0.87670, saving model to /content/saved_models/cifar10_ResNet32v1_model.375.h5\n",
            "Epoch 376/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3895 - acc: 0.9340 - val_loss: 0.8150 - val_acc: 0.8214\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.87670\n",
            "Epoch 377/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3944 - acc: 0.9339 - val_loss: 0.7022 - val_acc: 0.8507\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.87670\n",
            "Epoch 378/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4037 - acc: 0.9253 - val_loss: 0.7304 - val_acc: 0.8461\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.87670\n",
            "Epoch 379/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3957 - acc: 0.9255 - val_loss: 0.8451 - val_acc: 0.8169\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.87670\n",
            "Epoch 380/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3855 - acc: 0.9304 - val_loss: 0.7484 - val_acc: 0.8373\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.87670\n",
            "Epoch 381/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4016 - acc: 0.9312 - val_loss: 0.8304 - val_acc: 0.8277\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.87670\n",
            "Epoch 382/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3944 - acc: 0.9282 - val_loss: 0.6126 - val_acc: 0.8750\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.87670\n",
            "Epoch 383/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3855 - acc: 0.9291 - val_loss: 0.7216 - val_acc: 0.8457\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.87670\n",
            "Epoch 384/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4017 - acc: 0.9316 - val_loss: 0.7278 - val_acc: 0.8428\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.87670\n",
            "Epoch 385/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3739 - acc: 0.9340 - val_loss: 0.7416 - val_acc: 0.8388\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.87670\n",
            "Epoch 386/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3953 - acc: 0.9314 - val_loss: 0.6210 - val_acc: 0.8680\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.87670\n",
            "Epoch 387/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3898 - acc: 0.9332 - val_loss: 0.6925 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.87670\n",
            "Epoch 388/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3914 - acc: 0.9290 - val_loss: 0.6547 - val_acc: 0.8626\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.87670\n",
            "Epoch 389/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3870 - acc: 0.9287 - val_loss: 0.7419 - val_acc: 0.8447\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.87670\n",
            "Epoch 390/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3845 - acc: 0.9316 - val_loss: 0.7843 - val_acc: 0.8294\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.87670\n",
            "Epoch 391/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3872 - acc: 0.9317 - val_loss: 0.7000 - val_acc: 0.8514\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.87670\n",
            "Epoch 392/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3847 - acc: 0.9341 - val_loss: 0.7841 - val_acc: 0.8400\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.87670\n",
            "Epoch 393/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3900 - acc: 0.9331 - val_loss: 0.6740 - val_acc: 0.8605\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.87670\n",
            "Epoch 394/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3769 - acc: 0.9366 - val_loss: 0.7212 - val_acc: 0.8437\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.87670\n",
            "Epoch 395/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3775 - acc: 0.9353 - val_loss: 1.0603 - val_acc: 0.7890\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.87670\n",
            "Epoch 396/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3910 - acc: 0.9315 - val_loss: 0.5970 - val_acc: 0.8697\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.87670\n",
            "Epoch 397/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3802 - acc: 0.9320 - val_loss: 0.8151 - val_acc: 0.8148\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.87670\n",
            "Epoch 398/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4083 - acc: 0.9221 - val_loss: 0.6908 - val_acc: 0.8476\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.87670\n",
            "Epoch 399/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3922 - acc: 0.9301 - val_loss: 0.8437 - val_acc: 0.8161\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.87670\n",
            "Epoch 400/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3892 - acc: 0.9316 - val_loss: 0.6420 - val_acc: 0.8624\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.87670\n",
            "Epoch 401/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3752 - acc: 0.9359 - val_loss: 0.7343 - val_acc: 0.8503\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.87670\n",
            "Epoch 402/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3686 - acc: 0.9395 - val_loss: 0.5192 - val_acc: 0.9009\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.87670 to 0.90090, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3371 - acc: 0.9506 - val_loss: 0.5078 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.90090 to 0.90310, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3193 - acc: 0.9604 - val_loss: 0.4944 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.90310 to 0.90650, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3282 - acc: 0.9570 - val_loss: 0.4922 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.90650 to 0.90870, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3144 - acc: 0.9603 - val_loss: 0.4899 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00406: val_acc did not improve from 0.90870\n",
            "Epoch 407/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3080 - acc: 0.9597 - val_loss: 0.4844 - val_acc: 0.9106\n",
            "\n",
            "Epoch 00407: val_acc improved from 0.90870 to 0.91060, saving model to /content/saved_models/cifar10_ResNet32v1_model.407.h5\n",
            "Epoch 408/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3048 - acc: 0.9645 - val_loss: 0.4796 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00408: val_acc improved from 0.91060 to 0.91190, saving model to /content/saved_models/cifar10_ResNet32v1_model.408.h5\n",
            "Epoch 409/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3037 - acc: 0.9621 - val_loss: 0.4845 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.91190\n",
            "Epoch 410/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3016 - acc: 0.9623 - val_loss: 0.4827 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00410: val_acc did not improve from 0.91190\n",
            "Epoch 411/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2921 - acc: 0.9661 - val_loss: 0.4818 - val_acc: 0.9096\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.91190\n",
            "Epoch 412/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2938 - acc: 0.9648 - val_loss: 0.4855 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00412: val_acc did not improve from 0.91190\n",
            "Epoch 413/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2888 - acc: 0.9675 - val_loss: 0.4822 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.91190\n",
            "Epoch 414/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2818 - acc: 0.9680 - val_loss: 0.4790 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.91190\n",
            "Epoch 415/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2801 - acc: 0.9695 - val_loss: 0.4769 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00415: val_acc improved from 0.91190 to 0.91280, saving model to /content/saved_models/cifar10_ResNet32v1_model.415.h5\n",
            "Epoch 416/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2834 - acc: 0.9681 - val_loss: 0.4845 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.91280\n",
            "Epoch 417/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2903 - acc: 0.9704 - val_loss: 0.4862 - val_acc: 0.9094\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.91280\n",
            "Epoch 418/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2812 - acc: 0.9707 - val_loss: 0.4902 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.91280\n",
            "Epoch 419/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2711 - acc: 0.9719 - val_loss: 0.4873 - val_acc: 0.9102\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.91280\n",
            "Epoch 420/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2748 - acc: 0.9709 - val_loss: 0.4884 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.91280\n",
            "Epoch 421/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2788 - acc: 0.9691 - val_loss: 0.4766 - val_acc: 0.9134\n",
            "\n",
            "Epoch 00421: val_acc improved from 0.91280 to 0.91340, saving model to /content/saved_models/cifar10_ResNet32v1_model.421.h5\n",
            "Epoch 422/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2723 - acc: 0.9703 - val_loss: 0.4791 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00422: val_acc did not improve from 0.91340\n",
            "Epoch 423/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2681 - acc: 0.9719 - val_loss: 0.4798 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.91340\n",
            "Epoch 424/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2626 - acc: 0.9747 - val_loss: 0.4822 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.91340\n",
            "Epoch 425/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2658 - acc: 0.9718 - val_loss: 0.4845 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.91340\n",
            "Epoch 426/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2633 - acc: 0.9732 - val_loss: 0.4857 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.91340\n",
            "Epoch 427/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2702 - acc: 0.9701 - val_loss: 0.4886 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.91340\n",
            "Epoch 428/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2621 - acc: 0.9757 - val_loss: 0.4850 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.91340\n",
            "Epoch 429/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2683 - acc: 0.9698 - val_loss: 0.4800 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.91340\n",
            "Epoch 430/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2677 - acc: 0.9730 - val_loss: 0.4829 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.91340\n",
            "Epoch 431/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2655 - acc: 0.9706 - val_loss: 0.4855 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.91340\n",
            "Epoch 432/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2549 - acc: 0.9743 - val_loss: 0.4802 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.91340\n",
            "Epoch 433/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2605 - acc: 0.9751 - val_loss: 0.4808 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.91340\n",
            "Epoch 434/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2624 - acc: 0.9723 - val_loss: 0.4874 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00434: val_acc did not improve from 0.91340\n",
            "Epoch 435/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2623 - acc: 0.9705 - val_loss: 0.4789 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.91340\n",
            "Epoch 436/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2557 - acc: 0.9733 - val_loss: 0.4796 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00436: val_acc improved from 0.91340 to 0.91370, saving model to /content/saved_models/cifar10_ResNet32v1_model.436.h5\n",
            "Epoch 437/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2555 - acc: 0.9730 - val_loss: 0.4960 - val_acc: 0.9091\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.91370\n",
            "Epoch 438/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2522 - acc: 0.9751 - val_loss: 0.4822 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.91370\n",
            "Epoch 439/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2584 - acc: 0.9738 - val_loss: 0.4777 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00439: val_acc improved from 0.91370 to 0.91600, saving model to /content/saved_models/cifar10_ResNet32v1_model.439.h5\n",
            "Epoch 440/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2507 - acc: 0.9755 - val_loss: 0.4875 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.91600\n",
            "Epoch 441/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2513 - acc: 0.9772 - val_loss: 0.4758 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.91600\n",
            "Epoch 442/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2560 - acc: 0.9741 - val_loss: 0.4842 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.91600\n",
            "Epoch 443/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2455 - acc: 0.9773 - val_loss: 0.4845 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.91600\n",
            "Epoch 444/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2430 - acc: 0.9776 - val_loss: 0.4935 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.91600\n",
            "Epoch 445/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2425 - acc: 0.9779 - val_loss: 0.4873 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.91600\n",
            "Epoch 446/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2491 - acc: 0.9753 - val_loss: 0.4884 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.91600\n",
            "Epoch 447/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.2533 - acc: 0.9731 - val_loss: 0.4857 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.91600\n",
            "Epoch 448/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2376 - acc: 0.9792 - val_loss: 0.4804 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.91600\n",
            "Epoch 449/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2433 - acc: 0.9773 - val_loss: 0.4812 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.91600\n",
            "Epoch 450/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2407 - acc: 0.9763 - val_loss: 0.4869 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.91600\n",
            "Epoch 451/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2386 - acc: 0.9788 - val_loss: 0.4854 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.91600\n",
            "Epoch 452/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2382 - acc: 0.9769 - val_loss: 0.4826 - val_acc: 0.9141\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.91600\n",
            "Epoch 453/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2345 - acc: 0.9808 - val_loss: 0.4892 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.91600\n",
            "Epoch 454/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2314 - acc: 0.9814 - val_loss: 0.4858 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.91600\n",
            "Epoch 455/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2341 - acc: 0.9795 - val_loss: 0.4862 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.91600\n",
            "Epoch 456/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2356 - acc: 0.9792 - val_loss: 0.4914 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.91600\n",
            "Epoch 457/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2297 - acc: 0.9794 - val_loss: 0.4986 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.91600\n",
            "Epoch 458/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2314 - acc: 0.9800 - val_loss: 0.4843 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.91600\n",
            "Epoch 459/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2379 - acc: 0.9782 - val_loss: 0.4841 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.91600\n",
            "Epoch 460/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2349 - acc: 0.9799 - val_loss: 0.4942 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.91600\n",
            "Epoch 461/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2317 - acc: 0.9809 - val_loss: 0.4860 - val_acc: 0.9146\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.91600\n",
            "Epoch 462/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2293 - acc: 0.9791 - val_loss: 0.4892 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.91600\n",
            "Epoch 463/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2322 - acc: 0.9802 - val_loss: 0.4841 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.91600\n",
            "Epoch 464/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2212 - acc: 0.9837 - val_loss: 0.4751 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.91600\n",
            "Epoch 465/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2247 - acc: 0.9819 - val_loss: 0.4849 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.91600\n",
            "Epoch 466/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2265 - acc: 0.9799 - val_loss: 0.5108 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.91600\n",
            "Epoch 467/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2251 - acc: 0.9808 - val_loss: 0.4922 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.91600\n",
            "Epoch 468/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2303 - acc: 0.9816 - val_loss: 0.4852 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.91600\n",
            "Epoch 469/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2213 - acc: 0.9814 - val_loss: 0.4902 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.91600\n",
            "Epoch 470/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2235 - acc: 0.9804 - val_loss: 0.4900 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.91600\n",
            "Epoch 471/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2205 - acc: 0.9822 - val_loss: 0.4941 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.91600\n",
            "Epoch 472/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2249 - acc: 0.9807 - val_loss: 0.4889 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.91600\n",
            "Epoch 473/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2118 - acc: 0.9852 - val_loss: 0.4872 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.91600\n",
            "Epoch 474/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2216 - acc: 0.9809 - val_loss: 0.4864 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.91600\n",
            "Epoch 475/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2184 - acc: 0.9827 - val_loss: 0.4809 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.91600\n",
            "Epoch 476/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2206 - acc: 0.9820 - val_loss: 0.5168 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.91600\n",
            "Epoch 477/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2209 - acc: 0.9813 - val_loss: 0.4950 - val_acc: 0.9106\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.91600\n",
            "Epoch 478/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2192 - acc: 0.9839 - val_loss: 0.5112 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.91600\n",
            "Epoch 479/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2249 - acc: 0.9792 - val_loss: 0.5007 - val_acc: 0.9085\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.91600\n",
            "Epoch 480/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2165 - acc: 0.9834 - val_loss: 0.5050 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.91600\n",
            "Epoch 481/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2116 - acc: 0.9852 - val_loss: 0.5015 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.91600\n",
            "Epoch 482/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2139 - acc: 0.9834 - val_loss: 0.5092 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.91600\n",
            "Epoch 483/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2143 - acc: 0.9821 - val_loss: 0.4949 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.91600\n",
            "Epoch 484/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2137 - acc: 0.9835 - val_loss: 0.4893 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.91600\n",
            "Epoch 485/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2142 - acc: 0.9817 - val_loss: 0.4913 - val_acc: 0.9146\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.91600\n",
            "Epoch 486/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2189 - acc: 0.9816 - val_loss: 0.4996 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.91600\n",
            "Epoch 487/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2106 - acc: 0.9851 - val_loss: 0.4971 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.91600\n",
            "Epoch 488/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2103 - acc: 0.9834 - val_loss: 0.5069 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.91600\n",
            "Epoch 489/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2078 - acc: 0.9848 - val_loss: 0.5195 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.91600\n",
            "Epoch 490/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2063 - acc: 0.9863 - val_loss: 0.4976 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.91600\n",
            "Epoch 491/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2053 - acc: 0.9873 - val_loss: 0.5055 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.91600\n",
            "Epoch 492/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2142 - acc: 0.9813 - val_loss: 0.5056 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.91600\n",
            "Epoch 493/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2128 - acc: 0.9834 - val_loss: 0.4994 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.91600\n",
            "Epoch 494/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2138 - acc: 0.9830 - val_loss: 0.4969 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.91600\n",
            "Epoch 495/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2062 - acc: 0.9848 - val_loss: 0.4953 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.91600\n",
            "Epoch 496/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2076 - acc: 0.9832 - val_loss: 0.5261 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.91600\n",
            "Epoch 497/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2050 - acc: 0.9851 - val_loss: 0.5012 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.91600\n",
            "Epoch 498/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2046 - acc: 0.9839 - val_loss: 0.5050 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.91600\n",
            "Epoch 499/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2065 - acc: 0.9864 - val_loss: 0.4925 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.91600\n",
            "Epoch 500/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2050 - acc: 0.9860 - val_loss: 0.4919 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.91600\n",
            "Epoch 501/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2071 - acc: 0.9844 - val_loss: 0.5037 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.91600\n",
            "Epoch 502/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1996 - acc: 0.9864 - val_loss: 0.5065 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.91600\n",
            "Epoch 503/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2016 - acc: 0.9862 - val_loss: 0.5050 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.91600\n",
            "Epoch 504/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2031 - acc: 0.9851 - val_loss: 0.4894 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.91600\n",
            "Epoch 505/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2120 - acc: 0.9830 - val_loss: 0.4769 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.91600\n",
            "Epoch 506/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2069 - acc: 0.9838 - val_loss: 0.5093 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.91600\n",
            "Epoch 507/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2063 - acc: 0.9834 - val_loss: 0.5116 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.91600\n",
            "Epoch 508/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2035 - acc: 0.9844 - val_loss: 0.5057 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.91600\n",
            "Epoch 509/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1994 - acc: 0.9865 - val_loss: 0.4964 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.91600\n",
            "Epoch 510/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2005 - acc: 0.9851 - val_loss: 0.5046 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.91600\n",
            "Epoch 511/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1989 - acc: 0.9861 - val_loss: 0.5215 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.91600\n",
            "Epoch 512/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1937 - acc: 0.9883 - val_loss: 0.5091 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.91600\n",
            "Epoch 513/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1983 - acc: 0.9863 - val_loss: 0.5247 - val_acc: 0.9078\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.91600\n",
            "Epoch 514/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1979 - acc: 0.9858 - val_loss: 0.5145 - val_acc: 0.9095\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.91600\n",
            "Epoch 515/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1965 - acc: 0.9860 - val_loss: 0.5166 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.91600\n",
            "Epoch 516/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1991 - acc: 0.9850 - val_loss: 0.5081 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.91600\n",
            "Epoch 517/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1986 - acc: 0.9862 - val_loss: 0.5098 - val_acc: 0.9114\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.91600\n",
            "Epoch 518/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1975 - acc: 0.9857 - val_loss: 0.5138 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.91600\n",
            "Epoch 519/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1974 - acc: 0.9859 - val_loss: 0.5366 - val_acc: 0.9077\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.91600\n",
            "Epoch 520/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1942 - acc: 0.9847 - val_loss: 0.4999 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.91600\n",
            "Epoch 521/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1919 - acc: 0.9885 - val_loss: 0.5169 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.91600\n",
            "Epoch 522/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1910 - acc: 0.9869 - val_loss: 0.4992 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.91600\n",
            "Epoch 523/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2011 - acc: 0.9858 - val_loss: 0.5100 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.91600\n",
            "Epoch 524/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1946 - acc: 0.9859 - val_loss: 0.5109 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.91600\n",
            "Epoch 525/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1908 - acc: 0.9879 - val_loss: 0.4969 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.91600\n",
            "Epoch 526/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1928 - acc: 0.9863 - val_loss: 0.5121 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.91600\n",
            "Epoch 527/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1892 - acc: 0.9874 - val_loss: 0.5115 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.91600\n",
            "Epoch 528/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1900 - acc: 0.9885 - val_loss: 0.5082 - val_acc: 0.9123\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.91600\n",
            "Epoch 529/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1923 - acc: 0.9874 - val_loss: 0.5133 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.91600\n",
            "Epoch 530/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1972 - acc: 0.9838 - val_loss: 0.5249 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.91600\n",
            "Epoch 531/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1877 - acc: 0.9888 - val_loss: 0.5239 - val_acc: 0.9089\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.91600\n",
            "Epoch 532/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1929 - acc: 0.9861 - val_loss: 0.5001 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.91600\n",
            "Epoch 533/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1925 - acc: 0.9842 - val_loss: 0.5277 - val_acc: 0.9068\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.91600\n",
            "Epoch 534/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1871 - acc: 0.9878 - val_loss: 0.5049 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.91600\n",
            "Epoch 535/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1856 - acc: 0.9894 - val_loss: 0.5054 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.91600\n",
            "Epoch 536/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1915 - acc: 0.9866 - val_loss: 0.5117 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.91600\n",
            "Epoch 537/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1899 - acc: 0.9890 - val_loss: 0.4988 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.91600\n",
            "Epoch 538/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1871 - acc: 0.9881 - val_loss: 0.5066 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00538: val_acc improved from 0.91600 to 0.91610, saving model to /content/saved_models/cifar10_ResNet32v1_model.538.h5\n",
            "Epoch 539/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1807 - acc: 0.9901 - val_loss: 0.5023 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.91610\n",
            "Epoch 540/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1901 - acc: 0.9860 - val_loss: 0.5528 - val_acc: 0.9068\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.91610\n",
            "Epoch 541/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1849 - acc: 0.9890 - val_loss: 0.4992 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.91610\n",
            "Epoch 542/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1862 - acc: 0.9894 - val_loss: 0.5118 - val_acc: 0.9114\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.91610\n",
            "Epoch 543/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1923 - acc: 0.9858 - val_loss: 0.5015 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.91610\n",
            "Epoch 544/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1822 - acc: 0.9897 - val_loss: 0.5084 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.91610\n",
            "Epoch 545/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1850 - acc: 0.9892 - val_loss: 0.5043 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.91610\n",
            "Epoch 546/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1876 - acc: 0.9871 - val_loss: 0.4984 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.91610\n",
            "Epoch 547/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1856 - acc: 0.9883 - val_loss: 0.5319 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.91610\n",
            "Epoch 548/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1851 - acc: 0.9873 - val_loss: 0.5076 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.91610\n",
            "Epoch 549/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1832 - acc: 0.9864 - val_loss: 0.5002 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.91610\n",
            "Epoch 550/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1825 - acc: 0.9893 - val_loss: 0.5027 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.91610\n",
            "Epoch 551/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1819 - acc: 0.9886 - val_loss: 0.5041 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.91610\n",
            "Epoch 552/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1817 - acc: 0.9890 - val_loss: 0.5398 - val_acc: 0.9066\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.91610\n",
            "Epoch 553/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1869 - acc: 0.9876 - val_loss: 0.5152 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.91610\n",
            "Epoch 554/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1803 - acc: 0.9895 - val_loss: 0.5052 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.91610\n",
            "Epoch 555/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1875 - acc: 0.9864 - val_loss: 0.5072 - val_acc: 0.9123\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.91610\n",
            "Epoch 556/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1758 - acc: 0.9913 - val_loss: 0.5078 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.91610\n",
            "Epoch 557/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1878 - acc: 0.9842 - val_loss: 0.5275 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.91610\n",
            "Epoch 558/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1810 - acc: 0.9894 - val_loss: 0.5094 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.91610\n",
            "Epoch 559/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1790 - acc: 0.9891 - val_loss: 0.5042 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.91610\n",
            "Epoch 560/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1758 - acc: 0.9903 - val_loss: 0.5091 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.91610\n",
            "Epoch 561/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1730 - acc: 0.9910 - val_loss: 0.5201 - val_acc: 0.9102\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.91610\n",
            "Epoch 562/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1814 - acc: 0.9883 - val_loss: 0.4936 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.91610\n",
            "Epoch 563/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1761 - acc: 0.9882 - val_loss: 0.5118 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.91610\n",
            "Epoch 564/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1761 - acc: 0.9897 - val_loss: 0.5207 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.91610\n",
            "Epoch 565/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1796 - acc: 0.9880 - val_loss: 0.5029 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.91610\n",
            "Epoch 566/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1815 - acc: 0.9870 - val_loss: 0.4993 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.91610\n",
            "Epoch 567/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1785 - acc: 0.9888 - val_loss: 0.5082 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.91610\n",
            "Epoch 568/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1806 - acc: 0.9886 - val_loss: 0.5070 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.91610\n",
            "Epoch 569/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1754 - acc: 0.9878 - val_loss: 0.5071 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.91610\n",
            "Epoch 570/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1776 - acc: 0.9895 - val_loss: 0.5162 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.91610\n",
            "Epoch 571/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1790 - acc: 0.9880 - val_loss: 0.5201 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.91610\n",
            "Epoch 572/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1762 - acc: 0.9879 - val_loss: 0.5182 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.91610\n",
            "Epoch 573/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1757 - acc: 0.9880 - val_loss: 0.5154 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.91610\n",
            "Epoch 574/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1779 - acc: 0.9888 - val_loss: 0.5188 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.91610\n",
            "Epoch 575/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1739 - acc: 0.9877 - val_loss: 0.5057 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.91610\n",
            "Epoch 576/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1726 - acc: 0.9889 - val_loss: 0.5182 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.91610\n",
            "Epoch 577/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1766 - acc: 0.9882 - val_loss: 0.5223 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.91610\n",
            "Epoch 578/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1769 - acc: 0.9876 - val_loss: 0.5188 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.91610\n",
            "Epoch 579/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1733 - acc: 0.9890 - val_loss: 0.5235 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.91610\n",
            "Epoch 580/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1667 - acc: 0.9929 - val_loss: 0.5231 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.91610\n",
            "Epoch 581/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1707 - acc: 0.9897 - val_loss: 0.5363 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.91610\n",
            "Epoch 582/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1758 - acc: 0.9888 - val_loss: 0.5306 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.91610\n",
            "Epoch 583/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1789 - acc: 0.9872 - val_loss: 0.5380 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.91610\n",
            "Epoch 584/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1729 - acc: 0.9894 - val_loss: 0.5069 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.91610\n",
            "Epoch 585/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1697 - acc: 0.9909 - val_loss: 0.5131 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.91610\n",
            "Epoch 586/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1735 - acc: 0.9881 - val_loss: 0.5221 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.91610\n",
            "Epoch 587/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1742 - acc: 0.9881 - val_loss: 0.5340 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.91610\n",
            "Epoch 588/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1770 - acc: 0.9871 - val_loss: 0.5305 - val_acc: 0.9083\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.91610\n",
            "Epoch 589/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1712 - acc: 0.9906 - val_loss: 0.5167 - val_acc: 0.9138\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.91610\n",
            "Epoch 590/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1707 - acc: 0.9904 - val_loss: 0.5065 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.91610\n",
            "Epoch 591/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1703 - acc: 0.9900 - val_loss: 0.5019 - val_acc: 0.9138\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.91610\n",
            "Epoch 592/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1718 - acc: 0.9891 - val_loss: 0.5121 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.91610\n",
            "Epoch 593/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1736 - acc: 0.9896 - val_loss: 0.5157 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.91610\n",
            "Epoch 594/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1706 - acc: 0.9880 - val_loss: 0.5084 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.91610\n",
            "Epoch 595/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1671 - acc: 0.9893 - val_loss: 0.5304 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.91610\n",
            "Epoch 596/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1643 - acc: 0.9921 - val_loss: 0.5157 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.91610\n",
            "Epoch 597/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1685 - acc: 0.9901 - val_loss: 0.5042 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.91610\n",
            "Epoch 598/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1720 - acc: 0.9889 - val_loss: 0.5076 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.91610\n",
            "Epoch 599/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1680 - acc: 0.9903 - val_loss: 0.5071 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.91610\n",
            "Epoch 600/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1707 - acc: 0.9879 - val_loss: 0.5286 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.91610\n",
            "Epoch 601/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1657 - acc: 0.9907 - val_loss: 0.5260 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.91610\n",
            "Epoch 602/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1666 - acc: 0.9911 - val_loss: 0.5080 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00602: val_acc did not improve from 0.91610\n",
            "Epoch 603/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1722 - acc: 0.9891 - val_loss: 0.5028 - val_acc: 0.9134\n",
            "\n",
            "Epoch 00603: val_acc did not improve from 0.91610\n",
            "Epoch 604/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1660 - acc: 0.9905 - val_loss: 0.5016 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00604: val_acc did not improve from 0.91610\n",
            "Epoch 605/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1682 - acc: 0.9894 - val_loss: 0.5002 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00605: val_acc did not improve from 0.91610\n",
            "Epoch 606/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1652 - acc: 0.9923 - val_loss: 0.5000 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00606: val_acc did not improve from 0.91610\n",
            "Epoch 607/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1621 - acc: 0.9926 - val_loss: 0.4988 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00607: val_acc did not improve from 0.91610\n",
            "Epoch 608/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1599 - acc: 0.9923 - val_loss: 0.4996 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00608: val_acc improved from 0.91610 to 0.91640, saving model to /content/saved_models/cifar10_ResNet32v1_model.608.h5\n",
            "Epoch 609/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1580 - acc: 0.9945 - val_loss: 0.4982 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00609: val_acc did not improve from 0.91640\n",
            "Epoch 610/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1640 - acc: 0.9911 - val_loss: 0.4986 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00610: val_acc did not improve from 0.91640\n",
            "Epoch 611/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1630 - acc: 0.9911 - val_loss: 0.4976 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.91640\n",
            "Epoch 612/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1644 - acc: 0.9903 - val_loss: 0.4964 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00612: val_acc improved from 0.91640 to 0.91670, saving model to /content/saved_models/cifar10_ResNet32v1_model.612.h5\n",
            "Epoch 613/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1638 - acc: 0.9911 - val_loss: 0.4958 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00613: val_acc did not improve from 0.91670\n",
            "Epoch 614/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1617 - acc: 0.9923 - val_loss: 0.4945 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.91670\n",
            "Epoch 615/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1641 - acc: 0.9908 - val_loss: 0.4985 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.91670\n",
            "Epoch 616/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1589 - acc: 0.9938 - val_loss: 0.4984 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00616: val_acc did not improve from 0.91670\n",
            "Epoch 617/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1620 - acc: 0.9905 - val_loss: 0.4968 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.91670\n",
            "Epoch 618/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1603 - acc: 0.9932 - val_loss: 0.4963 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00618: val_acc improved from 0.91670 to 0.91740, saving model to /content/saved_models/cifar10_ResNet32v1_model.618.h5\n",
            "Epoch 619/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1648 - acc: 0.9909 - val_loss: 0.4966 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00619: val_acc did not improve from 0.91740\n",
            "Epoch 620/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1601 - acc: 0.9923 - val_loss: 0.4959 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.91740\n",
            "Epoch 621/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1631 - acc: 0.9910 - val_loss: 0.4939 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00621: val_acc did not improve from 0.91740\n",
            "Epoch 622/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1586 - acc: 0.9923 - val_loss: 0.4951 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.91740\n",
            "Epoch 623/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1586 - acc: 0.9931 - val_loss: 0.4979 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.91740\n",
            "Epoch 624/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1631 - acc: 0.9920 - val_loss: 0.4984 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.91740\n",
            "Epoch 625/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1590 - acc: 0.9925 - val_loss: 0.4956 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.91740\n",
            "Epoch 626/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1607 - acc: 0.9913 - val_loss: 0.4957 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.91740\n",
            "Epoch 627/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1579 - acc: 0.9930 - val_loss: 0.4948 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00627: val_acc did not improve from 0.91740\n",
            "Epoch 628/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1560 - acc: 0.9940 - val_loss: 0.4929 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00628: val_acc did not improve from 0.91740\n",
            "Epoch 629/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1593 - acc: 0.9926 - val_loss: 0.4951 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.91740\n",
            "Epoch 630/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1616 - acc: 0.9918 - val_loss: 0.4941 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00630: val_acc did not improve from 0.91740\n",
            "Epoch 631/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1602 - acc: 0.9923 - val_loss: 0.4954 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00631: val_acc did not improve from 0.91740\n",
            "Epoch 632/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1625 - acc: 0.9918 - val_loss: 0.4944 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00632: val_acc did not improve from 0.91740\n",
            "Epoch 633/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1584 - acc: 0.9929 - val_loss: 0.4940 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.91740\n",
            "Epoch 634/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1609 - acc: 0.9912 - val_loss: 0.4931 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.91740\n",
            "Epoch 635/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1599 - acc: 0.9927 - val_loss: 0.4927 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.91740\n",
            "Epoch 636/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1615 - acc: 0.9924 - val_loss: 0.4927 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.91740\n",
            "Epoch 637/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1603 - acc: 0.9936 - val_loss: 0.4946 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00637: val_acc did not improve from 0.91740\n",
            "Epoch 638/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1582 - acc: 0.9934 - val_loss: 0.4948 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.91740\n",
            "Epoch 639/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1581 - acc: 0.9936 - val_loss: 0.4908 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.91740\n",
            "Epoch 640/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1570 - acc: 0.9939 - val_loss: 0.4915 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.91740\n",
            "Epoch 641/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1579 - acc: 0.9929 - val_loss: 0.4945 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.91740\n",
            "Epoch 642/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1589 - acc: 0.9930 - val_loss: 0.4972 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.91740\n",
            "Epoch 643/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1578 - acc: 0.9927 - val_loss: 0.4964 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.91740\n",
            "Epoch 644/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1595 - acc: 0.9922 - val_loss: 0.4944 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.91740\n",
            "Epoch 645/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1585 - acc: 0.9930 - val_loss: 0.4936 - val_acc: 0.9173\n",
            "\n",
            "Epoch 00645: val_acc did not improve from 0.91740\n",
            "Epoch 646/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1554 - acc: 0.9937 - val_loss: 0.4935 - val_acc: 0.9173\n",
            "\n",
            "Epoch 00646: val_acc did not improve from 0.91740\n",
            "Epoch 647/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1555 - acc: 0.9951 - val_loss: 0.4938 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00647: val_acc improved from 0.91740 to 0.91790, saving model to /content/saved_models/cifar10_ResNet32v1_model.647.h5\n",
            "Epoch 648/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1574 - acc: 0.9940 - val_loss: 0.4953 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.91790\n",
            "Epoch 649/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1561 - acc: 0.9937 - val_loss: 0.4991 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.91790\n",
            "Epoch 650/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1551 - acc: 0.9943 - val_loss: 0.4975 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00650: val_acc did not improve from 0.91790\n",
            "Epoch 651/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1569 - acc: 0.9936 - val_loss: 0.4948 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00651: val_acc did not improve from 0.91790\n",
            "Epoch 652/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1591 - acc: 0.9930 - val_loss: 0.4985 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00652: val_acc did not improve from 0.91790\n",
            "Epoch 653/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1580 - acc: 0.9917 - val_loss: 0.4984 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00653: val_acc did not improve from 0.91790\n",
            "Epoch 654/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1527 - acc: 0.9960 - val_loss: 0.4962 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00654: val_acc did not improve from 0.91790\n",
            "Epoch 655/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1563 - acc: 0.9942 - val_loss: 0.4956 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00655: val_acc did not improve from 0.91790\n",
            "Epoch 656/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1539 - acc: 0.9968 - val_loss: 0.4949 - val_acc: 0.9181\n",
            "\n",
            "Epoch 00656: val_acc improved from 0.91790 to 0.91810, saving model to /content/saved_models/cifar10_ResNet32v1_model.656.h5\n",
            "Epoch 657/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1562 - acc: 0.9947 - val_loss: 0.4942 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00657: val_acc improved from 0.91810 to 0.91860, saving model to /content/saved_models/cifar10_ResNet32v1_model.657.h5\n",
            "Epoch 658/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1560 - acc: 0.9931 - val_loss: 0.4956 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00658: val_acc did not improve from 0.91860\n",
            "Epoch 659/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1548 - acc: 0.9943 - val_loss: 0.4960 - val_acc: 0.9173\n",
            "\n",
            "Epoch 00659: val_acc did not improve from 0.91860\n",
            "Epoch 660/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1566 - acc: 0.9950 - val_loss: 0.4958 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00660: val_acc did not improve from 0.91860\n",
            "Epoch 661/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1548 - acc: 0.9950 - val_loss: 0.4957 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00661: val_acc did not improve from 0.91860\n",
            "Epoch 662/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1592 - acc: 0.9926 - val_loss: 0.4957 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00662: val_acc did not improve from 0.91860\n",
            "Epoch 663/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1578 - acc: 0.9940 - val_loss: 0.4964 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00663: val_acc did not improve from 0.91860\n",
            "Epoch 664/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1566 - acc: 0.9931 - val_loss: 0.4985 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00664: val_acc did not improve from 0.91860\n",
            "Epoch 665/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1548 - acc: 0.9942 - val_loss: 0.4973 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00665: val_acc did not improve from 0.91860\n",
            "Epoch 666/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1561 - acc: 0.9948 - val_loss: 0.4965 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00666: val_acc did not improve from 0.91860\n",
            "Epoch 667/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1583 - acc: 0.9934 - val_loss: 0.4976 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00667: val_acc did not improve from 0.91860\n",
            "Epoch 668/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1517 - acc: 0.9956 - val_loss: 0.4973 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00668: val_acc did not improve from 0.91860\n",
            "Epoch 669/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1541 - acc: 0.9950 - val_loss: 0.4961 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00669: val_acc did not improve from 0.91860\n",
            "Epoch 670/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1533 - acc: 0.9944 - val_loss: 0.4961 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00670: val_acc did not improve from 0.91860\n",
            "Epoch 671/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1547 - acc: 0.9942 - val_loss: 0.4960 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00671: val_acc did not improve from 0.91860\n",
            "Epoch 672/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1571 - acc: 0.9936 - val_loss: 0.4960 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00672: val_acc did not improve from 0.91860\n",
            "Epoch 673/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1539 - acc: 0.9942 - val_loss: 0.4977 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00673: val_acc did not improve from 0.91860\n",
            "Epoch 674/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1560 - acc: 0.9943 - val_loss: 0.5027 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00674: val_acc did not improve from 0.91860\n",
            "Epoch 675/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1553 - acc: 0.9936 - val_loss: 0.5009 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00675: val_acc did not improve from 0.91860\n",
            "Epoch 676/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1567 - acc: 0.9946 - val_loss: 0.4971 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00676: val_acc did not improve from 0.91860\n",
            "Epoch 677/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1549 - acc: 0.9948 - val_loss: 0.4983 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00677: val_acc did not improve from 0.91860\n",
            "Epoch 678/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1526 - acc: 0.9955 - val_loss: 0.4999 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00678: val_acc did not improve from 0.91860\n",
            "Epoch 679/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1531 - acc: 0.9940 - val_loss: 0.4997 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00679: val_acc did not improve from 0.91860\n",
            "Epoch 680/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1546 - acc: 0.9950 - val_loss: 0.4959 - val_acc: 0.9175\n",
            "\n",
            "Epoch 00680: val_acc did not improve from 0.91860\n",
            "Epoch 681/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1557 - acc: 0.9949 - val_loss: 0.4938 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00681: val_acc did not improve from 0.91860\n",
            "Epoch 682/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1543 - acc: 0.9931 - val_loss: 0.4966 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00682: val_acc did not improve from 0.91860\n",
            "Epoch 683/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1542 - acc: 0.9944 - val_loss: 0.4955 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00683: val_acc did not improve from 0.91860\n",
            "Epoch 684/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1538 - acc: 0.9946 - val_loss: 0.4967 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00684: val_acc did not improve from 0.91860\n",
            "Epoch 685/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1568 - acc: 0.9929 - val_loss: 0.4957 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00685: val_acc did not improve from 0.91860\n",
            "Epoch 686/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1571 - acc: 0.9925 - val_loss: 0.4969 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00686: val_acc did not improve from 0.91860\n",
            "Epoch 687/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1580 - acc: 0.9923 - val_loss: 0.5001 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00687: val_acc did not improve from 0.91860\n",
            "Epoch 688/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1547 - acc: 0.9933 - val_loss: 0.4991 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00688: val_acc did not improve from 0.91860\n",
            "Epoch 689/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1541 - acc: 0.9945 - val_loss: 0.4981 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00689: val_acc did not improve from 0.91860\n",
            "Epoch 690/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1523 - acc: 0.9946 - val_loss: 0.4959 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00690: val_acc did not improve from 0.91860\n",
            "Epoch 691/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1574 - acc: 0.9908 - val_loss: 0.4990 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00691: val_acc did not improve from 0.91860\n",
            "Epoch 692/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1497 - acc: 0.9959 - val_loss: 0.5001 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00692: val_acc did not improve from 0.91860\n",
            "Epoch 693/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1523 - acc: 0.9940 - val_loss: 0.4983 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00693: val_acc did not improve from 0.91860\n",
            "Epoch 694/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1558 - acc: 0.9935 - val_loss: 0.4997 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00694: val_acc did not improve from 0.91860\n",
            "Epoch 695/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1571 - acc: 0.9924 - val_loss: 0.4990 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00695: val_acc did not improve from 0.91860\n",
            "Epoch 696/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1564 - acc: 0.9926 - val_loss: 0.4983 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00696: val_acc did not improve from 0.91860\n",
            "Epoch 697/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1548 - acc: 0.9939 - val_loss: 0.4981 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00697: val_acc did not improve from 0.91860\n",
            "Epoch 698/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1574 - acc: 0.9924 - val_loss: 0.4980 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00698: val_acc did not improve from 0.91860\n",
            "Epoch 699/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1543 - acc: 0.9941 - val_loss: 0.5005 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00699: val_acc did not improve from 0.91860\n",
            "Epoch 700/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1542 - acc: 0.9925 - val_loss: 0.5021 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00700: val_acc did not improve from 0.91860\n",
            "Epoch 701/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1568 - acc: 0.9929 - val_loss: 0.5015 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00701: val_acc did not improve from 0.91860\n",
            "Epoch 702/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1527 - acc: 0.9955 - val_loss: 0.5027 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00702: val_acc did not improve from 0.91860\n",
            "Epoch 703/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1519 - acc: 0.9941 - val_loss: 0.5008 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00703: val_acc did not improve from 0.91860\n",
            "Epoch 704/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1529 - acc: 0.9942 - val_loss: 0.5023 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00704: val_acc did not improve from 0.91860\n",
            "Epoch 705/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1529 - acc: 0.9949 - val_loss: 0.5015 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00705: val_acc did not improve from 0.91860\n",
            "Epoch 706/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1543 - acc: 0.9943 - val_loss: 0.4983 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00706: val_acc did not improve from 0.91860\n",
            "Epoch 707/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1525 - acc: 0.9944 - val_loss: 0.5006 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00707: val_acc did not improve from 0.91860\n",
            "Epoch 708/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1539 - acc: 0.9946 - val_loss: 0.4992 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00708: val_acc did not improve from 0.91860\n",
            "Epoch 709/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1492 - acc: 0.9960 - val_loss: 0.5002 - val_acc: 0.9175\n",
            "\n",
            "Epoch 00709: val_acc did not improve from 0.91860\n",
            "Epoch 710/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1524 - acc: 0.9946 - val_loss: 0.5016 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00710: val_acc did not improve from 0.91860\n",
            "Epoch 711/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1534 - acc: 0.9921 - val_loss: 0.5022 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00711: val_acc did not improve from 0.91860\n",
            "Epoch 712/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1502 - acc: 0.9956 - val_loss: 0.5056 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00712: val_acc did not improve from 0.91860\n",
            "Epoch 713/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1555 - acc: 0.9925 - val_loss: 0.5044 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00713: val_acc did not improve from 0.91860\n",
            "Epoch 714/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1501 - acc: 0.9957 - val_loss: 0.5047 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00714: val_acc did not improve from 0.91860\n",
            "Epoch 715/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1572 - acc: 0.9928 - val_loss: 0.5056 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00715: val_acc did not improve from 0.91860\n",
            "Epoch 716/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1569 - acc: 0.9931 - val_loss: 0.5057 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00716: val_acc did not improve from 0.91860\n",
            "Epoch 717/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1526 - acc: 0.9938 - val_loss: 0.5060 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00717: val_acc did not improve from 0.91860\n",
            "Epoch 718/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1548 - acc: 0.9947 - val_loss: 0.5047 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00718: val_acc did not improve from 0.91860\n",
            "Epoch 719/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1530 - acc: 0.9944 - val_loss: 0.5031 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00719: val_acc did not improve from 0.91860\n",
            "Epoch 720/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1549 - acc: 0.9924 - val_loss: 0.5055 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00720: val_acc did not improve from 0.91860\n",
            "Epoch 721/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1539 - acc: 0.9939 - val_loss: 0.5047 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00721: val_acc did not improve from 0.91860\n",
            "Epoch 722/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1553 - acc: 0.9933 - val_loss: 0.5028 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00722: val_acc did not improve from 0.91860\n",
            "Epoch 723/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1530 - acc: 0.9942 - val_loss: 0.5043 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00723: val_acc did not improve from 0.91860\n",
            "Epoch 724/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1485 - acc: 0.9960 - val_loss: 0.5043 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00724: val_acc did not improve from 0.91860\n",
            "Epoch 725/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1549 - acc: 0.9922 - val_loss: 0.5061 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00725: val_acc did not improve from 0.91860\n",
            "Epoch 726/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1495 - acc: 0.9962 - val_loss: 0.5072 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00726: val_acc did not improve from 0.91860\n",
            "Epoch 727/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1539 - acc: 0.9929 - val_loss: 0.5055 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00727: val_acc did not improve from 0.91860\n",
            "Epoch 728/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1517 - acc: 0.9937 - val_loss: 0.5071 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00728: val_acc did not improve from 0.91860\n",
            "Epoch 729/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1552 - acc: 0.9942 - val_loss: 0.5058 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00729: val_acc did not improve from 0.91860\n",
            "Epoch 730/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1523 - acc: 0.9946 - val_loss: 0.5050 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00730: val_acc did not improve from 0.91860\n",
            "Epoch 731/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1489 - acc: 0.9960 - val_loss: 0.5030 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00731: val_acc did not improve from 0.91860\n",
            "Epoch 732/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1495 - acc: 0.9953 - val_loss: 0.5053 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00732: val_acc did not improve from 0.91860\n",
            "Epoch 733/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1499 - acc: 0.9957 - val_loss: 0.5058 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00733: val_acc did not improve from 0.91860\n",
            "Epoch 734/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1510 - acc: 0.9953 - val_loss: 0.5054 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00734: val_acc did not improve from 0.91860\n",
            "Epoch 735/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1511 - acc: 0.9955 - val_loss: 0.5067 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00735: val_acc did not improve from 0.91860\n",
            "Epoch 736/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1534 - acc: 0.9932 - val_loss: 0.5032 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00736: val_acc did not improve from 0.91860\n",
            "Epoch 737/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1478 - acc: 0.9963 - val_loss: 0.5046 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00737: val_acc did not improve from 0.91860\n",
            "Epoch 738/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1533 - acc: 0.9945 - val_loss: 0.5041 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00738: val_acc did not improve from 0.91860\n",
            "Epoch 739/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1506 - acc: 0.9957 - val_loss: 0.5008 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00739: val_acc did not improve from 0.91860\n",
            "Epoch 740/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1556 - acc: 0.9928 - val_loss: 0.5004 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00740: val_acc did not improve from 0.91860\n",
            "Epoch 741/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1488 - acc: 0.9948 - val_loss: 0.5000 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00741: val_acc did not improve from 0.91860\n",
            "Epoch 742/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1513 - acc: 0.9952 - val_loss: 0.5027 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00742: val_acc did not improve from 0.91860\n",
            "Epoch 743/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1529 - acc: 0.9939 - val_loss: 0.5028 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00743: val_acc did not improve from 0.91860\n",
            "Epoch 744/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1547 - acc: 0.9938 - val_loss: 0.5037 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00744: val_acc did not improve from 0.91860\n",
            "Epoch 745/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1498 - acc: 0.9950 - val_loss: 0.5016 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00745: val_acc did not improve from 0.91860\n",
            "Epoch 746/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1522 - acc: 0.9938 - val_loss: 0.5006 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00746: val_acc did not improve from 0.91860\n",
            "Epoch 747/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1497 - acc: 0.9952 - val_loss: 0.5016 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00747: val_acc did not improve from 0.91860\n",
            "Epoch 748/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1490 - acc: 0.9950 - val_loss: 0.5034 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00748: val_acc did not improve from 0.91860\n",
            "Epoch 749/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1515 - acc: 0.9947 - val_loss: 0.5007 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00749: val_acc did not improve from 0.91860\n",
            "Epoch 750/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1550 - acc: 0.9936 - val_loss: 0.4990 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00750: val_acc did not improve from 0.91860\n",
            "Epoch 751/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1502 - acc: 0.9943 - val_loss: 0.4987 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00751: val_acc did not improve from 0.91860\n",
            "Epoch 752/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1489 - acc: 0.9952 - val_loss: 0.5021 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00752: val_acc did not improve from 0.91860\n",
            "Epoch 753/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1493 - acc: 0.9956 - val_loss: 0.5023 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00753: val_acc did not improve from 0.91860\n",
            "Epoch 754/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1516 - acc: 0.9946 - val_loss: 0.5028 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00754: val_acc did not improve from 0.91860\n",
            "Epoch 755/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1523 - acc: 0.9925 - val_loss: 0.5035 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00755: val_acc did not improve from 0.91860\n",
            "Epoch 756/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1472 - acc: 0.9961 - val_loss: 0.5040 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00756: val_acc did not improve from 0.91860\n",
            "Epoch 757/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1493 - acc: 0.9958 - val_loss: 0.5024 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00757: val_acc did not improve from 0.91860\n",
            "Epoch 758/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1507 - acc: 0.9939 - val_loss: 0.5014 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00758: val_acc did not improve from 0.91860\n",
            "Epoch 759/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1553 - acc: 0.9912 - val_loss: 0.5045 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00759: val_acc did not improve from 0.91860\n",
            "Epoch 760/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1543 - acc: 0.9932 - val_loss: 0.5063 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00760: val_acc did not improve from 0.91860\n",
            "Epoch 761/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1525 - acc: 0.9940 - val_loss: 0.5045 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00761: val_acc did not improve from 0.91860\n",
            "Epoch 762/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1486 - acc: 0.9953 - val_loss: 0.5031 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00762: val_acc did not improve from 0.91860\n",
            "Epoch 763/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1522 - acc: 0.9948 - val_loss: 0.5050 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00763: val_acc did not improve from 0.91860\n",
            "Epoch 764/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1483 - acc: 0.9956 - val_loss: 0.5041 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00764: val_acc did not improve from 0.91860\n",
            "Epoch 765/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1509 - acc: 0.9949 - val_loss: 0.5029 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00765: val_acc did not improve from 0.91860\n",
            "Epoch 766/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1522 - acc: 0.9929 - val_loss: 0.5037 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00766: val_acc did not improve from 0.91860\n",
            "Epoch 767/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1509 - acc: 0.9937 - val_loss: 0.5041 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00767: val_acc did not improve from 0.91860\n",
            "Epoch 768/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1485 - acc: 0.9950 - val_loss: 0.5032 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00768: val_acc did not improve from 0.91860\n",
            "Epoch 769/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1512 - acc: 0.9933 - val_loss: 0.5067 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00769: val_acc did not improve from 0.91860\n",
            "Epoch 770/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1485 - acc: 0.9956 - val_loss: 0.5069 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00770: val_acc did not improve from 0.91860\n",
            "Epoch 771/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1464 - acc: 0.9970 - val_loss: 0.5033 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00771: val_acc did not improve from 0.91860\n",
            "Epoch 772/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1483 - acc: 0.9948 - val_loss: 0.5051 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00772: val_acc did not improve from 0.91860\n",
            "Epoch 773/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1545 - acc: 0.9929 - val_loss: 0.5084 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00773: val_acc did not improve from 0.91860\n",
            "Epoch 774/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1508 - acc: 0.9947 - val_loss: 0.5059 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00774: val_acc did not improve from 0.91860\n",
            "Epoch 775/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1498 - acc: 0.9947 - val_loss: 0.5039 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00775: val_acc did not improve from 0.91860\n",
            "Epoch 776/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1493 - acc: 0.9947 - val_loss: 0.5056 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00776: val_acc did not improve from 0.91860\n",
            "Epoch 777/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1480 - acc: 0.9966 - val_loss: 0.5060 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00777: val_acc did not improve from 0.91860\n",
            "Epoch 778/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1516 - acc: 0.9949 - val_loss: 0.5070 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00778: val_acc did not improve from 0.91860\n",
            "Epoch 779/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1487 - acc: 0.9953 - val_loss: 0.5061 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00779: val_acc did not improve from 0.91860\n",
            "Epoch 780/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1464 - acc: 0.9962 - val_loss: 0.5071 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00780: val_acc did not improve from 0.91860\n",
            "Epoch 781/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1535 - acc: 0.9926 - val_loss: 0.5059 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00781: val_acc did not improve from 0.91860\n",
            "Epoch 782/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1519 - acc: 0.9937 - val_loss: 0.5036 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00782: val_acc did not improve from 0.91860\n",
            "Epoch 783/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1504 - acc: 0.9935 - val_loss: 0.5045 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00783: val_acc did not improve from 0.91860\n",
            "Epoch 784/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1538 - acc: 0.9926 - val_loss: 0.5088 - val_acc: 0.9150\n",
            "\n",
            "Epoch 00784: val_acc did not improve from 0.91860\n",
            "Epoch 785/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1477 - acc: 0.9964 - val_loss: 0.5079 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00785: val_acc did not improve from 0.91860\n",
            "Epoch 786/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1481 - acc: 0.9948 - val_loss: 0.5046 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00786: val_acc did not improve from 0.91860\n",
            "Epoch 787/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1481 - acc: 0.9954 - val_loss: 0.5046 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00787: val_acc did not improve from 0.91860\n",
            "Epoch 788/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1516 - acc: 0.9931 - val_loss: 0.5029 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00788: val_acc did not improve from 0.91860\n",
            "Epoch 789/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1498 - acc: 0.9935 - val_loss: 0.5036 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00789: val_acc did not improve from 0.91860\n",
            "Epoch 790/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1482 - acc: 0.9953 - val_loss: 0.5059 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00790: val_acc did not improve from 0.91860\n",
            "Epoch 791/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1466 - acc: 0.9960 - val_loss: 0.5054 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00791: val_acc did not improve from 0.91860\n",
            "Epoch 792/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1489 - acc: 0.9949 - val_loss: 0.5046 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00792: val_acc did not improve from 0.91860\n",
            "Epoch 793/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1441 - acc: 0.9966 - val_loss: 0.5041 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00793: val_acc did not improve from 0.91860\n",
            "Epoch 794/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1462 - acc: 0.9963 - val_loss: 0.5076 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00794: val_acc did not improve from 0.91860\n",
            "Epoch 795/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1441 - acc: 0.9974 - val_loss: 0.5053 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00795: val_acc did not improve from 0.91860\n",
            "Epoch 796/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1498 - acc: 0.9943 - val_loss: 0.5081 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00796: val_acc did not improve from 0.91860\n",
            "Epoch 797/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1503 - acc: 0.9951 - val_loss: 0.5062 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00797: val_acc did not improve from 0.91860\n",
            "Epoch 798/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1474 - acc: 0.9964 - val_loss: 0.5041 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00798: val_acc did not improve from 0.91860\n",
            "Epoch 799/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1441 - acc: 0.9966 - val_loss: 0.5062 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00799: val_acc did not improve from 0.91860\n",
            "Epoch 800/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1487 - acc: 0.9954 - val_loss: 0.5072 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00800: val_acc did not improve from 0.91860\n",
            "Epoch 801/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1478 - acc: 0.9943 - val_loss: 0.5039 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00801: val_acc did not improve from 0.91860\n",
            "Epoch 802/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1491 - acc: 0.9940 - val_loss: 0.5045 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00802: val_acc did not improve from 0.91860\n",
            "Epoch 803/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1464 - acc: 0.9969 - val_loss: 0.5045 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00803: val_acc did not improve from 0.91860\n",
            "Epoch 804/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1477 - acc: 0.9948 - val_loss: 0.5052 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00804: val_acc did not improve from 0.91860\n",
            "Epoch 805/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1501 - acc: 0.9938 - val_loss: 0.5057 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00805: val_acc did not improve from 0.91860\n",
            "Epoch 806/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1520 - acc: 0.9939 - val_loss: 0.5053 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00806: val_acc did not improve from 0.91860\n",
            "Epoch 807/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1498 - acc: 0.9938 - val_loss: 0.5050 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00807: val_acc did not improve from 0.91860\n",
            "Epoch 808/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1531 - acc: 0.9938 - val_loss: 0.5050 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00808: val_acc did not improve from 0.91860\n",
            "Epoch 809/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1480 - acc: 0.9955 - val_loss: 0.5051 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00809: val_acc did not improve from 0.91860\n",
            "Epoch 810/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1520 - acc: 0.9935 - val_loss: 0.5051 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00810: val_acc did not improve from 0.91860\n",
            "Epoch 811/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1495 - acc: 0.9945 - val_loss: 0.5053 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00811: val_acc did not improve from 0.91860\n",
            "Epoch 812/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1478 - acc: 0.9953 - val_loss: 0.5053 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00812: val_acc did not improve from 0.91860\n",
            "Epoch 813/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1508 - acc: 0.9935 - val_loss: 0.5061 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00813: val_acc did not improve from 0.91860\n",
            "Epoch 814/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1489 - acc: 0.9951 - val_loss: 0.5066 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00814: val_acc did not improve from 0.91860\n",
            "Epoch 815/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1485 - acc: 0.9950 - val_loss: 0.5061 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00815: val_acc did not improve from 0.91860\n",
            "Epoch 816/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1468 - acc: 0.9954 - val_loss: 0.5060 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00816: val_acc did not improve from 0.91860\n",
            "Epoch 817/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1484 - acc: 0.9946 - val_loss: 0.5057 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00817: val_acc did not improve from 0.91860\n",
            "Epoch 818/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1490 - acc: 0.9945 - val_loss: 0.5064 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00818: val_acc did not improve from 0.91860\n",
            "Epoch 819/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1474 - acc: 0.9957 - val_loss: 0.5074 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00819: val_acc did not improve from 0.91860\n",
            "Epoch 820/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1488 - acc: 0.9942 - val_loss: 0.5066 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00820: val_acc did not improve from 0.91860\n",
            "Epoch 821/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1491 - acc: 0.9944 - val_loss: 0.5070 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00821: val_acc did not improve from 0.91860\n",
            "Epoch 822/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1483 - acc: 0.9945 - val_loss: 0.5063 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00822: val_acc did not improve from 0.91860\n",
            "Epoch 823/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1460 - acc: 0.9969 - val_loss: 0.5065 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00823: val_acc did not improve from 0.91860\n",
            "Epoch 824/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1473 - acc: 0.9949 - val_loss: 0.5066 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00824: val_acc did not improve from 0.91860\n",
            "Epoch 825/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1464 - acc: 0.9960 - val_loss: 0.5076 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00825: val_acc did not improve from 0.91860\n",
            "Epoch 826/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1481 - acc: 0.9948 - val_loss: 0.5075 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00826: val_acc did not improve from 0.91860\n",
            "Epoch 827/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1497 - acc: 0.9942 - val_loss: 0.5074 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00827: val_acc did not improve from 0.91860\n",
            "Epoch 828/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1480 - acc: 0.9951 - val_loss: 0.5071 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00828: val_acc did not improve from 0.91860\n",
            "Epoch 829/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1491 - acc: 0.9936 - val_loss: 0.5066 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00829: val_acc did not improve from 0.91860\n",
            "Epoch 830/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1475 - acc: 0.9942 - val_loss: 0.5060 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00830: val_acc did not improve from 0.91860\n",
            "Epoch 831/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1459 - acc: 0.9959 - val_loss: 0.5064 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00831: val_acc did not improve from 0.91860\n",
            "Epoch 832/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1470 - acc: 0.9954 - val_loss: 0.5061 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00832: val_acc did not improve from 0.91860\n",
            "Epoch 833/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1487 - acc: 0.9952 - val_loss: 0.5060 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00833: val_acc did not improve from 0.91860\n",
            "Epoch 834/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1462 - acc: 0.9971 - val_loss: 0.5062 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00834: val_acc did not improve from 0.91860\n",
            "Epoch 835/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1470 - acc: 0.9958 - val_loss: 0.5067 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00835: val_acc did not improve from 0.91860\n",
            "Epoch 836/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1499 - acc: 0.9951 - val_loss: 0.5057 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00836: val_acc did not improve from 0.91860\n",
            "Epoch 837/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1475 - acc: 0.9952 - val_loss: 0.5061 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00837: val_acc did not improve from 0.91860\n",
            "Epoch 838/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1492 - acc: 0.9937 - val_loss: 0.5062 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00838: val_acc did not improve from 0.91860\n",
            "Epoch 839/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1495 - acc: 0.9941 - val_loss: 0.5063 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00839: val_acc did not improve from 0.91860\n",
            "Epoch 840/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1486 - acc: 0.9945 - val_loss: 0.5065 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00840: val_acc did not improve from 0.91860\n",
            "Epoch 841/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1492 - acc: 0.9948 - val_loss: 0.5064 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00841: val_acc did not improve from 0.91860\n",
            "Epoch 842/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1515 - acc: 0.9940 - val_loss: 0.5063 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00842: val_acc did not improve from 0.91860\n",
            "Epoch 843/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1473 - acc: 0.9958 - val_loss: 0.5054 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00843: val_acc did not improve from 0.91860\n",
            "Epoch 844/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1515 - acc: 0.9940 - val_loss: 0.5075 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00844: val_acc did not improve from 0.91860\n",
            "Epoch 845/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1494 - acc: 0.9954 - val_loss: 0.5066 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00845: val_acc did not improve from 0.91860\n",
            "Epoch 846/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1520 - acc: 0.9936 - val_loss: 0.5065 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00846: val_acc did not improve from 0.91860\n",
            "Epoch 847/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1503 - acc: 0.9928 - val_loss: 0.5065 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00847: val_acc did not improve from 0.91860\n",
            "Epoch 848/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1489 - acc: 0.9954 - val_loss: 0.5070 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00848: val_acc did not improve from 0.91860\n",
            "Epoch 849/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1471 - acc: 0.9957 - val_loss: 0.5064 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00849: val_acc did not improve from 0.91860\n",
            "Epoch 850/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1485 - acc: 0.9954 - val_loss: 0.5067 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00850: val_acc did not improve from 0.91860\n",
            "Epoch 851/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1484 - acc: 0.9956 - val_loss: 0.5064 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00851: val_acc did not improve from 0.91860\n",
            "Epoch 852/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1458 - acc: 0.9961 - val_loss: 0.5068 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00852: val_acc did not improve from 0.91860\n",
            "Epoch 853/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1494 - acc: 0.9937 - val_loss: 0.5061 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00853: val_acc did not improve from 0.91860\n",
            "Epoch 854/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1481 - acc: 0.9951 - val_loss: 0.5068 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00854: val_acc did not improve from 0.91860\n",
            "Epoch 855/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1477 - acc: 0.9957 - val_loss: 0.5069 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00855: val_acc did not improve from 0.91860\n",
            "Epoch 856/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1493 - acc: 0.9945 - val_loss: 0.5064 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00856: val_acc did not improve from 0.91860\n",
            "Epoch 857/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1496 - acc: 0.9940 - val_loss: 0.5062 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00857: val_acc did not improve from 0.91860\n",
            "Epoch 858/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1500 - acc: 0.9954 - val_loss: 0.5065 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00858: val_acc did not improve from 0.91860\n",
            "Epoch 859/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1482 - acc: 0.9939 - val_loss: 0.5074 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00859: val_acc did not improve from 0.91860\n",
            "Epoch 860/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1495 - acc: 0.9943 - val_loss: 0.5067 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00860: val_acc did not improve from 0.91860\n",
            "Epoch 861/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1474 - acc: 0.9953 - val_loss: 0.5056 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00861: val_acc did not improve from 0.91860\n",
            "Epoch 862/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1498 - acc: 0.9952 - val_loss: 0.5058 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00862: val_acc did not improve from 0.91860\n",
            "Epoch 863/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1476 - acc: 0.9956 - val_loss: 0.5056 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00863: val_acc did not improve from 0.91860\n",
            "Epoch 864/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1472 - acc: 0.9959 - val_loss: 0.5064 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00864: val_acc did not improve from 0.91860\n",
            "Epoch 865/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1471 - acc: 0.9953 - val_loss: 0.5070 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00865: val_acc did not improve from 0.91860\n",
            "Epoch 866/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1462 - acc: 0.9959 - val_loss: 0.5083 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00866: val_acc did not improve from 0.91860\n",
            "Epoch 867/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1482 - acc: 0.9948 - val_loss: 0.5070 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00867: val_acc did not improve from 0.91860\n",
            "Epoch 868/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1508 - acc: 0.9928 - val_loss: 0.5069 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00868: val_acc did not improve from 0.91860\n",
            "Epoch 869/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1470 - acc: 0.9958 - val_loss: 0.5070 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00869: val_acc did not improve from 0.91860\n",
            "Epoch 870/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1460 - acc: 0.9958 - val_loss: 0.5071 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00870: val_acc did not improve from 0.91860\n",
            "Epoch 871/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1492 - acc: 0.9940 - val_loss: 0.5076 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00871: val_acc did not improve from 0.91860\n",
            "Epoch 872/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1468 - acc: 0.9953 - val_loss: 0.5070 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00872: val_acc did not improve from 0.91860\n",
            "Epoch 873/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1492 - acc: 0.9940 - val_loss: 0.5075 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00873: val_acc did not improve from 0.91860\n",
            "Epoch 874/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1469 - acc: 0.9946 - val_loss: 0.5067 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00874: val_acc did not improve from 0.91860\n",
            "Epoch 875/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1428 - acc: 0.9977 - val_loss: 0.5069 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00875: val_acc did not improve from 0.91860\n",
            "Epoch 876/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1465 - acc: 0.9953 - val_loss: 0.5068 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00876: val_acc did not improve from 0.91860\n",
            "Epoch 877/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1452 - acc: 0.9970 - val_loss: 0.5069 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00877: val_acc did not improve from 0.91860\n",
            "Epoch 878/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1468 - acc: 0.9951 - val_loss: 0.5071 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00878: val_acc did not improve from 0.91860\n",
            "Epoch 879/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1538 - acc: 0.9928 - val_loss: 0.5072 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00879: val_acc did not improve from 0.91860\n",
            "Epoch 880/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1477 - acc: 0.9954 - val_loss: 0.5061 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00880: val_acc did not improve from 0.91860\n",
            "Epoch 881/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1460 - acc: 0.9959 - val_loss: 0.5073 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00881: val_acc did not improve from 0.91860\n",
            "Epoch 882/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1495 - acc: 0.9948 - val_loss: 0.5070 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00882: val_acc did not improve from 0.91860\n",
            "Epoch 883/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1482 - acc: 0.9949 - val_loss: 0.5067 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00883: val_acc did not improve from 0.91860\n",
            "Epoch 884/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1490 - acc: 0.9943 - val_loss: 0.5075 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00884: val_acc did not improve from 0.91860\n",
            "Epoch 885/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1481 - acc: 0.9953 - val_loss: 0.5074 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00885: val_acc did not improve from 0.91860\n",
            "Epoch 886/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1470 - acc: 0.9954 - val_loss: 0.5076 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00886: val_acc did not improve from 0.91860\n",
            "Epoch 887/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1460 - acc: 0.9954 - val_loss: 0.5067 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00887: val_acc did not improve from 0.91860\n",
            "Epoch 888/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1471 - acc: 0.9958 - val_loss: 0.5070 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00888: val_acc did not improve from 0.91860\n",
            "Epoch 889/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1482 - acc: 0.9946 - val_loss: 0.5068 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00889: val_acc did not improve from 0.91860\n",
            "Epoch 890/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1476 - acc: 0.9954 - val_loss: 0.5080 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00890: val_acc did not improve from 0.91860\n",
            "Epoch 891/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1479 - acc: 0.9945 - val_loss: 0.5075 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00891: val_acc did not improve from 0.91860\n",
            "Epoch 892/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1487 - acc: 0.9946 - val_loss: 0.5079 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00892: val_acc did not improve from 0.91860\n",
            "Epoch 893/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1456 - acc: 0.9969 - val_loss: 0.5074 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00893: val_acc did not improve from 0.91860\n",
            "Epoch 894/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1485 - acc: 0.9941 - val_loss: 0.5076 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00894: val_acc did not improve from 0.91860\n",
            "Epoch 895/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1463 - acc: 0.9962 - val_loss: 0.5073 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00895: val_acc did not improve from 0.91860\n",
            "Epoch 896/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1476 - acc: 0.9945 - val_loss: 0.5084 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00896: val_acc did not improve from 0.91860\n",
            "Epoch 897/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1495 - acc: 0.9953 - val_loss: 0.5079 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00897: val_acc did not improve from 0.91860\n",
            "Epoch 898/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1499 - acc: 0.9945 - val_loss: 0.5066 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00898: val_acc did not improve from 0.91860\n",
            "Epoch 899/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1468 - acc: 0.9953 - val_loss: 0.5067 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00899: val_acc did not improve from 0.91860\n",
            "Epoch 900/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1481 - acc: 0.9954 - val_loss: 0.5082 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00900: val_acc did not improve from 0.91860\n",
            "Epoch 901/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1478 - acc: 0.9955 - val_loss: 0.5073 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00901: val_acc did not improve from 0.91860\n",
            "Epoch 902/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1528 - acc: 0.9935 - val_loss: 0.5077 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00902: val_acc did not improve from 0.91860\n",
            "Epoch 903/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1472 - acc: 0.9947 - val_loss: 0.5073 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00903: val_acc did not improve from 0.91860\n",
            "Epoch 904/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1488 - acc: 0.9944 - val_loss: 0.5059 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00904: val_acc did not improve from 0.91860\n",
            "Epoch 905/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1445 - acc: 0.9968 - val_loss: 0.5072 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00905: val_acc did not improve from 0.91860\n",
            "Epoch 906/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1449 - acc: 0.9962 - val_loss: 0.5060 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00906: val_acc did not improve from 0.91860\n",
            "Epoch 907/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1466 - acc: 0.9958 - val_loss: 0.5066 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00907: val_acc did not improve from 0.91860\n",
            "Epoch 908/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1475 - acc: 0.9960 - val_loss: 0.5071 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00908: val_acc did not improve from 0.91860\n",
            "Epoch 909/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1475 - acc: 0.9959 - val_loss: 0.5066 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00909: val_acc did not improve from 0.91860\n",
            "Epoch 910/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1462 - acc: 0.9961 - val_loss: 0.5068 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00910: val_acc did not improve from 0.91860\n",
            "Epoch 911/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1446 - acc: 0.9969 - val_loss: 0.5060 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00911: val_acc did not improve from 0.91860\n",
            "Epoch 912/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1449 - acc: 0.9963 - val_loss: 0.5054 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00912: val_acc did not improve from 0.91860\n",
            "Epoch 913/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1485 - acc: 0.9941 - val_loss: 0.5068 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00913: val_acc did not improve from 0.91860\n",
            "Epoch 914/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1479 - acc: 0.9953 - val_loss: 0.5065 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00914: val_acc did not improve from 0.91860\n",
            "Epoch 915/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1481 - acc: 0.9950 - val_loss: 0.5074 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00915: val_acc did not improve from 0.91860\n",
            "Epoch 916/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1460 - acc: 0.9967 - val_loss: 0.5067 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00916: val_acc did not improve from 0.91860\n",
            "Epoch 917/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1440 - acc: 0.9971 - val_loss: 0.5078 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00917: val_acc did not improve from 0.91860\n",
            "Epoch 918/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1446 - acc: 0.9969 - val_loss: 0.5066 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00918: val_acc did not improve from 0.91860\n",
            "Epoch 919/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1460 - acc: 0.9969 - val_loss: 0.5060 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00919: val_acc did not improve from 0.91860\n",
            "Epoch 920/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1475 - acc: 0.9944 - val_loss: 0.5063 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00920: val_acc did not improve from 0.91860\n",
            "Epoch 921/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1471 - acc: 0.9957 - val_loss: 0.5072 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00921: val_acc did not improve from 0.91860\n",
            "Epoch 922/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1486 - acc: 0.9929 - val_loss: 0.5070 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00922: val_acc did not improve from 0.91860\n",
            "Epoch 923/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1448 - acc: 0.9960 - val_loss: 0.5077 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00923: val_acc did not improve from 0.91860\n",
            "Epoch 924/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1482 - acc: 0.9948 - val_loss: 0.5059 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00924: val_acc did not improve from 0.91860\n",
            "Epoch 925/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1484 - acc: 0.9951 - val_loss: 0.5077 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00925: val_acc did not improve from 0.91860\n",
            "Epoch 926/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1469 - acc: 0.9957 - val_loss: 0.5081 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00926: val_acc did not improve from 0.91860\n",
            "Epoch 927/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1492 - acc: 0.9932 - val_loss: 0.5072 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00927: val_acc did not improve from 0.91860\n",
            "Epoch 928/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1502 - acc: 0.9947 - val_loss: 0.5071 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00928: val_acc did not improve from 0.91860\n",
            "Epoch 929/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1465 - acc: 0.9960 - val_loss: 0.5075 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00929: val_acc did not improve from 0.91860\n",
            "Epoch 930/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1447 - acc: 0.9965 - val_loss: 0.5085 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00930: val_acc did not improve from 0.91860\n",
            "Epoch 931/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1488 - acc: 0.9953 - val_loss: 0.5081 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00931: val_acc did not improve from 0.91860\n",
            "Epoch 932/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1477 - acc: 0.9952 - val_loss: 0.5076 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00932: val_acc did not improve from 0.91860\n",
            "Epoch 933/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1471 - acc: 0.9958 - val_loss: 0.5078 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00933: val_acc did not improve from 0.91860\n",
            "Epoch 934/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1469 - acc: 0.9959 - val_loss: 0.5071 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00934: val_acc did not improve from 0.91860\n",
            "Epoch 935/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1480 - acc: 0.9947 - val_loss: 0.5069 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00935: val_acc did not improve from 0.91860\n",
            "Epoch 936/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1453 - acc: 0.9954 - val_loss: 0.5084 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00936: val_acc did not improve from 0.91860\n",
            "Epoch 937/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1472 - acc: 0.9955 - val_loss: 0.5079 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00937: val_acc did not improve from 0.91860\n",
            "Epoch 938/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1488 - acc: 0.9944 - val_loss: 0.5076 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00938: val_acc did not improve from 0.91860\n",
            "Epoch 939/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1496 - acc: 0.9942 - val_loss: 0.5070 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00939: val_acc did not improve from 0.91860\n",
            "Epoch 940/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1501 - acc: 0.9937 - val_loss: 0.5078 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00940: val_acc did not improve from 0.91860\n",
            "Epoch 941/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1461 - acc: 0.9958 - val_loss: 0.5082 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00941: val_acc did not improve from 0.91860\n",
            "Epoch 942/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1471 - acc: 0.9962 - val_loss: 0.5082 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00942: val_acc did not improve from 0.91860\n",
            "Epoch 943/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1484 - acc: 0.9958 - val_loss: 0.5083 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00943: val_acc did not improve from 0.91860\n",
            "Epoch 944/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1431 - acc: 0.9974 - val_loss: 0.5075 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00944: val_acc did not improve from 0.91860\n",
            "Epoch 945/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1462 - acc: 0.9959 - val_loss: 0.5074 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00945: val_acc did not improve from 0.91860\n",
            "Epoch 946/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1481 - acc: 0.9957 - val_loss: 0.5075 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00946: val_acc did not improve from 0.91860\n",
            "Epoch 947/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1493 - acc: 0.9947 - val_loss: 0.5078 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00947: val_acc did not improve from 0.91860\n",
            "Epoch 948/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1457 - acc: 0.9967 - val_loss: 0.5067 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00948: val_acc did not improve from 0.91860\n",
            "Epoch 949/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1479 - acc: 0.9945 - val_loss: 0.5064 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00949: val_acc did not improve from 0.91860\n",
            "Epoch 950/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1464 - acc: 0.9957 - val_loss: 0.5060 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00950: val_acc did not improve from 0.91860\n",
            "Epoch 951/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1459 - acc: 0.9965 - val_loss: 0.5072 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00951: val_acc did not improve from 0.91860\n",
            "Epoch 952/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1461 - acc: 0.9960 - val_loss: 0.5064 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00952: val_acc did not improve from 0.91860\n",
            "Epoch 953/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1471 - acc: 0.9940 - val_loss: 0.5066 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00953: val_acc did not improve from 0.91860\n",
            "Epoch 954/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1498 - acc: 0.9954 - val_loss: 0.5066 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00954: val_acc did not improve from 0.91860\n",
            "Epoch 955/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1510 - acc: 0.9939 - val_loss: 0.5078 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00955: val_acc did not improve from 0.91860\n",
            "Epoch 956/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1483 - acc: 0.9954 - val_loss: 0.5068 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00956: val_acc did not improve from 0.91860\n",
            "Epoch 957/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1503 - acc: 0.9934 - val_loss: 0.5072 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00957: val_acc did not improve from 0.91860\n",
            "Epoch 958/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1446 - acc: 0.9963 - val_loss: 0.5070 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00958: val_acc did not improve from 0.91860\n",
            "Epoch 959/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1471 - acc: 0.9955 - val_loss: 0.5082 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00959: val_acc did not improve from 0.91860\n",
            "Epoch 960/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1473 - acc: 0.9952 - val_loss: 0.5069 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00960: val_acc did not improve from 0.91860\n",
            "Epoch 961/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1466 - acc: 0.9958 - val_loss: 0.5071 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00961: val_acc did not improve from 0.91860\n",
            "Epoch 962/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1502 - acc: 0.9945 - val_loss: 0.5074 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00962: val_acc did not improve from 0.91860\n",
            "Epoch 963/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1505 - acc: 0.9944 - val_loss: 0.5083 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00963: val_acc did not improve from 0.91860\n",
            "Epoch 964/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1464 - acc: 0.9954 - val_loss: 0.5061 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00964: val_acc did not improve from 0.91860\n",
            "Epoch 965/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1492 - acc: 0.9948 - val_loss: 0.5062 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00965: val_acc did not improve from 0.91860\n",
            "Epoch 966/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1471 - acc: 0.9950 - val_loss: 0.5070 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00966: val_acc did not improve from 0.91860\n",
            "Epoch 967/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1465 - acc: 0.9946 - val_loss: 0.5066 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00967: val_acc did not improve from 0.91860\n",
            "Epoch 968/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1477 - acc: 0.9952 - val_loss: 0.5065 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00968: val_acc did not improve from 0.91860\n",
            "Epoch 969/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1483 - acc: 0.9950 - val_loss: 0.5076 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00969: val_acc did not improve from 0.91860\n",
            "Epoch 970/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1477 - acc: 0.9941 - val_loss: 0.5071 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00970: val_acc did not improve from 0.91860\n",
            "Epoch 971/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1448 - acc: 0.9967 - val_loss: 0.5084 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00971: val_acc did not improve from 0.91860\n",
            "Epoch 972/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1461 - acc: 0.9959 - val_loss: 0.5065 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00972: val_acc did not improve from 0.91860\n",
            "Epoch 973/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1494 - acc: 0.9941 - val_loss: 0.5084 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00973: val_acc did not improve from 0.91860\n",
            "Epoch 974/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1464 - acc: 0.9967 - val_loss: 0.5068 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00974: val_acc did not improve from 0.91860\n",
            "Epoch 975/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1454 - acc: 0.9963 - val_loss: 0.5075 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00975: val_acc did not improve from 0.91860\n",
            "Epoch 976/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1490 - acc: 0.9947 - val_loss: 0.5076 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00976: val_acc did not improve from 0.91860\n",
            "Epoch 977/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1475 - acc: 0.9951 - val_loss: 0.5074 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00977: val_acc did not improve from 0.91860\n",
            "Epoch 978/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1462 - acc: 0.9948 - val_loss: 0.5071 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00978: val_acc did not improve from 0.91860\n",
            "Epoch 979/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1456 - acc: 0.9960 - val_loss: 0.5073 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00979: val_acc did not improve from 0.91860\n",
            "Epoch 980/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1468 - acc: 0.9954 - val_loss: 0.5071 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00980: val_acc did not improve from 0.91860\n",
            "Epoch 981/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1478 - acc: 0.9949 - val_loss: 0.5082 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00981: val_acc did not improve from 0.91860\n",
            "Epoch 982/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1424 - acc: 0.9974 - val_loss: 0.5074 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00982: val_acc did not improve from 0.91860\n",
            "Epoch 983/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1460 - acc: 0.9953 - val_loss: 0.5068 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00983: val_acc did not improve from 0.91860\n",
            "Epoch 984/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1436 - acc: 0.9968 - val_loss: 0.5071 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00984: val_acc did not improve from 0.91860\n",
            "Epoch 985/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1458 - acc: 0.9950 - val_loss: 0.5074 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00985: val_acc did not improve from 0.91860\n",
            "Epoch 986/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1483 - acc: 0.9950 - val_loss: 0.5064 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00986: val_acc did not improve from 0.91860\n",
            "Epoch 987/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1466 - acc: 0.9964 - val_loss: 0.5065 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00987: val_acc did not improve from 0.91860\n",
            "Epoch 988/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1446 - acc: 0.9962 - val_loss: 0.5059 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00988: val_acc did not improve from 0.91860\n",
            "Epoch 989/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1478 - acc: 0.9956 - val_loss: 0.5065 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00989: val_acc did not improve from 0.91860\n",
            "Epoch 990/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1484 - acc: 0.9948 - val_loss: 0.5063 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00990: val_acc did not improve from 0.91860\n",
            "Epoch 991/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1487 - acc: 0.9955 - val_loss: 0.5065 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00991: val_acc did not improve from 0.91860\n",
            "Epoch 992/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1476 - acc: 0.9955 - val_loss: 0.5076 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00992: val_acc did not improve from 0.91860\n",
            "Epoch 993/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1506 - acc: 0.9932 - val_loss: 0.5058 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00993: val_acc did not improve from 0.91860\n",
            "Epoch 994/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1483 - acc: 0.9942 - val_loss: 0.5064 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00994: val_acc did not improve from 0.91860\n",
            "Epoch 995/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1510 - acc: 0.9944 - val_loss: 0.5069 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00995: val_acc did not improve from 0.91860\n",
            "Epoch 996/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1465 - acc: 0.9960 - val_loss: 0.5062 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00996: val_acc did not improve from 0.91860\n",
            "Epoch 997/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1484 - acc: 0.9958 - val_loss: 0.5076 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00997: val_acc did not improve from 0.91860\n",
            "Epoch 998/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1451 - acc: 0.9965 - val_loss: 0.5070 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00998: val_acc did not improve from 0.91860\n",
            "Epoch 999/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1434 - acc: 0.9972 - val_loss: 0.5078 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00999: val_acc did not improve from 0.91860\n",
            "Epoch 1000/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1444 - acc: 0.9973 - val_loss: 0.5084 - val_acc: 0.9164\n",
            "\n",
            "Epoch 01000: val_acc did not improve from 0.91860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "x2NvLySCxHCC",
        "outputId": "55090288-1ad1-44c6-b1f0-952514c1fd70"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('simple_trainHistoryDict', \"rb\"))\n",
        "functions.plot_loss_acc(history, 2, 0.4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXfd0FQq4UHz",
        "outputId": "07867d01-b23e-4960-f4b4-2d97a5f80677"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9164000153541565"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv0kNxrQxlFN",
        "outputId": "eeb47724-f441-4ebe-cc92-52ec4333bfdb"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0835999846458435"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBFMbHvLIf5g"
      },
      "source": [
        "#### Model with clipping to 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8s3DicMIfMr",
        "outputId": "58cd5e6b-df7f-45ea-8b77-b2b9ea07b6d4"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ju7AUyp1rfh",
        "outputId": "3cfdc7c8-28ed-4be7-cdce-bebea6760551"
      },
      "source": [
        "callbacks = functions.standard_callbacks(model_type) + [functions.Clipping(0.5, \"simple\", False)]\n",
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'simple_trainHistoryDict_clip_05', steps_per_epoch=100, epochs=650,\n",
        "                       batch_size=100,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 43s 86ms/step - loss: 2.2006 - acc: 0.3265 - val_loss: 2.3642 - val_acc: 0.2484\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.24840, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 1.7926 - acc: 0.3541 - val_loss: 3.6236 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.24840\n",
            "Epoch 3/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.5951 - acc: 0.4249 - val_loss: 3.5198 - val_acc: 0.1021\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.24840\n",
            "Epoch 4/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 1.4126 - acc: 0.4980 - val_loss: 1.9510 - val_acc: 0.3602\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.24840 to 0.36020, saving model to /content/saved_models/cifar10_ResNet32v1_model.004.h5\n",
            "Epoch 5/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 1.3215 - acc: 0.5336 - val_loss: 4.6725 - val_acc: 0.2246\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.36020\n",
            "Epoch 6/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.2454 - acc: 0.5593 - val_loss: 4.3840 - val_acc: 0.2989\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.36020\n",
            "Epoch 7/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 1.1778 - acc: 0.5869 - val_loss: 1.3978 - val_acc: 0.5549\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.36020 to 0.55490, saving model to /content/saved_models/cifar10_ResNet32v1_model.007.h5\n",
            "Epoch 8/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.1446 - acc: 0.5962 - val_loss: 3.5639 - val_acc: 0.3806\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.55490\n",
            "Epoch 9/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 1.1061 - acc: 0.6121 - val_loss: 1.5495 - val_acc: 0.5589\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.55490 to 0.55890, saving model to /content/saved_models/cifar10_ResNet32v1_model.009.h5\n",
            "Epoch 10/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 1.0470 - acc: 0.6347 - val_loss: 5.4858 - val_acc: 0.3172\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.55890\n",
            "Epoch 11/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 1.0335 - acc: 0.6435 - val_loss: 8.1854 - val_acc: 0.2157\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.55890\n",
            "Epoch 12/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 1.0237 - acc: 0.6446 - val_loss: 2.2764 - val_acc: 0.4158\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.55890\n",
            "Epoch 13/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.0249 - acc: 0.6483 - val_loss: 2.1048 - val_acc: 0.5021\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.55890\n",
            "Epoch 14/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.9868 - acc: 0.6562 - val_loss: 3.3226 - val_acc: 0.4139\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.55890\n",
            "Epoch 15/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.9602 - acc: 0.6689 - val_loss: 3.9643 - val_acc: 0.3533\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.55890\n",
            "Epoch 16/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.9487 - acc: 0.6742 - val_loss: 5.3877 - val_acc: 0.3049\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.55890\n",
            "Epoch 17/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.9443 - acc: 0.6783 - val_loss: 2.8531 - val_acc: 0.4316\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.55890\n",
            "Epoch 18/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.9308 - acc: 0.6830 - val_loss: 8.5328 - val_acc: 0.1666\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.55890\n",
            "Epoch 19/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.9032 - acc: 0.6883 - val_loss: 3.6458 - val_acc: 0.3896\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.55890\n",
            "Epoch 20/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.9042 - acc: 0.6904 - val_loss: 2.8230 - val_acc: 0.4430\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.55890\n",
            "Epoch 21/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.9194 - acc: 0.6853 - val_loss: 2.2020 - val_acc: 0.4837\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.55890\n",
            "Epoch 22/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.8856 - acc: 0.6969 - val_loss: 6.3014 - val_acc: 0.2623\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.55890\n",
            "Epoch 23/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.8832 - acc: 0.6965 - val_loss: 2.8549 - val_acc: 0.4608\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.55890\n",
            "Epoch 24/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.8391 - acc: 0.7155 - val_loss: 5.0534 - val_acc: 0.3933\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.55890\n",
            "Epoch 25/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.8626 - acc: 0.7042 - val_loss: 2.5322 - val_acc: 0.4686\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.55890\n",
            "Epoch 26/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.8722 - acc: 0.7036 - val_loss: 2.1549 - val_acc: 0.5092\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.55890\n",
            "Epoch 27/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.8606 - acc: 0.7081 - val_loss: 3.9011 - val_acc: 0.4224\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.55890\n",
            "Epoch 28/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.8350 - acc: 0.7161 - val_loss: 2.3612 - val_acc: 0.4847\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.55890\n",
            "Epoch 29/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.8355 - acc: 0.7184 - val_loss: 4.5575 - val_acc: 0.2940\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.55890\n",
            "Epoch 30/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.8282 - acc: 0.7168 - val_loss: 2.1145 - val_acc: 0.5284\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.55890\n",
            "Epoch 31/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.8541 - acc: 0.7097 - val_loss: 1.6700 - val_acc: 0.5922\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.55890 to 0.59220, saving model to /content/saved_models/cifar10_ResNet32v1_model.031.h5\n",
            "Epoch 32/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.8317 - acc: 0.7170 - val_loss: 2.6497 - val_acc: 0.4626\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.59220\n",
            "Epoch 33/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.8158 - acc: 0.7213 - val_loss: 3.0322 - val_acc: 0.4627\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.59220\n",
            "Epoch 34/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.8224 - acc: 0.7200 - val_loss: 5.1023 - val_acc: 0.3391\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.59220\n",
            "Epoch 35/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.8165 - acc: 0.7227 - val_loss: 1.6566 - val_acc: 0.5940\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.59220 to 0.59400, saving model to /content/saved_models/cifar10_ResNet32v1_model.035.h5\n",
            "Epoch 36/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.8101 - acc: 0.7252 - val_loss: 2.4896 - val_acc: 0.4879\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.59400\n",
            "Epoch 37/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.7861 - acc: 0.7311 - val_loss: 5.9338 - val_acc: 0.2659\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.59400\n",
            "Epoch 38/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7922 - acc: 0.7350 - val_loss: 2.7750 - val_acc: 0.4908\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.59400\n",
            "Epoch 39/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7937 - acc: 0.7332 - val_loss: 2.2267 - val_acc: 0.5151\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.59400\n",
            "Epoch 40/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7813 - acc: 0.7372 - val_loss: 1.7774 - val_acc: 0.5875\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.59400\n",
            "Epoch 41/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7940 - acc: 0.7345 - val_loss: 2.4715 - val_acc: 0.5247\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.59400\n",
            "Epoch 42/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7860 - acc: 0.7345 - val_loss: 2.4921 - val_acc: 0.4988\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.59400\n",
            "Epoch 43/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.7732 - acc: 0.7447 - val_loss: 4.4540 - val_acc: 0.3543\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.59400\n",
            "Epoch 44/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.7767 - acc: 0.7367 - val_loss: 2.9059 - val_acc: 0.4727\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.59400\n",
            "Epoch 45/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.7725 - acc: 0.7377 - val_loss: 2.1938 - val_acc: 0.5129\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.59400\n",
            "Epoch 46/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7678 - acc: 0.7385 - val_loss: 2.3545 - val_acc: 0.5104\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.59400\n",
            "Epoch 47/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7506 - acc: 0.7475 - val_loss: 2.4996 - val_acc: 0.4946\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.59400\n",
            "Epoch 48/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7563 - acc: 0.7430 - val_loss: 2.0325 - val_acc: 0.5180\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.59400\n",
            "Epoch 49/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7576 - acc: 0.7414 - val_loss: 1.1522 - val_acc: 0.6740\n",
            "\n",
            "Epoch 00049: val_acc improved from 0.59400 to 0.67400, saving model to /content/saved_models/cifar10_ResNet32v1_model.049.h5\n",
            "Epoch 50/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7722 - acc: 0.7419 - val_loss: 2.2813 - val_acc: 0.5101\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.67400\n",
            "Epoch 51/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7808 - acc: 0.7395 - val_loss: 1.6735 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.67400\n",
            "Epoch 52/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7594 - acc: 0.7482 - val_loss: 1.7833 - val_acc: 0.5387\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.67400\n",
            "Epoch 53/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7460 - acc: 0.7477 - val_loss: 2.1297 - val_acc: 0.5753\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.67400\n",
            "Epoch 54/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7639 - acc: 0.7452 - val_loss: 2.1281 - val_acc: 0.5369\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.67400\n",
            "Epoch 55/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7523 - acc: 0.7425 - val_loss: 3.8359 - val_acc: 0.3483\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.67400\n",
            "Epoch 56/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7440 - acc: 0.7468 - val_loss: 2.0439 - val_acc: 0.5670\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.67400\n",
            "Epoch 57/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7357 - acc: 0.7515 - val_loss: 2.3990 - val_acc: 0.4813\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.67400\n",
            "Epoch 58/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7528 - acc: 0.7486 - val_loss: 2.8491 - val_acc: 0.4572\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.67400\n",
            "Epoch 59/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7448 - acc: 0.7518 - val_loss: 3.7411 - val_acc: 0.4616\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.67400\n",
            "Epoch 60/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7227 - acc: 0.7567 - val_loss: 3.3227 - val_acc: 0.4224\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.67400\n",
            "Epoch 61/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7353 - acc: 0.7528 - val_loss: 1.5426 - val_acc: 0.5705\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.67400\n",
            "Epoch 62/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.7439 - acc: 0.7510 - val_loss: 4.7770 - val_acc: 0.3789\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.67400\n",
            "Epoch 63/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7183 - acc: 0.7585 - val_loss: 2.1810 - val_acc: 0.5215\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.67400\n",
            "Epoch 64/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7315 - acc: 0.7540 - val_loss: 1.7467 - val_acc: 0.5657\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.67400\n",
            "Epoch 65/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6987 - acc: 0.7662 - val_loss: 2.0703 - val_acc: 0.5245\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.67400\n",
            "Epoch 66/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7251 - acc: 0.7574 - val_loss: 3.2083 - val_acc: 0.4316\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.67400\n",
            "Epoch 67/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7497 - acc: 0.7485 - val_loss: 2.4240 - val_acc: 0.4834\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.67400\n",
            "Epoch 68/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7172 - acc: 0.7578 - val_loss: 1.7220 - val_acc: 0.5740\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.67400\n",
            "Epoch 69/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7286 - acc: 0.7501 - val_loss: 10.0275 - val_acc: 0.1944\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.67400\n",
            "Epoch 70/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7225 - acc: 0.7550 - val_loss: 2.3544 - val_acc: 0.5321\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.67400\n",
            "Epoch 71/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7379 - acc: 0.7512 - val_loss: 1.6166 - val_acc: 0.5796\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.67400\n",
            "Epoch 72/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6892 - acc: 0.7690 - val_loss: 7.1479 - val_acc: 0.2962\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.67400\n",
            "Epoch 73/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7212 - acc: 0.7573 - val_loss: 2.6826 - val_acc: 0.5124\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.67400\n",
            "Epoch 74/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.7029 - acc: 0.7656 - val_loss: 1.1884 - val_acc: 0.6539\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.67400\n",
            "Epoch 75/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6985 - acc: 0.7619 - val_loss: 3.7398 - val_acc: 0.4180\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.67400\n",
            "Epoch 76/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.7039 - acc: 0.7624 - val_loss: 3.7012 - val_acc: 0.4171\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.67400\n",
            "Epoch 77/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7090 - acc: 0.7657 - val_loss: 2.3457 - val_acc: 0.5473\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.67400\n",
            "Epoch 78/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.7319 - acc: 0.7585 - val_loss: 3.0157 - val_acc: 0.4268\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.67400\n",
            "Epoch 79/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6884 - acc: 0.7680 - val_loss: 1.5688 - val_acc: 0.5757\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.67400\n",
            "Epoch 80/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7159 - acc: 0.7616 - val_loss: 3.5700 - val_acc: 0.4491\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.67400\n",
            "Epoch 81/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6985 - acc: 0.7639 - val_loss: 2.3329 - val_acc: 0.5210\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.67400\n",
            "Epoch 82/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6975 - acc: 0.7680 - val_loss: 1.7093 - val_acc: 0.5884\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.67400\n",
            "Epoch 83/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7207 - acc: 0.7568 - val_loss: 1.9939 - val_acc: 0.5420\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.67400\n",
            "Epoch 84/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6962 - acc: 0.7618 - val_loss: 1.7696 - val_acc: 0.6123\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.67400\n",
            "Epoch 85/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6733 - acc: 0.7747 - val_loss: 3.3902 - val_acc: 0.4472\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.67400\n",
            "Epoch 86/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7056 - acc: 0.7589 - val_loss: 1.7144 - val_acc: 0.5705\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.67400\n",
            "Epoch 87/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6976 - acc: 0.7671 - val_loss: 2.8452 - val_acc: 0.4463\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.67400\n",
            "Epoch 88/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6820 - acc: 0.7697 - val_loss: 2.4110 - val_acc: 0.5334\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.67400\n",
            "Epoch 89/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6906 - acc: 0.7706 - val_loss: 1.9134 - val_acc: 0.5978\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.67400\n",
            "Epoch 90/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6834 - acc: 0.7698 - val_loss: 1.7515 - val_acc: 0.5894\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.67400\n",
            "Epoch 91/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6973 - acc: 0.7656 - val_loss: 1.3455 - val_acc: 0.6449\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.67400\n",
            "Epoch 92/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6934 - acc: 0.7670 - val_loss: 3.1295 - val_acc: 0.4557\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.67400\n",
            "Epoch 93/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6640 - acc: 0.7776 - val_loss: 1.7886 - val_acc: 0.5912\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.67400\n",
            "Epoch 94/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6898 - acc: 0.7664 - val_loss: 1.1919 - val_acc: 0.6617\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.67400\n",
            "Epoch 95/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6835 - acc: 0.7700 - val_loss: 3.2295 - val_acc: 0.4720\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.67400\n",
            "Epoch 96/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.6769 - acc: 0.7746 - val_loss: 2.7666 - val_acc: 0.4762\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.67400\n",
            "Epoch 97/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6786 - acc: 0.7702 - val_loss: 0.9771 - val_acc: 0.6960\n",
            "\n",
            "Epoch 00097: val_acc improved from 0.67400 to 0.69600, saving model to /content/saved_models/cifar10_ResNet32v1_model.097.h5\n",
            "Epoch 98/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6825 - acc: 0.7724 - val_loss: 2.1696 - val_acc: 0.4841\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.69600\n",
            "Epoch 99/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6738 - acc: 0.7755 - val_loss: 3.7218 - val_acc: 0.4472\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.69600\n",
            "Epoch 100/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6932 - acc: 0.7654 - val_loss: 2.6793 - val_acc: 0.5000\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.69600\n",
            "Epoch 101/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6866 - acc: 0.7726 - val_loss: 1.8041 - val_acc: 0.5602\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.69600\n",
            "Epoch 102/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6515 - acc: 0.7823 - val_loss: 1.7639 - val_acc: 0.5902\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.69600\n",
            "Epoch 103/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6892 - acc: 0.7695 - val_loss: 0.9827 - val_acc: 0.7117\n",
            "\n",
            "Epoch 00103: val_acc improved from 0.69600 to 0.71170, saving model to /content/saved_models/cifar10_ResNet32v1_model.103.h5\n",
            "Epoch 104/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6903 - acc: 0.7662 - val_loss: 1.9955 - val_acc: 0.5733\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.71170\n",
            "Epoch 105/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6907 - acc: 0.7713 - val_loss: 3.0488 - val_acc: 0.4270\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.71170\n",
            "Epoch 106/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6704 - acc: 0.7760 - val_loss: 1.7744 - val_acc: 0.6210\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.71170\n",
            "Epoch 107/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6585 - acc: 0.7808 - val_loss: 2.8452 - val_acc: 0.4630\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.71170\n",
            "Epoch 108/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6782 - acc: 0.7748 - val_loss: 1.7036 - val_acc: 0.5686\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.71170\n",
            "Epoch 109/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6677 - acc: 0.7734 - val_loss: 1.2567 - val_acc: 0.6465\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.71170\n",
            "Epoch 110/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6701 - acc: 0.7784 - val_loss: 1.2594 - val_acc: 0.6684\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.71170\n",
            "Epoch 111/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6847 - acc: 0.7673 - val_loss: 1.2591 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.71170\n",
            "Epoch 112/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6847 - acc: 0.7758 - val_loss: 2.8770 - val_acc: 0.4850\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.71170\n",
            "Epoch 113/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6592 - acc: 0.7825 - val_loss: 1.6043 - val_acc: 0.6226\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.71170\n",
            "Epoch 114/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6610 - acc: 0.7811 - val_loss: 1.7289 - val_acc: 0.5958\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.71170\n",
            "Epoch 115/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6841 - acc: 0.7727 - val_loss: 1.2967 - val_acc: 0.6467\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.71170\n",
            "Epoch 116/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6713 - acc: 0.7777 - val_loss: 2.2802 - val_acc: 0.5346\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.71170\n",
            "Epoch 117/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6654 - acc: 0.7771 - val_loss: 1.5991 - val_acc: 0.6139\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.71170\n",
            "Epoch 118/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6578 - acc: 0.7820 - val_loss: 1.4132 - val_acc: 0.6349\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.71170\n",
            "Epoch 119/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6466 - acc: 0.7880 - val_loss: 2.7652 - val_acc: 0.4744\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.71170\n",
            "Epoch 120/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6704 - acc: 0.7764 - val_loss: 1.8330 - val_acc: 0.6038\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.71170\n",
            "Epoch 121/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6583 - acc: 0.7797 - val_loss: 1.4045 - val_acc: 0.6119\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.71170\n",
            "Epoch 122/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6649 - acc: 0.7754 - val_loss: 2.4883 - val_acc: 0.4653\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.71170\n",
            "Epoch 123/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6422 - acc: 0.7883 - val_loss: 1.8317 - val_acc: 0.5767\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.71170\n",
            "Epoch 124/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6741 - acc: 0.7711 - val_loss: 3.6491 - val_acc: 0.4253\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.71170\n",
            "Epoch 125/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6582 - acc: 0.7824 - val_loss: 3.3474 - val_acc: 0.4303\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.71170\n",
            "Epoch 126/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6666 - acc: 0.7757 - val_loss: 1.3466 - val_acc: 0.6487\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.71170\n",
            "Epoch 127/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6596 - acc: 0.7754 - val_loss: 1.4897 - val_acc: 0.6103\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.71170\n",
            "Epoch 128/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6668 - acc: 0.7770 - val_loss: 3.5439 - val_acc: 0.3674\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.71170\n",
            "Epoch 129/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6524 - acc: 0.7848 - val_loss: 1.5973 - val_acc: 0.5940\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.71170\n",
            "Epoch 130/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6522 - acc: 0.7839 - val_loss: 3.1661 - val_acc: 0.4465\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.71170\n",
            "Epoch 131/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6607 - acc: 0.7801 - val_loss: 2.0430 - val_acc: 0.5410\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.71170\n",
            "Epoch 132/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6493 - acc: 0.7830 - val_loss: 3.1268 - val_acc: 0.4532\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.71170\n",
            "Epoch 133/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6577 - acc: 0.7792 - val_loss: 1.5789 - val_acc: 0.5565\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.71170\n",
            "Epoch 134/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6462 - acc: 0.7832 - val_loss: 5.5970 - val_acc: 0.3334\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.71170\n",
            "Epoch 135/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6379 - acc: 0.7879 - val_loss: 2.6105 - val_acc: 0.5294\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.71170\n",
            "Epoch 136/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6433 - acc: 0.7855 - val_loss: 1.2543 - val_acc: 0.6582\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.71170\n",
            "Epoch 137/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6500 - acc: 0.7842 - val_loss: 1.6412 - val_acc: 0.6008\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.71170\n",
            "Epoch 138/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6465 - acc: 0.7811 - val_loss: 2.3248 - val_acc: 0.4807\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.71170\n",
            "Epoch 139/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6508 - acc: 0.7836 - val_loss: 1.8525 - val_acc: 0.5656\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.71170\n",
            "Epoch 140/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6350 - acc: 0.7905 - val_loss: 3.2092 - val_acc: 0.3686\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.71170\n",
            "Epoch 141/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6291 - acc: 0.7904 - val_loss: 1.4586 - val_acc: 0.5927\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.71170\n",
            "Epoch 142/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6641 - acc: 0.7762 - val_loss: 1.8565 - val_acc: 0.5578\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.71170\n",
            "Epoch 143/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6360 - acc: 0.7871 - val_loss: 0.9920 - val_acc: 0.6997\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.71170\n",
            "Epoch 144/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6556 - acc: 0.7839 - val_loss: 1.2191 - val_acc: 0.6695\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.71170\n",
            "Epoch 145/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6388 - acc: 0.7864 - val_loss: 1.5616 - val_acc: 0.6054\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.71170\n",
            "Epoch 146/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6415 - acc: 0.7834 - val_loss: 2.2460 - val_acc: 0.5411\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.71170\n",
            "Epoch 147/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6422 - acc: 0.7884 - val_loss: 1.1224 - val_acc: 0.6540\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.71170\n",
            "Epoch 148/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6406 - acc: 0.7860 - val_loss: 1.4395 - val_acc: 0.6003\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.71170\n",
            "Epoch 149/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6216 - acc: 0.7922 - val_loss: 2.0337 - val_acc: 0.5749\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.71170\n",
            "Epoch 150/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6313 - acc: 0.7906 - val_loss: 2.2270 - val_acc: 0.5590\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.71170\n",
            "Epoch 151/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6244 - acc: 0.7908 - val_loss: 1.4853 - val_acc: 0.6489\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.71170\n",
            "Epoch 152/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6487 - acc: 0.7838 - val_loss: 1.6295 - val_acc: 0.6218\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.71170\n",
            "Epoch 153/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6411 - acc: 0.7848 - val_loss: 1.3542 - val_acc: 0.6183\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.71170\n",
            "Epoch 154/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6417 - acc: 0.7883 - val_loss: 1.1401 - val_acc: 0.6746\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.71170\n",
            "Epoch 155/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6370 - acc: 0.7877 - val_loss: 1.4514 - val_acc: 0.6151\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.71170\n",
            "Epoch 156/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6123 - acc: 0.7989 - val_loss: 1.9340 - val_acc: 0.5292\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.71170\n",
            "Epoch 157/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6320 - acc: 0.7819 - val_loss: 0.8390 - val_acc: 0.7377\n",
            "\n",
            "Epoch 00157: val_acc improved from 0.71170 to 0.73770, saving model to /content/saved_models/cifar10_ResNet32v1_model.157.h5\n",
            "Epoch 158/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6431 - acc: 0.7876 - val_loss: 1.2947 - val_acc: 0.6670\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.73770\n",
            "Epoch 159/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6217 - acc: 0.7930 - val_loss: 4.8745 - val_acc: 0.3740\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.73770\n",
            "Epoch 160/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6447 - acc: 0.7806 - val_loss: 1.3619 - val_acc: 0.6492\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.73770\n",
            "Epoch 161/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6436 - acc: 0.7815 - val_loss: 1.4236 - val_acc: 0.5894\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.73770\n",
            "Epoch 162/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6435 - acc: 0.7841 - val_loss: 2.4273 - val_acc: 0.5351\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.73770\n",
            "Epoch 163/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6276 - acc: 0.7896 - val_loss: 2.6357 - val_acc: 0.4824\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.73770\n",
            "Epoch 164/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6288 - acc: 0.7927 - val_loss: 1.1212 - val_acc: 0.6693\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.73770\n",
            "Epoch 165/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6322 - acc: 0.7913 - val_loss: 2.4355 - val_acc: 0.5071\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.73770\n",
            "Epoch 166/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5994 - acc: 0.7971 - val_loss: 5.5150 - val_acc: 0.2685\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.73770\n",
            "Epoch 167/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6357 - acc: 0.7890 - val_loss: 1.5307 - val_acc: 0.6394\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.73770\n",
            "Epoch 168/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6374 - acc: 0.7867 - val_loss: 1.8161 - val_acc: 0.5586\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.73770\n",
            "Epoch 169/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6286 - acc: 0.7925 - val_loss: 1.5565 - val_acc: 0.6182\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.73770\n",
            "Epoch 170/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6461 - acc: 0.7874 - val_loss: 1.4951 - val_acc: 0.6155\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.73770\n",
            "Epoch 171/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6349 - acc: 0.7891 - val_loss: 1.4126 - val_acc: 0.6137\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.73770\n",
            "Epoch 172/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6312 - acc: 0.7876 - val_loss: 2.2156 - val_acc: 0.5013\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.73770\n",
            "Epoch 173/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6236 - acc: 0.7924 - val_loss: 1.5125 - val_acc: 0.6289\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.73770\n",
            "Epoch 174/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6270 - acc: 0.7928 - val_loss: 1.6633 - val_acc: 0.5907\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.73770\n",
            "Epoch 175/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6191 - acc: 0.7909 - val_loss: 1.7213 - val_acc: 0.6294\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.73770\n",
            "Epoch 176/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6311 - acc: 0.7912 - val_loss: 2.0703 - val_acc: 0.5577\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.73770\n",
            "Epoch 177/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6186 - acc: 0.7936 - val_loss: 2.3478 - val_acc: 0.5068\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.73770\n",
            "Epoch 178/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6261 - acc: 0.7903 - val_loss: 1.2646 - val_acc: 0.6594\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.73770\n",
            "Epoch 179/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6284 - acc: 0.7924 - val_loss: 1.4595 - val_acc: 0.6242\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.73770\n",
            "Epoch 180/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6248 - acc: 0.7905 - val_loss: 1.5097 - val_acc: 0.6114\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.73770\n",
            "Epoch 181/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6099 - acc: 0.7951 - val_loss: 1.7867 - val_acc: 0.5642\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.73770\n",
            "Epoch 182/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6126 - acc: 0.7985 - val_loss: 2.0151 - val_acc: 0.5548\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.73770\n",
            "Epoch 183/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6149 - acc: 0.7940 - val_loss: 1.2871 - val_acc: 0.6414\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.73770\n",
            "Epoch 184/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6111 - acc: 0.7992 - val_loss: 5.8831 - val_acc: 0.2713\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.73770\n",
            "Epoch 185/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6108 - acc: 0.7977 - val_loss: 1.2499 - val_acc: 0.6686\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.73770\n",
            "Epoch 186/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6332 - acc: 0.7916 - val_loss: 5.6675 - val_acc: 0.3483\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.73770\n",
            "Epoch 187/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6188 - acc: 0.7956 - val_loss: 4.1840 - val_acc: 0.3850\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.73770\n",
            "Epoch 188/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6242 - acc: 0.7933 - val_loss: 1.7340 - val_acc: 0.5804\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.73770\n",
            "Epoch 189/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5967 - acc: 0.8015 - val_loss: 1.4269 - val_acc: 0.6006\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.73770\n",
            "Epoch 190/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6216 - acc: 0.7968 - val_loss: 1.6706 - val_acc: 0.5732\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.73770\n",
            "Epoch 191/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6307 - acc: 0.7866 - val_loss: 1.4655 - val_acc: 0.6118\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.73770\n",
            "Epoch 192/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6145 - acc: 0.7934 - val_loss: 2.7992 - val_acc: 0.4100\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.73770\n",
            "Epoch 193/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5970 - acc: 0.8052 - val_loss: 2.2717 - val_acc: 0.5280\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.73770\n",
            "Epoch 194/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6155 - acc: 0.7909 - val_loss: 1.9678 - val_acc: 0.5767\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.73770\n",
            "Epoch 195/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6206 - acc: 0.7957 - val_loss: 1.7355 - val_acc: 0.5871\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.73770\n",
            "Epoch 196/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6179 - acc: 0.7946 - val_loss: 1.7320 - val_acc: 0.5907\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.73770\n",
            "Epoch 197/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6162 - acc: 0.7959 - val_loss: 2.4172 - val_acc: 0.5029\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.73770\n",
            "Epoch 198/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6128 - acc: 0.7971 - val_loss: 1.8567 - val_acc: 0.5438\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.73770\n",
            "Epoch 199/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6149 - acc: 0.7987 - val_loss: 1.9767 - val_acc: 0.6051\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.73770\n",
            "Epoch 200/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6240 - acc: 0.7923 - val_loss: 2.0032 - val_acc: 0.5679\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.73770\n",
            "Epoch 201/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6272 - acc: 0.7966 - val_loss: 2.6881 - val_acc: 0.4051\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.73770\n",
            "Epoch 202/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6082 - acc: 0.8012 - val_loss: 1.4298 - val_acc: 0.6154\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.73770\n",
            "Epoch 203/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6163 - acc: 0.7938 - val_loss: 3.4615 - val_acc: 0.4519\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.73770\n",
            "Epoch 204/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6218 - acc: 0.7941 - val_loss: 1.5396 - val_acc: 0.6019\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.73770\n",
            "Epoch 205/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6062 - acc: 0.8003 - val_loss: 1.2398 - val_acc: 0.6333\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.73770\n",
            "Epoch 206/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6112 - acc: 0.8004 - val_loss: 1.7591 - val_acc: 0.5797\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.73770\n",
            "Epoch 207/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6068 - acc: 0.7978 - val_loss: 1.3487 - val_acc: 0.6244\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.73770\n",
            "Epoch 208/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6146 - acc: 0.7976 - val_loss: 1.5636 - val_acc: 0.5958\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.73770\n",
            "Epoch 209/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6366 - acc: 0.7889 - val_loss: 2.2662 - val_acc: 0.4421\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.73770\n",
            "Epoch 210/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6040 - acc: 0.7981 - val_loss: 1.4329 - val_acc: 0.6271\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.73770\n",
            "Epoch 211/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6063 - acc: 0.7998 - val_loss: 2.4663 - val_acc: 0.4970\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.73770\n",
            "Epoch 212/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6073 - acc: 0.7989 - val_loss: 1.3509 - val_acc: 0.6068\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.73770\n",
            "Epoch 213/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6055 - acc: 0.8008 - val_loss: 1.3760 - val_acc: 0.6267\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.73770\n",
            "Epoch 214/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6200 - acc: 0.7968 - val_loss: 1.3299 - val_acc: 0.6344\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.73770\n",
            "Epoch 215/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5843 - acc: 0.8046 - val_loss: 1.0513 - val_acc: 0.6920\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.73770\n",
            "Epoch 216/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6255 - acc: 0.7913 - val_loss: 2.2581 - val_acc: 0.5170\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.73770\n",
            "Epoch 217/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6334 - acc: 0.7866 - val_loss: 1.8639 - val_acc: 0.4988\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.73770\n",
            "Epoch 218/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5932 - acc: 0.8054 - val_loss: 1.4715 - val_acc: 0.5936\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.73770\n",
            "Epoch 219/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5980 - acc: 0.7994 - val_loss: 2.4174 - val_acc: 0.4766\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.73770\n",
            "Epoch 220/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6211 - acc: 0.7932 - val_loss: 4.4051 - val_acc: 0.3223\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.73770\n",
            "Epoch 221/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6109 - acc: 0.7999 - val_loss: 1.4536 - val_acc: 0.5923\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.73770\n",
            "Epoch 222/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6119 - acc: 0.7961 - val_loss: 1.9925 - val_acc: 0.5499\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.73770\n",
            "Epoch 223/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6262 - acc: 0.7949 - val_loss: 2.1034 - val_acc: 0.5305\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.73770\n",
            "Epoch 224/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5937 - acc: 0.7969 - val_loss: 2.5430 - val_acc: 0.4378\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.73770\n",
            "Epoch 225/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6216 - acc: 0.7955 - val_loss: 6.7342 - val_acc: 0.2356\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.73770\n",
            "Epoch 226/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6122 - acc: 0.7955 - val_loss: 2.5865 - val_acc: 0.4640\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.73770\n",
            "Epoch 227/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6092 - acc: 0.7970 - val_loss: 1.5525 - val_acc: 0.6501\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.73770\n",
            "Epoch 228/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5971 - acc: 0.8040 - val_loss: 2.0546 - val_acc: 0.5222\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.73770\n",
            "Epoch 229/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6026 - acc: 0.7995 - val_loss: 1.2085 - val_acc: 0.6602\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.73770\n",
            "Epoch 230/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6156 - acc: 0.7952 - val_loss: 0.9524 - val_acc: 0.7127\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.73770\n",
            "Epoch 231/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6006 - acc: 0.8048 - val_loss: 1.3759 - val_acc: 0.6352\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.73770\n",
            "Epoch 232/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5977 - acc: 0.8002 - val_loss: 4.0805 - val_acc: 0.3740\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.73770\n",
            "Epoch 233/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6043 - acc: 0.8008 - val_loss: 2.2764 - val_acc: 0.5023\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.73770\n",
            "Epoch 234/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6052 - acc: 0.8006 - val_loss: 2.5501 - val_acc: 0.4954\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.73770\n",
            "Epoch 235/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6019 - acc: 0.8022 - val_loss: 1.5997 - val_acc: 0.5438\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.73770\n",
            "Epoch 236/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6093 - acc: 0.7966 - val_loss: 2.5579 - val_acc: 0.4934\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.73770\n",
            "Epoch 237/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5952 - acc: 0.8045 - val_loss: 1.6544 - val_acc: 0.5850\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.73770\n",
            "Epoch 238/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6096 - acc: 0.7979 - val_loss: 3.1775 - val_acc: 0.4845\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.73770\n",
            "Epoch 239/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.5986 - acc: 0.7990 - val_loss: 1.9889 - val_acc: 0.5635\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.73770\n",
            "Epoch 240/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6110 - acc: 0.7986 - val_loss: 2.2668 - val_acc: 0.4811\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.73770\n",
            "Epoch 241/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5845 - acc: 0.8062 - val_loss: 1.1459 - val_acc: 0.6373\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.73770\n",
            "Epoch 242/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5963 - acc: 0.8033 - val_loss: 1.9146 - val_acc: 0.5354\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.73770\n",
            "Epoch 243/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6076 - acc: 0.7988 - val_loss: 1.2257 - val_acc: 0.6569\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.73770\n",
            "Epoch 244/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5910 - acc: 0.8063 - val_loss: 1.2294 - val_acc: 0.6482\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.73770\n",
            "Epoch 245/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5951 - acc: 0.8037 - val_loss: 1.2797 - val_acc: 0.6632\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.73770\n",
            "Epoch 246/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6030 - acc: 0.8014 - val_loss: 1.7933 - val_acc: 0.5810\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.73770\n",
            "Epoch 247/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6239 - acc: 0.7953 - val_loss: 1.7841 - val_acc: 0.5345\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.73770\n",
            "Epoch 248/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6020 - acc: 0.7997 - val_loss: 1.3192 - val_acc: 0.6387\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.73770\n",
            "Epoch 249/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.5931 - acc: 0.8088 - val_loss: 1.3062 - val_acc: 0.6518\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.73770\n",
            "Epoch 250/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5987 - acc: 0.8002 - val_loss: 1.1567 - val_acc: 0.6588\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.73770\n",
            "Epoch 251/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6006 - acc: 0.8031 - val_loss: 1.1105 - val_acc: 0.6615\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.73770\n",
            "Epoch 252/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5958 - acc: 0.8033 - val_loss: 1.3540 - val_acc: 0.6468\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.73770\n",
            "Epoch 253/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6013 - acc: 0.8022 - val_loss: 2.9676 - val_acc: 0.3782\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.73770\n",
            "Epoch 254/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5917 - acc: 0.8059 - val_loss: 1.0483 - val_acc: 0.7126\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.73770\n",
            "Epoch 255/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5928 - acc: 0.8000 - val_loss: 1.4007 - val_acc: 0.6302\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.73770\n",
            "Epoch 256/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5863 - acc: 0.8063 - val_loss: 3.0793 - val_acc: 0.3721\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.73770\n",
            "Epoch 257/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5922 - acc: 0.8030 - val_loss: 1.6820 - val_acc: 0.5905\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.73770\n",
            "Epoch 258/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6064 - acc: 0.7985 - val_loss: 1.8509 - val_acc: 0.5506\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.73770\n",
            "Epoch 259/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6138 - acc: 0.7961 - val_loss: 1.7919 - val_acc: 0.5856\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.73770\n",
            "Epoch 260/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5897 - acc: 0.8060 - val_loss: 2.9137 - val_acc: 0.3331\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.73770\n",
            "Epoch 261/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6032 - acc: 0.8002 - val_loss: 2.7229 - val_acc: 0.4371\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.73770\n",
            "Epoch 262/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5859 - acc: 0.8091 - val_loss: 1.8959 - val_acc: 0.5460\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.73770\n",
            "Epoch 263/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5981 - acc: 0.8043 - val_loss: 0.9895 - val_acc: 0.6946\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.73770\n",
            "Epoch 264/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5975 - acc: 0.8015 - val_loss: 1.8407 - val_acc: 0.5147\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.73770\n",
            "Epoch 265/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5835 - acc: 0.8055 - val_loss: 1.9330 - val_acc: 0.5099\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.73770\n",
            "Epoch 266/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5939 - acc: 0.8016 - val_loss: 1.3465 - val_acc: 0.6057\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.73770\n",
            "Epoch 267/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5846 - acc: 0.8095 - val_loss: 1.2274 - val_acc: 0.6474\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.73770\n",
            "Epoch 268/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6166 - acc: 0.7987 - val_loss: 1.0960 - val_acc: 0.6845\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.73770\n",
            "Epoch 269/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6033 - acc: 0.7990 - val_loss: 1.0651 - val_acc: 0.6892\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.73770\n",
            "Epoch 270/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6043 - acc: 0.7998 - val_loss: 1.0757 - val_acc: 0.6613\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.73770\n",
            "Epoch 271/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5939 - acc: 0.8062 - val_loss: 1.2685 - val_acc: 0.6813\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.73770\n",
            "Epoch 272/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5783 - acc: 0.8084 - val_loss: 1.7128 - val_acc: 0.5988\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.73770\n",
            "Epoch 273/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5721 - acc: 0.8110 - val_loss: 3.7652 - val_acc: 0.3494\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.73770\n",
            "Epoch 274/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5952 - acc: 0.8070 - val_loss: 1.9457 - val_acc: 0.5355\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.73770\n",
            "Epoch 275/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5883 - acc: 0.8040 - val_loss: 2.5146 - val_acc: 0.5229\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.73770\n",
            "Epoch 276/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5926 - acc: 0.8009 - val_loss: 1.9464 - val_acc: 0.6031\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.73770\n",
            "Epoch 277/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.6022 - acc: 0.7990 - val_loss: 1.0793 - val_acc: 0.6925\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.73770\n",
            "Epoch 278/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5939 - acc: 0.8038 - val_loss: 1.3419 - val_acc: 0.5893\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.73770\n",
            "Epoch 279/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5916 - acc: 0.8031 - val_loss: 1.8944 - val_acc: 0.5000\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.73770\n",
            "Epoch 280/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5840 - acc: 0.8036 - val_loss: 1.6235 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.73770\n",
            "Epoch 281/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5850 - acc: 0.8049 - val_loss: 1.0582 - val_acc: 0.6821\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.73770\n",
            "Epoch 282/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5957 - acc: 0.8028 - val_loss: 1.3468 - val_acc: 0.6393\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.73770\n",
            "Epoch 283/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5897 - acc: 0.8071 - val_loss: 1.8974 - val_acc: 0.5704\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.73770\n",
            "Epoch 284/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5910 - acc: 0.8015 - val_loss: 1.6835 - val_acc: 0.5887\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.73770\n",
            "Epoch 285/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5957 - acc: 0.8020 - val_loss: 1.9732 - val_acc: 0.5187\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.73770\n",
            "Epoch 286/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5835 - acc: 0.8057 - val_loss: 0.9758 - val_acc: 0.7026\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.73770\n",
            "Epoch 287/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6012 - acc: 0.8014 - val_loss: 3.1820 - val_acc: 0.3829\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.73770\n",
            "Epoch 288/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5925 - acc: 0.8039 - val_loss: 2.2763 - val_acc: 0.5050\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.73770\n",
            "Epoch 289/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5956 - acc: 0.7997 - val_loss: 1.1950 - val_acc: 0.6717\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.73770\n",
            "Epoch 290/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5982 - acc: 0.8027 - val_loss: 1.5026 - val_acc: 0.6200\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.73770\n",
            "Epoch 291/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6065 - acc: 0.7970 - val_loss: 1.6030 - val_acc: 0.6038\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.73770\n",
            "Epoch 292/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6079 - acc: 0.7955 - val_loss: 3.7963 - val_acc: 0.4039\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.73770\n",
            "Epoch 293/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5844 - acc: 0.8075 - val_loss: 0.8665 - val_acc: 0.7377\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.73770\n",
            "Epoch 294/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6016 - acc: 0.7986 - val_loss: 2.1056 - val_acc: 0.4859\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.73770\n",
            "Epoch 295/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5985 - acc: 0.8052 - val_loss: 2.6333 - val_acc: 0.4453\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.73770\n",
            "Epoch 296/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5793 - acc: 0.8065 - val_loss: 3.0203 - val_acc: 0.4761\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.73770\n",
            "Epoch 297/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5934 - acc: 0.8035 - val_loss: 1.6855 - val_acc: 0.5950\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.73770\n",
            "Epoch 298/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6083 - acc: 0.7976 - val_loss: 1.2905 - val_acc: 0.6665\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.73770\n",
            "Epoch 299/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5912 - acc: 0.8047 - val_loss: 2.6354 - val_acc: 0.4392\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.73770\n",
            "Epoch 300/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5792 - acc: 0.8086 - val_loss: 2.4438 - val_acc: 0.4862\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.73770\n",
            "Epoch 301/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5858 - acc: 0.8046 - val_loss: 3.1045 - val_acc: 0.4279\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.73770\n",
            "Epoch 302/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5942 - acc: 0.8018 - val_loss: 2.0975 - val_acc: 0.5394\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.73770\n",
            "Epoch 303/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5966 - acc: 0.8061 - val_loss: 0.8737 - val_acc: 0.7310\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.73770\n",
            "Epoch 304/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6106 - acc: 0.7972 - val_loss: 2.8793 - val_acc: 0.4509\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.73770\n",
            "Epoch 305/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5951 - acc: 0.7999 - val_loss: 2.8339 - val_acc: 0.3945\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.73770\n",
            "Epoch 306/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5896 - acc: 0.8053 - val_loss: 1.2417 - val_acc: 0.6761\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.73770\n",
            "Epoch 307/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5945 - acc: 0.8013 - val_loss: 1.7545 - val_acc: 0.5818\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.73770\n",
            "Epoch 308/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6005 - acc: 0.8042 - val_loss: 3.3833 - val_acc: 0.4398\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.73770\n",
            "Epoch 309/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5860 - acc: 0.8085 - val_loss: 1.8569 - val_acc: 0.5210\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.73770\n",
            "Epoch 310/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6044 - acc: 0.7955 - val_loss: 1.5952 - val_acc: 0.6372\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.73770\n",
            "Epoch 311/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5898 - acc: 0.8054 - val_loss: 0.9443 - val_acc: 0.6809\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.73770\n",
            "Epoch 312/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6007 - acc: 0.7997 - val_loss: 2.4181 - val_acc: 0.4809\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.73770\n",
            "Epoch 313/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5945 - acc: 0.8001 - val_loss: 1.6037 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.73770\n",
            "Epoch 314/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5835 - acc: 0.8089 - val_loss: 3.0252 - val_acc: 0.4461\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.73770\n",
            "Epoch 315/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5860 - acc: 0.8063 - val_loss: 5.2148 - val_acc: 0.3649\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.73770\n",
            "Epoch 316/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5853 - acc: 0.8061 - val_loss: 1.8862 - val_acc: 0.5094\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.73770\n",
            "Epoch 317/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5919 - acc: 0.8046 - val_loss: 1.0610 - val_acc: 0.6993\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.73770\n",
            "Epoch 318/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5964 - acc: 0.8013 - val_loss: 1.3598 - val_acc: 0.6157\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.73770\n",
            "Epoch 319/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5932 - acc: 0.7988 - val_loss: 1.6906 - val_acc: 0.6229\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.73770\n",
            "Epoch 320/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5825 - acc: 0.8043 - val_loss: 1.5731 - val_acc: 0.5496\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.73770\n",
            "Epoch 321/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5878 - acc: 0.8030 - val_loss: 1.0482 - val_acc: 0.6895\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.73770\n",
            "Epoch 322/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5795 - acc: 0.8089 - val_loss: 1.0256 - val_acc: 0.6635\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.73770\n",
            "Epoch 323/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5777 - acc: 0.8096 - val_loss: 0.8054 - val_acc: 0.7359\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.73770\n",
            "Epoch 324/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5810 - acc: 0.8071 - val_loss: 1.9580 - val_acc: 0.5348\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.73770\n",
            "Epoch 325/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5750 - acc: 0.8143 - val_loss: 4.7399 - val_acc: 0.3266\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.73770\n",
            "Epoch 326/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5996 - acc: 0.7999 - val_loss: 0.9128 - val_acc: 0.7362\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.73770\n",
            "Epoch 327/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5763 - acc: 0.8108 - val_loss: 1.6566 - val_acc: 0.5929\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.73770\n",
            "Epoch 328/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5983 - acc: 0.8052 - val_loss: 2.5006 - val_acc: 0.4374\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.73770\n",
            "Epoch 329/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5768 - acc: 0.8105 - val_loss: 1.3028 - val_acc: 0.6507\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.73770\n",
            "Epoch 330/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5967 - acc: 0.8000 - val_loss: 1.4863 - val_acc: 0.6105\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.73770\n",
            "Epoch 331/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5869 - acc: 0.8050 - val_loss: 1.2160 - val_acc: 0.6532\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.73770\n",
            "Epoch 332/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5938 - acc: 0.8057 - val_loss: 4.8387 - val_acc: 0.3250\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.73770\n",
            "Epoch 333/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6005 - acc: 0.7999 - val_loss: 1.5272 - val_acc: 0.5988\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.73770\n",
            "Epoch 334/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5868 - acc: 0.8039 - val_loss: 1.8188 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.73770\n",
            "Epoch 335/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5789 - acc: 0.8095 - val_loss: 1.4950 - val_acc: 0.5679\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.73770\n",
            "Epoch 336/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5774 - acc: 0.8101 - val_loss: 2.7751 - val_acc: 0.4230\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.73770\n",
            "Epoch 337/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5861 - acc: 0.8056 - val_loss: 2.0625 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.73770\n",
            "Epoch 338/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5646 - acc: 0.8113 - val_loss: 1.3397 - val_acc: 0.6213\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.73770\n",
            "Epoch 339/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5815 - acc: 0.8073 - val_loss: 3.3009 - val_acc: 0.4130\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.73770\n",
            "Epoch 340/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6024 - acc: 0.8027 - val_loss: 2.6683 - val_acc: 0.4641\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.73770\n",
            "Epoch 341/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5759 - acc: 0.8074 - val_loss: 3.0308 - val_acc: 0.4700\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.73770\n",
            "Epoch 342/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5753 - acc: 0.8086 - val_loss: 1.1563 - val_acc: 0.6396\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.73770\n",
            "Epoch 343/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6055 - acc: 0.7966 - val_loss: 2.2280 - val_acc: 0.4794\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.73770\n",
            "Epoch 344/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5795 - acc: 0.8107 - val_loss: 2.6595 - val_acc: 0.5161\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.73770\n",
            "Epoch 345/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6004 - acc: 0.8018 - val_loss: 1.5951 - val_acc: 0.6011\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.73770\n",
            "Epoch 346/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5952 - acc: 0.8000 - val_loss: 2.4275 - val_acc: 0.5218\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.73770\n",
            "Epoch 347/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5802 - acc: 0.8118 - val_loss: 2.6447 - val_acc: 0.4643\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.73770\n",
            "Epoch 348/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5914 - acc: 0.8021 - val_loss: 1.6930 - val_acc: 0.5837\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.73770\n",
            "Epoch 349/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5720 - acc: 0.8105 - val_loss: 1.7397 - val_acc: 0.5837\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.73770\n",
            "Epoch 350/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5969 - acc: 0.8029 - val_loss: 2.1763 - val_acc: 0.5172\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.73770\n",
            "Epoch 351/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5778 - acc: 0.8107 - val_loss: 1.6741 - val_acc: 0.5391\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.73770\n",
            "Epoch 352/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5806 - acc: 0.8108 - val_loss: 2.3094 - val_acc: 0.4904\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.73770\n",
            "Epoch 353/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6222 - acc: 0.7929 - val_loss: 1.3543 - val_acc: 0.6435\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.73770\n",
            "Epoch 354/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5903 - acc: 0.8025 - val_loss: 2.7236 - val_acc: 0.4814\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.73770\n",
            "Epoch 355/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5898 - acc: 0.8071 - val_loss: 1.2960 - val_acc: 0.6092\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.73770\n",
            "Epoch 356/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5763 - acc: 0.8075 - val_loss: 0.9655 - val_acc: 0.6877\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.73770\n",
            "Epoch 357/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5913 - acc: 0.8020 - val_loss: 1.8280 - val_acc: 0.5679\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.73770\n",
            "Epoch 358/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5999 - acc: 0.8017 - val_loss: 2.5470 - val_acc: 0.4883\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.73770\n",
            "Epoch 359/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5915 - acc: 0.8000 - val_loss: 0.9040 - val_acc: 0.7267\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.73770\n",
            "Epoch 360/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5700 - acc: 0.8109 - val_loss: 1.5341 - val_acc: 0.5923\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.73770\n",
            "Epoch 361/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5739 - acc: 0.8140 - val_loss: 4.2086 - val_acc: 0.4342\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.73770\n",
            "Epoch 362/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5753 - acc: 0.8106 - val_loss: 2.1421 - val_acc: 0.5225\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.73770\n",
            "Epoch 363/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5835 - acc: 0.8087 - val_loss: 3.2414 - val_acc: 0.4276\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.73770\n",
            "Epoch 364/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5830 - acc: 0.8050 - val_loss: 2.3142 - val_acc: 0.5497\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.73770\n",
            "Epoch 365/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5863 - acc: 0.8075 - val_loss: 1.0908 - val_acc: 0.6729\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.73770\n",
            "Epoch 366/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5790 - acc: 0.8126 - val_loss: 2.2711 - val_acc: 0.4456\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.73770\n",
            "Epoch 367/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5952 - acc: 0.7991 - val_loss: 0.9558 - val_acc: 0.7070\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.73770\n",
            "Epoch 368/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5890 - acc: 0.7995 - val_loss: 1.6807 - val_acc: 0.5460\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.73770\n",
            "Epoch 369/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5651 - acc: 0.8145 - val_loss: 1.3315 - val_acc: 0.6504\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.73770\n",
            "Epoch 370/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5733 - acc: 0.8100 - val_loss: 1.1875 - val_acc: 0.6680\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.73770\n",
            "Epoch 371/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5834 - acc: 0.8073 - val_loss: 4.6170 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.73770\n",
            "Epoch 372/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5787 - acc: 0.8078 - val_loss: 2.4348 - val_acc: 0.5305\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.73770\n",
            "Epoch 373/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5899 - acc: 0.8019 - val_loss: 2.7460 - val_acc: 0.4204\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.73770\n",
            "Epoch 374/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5825 - acc: 0.8082 - val_loss: 1.5048 - val_acc: 0.5838\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.73770\n",
            "Epoch 375/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5721 - acc: 0.8094 - val_loss: 2.5153 - val_acc: 0.4810\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.73770\n",
            "Epoch 376/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5746 - acc: 0.8115 - val_loss: 1.2788 - val_acc: 0.6232\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.73770\n",
            "Epoch 377/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5859 - acc: 0.8066 - val_loss: 2.1766 - val_acc: 0.4402\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.73770\n",
            "Epoch 378/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5791 - acc: 0.8067 - val_loss: 1.2254 - val_acc: 0.6632\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.73770\n",
            "Epoch 379/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5848 - acc: 0.8081 - val_loss: 1.5924 - val_acc: 0.6099\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.73770\n",
            "Epoch 380/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5846 - acc: 0.8043 - val_loss: 1.3815 - val_acc: 0.6119\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.73770\n",
            "Epoch 381/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5914 - acc: 0.8053 - val_loss: 1.5066 - val_acc: 0.6016\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.73770\n",
            "Epoch 382/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5828 - acc: 0.8089 - val_loss: 2.5444 - val_acc: 0.4773\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.73770\n",
            "Epoch 383/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5665 - acc: 0.8116 - val_loss: 1.1166 - val_acc: 0.7082\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.73770\n",
            "Epoch 384/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5768 - acc: 0.8056 - val_loss: 3.8035 - val_acc: 0.4145\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.73770\n",
            "Epoch 385/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5999 - acc: 0.8011 - val_loss: 2.7051 - val_acc: 0.4389\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.73770\n",
            "Epoch 386/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5741 - acc: 0.8056 - val_loss: 1.4834 - val_acc: 0.6273\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.73770\n",
            "Epoch 387/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5821 - acc: 0.8053 - val_loss: 1.9045 - val_acc: 0.5268\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.73770\n",
            "Epoch 388/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5614 - acc: 0.8142 - val_loss: 1.3646 - val_acc: 0.6263\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.73770\n",
            "Epoch 389/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5729 - acc: 0.8106 - val_loss: 3.9638 - val_acc: 0.4113\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.73770\n",
            "Epoch 390/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5572 - acc: 0.8157 - val_loss: 1.6206 - val_acc: 0.5709\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.73770\n",
            "Epoch 391/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5885 - acc: 0.8064 - val_loss: 1.8867 - val_acc: 0.5327\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.73770\n",
            "Epoch 392/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5734 - acc: 0.8080 - val_loss: 0.9017 - val_acc: 0.7092\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.73770\n",
            "Epoch 393/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5736 - acc: 0.8062 - val_loss: 2.5957 - val_acc: 0.4806\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.73770\n",
            "Epoch 394/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5741 - acc: 0.8084 - val_loss: 3.6285 - val_acc: 0.3915\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.73770\n",
            "Epoch 395/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5821 - acc: 0.8056 - val_loss: 1.2991 - val_acc: 0.5954\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.73770\n",
            "Epoch 396/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5638 - acc: 0.8164 - val_loss: 2.3119 - val_acc: 0.4578\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.73770\n",
            "Epoch 397/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5759 - acc: 0.8099 - val_loss: 2.4586 - val_acc: 0.4799\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.73770\n",
            "Epoch 398/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5526 - acc: 0.8122 - val_loss: 1.0161 - val_acc: 0.6818\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.73770\n",
            "Epoch 399/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5627 - acc: 0.8153 - val_loss: 1.1591 - val_acc: 0.6889\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.73770\n",
            "Epoch 400/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5732 - acc: 0.8088 - val_loss: 1.6025 - val_acc: 0.6293\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.73770\n",
            "Epoch 401/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5678 - acc: 0.8145 - val_loss: 1.7439 - val_acc: 0.5655\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.73770\n",
            "Epoch 402/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4558 - acc: 0.8538 - val_loss: 0.5675 - val_acc: 0.8153\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.73770 to 0.81530, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3864 - acc: 0.8768 - val_loss: 0.5153 - val_acc: 0.8301\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.81530 to 0.83010, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3727 - acc: 0.8810 - val_loss: 0.4283 - val_acc: 0.8585\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.83010 to 0.85850, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3634 - acc: 0.8818 - val_loss: 0.4151 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.85850 to 0.86670, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3479 - acc: 0.8881 - val_loss: 0.3949 - val_acc: 0.8722\n",
            "\n",
            "Epoch 00406: val_acc improved from 0.86670 to 0.87220, saving model to /content/saved_models/cifar10_ResNet32v1_model.406.h5\n",
            "Epoch 407/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3288 - acc: 0.8930 - val_loss: 0.3750 - val_acc: 0.8793\n",
            "\n",
            "Epoch 00407: val_acc improved from 0.87220 to 0.87930, saving model to /content/saved_models/cifar10_ResNet32v1_model.407.h5\n",
            "Epoch 408/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3168 - acc: 0.8974 - val_loss: 0.3912 - val_acc: 0.8704\n",
            "\n",
            "Epoch 00408: val_acc did not improve from 0.87930\n",
            "Epoch 409/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3162 - acc: 0.8967 - val_loss: 0.4173 - val_acc: 0.8620\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.87930\n",
            "Epoch 410/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3176 - acc: 0.8959 - val_loss: 0.4343 - val_acc: 0.8605\n",
            "\n",
            "Epoch 00410: val_acc did not improve from 0.87930\n",
            "Epoch 411/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3164 - acc: 0.8975 - val_loss: 0.3811 - val_acc: 0.8761\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.87930\n",
            "Epoch 412/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3005 - acc: 0.9031 - val_loss: 0.3818 - val_acc: 0.8751\n",
            "\n",
            "Epoch 00412: val_acc did not improve from 0.87930\n",
            "Epoch 413/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3029 - acc: 0.9033 - val_loss: 0.4034 - val_acc: 0.8698\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.87930\n",
            "Epoch 414/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2891 - acc: 0.9072 - val_loss: 0.3741 - val_acc: 0.8793\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.87930\n",
            "Epoch 415/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2801 - acc: 0.9101 - val_loss: 0.3746 - val_acc: 0.8785\n",
            "\n",
            "Epoch 00415: val_acc did not improve from 0.87930\n",
            "Epoch 416/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2844 - acc: 0.9098 - val_loss: 0.3612 - val_acc: 0.8817\n",
            "\n",
            "Epoch 00416: val_acc improved from 0.87930 to 0.88170, saving model to /content/saved_models/cifar10_ResNet32v1_model.416.h5\n",
            "Epoch 417/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2768 - acc: 0.9069 - val_loss: 0.3922 - val_acc: 0.8746\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.88170\n",
            "Epoch 418/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2749 - acc: 0.9126 - val_loss: 0.4507 - val_acc: 0.8599\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.88170\n",
            "Epoch 419/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2660 - acc: 0.9142 - val_loss: 0.3473 - val_acc: 0.8881\n",
            "\n",
            "Epoch 00419: val_acc improved from 0.88170 to 0.88810, saving model to /content/saved_models/cifar10_ResNet32v1_model.419.h5\n",
            "Epoch 420/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2698 - acc: 0.9141 - val_loss: 0.4256 - val_acc: 0.8646\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.88810\n",
            "Epoch 421/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2667 - acc: 0.9150 - val_loss: 0.4066 - val_acc: 0.8685\n",
            "\n",
            "Epoch 00421: val_acc did not improve from 0.88810\n",
            "Epoch 422/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2543 - acc: 0.9196 - val_loss: 0.3529 - val_acc: 0.8852\n",
            "\n",
            "Epoch 00422: val_acc did not improve from 0.88810\n",
            "Epoch 423/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2539 - acc: 0.9209 - val_loss: 0.3797 - val_acc: 0.8779\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.88810\n",
            "Epoch 424/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2536 - acc: 0.9188 - val_loss: 0.3603 - val_acc: 0.8820\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.88810\n",
            "Epoch 425/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2560 - acc: 0.9176 - val_loss: 0.3630 - val_acc: 0.8835\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.88810\n",
            "Epoch 426/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2557 - acc: 0.9170 - val_loss: 0.3723 - val_acc: 0.8789\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.88810\n",
            "Epoch 427/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2559 - acc: 0.9169 - val_loss: 0.3471 - val_acc: 0.8896\n",
            "\n",
            "Epoch 00427: val_acc improved from 0.88810 to 0.88960, saving model to /content/saved_models/cifar10_ResNet32v1_model.427.h5\n",
            "Epoch 428/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2470 - acc: 0.9209 - val_loss: 0.3882 - val_acc: 0.8752\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.88960\n",
            "Epoch 429/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2631 - acc: 0.9131 - val_loss: 0.3349 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00429: val_acc improved from 0.88960 to 0.89290, saving model to /content/saved_models/cifar10_ResNet32v1_model.429.h5\n",
            "Epoch 430/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2429 - acc: 0.9239 - val_loss: 0.3707 - val_acc: 0.8784\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.89290\n",
            "Epoch 431/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2454 - acc: 0.9220 - val_loss: 0.3480 - val_acc: 0.8895\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.89290\n",
            "Epoch 432/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2541 - acc: 0.9174 - val_loss: 0.3857 - val_acc: 0.8784\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.89290\n",
            "Epoch 433/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2448 - acc: 0.9209 - val_loss: 0.3799 - val_acc: 0.8808\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.89290\n",
            "Epoch 434/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2404 - acc: 0.9223 - val_loss: 0.4008 - val_acc: 0.8731\n",
            "\n",
            "Epoch 00434: val_acc did not improve from 0.89290\n",
            "Epoch 435/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2447 - acc: 0.9211 - val_loss: 0.4049 - val_acc: 0.8717\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.89290\n",
            "Epoch 436/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2340 - acc: 0.9266 - val_loss: 0.3519 - val_acc: 0.8873\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.89290\n",
            "Epoch 437/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.2409 - acc: 0.9245 - val_loss: 0.3536 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.89290\n",
            "Epoch 438/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2280 - acc: 0.9280 - val_loss: 0.3450 - val_acc: 0.8926\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.89290\n",
            "Epoch 439/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2451 - acc: 0.9209 - val_loss: 0.4031 - val_acc: 0.8725\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.89290\n",
            "Epoch 440/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2202 - acc: 0.9305 - val_loss: 0.3698 - val_acc: 0.8790\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.89290\n",
            "Epoch 441/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2218 - acc: 0.9289 - val_loss: 0.3913 - val_acc: 0.8774\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.89290\n",
            "Epoch 442/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2222 - acc: 0.9296 - val_loss: 0.3681 - val_acc: 0.8858\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.89290\n",
            "Epoch 443/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2407 - acc: 0.9198 - val_loss: 0.4502 - val_acc: 0.8627\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.89290\n",
            "Epoch 444/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.2211 - acc: 0.9285 - val_loss: 0.3549 - val_acc: 0.8868\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.89290\n",
            "Epoch 445/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2176 - acc: 0.9288 - val_loss: 0.3379 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.89290\n",
            "Epoch 446/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2240 - acc: 0.9283 - val_loss: 0.3794 - val_acc: 0.8816\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.89290\n",
            "Epoch 447/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2126 - acc: 0.9325 - val_loss: 0.3490 - val_acc: 0.8911\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.89290\n",
            "Epoch 448/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2202 - acc: 0.9293 - val_loss: 0.3893 - val_acc: 0.8809\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.89290\n",
            "Epoch 449/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2108 - acc: 0.9324 - val_loss: 0.3947 - val_acc: 0.8737\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.89290\n",
            "Epoch 450/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2069 - acc: 0.9344 - val_loss: 0.3356 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00450: val_acc improved from 0.89290 to 0.89550, saving model to /content/saved_models/cifar10_ResNet32v1_model.450.h5\n",
            "Epoch 451/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2082 - acc: 0.9340 - val_loss: 0.3517 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.89550\n",
            "Epoch 452/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2101 - acc: 0.9313 - val_loss: 0.3533 - val_acc: 0.8899\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.89550\n",
            "Epoch 453/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2179 - acc: 0.9309 - val_loss: 0.3483 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.89550\n",
            "Epoch 454/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2103 - acc: 0.9332 - val_loss: 0.3646 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.89550\n",
            "Epoch 455/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.2073 - acc: 0.9331 - val_loss: 0.3455 - val_acc: 0.8947\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.89550\n",
            "Epoch 456/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2012 - acc: 0.9358 - val_loss: 0.3454 - val_acc: 0.8903\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.89550\n",
            "Epoch 457/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2033 - acc: 0.9339 - val_loss: 0.3566 - val_acc: 0.8867\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.89550\n",
            "Epoch 458/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1993 - acc: 0.9375 - val_loss: 0.3727 - val_acc: 0.8844\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.89550\n",
            "Epoch 459/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1978 - acc: 0.9362 - val_loss: 0.3401 - val_acc: 0.8930\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.89550\n",
            "Epoch 460/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1995 - acc: 0.9364 - val_loss: 0.3688 - val_acc: 0.8841\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.89550\n",
            "Epoch 461/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1925 - acc: 0.9402 - val_loss: 0.3488 - val_acc: 0.8911\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.89550\n",
            "Epoch 462/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2040 - acc: 0.9353 - val_loss: 0.3922 - val_acc: 0.8809\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.89550\n",
            "Epoch 463/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1865 - acc: 0.9396 - val_loss: 0.3300 - val_acc: 0.8941\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.89550\n",
            "Epoch 464/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1948 - acc: 0.9370 - val_loss: 0.3529 - val_acc: 0.8849\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.89550\n",
            "Epoch 465/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.2007 - acc: 0.9339 - val_loss: 0.3438 - val_acc: 0.8891\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.89550\n",
            "Epoch 466/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1892 - acc: 0.9407 - val_loss: 0.3775 - val_acc: 0.8852\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.89550\n",
            "Epoch 467/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1945 - acc: 0.9385 - val_loss: 0.3492 - val_acc: 0.8943\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.89550\n",
            "Epoch 468/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1931 - acc: 0.9423 - val_loss: 0.3576 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.89550\n",
            "Epoch 469/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1844 - acc: 0.9405 - val_loss: 0.5759 - val_acc: 0.8398\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.89550\n",
            "Epoch 470/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1753 - acc: 0.9443 - val_loss: 0.3442 - val_acc: 0.8933\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.89550\n",
            "Epoch 471/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1945 - acc: 0.9396 - val_loss: 0.3412 - val_acc: 0.8966\n",
            "\n",
            "Epoch 00471: val_acc improved from 0.89550 to 0.89660, saving model to /content/saved_models/cifar10_ResNet32v1_model.471.h5\n",
            "Epoch 472/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1848 - acc: 0.9424 - val_loss: 0.3030 - val_acc: 0.9029\n",
            "\n",
            "Epoch 00472: val_acc improved from 0.89660 to 0.90290, saving model to /content/saved_models/cifar10_ResNet32v1_model.472.h5\n",
            "Epoch 473/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1887 - acc: 0.9396 - val_loss: 0.3513 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.90290\n",
            "Epoch 474/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1911 - acc: 0.9365 - val_loss: 0.3609 - val_acc: 0.8872\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.90290\n",
            "Epoch 475/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1853 - acc: 0.9401 - val_loss: 0.3186 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.90290\n",
            "Epoch 476/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1869 - acc: 0.9419 - val_loss: 0.3158 - val_acc: 0.9012\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.90290\n",
            "Epoch 477/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1836 - acc: 0.9438 - val_loss: 0.3369 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.90290\n",
            "Epoch 478/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1821 - acc: 0.9445 - val_loss: 0.3416 - val_acc: 0.8954\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.90290\n",
            "Epoch 479/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1857 - acc: 0.9423 - val_loss: 0.3661 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.90290\n",
            "Epoch 480/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1770 - acc: 0.9433 - val_loss: 0.3514 - val_acc: 0.8902\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.90290\n",
            "Epoch 481/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1893 - acc: 0.9413 - val_loss: 0.3647 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.90290\n",
            "Epoch 482/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1869 - acc: 0.9406 - val_loss: 0.3371 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.90290\n",
            "Epoch 483/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1818 - acc: 0.9429 - val_loss: 0.3685 - val_acc: 0.8875\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.90290\n",
            "Epoch 484/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1850 - acc: 0.9415 - val_loss: 0.4473 - val_acc: 0.8670\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.90290\n",
            "Epoch 485/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1718 - acc: 0.9461 - val_loss: 0.3395 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.90290\n",
            "Epoch 486/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1794 - acc: 0.9402 - val_loss: 0.3132 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00486: val_acc improved from 0.90290 to 0.90610, saving model to /content/saved_models/cifar10_ResNet32v1_model.486.h5\n",
            "Epoch 487/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1721 - acc: 0.9492 - val_loss: 0.4060 - val_acc: 0.8794\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.90610\n",
            "Epoch 488/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1723 - acc: 0.9444 - val_loss: 0.3598 - val_acc: 0.8850\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.90610\n",
            "Epoch 489/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1787 - acc: 0.9431 - val_loss: 0.3421 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.90610\n",
            "Epoch 490/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1660 - acc: 0.9461 - val_loss: 0.3555 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.90610\n",
            "Epoch 491/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1769 - acc: 0.9416 - val_loss: 0.4005 - val_acc: 0.8776\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.90610\n",
            "Epoch 492/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1716 - acc: 0.9463 - val_loss: 0.3534 - val_acc: 0.8939\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.90610\n",
            "Epoch 493/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1772 - acc: 0.9445 - val_loss: 0.3340 - val_acc: 0.8931\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.90610\n",
            "Epoch 494/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1707 - acc: 0.9466 - val_loss: 0.3496 - val_acc: 0.8903\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.90610\n",
            "Epoch 495/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1709 - acc: 0.9465 - val_loss: 0.3282 - val_acc: 0.8948\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.90610\n",
            "Epoch 496/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1781 - acc: 0.9435 - val_loss: 0.3499 - val_acc: 0.8859\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.90610\n",
            "Epoch 497/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1671 - acc: 0.9478 - val_loss: 0.3556 - val_acc: 0.8928\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.90610\n",
            "Epoch 498/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1647 - acc: 0.9493 - val_loss: 0.3762 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.90610\n",
            "Epoch 499/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1663 - acc: 0.9481 - val_loss: 0.3945 - val_acc: 0.8817\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.90610\n",
            "Epoch 500/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1622 - acc: 0.9509 - val_loss: 0.3416 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.90610\n",
            "Epoch 501/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1567 - acc: 0.9501 - val_loss: 0.3612 - val_acc: 0.8915\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.90610\n",
            "Epoch 502/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1615 - acc: 0.9503 - val_loss: 0.3634 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.90610\n",
            "Epoch 503/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1627 - acc: 0.9491 - val_loss: 0.3441 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.90610\n",
            "Epoch 504/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1635 - acc: 0.9479 - val_loss: 0.3288 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.90610\n",
            "Epoch 505/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1574 - acc: 0.9511 - val_loss: 0.4772 - val_acc: 0.8621\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.90610\n",
            "Epoch 506/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1565 - acc: 0.9510 - val_loss: 0.3614 - val_acc: 0.8952\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.90610\n",
            "Epoch 507/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1563 - acc: 0.9508 - val_loss: 0.4442 - val_acc: 0.8704\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.90610\n",
            "Epoch 508/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1597 - acc: 0.9506 - val_loss: 0.3786 - val_acc: 0.8843\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.90610\n",
            "Epoch 509/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1629 - acc: 0.9484 - val_loss: 0.4674 - val_acc: 0.8712\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.90610\n",
            "Epoch 510/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1578 - acc: 0.9511 - val_loss: 0.3685 - val_acc: 0.8901\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.90610\n",
            "Epoch 511/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1543 - acc: 0.9508 - val_loss: 0.3896 - val_acc: 0.8855\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.90610\n",
            "Epoch 512/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1592 - acc: 0.9507 - val_loss: 0.3502 - val_acc: 0.8902\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.90610\n",
            "Epoch 513/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1517 - acc: 0.9520 - val_loss: 0.3610 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.90610\n",
            "Epoch 514/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1565 - acc: 0.9523 - val_loss: 0.3435 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.90610\n",
            "Epoch 515/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1605 - acc: 0.9471 - val_loss: 0.3371 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.90610\n",
            "Epoch 516/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1557 - acc: 0.9514 - val_loss: 0.3833 - val_acc: 0.8849\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.90610\n",
            "Epoch 517/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1623 - acc: 0.9491 - val_loss: 0.3691 - val_acc: 0.8871\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.90610\n",
            "Epoch 518/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1689 - acc: 0.9481 - val_loss: 0.4636 - val_acc: 0.8645\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.90610\n",
            "Epoch 519/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1513 - acc: 0.9542 - val_loss: 0.3728 - val_acc: 0.8852\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.90610\n",
            "Epoch 520/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1511 - acc: 0.9533 - val_loss: 0.3594 - val_acc: 0.8934\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.90610\n",
            "Epoch 521/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1526 - acc: 0.9518 - val_loss: 0.4536 - val_acc: 0.8701\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.90610\n",
            "Epoch 522/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1520 - acc: 0.9544 - val_loss: 0.3490 - val_acc: 0.8921\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.90610\n",
            "Epoch 523/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1559 - acc: 0.9503 - val_loss: 0.3968 - val_acc: 0.8815\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.90610\n",
            "Epoch 524/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1553 - acc: 0.9501 - val_loss: 0.3463 - val_acc: 0.8920\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.90610\n",
            "Epoch 525/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1507 - acc: 0.9534 - val_loss: 0.3677 - val_acc: 0.8911\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.90610\n",
            "Epoch 526/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1433 - acc: 0.9549 - val_loss: 0.3403 - val_acc: 0.8977\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.90610\n",
            "Epoch 527/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1535 - acc: 0.9513 - val_loss: 0.3785 - val_acc: 0.8871\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.90610\n",
            "Epoch 528/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1556 - acc: 0.9498 - val_loss: 0.3496 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.90610\n",
            "Epoch 529/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1488 - acc: 0.9546 - val_loss: 0.3501 - val_acc: 0.8927\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.90610\n",
            "Epoch 530/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1550 - acc: 0.9525 - val_loss: 0.4341 - val_acc: 0.8787\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.90610\n",
            "Epoch 531/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1508 - acc: 0.9520 - val_loss: 0.3733 - val_acc: 0.8885\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.90610\n",
            "Epoch 532/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1476 - acc: 0.9540 - val_loss: 0.3446 - val_acc: 0.8977\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.90610\n",
            "Epoch 533/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1412 - acc: 0.9566 - val_loss: 0.3259 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.90610\n",
            "Epoch 534/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1456 - acc: 0.9557 - val_loss: 0.3910 - val_acc: 0.8852\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.90610\n",
            "Epoch 535/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1395 - acc: 0.9579 - val_loss: 0.4416 - val_acc: 0.8732\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.90610\n",
            "Epoch 536/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1517 - acc: 0.9531 - val_loss: 0.3609 - val_acc: 0.8935\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.90610\n",
            "Epoch 537/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1513 - acc: 0.9529 - val_loss: 0.3414 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.90610\n",
            "Epoch 538/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1481 - acc: 0.9534 - val_loss: 0.3606 - val_acc: 0.8953\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.90610\n",
            "Epoch 539/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1409 - acc: 0.9571 - val_loss: 0.3249 - val_acc: 0.9044\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.90610\n",
            "Epoch 540/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1431 - acc: 0.9536 - val_loss: 0.3765 - val_acc: 0.8895\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.90610\n",
            "Epoch 541/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1425 - acc: 0.9557 - val_loss: 0.3329 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.90610\n",
            "Epoch 542/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1377 - acc: 0.9567 - val_loss: 0.3396 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.90610\n",
            "Epoch 543/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1454 - acc: 0.9559 - val_loss: 0.3154 - val_acc: 0.9068\n",
            "\n",
            "Epoch 00543: val_acc improved from 0.90610 to 0.90680, saving model to /content/saved_models/cifar10_ResNet32v1_model.543.h5\n",
            "Epoch 544/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1458 - acc: 0.9558 - val_loss: 0.4100 - val_acc: 0.8812\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.90680\n",
            "Epoch 545/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1398 - acc: 0.9587 - val_loss: 0.3351 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.90680\n",
            "Epoch 546/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1488 - acc: 0.9527 - val_loss: 0.3579 - val_acc: 0.8964\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.90680\n",
            "Epoch 547/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1417 - acc: 0.9565 - val_loss: 0.3870 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.90680\n",
            "Epoch 548/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1332 - acc: 0.9600 - val_loss: 0.3241 - val_acc: 0.9030\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.90680\n",
            "Epoch 549/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1412 - acc: 0.9559 - val_loss: 0.3979 - val_acc: 0.8819\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.90680\n",
            "Epoch 550/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1411 - acc: 0.9546 - val_loss: 0.3629 - val_acc: 0.8954\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.90680\n",
            "Epoch 551/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.1488 - acc: 0.9528 - val_loss: 0.4013 - val_acc: 0.8862\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.90680\n",
            "Epoch 552/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1376 - acc: 0.9556 - val_loss: 0.3590 - val_acc: 0.8906\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.90680\n",
            "Epoch 553/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1453 - acc: 0.9554 - val_loss: 0.3853 - val_acc: 0.8864\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.90680\n",
            "Epoch 554/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1365 - acc: 0.9602 - val_loss: 0.3816 - val_acc: 0.8860\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.90680\n",
            "Epoch 555/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1396 - acc: 0.9545 - val_loss: 0.3710 - val_acc: 0.8868\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.90680\n",
            "Epoch 556/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1342 - acc: 0.9589 - val_loss: 0.4074 - val_acc: 0.8822\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.90680\n",
            "Epoch 557/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1448 - acc: 0.9532 - val_loss: 0.4487 - val_acc: 0.8659\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.90680\n",
            "Epoch 558/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1443 - acc: 0.9551 - val_loss: 0.3321 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.90680\n",
            "Epoch 559/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1381 - acc: 0.9575 - val_loss: 0.3679 - val_acc: 0.8939\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.90680\n",
            "Epoch 560/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1309 - acc: 0.9626 - val_loss: 0.3225 - val_acc: 0.9023\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.90680\n",
            "Epoch 561/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1239 - acc: 0.9625 - val_loss: 0.3633 - val_acc: 0.8954\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.90680\n",
            "Epoch 562/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1277 - acc: 0.9594 - val_loss: 0.3333 - val_acc: 0.9010\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.90680\n",
            "Epoch 563/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1320 - acc: 0.9584 - val_loss: 0.3370 - val_acc: 0.9007\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.90680\n",
            "Epoch 564/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1352 - acc: 0.9587 - val_loss: 0.3726 - val_acc: 0.8901\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.90680\n",
            "Epoch 565/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1371 - acc: 0.9567 - val_loss: 0.4112 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.90680\n",
            "Epoch 566/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1305 - acc: 0.9589 - val_loss: 0.3377 - val_acc: 0.9011\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.90680\n",
            "Epoch 567/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1324 - acc: 0.9609 - val_loss: 0.3906 - val_acc: 0.8891\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.90680\n",
            "Epoch 568/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1375 - acc: 0.9574 - val_loss: 0.4581 - val_acc: 0.8724\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.90680\n",
            "Epoch 569/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1322 - acc: 0.9604 - val_loss: 0.3509 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.90680\n",
            "Epoch 570/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1320 - acc: 0.9580 - val_loss: 0.3653 - val_acc: 0.8940\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.90680\n",
            "Epoch 571/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1320 - acc: 0.9604 - val_loss: 0.3972 - val_acc: 0.8887\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.90680\n",
            "Epoch 572/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1345 - acc: 0.9593 - val_loss: 0.4177 - val_acc: 0.8827\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.90680\n",
            "Epoch 573/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1349 - acc: 0.9579 - val_loss: 0.3508 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.90680\n",
            "Epoch 574/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.1281 - acc: 0.9608 - val_loss: 0.3527 - val_acc: 0.8957\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.90680\n",
            "Epoch 575/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1363 - acc: 0.9573 - val_loss: 0.3732 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.90680\n",
            "Epoch 576/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1305 - acc: 0.9588 - val_loss: 0.3130 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.90680\n",
            "Epoch 577/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1219 - acc: 0.9608 - val_loss: 0.3833 - val_acc: 0.8849\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.90680\n",
            "Epoch 578/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1350 - acc: 0.9573 - val_loss: 0.3716 - val_acc: 0.8882\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.90680\n",
            "Epoch 579/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1345 - acc: 0.9568 - val_loss: 0.3692 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.90680\n",
            "Epoch 580/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1310 - acc: 0.9608 - val_loss: 0.3658 - val_acc: 0.8906\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.90680\n",
            "Epoch 581/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1280 - acc: 0.9617 - val_loss: 0.3874 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.90680\n",
            "Epoch 582/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1290 - acc: 0.9611 - val_loss: 0.3569 - val_acc: 0.8933\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.90680\n",
            "Epoch 583/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1269 - acc: 0.9636 - val_loss: 0.3927 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.90680\n",
            "Epoch 584/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1228 - acc: 0.9641 - val_loss: 0.3505 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.90680\n",
            "Epoch 585/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1303 - acc: 0.9597 - val_loss: 0.3701 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.90680\n",
            "Epoch 586/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1306 - acc: 0.9589 - val_loss: 0.3806 - val_acc: 0.8861\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.90680\n",
            "Epoch 587/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.1302 - acc: 0.9605 - val_loss: 0.4392 - val_acc: 0.8786\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.90680\n",
            "Epoch 588/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1326 - acc: 0.9572 - val_loss: 0.4269 - val_acc: 0.8808\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.90680\n",
            "Epoch 589/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1272 - acc: 0.9623 - val_loss: 0.3743 - val_acc: 0.8932\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.90680\n",
            "Epoch 590/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1317 - acc: 0.9611 - val_loss: 0.3476 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.90680\n",
            "Epoch 591/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1327 - acc: 0.9594 - val_loss: 0.3364 - val_acc: 0.9008\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.90680\n",
            "Epoch 592/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1315 - acc: 0.9603 - val_loss: 0.3852 - val_acc: 0.8943\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.90680\n",
            "Epoch 593/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1193 - acc: 0.9635 - val_loss: 0.4475 - val_acc: 0.8762\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.90680\n",
            "Epoch 594/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1267 - acc: 0.9614 - val_loss: 0.3542 - val_acc: 0.8942\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.90680\n",
            "Epoch 595/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1192 - acc: 0.9624 - val_loss: 0.3269 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.90680\n",
            "Epoch 596/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1252 - acc: 0.9621 - val_loss: 0.3893 - val_acc: 0.8811\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.90680\n",
            "Epoch 597/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1317 - acc: 0.9584 - val_loss: 0.3270 - val_acc: 0.9063\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.90680\n",
            "Epoch 598/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1233 - acc: 0.9624 - val_loss: 0.4364 - val_acc: 0.8764\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.90680\n",
            "Epoch 599/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1264 - acc: 0.9624 - val_loss: 0.3759 - val_acc: 0.8909\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.90680\n",
            "Epoch 600/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1202 - acc: 0.9628 - val_loss: 0.3342 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.90680\n",
            "Epoch 601/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1289 - acc: 0.9601 - val_loss: 0.3624 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.90680\n",
            "Epoch 602/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1194 - acc: 0.9643 - val_loss: 0.3117 - val_acc: 0.9085\n",
            "\n",
            "Epoch 00602: val_acc improved from 0.90680 to 0.90850, saving model to /content/saved_models/cifar10_ResNet32v1_model.602.h5\n",
            "Epoch 603/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.1178 - acc: 0.9662 - val_loss: 0.3034 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00603: val_acc improved from 0.90850 to 0.90970, saving model to /content/saved_models/cifar10_ResNet32v1_model.603.h5\n",
            "Epoch 604/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1227 - acc: 0.9661 - val_loss: 0.2993 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00604: val_acc improved from 0.90970 to 0.91030, saving model to /content/saved_models/cifar10_ResNet32v1_model.604.h5\n",
            "Epoch 605/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1195 - acc: 0.9667 - val_loss: 0.2962 - val_acc: 0.9106\n",
            "\n",
            "Epoch 00605: val_acc improved from 0.91030 to 0.91060, saving model to /content/saved_models/cifar10_ResNet32v1_model.605.h5\n",
            "Epoch 606/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1160 - acc: 0.9646 - val_loss: 0.2939 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00606: val_acc improved from 0.91060 to 0.91100, saving model to /content/saved_models/cifar10_ResNet32v1_model.606.h5\n",
            "Epoch 607/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1177 - acc: 0.9662 - val_loss: 0.2914 - val_acc: 0.9114\n",
            "\n",
            "Epoch 00607: val_acc improved from 0.91100 to 0.91140, saving model to /content/saved_models/cifar10_ResNet32v1_model.607.h5\n",
            "Epoch 608/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1197 - acc: 0.9665 - val_loss: 0.2907 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00608: val_acc did not improve from 0.91140\n",
            "Epoch 609/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1082 - acc: 0.9691 - val_loss: 0.2886 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00609: val_acc improved from 0.91140 to 0.91220, saving model to /content/saved_models/cifar10_ResNet32v1_model.609.h5\n",
            "Epoch 610/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1134 - acc: 0.9678 - val_loss: 0.2876 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00610: val_acc improved from 0.91220 to 0.91260, saving model to /content/saved_models/cifar10_ResNet32v1_model.610.h5\n",
            "Epoch 611/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1154 - acc: 0.9673 - val_loss: 0.2857 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.91260\n",
            "Epoch 612/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1139 - acc: 0.9689 - val_loss: 0.2849 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00612: val_acc did not improve from 0.91260\n",
            "Epoch 613/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1119 - acc: 0.9680 - val_loss: 0.2829 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00613: val_acc improved from 0.91260 to 0.91290, saving model to /content/saved_models/cifar10_ResNet32v1_model.613.h5\n",
            "Epoch 614/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1119 - acc: 0.9676 - val_loss: 0.2826 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.91290\n",
            "Epoch 615/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1092 - acc: 0.9701 - val_loss: 0.2807 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.91290\n",
            "Epoch 616/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1102 - acc: 0.9695 - val_loss: 0.2808 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00616: val_acc improved from 0.91290 to 0.91310, saving model to /content/saved_models/cifar10_ResNet32v1_model.616.h5\n",
            "Epoch 617/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1085 - acc: 0.9695 - val_loss: 0.2805 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00617: val_acc improved from 0.91310 to 0.91330, saving model to /content/saved_models/cifar10_ResNet32v1_model.617.h5\n",
            "Epoch 618/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1106 - acc: 0.9709 - val_loss: 0.2795 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00618: val_acc did not improve from 0.91330\n",
            "Epoch 619/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1159 - acc: 0.9692 - val_loss: 0.2788 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00619: val_acc improved from 0.91330 to 0.91360, saving model to /content/saved_models/cifar10_ResNet32v1_model.619.h5\n",
            "Epoch 620/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1031 - acc: 0.9721 - val_loss: 0.2787 - val_acc: 0.9138\n",
            "\n",
            "Epoch 00620: val_acc improved from 0.91360 to 0.91380, saving model to /content/saved_models/cifar10_ResNet32v1_model.620.h5\n",
            "Epoch 621/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1083 - acc: 0.9712 - val_loss: 0.2785 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00621: val_acc improved from 0.91380 to 0.91420, saving model to /content/saved_models/cifar10_ResNet32v1_model.621.h5\n",
            "Epoch 622/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1058 - acc: 0.9720 - val_loss: 0.2777 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.91420\n",
            "Epoch 623/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1039 - acc: 0.9729 - val_loss: 0.2775 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.91420\n",
            "Epoch 624/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1075 - acc: 0.9717 - val_loss: 0.2771 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.91420\n",
            "Epoch 625/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1052 - acc: 0.9717 - val_loss: 0.2767 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00625: val_acc improved from 0.91420 to 0.91430, saving model to /content/saved_models/cifar10_ResNet32v1_model.625.h5\n",
            "Epoch 626/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1068 - acc: 0.9698 - val_loss: 0.2765 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.91430\n",
            "Epoch 627/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.1065 - acc: 0.9708 - val_loss: 0.2761 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00627: val_acc improved from 0.91430 to 0.91450, saving model to /content/saved_models/cifar10_ResNet32v1_model.627.h5\n",
            "Epoch 628/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1037 - acc: 0.9732 - val_loss: 0.2753 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00628: val_acc did not improve from 0.91450\n",
            "Epoch 629/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1088 - acc: 0.9706 - val_loss: 0.2756 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.91450\n",
            "Epoch 630/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1070 - acc: 0.9704 - val_loss: 0.2746 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00630: val_acc did not improve from 0.91450\n",
            "Epoch 631/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1054 - acc: 0.9730 - val_loss: 0.2739 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00631: val_acc improved from 0.91450 to 0.91470, saving model to /content/saved_models/cifar10_ResNet32v1_model.631.h5\n",
            "Epoch 632/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1036 - acc: 0.9738 - val_loss: 0.2732 - val_acc: 0.9150\n",
            "\n",
            "Epoch 00632: val_acc improved from 0.91470 to 0.91500, saving model to /content/saved_models/cifar10_ResNet32v1_model.632.h5\n",
            "Epoch 633/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1042 - acc: 0.9715 - val_loss: 0.2733 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00633: val_acc improved from 0.91500 to 0.91510, saving model to /content/saved_models/cifar10_ResNet32v1_model.633.h5\n",
            "Epoch 634/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1062 - acc: 0.9697 - val_loss: 0.2721 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00634: val_acc improved from 0.91510 to 0.91530, saving model to /content/saved_models/cifar10_ResNet32v1_model.634.h5\n",
            "Epoch 635/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1016 - acc: 0.9739 - val_loss: 0.2721 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.91530\n",
            "Epoch 636/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1053 - acc: 0.9713 - val_loss: 0.2726 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.91530\n",
            "Epoch 637/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1016 - acc: 0.9717 - val_loss: 0.2725 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00637: val_acc improved from 0.91530 to 0.91650, saving model to /content/saved_models/cifar10_ResNet32v1_model.637.h5\n",
            "Epoch 638/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1021 - acc: 0.9726 - val_loss: 0.2724 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.91650\n",
            "Epoch 639/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1043 - acc: 0.9731 - val_loss: 0.2733 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.91650\n",
            "Epoch 640/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1007 - acc: 0.9714 - val_loss: 0.2721 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.91650\n",
            "Epoch 641/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0988 - acc: 0.9740 - val_loss: 0.2719 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.91650\n",
            "Epoch 642/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0985 - acc: 0.9750 - val_loss: 0.2707 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.91650\n",
            "Epoch 643/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1040 - acc: 0.9722 - val_loss: 0.2706 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.91650\n",
            "Epoch 644/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1035 - acc: 0.9713 - val_loss: 0.2705 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.91650\n",
            "Epoch 645/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0977 - acc: 0.9755 - val_loss: 0.2706 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00645: val_acc improved from 0.91650 to 0.91670, saving model to /content/saved_models/cifar10_ResNet32v1_model.645.h5\n",
            "Epoch 646/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0941 - acc: 0.9762 - val_loss: 0.2706 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00646: val_acc did not improve from 0.91670\n",
            "Epoch 647/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0996 - acc: 0.9745 - val_loss: 0.2701 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00647: val_acc did not improve from 0.91670\n",
            "Epoch 648/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0993 - acc: 0.9745 - val_loss: 0.2706 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.91670\n",
            "Epoch 649/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1001 - acc: 0.9737 - val_loss: 0.2697 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00649: val_acc improved from 0.91670 to 0.91680, saving model to /content/saved_models/cifar10_ResNet32v1_model.649.h5\n",
            "Epoch 650/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0980 - acc: 0.9731 - val_loss: 0.2695 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00650: val_acc did not improve from 0.91680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqtP1kexx3yY",
        "outputId": "54c39572-b1a9-4158-acb0-95ee5fa7481b"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('simple_trainHistoryDict_clip_05', \"rb\"))\n",
        "functions.plot_loss_acc(history, 2, 0.4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAGDCAYAAADZHo16AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9d5hb13W3+27U6eSwd5HqpBplUsWSbNMliUsk5d4kLmn2vUn0ObETx065zk0+27GTG6dcp9pxyaeUL7F95fizJTty7NjhSLJVrF4oiqJEkeKQYieHnIq27x/nbGDj4DRggAFmsN7nmQfAqRsYYJ+FH35rLaW1RhAEQRAEQRCECol2D0AQBEEQBEEQOg0JkgVBEARBEATBgwTJgiAIgiAIguBBgmRBEARBEARB8CBBsiAIgiAIgiB4kCBZEARBEARBEDxIkCwIgiAIgiAIHiRIFuY9Sqn9Sqk3tXscgiAIQjDuXD2llBq3/v623eMShCBS7R6AIAiCIAhdw81a6++GbaCUSmmtC55lSa11Me5J6t1eEPwQJVlYkCilskqpv1RKHXb//lIplXXXLVNKfVMpdUYpdUopdZ9SKuGu+7+UUoeUUueUUnuUUm9s7zMRBEFY2Cil3qOU+oFS6i+UUieBjyml/lEp9XdKqbuVUhPA65VSm5VSI+7cvUspdYt1jJrt2/aEhAWDKMnCQuX3gOuBrYAG7gR+H/jvwG8Co8Byd9vrAa2UugR4P3CN1vqwUmojkJzbYQuCIHQl1wFfBlYCaeDvgJ8B3gr8ONAPPA7cDvwocBNwp1Jqu9Z6j3sMe/vMnI5eWJCIkiwsVH4W+LjW+pjW+jjwB8DPu+vywGrgPK11Xmt9n9ZaA0UgC2xRSqW11vu11i+2ZfSCIAgLk6+7SrD5+2V3+WGt9d9orQta6yl32Z1a6x9orUs4gscA8EmtdU5r/V/AN4F3Wccub6+1np67pyQsVCRIFhYqa4AD1uMD7jKAPwNeAL6jlNqnlPowgNb6BeA3gI8Bx5RSX1ZKrUEQBEFoFj+htV5s/X3BXX7QZ1t72RrgoBswGw4AawO2F4RZI0GysFA5DJxnPd7gLkNrfU5r/Zta6/OBW4APGe+x1vqLWuub3H018CdzO2xBEISuREcsOwysN/kjLhuAQxHHEISGkSBZWCiklVI95g/4EvD7SqnlSqllwEeAfwFQSv24UupCpZQCxnBsFiWl1CVKqTe4CX7TwBRQ8j+dIAiCMIc8BEwCv6OUSiuldgA34/iYBaElSJAsLBTuxglqzV8P8AjwFPA08Bjwh+62FwHfBcaBB4DPaK134viRPwmcAI4AK4DfnbunIAiCsOD5hqdO8tfi7KS1zuEExW/BmaM/A/yC1vq5Fo5V6HKUk68kCIIgCIIgCIJBlGRBEARBEARB8BAZJCul1iuldiqlnnWLd3/AZxullPprpdQLSqmnlFKvsta9Wym11/17d7OfgCAIglCNUurNbjOcF0z1loDtflIppZVS261lv+vut0cp9WNzM2JBEITOI9JuoZRaDazWWj+mlBoEHsUp4fKstc1bgV/DKeJ9HfBXWuvrlFJLcHyh23GyTh8FtmmtT7fk2QiCIHQ5Sqkk8DzwIzhNcx4G3mXP2e52g8C/4zRdeL/W+hGl1BacpNdrcUpufRe4WNr7CoLQjUQqyVrrV7TWj7n3zwG7qa5LCHAr8M/a4UFgsRtc/xjwn1rrU25g/J/Am5v6DARBEASba4EXtNb73GSnL+PM0V4+gVPi0G66cCvwZa31jNb6JZx64te2esCCIAidSF2eZLdN79U4pVhs1lJdxHvUXRa0XBAEQWgNkfOua4lbr7X+93r3FQRB6BZScTdUSg0AXwV+Q2t9ttkDUUrdBtwG0Nvbu239+vV17V8qlUgkomN+pUsMjO9jJruMXGYxAMniNH2To0z1rqGQ6qt/8B6SpRn6JpzrzLnBC2vHUJhmYGqUqd7VFFL95eV9k6NolWCqN7zJW//EyxSTWVLFKVSpUHOenunjpArjFJM9JHSBib76Xsu+yUMoXWSif0PN69ozfZRkcYaJ/g2V51ucoW/yYPn1S+fH6Jk+DkAus5iZ7LKq4yeLU/RNHmKyby3FZC8D4/vIp4eYyS4jVZikd+owM9mlZGdOlrcxJEp5+icOMN27knxqsOq4qjDFwJRTV97sl8mdITtzgnx6iOmeFTXn7p84QDHZQyE1SO/UYSb71tE3OQpAPr2I6Z7lga+TOXYhNUCiNEM+PUR25iTnBi9gYHw/hdRA4P5x36+dgIy1Pp5//vkTWuvgN06bcZsxfAp4zyyPM6s5G+DoRImChrUDnf/+6pk6QrKUq5r7+iYPA5rJvvDvEUoXGRh/iUJqgKneVeV5brJvPcVkloGJ/RSSfUz3rKBn+hipwiTjAxt9j5XOn6Nn+igT/RspJVI1y8/1rodUtrw8kzvtzkuVa4QZTz69iHR+jKneVRRSAwBVYyk/d595P1WcpHfyMIVUH6nCpO+1zsy3WqV8n0+pVKIvd5J0foxcZpiZ7FLf59w3eYhkcarmGp0qTNA79Up5/Ob6YNAqyfjApqrjgHN9yM6cIpM7xUx2KbnMcNX5zNw+PnA+2u1d0glzS1xkrPUROmdrrSP/gDTwbeBDAes/h+N5M4/3AKtxeqp/Lmi7oL9t27bpetm5c2e8DXNTWn90SOt7/7yy7KXvO8teHKn7vL4cftI53keHfFf/8Bv/4Kzb9fXqFZ/bofX//Mno4//Ndq3veLfWf3pB5TyFXGX9nb+m9Z9dpPWXfkbrz9xQ//g/c6PWf3W11trndb3j3Vr/tef/M/qIM4bnvuU8vv/T7rgWaf3vv1V7/Bd3Ouv3/8B5/McbKts9d7ez7gd/7dzuu7d632PPOcuf+krNYR++639UXo/99zsL7/sL5/HX3+c83ndP9XE/dbnW/+u/ab33u87yF/6rcoyv/2r463TvnzvbfeX/0PpTl2m985PO42JB6z85X+u7PhC4a+z3awcgY60P4BEdY15t1R/wauDb1uPfBX7XerwIp87sfvdvGqeb2Xafbb8NvDrqnI3M2Vpr/fa/+Jbe8Wc7G9p3rjny6beV58Uyt79F6394W/TO4yecueGuX3cev3SfOw/d4zz+0wsr677xQWf+COJhd54bO1y9/Jmvaf3RIef6YrPzj53tSyVrPMedZXe+370W3VlZ9xdXaP3V26qPcce7neuOzYs7nX1vf6sz1/vx8kPONp+63Hf1zp07tf7mbzrbfO8T/sfQ2j3HkNYHHqhdd3R35f6p/ZX5+xMrtP6jNdXbfuFNWv/Trc79733C2W7nJ2uP+fi/OutO7qse6zxBxlofYXN2nOoWCvgfwG6t9acCNrsL+AW3ysX1wJjW+hV3gv1RpdSwUmoY+FF3Wfsw37ALucqygmvJS/U05xwq/GU130zRnmZuuhS5b/n4ugTFfGWZfV8XQSWd7VyluS5y41DK+6/TGpTyDqj6odk31QMln3wf87zNc02kKtuZ22TGfewZv1mfSNYe1n7tzBgDx+omrJrXyhyvYNkz/cbu9zwSaWdb+3klks6xBWHueRi4SCm1SSmVAd6JM0cDoLUe01ov01pv1FpvBB4EbtFaP+Ju906lVFYptQmn8c4PWzXQVEKRK8yXppaJ2s90MR9vzjZKWdb99Svj/oKYm3BuS3lnHgFn7isGzL9QuXZZajEAaUdhTZRmqpeX5yVrLjRjLrrzq6VIO/OxZ971uzaZfQpTkEz7j9XM4z7zdeU47joVso0Ze8+i2nUrLq3ct1+TFVsgP1W9balgjcVzLbDpcxXtyVPBYxK6gjga943AzwNvUEo94f69VSn1XqXUe91t7gb24SR5fAH4VQCt9Smc5JCH3b+Pu8vah1LOB9cOhgrupOKddBo+R9TL6n44Zxsk2xNZ1f2SMxHYwWc95MZD9tPUBMVV66hM8Oke/yC9JkhOVrYz68pBchFmxuHO98HU6cpFymdCrQqSy2P0jNVMtqaqS6noXMDM8exJNeoLRsmMNe2MSxed8ynlHK80Xy7+wkJCa10A3o8jSOwG7tBa71JKfVwpdUvEvruAO4Bngf8A3qdbWNkinYBccX58TrRK1H6mcxOVwDcMM79k3SAvM1DZH5x5yASayTQUcwRSdK9XZo40pB1bWrLoEyQHXVfMeaqC5KS/OFETJLvjzU9V7nspB8lhzk4jaIRc+0xg6xck29jX8FVXOHNy0XouulgZi/daYFMOkk+Gn09Y8ER6krXW3yc4KjLbaOB9AetuB25vaHStIpmtnoTmXEkO+HDWFSRrJxhN9TjjL3kmAqNmNqQkT0Am4F/upyR7H5tzpnr81dSSj5JsttNW4GmO9coT8Pi/wOZbYcD1yfkqE81Qkq0LTNRrZ4/VKMnmOKIkC21Ea303jnhhL/tIwLY7PI//CPijlg3OIplg3ijJ2ogTNtNj0YEbOEHxq34BLnqT+9goyePObTFfCd5S2Uog7EeQkpxxlORYQbJ5bH71s+dTez4uH0PXChNmvPkpSAaEEmaMoUGyOV7Itc+MN+q1TrrnS/fDkvOd+4VpSLpfSkpF63mEKclLnFsJkrue2Il7C4pUtjoYmnMlOcRuEcfArpSrJOedScMbJJeKFSW53kCtVIT8ZMgXhhAlWVtKskpUbAg123mCZJWsbGfGaxQIXYS8+yWmONMiJTlZOV6hDiW5rBy7AbGttqhEYyr+AiCfzzM6Osr09HT0xk1m0aJF7N69e07O1dPTw7p160inA1Q0IZL0PAqSQdXOpzNnITsUvWsiAbf8TeWxr93CvRwnM+78XvQXA4ozzli8gWeo3SJgHvS1WyRr5y5dqhUcklaQPCsl2YwpLEh2r2fpiMR6cw1fekFl28I0ZE2QbNktREkuI3N2MBIkQxuV5FnYLUoFZ/tUL3DaR0lO+k92Udg///kOPsyTbAJP11+XCAgUa+wW1nZmwrI9yWZdYaaiQrfKk5y3PckRF2+jHCdca4UuVYLtLlaSR0dHGRwcZOPGjaia17+1nDt3jsHBGD9/zxKtNSdPnmR0dJRNmzZF7yD4kkoo8sX58TnRyjOflopOkBxHSfaStoJkrZ15zrZbgPNrZ6K3dt/CjHMN8362ynYLT6Cjtc91xQTJPnYL5fMLZJQnOSh4jeNJts8buC7hvM5R84kRPJZdbOUfefJMys814DoMzhefRKprgmSZs4OZHzVCmk0yU/1zVtOV5Kg3WRMS98yY025gX6Mkp/wnuyjMz39BiXvOADwPPY+LBec1DlKy/RL3auwWVpBsfMLFnKUk175ODSnJWlcCXahPSTbKsVGS7f+f94LaRUxPT7N06dI5n2znEqUUS5cubYvyspBIJaBQ0pRK4Z1fOwHHbmF9pmfcSqiNBMnJlCPK2PkfduIeBPuSi7mKrcDGDbx9leRIu4U3cc+rJId5kqeDleJUDCW5LGhEeJLjvs6X/QRsuaX8paHGQldWkgOuw2ZMvUu6JkiWOTuY7gySUz1tVZLLeD+cfskRQcc3E6j5Bm9nQ9t2i3oDtRkTJAcEiL5KsrUO3Ek8JEj3Brr2djXVLYqVwLUwE1rdoiogLsfIUaq3FehCfYl7Rjk2Srj982gjVpcFxEKebA3d8BxbTcqdAuZD8p72Wqimx5zbnhh2Cz8y/Y6SbALVpGW3gIr3uFSCr70XDrpFRgozleDTpp7EvVC7RUB1C++cax4XZ4KDYBPMx1KSQ65966+FC94YfQyAn7odttxaEb3sOd0vcc/PkwyO5aJLgmTojvmskefYpUFypq2e5EoJOL/EvZiTSXnMRkm2Ju/ZJO7ZiSS++HmSfUrAJdLBQbr2WCbs7WoS94oBSvJsPclmJ+u1As9Pc3GCZK+SrCrPTapbtIUzZ87wmc98pu793vrWt3LmzJkWjEgIIp1wPi/zIUh2SsBZc/b0LJRkqATJRY+a61WSxw7Ck1+CF/+rstxXSXaC5ETJo0D72S3KJeCM3cJO3AvyJHuOYZd9iywBF8eTHBLA3PRBeNufRx/Dxlwbq5RkK3Hv/Nc7txf+iP/+fUudikpCy+nkObtLg+Qej91i2g3qYgSocZiLEnBlJdn9SSkwca/Oi48JktH+QZ7WgXl75ciz6PrrGvIk+9ktJp37EUqytgPnuJ5kb+Jevs46yWVPcrHibzbPrYuV5HYSNOEWCuFfeu6++24WL17cqmEJPiTdj+N8SN7TypO4V1aSGw2SB1y7hVFzA+wWp150bk2+SJCSnEhCMuvjSfa7rrgvvK/dwiefIsyTbI/dSzJVLUKE4ZdANxvKQbJH+DBjWbcNPjYGG2/037+ve+wW7aaT5+zuTNxLZjzNRGaaZ7WAWSTu+SVYBBzffPDLQXKTmomYiRgC9vVRkmtKwOUrnmhfT7I7Gfp6kn2aiZjAtRBe3aJ6XHE9yd4ScK5qnUjH9CRb1S28JeC61JPcbj784Q/z4osvsnXrVtLpND09PQwPD/Pcc8/x/PPP8xM/8RMcPHiQ6elpPvCBD3DbbbcBsHHjRh555BHGx8d5y1vewk033cT999/P2rVrufPOO+nt9UmiEmZF2tgt5kWQHGS3mIWSPGMFyWW7hUncc+f0k54guTjjryQDZPoC7Bae7cp2iwBPck0TjoggOagEHDhjjVMnudmUg2TbQleMp2pD19kt2kknz9ndGSSnstWddApTlQS4ZtBwCbg6PMnlWplBiXuz9CSDf/JeLE9y3lWSI+wWVR33vM1ErDrJRkkuNrm6hdaVwNbsawLydF+0Elz2JCcrY/XzWXcxf/CNXTx7+GxTj7llzRAfvfmywPWf/OQneeaZZ3jiiScYGRnhbW97G88880w5o/n2229nyZIlTE1Ncc011/CTP/mTLF26tOoYe/fu5Utf+hJf+MIXePvb385Xv/pVfu7nfq6pz0OoeJLz88Zu4ZO4F6cEnB/ZIZg+YwWq7pxngu7JE8DFtUFyIeevJAOk+2oT9wizWwQl7sXxJMdQkqGSxB1Js5VkU90iIHEvir6lTpxQilmadYEgc3Y13fOft0n1eJqJdIqSHLdOcqJiFykrybYn2QRvPpNdFDk7SI6pJAeWgAsIFM1Yy/5dvyA5U3lc8FOS41a3CBqqtoJ1n7bUQd0Cq07oSfor5pEScJ3HtddeW1Xy56//+q+56qqruP766zl48CB79+6t2WfTpk1s3boVgG3btrF///65Gm5XkTKe5G5Uko1S6bU8rHSDiSPPOLcnX3Buy/kiIUpyurdBu4VtVYvpSa5SkkOC5FTcILnJlKtbWK+HLtWnJOsizIw1f2xCKJ00Z3enklzTlnq6eUl7UIeS3GjHPWWVgHMnAt/qFsYGEKL+erGD5KJPkBin416x4Pz8FuSJtoNTqFacS35KspW4F1rdwkdJrnlsBfTlYyWsmp+WjSWO3SKRrHyxMU1UzHOTxL1Q9WCu6O/vL98fGRnhu9/9Lg888AB9fX3s2LHDtyRQNluZD5LJJFNTUzXbCLPHKMkz8yVItuczEyQ3qiQbpdLMs2bOG1ztrDvylPPYeJLLuRm54OtVuo9E3pu4F1ICzldJ9guSfX7ltAPjsMAzmWlevk89lKtbeDzJcatPlbvunYLe4eaOrYORObuaLlWSsx3qSW4gcS/lk7inLbuF33nCaMSTXF5lKcnJTLAnusZukaxVks0E503ci13dwsUbHNueZDtY9ybupfviJe7Z+xZzlYBZlOS2MTg4yLlz53zXjY2NMTw8TF9fH8899xwPPvjgHI9OsDGe5HljtzA2LXCC5MxAuB83jL4ljmXDzG92abJVV8KRp50g9vQBZ3mVJznYblFfCbg67BahiXsRQXJoo5BWe5K9iXt1KMkgvuQ5oJPn7O5UklPZ2uoWzVSSIy0TTQiSvUpylSe5UEncM4/jfpOfsd6ovgFuWMc9l2KuUgKu4PXHEdOT7JO4F6EkxyoBV+VJto5V7rjnXrDSvdWvhR/m/+XnSU4k/Z+70HKWLl3KjTfeyOWXX05vby8rV64sr3vzm9/MZz/7WTZv3swll1zC9ddf38aRCvPObgHOHJRMOSXgGrVaQEWpnDjm3NrK7Kor4KHPOlYLM09VeZKD7RaJkqdsWVhb6qDqFvV6ksPsFjd9EBatC15fPkerqlt4SsDFDpKNkixBcqvp5Dm7O4PkZNZjt+gQJbmeZiJm4jTNRIIS98zjuOQiEvfClOSaEnBB1S08vuKqINlUt7DrJBslebrWqlFFjMQ9W0kuWeMwxys3lumNrpFpPOS2klwuASdKcjv54he/6Ls8m83yrW99y3ed8bAtW7aMZ555prz8t37rt5o+PsFh3jUTAfdznXKS7mYVJLtK5bmjzq0dvK260plP9tztPB7e6PEkhynJcTzJAMpSku06yT6NkILUaDPPhSXubXt38LpW4q1uoXXlV9Y4lJXkU+HbCU2hU+fsLrVbeEvAzbUnOaDTj9bhP0v5Hd+vLbW3rFk9yXtVdouA8m1hgSdUl4ALs1uENRNJ+DQTiayT3KCSbLrmgSdxLyLINV9qEnaQbFtIJEgWhDDmU3WLKiUZHLtFo35kqARh40ecWzvQXH2lc7vra87tqis9dZLrKQGH/zVJqRC7hWfu8isBBxUxo1HLSSvxVrcoX1vEbiHEp0uDZLeZiAnqCtNzrCQHlYCrw25h8C0BV/IoyXUEyXYJON+uezE67lWVgAtoSAJWkpvlXbYDaBNkF/w67oX5j6kN5L3LtdUsxa+ZSLq3Dk+ySYKxbC2iJAtCJOl5ZLeoscnNzNJu0ev+nD9u7BZW8Lb0QufXrCNPO+dYvAFyphRmlN0ihicZqnNb7MDRL5ck6BhmvzAluV0o5VwfjchinlPcxL3MgKPYS5Dc1XRnkJzMOh9686EJ+2beCLPquBcjicFWm43douhtJmJVbKgrcS+iBFxopQyjJBdcT3LcxD3LbmFbIMzymEpyNUFj9FOS7bbU7rnSffFLwJUVe6u6hbSlFoRITMe9+VHdwv2ca0tJbobdYtzYLexqEclKKbilFzqNR/ITzpxSmA4pAReUuOc3H1odBKOU5KggOcyTHJsme5LBTdJ3X49yZ8OYSrJS0lBE6NIg2fszTMcoyXE9ydaEV7ZbWJNaudWylbgXl0bqJNeUgMtbJeB81FTfOsnGbmFUZtPu2VMCLrTjXsiYvMttT7KtuufrKAFXbkTiUydZ2lILQiSV6hYtCJCajK/dohmJe36eZHCS9wCWXOAEyeDkZ0SVgCvNwOn98KktcOjRcCXZ0Eh1C3u/dpR4i0Oqt2KhK/l8IYiid4l4kruc7g6SzU9NnaQkx5lsquwWQSXgUg0m7k04PzN5j1k+doyOe+UScAG+3LA6ybbKbOost0xJ9ikBV5hyzp3MxquTXOVJzleXgBNPsiCEUk7cmwdKMnanVK3d6haz8CSnspAZrHiSvb5e40s2SjI483NE4l5CF+GBT8PZQ3D8+WAl2S6PaVdkilsnGTrbbgGukmyCZKMk1xHQ9y0RJbnL6c4g2Uww5U5uc60kexLdyisa8CSXS8DZzUQKjSfuzYxDz+KI/WJ4ksM67oXWSbZUZl8lOay6hT2kGEqyXwk4qIw9yqZiEi3NWEreZiLSlloQwqiUgOv8L5TlebtUdIJVXZydkgzQN1zxJHsDzTVXO7fLL4G0CZLHnXklxJMMwGP/07nNT4ZXt4BaZTWouoVfcFlO3JtFkNyqOsngXNfNdb7exD1wmohEVTkSFjTdGSR76yfm5zZIrlIkbGYVJIck7tXzs39uAnrdINkvcS9O974qu0VYx72AOskq4QbJKedYxidcmG6uklyyrBtKVdaZDlGxPMnKU93CUsfFbjEvGBgYaPcQupbUfLRb6NLsW1Ib+pZWLG7eQHPN1fCeu2HzzRUl2fz0H6gkm1bM7pyZnwR0uN2iJkj2mfvy0/7nLFcoaoKS3Ow6yeDYEb2e5LiJe+A8Z99SqEI7mcs5u0uDZPfDXsw5H8xis+skRwSRfnWSTQe4hqtbWAGZ+WmsrHDGDNa0hty5CCU5xJNcVQIu7Z8lDfGCZHDGb5ekK0RUt/AbU9Dyqo57lqINVmWOuJ5kn7bUkrgnCJEYT/J8qJNcETeKs29JbTDJe+CvcG680ZlLTJA85QbJgSXg3O1WXu7c5qdCPMkhSnKVfU/DxHHoX157jEQHl4AD/+oW9SjJYpvrejr0nd1iTGZwYbryLbOZnuRYqNogGRpQkn2qW5SbidRptzATqlGSS27RfButqe0o6LVbuM1EdCnAk+zXTKRYOae93E4kLNbjSS6fLHis3mOpJFBwleQYQbKvJ1kS99rNhz/8YdavX8/73vc+AD72sY+RSqXYuXMnp0+fJp/P84d/+IfceuutbR6pML+qW1iJezNnnfvNUJINYcGbyRMxP/0HKckmSL7+V+CbH3RtIRGJe9651JtLMnXaET4GVlJDx3uSbSW5gcQ9lWiNwi1U0clzdncGyWW7Rc7qsNZEJTkO3g+fX3vQsH0Noc1E6kzcM6ptWUnOU/sWCZswPM1EEoXg5D+wfqpLepRka7lpDW0mu0arW3g78NmeZPtiUaSiJOuSa10J+OJiXueqjnuSuFfFtz7s1HptJquugLd8MnD1O97xDn7jN36jPOHecccdfPvb3+bXf/3XGRoa4sSJE1x//fXccsstqFb6IYVIlFJkkol5kbhX1XGvbLdYPLuDmlrJEO7rzbhiyGSEknzBG9h74W1cdMXb4dv/tyt8BNgtwjzJ6MrcZzzTAytqD2EU5FmVgGuxJ9n8rxpJ3OvGevcyZ1fRpUGylbjXLiVZJaqVZFNpI0gh8O5rSPkl7jWoJOfcgLQ3xG4R1nHPYJqJlAr+E0xcu0UiVQmSe4edya5ZnmRb5a5SknHGXlUTNShILlUryaVCtVWk2ybXDuHqq6/m2LFjHD58mOPHjzM8PMyqVav44Ac/yL333ksikeDQoUMcPXqUVatWtXu4Xc9AT4rxmfng+zRKsu1JbqbdIixI9tgtguokZ/o5tO5tXJTKOMl+JnHPbz40i/w8yeDWu8/AREiQ3NQScK2qkzyLxL1EQsSOOaCT52RWo3oAACAASURBVOzuDJLNBFOcabOSbAfJ7kUiTrDuqyTbnuRSdQm4uMGaV0mO3XHPrNJu/WHjSc4FdNwzQbJdJzkgSDZ2i57FjqIRt7qFPSYbZSXueVXpsic5Y10oisEqScnrSRYluYYQ9aCV/PRP/zT/9m//xpEjR3jHO97Bv/7rv3L8+HEeffRR0uk0GzduZHp6ui1jE6pZ3Jfm9GTnB8mtSdyzlOQ4douykhxDTEn3WtUt/ILkkMQ9qMyPZSXZz26Rrr5thHKA3QKFMN1bWwKunsS9bhQ7ZM6uojuD5HIzkVwHKskxJht7wktmaxPkjFe23sQ905LaTPy+fuKIjntmn2QGElP+arTtO4ZKJQiTTGfXGp60Lka6aLVRrbcEnOexnbiX8AbJacuqEqLC+zUTqWpL3fk/IS9U3vGOd/DLv/zLnDhxgnvuuYc77riDFStWkE6n2blzJwcOHGj3EAWXJX0ZTk/k2j2MSHztFrNO3LPtFmFBslGSjSc5xvUq3RfTbuGZS71znwmSfRP3mmC3uOmDzvO69pcbP0YQs+m4ByJ2zCGdOmd3eZA83TlKsvkg12u3MAFd0VMnucpuUaeS3DtcOU4NER33ysF+SMc923cM1d7pqsQ9y5NsLCD5Kef8kb6kiOoWxnMHlbEoW0mOEyQXQaUtz7IWJblDuOyyyzh37hxr165l9erV/OzP/iw333wzV1xxBdu3b+fSSy9t9xAFl+H+DAdPTbZ7GJFUJe5NjznXjPQsrxtx7RapXkBZ1S1iXCcyfY6SbCoNeQlUkr1B8lHnGOa6YGMC+9koyT2L4Oa/anz/MKqqW9Sb9E13KsltolPn7O4Okou2ktzmxD0T5MZRCGzfq6kn7Ju4N1tPcp11ko3VAtyJOaSZSJWSbI3Ta7fIeywg+cl4k1xgCTijBtnNRDxZ3ok0sZIevUoyWAG3VLdoN08/XUk+WbZsGQ888IDvduPj477LhblhuC/N06Odb7eo5DO4QfJsVWSoDpLD1NhEwlGGJyM8yTbpXshNQnawvhJw3l8gJ447fmS/ObWsJHdoKCHVLeYVnThnd2ed5HIJONuTPJ/sFu6/zajOiXR1MFdO3IuhhtrUVLeIqSTbj4vuPnaFiKjOgrYHrqq6hTWZGQtIfiqmH7meZiLWl47y2GN8wfCWgLOfi13WThCEQIb7M5yazKE7PBipKQE3Wz8yxC8BB47lwtgt4lyvynaLAE9yYHULT5A8ftQ/ac/et6NLwE27Ak4D1S3kF8GupzuD5JQdJLdLScYTJDdgtzABdSJZUXC1xvnZv4GOe8aTXO64F7O6RWVldSm7cvAb0VnQDuZ1sTZotcc0ayXZrwScCWytLx9xgmQT0FcpyT6ttgVBCGRJX4ZcocRkrrODEV2ueKMdJbkZQbIpAVfu+hmCHSTHuU6k+5xf4uqtk+znSe4PCpKb0Ja6laSygHYbh8UsH2ojvwh2Pd0dJBdnKu07264kG7tFHUFy+Vu8ZbewfVf1Ju4Zu0U5ca8RT7J5HpYPznucwCC5SI3dwmDU7dxk85XkmhJwmXhfMLSPklwV4Gv5qU4QIhjuc+a8Ux2fvOdJ3Jtt+TdwvMWZwXhBZmagUu0nlpLc22DHPY9AMH4sREn2+dWvkyi36Z6WxD2hIbozSLbtFpMnnft2lvFcoBJU1YU0dos4CRleJdnUJIbqBhmNJO4lM5UufnHrJNvrbE9ykK/XrmABHk+yrq02AdWJe0HNPWwaUpKtTO1YiXvax5PsUWe6dILt9J/Om0E3PMe5YLjfmfPOdHgZuJrEvWYoyeBce+LYFUxDEYgnpmTcOsnQWOKeLjrJzRPH/cu/gfVrZocGyebLRH5aEvci6Ib5rJHnGBltKKVuV0odU0o9E7D+t5VST7h/zyilikqpJe66/Uqpp911j9Q9ulZhPtiFGTh72JksgiaBVtGMZiIJy25R9CrJqVpFIIqZcWdiLQeIceskW+pslSc54PxhdotS0V/hKHuSm6gkxyoBFzJBmrH6Bfx2uaguo6enh5MnTy7oSVdrzcmTJ+npmWObVkyUUm9WSu1RSr2glPqwz/r3WnPz95VSW9zlG5VSU9ac/tlWj3VJvzOPnZrsbCVZK0/iXtOC5KXxAjdTBg7iK8m5yWAlObTjHs78NnXKeb5RnuSOtVvYSnIDiXuJpH9ezQJD5uxg4rxb/hH4W+CfA078Z8CfASilbgY+qLU+ZW3yeq31ibpG1WqUcjzIRVdJ7l8x9x/ymhJwDdRJtsvveJXkRhP3MoPhAWJUxz07ATHIshDqSS7VqrGJdEXdzk81z5McWgKuCZ5k6Eoled26dYyOjnL8+PE5P/f09PScBa49PT2sW7duTs5VD0qpJPBp4EeAUeBhpdRdWutnrc2+qLX+rLv9LcCngDe7617UWm+dq/Eudu0WnV8r2f1s56cddXVwdXMO27cExg5Gb2cHyXHrJJfyjhhkq9CGshjh9SRbc9/4Ued+YJDchGYircTOP2qoLbVVDWkBI3N2MJFBstb6XqXUxpjHexfwpbpG0C6SbpHxs6/A0Jq5P/9slGQ7eASPJ9l0FbKCt7hNLXLnIDtQOX4x7/NbQ0THPW8JOKjtuufXTMSM3a+6RbrP+tmsXiXZO7n5dNwrl4CzbCyx6yR7PcmegLsLleR0Os2mTZvacu6RkRGuvvrqtpy7g7gWeEFrvQ9AKfVl4FagHCRrrc9a2/dT+0GZM5aYILnjlWR3fhh72bldtL45B+5fHi9x3HTdg/jVLcAVP/pr18cpATfhBk2BiXtGWOhUu4X7uhamGkzc6455XObsYJr2zlZK9eEoEe+3FmvgO0opDXxOa/35kP1vA24DWLlyJSMjI3Wdf3x8vK59bijBiZdfYtHYXib71rCrzvNFceXwVYwtupwDPscdHx9nOpfj9OHD7HHXrzj6BFuAHz76JJP9J0OPvengKOcB49M5HhkZYfvUNFPHXmHXyAjp3FluBPa+uI9Tpx/lOmD3rqc5enJZ9JiPHCRZLPL4PffwWpXk4P59jK+4qup13X5unOn8SZ6xlmWnj/Nq4Lk9e5g8OMmrgKd27aZn+hgXA/d//15y2Uoh+osPH2JpvsAD5ef+PFuAhx68n01HX2Fgapofjoxw2cnTLAdmdIJnnnyGbUBuYoxSIsmDAa+r4QcPPEA+s5g1h/ZyMXDolVfYOzJCZuYUNwDP79lDLnOMy4FHHn2c8efH2DY+ySBw6MhxTuWe5QrgkYcfYnzQ//9x7eQE546f4OVHHuMad9mRo8d4bmSEdQdf4kLg+/feQyE9ULNvve/XdiJjnXesBWxpchS4zruRUup9wIeADPAGa9UmpdTjwFng97XW9/mdZLZzNjj/r8d/+AMU8Pize9mU79xOiOlppwLRy0/exwbgif0nOTM2Muvj9mZfQ3bjZs5EvH4XHT/DWvf+Pfc/hA5Qb81nYM2hg1wMTJ89yWQhy1Oe4183PUMvcPLMWZ621i09sbs89/VPHGQz8NCz+5naX2u/u+jIMdYCTzy1izMH609xavXndfjU81wFPPbDB8jkTnE58PBjTzDx/JlY+284cIDzgXtHdjI+lZs3c8t8mgc7fazN/Pp3M/ADj9XiJq31IaXUCuA/lVLPaa3v9dvZDaA/D7B9+3a9Y8eOuk4+MjJCXfs8PsSalcvg1Bj957+lvn3jsONelgB+381GRkbo6elj9aqVrDbnfeIV2A3XvvpGWBLxja54L7wMA4OLnHHvWczA4LBzf/wY3A8XXXwJXHQD/BA2X3Ixm6/eET3mFzKQcY/z/QznrVvNS5mB6tdmdz8Di5dXLztzEB6ESy+5GJZeCI/DlVtfBWcOwF644dXXVav1Y/8G472VY+w6Dbvhuu3bYPw7oE84647/I5yAbP8itl17AzwGGVWEniHf/5f9QbvxhhthYDk8/ALshbVr1rB2xw44dxQegIsvvshRcHbB9muuhVWXw97FMA5r129k7QVXwzOw/eqrYd02/9friQx9q1az8rrrwXXcr1qzhlU7dsBDe+BFuOnGG3yTQut+v7YRGevCRGv9aeDTSqmfAX4feDfwCrBBa31SKbUN+LpS6jKP8mz2n9WcDZX/1+L7vsPQ8tXs2HHFLJ5Ra3nszj0AbBh0VMWtr7s5eq5uJrnvweFvAfC6178p0FJW/gw8eQT2Qk+iQM+SpbWfiyf7YBqWLltRve75nDv3bYWXJ+E5uO4NP+7vwZ76FhyGrduugQ3X1/2UWv553Z+Cp+BVV26BiROwC6659jpYsTne/t9/Al6C177mRkbuf3jezC3zaR7s9LE2s7rFO/FYLbTWh9zbY8DXcH4G7AySGcePPDPWJruFamKd5IAScHUn7p2r/CwX1Awj0pNsl4ALStzT4XYLb0m2VK9lt5hoXnWLwBJwMZuJhHmS7Ux4QZhbDgG2F2CduyyILwM/AaC1ntFan3TvPwq8CFzconGWGe7PcHpinlS3OL0fUDC0Nmzz5mPsFslMdE1lqJQ/y01ElIDzepKtpOPxo45lIai7oF2GtBMxdov8LBL3QObxLqYpQbJSahHwOuBOa1m/UmrQ3Ad+FPCtkNEWUj1w6iXn/lxPdgB4g2T3AhHHa1ZT3SJV2d/2XdXTTKQwAydfgKUXuMcMaoYRYl2MXQIuxJNc8qmTnO6tfHmwPctxqEm4sC4u2pO4V87UzsT0JLul7OygvXys7vCyCR3Jw8BFSqlNSqkMjoBxl72BUuoi6+HbgL3u8uVu4h9KqfOBi4B9rR7wkr7M/PEkn97vJO3FKdfZTIyAESdpDyqe5OJMYyXgSgUYP+74kYOC8vkSJFfVSRZPshCfyHe2UupLwA5gmVJqFPgokAYw2dHA/wZ8R2s9Ye26Eviacj5cKZxs6v9o3tBnSSoDR19w7rctcc+nTnJdbamtzGITiNrflu0EjDMvw+P/Ajt+13/CO/asE+Cuubpy7KKPsuNbJ9mvBFxEx72EX5Bsmol4EkrsxD2IOckFjDFMSS4nocQMkk0Coh20e1VpUSCEOUZrXVBKvR/4NpAEbtda71JKfRx4RGt9F/B+pdSbgDxwGsdqAfBa4ONKqTxQAt7rsdC1hMV9GUZPT7b6NLOiHCRPj8HyS+d+ACZIjhucp62KFnW1pbaD5JCW1Pa2HVsCzgTJM4133IMFX91CCCZOdYt3xdjmH3FKxdnL9gFXNTqwlpPMViwOQ00q5VMPNSXgGrBblL/FJyv76wC7xe5vwD1/Alf/PCz2yco+/Lhza4Jk28JRRUTHvZLVOTB2nWS7mUipVo1N91S/LnEmucCfI33qJHstErGrW7hj9eu4V6/VRRCaiNb6buBuz7KPWPc/ELDfV4GvtnZ0tSzpT/P0oc5Wkqt+eG1WZYt6qFtJ7q3cr6fjnm2TmzgOi88LPkdyvpSAm7Lq4ovdQohPd3bcg2plcrATSsDV05ba1Em2Pcnu/iXbbmF9wKfdvJuZmvwbh8OPQ+9wZUK0ay/bRHXcM4p4VQm4uHWSi9VWDNtuUbeSHIBfxz3fZiIxyudpHyVZSsAJQt0M92c4PZnv6GYG2p73/ISGVlOvkmyXfWvIblFyleTlwefo9BJw5bbUMw123OveplCCgwTJfUsdpXKu8auT7FUlw/aFyrd3uy11eSJIVKuhJjieHvM/5uHHHRXZTuaIqyTbj+N03PPWSVYeJdkbtKb7qtUT3+5R3iFFJbbo6i8U9m09zUQSUUpyzBrVgtDFDPdlyBVKTOY6NxjR9ryzeMPcD2BWSnKY3SKgmcjpl5yKEGEi0rxpJiKJe0JjdG+QbBTbdviRwT9IjqMim33B6rhnVaIIStwLC5LzU3Bsd8VqAdWBt02YkoyduJcKThyM3XHPXZ7qcZ6r14YRSozqFqFKchxPcsnHk+yxbogCIQiRmIYipzq66571OV/UjiDZrW7RkCe5HiXZfZ4jf+wE2lt/JvgcHe9Jdr8o5CVxT2iM7g2SjaG/LZUtaE6QXP4Wn6zYNeyflGy7w3RIkHx0lzOB2EGyXTGjihBPstYBJeD8gmQ7sLTsFrbKbCvJUFEFmuVJDlWS6/Ek26q458IjCoQgRDLc3/ld96qV5DbYLcw8WG91C6jPk2weT56E1/xm+HPNDjpzoK1adxJGXClMN5a4J0py19OhRqI5wARcbVWSPdUt4ioEZSXZ3d72D1cpyZZloKwk+3iSTdLe6q2VZYlk/DrJdtBc/raeDp5gauok23YLXVuSzdhhkhmnLXXTlGRP4l7Cel3jBLm66BzPz5MsJeAEITbDfc4X/tOTnVsrucqTvGjd3A+g7EmOGSRXtbpuoLrFkgvghl8LP8cVPw0rtvg3GukUUj2eEnB1hD3lXwTFNtetdK+S3Ha7hbdO8mztFsaTbDJ4k24Al4hWkg8/AX3Lqif+RLpinajCz5NsrSsryangQNEu82bGD5bdwpRrmyMlOeFRfxOpymvcqCdZSsAJQmzKSnJH2y3cz3bf0uqkuLnCbiYSh0SiYjeop5nI0BpYdSXc/JfRAXmmD9ZfE2887SLd4/EkN2K3kCC5W+liJdn9lt2OyhbgEyTn4/u6/JqJeJXkRLJ6XVlJ9ulZ703a8x7TJqrjXlUJuADLQlgzEV0Ela5ebn7KMz8zNktJxtNMxNduERLkhtVJFiVZEGIzHzzJZbtFO8q/Qf1KMjhBbGGqPrtFdhDee19jY+xEUt4guZ7EPemc2u10r5KcareSnKCqe11hpgEl2VS38GlLbQd+OkJJPvE8rNxSvSyZDpgYQpTkekrA2YGut5lIwmO3MF9oykpyA9Utyo/tOsmzbCYSVie5/NxFgRCEKIZ60ygFZ+aDJ7kdfmRw5j+VjH+dgMqvcPUk7i00UtnqxL041w+DJO51PV0cJHda4l4+fkJGTTMRK8nOm8FrKl8EVbcoFhz1NzNYvdxOBrSJ8iT7loCLqm5heZLjJO41S0kOTNyL20wkpE6yUSBkchWESJIJxeLeNKfmQ5DcjsoW4Mxdmf76lOSwIDnIk7zQSPVWPMkqGaM8qIUk7nU93RskZ4ecyaGjSsDFtVv4NRPxKQEHzoc8P+VMElAbJJvl3om3no57NqV8ZSIK9STHKQFngmRjt8hUP7cwYnXc8yrJfh33AiZH2/td1WJbPMmC0AjD/ZmOtluUElnnurG6jY1k+5dD75L426cb8CQvNFJZyE3Ac9+EZRfXt68oyV3PAv8KGcKrfh7WXQPZgfacvyZIbsBu4edJ9iYnJJIwdaqyb02Q7LazTnkaqgQl7mmCrQymBJwJ3oMCRW8zkZog2Vvdwp3om6oklyqBbiPNRGpaWic93QKlLbUg1MPKwR6OjE23exiBlJJZ+NCzlQS6dvBzX62vkkRZSfZZ1y12i3Qv7L/PmYvf8S/17StNobqe7lWSexbBhuvad35fu0WdiXt+bam1J/BLpGDqtNmxTiU5rifZUwIu4Um8q0nc09VqcFQzkUaU5ED8mol4AtuwboHl52AUe0/zEG+ALwqEIMRi3XAvo6en2j2McLKD9f1c32yWbIK+OpTkjNgtSGWdeXzdNXDpj9e3r5SA63q6N0huN751kuN6kj2BmK+SbAVtJkgeXB0SJHuU5GSA3SKq414xb5Wmi1sCzlKc7XWBnuQ6Evfs19hebkrA+SnaduJeUJCrLbuFfSuJe4LQEGuHezl2boaZgnyxbBqhdosuUZLNte1NH6v/C450Tu16JEhuF01pS52u3Br7QFkdtQLoKbfs2+L1TpCsPVU1wF9JrrfjHjiKdiLCbhHkSdZxq1s0YrfwVLfQ7vn8ku7iVLcoeZVkT7AsiXuCUBdrFzsB3StnOtdyMe9Iu2XjutmTfMlb4Pr3wcab6t9XEve6ngX+FbLDsYPkQj2Jez5tqaFSHQKqqyyMH3fuL1oPBx9ykhiMFztISba7+FWNWQfn7WntVLcodwKcZXULbzOReuokBykGtpJcU4rOCs6jEu9qbC1BSrJMroIQh3XDzud89PQUG5e1oVnHQiRMSe4Wu8WrfqHxfSVxr+sRJbld+CrJdZaAszvuQaUZB1QHfPkJ577pqDdjtaYOU5Lrrm7h1kmOtFtEJe656867wWl7unhD9RgbUpI9y00JuCol2W5LnXAe1+1J9vyEKYl7ghCLdcNOQHfozGSbR7KAMAKD33zYLXaL2SBKctcjQXK7qPEk52dR3cK99VWSrQnQFMG3fcmBSnKy8Y57kYl7Ec1EzNiXXgA/+feVxi9ehTqM2SjJ5fMEfVGg8r8L8iQbBacgPx0LQhxWLeohoeBQpyfvzSfCEveCOu4JFURJ7nokSG4XviXgZlEnGaqD5HLQZgWBpgh+VZAcoCQnA+wWkR33YpSA89otzP1yW+qAt2U9HfdiK8n2OKzqFuZxo55ko+DkJir7jB2qdD4UBKGKdDLBqqEeRs9IkNw0YtVJliA5kHLing7fTliwSJDcLpqRuOfnSfbaAMy6VC/0L3Xux1KSU5XueTZRHfdKheqkQbOs6hjeIFlVVFutg4Pgcgm4BtpS1yx3S8BFKskB1Sm8dZKDlOS8dcH/51vhnj+JHrsgdClr50MZuPlErI57CzxxbzaYBGyxW3QtEiS3C786yal6q1uYkmU+dguvDaBnCLJuEfo4SnLDnmRLSS57kj2BZqlUO2mXg+RScIk3E8iHTeqmG5YdDNt421LbSnu6z/niYds6YnuSPcp9xk08yltK8vhRq2a1IAhe1i7uFbtFMykHyeJJbgixW3Q98uloF00pAWcpnuAEqDVtqd112aFKp6a4SrJvx706PMkq4Fu4V0kun69Ya4GwScVoJvLzX4eTL9Qurxqzoqwk2+fa9m5Yf211QmRUxz1vybeqhiSpipKstWO9EEVCEAJZN9zHN556hUKxRCopGs6sCVOSxW4RjSTudT0yC7ULO3GvVHKCsdm0pQaPkuwuU5aS3DPk3J8+UzlWYFvqBpTkcgm4GIl7NUFysra6hZc4JeD6ljiBbhhKuUqyJ3Gvd9ipqFEeU0iQHORJtsee7oecm6lfzLl1oGWyFYQg1g73UixpjpyVhNemkAlRkrulBNxsECW565EguV0oVVEjiznntm4l2ev9LfoonJaSnMo63mRfJdkncU+Xaq0SoZ5kUwLOa7eIqySbIDkgCK6rBFwYRkkOOVd5TEF1kr2KvV+Q3At5N0g2CXzS3lQQAjENRcRy0SRiddwTT3IgoiR3PRIkt4tmBMk1SnK+onx6J0CjIvcsCvAk+5SAA1TNN+g6Ou4FKsk+lopykBxit6inBJzhgjc6t1e8vXq82iTuhXwEEomQttTurwBhSnKmrxIkm1uZbAUhkEqtZAmSm4LYLWaHVLfoeuTT0S5sT7Jp/9xoW+qwEnDmNjvo3NYEydNOgJf0vBXcQFfFUpKtdbbdolwCznuMKCW5GSXgXJZdCB8b8yx0lWRv4p6XOHYL7+tsB/Dpvoon2dgu5Gc7QQhkjSjJzSU0SJbEvUjKQbLM292KKMntQiUoV14oumpu3DrJKy+DDTfAsour96sqAee1W7hJez2Lqmv1FqZrVWRrP6W9QaKfJ9mrJBsbiFX/uOoQpVo1OJF07SI6WClO1dGWOowqJbnBILlcAs597r6e5L6KzcJUuQgqKScIAj3pJMsGslIGrlnEKgEnQXIgYrfoeuTT0S6qlGTXbuH1BQexaC38n9+qPDYf5GJIMxHbbjF5srJvYcb/vOUg2esnJlhJ9paAM8epOYZPLeQ41S2STfYkz0ZJrvky4rFdgOtJNkryRPV+giD4sm64V+wWzSIT1pZaguRIJHGv6xEluV3Mxm7hxbZbBCWUZYM8yQFKctIEyV7lM8qTXKh4ks04fEvAeY5RZbcICMKbriT7KNpVY/IZu8GbIOnrSe6vKMg58SQLQhw2LOnjpRMT0RsK0Uji3uwQJbnrkSC5XdhBcqFOu4WXhN1MxARvnsoXYYl7IUpyosYqEeVJzlf7m/3UWD+12LSADqs4kYxRJzkWtpIcpIpbYwLndbKTN7wl4Hw9yZaSnJfqFoIQh0tXD3LozBRjkz512oX6SPc71wcTLPshSnIwoiR3PRIktws/u8WslWSrmYi3uYVXSTYBX6An2STuxahuYZeAK+Wrn0ci6VNGzicQNnaLsOoWZSV5lm9bW0mOUwIuPw3/7yXwzFernwNYCnKQJ9mUgJPEPUGIw2VrnPyJXa94E26Fukll4D3/Dq/6hdp1krgXjVS36HokSG4XdjOR2dotjHJb9vRagV+NkjzkBLJG4azbkxzRca+Yr7Zb+LV2briZSDOVZOIn7k2dctpJn95fWVcOkj1fRrxBspSAE4S6uGyNM1c9e/hsxJZCLDZcB72La5eLJzkasVt0PRIkt4vZ1En2UlUCrlAd+CkfJRkqlotIT7KfkhyAn90i0JMcUgIusLqFO85meZJjJe4VYeac89j8n8DyJJuEPR9/nzQTEYS6WTaQZeVQVoLklmOCZAkDApEScF1P5KdDKXW7UuqYUuqZgPU7lFJjSqkn3L+PWOverJTao5R6QSn14WYOfP5jB8nGkzzLILno2i2qlOSoILkJSnJNCTiPklxzjIBmIiYIjayT3KyOe1FKsqtumyC5YLXKDfIkexP3ijmn6ogoycIcEjX3KqXeq5R62p2zv6+U2mKt+113vz1KqR+b25E7bFk9xC4JkluL2C2iESW564nzFfIfgTdHbHOf1nqr+/dxAKVUEvg08BZgC/AueyLuevzsFqlGg2RP4l7CJ0juqVNJDgqSfT3J1rpSobYEnF/yX02d5FTldWhmxz0/ykpyHE9yAWbci3XBR0mu8SR7lGRwAmQpASfMETHn3i9qra/QWm8F/hT4lLvvFuCdwGU48/5n3OPNKZetWcQLx8eZzsvnpWWI3SIaSdzreiKDZK31vcCpBo59LfCC1nqf1joHfBm4lx/lbQAAIABJREFUtYHjLEyamrhnvu0WfJRk00zEDZIzbue9nFFHg5TkgMS9ME9ysVC1r7MuGbPjXrKiqAcFyaYwfqOvU2VQVJTksLbUIUqyjqEkm/HmpypKstgthNYTOfdqrW2Ztp+Kj+pW4Mta6xmt9UvAC+7x5pTL1gxRLGn2HDk316fuHkRJjkaU5K6nWZ+OVyulngQOA7+ltd4FrAUOWtuMAtcFHUApdRtwG8DKlSsZGRmpawDj4+N179MuxsfHOfTKEZbnZrh/ZIQVR59kC/DQo48z1Xe87uP1TB3leuC5Z59h8NzLrCiW+IH7Wlx4+AhrVIp7f/AgAP3j+7kG2PXYQxwfTXHdudOcVWPs9rx2w6d2cRUwPXGu6nV9banI6MsH2WctU6U8rwMO7NvLecCLB17moLv+upkcZ185VHX81xTyHBodrTrGlWfOksmdZgDY99J+Xi5Vj8ewfMtvc/rMSgo+/+u474EbiwVOHNjLorEDTPes4KmAfS4/dYbszBiHnnyYS4Ejowd4zt128ekn2Qo8/uRTjB0ocvmp0ywDHn3iCc7tc5IiVx45wGbgwe/vZOPBfawCzo2d4dGRkXn3fpWxzitizb1KqfcBHwIywBusfR/07LvW7ySznbMh+P91btL5Mvm1kYc5vb7B0phNZr68t+KOc/PRY6wEvv/AgxTSQy0flx+d/pqqUoHXAS/t28f4sks7eqw2nf662nT6WJsRJD8GnKe1HldKvRX4OnBRvQfRWn8e+DzA9u3b9Y4dO+raf2RkhHr3aRcjIyOsXbsOTiedMT9+CHbDda++CYY31n/As4fhIbj04gvhlQkY66m8FpsysH8rO17nPj59AB6Byy46D67eAY8m6F27gZXe1+6lBDwFfb1ZrrbX3avYcN55bLCXFXJwL5y3bjW8DBdceAkX3OCuf3qA3hXLqo9/H2zY4DnGoRVwegIm4PwLLuT8mzzjKRO0vI73wINpVh/5HqDoe+Nvs2N7wD5H/x5OjnPpprWwB1YtH2aVOf4LRXgSrn7VNthwPRz5ApyEbdu2w9ptzjbPjsFzcP2rroCxb8BRGBzoY8eOHfPu/SpjXXhorT8NfFop9TPA7wPvrnP/Wc3ZEPz/KpU0n3joOxQGV7FjxxV1H7cVzJf3VuxxnvoiHIObXvO6ig1vjun417RUgnth08YNHGCgs8dq0fGvq0Wnj3XWQbL9s53W+m6l1GeUUsuAQ8B6a9N17jIBAuwWMdtSe7ET97wVG867wfkzZF27xcy4cxvhSa5pJhLWcc+vlF091S1MU5VWd4AaWgP9y+HWTzvlkYIwnuRp40meqayr8ST7taX2sVt4rSeC0HzqnXu/DPxdg/u2hERCsXmNJO+1FLFbRGPseKWi1ALrUmb9b1dKrVLKiZKUUte6xzwJPAxcpJTapJTK4CSD3DXb8y0YmlknuVwCrhhdsSEz4NxGepID2lKHddwrmecR0XHPt5lIMjpxr1n80vfgVx8MD5DBJ3HPL0iO4UnOTUgzEWEuiZx7lVL2r31vA/a69+8C3qmUyiqlNuH8KvjDORhzDZetGWL3K2cpFOWLZWuQxL1YKJ8KTULXEPnpUEp9Cec37mVKqVHgo0AaQGv9WeCngF9RShWAKeCdWmsNFJRS7we+DSSB212vsgAeJXm2bantOskRtX9TGScYj6kk19VxzyjiVSXgErXJaoF1kucoSM70xduuHCSHlIBLeBRkb51kcJXkier9BKFFaK19516l1MeBR7TWdwHvV0q9CcgDp3GtFu52dwDPAgXgfVq3J0K4ct0i/uEHJfYeG2fz6vZ4Zhc0oiTHI+H+GjrnNV6ETiDy06G1flfE+r8F/jZg3d3A3Y0NbYHj10zET9GNg92WuhRRsQEcNTk37lSj0MWIINmnfFuQkmyqW4SVgNMa0AF2C1MnuUNmI1OZI6yZSJjdItPv3OZtJVlUMaH1+M29WuuPWPc/ELLvHwF/1LrRxeOqdU6XuKdGz0iQ3ArMNN5qUWK+I0pyVyOfjnZRFSS7CmqiCUqytwScH9kBR0k2yqhfcJ40JeC8QV2YJ9koySEd97w2Bfs5lJuJBNVhnmNmXQLOVpLFbiEI9bBxaT+DPSmeHB1r91AWJirhzLudMt92KrY1Uug6JEhuFypBuTRpMedMVo22B7U9yaUITzI4tZJz4xWPbT1KMgR33CsnIIZ03PO2cy5vl4juuDfX1NgtfDzJ5eDYz27hKsm5yYqSLIl7ghCLREJx1brFPHnwTLuHskBRYrWIQ8In+VzoGjokGulCbE9yYWZ2DTISCSfwnTzpJu5FTHzZASfwC1OS/TzJ5W/TQYl7Ps1EEqn4SrI5V6urW8QlLEiuaUtt7BbWa2N33MtLxz1BqJcr1y1iz5Fz0nmvFSgJkmOhEjJvdzESJLeLqsS9/Oy7yC29AE6+GN1qGSqe5HKQHKYkW8qnCZIDO+75dA5UifhBsr1PJ2ACfF8l2bwWMdpST5+pfIEQRUIQYnPV+sUUSlpKwbUClegcQaKTESW5q+mQaKQL8dZJbkqQ/EJ0q2WwPMnGbhGmJBfg3BG471NUOtcGJe6ZIDmkBJxXgfWcz1nXIRN32ZPseiKLdpBsnoeqbAvVz0sppwzcxPHa/QRBiMRO3hOaTM9i6F3S7lF0PpK419VIkNwumq4kXwhjB52avJFK8mC0klxO3CvCrq/D9/4AxkbdsUc0E0nE8CTPCyXZm7hXpycZHDV54qS7Li3VLQShDlYt6mHlUFZ8ya3gNR+C93yz3aPofERJ7mo6JBrpQkwgqLWjUDZaI9mw5AInADu1L/ontFhKsnOMRKkIU6edZfkpM3j/4/om7nlLwHlKp3nO56zrkLelqd2sS26JOp86yWHVLcBJ3jNKcnZQJltBqJMr1y3mKalw0Xyyg7BoXbtH0flIdYuupkOikS6kHCSXnOCy0RrJhqUXOrdnD8X0JJ+Dghv0+nqSLSV52lVxTBmzoIpBZSXZWwLO9jXHUJI7xSdnj6lvWaVZC8SrkwyOkjx5wrmfHRQlWRDqZOv6xew7McHJ8ZnojQWh2YjdoquRILltuJGmLrl2i1kqyUvPr9yPoyTrEky5wW9UdQuzXaiSrKz22t6Oe/XaLTqkbqf9OvYvd26N+h6nTjI43f0mTJA8JEqyINTJGzevAOD/e+Rgm0cidCWJhMzbXYwEye1CWUHybEvAAfQOQ99S99gxOu6BUzIOottSe+0WQUFsyc+THGS38ByjIz3J1pj6lzm3Jnmv5ClXV/Yke+0WfY7/G6BnSBQJQaiTS1cNcdOFy/in+/eTK8gvMcIcI0pyV9Mh0UgXUuVJzkFylnYLqFguIuskDzq3RuEM8ST72i38lGSl/D3J3o57fpYM63zlfToBvyC5rCSbEnBeJdlrt+ir3M8MiCIhCA3wi6/ZxNGzM/z704fbPRSh25DEva5GguR2UeVJboLdApzkPYjRcc/tBGe8sn5KsltovkpJNolrQUqyr93CoyQbVdUE6vZ25XN3yNtS+dkt3NfAa7fwepMNplYyiCdZEBrkdRct58IVA/z9fS+hJYlKmEtESe5qOiQa6UK8iXuztVuAUysZ4iXuQbjdAiCR9niSQ5RkLCW5pgScFRjOmCB5yHOuDgySqxL3XCtLwX2OXm+1+WLi/YJivpCAGyTLZCsI9ZJIKH7xpk3sOnyWJ6QcnDCXqER18rnQVXRINNKFtCRINnaLqMS9GHYLcJXkQjxPsgpI3PN23JtxO2dlB2rOVbnfKXaLECXZ60nuW+LUn/baSLxKMsiEKwgN8PpLnAQ+qZkszCmJhPwC2MVI4/Z2UVMCrplKchMS9wCSKVKFyUpCXqiSjL/f2Gu3MI05auwWHVon2WCC5KJXSXbHffUvwMVvrrXNeD3JIGqyIDTAyqEsw31pnjtyrt1DEboJsVt0NR0SjXQhrVCSl7hl4OKUgANHSVbJ6jbSNokUmZxVxD+0ukVA4p63415QkGxbRDqmBJz7uqR6K7aJIE9yKuNfmN8EyaneyussSSCCUDdKKS5dNcRuCZKFuUQS97oaCZLbhV3dopBrTuJeph8WrXcCstDtLCU5SEUGSKRI532C5CAl2QSOYSXgcnE8yR1mt8gOVl6ncpDsaUsdRMYNkjP9leclqoQgNMTm1UPsOXKWYkmS94Q5QpTkrkbsFu3CrpPcLCUZ4O3/5NRMDsP+2T+s018iTXomppJsL6spAWcn7p2tHkP5XB2cuJcdrNhhTOJeKaApihejJGf6qn89EAShbi5dPch0vsSBkxOcv3wgegdBmC2iJHc1HRKNdCHK23GvCXWSAdZuq9gugkimKmpzqJKc9LdbBPalxgks7YDZz26RzNZ6sDsySI6hJMcNktP9lePJhCsIDbFltfML1O5XxHIhzBFKEve6mQ6JRrqQcnBlmok0wW5RD8aXHKYkJ9MkSzOVxyZxL8iTDNVWC3C/hXsS97x+ZLOd3/12UqUku69TOXGvCKho/7SpbpHps+wWMuEKQiNcuGKAZELx3JGz7R6K0C1IkNzVSJDcLqoS95rQlrpejN0hwpNcpnc4XEk2waI32Pd23AsMkjtRSTZB8lBF6beV5DjBfFlJ7hMlWRBmSU86yfnL+kVJFuYOsVt0NR0SjXQhJhAs5p2AK0zRbQVGSU6H2y0AJ9DtWwaFsOoWZh9vu+mUo7qaLlkz4/MvSO4ZsuwWrrJeKsYbZ1XinvliJBOuIDTKpauH2P2KKMnCHCGJe11Nh0Qjs+OFY+f45r4cY5P5dg8lPiZgMkHXXNstMm6gGqoku2PqXezYBkI9yQFKcsJjMZg5V1vZAjqzuoX5H1Ul7rn/L12KN05RkgWhqVy6apBDZ6Y4Oz2P5nth/iJKclezIILkPUfG+bfn8xw9N93uocSnHCS7Y55ru0UcT3JZSfUEyaFKckCQbCaZmbPRnuROq5NclbhnB8kxPj5S3UIQmopJ3nvswOk2j0ToCkRJ7moWRJDcl3UCrImZQsSWHUS7g+Q4nmSjCvcOO9uVO+75UPYke+wWRm01yXsz52pbUkNn2y2ybrtplXD84+AE/bE8yW7iXlrqJAtCM7hszRBKwXv+4WGu+aPvcucTh9o9JGEhk/CUMRW6ig6JRmZHf8YJZiZz8yj4aHeQHEtJdoM6r92i3uoWUAkM4yTudWJ1C6Wc5D07cS+O4m069WWkBJwgNIMVQz3c9b6b+O8/voWVQ1l+72vP8MrYVPSOgtAISsmvf13MggiS+zJO8DE+n5RkE1SWPclzrSTX40kedoLpspIcEhx6n4cJNI2SnJuHiXvGQ53KWnaLYkxPspSAE4Rmc8W6RfziTZv4zM9so1Aq8bG7drV7SMJCRewWXU2HRCOzYyBrlOR5FCQbFfLUS85tVJe8ZlOvJznVC3lXRQ3ruBdotyg53eoK0/MnSO5f6oxl8XnO46ogOWYJuOwQvPZ3YPMtkHCflyjJgtAUNizt4wNvvJhv7zrKP92/n1MTuXYPSVhoSOJeV9Mh0cjsqHiS59Eb2QSCT3/F8Qef/7q5PX89dZJ7h51SccaPG9pxL8RukRt37vtWt7Deip1S3WJ4I/zm87DhOuexHSTHLQGnFLzh92D5JeJJFoQW8Euv2cSV6xbx0bt28apP/Ccf+PLj7R6SsJAQJbmrWRBBcsWTPJ+UZPelH/0hbL658rP8XBGr454JkhdX2lhDuCc5qARcqeBUtoBKgF61XQcqyQADyyv3k9nKF4W4JeBspLqFIDSddDLBV977au74b6/m9Zcs51vPHKFQlM+Y0CQkca+r6aBopHF600kUMD4flWSAK35q7s8fy5PsUZLL1NFMxATEM+ecP4hht+iQEnBeUj31l4CzkcQ9QWgJ2VSSazct4Zata8gVSrx0YqLdQxIWCqIkdzULIkhOJBTZJEzOp8Q9E2D1L4dNO+b+/LE8ya4q3BNDSQ5qSz242rk9e9jptgfzp7qFlxpPcp0fH7FbCEJL2ezWUH5WOvIJzUKqW3Q1kVd5pdTtSqljSqlnAtb/rFLqKaXU00qp+5VSV1nr9rvLn1BKPdLMgXvJphQT87EE3GX/e22y21xQrye5KpiuowTc0Brn9uxhS0n28yTbzUQ69LtbI55km4SVxCgILUQp9Wal1B6l1AtKqQ/7rP+QUupZd+7+nlLqPGtd0Z2zn1BK3TW3I58dFywfIJNMSJAsNA9J3Otq4kRn/wj8LfDPAetfAl6ntT6tlHoL8HngOmv967XWJ2Y1yhj0JOdZM5GBFY6yuPVd7Tl/Nk6Q7KmTbAizQwQpyecOVwLt+VLdwksqC9PuxXdWnmSZcIXWoZRKAp8GfgQYBR5WSt2ltX7W2uxxYLvWelIp9SvAnwLvcNdNaa23zumgm0Q6meCilQM8e1iCZKFJiN2iq4mMRrTW9wKnQtbfr7U2/UEfBNY1aWx10ZNS8ytxb+02+J0XYc3V7Tm/8SSH1WdO2naLCE+yWeQNktM90LvEoyRHJe51qN2iKnFvNkqyTLhCS7kWeEFrvU9rnQO+DNxqb6C13qm1NoXP2zZvt4LNq4fY/cq5dg9DWCiIktzVNPt3/l8EvmU91sB3lFIa+JzW+vNBOyqlbgNuA1i5ciUjIyN1nThFkUNHT9S9XzsYHx9n5J572jsIXeSCdTczeryPmYDX7MLDR1gH3PvwUyw78RJb3OW79+zh6Fj1PjcWCqSBo8dPsdtzvO2JRUy/9DRjp0pcANz3wycopp6v2iadO8ON7v37H3iQXLb+utHj4+Mt/f9vOX2W/onTPDwywpZjR+mfmubhOs63+PRTbAWeePwxxtOb5sV7FVr/ujaT+TTWFrIWOGg9HqX61z0v3nm7x7XHFYBPaq2/7rfTbOdsaM3/Kz2R58R4jq9/+79YnG3er1Lz5b01X8YJ82OsFx56hVX53LwYq0HG2jyaFiQrpV6PM9neZC2+SWt9SCm1AvhPpdRzrjJdgxtAfx5g+/bteseOHXWd/1OP/AeqZ4AdO26K3rjNjIyMUO/zawmvfyPrw9aXfkD+6E5e+8Yfg2dnYLezePOlm9m8dUf1tg+moQAr16xjpfe5HbqIgXNHWLZ+JexTvOYNb65Neps8Bfc7d2+48abq0msxafnreupL8PKoc44jXwB1pr7z7U/Dk7D1qis48zKd8R6IQce8X2Mwn8baCSilfg7YDtiF2s9z5+3zgf9SSj2ttX7Ru+9s52xozf8r++JJvvTcgwxvuoLXXVz/PBLEfHlvzZdxwjwZ68x/wjHFwMBA54/VZV68ri6dPtamfM1WSl0J/D1wq9b6pFmutT7k3h4DvobzM2BLyKbmW1vqecCrf5Untv4/zv0oT7JZ5i0BB44v+dwrjt0iO+hfFcJO3OvY6hYZTwm4OscpdgthbjgEVd9/17nLqlBKvQn4PeAWrbXpFGTP2/uAEaBNnrDG2OJWuNgtyXtCM5DqFl3NrINkpdQG4H8BP6+1ft5a3q+UGjT3gR8FfCtkNIOepGJyPlW3mA/0DjMxsNG5H1ndwsXrSQYYWgsTx2HihH/SHsyjOslua25dqn+c5RJwMuEKLeVh4CKl1CalVAZ4J1BVpUIpdTXwOZwA+Zi1fFgplXXvLwNuBOyEv45nUV+atYt7q5L3zk7n+e2vPMmxc9NtHJkwL5HEva4m0m6hlPoSsANYppQaBT4KpAG01p8FPgIsBT6jnKChoLXeDqwEvuYuSwFf1Fr/RwueAwA9qXlW3WK+EbfjnrcEHMCQW+Hi5N6YQXKHVrdIZqCYc+6XivUr3kZBLxVxP0KC0HS01gWl1PuBbwNJ4Hat9S6l1MeBR7TWdwF/BgwAX3Hn6Je11rcAm4HPKaVKOCLKJz1VMeYFm1cPVinJO587xlceHWXVoh5+80cvaePIhHmHJO51NZFBstY6tEaZ1vqXgF/yWb4PuKp2j9aQTTrVLbTWqE5VIuczcTvu+dV8NrWST+yF5Zf67zcfqlvUKMnSTEToTLTWdwN3e5Z9xLr/poD97geuaO3oWs+WNYv4r+eOMTaVZ1Fvmh++5BRo+uqjo/zGmy4mmZBrhBATUZK7mg6V7OqnJwmFkmamID9lt4TYHfd8SsoNukFybjxYSbYDzk5VklM9TnBcLLgl4BqtkyzvUUFoJTdesJSShgdedEr0P7L/NP2ZJIfHpvnBCy0v2y8sJBJik+tmOjQaqZ+elBOkiS+5RaRDmo7YhNktICRIVpWgs2ODZPcLQGHabUstiXuC0Im86rxhBrIp7t17grHJPHuOnuMXb9rE4r40dzxyMPoAgmBwr0tKguSupA39kFtD1o0/JmYKLOkPaZAhNIbdTCTMk+xnt+hZDOk+yE/6t6Q2JFJQbMDrO1eY16Aw47SWFruFIHQk6WSCV1+wlHufP84bL10BwA0XLuPsdIEv/vBlHt5/irHJPNvOG2ZYrhdCGOXrnW7rMIT20KGSXf2IktxiIjvuhSTuKVVpTx2kJEPFl9ypSrKxkhRnGvMkl5VkUSQEodW89uLljJ6e4iuPjJJOKq5at5if2raOXKHET3/2AX7pnx/hz7+zp93DFDqdhCjJ3cyCU5KlVnKLiKqTbPArAQdO8t6pF/1bUhs6PUguK8nTMD0GizfUt3/Zkyxf5ASh1bzuIqeRyH/sOsLVGxbTm0ly+dpF3P6e7eSLms/e8yJPjp5p8yiFjqdst5B5uxvp0GikfnrLSrIEyS0hkbRU4jpLwEGlwkWokpx0jtOp1UlMrejCDJzeD0s2/f/s3Xd4lFX2wPHvnZJMeg8J6YTQQwsdBCwoYhd777qr7q676+66/lx31dVVt7i6rr33jo0VQUGKAgLSQw01JKQBaaTNvL8/7qSRwiQkmZnM+TwPz2Rm3nfmJMDL4cy553bsfOlJFqLHJEcFkhoVCMDY1MiGx08Z1IczhsYxoV8UW/PLqK5r/e+jYRjsKqrokViFB5NKsk/rNUlyY0+yJCDdpr6a3G4luY0PJ1xtt/DUKjI0JsmH90FtBUR0MEmWzUSE6FFTndtSj0mJaPFcZkIYtXaDrfllrZ77wpIcTv77In7ae6hbYxQermGKkVy3fZEHZyQdU9+TLBuKdKOGvuQO9iSD3nUPjr9wz1MX7UFjkly4Rd92tJIs7RZC9KjZoxMZkRTOhPSoFs9lJoQBsH7/kRbPFZZV8+Q3OwB4cemu7g1SeDapJPu0XtSTLO0W3a4+SW63ktzGSvHQXlBJNtcnyc7FPhGpHTtf2i2E6FEjksL59PbJrT6XGBFAeKCVjbktk+R/fL2V6jo7szLj+N+GPPaVVHZ3qMJTOf+9U4ZMt/BFvSZJtjm/kwqZbtF9rO1UktsbAQeQMAb6joI+w9p+fZPZs5Pk+v8kFG4BVCcW7km7hRCeQilFZkIYG5xJ8rdbDvLF+jyC/S28t2ofN05O48aT0vh600Fe+343U9pZcyx6MWm38Gm9Jkn2M+n/8FVKu0X3aa+SfNx2i3i4ZVH7r2+yeO6W1NCk3WIrhCU23neVVJKF8CiZCWE8vziHkooa7v5gPVW1+u9m37AA7jw1g7AAK2cNj+fdH/eRdZLMU/ZJ0m7h03pNkqyUIsjPQrks3Os+DWPgOjECzhWe3m5RnxTXlEHfkR0/X3qShfAomQlh1DkMfvvBOooravj09smMSArHMAyU8z/+N0xO49O1B/jhgIkzneflHj5KZKAfAX4e/J960TVkxz2f5sEZSccF+pmlJ7k7tduTfJxKsitMFs8d/wbNK8cdXbQHjZVkudgK4REyE/XivW+3FDArM44RSeEADQkywPDEMAb2CWFprv635UhlLTP/tZgrX1xOnV3+Lvd6Ukn2ab0qSQ72t0hPcndqb7pFvbZ6kl1hMnv2dAtzkyS5o4v2oLGSLO0WQniEhPAAIgKtmE2K354+sNVjlFLMzkog54iDnYXlvLliD2XVdazZe5inF+7s4YhFj2toAZTrti/qNe0WAIH+ZulJ7k7WE+hJdoW3tFtAx2ckQ5OFe3KxFcITKKW4dlIqVrOJfjFtr8w7f2QCj8zdwtsr9vLp2gNMHRBDVJAfT367nSkZ0WS1ModZ9BIy3cKn9a4k2c8i21J3J0t7Pcn10y1OYHGLt0y3gBNrt3DIx3ZCeIpfnTbguMfEhtrIjDbz8rJdGAbcNq0fwxLCWLmrhPvmbOTLX0xp1qIhehFpt/BpHpyRdFyQn5lKabfoPu1VkuudULuFl0y3AKkkC+FjJidYMAzdozyxXxShNit3ntKfzXmlrNhV4u7wRHeREXA+rXclyf4WKmThXvdpr5LcJe0WHl5JNpl1Ih8QAQHhnThfepKF8FajYs2clBHN72cOaqganz8qgYhAKy/Lrny9l1SSfZoHZyQdF+RnkW2pu1NDJbmdY3rzCDjQi/c6s2ivnjLLdAshvJCfWfHGjeOZ3D+64TGb1cyV41OYn32QvcWd25Xv/R/38X9zNnRVmKKryQg4n+bhGUnH6IV7UqXrNu1Ot6ivJJ9gu4XJw/9IWvw712pRT5mk3UKIXuTqiSmYleLFpTkdPtfhMHhiwTbeWrGXI5W13RCdOGFSSfZpHp6RdEyws93CkFWo3aPdOclOvb2SfOp9MP62zp9vMku7hRC9SJ9QGxeMSuD1H/Zw3Ssr2VFQ5vK5y3OKOXCkCsOAlbulr9kjNfx7J0myL/LwjKRjAv0sOAyorpM/zN2ivR336h/qzT3JAGNugOTxnT9f2i2E6HX+ekEm/3fWYFbvOcQ5Ty1jV1GFS+d9uGY/If4W/CwmVuQUd3OUolOk3cKneXhG0jFB/voPs4yB6yau7Lh3IpXk8BQIS+r8+d5AKslC9Dp+FhM3ndSPeb+aitWs+P2H63E4mn+iWV3X/O99RXUdX23M56zh8YxMCpcJGZ5K2i18Wq9KkgP9dD+s9CV3k/YqyfVOJEme8SBc9XHnz/cG0pPxwYQIAAAgAElEQVQsRK/VNzyA+84ewsrdJby5Yk/D47uLKhj70AKeXrij4bH/bcynssbO7KxEJqRFsunAEUqranE4DLbkl0rboKeQEXA+rVclycHOSrKMgesm7VWSu2QEnMnzF+6dKJO0WwjRm12UlcjUATH87X9b2Jh7BMMw+MPH6ymtquOJBdvYUVBGWVUtLyzOISUqkDEpEYzvF4XDgNW7D/HP+duY+cQS3lqx193figCpJPu4XpWRNFSSJUnuHu1Ot3A6kUqyL1AmabcQohdTSvHY7OFEBPpxxQvLefCLbJbnlPDb0wcQ6Gfhjx9v5LY3V7OjsJw/nzsUpRSjkyOwmhUvL9vFM9/tJNDPzANfbGZj7hF3fztCepJ9Wq9Kkht7kiUJ6RaRabpSHNq3lSe7YAScL1BmabcQopeLC7Px7i0TCA2w8vKyXYxPi+Tn0/vzx1mDWLm7hGU7inls9nBOHhgLQICfmeGJ4SzZXkRsiD9zf3ESkYF+/PytNdzz8XquenEFK6Vn2T2ci8klSfZNvSpJjgrS2wYfLK1ycyS9VHQG/F8BRKW3fE4p5wi39nYaEXrhnlxshejtkiIDee/WiVw6JonHLxqByaS4ZEwSV09I4eELMpmdldjs+In9ogD42+zhpEYH8dQVozhytJZ5mw6yes8hnlm0o7W3AaCq1i5V5+7S0AIo121f1KvKfokRAVjNipxC18bviE5or2f4RPqRfYVUkoXwGQnhATx60fCG+0opHjx/WKvH3jKtH1MHxDAuLRKAsamRrLlvBmaT4tGvtvD84hwKy6qJCfFvdp7DYXDH22v4dksBS39/SpuxzNuUT6jNysT0qC74znyItFv4tF5VSbaYTSRHBrKrqNzdofggJf3IrjBJT7IQoqVQm7UhQa5nNulP5i4clYDdYfDZugMtznvmu50syC7AYcBXG/Nbfe06u4O73lvLlS8u560mUzeEC2Thnk/rVUkyQL+YYKkku4skyccnm4kIITooo08IwxPD+HjN/obHau0OPli1j398vZWzh8czKC6E/23Ma/X87LwyKmvs9A0P4N5PNnLOU0uZ/LdvueKF5W4fNVdQWsU9H2/gyFEP3ZZbRsD5NJeSZKXUy0qpAqXUxjaeV0qpJ5VSO5RS65VSo5s8d61Sarvz17VdFXhb+sUEsae4ErtDZkz2KKWk3cIVMidZ9ACl1Eyl1FbnNfkPrTz/a6XUZuf1+hulVEqT53r0mi1cc8GoBDYdKOWrjXn84+utTHn0W+7+cD1D+oby6OzhzMqMZ9WeQxyqapnMrdqjF/29c/MEbpuWTqCfmeTIQL7fWczqPYd6+ltp5i9fbOadlXtZsPmgW+Nok1SSfZqrleRXgZntPH8mkOH8dQvwDIBSKhK4HxgPjAPuV0pFdDZYV6RHB1Njd7D/UGV3vo1ojVSSj0923BPdTCllBp5GX5eHAJcrpYYcc9hPwBjDMIYDHwKPOc/t8Wu2cM05I/piMSlue3MNTy/cwaC4UF68Zgyf3j6FIH8LszLjMAxYfdDOkaO1PLNoJ4crawBYtfsQfcNsJEUG8oczB/HerRN58doxBPqZ+XB1Y3W6rKpnq7mbi+18uV5Xvz12eodMt/BpLi3cMwxjsVIqtZ1DzgNeN/TnNsuVUuFKqXhgOjDfMIwSAKXUfHSy/c6JBN2etJggAHIKK0iJCuqutxEtKBn/5gpptxDdbxywwzCMHACl1Lvoa/Tm+gMMw1jY5PjlwFXOr8+gh6/ZwjXRwf48Ons4FTV1nDksvsUCvv6xIWTEBvPd/kq+/+8ycgorKK2q5XdnDGTVnhLGpTVfsBfkb+HMYfF8sT6P+88Zyodr9vOXzzbx+o3jmJQe3exYh8PAZGo5ucgwDEqP1hEW2PECSU2dgzc3V5McGUhKVCArdhV3+DV6hKqvJcqn076oq3qSE4B9Te7vdz7W1uPdpl+0Tox3FsrivR6lZOGeS2Thnuh+Hb3u3gj8r5Pnih40OyuRayamtkiQ683KjGdfmYNDFTVkJoTxwap97Cqq4GBpNWNTW34gcPGYRMqr63jim208+MVm6hwGf5+3FcMwKKuq5aoXVzDiL1+Tfu9c/vzZphbnv7hkF2MfXtCp8XNzfsrlQIXB/ecMYWpGDLuLK9sc3/rQF5u56bVVHX4PV1VU17Xdmy3tFj7NY0p/Sqlb0K0a9OnTh0WLFnXo/PLychYtWoRhGARZYen67fS3e+a2nvWxegNXYx1bWYmhzKxy4/flDT/XrPJKamoKKA/1/FjrecPPtZ43xeoJlFJXAWOAaZ0494Su2eBdv1/eEGua3cHkOIPzBljIr6jin7k1/OaNpQAYhTtZtGh3s+MdhkFMgOK573II91ecnWbl4+2H+fcH3/D9gTpWHbQzLdHCgXITby7fzWj/AkL9dUW5xm7w1HeV1NTBna99z30TbZicc/INw2BjkR2bRZEWZsLSShX6rdVVRNsMTPmbsZTqBPTVL5cyPr5lWvLFT5UcrDD44uuFBPvp17I7DLaUONh+2M7wGDP9wswtznPF1hI7j6+q4sZh/kzs2/K9/auKmAjUVFV6/O9/PW/4s1rP02PtqiQ5F0hqcj/R+VguuuWi6eOLWnsBwzCeB54HGDNmjDF9+vTWDmvTokWLqD9nQPYyqi1mpk+f0KHX6ClNY/V0Lse6MQisNrd+X17xc90eDgERBAcHe36sTl7xc3Xypli7UVvX42aUUqcB9wLTDMOobnLu9GPOXdTam5zoNRu86/fLW2INt+k4HQ6D93MW8lPBUYL9LVx19ikNI+Wauo4d/P3rrTx99TjGpUWy6h/f8fLmGkqr7Pxu5kB+Pr0/OwrKOe2f37HbksgvpmcA8PaKvZTWbODK8cm8tWIve/xSuW5SKtl5Zfz5s02s3K17jIP8zFw/OY3fnD4A5UyiK2vqyF4wn+kJVk4++WTq7A7+vvprygL6MH16ZrP4jtbYKZj3lW52iBvI9OF9Wb//MDe8uoqicv3Hds6OWkYkhvHPS0eSHhPs8s9qX0klv356GXUOOBoUx/TprcywLsuH5WDzs3rF7z94z59V8PxYu6rd4jPgGueUiwnAEcMw8oB5wOlKqQjn4o/TnY91q37RweTIrOSeJ9Mtjk9Ju4Xodj8CGUqpNKWUH3AZ+hrdQCk1CngOONcwjIImT7nlmi26nsmkuHxcMgCjksNbTZABfjYtnaW/P4XJ/aOxmk388tQMSqvqmDYghtum6t1V+8cGM31gDK//sIfqOjt2h8ELS3IYnhjGQ+cPY+qAGB753xZG/OVrZj25hO0FZTxyYSbPXjWaaQNj+M/CHdw7ZyMO59SppduLqKlzMDJW1+ksZhNZqZGs3FWC3WHw4er9DYvvtx4so35Y1eJthQD8d+FO7A4Hz141mlX/dxoPnDeUvSWV/Ob9dS5PtjpaY+fm11dRa3eQFh3Elryy1g+UEXA+zaVKslLqHXR1IVoptR+9+tkKYBjGs8BcYBawA6gErnc+V6KUehB90QZ4oH5BSHfqFxPER2v2U15dR7C/x3SU9G5KgdnP3VF4PtlxT3QzwzDqlFJ3oJNbM/CyYRiblFIPAKsMw/gMeBwIBj5wVvf2GoZxrruu2aJ7XDImiae+3d5iIV5TJpMiITyg4f75oxLws5iYOiCm2WK9Gyancc3LK3l64U6q6+zsKqrg6StGo5Ti4QuG8dAX2cSE+JMeE8R5IxOICNL/HpwxNI7H523lv4t2Umd38Ojs4SzIPkiIzcKAiMY63fi0SB6ft5XLn1/Oyt0lzB6dyD8uGUF2XikAmQlhLN5WRFF5NQuyD3LdpFRmDosH4JqJqYTarPzqvbW8vWIPV09MPe7P5uVlu9iSX8Yr14/l2+wC5qzNxTAMlFKs3lOCv8XMsIQw6Un2ca5Ot7j8OM8bwO1tPPcy8HLHQ+u8+sV7uworyEwM68m39m1m+Q/JcZnM4JCLrehehmHMRRcvmj72pyZfn9bOuT1+zRbdIybEn8V3n9yQsLrCbFKcM6Jvi8dPyohmQJ9gnvxmOwBjUyOYOSwOgMSIQJ69OqvV11NK8buZgzApxX8W7mBIfCjfbilg+sBYLKbGBX/jnbsNrtt/mH7RQXy/swjDMMjOKyXY38IV45O55+MNPPbVFuocBpeOTWr2PueN7MtHa/bz2FdbOX1oHH1CbW1+j0eO1vLcdzs5dVAsJw+M5cDho5QtryP38FESwgO48+2fKKuq45PbJ9E/RP9HQbl50xXhHr1uxz3Qu+4B0nLRo2QzEZfIZiJCiB4UG2rDaj7xf+qVUrx4zVhevX4sK+89lQ9um9RmC0drfj1jAKcMiuXPn2+mqLyG0wbHNnt+VHIEf5w1iE/vmMwNU9LIO1LFrqIKsvNKGRQXwtQBMQC8v2o/o5LDyegT0iK+h84fRo3dwb2fbGiYVvHw3Gxueu1HSpvMgH5p6S5Kq+q4a8YAAAbFhQKwJa+M3cWVHDhSRVl1HTe9toojVfXJsRQ3fFGvTJJTowOxmhWbD5S6OxTfISPgXCObiQghvFRyVCDTB8YSG9J2lbYtJpPiX5eMJDEiALNJMX1A8yTZbFLcMjWdQXGhTOmv20OW7ihiS14Zg+NDSQgPIN25D8KlY5JavD5ASlQQv5s5iAXZBby/ah/v/biX5xfnsCC7gCtfWEFReTXr9h3m5aW7mJUZp9spgIFxOuHekl/Ksh1FADx20XByDx/lz19kA9Ju4at65efj/hYzmQlhrHLzdps+JTAKgmOPf5yvk81EhBA+KizQyps3jmdHQXm7G5CkRAWSEB7Aez/uo6y6jsHxutI7Y0gchSv2cHYr7SD1rp+UyjfZB/nL53ru80kZ0VwzMZXb317D2L8uwDDA32LirtMGNJwT7G8hOTKQ7PwyDMMgPszGxVmJLN1exPq9ertsSZJ9U69MkgHGpkby8rJdVNXasVk7Nz9RdMClb8qOe66QdgshhA9LjQ4iNbr93XCVUkxKj+ID55bZg+N1pfeuGRncOCWt3QX5JpPi8YtHMPNfiwkLsvLEpSOJCvbnnZvHM2/TQYb2DWV8WhRxYc2r4YPiQsg+UMqhyhpOGdQHpRRB/mYqnF0akiT7pl6b1YxNjeS5xTms23eY8f2ijn+CODEB4e6OwDtIu4UQQhzXlIxoPli9H6Ua2yH8LWZiQo5f9EoID+DTOyYT6GchKljvTpiVEklWSmSb5wyKD+XrzbpqPCld5ww2q5nKOulJ9mW9sicZICtFb8EpLRfCo0i7hRBCHNdEZ6KaFhVEoF/H63n9YoJbVIvbMziucSHgpP6NSXJVrU6SpZLsm3ptJTkiyI+M2GB+3C0jPoUHMclmIkIIcTyxITayUiIY0Mf1HfROxCBn33O/6CDiw/TcaJvFTI3dwPAzSZLso3ptkgwwJjWSL9YfwO4wOjSqRohuI5uJCCGES96+eTxm1TP/didHBhIeaGXawJiGx2xW54ftyoy0W/imXttuAXrYeVlVHdsOtrHdpBA9zSTtFkII4Qp/ixlLF8x4doXZpPjizincfcbAhscaFv2bzFJJ9lG9PEnWTfqrpOVCeAol7RZCCOGJEiMCm/U/BziTZENJu4Wv6tVJcmJEAH3DbCx1DgcXwu2k3UIIIbyCv7PdwlBSSfZVvTpJVkpx2pA+fLetkKM1kpgID2Ayg0MutkII4eka91hQSE+yb+rVSTLAGUPjqKp1sHh7obtDEUI2ExFCCC9ha2i3kEqyr+r1SfK4tEjCAqzM25Tv7lCEkM1EhBDCS9gsOkVySE+yz+r1SbLVbOLUwbF8k11ArV3+kAs3k81EhBDCKwT4OSvJyAg4X9Xrk2TQLRdHjtaycpdMuRBuJu0WQgjhFerbLaSS7Lt8IkmemhGDzWriq43SciHcTBbuCSGEV7BZnEkykiT7Kp9IkgP8zJwyKJYvN+RRUyd/0IUbyQg4IYTwCvU77jlQgOHeYIRb+ESSDHBxVhIlFTV8u+Wgu0MRvswkm4kIIYQ38LdKJdnX+UySfFJGNH1C/flg1X53hyJ8mVSShRDCKwQ0S5Lluu2LfCZJtphNzB6dyMKtBRwsrXJ3OMJXmWS6hRBCeAOrWWFSYJdKss/ymSQZ4OIxSTgM+HhNrrtDEb5KSbuFEEJ4A6UUNqsZOyZkBJxv8qkkOS06iHGpkbz6/S52FVW4Oxzhi5QZMMCQRSBCCOHp6pNkqST7Jp9KkgH+dM4QauocXPTM96zbd9jd4QhfY9I9bnLBFUIIzxdgNWM3FEoKGz7J55LkYQlhfPSzSQT4mbnqxRWUVtW6OyThS1T9XzlJkoUQwtP5W03YDWm38FU+lyQD9IsJ5j9XjKasuo4v1+e5OxzhS6SSLIQQXsNmMWNHyTXbR/lkkgwwIjGMjNhgPlwtI+FED1KSJAshhLewWU3UGdKT7Kt8NklWSnFRViKr9xwip7Dc3eEIX+GsJMtHd0II4flsVjN1hlSSfZXPJskAF4xKwKTgozVSTRY9xNmTLBdcIYTwfAFWM3XSk+yzfDpJjg21MW1ADB+vyaXOLn8BRA+QdgshhPAaupIs12xf5dNJMsDl45LJO1LF7Ge+Z/vBMneHI3o7k1SShRDCW/hLT7JPs7g7AHc7fWgc/7liFH/6dBMz/72EsAArAVYz9509mJnD4t0dnuhtlPQkCyGEt6jvSZZrtm9yqZKslJqplNqqlNqhlPpDK8//Sym11vlrm1LqcJPn7E2e+6wrg+8qZw/vy9d3TeVn09KZlRlHkL+Z3324noOlVe4OTfQ2MgJO9AAXrtlTlVJrlFJ1SqmLjnnO46/ZQvQUm8VMrUMW7vmq41aSlVJm4GlgBrAf+FEp9ZlhGJvrjzEM464mx98JjGryEkcNwxjZdSF3j+hgf357xkAAdhVVMPOJxdz7yQZeuGYMSik3Ryd6DelJFt3MlWs2sBe4DvhtKy/hFddsIXpCgJ+JWmm38FmuVJLHATsMw8gxDKMGeBc4r53jLwfe6Yrg3CUtOoi7zxjIguwCPlt3wN3hiN5EdtwT3e+412zDMHYbhrEe+YMoRLtsFme7hSTJPsmVnuQEYF+T+/uB8a0dqJRKAdKAb5s8bFNKrQLqgL8ZhjGnjXNvAW4B6NOnD4sWLXIhtEbl5eUdPqc9/QyDlFATj3y2jpBD2zB1YTW5q2PtThJr14o9uJUhwNEKz4+1njf8XOt5U6zdyOVrdht65JoN3vX75S2xekuc4B2x7t9bSz8UDnudx8dazxt+rvU8PdauXrh3GfChYRj2Jo+lGIaRq5TqB3yrlNpgGMbOY080DON54HmAMWPGGNOnT+/QGy9atIiOnnM85ZEH+MU7P2HEDWH64D5d9rrdEWt3kVi72IYiyIagABvjPD1WJ6/4uTp5U6werEeu2eBdv1/eEqu3xAneEes+/904ckwohcfHWs8bfq71PD1WV9otcoGkJvcTnY+15jKOabUwDCPXeZsDLKJ5v7JHO3NYHPFhNl5ausvdoYjeQhbuie7XkWt2C958zRaiq9msZuxIT7KvciVJ/hHIUEqlKaX80IlwixXPSqlBQATwQ5PHIpRS/s6vo4HJwOZjz/VUVrOJ6yal8v3OYjYdOOLucERv0DACznBrGKJXc+ma3Rpvv2YL0dXqk2TpSfZNx02SDcOoA+4A5gHZwPuGYWxSSj2glDq3yaGXAe8ahtH0X//BwCql1DpgIbq/zasuuJeNSybQz8yLSxqryav3HOKejzdQUyd/aUQHSSVZdDNXrtlKqbFKqf3AxcBzSqlNztO9/potRFeyWc04DEmSfZVLPcmGYcwF5h7z2J+Ouf/nVs77Hsg8gfjcLizAylUTUnhhSQ63TutHekwwd3+4jpzCCjJig7lhShqHK2t49Kut3HFKfxLCA9wdsvBkqn7HPftxDhSi8453zTYM40d0G8ax53n9NVuIrmSzmqTdwof5/LbUrrh9en9CbVYembuFd3/cR05hBX3DbDz17XaOVNbym/fX8c7Kvby3cq+7QxWeTnbcE0IIr2GzmnEgO+75KkmSXRAWaOWOk/vz3bZCHpmbzfi0SJ6/ZgyHj9Zy0bPf882WAoL9LXy9+aC7QxWezlRfSZYLrhBCeLoAqxmHVJJ9liTJLrpmUgqJEQFU1ti596zBDEsI44KRCWwvKGdWZhy/OLU/W/LL2FdS6e5QhSeTHfeEEMJrNGu3OLQb5t4N9lp3hyV6SFfPSe61/C1mnr0qi+0FZQxPDAfgnlmDSYwM5KaT0igur+HhuVtYkH2Q6yenNTv3cGUNf/xkA8t2FDOgTzAJlhqmTjUwmWS7a59jkukWQgjhLfwtzkoyDlj0KKx7G0ZcBglZ7g6tdWX5BJXvAqa7O5JeQSrJHTAsIYwLRjWudYkJ8efXMwYQarOSFh1ERmww850tFyt3lfDm8j28smwXs/69hPmbD3LKoFhq7QZzdtTy1oo9AFTX2Xlj+R6Kyqvd8j2JHiaVZCGE8Br1I+AsjhrY+JF+sDjHvUG1Z+HDZG54yN1R9BpSSe5CM4b04bnFOdz/6UZe+2FPw+PJkYF89LNJDE8MxzAMzv77Vzz61VZOHhTLX7/M5n8b83lr+R7euXkCEUF+bvwORLdT0pMshBDeor7dwkId2Ov0g8U7Gg/Yvxr6DAGrh0y2KsvDv7oEHPYmn1yKzpJKcheaMaQPdofBaz/s4eoJKSy/51RW3nsq3/5mWkOLhlKKa4f6U+dwcPZTS/nfxnwuH5dETlEF176yktIq6XXq1WROshBCeA2b1YxRnyqlTYOwZChx7tJeegBePBXWvO6+AI9VUaRbQyqL3R1JryBJchcakRjOdZNS+fdlI3nw/GHEhdmIDbFhMTf/MccGmvj1jAEcrqzlF6dm8MiFw3nmytFsPlDKVS+uoFhaL3ovGQEnhBBew2o2YTg/AWT8rRDVr7GSnLcOMKBwq9via6E+OS6XaVtdQZLkLmQyKf587lDOG5lw3GNvPqkfC349jbtOywDg1MF9eO7qLLbml3Hxcz+wt1imZPRKJtlMRAghvMlPpqGs9h8PA2ZCVH/dk2wYkL9BH3BoV/sv0JMqS/StJMldQpJkN1FK0T82GKUaJ1ycOrgPb9w4nsLSak75xyJ+/d5adhaWuzFK0eUaFu7JdAshhPAGa6yjeSrkN7pdLjIdqo/oim3eOn1AiYcs5Kurhpoy/XV5gXtj6SUkSfYw49Ii+equqVw9MYWvNuVzwdPLyM4rdfn8mjoHDkdjAlZaVUuOJNqewyTtFkII4U38LWZq6i/ZUf31bfGOxkry4X2eMTu5aR+yVJK7hCTJHighPID7zxnKvF9NJdDPwjUvr2zWfmEYRosFfg6Hwbsr9zLhkW+49PkfKK2qpaSihtn//Z4z/72EgtKqnv42RGtkuoUQQniVAD8zNXZn8SkqXd/mroHDeyAqAww7HN7b/KT9q2Dzpz0baEVR49dSSe4SMgLOgyVFBvLGjeO4+LkfOOvJJWSlRhAb4s/S7UUcOFLFOSP68tvTB7B232GeX5zDpgOlZCaEsXbfYa54YTkKxd6SSmrtDl5YksO9Zw1x97ckZE6yEEJ4FZvVRE2N8054MpgssHmOvj/kPFjydyjZ1ZhAGwZ8dqduw+g3HWxhPRNoZyvJh/fqmCNSuj4mLyeVZA+X0SeEd26ewKzMeHIPHeV/G/IZlhDG9ZNT+XpTPtMeX8Qv313L0Ro7T1w6ks/umMzzV49h+8FysvNKefaqLM4bmcCby/fK1AxPICPghBDCq9gsZmrrK8lmK4SnwL4V+v6Q8/Rt08V7uauhYDPUVUH25z0XqDNJrrWEuF5JttfB6+fBJ7d2Y2DeSyrJXmBwfCiPXjS8xeM3Tknj/VX7GZUczrSMmIZtrk8eFMvHP59EVa2drJRIkiIDmLM2lycWbCc2xJ/F2wu5/5yhDEvQ/7vdsP8IJZU1RARa2VNcyfKcYpIiA7ltWnqbMW07WEb+kSqq6xyMSAwjNtTWPd98b1M/Skh6koUQwivYrGYONR1IFJWuZyUH94G4TLAGNV+8t/pV/VhQFKx7F0Zd1TOBOpPk8uAUIlytJG+eo2OvKNLV5CbDBIQkyV4tMSKQX88Y0OpzQ/s2frzTPzaEWcPieWO53gUw2F/3Ob9/6wQ+W5fHk99sb3aun9lEjd1BYkQAwa289s7Ccs54YjH1AxqsZsX5IxO485QMkqMCu+R767WkkiyEEF7FZm2ycA/04r3tX+sEWSmITNPtFgDVZbDxYxh2IYQlwqK/wZH9+uvuVlkMKCoDk4go+f74xzscsOQf+uvqUijLh9D4bg3R20iS7CP+eNZg0mODOXdEPCaluOS5H5j176XU2B1cnJXIJWOTOFRRQ2yojUFxIVz+wnLu+WgD9423tnitOT/looDXbhhHkL+FT9fm8v6qfSzcWsB7t04kPSaY73cWsSWvjOsnpzYbc+fzpCdZCCG8is1qamy3AIjsp2/jnJ/wRqZB4Tb99caPoLYCRl8LgZGw6BHY8CFM+VX3B1pRBAERVPtHQdURqK0Cazuf8m77SreFjLoKfnoTCrdIknwMSZJ9REJ4QLOq8xs3judX767lkrFJ3NBKIvvkZaM468klPLqyitWV6xmTGsFFWfp/wnPW5jK5fzRTB8QAkJUSwTUTU7ns+R+48oUVnDo4lrdW6JW+R2vt3H5yf5di3JJfSlFZDVMyojv9fW7JL2VLXhnnjzr+hi71qmrtFJZVEx/WcnfELiftFkII4VVaVJKjnf+WxjuT5Ig02PY1OOzw44sQOwQSx+gqc+JYWP9ezyTJlcUQGEWNX4S+X1GgFxq2Zdm/dX/19D/qJLloG6Sf3P1xehFJkn3U4PhQ5t01tc3nkyIDeeaqLB746EfmZx/kvVX7cBgG/WOD2VdylF+e2rzNo39sMG/cOJ7Lnl/OWyv2ct2kVEoqanh83lbiQjqpTPYAACAASURBVG1YLSay80qZMaQPo5MjWrxfaVUt17y0kqLyal65fhzTnAl4vYLSKjbkHmFLfhkV1XXYDYOLRieS0ScE0CPwvtpVy8fzl1Fjd2BgcMGo1j/eKiitIizQir9FV3Vvf2sN32wpwGpW9IsOZmJ6FNMHxjC1SZ+3qzbsP8Iry3bxl/OGEmJrWYWXdgshhPAuNqupcQQcQOpJcMFzMOhsfT+yH9irYcVzenbyBc819vYOPhfm36cX0gXHdm+glcUQFE2NX7i+X95OklxdphcfTvsdhPbVEzg8aXttDyFJsmjT5P7R3DM+gKlTp3HFi8t56ItsJqZH4W8xccbQPi2OHxwfypzbJ3O4soZRyRFU1drZU1LJbz5Y13DMM4t2kpUSwcyhcYxJjWB4Yjhmk+Kxr7ZQVF5NcmQgd7y9hjm3TyY9RndEv7gkh7/OzW7WA+0w4It1eXz1q5MI9rdw1/tr+XRrDTOG9OFQRQ33zdlEVnJkix7p/CNVnPbP7xgSH8rbN4/nh5xivtlSwCVjEokK9mdj7hHeWbmXV7/fzbCEUH4/cxAnZTRP2Nuy/1Al17/6I0Xl1UzqH91QeW9G2i2EEMKr2CzHVJJNJhhxWeP9yDR9+80DusqceXHjc31H6tv89dD/tO4NtLIYIvs1VpLbW7yXtw4wIMFZ8Y4eKElyKyRJFsdlMikemz2CM55YzNebD3L28PjWq6RAWnQQEAToj6heunYMn649wOjkcNJjg/lo9X7eWL6Hv87NBiA5MpBzR/TlzeV7uXFKGtdPTuW8/yzjiheWc1FWImVVdbz+wx5mDo3jppPSGBQfSrC/hTV7D3HRM9/z4BebSQgP5NO1B7igv5V/Xp1F7uGjnPnvJdzxzhruOXMwo1PCG6rGD365maO1dlbuLuFfC7bxTXYBSZEBPHj+sIZjqmrtfLk+j3/O38bVL63k8YuGc/GYJAA+Wr2ftJigFtXw0qpabnj1R2rq7EQF+TF/c37rSbJJNhMRQghvEmKzUmPX/zbYrOaWB9T3KNcdhZP/2GRnVaDPMH2bv6FnkuTEsU0qye0kyftX6duELH0bMwC2zeve+LyQJMnCJclRgdwzaxB/+nQTs0e7vko3OtifG6ekNdy/fnIa109Oo6C0iu93FvPKsl38Z+GOhp7pIH8Lr1w/lke/2sKz3+VgdxhcNymV+84egrlJ68Po5Ahum5bOfxftBODC0QmcE3MIpRSJEYE8Nns4v3j3Jy5/YTmBfmZunJLG0L5hfLk+j1/PGMDekkqeXqjPffqK0Q0JMujkfnZWImePiOfql1bywBebmZIRzZLtRfzuw/X4W0y8dO3Yht7pI5W1XPvKSnIKK3j9hnHM3ZjHR6tzqaq14zAMbn1jNaOTI7jjlP5YVf37NPnoTgghhMca0Ed/qrntYBnDE8NbHhCaAGY/XY0dfF7z5wIjISy5cQvr1uQsgohU/auzDKOhJ7nWFAYoKGsnSc5drd8vKErfjxmk+5IrS3TMx7PuPb35SPKEzsfsBSRJFi67ekIK49OiGi4YJyI21Mb5oxI4b2RfVu05REywP0H++o/j8MRw3rppAiUVNRw4fJShfUNbnZDxy9MyWLazmACriUcuzOSHpUsanjszM541GdGsyClhztpcnvp2B6Ar3bdM7YfDMNiYe4TIID9mZca1GqO/xczjFw3njCcWc9sbq8nOK2NivygOVdZw42s/cvcZA0mMCOTf32xnZ0E5/71yNJP6R1PrMHhz+V6+31lEdl4ZS7YXsWR7EQuyD/LsJYNJApRhb/U9hRBCeJYhfUMB2HygtPUk2WSG85/RC/ZMrSz+jsuEvPWtv3htFbx9KfQZCjd90/k5xVVHwFEHgVEYNRYIjGq/kpy7pnmCGz1Q3xZuhZSJ7b+XYcDcu/XCxeu+6Fy8XkKSZOEypRQD40K6/DXHprb+v9bIID8ig/zaPNffYuaj2yZiNqlWk+gQm5XThvThtCF9uH7yIV5YnMPNU9MaPi77/M4pDTG0JSUqiN/PHMRfPt9MUmQA/71yNAZw7csreehL3TJis5p46boxDb3LE/pFEuxv4cPV+1m6vYhTB8VyydgkfvnuTzy/dBcPIu0WQgjhLZIiArGZITuvtO2DMi9q+7m4TNg6F2oqwC+o+XO5q/XOfLmrYcuXMPjszgVZvyV1UDTUoDc6aWvXvbJ8KN3f2GoBut0CoKiNJLl4p24rUUq/V/URvfCvphL8eu/+CJIkC6/m6si2rJQIsq7OavaY1cVzr52YisOAUwbFEuFM2ufcPpnCsmoKy6qJDvEjPiyg4Xh/i5lpA2P4cn0eSsFvzxjI4PhQUqOCKK6scx4lSbIQQngDk0mRFGJic3tJcnvihwMGHNwESeOaP7dnGaD0FIpvH4SBZzbvaXZVfZIcGAWH0JM02qok567Wt02T5LBksAQ0zntuKn8DPHsSXPqmTuLrdxe018C+5ZB+Ssfj9RLdPBRWCO9nMilunJLmXJSomU2KuDAbmYlhzRLkeqcP0dM/zh3Rl8Hx+qO6UJuVw0d1ciyVZCGE8B5JoSay88pwODqxniQuU9/mt9JysXsJxA2DGX/Rm3msf//4r2cYsPhxKNrR+FjTJBnaryTnrgaTpXHOM+g2kegMHcOxsj8HDDiwRt8v3tn43K7F+vbgJlj9Gthrjx+/F5EkWYhuMGNIH66ZmMIfzhzU8FhogIUjVboXWZJkIYTwHskhJsqr69h/6GjHTw5LAlt4y77kumrY9yOkTNEL/uJH6jFyVcdUrGsqYO3berMSgL0/wLcPwYL7G4+pKNK3DUmys5JstJLU71+le6CtxxR4Yga1PgZuy1x9W+BMoEty9MZYCVmQ853e3vqjm+DzX8ALJ8OBtcf/mXgJSZKF6AaBfhYeOG9YsypzqM1KaXWdc9c9mW4hhBDeIjlUp0udarlQSleTj51wkbtGj41LnaIruWf9A8ryYOFfmx+3+jWY8zPY9Im+v/ZtfbvlSyjZpb8+tpIcla43OCnY3Py1KorgwE/NWy3qxQ3TvcoVxY2PHd4LBzfof7cK9TocSnbq9pD+p0HeWlj9in6fsTfr6vXLM9ufrOFFJEkWooeEBlgpPVoHyiyVZCGE8CKJwSZMqpNJMkD8CJ1I2usaH9u9VN+mTHK+yRgYe5Peua++bxhg+9f6dtm/9UK5TXMg/VTdu7ziOf1cZTFYbI0LAwfO0ontpjmNr1O8E16aoXuJh1/aSozOjU/ymlSCt36lb4ddpBPymkpdSY7sB2nTwHDAV3/Qkz3OfAyu+VQn/hs/7NzPycNIkixEDwm1WSirqsVQJkmShRDCi/iZFf1igtl8oJNJckKWnmKx+PHGx/Ys1ZuNNJ1LfOp9EBIHX/5Gt0pUl+vFfeHJuqd57t1QUwZTfgVDL9SzjatKG2YkN4yQC46FlMm6+mwYcGS/TpCPHoZrP299vnH8CH3bLEn+Uu8iOOgswNDTL4pzIDIdEsfqxX72Gjj5Xl0Njx2sk+1173bu5+RhJEkWooeEBlhxGIBJKslCCOFtBseHtj8Grj1DzoORV8J3f4N598J3j8He5TqRbcoWBtP/oFsidi/VC/vsNXDWPyE4Dta+qSdRpEyBCT/TCfM7l+tj61st6g09H4q36wr2/Pt1b/MN81pO2KgXEA4RaY09xVVH9OsOPFNXigF2L9Pj3yL7gcUPMmZA0gRnEu004nKd0B90tno4vPffO0mSheghoc6tvA1lAmQzESGE8CZD4kPJPXyUI5WdmOBgMsO5/4FRV8EP/4GFD+s+5fG3tjx2+KUQEAnLn9GtFn7BurVhws/08yMu1VXbhNEw+ZdQnq97gY/tMx58rm65mP8n3f4w6ReN85Db0ndkYyV52zy9QcnAs3RSbPbTfdCge54BLnpFV6ab7jcwbDYoM6x/F9a8Do8kws5vO/4z8wAuJclKqZlKqa1KqR1KqT+08vx1SqlCpdRa56+bmjx3rVJqu/PXtV0ZvBDeJDRAjyU3kEqy6F4uXLOnKqXWKKXqlFIXHfOcXLOFaEX9znvZ+Z2sJptMcM5Tupr7m61w04LGZLMpawCMuUFvQLJpDvSbrqu2Y2+E8T+Dcbc0HjvjAbhzNdybB+c80fx16lsudiyAkHjdonE88SP1Yr3KElj/nq5aJ44Fs0W3Xexbro+LdMZttujYmr1vjK4wL38WPrsTaitg/Qeu/pQ8ynGTZKWUGXgaOBMYAlyulBrSyqHvGYYx0vnrRee5kcD9wHhgHHC/Uiqiy6IXwovUV5IdyoRqbSyPEF3AxWv2XuA64O1jzpVrthBtGByvd5ztdF8y6EQ5eQKE9Gn/uLE36VnGR0sg43T9mH8InPk3nfweq62dY4deoG9P+3PL3f5a09e5eG/7fF39HX5x41bbMYP0Qj1l0j3S7Rl9jZ6uMe5W3Tu9/evGEXZexJVK8jhgh2EYOYZh1ADvAue5+PpnAPMNwygxDOMQMB+Y2blQhfBuoQHOJBkTsuOe6EbHvWYbhrHbMIz1tPyDKNdsIdoQG2IjOti/833JHREaD8Mu1F9nzOj864y+Bq76uPVpFq2pX7z37UM6Ic68pPG5WOfc//DkltXjYw06C369BWY9pr+uLNIj77yMK9tSJwD7mtzfj64yHGu2UmoqsA24yzCMfW2cm9DamyilbgFuAejTpw+LFi1yIbRG5eXlHT7HXSTW7uHpsRZU6nykps5OXU21R8falKf/XJvypli7kavXbFfP7ZZrNnjX75e3xOotcYJ3xhrnX8fK7QdYtOhQt7+nNfhsQjIHUbJmGzq1ck3Ln6sZ9n/n8vnjbXEEHNlLWXA6qzfnw+Z8AKKKHGQCJYSz3uXft61Yav2ZjIk9C55nd1rFcWL1LK4kya74HHjHMIxqpdStwGtAhzbzNgzjeeB5gDFjxhjTp0/vUACLFi2io+e4i8TaPTw91sOVNfxu8XxMFj/8LGaPjrUpT/+5NuVNsXq7E71mg3f9fnlLrN4SJ3hnrD8czeaVpbuZfNJUrGbPnH1wwj/XggmweQ4hk29k+sQmr1OcBBsfJrL/2I6//v6JpFZnkzp5Aiz4s56wMexCj/8z4MrvcC6Q1OR+ovOxBoZhFBuGUe28+yKQ5eq5QviKYH/9f1I7MidZdKsTue7KNVuIdgyJD6XG7mBnYbm7Q+k+KZP1/ONhFzV/PCIVBszUI+E6KuN0vePgq2fBimdg0SNdEmp3cyVJ/hHIUEqlKaX8gMuAz5oeoJSKb3L3XMC5dyHzgNOVUhHOxR+nOx8TwudYzCaC/S3YDS/qSV7yT2IKlrk7CtExx71mt0Ou2UK0Y0i8nnBxQov3PN2YG+CX61ouLjSZ4Yr3oP+pHX/NAc6lDXlrIeMMKNoGRTtOPNZudtwk2TCMOuAO9IUyG3jfMIxNSqkHlFLnOg/7hVJqk1JqHfAL9KppDMMoAR5EX7R/BB5wPiaETwq1WahDeU8lefkzxOfNd3cUogNcuWYrpcYqpfYDFwPPKaU2Oc+Va7YQ7UiLDsLfYuqZxXvuYrYcf/pGR8UMhFP+Ty8iPOvv+rGtX3bte3QDl3qSDcOYC8w95rE/Nfn6HuCeNs59GXj5BGIUotcIDbBirzBh8oYk2V4HFYX4G8dZxSw8jgvX7B/RrRStnSvXbCHaYDGbGBgXwubenCR3B6Vg6t2N9+OGw5a5kD7CfTG5wDO7zoXopUJtVmoNhVe0W1QWAQa2qgKQuc5CCAHolovsvDIMuS523qCzYN8KrDWH3R1JuyRJFqIHhQZYsDu8pN2iTI/9MTtqoLLYzcEIIYRnGBwfSklFDQdLq49/sGjdwFmAQVTxj+6OpF2SJAvRg+oryV6RJJcfbPz68F73xSGEEB4kMzEMgC/WH3BzJF4sLhPCkul7YB4c9dxqsiTJQvSg0AAvSpKdlWQAjuxr+7h6Dgesew/+Mw7Wvdt9cQkhhBuNSgpn+sAY/vH1NvYWV7o7HO+kFJzyfwSX58Dz02DnQl2Mqa1yd2TNSJIsRA8KDbBS61AYOGD9+zD/T8c/yV2aVZKPkyTXVcNrZ8Mnt0DRVsj+vHtjE0IIN1FK8ciFmVhMit9/tB6HQ3qTO2XEpawd+TDYa+GN8+GJTPhbEnxwHWz72iMqzF21454QwgWhNgt2TARU5sFnd4K9Bqb9HvyCdCV233JImeTuMLWyfAiIoK6mCsvxKsm5q2HPMjjlPji4Cfat7JkYhRDCDeLDAvjjWYO55+MNvP7Dbq6bnObukLxSadgg+Nn3+t+PymLI3wgbPoBNn+gDwpMhpC8ERkH8cOg3HfqOBkvPTF2SJFmIHhQaYMWOiaCqPFAmMByQuwbSToKNH8HHN8FN30Ji1vFfrLuVH4TgOKorKrAcr5J8YK2+HXUVbPgQNn0M5QUQHNv9cQohhBtcNjaJ+ZsP8vDcLWSlRDb0KosOCgjX0y7qnf4g7F4Ceet10aWiAEpyYOtcvVOfyQqxg/TOgCOvgPjuGyMnSbIQPSjUZsVR3+V09r/g81/C/h91kpyzUD++f6XnJMkhfaiylxF05DgL9/LWQnAchMRB35H6sQNrYcDp3R+nEEK4gVKKf1w8gllPLuHnb6/miztPIizA6u6wvJ/FH/qfpn81VVkCu5fqTy7z18OqV2DFsxCaCLZQsNjgyg8hKKrLQpGeZCF6UGiAhYX2kfwUfT5kXQdR/XWSbBiwa7E+KHe1W2NsUHYQgvtQZYs9fk9y3rrG5DhuOKDgwE+uvU9Vqe5F2/ntCYUrhBA9LSLIj/9cMYq8w1X84+ut7g6ndwuMhCHnwoy/wNWfwG+3wqy/Q+pkiErXz5u79j8pUkkWogeF2qw8az8Xa4w/owASx8GO+fqjpCP7wGRpmSQbhl7UkDwJpv++ZwI1DCjP10lyuT9UHYbqMvAPaXlsTQUUbYMh5+v7tlCIztDVZVcUbNarmte9B+mndN33IIQQPSArJZLzRibw0er93H3GQEJsUk3uEQERMO5m/aubSCVZiB5U/1FcZa1zNXTiGKgohJ/e0PeHX6oT5sqSxpNyV0POIljxjJ4i0ROOHtKLCkPiqPaP0Y+1VU3O36B7q+sryQDxI12vJBfv0Lc75uvFi0II4WWumZhCRY2dj9fkAlBeXcfBUs8aZyY6TpJkIXpQqLPCUFnnfCBxrL5d+SKExMPwS/T9pgnmmtf17dFDsG1ezwRaP/6tvt0C2p6VXL9oL75Jktx3FJTlNZ+13Jb6JLmy2PXEWgghPMiIpHBGJIbxxvI9HCyt4qwnlzD7me9l62ovJ0myED0o2KY7nBoqybFDwBoENWWQNlUnl6AnXoBuZdj4sa4wh8TD2rd7JtD65DYkjiqbs5LcVpKctw6CYvWivXr138cBF1ouinfoRX8oXU0WQggvdPXEVHYUlHPOU0vZU1zJ/kNH2XqwzN1hiRMgSbIQPchsUoT4W6iscybJZgskjNZfp00FWxhED2jsS978qU6gs67TifL2r/Vote5W/x7BcdT4RYDZr+12i7y1utVCqcbH4jJxefFe8U79M0jI0t+fEEJ4obOHxxMRaOXw0Vr+eYkeS/bd1kI3RyVOhCTJQvSw0AArlbVNHqhvuUg9Sd8mZOkk2WGH1a9BZDokT9TzIA27HrTeHntd+8+7otxZSQ6O1fOcQxNaryTXVELhluatFgD+wRA7WA+IP9aR/bBlrv7a4dBJclQ6ZJyuK+i5a2DOz+HL3+gJG6AX9h3cfOLflxBCdBOb1cyL147l/VsncuHoRAb2CeG7bZIkezNJkoXoYSG2JpVkgIl3wGVvQ0SKvp+QpYenPztF78A39iZdpY0ZqJ9b87qePtGa/A3weDpsmnNiQZYdBGtg4zSL8GQ9waIphx1+eLrlor16A86APd83LkK018KyJ+E/4+Ddy/XOSqX7wV6tR+FlnAYY8MLJusVk9avw1Gh4bpoeEffcVCjacWLflxBCdKOslAhGJoUDMG1gDKt2H6KiugsKF8ItJEkWoodFBPpxuKpJkhsU1Xy3oaRx+vboIZj9Ekz4WeNzWdfryu2e71u+sGHAV/focW3z/wR1NZ0P0jn+raGFYsAZOgHPW6/vH94LL54KCx+CjDMg/dSWrzH4HF353vaVvj//TzD/vsbvb+e3jYv2ovpD/ChImqBHyd25Cm5fqYfJm61w8v/pQfHz/tj570kIIXrQtAEx1NgdLM8pdncoopMkSRaih41Ni2R3qYNDFW0ksfEj4Pqv4I5VkHlR817fYbN13/Kql1qet3Wu3spz8LlweA+sea3116+tgtK8xvu7FsPz03XbQ72yg80X4o28QleWf3xBJ+Of/0pXdWe/BFe8B1Zby/fpO1q3aWR/AeWFsOplGHE5XDMHogfqHQbr3zMyHUwmuHEeXPIahCXqFoxLXoObFsC0u2Ha72D7PNgmfctCCM83JjWCAKuZuRvyuf/TjUx85Bv2lVS6OyzRAZIkC9HDTh4YgwEs3t5Or1rKRN3Xeyy/QBh5JWz+rLFfF3TV+Ov7dPJ50ct645HFj+tWh8qS5vOH5/4G/j1cLwosyYH3rtYL7Bb/vfGY+kpyvYAIyLwY1n+gJ2zs/AZO/mPLJL4ppWDQ2frYJf/QM55P+o1+Lv0UXQ0/uFFP92iakLdl/G264jzvnp6bFy2EEJ3kbzEzMT2Kj9bs5/Xleygoq+b5xTnuDkt0gCTJQvSw4YnhBFtPYNXzmBvAUQs/Oecnl+bpHflKdsLpD+n2hFP/pGcdP5amf312hz62skQnusoE718Lr5ylk9kh58H69+DQHp1wl+W3TFzH3Qx1R/VrxQxybZejwWdDXZXeCGXwOXonPoD0k/XjGz/RFeO2Eu2mLH4w81HdorH0Cdd/XkII4SZXTUhmQr9IPrxtIhdnJfL+qn0Ulsl/8r2FbEstRA8zmxSZ0Wa+21aIw2FgMrmQIDYVnQH9psPCR3TCW1GoK6sXPA8DTtfHpEzU98vyIHeVrv5OuhN2LtQL5W5coKu7O+bDVR/rCu3W/+nq89FDUFOuR9I1FZepp2zs/QHOfEwn48eTPAkCIuFoCZz068bHUyaDyQrVR/R7uyrjNN1ysuTvMPR8CEuCLV/AgJl6O2whhPAgpwzqwymD9KdyEYF+vLdqH68s28Wt09L5bN0BZgzuQ1xYK+1qwiNIkiyEG2TGWPghr5oNuUcY4VwJ3SHnPwM/vgQF2Xoqxul/hZgBzY8Zcam+rSyBnYtg4cNQuBUSxkDSWD1R42gJBEXr40ZeoSdKAJz5ePPFhPXOfEyPp+s3zbU4zRaY+HM9Y7l+gxHQrSRJ42HP0o4lyaCryTu/hQ+ug6ojUJqr2zhO/VPHXkcIIXpQv5hgzhwWx6vf7+aNH/ZQVl3HOyv28tHPJmE2KR76cjNJEYHcPLWfu0MVTpIkC+EGmdFmlIKFWws6lySH9oVT73Pt2MBInah+96i+f97T+tZkakyQAabcBdvn65F0429p/bXih+tfHTH17tYfTz+5c0lycAyc8TDM+ZmezxwYCRs/glNc/HkIIYSb/Hx6fxZuKWTKgGgmpkdx/2ebuPvDdZRX17FoayExIf7cdFIaypUWNNHtJEkWwg1C/BQjk8JZuKWAX5024PgnnKgJP4cVz4IBDL2w9WMiUuGuTa71B3eFIefrNpDk8R0/d+QVkDgOIvvBurfh09sbt/IWQggPNSwhjM0PnNGQBJdV1fH4vK0opUfGfbetkJ2FFfSPbWXhtuhxkiQL4SanDe7D4/O2sq+kkqTIwO59s4BwmP2yXizn18579WT1Iro//OIEEttoZwV60NnwxV26mmw7vWtiE0KIbtK0Svzz6enU1DkYHB/KoLgQpv99ET/kFEuS7CFkuoUQbnLuiL4AfL7+QM+8YcZpetpEbxMQDv1nwKaP9eYlQgjhJZRS3DVjADOHxZESFUh8mE02H/EgkiQL4SZJkYFkpUTw2doeSpJ7s2EXQlkeYUey3R2JEEJ0ilKKCf2iWJFTjGEYLN1exF3vrZVtrd1IkmQh3OjcEX3Zkl/G1vwyd4fi3QaeCf6hDM7+J2yb5+5ohBCiUyb2i6KovIY1ew9x1/tr+eSnXH79/locDsPdofkkSZKFcKNZmfGYTYrP1uW6OxTv5hcE18zBbg6Cty+B966Cwm3ujkoIITpkYnoUAD9/aw3F5dVcMT6ZeZsO8sQCuZ65gyzcE8KNYkL8mdw/mjk/HeC2aemE2FzYoEO0LiGLVWP+yTTzT3pHvi1fQsYZEDdM7xAYMxCiMsAqg/uFEJ4pMSKAhPAAcg8f5YbJadx39mBq6xw8+e0OEiICuHRssrtD9CmSJAvhZtdPTuWm11Zx/tPLeO7qMbKq+QQYJitM+x1kXQ9L/wXb5+lfhkMfoEz/396dx1dVXvsf/6xzMkFCwpAQwgwSZgQEQRRUBBWcoLVWqha1qHVCb/XnVFv70tZWb+/PWqu2WoeronIVZ661KoO1KiiDIChCQFAmmWcyr/vH2WASQIImOWeH7/v1Oq+c/ey9T9Z5TrKysvez9xO71d2eojm7c+woNEBaFmS0gEa5kNa4bu/0ISJCbFzysG7Nmfb5Oq47pTNmxp0/6MXX24u45cVPyEhN5vQj8+Id5mFDRbJInA3t0pwJ4wZy9TNzGP3Aezx+8dEc3b5pvMMKt4wcGPH72KO0CDYWwPpFsRkH93xd8iaUH+CCmKQ0yOsN496s27hF5LD3mzN78MvTupGWHAUgJSnC3y44irGPfsg1E+dy+2sLMYMWmWl0yE5n3OCO9GqddcDXKyt3ohH90/9dVKtINrMRwJ+BKPCIu99VZf11wCVAKbAe+Jm7rwjWlQGfBJt+6e5n1VDsIvXGoCOaMfmawVzwyEwueuxDnhw3kH7tmsQ7rPohKRVye8QeFZWVwOYVUFYE7lC4BbavjT12rI0VyiFVjZydCjwJ9AM2Aue6+3IzM42pEgAAFx9JREFUaw98BnwebDrD3S+vq7hFBKIRIxqJVmprmJLEYxcfzQPTCti2u4Sycmf1lkKmLlrHR8s38/Z1J9AgJbrPa706bzW/eWUBz/18EPm5jerqLdQbBy2SzSwKPACcDKwEPjKzV9390wqbzQX6u/suM7sC+E/g3GDdbnfvU8Nxi9Q7eVkNeObSYxjz8AwueuxDnrpkIH2+y5TVUj3R5G8mJKlHqpmzxwGb3b2TmY0B7uabnL1UOVsk8WSmJXPLyG6V2mYu28i5D8/gwekFXH9Kl0rr1m0r5NcvL2Dr7hIee285f/hhr7oMt16ozt0tBgAF7r7M3YuBicCoihu4+zR33xUszgBa12yYIoeH3Mw0nrl0IE3SUxj76EwWrNoa75AkfA6as4PlJ4Lnk4BhZhqELRI2Azs2Y3Sfljz0zjKWb9i5t93d+dXLC9hdUsbgTtm8PHcVW3eVxDHScDL3b7/3npn9CBjh7pcEyz8FBrr71QfY/n5grbv/LlguBT4mNhTjLnd/+QD7XQZcBpCbm9tv4sSJh/RGduzYQUZGOC54Uqy1oz7FumF3OX+YWUhhmdO1aZQNu53BrZI4uV3d3/2iPvVrXRg6dOhsd+8fr+9fnZxtZguCbVYGy0uBgUAGsBBYDGwDfuXu7x7g+3yvnA2J8XlVV1hiDUucoFhrypbCcm5+dzdlDpkpRkqkHLMIq3c6P+6cTI/sKL95v5AxXVIY0SGx7qCUCP36bTm7Ri/cM7MLgP7ACRWa27n7KjPrCEw1s0/cfWnVfd39YeBhgP79+/uJJ554SN97+vTpHOo+8aJYa0d9i3XAgF1c9cwctpaUQXI5LxYUce0Ph9C8Ud2Ola1v/Srfag3Q1t03mlk/4GUz6+Hu26pu+H1zNoTr8wpLrGGJExRrTWrVdRNvLFjL5l3FrFi1lpzsHM7MbsgNp3QhKRph8ur3eX99EXdeGCvPZizbyJsL1zK0a3NO7NI8bnEner9Wp0heBbSpsNw6aKvEzIYDtwInuHvRnnZ3XxV8XWZm04G+wD5FsohU1rZZQ14bPxiA5Rt2Mvyed7hvyhJ+N1rjyuRbVSdn79lmpZklAVnARo+dWiwCcPfZwRHmzsCsWo9aRL6zo9s33XtXpFjh2a/S+rGD2jP+2bkc8cvXSY4aJWWxUQRvffo1028YSkpShP+dv4Z5K7dwy8iuVBx9VVpWTpk7qUn7XhhY31WnSP4IyDezDsQS6xjgvIobmFlf4CFip+/WVWhvAuxy9yIzywaOI3ZRn4gcgvbZ6fxkQFue/fBLxg3uSIfs9HiHJInroDkbeBW4EPgA+BEw1d3dzHKATe5eFpz9yweW1V3oIlIbTuuVx+ZdxWzYUUxRaRl9WjfGzLh8wmxemLOSE7vkcOOkeewsLmNIfjZD8nN4f+kGrpgwh627SzCDJ382gCH5OfF+K3XqoEWyu5ea2dXAP4ndTugxd19oZncAs9z9VeCPxMayPR/897HnVm/dgIfMrJzYRYJ3VbnCWkSqafywTkyavZKLH/+QIfk5DO2aw0ldc+MdliSYaubsR4GnzKwA2ESskAY4HrjDzEqAcuByd99U9+9CRGpSNGKMHdS+Upu7c2TrLB6cXsD0z9dRWu7kZqbyX28u5qi2Tbhx0nwaN0xm3OAOPPrvL3hxzqq9RfLX2wpJiUZokp4Sh3dTd6o1JtndXwder9J2W4Xnww+w3/uAzg2L1IDmjdK458e9eeKD5bw0dxVPzVjBxce159bTupEUrc6NauRwUY2cXQics5/9XgBeqPUARSTuzIzxJ+Vz6ZOz+GrTbv7fKZ3JaZTKTS98wgWPzmTl5t089/NBDOjQlC837eKfC9dSXFpOuTun3/dvdhaV8tNB7eiel8l7BRtISYpwx6ie9WriEs24JxIiI3vlMbJXHqVl5fz+9UU89t4XfLB0I9kZqSRHjUuHdOTYTtnxDlNEREJgeLfmHNk6i13FZVx6fEciZvx1+lLmfrmF8we2ZUCH2DjnkT1bMGn2St5buoG1WwvZsKOI4zvn8Mi7yyh3aJSaxPaiUpo3SuPa4flxflc1R0WySAglRSPcdmZ3erTM5MkZK9hVXMqarYWc98hMTu6eS8usNLbsLuHi4zpoQhIREdkvM+PZS4/BjL0X5t0+qiePv/cFN43sune7wfnZZKQm8fr8Ncz9ags9W2XyxMVHs3LzbrbuLqFbXiY3PD+Pe6csplPzDL7YsIOZX2xidJ9WjO7bKrRHl1Uki4TY2f1ac3a/2Nw9hSVlPPyvZTz0zlKikdjVywXrdjB5/OBKVyqLiIjskZ5auRQ8oXMOJ3SufIFealKUYd2a8+LcVZSVO/ee2wczo03ThntvpfPb0T2Zt3ILVz0zB4C8rDSuf34eD0wv4D+Gd+aMXnlEQlYsq0gWqSfSkqNcMyyf8Sd1wsx4cc5KrntuHm8sWMvIXnnsKi6lrNxplJZYN5MXEZHEN7JnC175eDUtMtM4rVfePuvTU5N45MKjeWnuKs7q3ZIjctL558Kv+dNbi7nm2bk8MLWAU3vk0jEng6Fdm5PVIPH/FqlIFqln9hw1HtWnFQ9OX8r/f2sx2Y1SuebZuewqLuPW07pxTv/WOrosIiLVdkLn5uRmpnLl0CNISdr/xeIdstO57uTOe5dH9GzBKd1zmfzJGh6cVsD90wood+jZKpOXrjyurkL/zlQki9RT0Yhx3cmdufLpOZzztw9o27QhnXMbcOML85n40ZdcMqQjJ3fPJVl3xhARkYNokBJlxi3DDvkASyRinNW7JWf1bklRaRmT563h+ufn8eC0pfRO8Co0wcMTke9jRI8WDO2SQ3pqEnf+oBeNUpN4btZX/GVqAVc+PYcWmWmcN7Atp/ZowTuL1/Hukg2c2bsl5/TTkWYREans+/5dSE2Kcna/1vxryXr+MnUJvz4mtYYiqx0qkkXqsUjEePziAZXaxgxoyzn92zB10Tqe/GA597y1mHveWgxAi8w0bpw0n9fmreaWkd3o3jKz0r5FpWW4x8Y/i4iIfBe3n9WD95du5O4PC/ky8iljB7WjXbPEm0lWRbLIYSgaMU7unsvJ3XNZun4H7xds4NhO2XRols6EmSu46x+LOO2+d+mWl0ljK+S5VbP5atNuFq3dRmpSlDtG9eAHfVvtPapQXu4s27CTjtnpobt6WURE6lbjhilMGDeQX098jyfeX87TM1dw35i+nNKjRbxDq0RFsshh7oicDI7Iydi7PHZQe844siWT56/mpbmrKFhfTuPSHeQ0SmXc4I7MWbGZ656bx2vzVtMhO4PdJWVMW7SOtdsKueCYtvx2VE8N1RARkW/VpUUjruyTRpe+A7liwhx+PmE2t53RnYuObb/P35Di0nKSo1bnf1tUJIvIPpqmpzB2UHvGDmrP9OnTOfHEE/auKyt3HpxWwFMzVjBr+WYABh3RjIEpTZkw40s6Zmdw0bHt+WztNlKTIhyRk6GiWURE9isvqwHPXnoM106cy+2vfconq7byu9E9aZiSxLrthTz0zjKenrmC8wa047YzuwOwZVcxxWXlNG+UVquxqUgWkUMSjRjjh+UzfljlqUfLy53dxWX89n8/5f5pBWzaWQxAdkYKuZlprNteRGFJGXlZaeQ3b8T1p3SmY04G5eXOvJVb6JiTsfe+mVt3lZCcZDRMUYoSEanvGqRE+esF/bh/agH3TlnMzGWbiERg5ebdGNC1RSaPvfcF/ds3Ib95Buc/MhMzePMXJ+z9u7G7uIwGKTV7vYz+AolIjYhEjHvH9OGG5+eTmhxhSH42JaXOjGUb2byrmF6tskhNirBmayHvLlnP2599zXkD2/LO4vUsW7+T1KQIw7vnsmF7ER8t30RacpQzj2zJsG6xm85HIsbarYVEI8aIHi009llEpB6JRoxrh+fTr10THpxeQLOMVM4+qjWj+7SiZeMG/PihD7hp0nySokY0YmzaUcxd/1jEH37Yi4kffsmfpyzh+csH0bpJwxqLSUWyiNSYhilJPHD+UZXafnx0m322W7etkF++tIDH31tOj5aZ3H12Lxau3sbk+WvIyUjl6qGd+HpbEa/OW83/zPpqn/3PPqo1d5/diyTd41lEpF4ZnJ/N4PzsfdrvP68vp9/3bxqmJPH0JQN5euYK/v7uFxSXlvPCnJWc0DmHpukpNRqLimQRqXPNM9P4+9h+rN9eRE6j1L1jlu8Y1bPSdr86oxvL1u9ke2EpZe60yEzj9U/W8OcpS9i6u4Sj2jVmy64SUpMiZKYlk7KtLB5vR0REalnrJg158xfHk5YcJatBMr84uTNvLFzLC3NWMrpPS/54Tu8anxxLRbKIxIWZ0Tzz2y+6aJSWTO82jSu1dWnRiEZpSdz5+me8/dnXpCZFKCkrp9xj699eP5OfHtOO4zvn6H7OIiL1SG6FvxkNU5J4+Kf9mbViM+cPaFsrQ/BUJItI6FwypCPn9G9DSjRCg5Qo7s6mncXc9dw7vLNmO5c9NZuGKVFO7dGCS4d0pHvLTNydr7cVsWzDDtZvL+K4TtlkZyT2bE8iInJg3fIy6ZaXefANvyMVySISSnuuaIbYUelmGamc3jGF3194PDOWbeQfC9byytxVvDR3FR1z0lm7tZBdxd8Mx0iOGqf2aEH3lplkNUimU04Gvds01tFnEREBVCSLSD2THI0wJD+HIfk53HRqVybMXMHcLzdzYufmdMhJp2N2OhmpSbzy8WpenLuSyfPXVNjXaJqeQkmZ06pxA14bPziO70REROJJRbKI1FtZDZO5amin/a7r3aYxt53ZncKSMjbvKmbhqm18tGJT7B7N0QjNG2kohojI4UxFsogc1tKSo+RlNSAvqwHDu+fGOxwREUkQusmoiIiIiEgVKpJFRERERKpQkSwiIiIiUoWKZBERERGRKlQki4iIiIhUoSJZRERERKQKFckiIiIiIlWoSBYRERERqUJFsoiIiIhIFSqSRURERESqqFaRbGYjzOxzMysws5v3sz7VzP4nWD/TzNpXWHdL0P65mZ1ac6GLiMj+KGeLiHx/By2SzSwKPACMBLoDPzGz7lU2GwdsdvdOwJ+Au4N9uwNjgB7ACODB4PVERKQWKGeLiNSM6hxJHgAUuPsydy8GJgKjqmwzCngieD4JGGZmFrRPdPcid/8CKAheT0REaodytohIDahOkdwK+KrC8sqgbb/buHspsBVoVs19RUSk5ihni4jUgKR4B7CHmV0GXBYs7jCzzw/xJbKBDTUbVa1RrLVDsdYOxXpo2sX5+9eJGsjZkBifV3WFJdawxAmKtbYo1kNzwJxdnSJ5FdCmwnLroG1/26w0syQgC9hYzX0BcPeHgYerEc9+mdksd+//XfevS4q1dijW2qFYQycUORvC9XmFJdawxAmKtbYo1ppTneEWHwH5ZtbBzFKIXdTxapVtXgUuDJ7/CJjq7h60jwmupO4A5AMf1kzoIiKyH8rZIiI14KBHkt291MyuBv4JRIHH3H2hmd0BzHL3V4FHgafMrADYRCwpE2z3HPApUApc5e5ltfReREQOe8rZIiI1o1pjkt39deD1Km23VXheCJxzgH3vBO78HjFW1/c67VfHFGvtUKy1Q7GGTEhyNoTr8wpLrGGJExRrbVGsNcRiZ9hERERERGQPTUstIiIiIlJFvSiSDzYFazyZWRszm2Zmn5rZQjO7NmhvamZvmdmS4GuTeMcKsdm6zGyumU0OljsE09YWBNPYpsQ7xj3MrLGZTTKzRWb2mZkNSsR+NbNfBJ/9AjN71szSEqlfzewxM1tnZgsqtO23Hy3mviDu+WZ2VJzj/GPw+c83s5fMrHGFdZpeOUEpZ9essOTtsORsSOy8HZac/S2xhiZvh75ItupNwRpPpcD17t4dOAa4KojvZmCKu+cDU4LlRHAt8FmF5buBPwXT124mNp1tovgz8Ia7dwV6E4s7ofrVzFoB1wD93b0nsQupxpBY/frfxKYgruhA/TiS2B0P8ondI/evdRQj7D/Ot4Ce7n4ksBi4BTS9ciJTzq4VYcnbCZ+zIRR5+78JR86GkOft0BfJVG8K1rhx9zXuPid4vp1YUmhF5WlhnwBGxyfCb5hZa+B04JFg2YCTiE1bCwkSJ4CZZQHHE7tKH3cvdvctJGC/ErtAtoHF7kfbEFhDAvWru/+L2B0OKjpQP44CnvSYGUBjM8uLV5zu/mYwYxzADGL39d0Tp6ZXTkzK2TUoLHk7ZDkbEjhvhyVnQ/jzdn0okkMzjaqZtQf6AjOBXHdfE6xaC+TGKayK7gVuBMqD5WbAlgo/zInUtx2A9cDjwWnGR8wsnQTrV3dfBfwX8CWxJLsVmE3i9useB+rHRP59+xnwj+B5Isd5uAvNZxOCnA3hyduhyNkQ2rwdxpwNCZ6360ORHApmlgG8APyHu2+ruC64iX9cbzNiZmcA69x9djzjOARJwFHAX929L7CTKqfpEqRfmxD777gD0BJIZ99TTwktEfrxYMzsVmKnyZ+OdyxSPyR6zobQ5e1Q5GwIf95OlH48mDDk7fpQJFd7GtV4MbNkYsn2aXd/MWj+es8pj+DrunjFFzgOOMvMlhM7/XkSsfFjjYPTTZBYfbsSWOnuM4PlScQScKL163DgC3df7+4lwIvE+jpR+3WPA/Vjwv2+mdlFwBnA+f7NPS0TLk7ZK+E/m5DkbAhX3g5LzoZw5u3Q5GwIT96uD0VydaZgjZtgfNijwGfufk+FVRWnhb0QeKWuY6vI3W9x99bu3p5YH0519/OBacSmrYUEiHMPd18LfGVmXYKmYcRmCUuofiV2uu4YM2sY/CzsiTMh+7WCA/Xjq8DY4IrpY4CtFU7x1TkzG0HsVPNZ7r6rwipNr5y4lLNrSJjydohyNoQzb4ciZ0PI8ra7h/4BnEbsCsmlwK3xjqdKbIOJnfaYD3wcPE4jNm5sCrAEeBtoGu9YK8R8IjA5eN6R2A9pAfA8kBrv+CrE2QeYFfTty0CTROxX4HZgEbAAeApITaR+BZ4lNu6uhNjRnnEH6kfAiN2ZYCnwCbGrv+MZZwGxMWx7frf+VmH7W4M4PwdGxvvnQI9Kn6Vyds3HnfB5Oyw5O4g1YfN2WHL2t8QamrytGfdERERERKqoD8MtRERERERqlIpkEREREZEqVCSLiIiIiFShIllEREREpAoVySIiIiIiVahIllAxszIz+7jC4+aD71Xt125vZgtq6vVERA53ytkSZkkH30Qkoex29z7xDkJERKpFOVtCS0eSpV4ws+Vm9p9m9omZfWhmnYL29mY21czmm9kUM2sbtOea2UtmNi94HBu8VNTM/m5mC83sTTNrEGx/jZl9GrzOxDi9TRGRekE5W8JARbKETYMqp+7OrbBuq7v3Au4H7g3a/gI84e5HAk8D9wXt9wHvuHtv4ChgYdCeDzzg7j2ALcDZQfvNQN/gdS6vrTcnIlLPKGdLaGnGPQkVM9vh7hn7aV8OnOTuy8wsGVjr7s3MbAOQ5+4lQfsad882s/VAa3cvqvAa7YG33D0/WL4JSHb335nZG8AOYlOpvuzuO2r5rYqIhJ5ytoSZjiRLfeIHeH4oiio8L+ObcfunAw8QO4LxkZlpPL+IyPejnC0JTUWy1CfnVvj6QfD8fWBM8Px84N3g+RTgCgAzi5pZ1oFe1MwiQBt3nwbcBGQB+xwZERGRQ6KcLQlN/1lJ2DQws48rLL/h7ntuKdTEzOYTO7Lwk6BtPPC4md0ArAcuDtqvBR42s3HEjj5cAaw5wPeMAhOCpGzAfe6+pcbekYhI/aWcLaGlMclSLwTj2/q7+4Z4xyIiIt9OOVvCQMMtRERERESq0JFkEREREZEqdCRZRERERKQKFckiIiIiIlWoSBYRERERqUJFsoiIiIhIFSqSRURERESqUJEsIiIiIlLF/wF3sZFaPIAyrgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3PeG4ir4ZaK",
        "outputId": "2ff5ae76-b4ee-4e6c-d73d-07f72e79f552"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9168000221252441"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKjOwC70x-LH",
        "outputId": "44129f5c-8967-460c-c7af-ae7d2574f923"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08319997787475586"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cP6RpFPvdW8"
      },
      "source": [
        "#### Model with clippting to 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87eLjhYJviSV",
        "outputId": "e3ccba57-7752-4fca-c1be-df6f5719c829"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkSUTPVYvodK",
        "outputId": "a9e4c5fe-ac82-4336-e9c7-52ca09cb7ebb"
      },
      "source": [
        "callbacks = functions.standard_callbacks(model_type) + [functions.Clipping(1, \"simple\", False)]\n",
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'simple_trainHistoryDict_clip_1', steps_per_epoch=100, epochs=650,\n",
        "                       batch_size=100,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 44s 89ms/step - loss: 2.1915 - acc: 0.3245 - val_loss: 3.1123 - val_acc: 0.1626\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.16260, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.7038 - acc: 0.3971 - val_loss: 3.9554 - val_acc: 0.1021\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.16260\n",
            "Epoch 3/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.4968 - acc: 0.4774 - val_loss: 2.9984 - val_acc: 0.1460\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.16260\n",
            "Epoch 4/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.3743 - acc: 0.5235 - val_loss: 1.5800 - val_acc: 0.4531\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.16260 to 0.45310, saving model to /content/saved_models/cifar10_ResNet32v1_model.004.h5\n",
            "Epoch 5/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.2835 - acc: 0.5663 - val_loss: 2.7744 - val_acc: 0.3587\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.45310\n",
            "Epoch 6/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.2100 - acc: 0.5913 - val_loss: 2.4733 - val_acc: 0.3964\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.45310\n",
            "Epoch 7/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 1.1470 - acc: 0.6159 - val_loss: 2.7936 - val_acc: 0.3233\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.45310\n",
            "Epoch 8/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.1048 - acc: 0.6322 - val_loss: 3.1713 - val_acc: 0.3146\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.45310\n",
            "Epoch 9/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.0581 - acc: 0.6445 - val_loss: 3.9229 - val_acc: 0.2918\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.45310\n",
            "Epoch 10/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.9917 - acc: 0.6717 - val_loss: 2.0693 - val_acc: 0.4641\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.45310 to 0.46410, saving model to /content/saved_models/cifar10_ResNet32v1_model.010.h5\n",
            "Epoch 11/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.9649 - acc: 0.6811 - val_loss: 2.1549 - val_acc: 0.4767\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.46410 to 0.47670, saving model to /content/saved_models/cifar10_ResNet32v1_model.011.h5\n",
            "Epoch 12/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.9366 - acc: 0.6878 - val_loss: 5.1154 - val_acc: 0.2415\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.47670\n",
            "Epoch 13/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.9295 - acc: 0.6967 - val_loss: 2.2774 - val_acc: 0.4418\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.47670\n",
            "Epoch 14/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.9021 - acc: 0.7049 - val_loss: 1.8256 - val_acc: 0.5439\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.47670 to 0.54390, saving model to /content/saved_models/cifar10_ResNet32v1_model.014.h5\n",
            "Epoch 15/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.8902 - acc: 0.7096 - val_loss: 4.5059 - val_acc: 0.2920\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.54390\n",
            "Epoch 16/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.8895 - acc: 0.7085 - val_loss: 3.2441 - val_acc: 0.3640\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.54390\n",
            "Epoch 17/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.8344 - acc: 0.7277 - val_loss: 1.7076 - val_acc: 0.5268\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.54390\n",
            "Epoch 18/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8313 - acc: 0.7279 - val_loss: 1.2663 - val_acc: 0.6295\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.54390 to 0.62950, saving model to /content/saved_models/cifar10_ResNet32v1_model.018.h5\n",
            "Epoch 19/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.8054 - acc: 0.7394 - val_loss: 1.8263 - val_acc: 0.5710\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.62950\n",
            "Epoch 20/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.8151 - acc: 0.7313 - val_loss: 2.2871 - val_acc: 0.4949\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.62950\n",
            "Epoch 21/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.8064 - acc: 0.7379 - val_loss: 1.3624 - val_acc: 0.5965\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.62950\n",
            "Epoch 22/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7946 - acc: 0.7372 - val_loss: 2.2745 - val_acc: 0.4841\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.62950\n",
            "Epoch 23/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7761 - acc: 0.7494 - val_loss: 3.5201 - val_acc: 0.3967\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.62950\n",
            "Epoch 24/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7665 - acc: 0.7548 - val_loss: 2.2866 - val_acc: 0.5212\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.62950\n",
            "Epoch 25/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7818 - acc: 0.7452 - val_loss: 1.3493 - val_acc: 0.6314\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.62950 to 0.63140, saving model to /content/saved_models/cifar10_ResNet32v1_model.025.h5\n",
            "Epoch 26/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7566 - acc: 0.7549 - val_loss: 3.8481 - val_acc: 0.4317\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.63140\n",
            "Epoch 27/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.7570 - acc: 0.7584 - val_loss: 0.9901 - val_acc: 0.6850\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.63140 to 0.68500, saving model to /content/saved_models/cifar10_ResNet32v1_model.027.h5\n",
            "Epoch 28/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.7437 - acc: 0.7628 - val_loss: 2.2161 - val_acc: 0.4331\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.68500\n",
            "Epoch 29/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.7293 - acc: 0.7632 - val_loss: 1.9046 - val_acc: 0.5635\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.68500\n",
            "Epoch 30/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.7457 - acc: 0.7558 - val_loss: 1.2401 - val_acc: 0.6517\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.68500\n",
            "Epoch 31/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.7222 - acc: 0.7663 - val_loss: 1.8404 - val_acc: 0.5406\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.68500\n",
            "Epoch 32/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7139 - acc: 0.7696 - val_loss: 1.9381 - val_acc: 0.5624\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.68500\n",
            "Epoch 33/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6986 - acc: 0.7776 - val_loss: 1.6804 - val_acc: 0.5873\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.68500\n",
            "Epoch 34/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7012 - acc: 0.7721 - val_loss: 1.2603 - val_acc: 0.6576\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.68500\n",
            "Epoch 35/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6870 - acc: 0.7799 - val_loss: 1.9586 - val_acc: 0.5384\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.68500\n",
            "Epoch 36/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7063 - acc: 0.7759 - val_loss: 1.3815 - val_acc: 0.6220\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.68500\n",
            "Epoch 37/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6770 - acc: 0.7849 - val_loss: 1.6627 - val_acc: 0.5676\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.68500\n",
            "Epoch 38/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6974 - acc: 0.7712 - val_loss: 0.8713 - val_acc: 0.7373\n",
            "\n",
            "Epoch 00038: val_acc improved from 0.68500 to 0.73730, saving model to /content/saved_models/cifar10_ResNet32v1_model.038.h5\n",
            "Epoch 39/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6960 - acc: 0.7749 - val_loss: 1.4762 - val_acc: 0.6350\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.73730\n",
            "Epoch 40/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6726 - acc: 0.7837 - val_loss: 1.1856 - val_acc: 0.6466\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.73730\n",
            "Epoch 41/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6567 - acc: 0.7869 - val_loss: 1.0165 - val_acc: 0.6987\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.73730\n",
            "Epoch 42/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6759 - acc: 0.7842 - val_loss: 1.3061 - val_acc: 0.6155\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.73730\n",
            "Epoch 43/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6439 - acc: 0.7936 - val_loss: 1.7368 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.73730\n",
            "Epoch 44/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6424 - acc: 0.7968 - val_loss: 1.0727 - val_acc: 0.6701\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.73730\n",
            "Epoch 45/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6553 - acc: 0.7944 - val_loss: 1.4389 - val_acc: 0.6155\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.73730\n",
            "Epoch 46/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6372 - acc: 0.7961 - val_loss: 1.2417 - val_acc: 0.6465\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.73730\n",
            "Epoch 47/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6385 - acc: 0.7954 - val_loss: 2.5825 - val_acc: 0.4914\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.73730\n",
            "Epoch 48/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6504 - acc: 0.7928 - val_loss: 1.6776 - val_acc: 0.5606\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.73730\n",
            "Epoch 49/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6474 - acc: 0.7950 - val_loss: 2.0889 - val_acc: 0.5533\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.73730\n",
            "Epoch 50/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6354 - acc: 0.7999 - val_loss: 2.5535 - val_acc: 0.4961\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.73730\n",
            "Epoch 51/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6346 - acc: 0.7989 - val_loss: 0.9527 - val_acc: 0.7145\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.73730\n",
            "Epoch 52/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6175 - acc: 0.8043 - val_loss: 1.7692 - val_acc: 0.5790\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.73730\n",
            "Epoch 53/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6408 - acc: 0.7986 - val_loss: 1.3473 - val_acc: 0.6416\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.73730\n",
            "Epoch 54/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6138 - acc: 0.8057 - val_loss: 1.5096 - val_acc: 0.6150\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.73730\n",
            "Epoch 55/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6224 - acc: 0.8016 - val_loss: 2.2022 - val_acc: 0.5637\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.73730\n",
            "Epoch 56/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6262 - acc: 0.7996 - val_loss: 2.6315 - val_acc: 0.4931\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.73730\n",
            "Epoch 57/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6087 - acc: 0.8102 - val_loss: 1.5223 - val_acc: 0.6057\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.73730\n",
            "Epoch 58/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6017 - acc: 0.8115 - val_loss: 0.8329 - val_acc: 0.7511\n",
            "\n",
            "Epoch 00058: val_acc improved from 0.73730 to 0.75110, saving model to /content/saved_models/cifar10_ResNet32v1_model.058.h5\n",
            "Epoch 59/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6079 - acc: 0.8074 - val_loss: 1.2792 - val_acc: 0.6523\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.75110\n",
            "Epoch 60/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6134 - acc: 0.8058 - val_loss: 1.9177 - val_acc: 0.5544\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.75110\n",
            "Epoch 61/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6234 - acc: 0.8032 - val_loss: 1.1557 - val_acc: 0.6804\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.75110\n",
            "Epoch 62/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5911 - acc: 0.8202 - val_loss: 1.5411 - val_acc: 0.6552\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.75110\n",
            "Epoch 63/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5982 - acc: 0.8101 - val_loss: 2.5360 - val_acc: 0.4439\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.75110\n",
            "Epoch 64/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6012 - acc: 0.8107 - val_loss: 1.2493 - val_acc: 0.6425\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.75110\n",
            "Epoch 65/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6070 - acc: 0.8081 - val_loss: 1.5285 - val_acc: 0.6050\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.75110\n",
            "Epoch 66/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5849 - acc: 0.8157 - val_loss: 1.5671 - val_acc: 0.5682\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.75110\n",
            "Epoch 67/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5836 - acc: 0.8158 - val_loss: 1.4032 - val_acc: 0.6316\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.75110\n",
            "Epoch 68/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6018 - acc: 0.8094 - val_loss: 0.9646 - val_acc: 0.7232\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.75110\n",
            "Epoch 69/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6090 - acc: 0.8073 - val_loss: 1.5588 - val_acc: 0.6165\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.75110\n",
            "Epoch 70/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5939 - acc: 0.8106 - val_loss: 1.8107 - val_acc: 0.5913\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.75110\n",
            "Epoch 71/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5993 - acc: 0.8113 - val_loss: 1.7813 - val_acc: 0.5626\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.75110\n",
            "Epoch 72/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5745 - acc: 0.8186 - val_loss: 3.1161 - val_acc: 0.4556\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.75110\n",
            "Epoch 73/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5843 - acc: 0.8171 - val_loss: 0.8686 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.75110\n",
            "Epoch 74/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5824 - acc: 0.8195 - val_loss: 1.4228 - val_acc: 0.6493\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.75110\n",
            "Epoch 75/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5767 - acc: 0.8176 - val_loss: 0.9872 - val_acc: 0.7266\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.75110\n",
            "Epoch 76/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5736 - acc: 0.8232 - val_loss: 0.8398 - val_acc: 0.7553\n",
            "\n",
            "Epoch 00076: val_acc improved from 0.75110 to 0.75530, saving model to /content/saved_models/cifar10_ResNet32v1_model.076.h5\n",
            "Epoch 77/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5656 - acc: 0.8229 - val_loss: 1.3518 - val_acc: 0.6345\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.75530\n",
            "Epoch 78/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5642 - acc: 0.8249 - val_loss: 1.3826 - val_acc: 0.6488\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.75530\n",
            "Epoch 79/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5716 - acc: 0.8233 - val_loss: 0.9401 - val_acc: 0.7256\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.75530\n",
            "Epoch 80/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.5659 - acc: 0.8225 - val_loss: 1.1681 - val_acc: 0.6918\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.75530\n",
            "Epoch 81/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5632 - acc: 0.8229 - val_loss: 1.8773 - val_acc: 0.5397\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.75530\n",
            "Epoch 82/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5612 - acc: 0.8240 - val_loss: 1.3316 - val_acc: 0.6552\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.75530\n",
            "Epoch 83/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5805 - acc: 0.8158 - val_loss: 0.7551 - val_acc: 0.7790\n",
            "\n",
            "Epoch 00083: val_acc improved from 0.75530 to 0.77900, saving model to /content/saved_models/cifar10_ResNet32v1_model.083.h5\n",
            "Epoch 84/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5681 - acc: 0.8225 - val_loss: 2.5988 - val_acc: 0.4264\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.77900\n",
            "Epoch 85/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5543 - acc: 0.8291 - val_loss: 2.3483 - val_acc: 0.5353\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.77900\n",
            "Epoch 86/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5637 - acc: 0.8265 - val_loss: 2.1559 - val_acc: 0.5005\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.77900\n",
            "Epoch 87/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5413 - acc: 0.8305 - val_loss: 1.1209 - val_acc: 0.7022\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.77900\n",
            "Epoch 88/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5496 - acc: 0.8269 - val_loss: 0.8449 - val_acc: 0.7468\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.77900\n",
            "Epoch 89/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5679 - acc: 0.8190 - val_loss: 1.1787 - val_acc: 0.6845\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.77900\n",
            "Epoch 90/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5517 - acc: 0.8308 - val_loss: 1.1957 - val_acc: 0.6754\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.77900\n",
            "Epoch 91/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5546 - acc: 0.8248 - val_loss: 1.0950 - val_acc: 0.6787\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.77900\n",
            "Epoch 92/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5467 - acc: 0.8339 - val_loss: 0.8062 - val_acc: 0.7636\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.77900\n",
            "Epoch 93/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5560 - acc: 0.8237 - val_loss: 1.0014 - val_acc: 0.7250\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.77900\n",
            "Epoch 94/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5475 - acc: 0.8297 - val_loss: 2.5387 - val_acc: 0.5029\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.77900\n",
            "Epoch 95/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5471 - acc: 0.8269 - val_loss: 0.9667 - val_acc: 0.7057\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.77900\n",
            "Epoch 96/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5579 - acc: 0.8283 - val_loss: 1.4235 - val_acc: 0.6685\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.77900\n",
            "Epoch 97/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5402 - acc: 0.8295 - val_loss: 3.1014 - val_acc: 0.4547\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.77900\n",
            "Epoch 98/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5376 - acc: 0.8328 - val_loss: 1.8908 - val_acc: 0.5437\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.77900\n",
            "Epoch 99/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5387 - acc: 0.8337 - val_loss: 2.5365 - val_acc: 0.4586\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.77900\n",
            "Epoch 100/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5485 - acc: 0.8292 - val_loss: 1.5808 - val_acc: 0.6101\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.77900\n",
            "Epoch 101/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5311 - acc: 0.8364 - val_loss: 1.2823 - val_acc: 0.6687\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.77900\n",
            "Epoch 102/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5347 - acc: 0.8338 - val_loss: 1.2891 - val_acc: 0.6514\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.77900\n",
            "Epoch 103/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5453 - acc: 0.8276 - val_loss: 1.3166 - val_acc: 0.6813\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.77900\n",
            "Epoch 104/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5130 - acc: 0.8399 - val_loss: 1.3393 - val_acc: 0.6287\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.77900\n",
            "Epoch 105/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5343 - acc: 0.8346 - val_loss: 1.7081 - val_acc: 0.5640\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.77900\n",
            "Epoch 106/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5282 - acc: 0.8320 - val_loss: 1.0121 - val_acc: 0.6925\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.77900\n",
            "Epoch 107/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5377 - acc: 0.8314 - val_loss: 1.1058 - val_acc: 0.6955\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.77900\n",
            "Epoch 108/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5423 - acc: 0.8341 - val_loss: 0.8720 - val_acc: 0.7442\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.77900\n",
            "Epoch 109/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5177 - acc: 0.8402 - val_loss: 0.9196 - val_acc: 0.7409\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.77900\n",
            "Epoch 110/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5352 - acc: 0.8317 - val_loss: 1.1121 - val_acc: 0.6914\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.77900\n",
            "Epoch 111/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5318 - acc: 0.8325 - val_loss: 1.1489 - val_acc: 0.6792\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.77900\n",
            "Epoch 112/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5185 - acc: 0.8376 - val_loss: 1.1084 - val_acc: 0.7145\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.77900\n",
            "Epoch 113/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5304 - acc: 0.8368 - val_loss: 1.6864 - val_acc: 0.6128\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.77900\n",
            "Epoch 114/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5226 - acc: 0.8377 - val_loss: 1.3162 - val_acc: 0.6321\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.77900\n",
            "Epoch 115/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5310 - acc: 0.8370 - val_loss: 0.9324 - val_acc: 0.7124\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.77900\n",
            "Epoch 116/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4980 - acc: 0.8464 - val_loss: 1.2399 - val_acc: 0.6610\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.77900\n",
            "Epoch 117/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5266 - acc: 0.8377 - val_loss: 1.3970 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.77900\n",
            "Epoch 118/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5245 - acc: 0.8354 - val_loss: 1.5120 - val_acc: 0.6442\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.77900\n",
            "Epoch 119/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5155 - acc: 0.8393 - val_loss: 1.0031 - val_acc: 0.7255\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.77900\n",
            "Epoch 120/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5200 - acc: 0.8377 - val_loss: 1.5945 - val_acc: 0.6044\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.77900\n",
            "Epoch 121/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5258 - acc: 0.8400 - val_loss: 1.6199 - val_acc: 0.6070\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.77900\n",
            "Epoch 122/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5224 - acc: 0.8412 - val_loss: 0.9172 - val_acc: 0.7335\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.77900\n",
            "Epoch 123/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5207 - acc: 0.8357 - val_loss: 1.7093 - val_acc: 0.6215\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.77900\n",
            "Epoch 124/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5152 - acc: 0.8391 - val_loss: 1.3538 - val_acc: 0.6696\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.77900\n",
            "Epoch 125/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5308 - acc: 0.8351 - val_loss: 1.0827 - val_acc: 0.7048\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.77900\n",
            "Epoch 126/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4817 - acc: 0.8464 - val_loss: 0.9302 - val_acc: 0.7377\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.77900\n",
            "Epoch 127/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5253 - acc: 0.8373 - val_loss: 1.1896 - val_acc: 0.6792\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.77900\n",
            "Epoch 128/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5064 - acc: 0.8395 - val_loss: 1.2314 - val_acc: 0.6774\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.77900\n",
            "Epoch 129/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5201 - acc: 0.8398 - val_loss: 1.4405 - val_acc: 0.6484\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.77900\n",
            "Epoch 130/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5098 - acc: 0.8401 - val_loss: 0.9085 - val_acc: 0.7415\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.77900\n",
            "Epoch 131/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.4967 - acc: 0.8494 - val_loss: 1.4224 - val_acc: 0.6267\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.77900\n",
            "Epoch 132/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5050 - acc: 0.8433 - val_loss: 1.3444 - val_acc: 0.6260\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.77900\n",
            "Epoch 133/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5090 - acc: 0.8434 - val_loss: 0.9129 - val_acc: 0.7432\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.77900\n",
            "Epoch 134/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5113 - acc: 0.8426 - val_loss: 1.0305 - val_acc: 0.7166\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.77900\n",
            "Epoch 135/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5167 - acc: 0.8422 - val_loss: 0.9976 - val_acc: 0.7093\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.77900\n",
            "Epoch 136/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4970 - acc: 0.8469 - val_loss: 0.9806 - val_acc: 0.7028\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.77900\n",
            "Epoch 137/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5113 - acc: 0.8444 - val_loss: 1.0060 - val_acc: 0.7061\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.77900\n",
            "Epoch 138/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5030 - acc: 0.8444 - val_loss: 1.9637 - val_acc: 0.5427\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.77900\n",
            "Epoch 139/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4940 - acc: 0.8465 - val_loss: 2.3553 - val_acc: 0.5090\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.77900\n",
            "Epoch 140/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4974 - acc: 0.8457 - val_loss: 1.1705 - val_acc: 0.7027\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.77900\n",
            "Epoch 141/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5035 - acc: 0.8434 - val_loss: 1.9707 - val_acc: 0.5116\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.77900\n",
            "Epoch 142/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5093 - acc: 0.8429 - val_loss: 0.9431 - val_acc: 0.7232\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.77900\n",
            "Epoch 143/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5097 - acc: 0.8454 - val_loss: 0.8399 - val_acc: 0.7506\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.77900\n",
            "Epoch 144/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5110 - acc: 0.8411 - val_loss: 1.0974 - val_acc: 0.6917\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.77900\n",
            "Epoch 145/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4954 - acc: 0.8485 - val_loss: 0.8027 - val_acc: 0.7559\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.77900\n",
            "Epoch 146/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4980 - acc: 0.8462 - val_loss: 1.7861 - val_acc: 0.5840\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.77900\n",
            "Epoch 147/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4925 - acc: 0.8504 - val_loss: 0.7138 - val_acc: 0.7846\n",
            "\n",
            "Epoch 00147: val_acc improved from 0.77900 to 0.78460, saving model to /content/saved_models/cifar10_ResNet32v1_model.147.h5\n",
            "Epoch 148/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4839 - acc: 0.8551 - val_loss: 1.4740 - val_acc: 0.5883\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.78460\n",
            "Epoch 149/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5023 - acc: 0.8463 - val_loss: 0.9250 - val_acc: 0.7424\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.78460\n",
            "Epoch 150/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5081 - acc: 0.8447 - val_loss: 0.9022 - val_acc: 0.7491\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.78460\n",
            "Epoch 151/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4939 - acc: 0.8478 - val_loss: 1.1849 - val_acc: 0.6925\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.78460\n",
            "Epoch 152/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4973 - acc: 0.8443 - val_loss: 1.3806 - val_acc: 0.6692\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.78460\n",
            "Epoch 153/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.4929 - acc: 0.8492 - val_loss: 0.8741 - val_acc: 0.7464\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.78460\n",
            "Epoch 154/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5001 - acc: 0.8468 - val_loss: 1.9777 - val_acc: 0.5243\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.78460\n",
            "Epoch 155/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4982 - acc: 0.8487 - val_loss: 1.0240 - val_acc: 0.7049\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.78460\n",
            "Epoch 156/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4936 - acc: 0.8495 - val_loss: 1.2967 - val_acc: 0.6723\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.78460\n",
            "Epoch 157/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4970 - acc: 0.8473 - val_loss: 1.6215 - val_acc: 0.6389\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.78460\n",
            "Epoch 158/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4712 - acc: 0.8563 - val_loss: 1.3721 - val_acc: 0.6375\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.78460\n",
            "Epoch 159/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4856 - acc: 0.8478 - val_loss: 1.0570 - val_acc: 0.7121\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.78460\n",
            "Epoch 160/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4948 - acc: 0.8466 - val_loss: 1.0517 - val_acc: 0.7037\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.78460\n",
            "Epoch 161/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5007 - acc: 0.8470 - val_loss: 1.3510 - val_acc: 0.6502\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.78460\n",
            "Epoch 162/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4971 - acc: 0.8437 - val_loss: 1.3067 - val_acc: 0.6562\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.78460\n",
            "Epoch 163/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4802 - acc: 0.8545 - val_loss: 1.0178 - val_acc: 0.6840\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.78460\n",
            "Epoch 164/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4917 - acc: 0.8515 - val_loss: 1.0506 - val_acc: 0.6897\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.78460\n",
            "Epoch 165/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4908 - acc: 0.8492 - val_loss: 0.9739 - val_acc: 0.7315\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.78460\n",
            "Epoch 166/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4789 - acc: 0.8557 - val_loss: 1.3319 - val_acc: 0.6847\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.78460\n",
            "Epoch 167/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4931 - acc: 0.8471 - val_loss: 1.5462 - val_acc: 0.6384\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.78460\n",
            "Epoch 168/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4877 - acc: 0.8484 - val_loss: 0.7917 - val_acc: 0.7601\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.78460\n",
            "Epoch 169/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4751 - acc: 0.8534 - val_loss: 0.7850 - val_acc: 0.7587\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.78460\n",
            "Epoch 170/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4990 - acc: 0.8495 - val_loss: 2.5693 - val_acc: 0.5454\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.78460\n",
            "Epoch 171/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4960 - acc: 0.8452 - val_loss: 0.7824 - val_acc: 0.7559\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.78460\n",
            "Epoch 172/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4878 - acc: 0.8456 - val_loss: 0.7889 - val_acc: 0.7787\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.78460\n",
            "Epoch 173/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4888 - acc: 0.8504 - val_loss: 1.0280 - val_acc: 0.6941\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.78460\n",
            "Epoch 174/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4916 - acc: 0.8477 - val_loss: 3.4021 - val_acc: 0.4237\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.78460\n",
            "Epoch 175/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4688 - acc: 0.8555 - val_loss: 1.0870 - val_acc: 0.7008\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.78460\n",
            "Epoch 176/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4849 - acc: 0.8521 - val_loss: 1.2550 - val_acc: 0.6553\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.78460\n",
            "Epoch 177/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4667 - acc: 0.8574 - val_loss: 0.9293 - val_acc: 0.7484\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.78460\n",
            "Epoch 178/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4600 - acc: 0.8580 - val_loss: 1.0178 - val_acc: 0.7225\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.78460\n",
            "Epoch 179/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4709 - acc: 0.8557 - val_loss: 1.8144 - val_acc: 0.5872\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.78460\n",
            "Epoch 180/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4812 - acc: 0.8514 - val_loss: 0.7413 - val_acc: 0.7724\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.78460\n",
            "Epoch 181/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4632 - acc: 0.8542 - val_loss: 1.2069 - val_acc: 0.6913\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.78460\n",
            "Epoch 182/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4847 - acc: 0.8530 - val_loss: 1.2165 - val_acc: 0.6757\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.78460\n",
            "Epoch 183/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4941 - acc: 0.8500 - val_loss: 1.1172 - val_acc: 0.6779\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.78460\n",
            "Epoch 184/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4757 - acc: 0.8535 - val_loss: 1.2211 - val_acc: 0.6838\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.78460\n",
            "Epoch 185/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4845 - acc: 0.8507 - val_loss: 0.9631 - val_acc: 0.7376\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.78460\n",
            "Epoch 186/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4735 - acc: 0.8568 - val_loss: 1.2887 - val_acc: 0.6698\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.78460\n",
            "Epoch 187/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4730 - acc: 0.8566 - val_loss: 0.9591 - val_acc: 0.7298\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.78460\n",
            "Epoch 188/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4637 - acc: 0.8557 - val_loss: 0.7249 - val_acc: 0.7856\n",
            "\n",
            "Epoch 00188: val_acc improved from 0.78460 to 0.78560, saving model to /content/saved_models/cifar10_ResNet32v1_model.188.h5\n",
            "Epoch 189/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4781 - acc: 0.8544 - val_loss: 1.4600 - val_acc: 0.6394\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.78560\n",
            "Epoch 190/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4655 - acc: 0.8584 - val_loss: 1.0824 - val_acc: 0.7138\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.78560\n",
            "Epoch 191/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4740 - acc: 0.8581 - val_loss: 1.1201 - val_acc: 0.6771\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.78560\n",
            "Epoch 192/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4700 - acc: 0.8591 - val_loss: 1.1155 - val_acc: 0.6961\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.78560\n",
            "Epoch 193/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4703 - acc: 0.8579 - val_loss: 1.0774 - val_acc: 0.6817\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.78560\n",
            "Epoch 194/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4719 - acc: 0.8554 - val_loss: 2.1547 - val_acc: 0.5169\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.78560\n",
            "Epoch 195/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4767 - acc: 0.8547 - val_loss: 0.8804 - val_acc: 0.7365\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.78560\n",
            "Epoch 196/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4745 - acc: 0.8509 - val_loss: 1.5457 - val_acc: 0.5921\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.78560\n",
            "Epoch 197/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4738 - acc: 0.8547 - val_loss: 1.1618 - val_acc: 0.6610\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.78560\n",
            "Epoch 198/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4599 - acc: 0.8619 - val_loss: 0.9076 - val_acc: 0.7505\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.78560\n",
            "Epoch 199/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4764 - acc: 0.8533 - val_loss: 1.5634 - val_acc: 0.6137\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.78560\n",
            "Epoch 200/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4751 - acc: 0.8566 - val_loss: 1.7147 - val_acc: 0.6171\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.78560\n",
            "Epoch 201/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4710 - acc: 0.8564 - val_loss: 1.0559 - val_acc: 0.7050\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.78560\n",
            "Epoch 202/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4693 - acc: 0.8574 - val_loss: 1.3996 - val_acc: 0.6652\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.78560\n",
            "Epoch 203/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4739 - acc: 0.8549 - val_loss: 0.8822 - val_acc: 0.7555\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.78560\n",
            "Epoch 204/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4579 - acc: 0.8611 - val_loss: 0.7998 - val_acc: 0.7628\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.78560\n",
            "Epoch 205/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4639 - acc: 0.8597 - val_loss: 1.7163 - val_acc: 0.6199\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.78560\n",
            "Epoch 206/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4786 - acc: 0.8554 - val_loss: 0.8090 - val_acc: 0.7611\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.78560\n",
            "Epoch 207/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4803 - acc: 0.8528 - val_loss: 1.0863 - val_acc: 0.6627\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.78560\n",
            "Epoch 208/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4629 - acc: 0.8585 - val_loss: 0.8855 - val_acc: 0.7382\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.78560\n",
            "Epoch 209/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4785 - acc: 0.8536 - val_loss: 0.8480 - val_acc: 0.7555\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.78560\n",
            "Epoch 210/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4682 - acc: 0.8580 - val_loss: 1.1738 - val_acc: 0.6869\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.78560\n",
            "Epoch 211/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4554 - acc: 0.8648 - val_loss: 0.8452 - val_acc: 0.7406\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.78560\n",
            "Epoch 212/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4726 - acc: 0.8562 - val_loss: 1.8281 - val_acc: 0.6171\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.78560\n",
            "Epoch 213/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4486 - acc: 0.8607 - val_loss: 1.2201 - val_acc: 0.6761\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.78560\n",
            "Epoch 214/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4487 - acc: 0.8661 - val_loss: 1.0859 - val_acc: 0.6872\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.78560\n",
            "Epoch 215/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4696 - acc: 0.8568 - val_loss: 1.4730 - val_acc: 0.6422\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.78560\n",
            "Epoch 216/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4689 - acc: 0.8575 - val_loss: 1.6558 - val_acc: 0.6057\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.78560\n",
            "Epoch 217/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4465 - acc: 0.8650 - val_loss: 0.9273 - val_acc: 0.7355\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.78560\n",
            "Epoch 218/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4476 - acc: 0.8657 - val_loss: 0.8093 - val_acc: 0.7654\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.78560\n",
            "Epoch 219/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4579 - acc: 0.8644 - val_loss: 1.6151 - val_acc: 0.6314\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.78560\n",
            "Epoch 220/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4636 - acc: 0.8567 - val_loss: 1.3138 - val_acc: 0.6780\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.78560\n",
            "Epoch 221/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4659 - acc: 0.8571 - val_loss: 1.0743 - val_acc: 0.6916\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.78560\n",
            "Epoch 222/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4869 - acc: 0.8493 - val_loss: 0.7793 - val_acc: 0.7602\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.78560\n",
            "Epoch 223/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4620 - acc: 0.8608 - val_loss: 1.0137 - val_acc: 0.7196\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.78560\n",
            "Epoch 224/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4584 - acc: 0.8608 - val_loss: 1.2857 - val_acc: 0.6733\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.78560\n",
            "Epoch 225/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4575 - acc: 0.8587 - val_loss: 0.9767 - val_acc: 0.7057\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.78560\n",
            "Epoch 226/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4402 - acc: 0.8654 - val_loss: 0.9320 - val_acc: 0.7366\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.78560\n",
            "Epoch 227/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4549 - acc: 0.8653 - val_loss: 1.5696 - val_acc: 0.6414\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.78560\n",
            "Epoch 228/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4658 - acc: 0.8561 - val_loss: 1.8868 - val_acc: 0.6151\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.78560\n",
            "Epoch 229/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4569 - acc: 0.8614 - val_loss: 1.5157 - val_acc: 0.6699\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.78560\n",
            "Epoch 230/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4648 - acc: 0.8564 - val_loss: 1.1040 - val_acc: 0.6614\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.78560\n",
            "Epoch 231/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4720 - acc: 0.8572 - val_loss: 0.9651 - val_acc: 0.7014\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.78560\n",
            "Epoch 232/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4598 - acc: 0.8638 - val_loss: 1.6981 - val_acc: 0.6340\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.78560\n",
            "Epoch 233/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4554 - acc: 0.8596 - val_loss: 1.3762 - val_acc: 0.6654\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.78560\n",
            "Epoch 234/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4714 - acc: 0.8546 - val_loss: 1.0157 - val_acc: 0.7043\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.78560\n",
            "Epoch 235/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4857 - acc: 0.8545 - val_loss: 0.8345 - val_acc: 0.7507\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.78560\n",
            "Epoch 236/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4468 - acc: 0.8643 - val_loss: 1.0857 - val_acc: 0.7089\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.78560\n",
            "Epoch 237/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4560 - acc: 0.8609 - val_loss: 0.8590 - val_acc: 0.7396\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.78560\n",
            "Epoch 238/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4627 - acc: 0.8625 - val_loss: 1.8810 - val_acc: 0.5825\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.78560\n",
            "Epoch 239/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4496 - acc: 0.8603 - val_loss: 1.0534 - val_acc: 0.7188\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.78560\n",
            "Epoch 240/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4587 - acc: 0.8617 - val_loss: 1.0335 - val_acc: 0.7259\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.78560\n",
            "Epoch 241/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4475 - acc: 0.8640 - val_loss: 0.6862 - val_acc: 0.8002\n",
            "\n",
            "Epoch 00241: val_acc improved from 0.78560 to 0.80020, saving model to /content/saved_models/cifar10_ResNet32v1_model.241.h5\n",
            "Epoch 242/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4621 - acc: 0.8562 - val_loss: 0.8702 - val_acc: 0.7577\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.80020\n",
            "Epoch 243/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4509 - acc: 0.8634 - val_loss: 1.2084 - val_acc: 0.6676\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.80020\n",
            "Epoch 244/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4421 - acc: 0.8687 - val_loss: 1.5978 - val_acc: 0.6410\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.80020\n",
            "Epoch 245/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4371 - acc: 0.8684 - val_loss: 1.8378 - val_acc: 0.6245\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.80020\n",
            "Epoch 246/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4512 - acc: 0.8626 - val_loss: 0.9523 - val_acc: 0.7131\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.80020\n",
            "Epoch 247/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4485 - acc: 0.8646 - val_loss: 0.8632 - val_acc: 0.7576\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.80020\n",
            "Epoch 248/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4540 - acc: 0.8635 - val_loss: 1.1438 - val_acc: 0.7154\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.80020\n",
            "Epoch 249/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4284 - acc: 0.8731 - val_loss: 1.5820 - val_acc: 0.6328\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.80020\n",
            "Epoch 250/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4591 - acc: 0.8596 - val_loss: 0.6368 - val_acc: 0.8105\n",
            "\n",
            "Epoch 00250: val_acc improved from 0.80020 to 0.81050, saving model to /content/saved_models/cifar10_ResNet32v1_model.250.h5\n",
            "Epoch 251/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4481 - acc: 0.8639 - val_loss: 0.9358 - val_acc: 0.7510\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.81050\n",
            "Epoch 252/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4564 - acc: 0.8625 - val_loss: 0.9248 - val_acc: 0.7367\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.81050\n",
            "Epoch 253/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4478 - acc: 0.8622 - val_loss: 1.3112 - val_acc: 0.6452\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.81050\n",
            "Epoch 254/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4664 - acc: 0.8586 - val_loss: 0.8096 - val_acc: 0.7588\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.81050\n",
            "Epoch 255/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4610 - acc: 0.8602 - val_loss: 0.7450 - val_acc: 0.7762\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.81050\n",
            "Epoch 256/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4456 - acc: 0.8627 - val_loss: 0.9559 - val_acc: 0.7184\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.81050\n",
            "Epoch 257/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4701 - acc: 0.8550 - val_loss: 1.1108 - val_acc: 0.7047\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.81050\n",
            "Epoch 258/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4463 - acc: 0.8611 - val_loss: 2.4122 - val_acc: 0.5364\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.81050\n",
            "Epoch 259/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4480 - acc: 0.8678 - val_loss: 0.9980 - val_acc: 0.7365\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.81050\n",
            "Epoch 260/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4546 - acc: 0.8636 - val_loss: 1.2718 - val_acc: 0.6774\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.81050\n",
            "Epoch 261/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4386 - acc: 0.8668 - val_loss: 1.1961 - val_acc: 0.7002\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.81050\n",
            "Epoch 262/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4514 - acc: 0.8632 - val_loss: 0.9424 - val_acc: 0.7409\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.81050\n",
            "Epoch 263/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4539 - acc: 0.8627 - val_loss: 0.7631 - val_acc: 0.7774\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.81050\n",
            "Epoch 264/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4578 - acc: 0.8663 - val_loss: 1.0474 - val_acc: 0.7189\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.81050\n",
            "Epoch 265/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4634 - acc: 0.8586 - val_loss: 1.9696 - val_acc: 0.5788\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.81050\n",
            "Epoch 266/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4386 - acc: 0.8687 - val_loss: 1.3189 - val_acc: 0.6355\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.81050\n",
            "Epoch 267/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4475 - acc: 0.8587 - val_loss: 1.2316 - val_acc: 0.6784\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.81050\n",
            "Epoch 268/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4369 - acc: 0.8692 - val_loss: 0.7772 - val_acc: 0.7889\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.81050\n",
            "Epoch 269/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4585 - acc: 0.8630 - val_loss: 0.7470 - val_acc: 0.7782\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.81050\n",
            "Epoch 270/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4637 - acc: 0.8619 - val_loss: 0.8910 - val_acc: 0.7449\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.81050\n",
            "Epoch 271/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4491 - acc: 0.8654 - val_loss: 1.1379 - val_acc: 0.7191\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.81050\n",
            "Epoch 272/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4383 - acc: 0.8635 - val_loss: 0.8439 - val_acc: 0.7416\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.81050\n",
            "Epoch 273/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4536 - acc: 0.8632 - val_loss: 1.0250 - val_acc: 0.7025\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.81050\n",
            "Epoch 274/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4360 - acc: 0.8661 - val_loss: 1.1020 - val_acc: 0.6810\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.81050\n",
            "Epoch 275/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4506 - acc: 0.8601 - val_loss: 0.9244 - val_acc: 0.7355\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.81050\n",
            "Epoch 276/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4385 - acc: 0.8676 - val_loss: 0.9278 - val_acc: 0.7287\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.81050\n",
            "Epoch 277/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4608 - acc: 0.8607 - val_loss: 1.0108 - val_acc: 0.7188\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.81050\n",
            "Epoch 278/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4544 - acc: 0.8613 - val_loss: 1.3509 - val_acc: 0.6720\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.81050\n",
            "Epoch 279/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4517 - acc: 0.8603 - val_loss: 0.8788 - val_acc: 0.7570\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.81050\n",
            "Epoch 280/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4570 - acc: 0.8603 - val_loss: 0.8414 - val_acc: 0.7394\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.81050\n",
            "Epoch 281/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4347 - acc: 0.8689 - val_loss: 1.4445 - val_acc: 0.6755\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.81050\n",
            "Epoch 282/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4444 - acc: 0.8643 - val_loss: 0.9235 - val_acc: 0.7453\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.81050\n",
            "Epoch 283/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4373 - acc: 0.8674 - val_loss: 0.8557 - val_acc: 0.7618\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.81050\n",
            "Epoch 284/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4398 - acc: 0.8683 - val_loss: 1.5012 - val_acc: 0.6278\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.81050\n",
            "Epoch 285/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4441 - acc: 0.8677 - val_loss: 0.6731 - val_acc: 0.7962\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.81050\n",
            "Epoch 286/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4420 - acc: 0.8669 - val_loss: 0.7585 - val_acc: 0.7780\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.81050\n",
            "Epoch 287/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4311 - acc: 0.8683 - val_loss: 0.9419 - val_acc: 0.7314\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.81050\n",
            "Epoch 288/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4526 - acc: 0.8588 - val_loss: 1.0534 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.81050\n",
            "Epoch 289/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4543 - acc: 0.8608 - val_loss: 0.9860 - val_acc: 0.7242\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.81050\n",
            "Epoch 290/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4401 - acc: 0.8659 - val_loss: 0.8960 - val_acc: 0.7593\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.81050\n",
            "Epoch 291/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4540 - acc: 0.8631 - val_loss: 0.8597 - val_acc: 0.7537\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.81050\n",
            "Epoch 292/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.4590 - acc: 0.8586 - val_loss: 1.2075 - val_acc: 0.6751\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.81050\n",
            "Epoch 293/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4383 - acc: 0.8676 - val_loss: 1.0492 - val_acc: 0.7138\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.81050\n",
            "Epoch 294/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4471 - acc: 0.8648 - val_loss: 1.0967 - val_acc: 0.6809\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.81050\n",
            "Epoch 295/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4503 - acc: 0.8632 - val_loss: 1.3656 - val_acc: 0.6401\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.81050\n",
            "Epoch 296/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4414 - acc: 0.8670 - val_loss: 0.8410 - val_acc: 0.7570\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.81050\n",
            "Epoch 297/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4437 - acc: 0.8685 - val_loss: 0.7454 - val_acc: 0.7813\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.81050\n",
            "Epoch 298/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4420 - acc: 0.8671 - val_loss: 0.8506 - val_acc: 0.7623\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.81050\n",
            "Epoch 299/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4336 - acc: 0.8673 - val_loss: 0.9605 - val_acc: 0.7345\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.81050\n",
            "Epoch 300/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4353 - acc: 0.8653 - val_loss: 1.1907 - val_acc: 0.6309\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.81050\n",
            "Epoch 301/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4286 - acc: 0.8737 - val_loss: 0.8010 - val_acc: 0.7654\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.81050\n",
            "Epoch 302/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4456 - acc: 0.8666 - val_loss: 1.3968 - val_acc: 0.6132\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.81050\n",
            "Epoch 303/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4516 - acc: 0.8645 - val_loss: 1.0175 - val_acc: 0.7032\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.81050\n",
            "Epoch 304/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4352 - acc: 0.8689 - val_loss: 3.3872 - val_acc: 0.4456\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.81050\n",
            "Epoch 305/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4389 - acc: 0.8666 - val_loss: 0.6646 - val_acc: 0.8111\n",
            "\n",
            "Epoch 00305: val_acc improved from 0.81050 to 0.81110, saving model to /content/saved_models/cifar10_ResNet32v1_model.305.h5\n",
            "Epoch 306/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4335 - acc: 0.8675 - val_loss: 1.5463 - val_acc: 0.6558\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.81110\n",
            "Epoch 307/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4513 - acc: 0.8632 - val_loss: 1.0522 - val_acc: 0.7131\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.81110\n",
            "Epoch 308/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4407 - acc: 0.8705 - val_loss: 1.4147 - val_acc: 0.6693\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.81110\n",
            "Epoch 309/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4550 - acc: 0.8610 - val_loss: 1.5864 - val_acc: 0.6447\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.81110\n",
            "Epoch 310/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4272 - acc: 0.8688 - val_loss: 1.2774 - val_acc: 0.6733\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.81110\n",
            "Epoch 311/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4461 - acc: 0.8632 - val_loss: 1.4099 - val_acc: 0.6417\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.81110\n",
            "Epoch 312/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4389 - acc: 0.8683 - val_loss: 1.0880 - val_acc: 0.7067\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.81110\n",
            "Epoch 313/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4470 - acc: 0.8645 - val_loss: 0.7875 - val_acc: 0.7575\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.81110\n",
            "Epoch 314/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.4224 - acc: 0.8720 - val_loss: 0.7188 - val_acc: 0.7856\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.81110\n",
            "Epoch 315/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4258 - acc: 0.8735 - val_loss: 0.9235 - val_acc: 0.7533\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.81110\n",
            "Epoch 316/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4454 - acc: 0.8652 - val_loss: 1.9295 - val_acc: 0.5514\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.81110\n",
            "Epoch 317/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4564 - acc: 0.8605 - val_loss: 1.2325 - val_acc: 0.6763\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.81110\n",
            "Epoch 318/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4390 - acc: 0.8655 - val_loss: 1.4186 - val_acc: 0.6273\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.81110\n",
            "Epoch 319/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4572 - acc: 0.8588 - val_loss: 0.5851 - val_acc: 0.8288\n",
            "\n",
            "Epoch 00319: val_acc improved from 0.81110 to 0.82880, saving model to /content/saved_models/cifar10_ResNet32v1_model.319.h5\n",
            "Epoch 320/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.4400 - acc: 0.8680 - val_loss: 1.0287 - val_acc: 0.6848\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.82880\n",
            "Epoch 321/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.4281 - acc: 0.8717 - val_loss: 1.2646 - val_acc: 0.6855\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.82880\n",
            "Epoch 322/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4391 - acc: 0.8662 - val_loss: 1.8600 - val_acc: 0.6266\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.82880\n",
            "Epoch 323/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4141 - acc: 0.8750 - val_loss: 1.2135 - val_acc: 0.6576\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.82880\n",
            "Epoch 324/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4414 - acc: 0.8670 - val_loss: 1.0860 - val_acc: 0.7243\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.82880\n",
            "Epoch 325/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4384 - acc: 0.8699 - val_loss: 0.8017 - val_acc: 0.7612\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.82880\n",
            "Epoch 326/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4532 - acc: 0.8652 - val_loss: 1.2110 - val_acc: 0.6973\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.82880\n",
            "Epoch 327/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4339 - acc: 0.8692 - val_loss: 1.6215 - val_acc: 0.6296\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.82880\n",
            "Epoch 328/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4248 - acc: 0.8747 - val_loss: 0.9366 - val_acc: 0.7425\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.82880\n",
            "Epoch 329/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4456 - acc: 0.8624 - val_loss: 2.5031 - val_acc: 0.5174\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.82880\n",
            "Epoch 330/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4346 - acc: 0.8709 - val_loss: 0.9447 - val_acc: 0.7327\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.82880\n",
            "Epoch 331/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4396 - acc: 0.8660 - val_loss: 0.8986 - val_acc: 0.7602\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.82880\n",
            "Epoch 332/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4369 - acc: 0.8686 - val_loss: 0.7435 - val_acc: 0.7717\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.82880\n",
            "Epoch 333/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4381 - acc: 0.8646 - val_loss: 1.0229 - val_acc: 0.7263\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.82880\n",
            "Epoch 334/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4317 - acc: 0.8696 - val_loss: 1.3865 - val_acc: 0.6497\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.82880\n",
            "Epoch 335/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4175 - acc: 0.8749 - val_loss: 1.1918 - val_acc: 0.6760\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.82880\n",
            "Epoch 336/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4459 - acc: 0.8648 - val_loss: 0.6976 - val_acc: 0.7933\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.82880\n",
            "Epoch 337/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4311 - acc: 0.8711 - val_loss: 0.7051 - val_acc: 0.7982\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.82880\n",
            "Epoch 338/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4218 - acc: 0.8741 - val_loss: 0.8177 - val_acc: 0.7603\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.82880\n",
            "Epoch 339/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4428 - acc: 0.8701 - val_loss: 0.9273 - val_acc: 0.7422\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.82880\n",
            "Epoch 340/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.4247 - acc: 0.8710 - val_loss: 0.6492 - val_acc: 0.7983\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.82880\n",
            "Epoch 341/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4550 - acc: 0.8634 - val_loss: 1.2436 - val_acc: 0.6937\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.82880\n",
            "Epoch 342/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4235 - acc: 0.8717 - val_loss: 1.3227 - val_acc: 0.6692\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.82880\n",
            "Epoch 343/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4284 - acc: 0.8692 - val_loss: 0.9029 - val_acc: 0.7556\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.82880\n",
            "Epoch 344/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4610 - acc: 0.8595 - val_loss: 0.9526 - val_acc: 0.7238\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.82880\n",
            "Epoch 345/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4400 - acc: 0.8683 - val_loss: 0.8611 - val_acc: 0.7598\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.82880\n",
            "Epoch 346/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.4453 - acc: 0.8690 - val_loss: 1.2051 - val_acc: 0.6692\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.82880\n",
            "Epoch 347/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4208 - acc: 0.8757 - val_loss: 1.1157 - val_acc: 0.7058\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.82880\n",
            "Epoch 348/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4249 - acc: 0.8699 - val_loss: 1.0090 - val_acc: 0.7202\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.82880\n",
            "Epoch 349/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4551 - acc: 0.8603 - val_loss: 0.7555 - val_acc: 0.7827\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.82880\n",
            "Epoch 350/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.4442 - acc: 0.8671 - val_loss: 1.0248 - val_acc: 0.7296\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.82880\n",
            "Epoch 351/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4298 - acc: 0.8746 - val_loss: 1.0745 - val_acc: 0.7078\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.82880\n",
            "Epoch 352/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4188 - acc: 0.8730 - val_loss: 1.0431 - val_acc: 0.7155\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.82880\n",
            "Epoch 353/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4162 - acc: 0.8727 - val_loss: 0.7217 - val_acc: 0.7797\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.82880\n",
            "Epoch 354/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4309 - acc: 0.8709 - val_loss: 1.4079 - val_acc: 0.6526\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.82880\n",
            "Epoch 355/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4225 - acc: 0.8731 - val_loss: 1.5143 - val_acc: 0.6280\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.82880\n",
            "Epoch 356/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4398 - acc: 0.8668 - val_loss: 1.5850 - val_acc: 0.5830\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.82880\n",
            "Epoch 357/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4442 - acc: 0.8636 - val_loss: 1.2890 - val_acc: 0.6788\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.82880\n",
            "Epoch 358/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4402 - acc: 0.8677 - val_loss: 1.9938 - val_acc: 0.5743\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.82880\n",
            "Epoch 359/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4410 - acc: 0.8691 - val_loss: 1.1177 - val_acc: 0.7199\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.82880\n",
            "Epoch 360/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.4423 - acc: 0.8677 - val_loss: 1.3164 - val_acc: 0.6756\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.82880\n",
            "Epoch 361/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4256 - acc: 0.8735 - val_loss: 1.1895 - val_acc: 0.6905\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.82880\n",
            "Epoch 362/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4338 - acc: 0.8709 - val_loss: 0.7222 - val_acc: 0.7838\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.82880\n",
            "Epoch 363/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4386 - acc: 0.8699 - val_loss: 0.9015 - val_acc: 0.7555\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.82880\n",
            "Epoch 364/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4292 - acc: 0.8722 - val_loss: 0.7098 - val_acc: 0.7879\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.82880\n",
            "Epoch 365/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4378 - acc: 0.8675 - val_loss: 0.8224 - val_acc: 0.7655\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.82880\n",
            "Epoch 366/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4221 - acc: 0.8736 - val_loss: 0.7060 - val_acc: 0.7873\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.82880\n",
            "Epoch 367/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4437 - acc: 0.8657 - val_loss: 1.2302 - val_acc: 0.6901\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.82880\n",
            "Epoch 368/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4375 - acc: 0.8693 - val_loss: 1.0181 - val_acc: 0.7295\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.82880\n",
            "Epoch 369/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4502 - acc: 0.8667 - val_loss: 1.5737 - val_acc: 0.5943\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.82880\n",
            "Epoch 370/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4303 - acc: 0.8685 - val_loss: 0.9940 - val_acc: 0.7374\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.82880\n",
            "Epoch 371/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4420 - acc: 0.8660 - val_loss: 0.9915 - val_acc: 0.7493\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.82880\n",
            "Epoch 372/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4489 - acc: 0.8661 - val_loss: 0.6507 - val_acc: 0.8008\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.82880\n",
            "Epoch 373/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4420 - acc: 0.8665 - val_loss: 1.8524 - val_acc: 0.5972\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.82880\n",
            "Epoch 374/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4395 - acc: 0.8673 - val_loss: 1.4075 - val_acc: 0.6722\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.82880\n",
            "Epoch 375/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4069 - acc: 0.8826 - val_loss: 0.7542 - val_acc: 0.7663\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.82880\n",
            "Epoch 376/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4242 - acc: 0.8679 - val_loss: 1.3733 - val_acc: 0.6480\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.82880\n",
            "Epoch 377/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4395 - acc: 0.8684 - val_loss: 1.3869 - val_acc: 0.6523\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.82880\n",
            "Epoch 378/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4231 - acc: 0.8708 - val_loss: 0.8682 - val_acc: 0.7536\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.82880\n",
            "Epoch 379/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4186 - acc: 0.8746 - val_loss: 1.1991 - val_acc: 0.6982\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.82880\n",
            "Epoch 380/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4531 - acc: 0.8614 - val_loss: 1.1437 - val_acc: 0.7144\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.82880\n",
            "Epoch 381/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4129 - acc: 0.8725 - val_loss: 1.6686 - val_acc: 0.6263\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.82880\n",
            "Epoch 382/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4350 - acc: 0.8677 - val_loss: 1.9101 - val_acc: 0.5502\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.82880\n",
            "Epoch 383/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4347 - acc: 0.8686 - val_loss: 1.2618 - val_acc: 0.6718\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.82880\n",
            "Epoch 384/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4279 - acc: 0.8696 - val_loss: 0.9293 - val_acc: 0.7355\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.82880\n",
            "Epoch 385/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4243 - acc: 0.8705 - val_loss: 1.9980 - val_acc: 0.5892\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.82880\n",
            "Epoch 386/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4231 - acc: 0.8718 - val_loss: 1.1833 - val_acc: 0.6909\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.82880\n",
            "Epoch 387/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4321 - acc: 0.8694 - val_loss: 0.9262 - val_acc: 0.7308\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.82880\n",
            "Epoch 388/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.4250 - acc: 0.8726 - val_loss: 0.9359 - val_acc: 0.7633\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.82880\n",
            "Epoch 389/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4329 - acc: 0.8701 - val_loss: 0.9848 - val_acc: 0.7473\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.82880\n",
            "Epoch 390/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4336 - acc: 0.8713 - val_loss: 1.0758 - val_acc: 0.7348\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.82880\n",
            "Epoch 391/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4242 - acc: 0.8701 - val_loss: 0.7996 - val_acc: 0.7675\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.82880\n",
            "Epoch 392/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4290 - acc: 0.8704 - val_loss: 0.6678 - val_acc: 0.7928\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.82880\n",
            "Epoch 393/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4394 - acc: 0.8682 - val_loss: 1.1787 - val_acc: 0.6726\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.82880\n",
            "Epoch 394/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4187 - acc: 0.8731 - val_loss: 0.9620 - val_acc: 0.7277\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.82880\n",
            "Epoch 395/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.4385 - acc: 0.8674 - val_loss: 1.1552 - val_acc: 0.6836\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.82880\n",
            "Epoch 396/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.4412 - acc: 0.8643 - val_loss: 1.1101 - val_acc: 0.7089\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.82880\n",
            "Epoch 397/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.4290 - acc: 0.8731 - val_loss: 1.1907 - val_acc: 0.6745\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.82880\n",
            "Epoch 398/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4463 - acc: 0.8634 - val_loss: 0.9049 - val_acc: 0.7538\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.82880\n",
            "Epoch 399/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4213 - acc: 0.8771 - val_loss: 0.7470 - val_acc: 0.7619\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.82880\n",
            "Epoch 400/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4242 - acc: 0.8754 - val_loss: 0.8118 - val_acc: 0.7772\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.82880\n",
            "Epoch 401/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4331 - acc: 0.8693 - val_loss: 0.9746 - val_acc: 0.7096\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.82880\n",
            "Epoch 402/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3413 - acc: 0.9003 - val_loss: 0.4079 - val_acc: 0.8792\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.82880 to 0.87920, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3013 - acc: 0.9155 - val_loss: 0.3956 - val_acc: 0.8815\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.87920 to 0.88150, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2906 - acc: 0.9188 - val_loss: 0.3510 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.88150 to 0.89560, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.2739 - acc: 0.9244 - val_loss: 0.3599 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00405: val_acc did not improve from 0.89560\n",
            "Epoch 406/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2747 - acc: 0.9223 - val_loss: 0.3518 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00406: val_acc improved from 0.89560 to 0.89760, saving model to /content/saved_models/cifar10_ResNet32v1_model.406.h5\n",
            "Epoch 407/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.2597 - acc: 0.9280 - val_loss: 0.3504 - val_acc: 0.8953\n",
            "\n",
            "Epoch 00407: val_acc did not improve from 0.89760\n",
            "Epoch 408/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.2454 - acc: 0.9351 - val_loss: 0.3421 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00408: val_acc improved from 0.89760 to 0.89920, saving model to /content/saved_models/cifar10_ResNet32v1_model.408.h5\n",
            "Epoch 409/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2529 - acc: 0.9325 - val_loss: 0.3458 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00409: val_acc improved from 0.89920 to 0.89970, saving model to /content/saved_models/cifar10_ResNet32v1_model.409.h5\n",
            "Epoch 410/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.2504 - acc: 0.9317 - val_loss: 0.3475 - val_acc: 0.8966\n",
            "\n",
            "Epoch 00410: val_acc did not improve from 0.89970\n",
            "Epoch 411/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2464 - acc: 0.9317 - val_loss: 0.3488 - val_acc: 0.8979\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.89970\n",
            "Epoch 412/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.2386 - acc: 0.9341 - val_loss: 0.3497 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00412: val_acc did not improve from 0.89970\n",
            "Epoch 413/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.2357 - acc: 0.9357 - val_loss: 0.3640 - val_acc: 0.8942\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.89970\n",
            "Epoch 414/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.2385 - acc: 0.9365 - val_loss: 0.3227 - val_acc: 0.9068\n",
            "\n",
            "Epoch 00414: val_acc improved from 0.89970 to 0.90680, saving model to /content/saved_models/cifar10_ResNet32v1_model.414.h5\n",
            "Epoch 415/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.2279 - acc: 0.9392 - val_loss: 0.3270 - val_acc: 0.9047\n",
            "\n",
            "Epoch 00415: val_acc did not improve from 0.90680\n",
            "Epoch 416/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.2292 - acc: 0.9375 - val_loss: 0.3704 - val_acc: 0.8906\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.90680\n",
            "Epoch 417/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.2191 - acc: 0.9420 - val_loss: 0.3420 - val_acc: 0.9016\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.90680\n",
            "Epoch 418/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.2200 - acc: 0.9419 - val_loss: 0.3383 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.90680\n",
            "Epoch 419/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.2198 - acc: 0.9444 - val_loss: 0.3280 - val_acc: 0.9066\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.90680\n",
            "Epoch 420/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2166 - acc: 0.9407 - val_loss: 0.3487 - val_acc: 0.9009\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.90680\n",
            "Epoch 421/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.2169 - acc: 0.9424 - val_loss: 0.3329 - val_acc: 0.9041\n",
            "\n",
            "Epoch 00421: val_acc did not improve from 0.90680\n",
            "Epoch 422/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.2117 - acc: 0.9444 - val_loss: 0.3426 - val_acc: 0.9029\n",
            "\n",
            "Epoch 00422: val_acc did not improve from 0.90680\n",
            "Epoch 423/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2105 - acc: 0.9424 - val_loss: 0.3138 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00423: val_acc improved from 0.90680 to 0.91110, saving model to /content/saved_models/cifar10_ResNet32v1_model.423.h5\n",
            "Epoch 424/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.2095 - acc: 0.9437 - val_loss: 0.3494 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.91110\n",
            "Epoch 425/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.2003 - acc: 0.9483 - val_loss: 0.3432 - val_acc: 0.9006\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.91110\n",
            "Epoch 426/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.2061 - acc: 0.9445 - val_loss: 0.3822 - val_acc: 0.8916\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.91110\n",
            "Epoch 427/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.1985 - acc: 0.9485 - val_loss: 0.3510 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.91110\n",
            "Epoch 428/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1930 - acc: 0.9517 - val_loss: 0.3169 - val_acc: 0.9090\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.91110\n",
            "Epoch 429/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1986 - acc: 0.9500 - val_loss: 0.3402 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.91110\n",
            "Epoch 430/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.2034 - acc: 0.9451 - val_loss: 0.3400 - val_acc: 0.9050\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.91110\n",
            "Epoch 431/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1933 - acc: 0.9486 - val_loss: 0.3534 - val_acc: 0.9005\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.91110\n",
            "Epoch 432/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.1976 - acc: 0.9485 - val_loss: 0.3291 - val_acc: 0.9066\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.91110\n",
            "Epoch 433/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1930 - acc: 0.9507 - val_loss: 0.3418 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.91110\n",
            "Epoch 434/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1870 - acc: 0.9513 - val_loss: 0.3256 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00434: val_acc did not improve from 0.91110\n",
            "Epoch 435/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1862 - acc: 0.9505 - val_loss: 0.3354 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.91110\n",
            "Epoch 436/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.1901 - acc: 0.9493 - val_loss: 0.3201 - val_acc: 0.9091\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.91110\n",
            "Epoch 437/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1834 - acc: 0.9530 - val_loss: 0.3404 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.91110\n",
            "Epoch 438/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1970 - acc: 0.9489 - val_loss: 0.3276 - val_acc: 0.9074\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.91110\n",
            "Epoch 439/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1924 - acc: 0.9483 - val_loss: 0.3186 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.91110\n",
            "Epoch 440/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.1747 - acc: 0.9551 - val_loss: 0.3598 - val_acc: 0.9004\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.91110\n",
            "Epoch 441/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1772 - acc: 0.9557 - val_loss: 0.3259 - val_acc: 0.9091\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.91110\n",
            "Epoch 442/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1961 - acc: 0.9476 - val_loss: 0.3204 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.91110\n",
            "Epoch 443/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1823 - acc: 0.9535 - val_loss: 0.3049 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00443: val_acc improved from 0.91110 to 0.91360, saving model to /content/saved_models/cifar10_ResNet32v1_model.443.h5\n",
            "Epoch 444/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.1774 - acc: 0.9543 - val_loss: 0.3055 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.91360\n",
            "Epoch 445/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.1767 - acc: 0.9568 - val_loss: 0.3266 - val_acc: 0.9050\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.91360\n",
            "Epoch 446/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1663 - acc: 0.9603 - val_loss: 0.3246 - val_acc: 0.9091\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.91360\n",
            "Epoch 447/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1859 - acc: 0.9503 - val_loss: 0.3266 - val_acc: 0.9090\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.91360\n",
            "Epoch 448/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1723 - acc: 0.9562 - val_loss: 0.3406 - val_acc: 0.9053\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.91360\n",
            "Epoch 449/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.1750 - acc: 0.9534 - val_loss: 0.3608 - val_acc: 0.9005\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.91360\n",
            "Epoch 450/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1749 - acc: 0.9551 - val_loss: 0.3081 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.91360\n",
            "Epoch 451/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.1637 - acc: 0.9607 - val_loss: 0.3232 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.91360\n",
            "Epoch 452/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1663 - acc: 0.9572 - val_loss: 0.3180 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.91360\n",
            "Epoch 453/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1729 - acc: 0.9573 - val_loss: 0.3354 - val_acc: 0.9036\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.91360\n",
            "Epoch 454/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1689 - acc: 0.9552 - val_loss: 0.3198 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.91360\n",
            "Epoch 455/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.1627 - acc: 0.9605 - val_loss: 0.3229 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.91360\n",
            "Epoch 456/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1662 - acc: 0.9577 - val_loss: 0.3387 - val_acc: 0.9040\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.91360\n",
            "Epoch 457/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1657 - acc: 0.9589 - val_loss: 0.3261 - val_acc: 0.9083\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.91360\n",
            "Epoch 458/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1652 - acc: 0.9565 - val_loss: 0.3134 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.91360\n",
            "Epoch 459/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1649 - acc: 0.9568 - val_loss: 0.3490 - val_acc: 0.9043\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.91360\n",
            "Epoch 460/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1655 - acc: 0.9568 - val_loss: 0.3250 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.91360\n",
            "Epoch 461/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1628 - acc: 0.9600 - val_loss: 0.3351 - val_acc: 0.9055\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.91360\n",
            "Epoch 462/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1562 - acc: 0.9611 - val_loss: 0.3289 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.91360\n",
            "Epoch 463/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1601 - acc: 0.9596 - val_loss: 0.3407 - val_acc: 0.9034\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.91360\n",
            "Epoch 464/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1573 - acc: 0.9615 - val_loss: 0.3334 - val_acc: 0.9088\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.91360\n",
            "Epoch 465/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1550 - acc: 0.9628 - val_loss: 0.3148 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.91360\n",
            "Epoch 466/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1572 - acc: 0.9615 - val_loss: 0.3230 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.91360\n",
            "Epoch 467/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1531 - acc: 0.9621 - val_loss: 0.3277 - val_acc: 0.9060\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.91360\n",
            "Epoch 468/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1541 - acc: 0.9629 - val_loss: 0.3169 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.91360\n",
            "Epoch 469/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.1556 - acc: 0.9619 - val_loss: 0.3185 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.91360\n",
            "Epoch 470/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.1579 - acc: 0.9600 - val_loss: 0.3277 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.91360\n",
            "Epoch 471/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1518 - acc: 0.9618 - val_loss: 0.3259 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.91360\n",
            "Epoch 472/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1547 - acc: 0.9621 - val_loss: 0.3184 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.91360\n",
            "Epoch 473/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1506 - acc: 0.9633 - val_loss: 0.3525 - val_acc: 0.9057\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.91360\n",
            "Epoch 474/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1480 - acc: 0.9646 - val_loss: 0.3658 - val_acc: 0.9043\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.91360\n",
            "Epoch 475/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1542 - acc: 0.9618 - val_loss: 0.3241 - val_acc: 0.9054\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.91360\n",
            "Epoch 476/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1396 - acc: 0.9657 - val_loss: 0.3355 - val_acc: 0.9079\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.91360\n",
            "Epoch 477/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1528 - acc: 0.9609 - val_loss: 0.3160 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.91360\n",
            "Epoch 478/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1472 - acc: 0.9657 - val_loss: 0.3382 - val_acc: 0.9081\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.91360\n",
            "Epoch 479/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.1440 - acc: 0.9649 - val_loss: 0.3506 - val_acc: 0.9044\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.91360\n",
            "Epoch 480/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1410 - acc: 0.9672 - val_loss: 0.3660 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.91360\n",
            "Epoch 481/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.1423 - acc: 0.9668 - val_loss: 0.3278 - val_acc: 0.9079\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.91360\n",
            "Epoch 482/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1407 - acc: 0.9659 - val_loss: 0.3573 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.91360\n",
            "Epoch 483/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.1429 - acc: 0.9656 - val_loss: 0.3245 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.91360\n",
            "Epoch 484/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1385 - acc: 0.9673 - val_loss: 0.3391 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.91360\n",
            "Epoch 485/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.1335 - acc: 0.9698 - val_loss: 0.3518 - val_acc: 0.9038\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.91360\n",
            "Epoch 486/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1456 - acc: 0.9662 - val_loss: 0.3647 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.91360\n",
            "Epoch 487/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1452 - acc: 0.9647 - val_loss: 0.3434 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.91360\n",
            "Epoch 488/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1394 - acc: 0.9659 - val_loss: 0.3426 - val_acc: 0.9075\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.91360\n",
            "Epoch 489/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1419 - acc: 0.9648 - val_loss: 0.3259 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.91360\n",
            "Epoch 490/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1293 - acc: 0.9689 - val_loss: 0.3341 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.91360\n",
            "Epoch 491/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1416 - acc: 0.9678 - val_loss: 0.3296 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.91360\n",
            "Epoch 492/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1324 - acc: 0.9690 - val_loss: 0.3575 - val_acc: 0.9041\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.91360\n",
            "Epoch 493/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1270 - acc: 0.9719 - val_loss: 0.3286 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.91360\n",
            "Epoch 494/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.1377 - acc: 0.9658 - val_loss: 0.3247 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.91360\n",
            "Epoch 495/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1405 - acc: 0.9649 - val_loss: 0.3791 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.91360\n",
            "Epoch 496/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1386 - acc: 0.9653 - val_loss: 0.3334 - val_acc: 0.9079\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.91360\n",
            "Epoch 497/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1386 - acc: 0.9669 - val_loss: 0.3358 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.91360\n",
            "Epoch 498/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1305 - acc: 0.9702 - val_loss: 0.3427 - val_acc: 0.9074\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.91360\n",
            "Epoch 499/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1392 - acc: 0.9664 - val_loss: 0.3247 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.91360\n",
            "Epoch 500/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.1330 - acc: 0.9675 - val_loss: 0.3419 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.91360\n",
            "Epoch 501/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1360 - acc: 0.9680 - val_loss: 0.3415 - val_acc: 0.9078\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.91360\n",
            "Epoch 502/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.1258 - acc: 0.9721 - val_loss: 0.3434 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.91360\n",
            "Epoch 503/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1250 - acc: 0.9731 - val_loss: 0.3357 - val_acc: 0.9114\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.91360\n",
            "Epoch 504/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1283 - acc: 0.9706 - val_loss: 0.3542 - val_acc: 0.9080\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.91360\n",
            "Epoch 505/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1303 - acc: 0.9698 - val_loss: 0.3266 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.91360\n",
            "Epoch 506/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1292 - acc: 0.9700 - val_loss: 0.3679 - val_acc: 0.9018\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.91360\n",
            "Epoch 507/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1279 - acc: 0.9706 - val_loss: 0.3572 - val_acc: 0.9060\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.91360\n",
            "Epoch 508/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1312 - acc: 0.9671 - val_loss: 0.3353 - val_acc: 0.9079\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.91360\n",
            "Epoch 509/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1301 - acc: 0.9699 - val_loss: 0.3273 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.91360\n",
            "Epoch 510/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1305 - acc: 0.9693 - val_loss: 0.3518 - val_acc: 0.9083\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.91360\n",
            "Epoch 511/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.1283 - acc: 0.9696 - val_loss: 0.3549 - val_acc: 0.9057\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.91360\n",
            "Epoch 512/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1250 - acc: 0.9709 - val_loss: 0.3626 - val_acc: 0.9052\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.91360\n",
            "Epoch 513/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1301 - acc: 0.9708 - val_loss: 0.3556 - val_acc: 0.9046\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.91360\n",
            "Epoch 514/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1248 - acc: 0.9710 - val_loss: 0.3407 - val_acc: 0.9081\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.91360\n",
            "Epoch 515/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1298 - acc: 0.9693 - val_loss: 0.3530 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.91360\n",
            "Epoch 516/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1206 - acc: 0.9727 - val_loss: 0.3374 - val_acc: 0.9088\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.91360\n",
            "Epoch 517/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.1278 - acc: 0.9692 - val_loss: 0.3541 - val_acc: 0.9074\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.91360\n",
            "Epoch 518/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1193 - acc: 0.9730 - val_loss: 0.3527 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.91360\n",
            "Epoch 519/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1225 - acc: 0.9722 - val_loss: 0.3458 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.91360\n",
            "Epoch 520/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1228 - acc: 0.9718 - val_loss: 0.3251 - val_acc: 0.9138\n",
            "\n",
            "Epoch 00520: val_acc improved from 0.91360 to 0.91380, saving model to /content/saved_models/cifar10_ResNet32v1_model.520.h5\n",
            "Epoch 521/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.1241 - acc: 0.9729 - val_loss: 0.3437 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.91380\n",
            "Epoch 522/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1139 - acc: 0.9750 - val_loss: 0.3464 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.91380\n",
            "Epoch 523/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1250 - acc: 0.9708 - val_loss: 0.3470 - val_acc: 0.9077\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.91380\n",
            "Epoch 524/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1188 - acc: 0.9742 - val_loss: 0.3564 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.91380\n",
            "Epoch 525/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.1245 - acc: 0.9711 - val_loss: 0.3451 - val_acc: 0.9090\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.91380\n",
            "Epoch 526/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1140 - acc: 0.9760 - val_loss: 0.3406 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.91380\n",
            "Epoch 527/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.1158 - acc: 0.9751 - val_loss: 0.3699 - val_acc: 0.9042\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.91380\n",
            "Epoch 528/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1136 - acc: 0.9775 - val_loss: 0.3417 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.91380\n",
            "Epoch 529/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.1146 - acc: 0.9749 - val_loss: 0.3423 - val_acc: 0.9078\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.91380\n",
            "Epoch 530/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1150 - acc: 0.9756 - val_loss: 0.3375 - val_acc: 0.9095\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.91380\n",
            "Epoch 531/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1211 - acc: 0.9737 - val_loss: 0.3516 - val_acc: 0.9070\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.91380\n",
            "Epoch 532/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1145 - acc: 0.9760 - val_loss: 0.3367 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.91380\n",
            "Epoch 533/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1158 - acc: 0.9753 - val_loss: 0.3509 - val_acc: 0.9077\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.91380\n",
            "Epoch 534/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1203 - acc: 0.9721 - val_loss: 0.3569 - val_acc: 0.9054\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.91380\n",
            "Epoch 535/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1170 - acc: 0.9742 - val_loss: 0.3726 - val_acc: 0.9052\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.91380\n",
            "Epoch 536/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1173 - acc: 0.9746 - val_loss: 0.3309 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00536: val_acc improved from 0.91380 to 0.91550, saving model to /content/saved_models/cifar10_ResNet32v1_model.536.h5\n",
            "Epoch 537/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1168 - acc: 0.9739 - val_loss: 0.3288 - val_acc: 0.9150\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.91550\n",
            "Epoch 538/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1207 - acc: 0.9719 - val_loss: 0.3479 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.91550\n",
            "Epoch 539/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1118 - acc: 0.9744 - val_loss: 0.3249 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.91550\n",
            "Epoch 540/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.1165 - acc: 0.9745 - val_loss: 0.3442 - val_acc: 0.9074\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.91550\n",
            "Epoch 541/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1134 - acc: 0.9750 - val_loss: 0.3816 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.91550\n",
            "Epoch 542/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.1100 - acc: 0.9756 - val_loss: 0.3678 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.91550\n",
            "Epoch 543/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.1067 - acc: 0.9785 - val_loss: 0.3522 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.91550\n",
            "Epoch 544/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1143 - acc: 0.9741 - val_loss: 0.3357 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.91550\n",
            "Epoch 545/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1147 - acc: 0.9739 - val_loss: 0.3460 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.91550\n",
            "Epoch 546/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1169 - acc: 0.9735 - val_loss: 0.3471 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.91550\n",
            "Epoch 547/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1061 - acc: 0.9788 - val_loss: 0.3513 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.91550\n",
            "Epoch 548/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.1034 - acc: 0.9808 - val_loss: 0.3215 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.91550\n",
            "Epoch 549/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1111 - acc: 0.9763 - val_loss: 0.3447 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.91550\n",
            "Epoch 550/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1086 - acc: 0.9778 - val_loss: 0.3631 - val_acc: 0.9070\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.91550\n",
            "Epoch 551/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.1092 - acc: 0.9765 - val_loss: 0.3467 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.91550\n",
            "Epoch 552/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1085 - acc: 0.9766 - val_loss: 0.3454 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.91550\n",
            "Epoch 553/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1082 - acc: 0.9767 - val_loss: 0.3373 - val_acc: 0.9138\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.91550\n",
            "Epoch 554/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1075 - acc: 0.9792 - val_loss: 0.3373 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00554: val_acc improved from 0.91550 to 0.91570, saving model to /content/saved_models/cifar10_ResNet32v1_model.554.h5\n",
            "Epoch 555/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1121 - acc: 0.9762 - val_loss: 0.3600 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.91570\n",
            "Epoch 556/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1038 - acc: 0.9799 - val_loss: 0.3568 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.91570\n",
            "Epoch 557/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1104 - acc: 0.9760 - val_loss: 0.3750 - val_acc: 0.9057\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.91570\n",
            "Epoch 558/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1109 - acc: 0.9763 - val_loss: 0.3892 - val_acc: 0.9029\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.91570\n",
            "Epoch 559/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.1039 - acc: 0.9786 - val_loss: 0.3446 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.91570\n",
            "Epoch 560/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1092 - acc: 0.9774 - val_loss: 0.3413 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.91570\n",
            "Epoch 561/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1104 - acc: 0.9766 - val_loss: 0.3364 - val_acc: 0.9134\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.91570\n",
            "Epoch 562/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.1085 - acc: 0.9764 - val_loss: 0.3518 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.91570\n",
            "Epoch 563/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1055 - acc: 0.9772 - val_loss: 0.3466 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.91570\n",
            "Epoch 564/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1021 - acc: 0.9799 - val_loss: 0.3496 - val_acc: 0.9094\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.91570\n",
            "Epoch 565/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1046 - acc: 0.9776 - val_loss: 0.3590 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.91570\n",
            "Epoch 566/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1024 - acc: 0.9782 - val_loss: 0.3788 - val_acc: 0.9032\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.91570\n",
            "Epoch 567/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1054 - acc: 0.9777 - val_loss: 0.3473 - val_acc: 0.9106\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.91570\n",
            "Epoch 568/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.1006 - acc: 0.9809 - val_loss: 0.3816 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.91570\n",
            "Epoch 569/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1060 - acc: 0.9762 - val_loss: 0.3493 - val_acc: 0.9134\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.91570\n",
            "Epoch 570/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1033 - acc: 0.9791 - val_loss: 0.3707 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.91570\n",
            "Epoch 571/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1053 - acc: 0.9767 - val_loss: 0.3492 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.91570\n",
            "Epoch 572/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.1063 - acc: 0.9777 - val_loss: 0.3403 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.91570\n",
            "Epoch 573/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1079 - acc: 0.9767 - val_loss: 0.3634 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.91570\n",
            "Epoch 574/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1050 - acc: 0.9790 - val_loss: 0.3462 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.91570\n",
            "Epoch 575/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1037 - acc: 0.9788 - val_loss: 0.3542 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.91570\n",
            "Epoch 576/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1110 - acc: 0.9768 - val_loss: 0.3407 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.91570\n",
            "Epoch 577/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0994 - acc: 0.9800 - val_loss: 0.4170 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.91570\n",
            "Epoch 578/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1053 - acc: 0.9780 - val_loss: 0.3678 - val_acc: 0.9084\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.91570\n",
            "Epoch 579/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1064 - acc: 0.9770 - val_loss: 0.3718 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.91570\n",
            "Epoch 580/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.1050 - acc: 0.9787 - val_loss: 0.3465 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.91570\n",
            "Epoch 581/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.1011 - acc: 0.9799 - val_loss: 0.3789 - val_acc: 0.9035\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.91570\n",
            "Epoch 582/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1001 - acc: 0.9800 - val_loss: 0.3273 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00582: val_acc improved from 0.91570 to 0.91630, saving model to /content/saved_models/cifar10_ResNet32v1_model.582.h5\n",
            "Epoch 583/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0998 - acc: 0.9800 - val_loss: 0.3453 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.91630\n",
            "Epoch 584/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0995 - acc: 0.9796 - val_loss: 0.3487 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.91630\n",
            "Epoch 585/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1062 - acc: 0.9768 - val_loss: 0.4168 - val_acc: 0.8964\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.91630\n",
            "Epoch 586/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0999 - acc: 0.9795 - val_loss: 0.3309 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00586: val_acc improved from 0.91630 to 0.91690, saving model to /content/saved_models/cifar10_ResNet32v1_model.586.h5\n",
            "Epoch 587/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1008 - acc: 0.9793 - val_loss: 0.4020 - val_acc: 0.8987\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.91690\n",
            "Epoch 588/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.1040 - acc: 0.9784 - val_loss: 0.3653 - val_acc: 0.9096\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.91690\n",
            "Epoch 589/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.1032 - acc: 0.9790 - val_loss: 0.3608 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.91690\n",
            "Epoch 590/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1053 - acc: 0.9775 - val_loss: 0.3371 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.91690\n",
            "Epoch 591/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.0972 - acc: 0.9809 - val_loss: 0.3692 - val_acc: 0.9063\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.91690\n",
            "Epoch 592/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0951 - acc: 0.9825 - val_loss: 0.4003 - val_acc: 0.9034\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.91690\n",
            "Epoch 593/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0972 - acc: 0.9825 - val_loss: 0.3508 - val_acc: 0.9090\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.91690\n",
            "Epoch 594/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.0964 - acc: 0.9807 - val_loss: 0.3558 - val_acc: 0.9138\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.91690\n",
            "Epoch 595/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0986 - acc: 0.9793 - val_loss: 0.3690 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.91690\n",
            "Epoch 596/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0977 - acc: 0.9791 - val_loss: 0.3474 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.91690\n",
            "Epoch 597/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1060 - acc: 0.9780 - val_loss: 0.3480 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.91690\n",
            "Epoch 598/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0972 - acc: 0.9810 - val_loss: 0.3359 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.91690\n",
            "Epoch 599/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1015 - acc: 0.9783 - val_loss: 0.3736 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.91690\n",
            "Epoch 600/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0978 - acc: 0.9808 - val_loss: 0.3770 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.91690\n",
            "Epoch 601/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0971 - acc: 0.9810 - val_loss: 0.3655 - val_acc: 0.9102\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.91690\n",
            "Epoch 602/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0936 - acc: 0.9816 - val_loss: 0.3412 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00602: val_acc did not improve from 0.91690\n",
            "Epoch 603/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.0959 - acc: 0.9804 - val_loss: 0.3340 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00603: val_acc improved from 0.91690 to 0.91720, saving model to /content/saved_models/cifar10_ResNet32v1_model.603.h5\n",
            "Epoch 604/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.1000 - acc: 0.9792 - val_loss: 0.3324 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00604: val_acc improved from 0.91720 to 0.91760, saving model to /content/saved_models/cifar10_ResNet32v1_model.604.h5\n",
            "Epoch 605/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0895 - acc: 0.9843 - val_loss: 0.3290 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00605: val_acc did not improve from 0.91760\n",
            "Epoch 606/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0944 - acc: 0.9815 - val_loss: 0.3285 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00606: val_acc improved from 0.91760 to 0.91800, saving model to /content/saved_models/cifar10_ResNet32v1_model.606.h5\n",
            "Epoch 607/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0904 - acc: 0.9831 - val_loss: 0.3267 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00607: val_acc improved from 0.91800 to 0.91820, saving model to /content/saved_models/cifar10_ResNet32v1_model.607.h5\n",
            "Epoch 608/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0900 - acc: 0.9837 - val_loss: 0.3255 - val_acc: 0.9183\n",
            "\n",
            "Epoch 00608: val_acc improved from 0.91820 to 0.91830, saving model to /content/saved_models/cifar10_ResNet32v1_model.608.h5\n",
            "Epoch 609/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0876 - acc: 0.9845 - val_loss: 0.3245 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00609: val_acc did not improve from 0.91830\n",
            "Epoch 610/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0939 - acc: 0.9839 - val_loss: 0.3230 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00610: val_acc did not improve from 0.91830\n",
            "Epoch 611/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0930 - acc: 0.9836 - val_loss: 0.3229 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.91830\n",
            "Epoch 612/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0917 - acc: 0.9832 - val_loss: 0.3199 - val_acc: 0.9187\n",
            "\n",
            "Epoch 00612: val_acc improved from 0.91830 to 0.91870, saving model to /content/saved_models/cifar10_ResNet32v1_model.612.h5\n",
            "Epoch 613/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0905 - acc: 0.9830 - val_loss: 0.3192 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00613: val_acc improved from 0.91870 to 0.91940, saving model to /content/saved_models/cifar10_ResNet32v1_model.613.h5\n",
            "Epoch 614/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.0933 - acc: 0.9823 - val_loss: 0.3194 - val_acc: 0.9185\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.91940\n",
            "Epoch 615/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0918 - acc: 0.9828 - val_loss: 0.3191 - val_acc: 0.9185\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.91940\n",
            "Epoch 616/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0893 - acc: 0.9842 - val_loss: 0.3179 - val_acc: 0.9187\n",
            "\n",
            "Epoch 00616: val_acc did not improve from 0.91940\n",
            "Epoch 617/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0916 - acc: 0.9828 - val_loss: 0.3171 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.91940\n",
            "Epoch 618/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0872 - acc: 0.9844 - val_loss: 0.3166 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00618: val_acc improved from 0.91940 to 0.91950, saving model to /content/saved_models/cifar10_ResNet32v1_model.618.h5\n",
            "Epoch 619/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0881 - acc: 0.9853 - val_loss: 0.3168 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00619: val_acc did not improve from 0.91950\n",
            "Epoch 620/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.0894 - acc: 0.9831 - val_loss: 0.3170 - val_acc: 0.9190\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.91950\n",
            "Epoch 621/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0894 - acc: 0.9836 - val_loss: 0.3156 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00621: val_acc did not improve from 0.91950\n",
            "Epoch 622/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0877 - acc: 0.9854 - val_loss: 0.3147 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.91950\n",
            "Epoch 623/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0873 - acc: 0.9838 - val_loss: 0.3143 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.91950\n",
            "Epoch 624/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0897 - acc: 0.9839 - val_loss: 0.3143 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00624: val_acc improved from 0.91950 to 0.91970, saving model to /content/saved_models/cifar10_ResNet32v1_model.624.h5\n",
            "Epoch 625/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0891 - acc: 0.9848 - val_loss: 0.3137 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.91970\n",
            "Epoch 626/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0906 - acc: 0.9837 - val_loss: 0.3140 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.91970\n",
            "Epoch 627/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0890 - acc: 0.9844 - val_loss: 0.3132 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00627: val_acc did not improve from 0.91970\n",
            "Epoch 628/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0888 - acc: 0.9838 - val_loss: 0.3129 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00628: val_acc did not improve from 0.91970\n",
            "Epoch 629/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.0885 - acc: 0.9836 - val_loss: 0.3122 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.91970\n",
            "Epoch 630/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0880 - acc: 0.9851 - val_loss: 0.3132 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00630: val_acc did not improve from 0.91970\n",
            "Epoch 631/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0909 - acc: 0.9834 - val_loss: 0.3125 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00631: val_acc improved from 0.91970 to 0.91990, saving model to /content/saved_models/cifar10_ResNet32v1_model.631.h5\n",
            "Epoch 632/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0849 - acc: 0.9855 - val_loss: 0.3115 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00632: val_acc did not improve from 0.91990\n",
            "Epoch 633/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.0892 - acc: 0.9847 - val_loss: 0.3111 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.91990\n",
            "Epoch 634/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.0906 - acc: 0.9831 - val_loss: 0.3117 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.91990\n",
            "Epoch 635/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0907 - acc: 0.9831 - val_loss: 0.3100 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00635: val_acc improved from 0.91990 to 0.92010, saving model to /content/saved_models/cifar10_ResNet32v1_model.635.h5\n",
            "Epoch 636/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0866 - acc: 0.9859 - val_loss: 0.3102 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.92010\n",
            "Epoch 637/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.0904 - acc: 0.9834 - val_loss: 0.3105 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00637: val_acc did not improve from 0.92010\n",
            "Epoch 638/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0847 - acc: 0.9869 - val_loss: 0.3102 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.92010\n",
            "Epoch 639/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0888 - acc: 0.9838 - val_loss: 0.3102 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.92010\n",
            "Epoch 640/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0870 - acc: 0.9847 - val_loss: 0.3099 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00640: val_acc improved from 0.92010 to 0.92020, saving model to /content/saved_models/cifar10_ResNet32v1_model.640.h5\n",
            "Epoch 641/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0860 - acc: 0.9856 - val_loss: 0.3096 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00641: val_acc improved from 0.92020 to 0.92060, saving model to /content/saved_models/cifar10_ResNet32v1_model.641.h5\n",
            "Epoch 642/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0897 - acc: 0.9843 - val_loss: 0.3088 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.92060\n",
            "Epoch 643/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0844 - acc: 0.9853 - val_loss: 0.3089 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.92060\n",
            "Epoch 644/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0817 - acc: 0.9882 - val_loss: 0.3086 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.92060\n",
            "Epoch 645/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.0888 - acc: 0.9851 - val_loss: 0.3085 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00645: val_acc did not improve from 0.92060\n",
            "Epoch 646/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.0864 - acc: 0.9857 - val_loss: 0.3085 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00646: val_acc did not improve from 0.92060\n",
            "Epoch 647/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0862 - acc: 0.9848 - val_loss: 0.3078 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00647: val_acc did not improve from 0.92060\n",
            "Epoch 648/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0887 - acc: 0.9843 - val_loss: 0.3077 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.92060\n",
            "Epoch 649/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0871 - acc: 0.9841 - val_loss: 0.3083 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.92060\n",
            "Epoch 650/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0841 - acc: 0.9856 - val_loss: 0.3073 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00650: val_acc did not improve from 0.92060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "zPmhfEhinjuy",
        "outputId": "06399143-473a-44c1-fb48-e42b99a2878d"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('simple_trainHistoryDict_clip_1', \"rb\"))\n",
        "functions.plot_loss_acc(history, 2, 0.4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr2veh9jnos3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cccf93f-4a22-4fbc-87fb-6f73b8167606"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9200000166893005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93YaguvSnri4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1edba186-c691-468d-a5e4-466cd02bdf22"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07999998331069946"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYsweyOS3wPM"
      },
      "source": [
        "#### Plotting final graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "MOF7V2LgY8_K",
        "outputId": "6d3451a9-43b4-4592-8823-7a38b41d93de"
      },
      "source": [
        "plot_final_graph(\"simple2_\", ylim_loss=2, ylim_error=0.4)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zjepj31fVNww"
      },
      "source": [
        "### decomposition_rank = 29 & compress_first = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq3bNGTuDGIm"
      },
      "source": [
        "#### Model without clipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ0P4VJ6Li7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4deed7c7-c03f-4b4c-931c-518938a8492a"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(\n",
        "    input_shape, conv_layer = functions.ConvDecomposed2D, compress_first=False,\n",
        "    decomposition_rank=29)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 32, 32, 16)   0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_165 (ConvDeco (None, 32, 32, 16)   2832        activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 32, 32, 16)   64          conv_decomposed2d_165[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 32, 32, 16)   0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_166 (ConvDeco (None, 32, 32, 16)   2832        activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 32, 32, 16)   64          conv_decomposed2d_166[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_75 (Add)                    (None, 32, 32, 16)   0           activation_155[0][0]             \n",
            "                                                                 batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 32, 32, 16)   0           add_75[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_167 (ConvDeco (None, 32, 32, 16)   2832        activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 32, 32, 16)   64          conv_decomposed2d_167[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 32, 32, 16)   0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_168 (ConvDeco (None, 32, 32, 16)   2832        activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 32, 32, 16)   64          conv_decomposed2d_168[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_76 (Add)                    (None, 32, 32, 16)   0           activation_157[0][0]             \n",
            "                                                                 batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 32, 32, 16)   0           add_76[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_169 (ConvDeco (None, 32, 32, 16)   2832        activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 32, 32, 16)   64          conv_decomposed2d_169[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 32, 32, 16)   0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_170 (ConvDeco (None, 32, 32, 16)   2832        activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 32, 32, 16)   64          conv_decomposed2d_170[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_77 (Add)                    (None, 32, 32, 16)   0           activation_159[0][0]             \n",
            "                                                                 batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 32, 32, 16)   0           add_77[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_171 (ConvDeco (None, 32, 32, 16)   2832        activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 32, 32, 16)   64          conv_decomposed2d_171[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 32, 32, 16)   0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_172 (ConvDeco (None, 32, 32, 16)   2832        activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 32, 32, 16)   64          conv_decomposed2d_172[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_78 (Add)                    (None, 32, 32, 16)   0           activation_161[0][0]             \n",
            "                                                                 batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 32, 32, 16)   0           add_78[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_173 (ConvDeco (None, 32, 32, 16)   2832        activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 32, 32, 16)   64          conv_decomposed2d_173[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 32, 32, 16)   0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_174 (ConvDeco (None, 32, 32, 16)   2832        activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 32, 32, 16)   64          conv_decomposed2d_174[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_79 (Add)                    (None, 32, 32, 16)   0           activation_163[0][0]             \n",
            "                                                                 batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 32, 32, 16)   0           add_79[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_175 (ConvDeco (None, 16, 16, 32)   5392        activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 16, 16, 32)   128         conv_decomposed2d_175[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 16, 16, 32)   0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_176 (ConvDeco (None, 16, 16, 32)   9457        activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_177 (ConvDeco (None, 16, 16, 32)   1680        activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 16, 16, 32)   128         conv_decomposed2d_176[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_80 (Add)                    (None, 16, 16, 32)   0           conv_decomposed2d_177[0][0]      \n",
            "                                                                 batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 16, 16, 32)   0           add_80[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_178 (ConvDeco (None, 16, 16, 32)   9457        activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 16, 16, 32)   128         conv_decomposed2d_178[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 16, 16, 32)   0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_179 (ConvDeco (None, 16, 16, 32)   9457        activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 16, 16, 32)   128         conv_decomposed2d_179[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_81 (Add)                    (None, 16, 16, 32)   0           activation_167[0][0]             \n",
            "                                                                 batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 16, 16, 32)   0           add_81[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_180 (ConvDeco (None, 16, 16, 32)   9457        activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 16, 16, 32)   128         conv_decomposed2d_180[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 16, 16, 32)   0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_181 (ConvDeco (None, 16, 16, 32)   9457        activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 16, 16, 32)   128         conv_decomposed2d_181[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_82 (Add)                    (None, 16, 16, 32)   0           activation_169[0][0]             \n",
            "                                                                 batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 16, 16, 32)   0           add_82[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_182 (ConvDeco (None, 16, 16, 32)   9457        activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 16, 16, 32)   128         conv_decomposed2d_182[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 16, 16, 32)   0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_183 (ConvDeco (None, 16, 16, 32)   9457        activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 16, 16, 32)   128         conv_decomposed2d_183[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_83 (Add)                    (None, 16, 16, 32)   0           activation_171[0][0]             \n",
            "                                                                 batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 16, 16, 32)   0           add_83[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_184 (ConvDeco (None, 16, 16, 32)   9457        activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 16, 16, 32)   128         conv_decomposed2d_184[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 16, 16, 32)   0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_185 (ConvDeco (None, 16, 16, 32)   9457        activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 16, 16, 32)   128         conv_decomposed2d_185[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_84 (Add)                    (None, 16, 16, 32)   0           activation_173[0][0]             \n",
            "                                                                 batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 16, 16, 32)   0           add_84[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_186 (ConvDeco (None, 8, 8, 64)     10417       activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 8, 8, 64)     256         conv_decomposed2d_186[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 8, 8, 64)     0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_187 (ConvDeco (None, 8, 8, 64)     11345       activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_188 (ConvDeco (None, 8, 8, 64)     3689        activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 8, 8, 64)     256         conv_decomposed2d_187[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_85 (Add)                    (None, 8, 8, 64)     0           conv_decomposed2d_188[0][0]      \n",
            "                                                                 batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 8, 8, 64)     0           add_85[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_189 (ConvDeco (None, 8, 8, 64)     11345       activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 8, 8, 64)     256         conv_decomposed2d_189[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 8, 8, 64)     0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_190 (ConvDeco (None, 8, 8, 64)     11345       activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 8, 8, 64)     256         conv_decomposed2d_190[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_86 (Add)                    (None, 8, 8, 64)     0           activation_177[0][0]             \n",
            "                                                                 batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 8, 8, 64)     0           add_86[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_191 (ConvDeco (None, 8, 8, 64)     11345       activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 8, 8, 64)     256         conv_decomposed2d_191[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 8, 8, 64)     0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_192 (ConvDeco (None, 8, 8, 64)     11345       activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 8, 8, 64)     256         conv_decomposed2d_192[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_87 (Add)                    (None, 8, 8, 64)     0           activation_179[0][0]             \n",
            "                                                                 batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 8, 8, 64)     0           add_87[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_193 (ConvDeco (None, 8, 8, 64)     11345       activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 8, 8, 64)     256         conv_decomposed2d_193[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 8, 8, 64)     0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_194 (ConvDeco (None, 8, 8, 64)     11345       activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 8, 8, 64)     256         conv_decomposed2d_194[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_88 (Add)                    (None, 8, 8, 64)     0           activation_181[0][0]             \n",
            "                                                                 batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 8, 8, 64)     0           add_88[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_195 (ConvDeco (None, 8, 8, 64)     11345       activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 8, 8, 64)     256         conv_decomposed2d_195[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 8, 8, 64)     0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_196 (ConvDeco (None, 8, 8, 64)     11345       activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 8, 8, 64)     256         conv_decomposed2d_196[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_89 (Add)                    (None, 8, 8, 64)     0           activation_183[0][0]             \n",
            "                                                                 batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 8, 8, 64)     0           add_89[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 1, 1, 64)     0           activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 64)           0           average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 10)           650         flatten_5[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 242,358\n",
            "Trainable params: 240,086\n",
            "Non-trainable params: 2,272\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMHS184LtygX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d2a8754-3536-4d66-a74d-3eafa38a0789"
      },
      "source": [
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'trainHistoryDict', steps_per_epoch=100, batch_size=100,\n",
        "                       epochs=650)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 49s 104ms/step - loss: 2.8575 - acc: 0.2660 - val_loss: 6.4128 - val_acc: 0.1269\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.12690, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 2.2402 - acc: 0.3735 - val_loss: 2.8754 - val_acc: 0.2428\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.12690 to 0.24280, saving model to /content/saved_models/cifar10_ResNet32v1_model.002.h5\n",
            "Epoch 3/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 2.1265 - acc: 0.4138 - val_loss: 2.9761 - val_acc: 0.2504\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.24280 to 0.25040, saving model to /content/saved_models/cifar10_ResNet32v1_model.003.h5\n",
            "Epoch 4/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 2.0292 - acc: 0.4528 - val_loss: 2.8335 - val_acc: 0.3470\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.25040 to 0.34700, saving model to /content/saved_models/cifar10_ResNet32v1_model.004.h5\n",
            "Epoch 5/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.9298 - acc: 0.4939 - val_loss: 2.0659 - val_acc: 0.4938\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.34700 to 0.49380, saving model to /content/saved_models/cifar10_ResNet32v1_model.005.h5\n",
            "Epoch 6/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.8663 - acc: 0.5159 - val_loss: 3.2709 - val_acc: 0.2988\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.49380\n",
            "Epoch 7/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.7824 - acc: 0.5464 - val_loss: 2.0349 - val_acc: 0.4826\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.49380\n",
            "Epoch 8/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.7352 - acc: 0.5659 - val_loss: 2.5221 - val_acc: 0.3670\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.49380\n",
            "Epoch 9/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.7075 - acc: 0.5756 - val_loss: 1.7378 - val_acc: 0.5646\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.49380 to 0.56460, saving model to /content/saved_models/cifar10_ResNet32v1_model.009.h5\n",
            "Epoch 10/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.6410 - acc: 0.5927 - val_loss: 1.9742 - val_acc: 0.5123\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.56460\n",
            "Epoch 11/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.6135 - acc: 0.6060 - val_loss: 2.7460 - val_acc: 0.3930\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.56460\n",
            "Epoch 12/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.5745 - acc: 0.6093 - val_loss: 2.0875 - val_acc: 0.5105\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.56460\n",
            "Epoch 13/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.5125 - acc: 0.6338 - val_loss: 1.9942 - val_acc: 0.5111\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.56460\n",
            "Epoch 14/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.5133 - acc: 0.6371 - val_loss: 1.7664 - val_acc: 0.5410\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.56460\n",
            "Epoch 15/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4929 - acc: 0.6350 - val_loss: 1.6614 - val_acc: 0.5930\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.56460 to 0.59300, saving model to /content/saved_models/cifar10_ResNet32v1_model.015.h5\n",
            "Epoch 16/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4452 - acc: 0.6542 - val_loss: 2.0104 - val_acc: 0.5088\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.59300\n",
            "Epoch 17/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4231 - acc: 0.6681 - val_loss: 1.5661 - val_acc: 0.6264\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.59300 to 0.62640, saving model to /content/saved_models/cifar10_ResNet32v1_model.017.h5\n",
            "Epoch 18/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3933 - acc: 0.6737 - val_loss: 1.5222 - val_acc: 0.6371\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.62640 to 0.63710, saving model to /content/saved_models/cifar10_ResNet32v1_model.018.h5\n",
            "Epoch 19/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3853 - acc: 0.6684 - val_loss: 1.5396 - val_acc: 0.6363\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.63710\n",
            "Epoch 20/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3173 - acc: 0.6972 - val_loss: 1.7075 - val_acc: 0.6058\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.63710\n",
            "Epoch 21/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3341 - acc: 0.6858 - val_loss: 1.6819 - val_acc: 0.5974\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.63710\n",
            "Epoch 22/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3022 - acc: 0.7006 - val_loss: 1.5272 - val_acc: 0.6348\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.63710\n",
            "Epoch 23/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2808 - acc: 0.7067 - val_loss: 2.4580 - val_acc: 0.4456\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.63710\n",
            "Epoch 24/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2618 - acc: 0.7143 - val_loss: 1.8726 - val_acc: 0.5618\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.63710\n",
            "Epoch 25/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2400 - acc: 0.7234 - val_loss: 1.6025 - val_acc: 0.6228\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.63710\n",
            "Epoch 26/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2381 - acc: 0.7160 - val_loss: 1.4341 - val_acc: 0.6637\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.63710 to 0.66370, saving model to /content/saved_models/cifar10_ResNet32v1_model.026.h5\n",
            "Epoch 27/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2355 - acc: 0.7217 - val_loss: 1.5586 - val_acc: 0.6217\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.66370\n",
            "Epoch 28/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.1995 - acc: 0.7316 - val_loss: 1.4266 - val_acc: 0.6595\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.66370\n",
            "Epoch 29/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2056 - acc: 0.7283 - val_loss: 1.4816 - val_acc: 0.6488\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.66370\n",
            "Epoch 30/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.1814 - acc: 0.7374 - val_loss: 1.6477 - val_acc: 0.6006\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.66370\n",
            "Epoch 31/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.1556 - acc: 0.7419 - val_loss: 1.3599 - val_acc: 0.6902\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.66370 to 0.69020, saving model to /content/saved_models/cifar10_ResNet32v1_model.031.h5\n",
            "Epoch 32/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.1763 - acc: 0.7340 - val_loss: 1.6850 - val_acc: 0.6048\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.69020\n",
            "Epoch 33/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.1483 - acc: 0.7418 - val_loss: 1.2944 - val_acc: 0.6993\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.69020 to 0.69930, saving model to /content/saved_models/cifar10_ResNet32v1_model.033.h5\n",
            "Epoch 34/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.1213 - acc: 0.7510 - val_loss: 1.6161 - val_acc: 0.6345\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.69930\n",
            "Epoch 35/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.1067 - acc: 0.7571 - val_loss: 1.3571 - val_acc: 0.6849\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.69930\n",
            "Epoch 36/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.1220 - acc: 0.7463 - val_loss: 1.5623 - val_acc: 0.6377\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.69930\n",
            "Epoch 37/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.1032 - acc: 0.7528 - val_loss: 1.2541 - val_acc: 0.7038\n",
            "\n",
            "Epoch 00037: val_acc improved from 0.69930 to 0.70380, saving model to /content/saved_models/cifar10_ResNet32v1_model.037.h5\n",
            "Epoch 38/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0747 - acc: 0.7649 - val_loss: 1.3995 - val_acc: 0.6664\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.70380\n",
            "Epoch 39/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0871 - acc: 0.7584 - val_loss: 1.6764 - val_acc: 0.6199\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.70380\n",
            "Epoch 40/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0832 - acc: 0.7623 - val_loss: 1.1306 - val_acc: 0.7432\n",
            "\n",
            "Epoch 00040: val_acc improved from 0.70380 to 0.74320, saving model to /content/saved_models/cifar10_ResNet32v1_model.040.h5\n",
            "Epoch 41/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0611 - acc: 0.7671 - val_loss: 1.2312 - val_acc: 0.7262\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.74320\n",
            "Epoch 42/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.0490 - acc: 0.7704 - val_loss: 1.7765 - val_acc: 0.6051\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.74320\n",
            "Epoch 43/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0303 - acc: 0.7758 - val_loss: 1.3366 - val_acc: 0.6923\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.74320\n",
            "Epoch 44/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.0385 - acc: 0.7728 - val_loss: 1.4780 - val_acc: 0.6455\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.74320\n",
            "Epoch 45/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0342 - acc: 0.7725 - val_loss: 1.3033 - val_acc: 0.6868\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.74320\n",
            "Epoch 46/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0263 - acc: 0.7763 - val_loss: 1.2169 - val_acc: 0.7230\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.74320\n",
            "Epoch 47/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0279 - acc: 0.7713 - val_loss: 1.4377 - val_acc: 0.6630\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.74320\n",
            "Epoch 48/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.0062 - acc: 0.7791 - val_loss: 1.5958 - val_acc: 0.6407\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.74320\n",
            "Epoch 49/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.0052 - acc: 0.7819 - val_loss: 1.5270 - val_acc: 0.6489\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.74320\n",
            "Epoch 50/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0071 - acc: 0.7799 - val_loss: 1.1193 - val_acc: 0.7418\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.74320\n",
            "Epoch 51/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.9779 - acc: 0.7911 - val_loss: 1.0985 - val_acc: 0.7563\n",
            "\n",
            "Epoch 00051: val_acc improved from 0.74320 to 0.75630, saving model to /content/saved_models/cifar10_ResNet32v1_model.051.h5\n",
            "Epoch 52/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.9754 - acc: 0.7839 - val_loss: 1.2743 - val_acc: 0.6943\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.75630\n",
            "Epoch 53/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9768 - acc: 0.7901 - val_loss: 1.1256 - val_acc: 0.7451\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.75630\n",
            "Epoch 54/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.9695 - acc: 0.7896 - val_loss: 1.3089 - val_acc: 0.7015\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.75630\n",
            "Epoch 55/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.9582 - acc: 0.7891 - val_loss: 1.2826 - val_acc: 0.6937\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.75630\n",
            "Epoch 56/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.9590 - acc: 0.7914 - val_loss: 1.5630 - val_acc: 0.6344\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.75630\n",
            "Epoch 57/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9360 - acc: 0.7955 - val_loss: 1.1494 - val_acc: 0.7393\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.75630\n",
            "Epoch 58/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9385 - acc: 0.7969 - val_loss: 1.3625 - val_acc: 0.6823\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.75630\n",
            "Epoch 59/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9313 - acc: 0.7975 - val_loss: 1.1685 - val_acc: 0.7288\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.75630\n",
            "Epoch 60/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9353 - acc: 0.7968 - val_loss: 1.2807 - val_acc: 0.7094\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.75630\n",
            "Epoch 61/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.9162 - acc: 0.8021 - val_loss: 1.3901 - val_acc: 0.6782\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.75630\n",
            "Epoch 62/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9391 - acc: 0.7949 - val_loss: 1.0057 - val_acc: 0.7760\n",
            "\n",
            "Epoch 00062: val_acc improved from 0.75630 to 0.77600, saving model to /content/saved_models/cifar10_ResNet32v1_model.062.h5\n",
            "Epoch 63/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9330 - acc: 0.7952 - val_loss: 1.1277 - val_acc: 0.7468\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.77600\n",
            "Epoch 64/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9044 - acc: 0.8033 - val_loss: 1.2089 - val_acc: 0.7167\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.77600\n",
            "Epoch 65/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9142 - acc: 0.8012 - val_loss: 1.5592 - val_acc: 0.6464\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.77600\n",
            "Epoch 66/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9073 - acc: 0.8043 - val_loss: 1.1708 - val_acc: 0.7202\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.77600\n",
            "Epoch 67/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8961 - acc: 0.8073 - val_loss: 1.1191 - val_acc: 0.7427\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.77600\n",
            "Epoch 68/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8836 - acc: 0.8079 - val_loss: 1.1948 - val_acc: 0.7158\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.77600\n",
            "Epoch 69/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9009 - acc: 0.8042 - val_loss: 1.0246 - val_acc: 0.7679\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.77600\n",
            "Epoch 70/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8801 - acc: 0.8094 - val_loss: 1.0420 - val_acc: 0.7628\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.77600\n",
            "Epoch 71/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8748 - acc: 0.8115 - val_loss: 1.0971 - val_acc: 0.7388\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.77600\n",
            "Epoch 72/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8657 - acc: 0.8116 - val_loss: 1.0909 - val_acc: 0.7463\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.77600\n",
            "Epoch 73/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8707 - acc: 0.8132 - val_loss: 1.2514 - val_acc: 0.6971\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.77600\n",
            "Epoch 74/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8871 - acc: 0.8071 - val_loss: 1.4670 - val_acc: 0.6652\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.77600\n",
            "Epoch 75/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8569 - acc: 0.8138 - val_loss: 1.3635 - val_acc: 0.6871\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.77600\n",
            "Epoch 76/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8600 - acc: 0.8130 - val_loss: 1.4922 - val_acc: 0.6417\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.77600\n",
            "Epoch 77/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8509 - acc: 0.8184 - val_loss: 1.2157 - val_acc: 0.7112\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.77600\n",
            "Epoch 78/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8463 - acc: 0.8190 - val_loss: 1.2406 - val_acc: 0.7057\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.77600\n",
            "Epoch 79/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8388 - acc: 0.8206 - val_loss: 1.0856 - val_acc: 0.7596\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.77600\n",
            "Epoch 80/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8338 - acc: 0.8214 - val_loss: 1.1381 - val_acc: 0.7382\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.77600\n",
            "Epoch 81/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8319 - acc: 0.8227 - val_loss: 1.0240 - val_acc: 0.7655\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.77600\n",
            "Epoch 82/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8167 - acc: 0.8269 - val_loss: 0.9379 - val_acc: 0.7891\n",
            "\n",
            "Epoch 00082: val_acc improved from 0.77600 to 0.78910, saving model to /content/saved_models/cifar10_ResNet32v1_model.082.h5\n",
            "Epoch 83/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8290 - acc: 0.8195 - val_loss: 1.1797 - val_acc: 0.7397\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.78910\n",
            "Epoch 84/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8225 - acc: 0.8217 - val_loss: 1.0440 - val_acc: 0.7644\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.78910\n",
            "Epoch 85/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8131 - acc: 0.8282 - val_loss: 1.5389 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.78910\n",
            "Epoch 86/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8182 - acc: 0.8233 - val_loss: 1.0376 - val_acc: 0.7558\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.78910\n",
            "Epoch 87/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8164 - acc: 0.8220 - val_loss: 1.2023 - val_acc: 0.7159\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.78910\n",
            "Epoch 88/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8032 - acc: 0.8280 - val_loss: 1.0652 - val_acc: 0.7521\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.78910\n",
            "Epoch 89/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8118 - acc: 0.8212 - val_loss: 1.1453 - val_acc: 0.7343\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.78910\n",
            "Epoch 90/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8030 - acc: 0.8273 - val_loss: 1.2152 - val_acc: 0.7115\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.78910\n",
            "Epoch 91/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8154 - acc: 0.8229 - val_loss: 1.0728 - val_acc: 0.7457\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.78910\n",
            "Epoch 92/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7777 - acc: 0.8357 - val_loss: 1.0760 - val_acc: 0.7476\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.78910\n",
            "Epoch 93/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8042 - acc: 0.8270 - val_loss: 1.1227 - val_acc: 0.7423\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.78910\n",
            "Epoch 94/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7988 - acc: 0.8297 - val_loss: 1.3348 - val_acc: 0.6877\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.78910\n",
            "Epoch 95/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7929 - acc: 0.8263 - val_loss: 1.0910 - val_acc: 0.7463\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.78910\n",
            "Epoch 96/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7876 - acc: 0.8272 - val_loss: 1.1273 - val_acc: 0.7462\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.78910\n",
            "Epoch 97/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7692 - acc: 0.8335 - val_loss: 0.9893 - val_acc: 0.7686\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.78910\n",
            "Epoch 98/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7801 - acc: 0.8301 - val_loss: 0.9903 - val_acc: 0.7739\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.78910\n",
            "Epoch 99/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7920 - acc: 0.8263 - val_loss: 1.1789 - val_acc: 0.7204\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.78910\n",
            "Epoch 100/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7785 - acc: 0.8273 - val_loss: 1.1522 - val_acc: 0.7307\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.78910\n",
            "Epoch 101/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7697 - acc: 0.8317 - val_loss: 0.9849 - val_acc: 0.7593\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.78910\n",
            "Epoch 102/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7567 - acc: 0.8373 - val_loss: 0.9222 - val_acc: 0.7896\n",
            "\n",
            "Epoch 00102: val_acc improved from 0.78910 to 0.78960, saving model to /content/saved_models/cifar10_ResNet32v1_model.102.h5\n",
            "Epoch 103/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7634 - acc: 0.8331 - val_loss: 0.9790 - val_acc: 0.7745\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.78960\n",
            "Epoch 104/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7597 - acc: 0.8360 - val_loss: 1.1363 - val_acc: 0.7394\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.78960\n",
            "Epoch 105/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7680 - acc: 0.8296 - val_loss: 0.9511 - val_acc: 0.7786\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.78960\n",
            "Epoch 106/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7542 - acc: 0.8380 - val_loss: 0.9529 - val_acc: 0.7696\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.78960\n",
            "Epoch 107/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7473 - acc: 0.8374 - val_loss: 0.9259 - val_acc: 0.7857\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.78960\n",
            "Epoch 108/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7526 - acc: 0.8352 - val_loss: 1.1072 - val_acc: 0.7459\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.78960\n",
            "Epoch 109/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7677 - acc: 0.8329 - val_loss: 0.9221 - val_acc: 0.7907\n",
            "\n",
            "Epoch 00109: val_acc improved from 0.78960 to 0.79070, saving model to /content/saved_models/cifar10_ResNet32v1_model.109.h5\n",
            "Epoch 110/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7361 - acc: 0.8444 - val_loss: 0.9925 - val_acc: 0.7588\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.79070\n",
            "Epoch 111/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7374 - acc: 0.8411 - val_loss: 1.1062 - val_acc: 0.7415\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.79070\n",
            "Epoch 112/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7437 - acc: 0.8407 - val_loss: 1.0660 - val_acc: 0.7553\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.79070\n",
            "Epoch 113/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7396 - acc: 0.8389 - val_loss: 1.1348 - val_acc: 0.7421\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.79070\n",
            "Epoch 114/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7551 - acc: 0.8323 - val_loss: 0.8762 - val_acc: 0.7941\n",
            "\n",
            "Epoch 00114: val_acc improved from 0.79070 to 0.79410, saving model to /content/saved_models/cifar10_ResNet32v1_model.114.h5\n",
            "Epoch 115/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7386 - acc: 0.8363 - val_loss: 1.0175 - val_acc: 0.7772\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.79410\n",
            "Epoch 116/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7374 - acc: 0.8399 - val_loss: 0.9412 - val_acc: 0.7755\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.79410\n",
            "Epoch 117/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7370 - acc: 0.8416 - val_loss: 1.2232 - val_acc: 0.7112\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.79410\n",
            "Epoch 118/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7279 - acc: 0.8380 - val_loss: 1.2049 - val_acc: 0.7284\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.79410\n",
            "Epoch 119/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7333 - acc: 0.8410 - val_loss: 0.9952 - val_acc: 0.7713\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.79410\n",
            "Epoch 120/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7189 - acc: 0.8425 - val_loss: 1.0949 - val_acc: 0.7465\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.79410\n",
            "Epoch 121/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7262 - acc: 0.8404 - val_loss: 1.1441 - val_acc: 0.7342\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.79410\n",
            "Epoch 122/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7161 - acc: 0.8436 - val_loss: 0.8951 - val_acc: 0.7990\n",
            "\n",
            "Epoch 00122: val_acc improved from 0.79410 to 0.79900, saving model to /content/saved_models/cifar10_ResNet32v1_model.122.h5\n",
            "Epoch 123/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7273 - acc: 0.8381 - val_loss: 1.1251 - val_acc: 0.7358\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.79900\n",
            "Epoch 124/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7176 - acc: 0.8448 - val_loss: 0.9918 - val_acc: 0.7584\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.79900\n",
            "Epoch 125/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7283 - acc: 0.8393 - val_loss: 0.9260 - val_acc: 0.7826\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.79900\n",
            "Epoch 126/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7081 - acc: 0.8455 - val_loss: 0.9639 - val_acc: 0.7701\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.79900\n",
            "Epoch 127/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7167 - acc: 0.8450 - val_loss: 1.1087 - val_acc: 0.7407\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.79900\n",
            "Epoch 128/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6869 - acc: 0.8535 - val_loss: 0.8748 - val_acc: 0.7930\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.79900\n",
            "Epoch 129/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7135 - acc: 0.8443 - val_loss: 0.9144 - val_acc: 0.7883\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.79900\n",
            "Epoch 130/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6865 - acc: 0.8565 - val_loss: 1.1079 - val_acc: 0.7468\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.79900\n",
            "Epoch 131/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7045 - acc: 0.8491 - val_loss: 1.0688 - val_acc: 0.7450\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.79900\n",
            "Epoch 132/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7006 - acc: 0.8485 - val_loss: 0.9881 - val_acc: 0.7629\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.79900\n",
            "Epoch 133/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6995 - acc: 0.8520 - val_loss: 0.8353 - val_acc: 0.8062\n",
            "\n",
            "Epoch 00133: val_acc improved from 0.79900 to 0.80620, saving model to /content/saved_models/cifar10_ResNet32v1_model.133.h5\n",
            "Epoch 134/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6996 - acc: 0.8509 - val_loss: 0.7988 - val_acc: 0.8152\n",
            "\n",
            "Epoch 00134: val_acc improved from 0.80620 to 0.81520, saving model to /content/saved_models/cifar10_ResNet32v1_model.134.h5\n",
            "Epoch 135/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6912 - acc: 0.8509 - val_loss: 1.3120 - val_acc: 0.6934\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.81520\n",
            "Epoch 136/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6927 - acc: 0.8490 - val_loss: 1.2306 - val_acc: 0.7029\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.81520\n",
            "Epoch 137/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6818 - acc: 0.8551 - val_loss: 0.9357 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.81520\n",
            "Epoch 138/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6851 - acc: 0.8504 - val_loss: 1.1901 - val_acc: 0.7026\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.81520\n",
            "Epoch 139/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6947 - acc: 0.8462 - val_loss: 1.0065 - val_acc: 0.7535\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.81520\n",
            "Epoch 140/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7165 - acc: 0.8395 - val_loss: 0.9188 - val_acc: 0.7837\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.81520\n",
            "Epoch 141/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6812 - acc: 0.8568 - val_loss: 0.9284 - val_acc: 0.7797\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.81520\n",
            "Epoch 142/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6810 - acc: 0.8509 - val_loss: 0.8399 - val_acc: 0.8064\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.81520\n",
            "Epoch 143/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6714 - acc: 0.8547 - val_loss: 0.9930 - val_acc: 0.7607\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.81520\n",
            "Epoch 144/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6807 - acc: 0.8528 - val_loss: 1.0678 - val_acc: 0.7537\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.81520\n",
            "Epoch 145/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6781 - acc: 0.8508 - val_loss: 1.2709 - val_acc: 0.7046\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.81520\n",
            "Epoch 146/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6743 - acc: 0.8547 - val_loss: 1.0178 - val_acc: 0.7593\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.81520\n",
            "Epoch 147/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6641 - acc: 0.8546 - val_loss: 1.0192 - val_acc: 0.7651\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.81520\n",
            "Epoch 148/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6738 - acc: 0.8525 - val_loss: 1.0724 - val_acc: 0.7443\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.81520\n",
            "Epoch 149/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6713 - acc: 0.8515 - val_loss: 0.9275 - val_acc: 0.7873\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.81520\n",
            "Epoch 150/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6726 - acc: 0.8517 - val_loss: 0.7767 - val_acc: 0.8245\n",
            "\n",
            "Epoch 00150: val_acc improved from 0.81520 to 0.82450, saving model to /content/saved_models/cifar10_ResNet32v1_model.150.h5\n",
            "Epoch 151/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6686 - acc: 0.8522 - val_loss: 0.9961 - val_acc: 0.7694\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.82450\n",
            "Epoch 152/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6645 - acc: 0.8599 - val_loss: 0.9158 - val_acc: 0.7905\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.82450\n",
            "Epoch 153/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6649 - acc: 0.8573 - val_loss: 0.8367 - val_acc: 0.7989\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.82450\n",
            "Epoch 154/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6729 - acc: 0.8534 - val_loss: 0.8702 - val_acc: 0.7974\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.82450\n",
            "Epoch 155/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6601 - acc: 0.8570 - val_loss: 0.8387 - val_acc: 0.8027\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.82450\n",
            "Epoch 156/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6653 - acc: 0.8517 - val_loss: 0.9766 - val_acc: 0.7728\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.82450\n",
            "Epoch 157/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6559 - acc: 0.8523 - val_loss: 0.9769 - val_acc: 0.7645\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.82450\n",
            "Epoch 158/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6541 - acc: 0.8599 - val_loss: 1.0707 - val_acc: 0.7444\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.82450\n",
            "Epoch 159/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6359 - acc: 0.8641 - val_loss: 1.0759 - val_acc: 0.7546\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.82450\n",
            "Epoch 160/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6417 - acc: 0.8598 - val_loss: 0.8241 - val_acc: 0.8088\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.82450\n",
            "Epoch 161/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6498 - acc: 0.8565 - val_loss: 0.8098 - val_acc: 0.8128\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.82450\n",
            "Epoch 162/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6455 - acc: 0.8608 - val_loss: 1.3037 - val_acc: 0.6971\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.82450\n",
            "Epoch 163/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6420 - acc: 0.8617 - val_loss: 0.9805 - val_acc: 0.7642\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.82450\n",
            "Epoch 164/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6490 - acc: 0.8615 - val_loss: 0.8595 - val_acc: 0.8024\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.82450\n",
            "Epoch 165/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6563 - acc: 0.8568 - val_loss: 1.0154 - val_acc: 0.7689\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.82450\n",
            "Epoch 166/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6459 - acc: 0.8592 - val_loss: 0.8213 - val_acc: 0.8035\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.82450\n",
            "Epoch 167/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6470 - acc: 0.8566 - val_loss: 0.8926 - val_acc: 0.8012\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.82450\n",
            "Epoch 168/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6393 - acc: 0.8625 - val_loss: 1.3027 - val_acc: 0.7022\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.82450\n",
            "Epoch 169/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6441 - acc: 0.8587 - val_loss: 0.8243 - val_acc: 0.8038\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.82450\n",
            "Epoch 170/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6508 - acc: 0.8589 - val_loss: 0.8403 - val_acc: 0.8040\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.82450\n",
            "Epoch 171/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6421 - acc: 0.8625 - val_loss: 1.1257 - val_acc: 0.7292\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.82450\n",
            "Epoch 172/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6388 - acc: 0.8603 - val_loss: 0.8180 - val_acc: 0.8045\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.82450\n",
            "Epoch 173/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6232 - acc: 0.8667 - val_loss: 0.9728 - val_acc: 0.7768\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.82450\n",
            "Epoch 174/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6331 - acc: 0.8634 - val_loss: 0.9460 - val_acc: 0.7749\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.82450\n",
            "Epoch 175/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6428 - acc: 0.8589 - val_loss: 1.1814 - val_acc: 0.7178\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.82450\n",
            "Epoch 176/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6358 - acc: 0.8611 - val_loss: 0.8880 - val_acc: 0.7912\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.82450\n",
            "Epoch 177/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6320 - acc: 0.8643 - val_loss: 0.9657 - val_acc: 0.7671\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.82450\n",
            "Epoch 178/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6435 - acc: 0.8560 - val_loss: 0.8606 - val_acc: 0.7937\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.82450\n",
            "Epoch 179/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6197 - acc: 0.8711 - val_loss: 0.9008 - val_acc: 0.7968\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.82450\n",
            "Epoch 180/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6181 - acc: 0.8692 - val_loss: 0.9497 - val_acc: 0.7740\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.82450\n",
            "Epoch 181/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6161 - acc: 0.8667 - val_loss: 0.7927 - val_acc: 0.8147\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.82450\n",
            "Epoch 182/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6247 - acc: 0.8653 - val_loss: 1.1158 - val_acc: 0.7353\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.82450\n",
            "Epoch 183/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6187 - acc: 0.8660 - val_loss: 0.8209 - val_acc: 0.8104\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.82450\n",
            "Epoch 184/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6185 - acc: 0.8672 - val_loss: 0.8093 - val_acc: 0.8231\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.82450\n",
            "Epoch 185/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6134 - acc: 0.8673 - val_loss: 0.8233 - val_acc: 0.8106\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.82450\n",
            "Epoch 186/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6293 - acc: 0.8624 - val_loss: 1.1138 - val_acc: 0.7409\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.82450\n",
            "Epoch 187/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6516 - acc: 0.8541 - val_loss: 0.9543 - val_acc: 0.7728\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.82450\n",
            "Epoch 188/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6056 - acc: 0.8678 - val_loss: 0.8974 - val_acc: 0.7801\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.82450\n",
            "Epoch 189/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6177 - acc: 0.8662 - val_loss: 0.9057 - val_acc: 0.7834\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.82450\n",
            "Epoch 190/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6021 - acc: 0.8716 - val_loss: 0.8485 - val_acc: 0.8089\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.82450\n",
            "Epoch 191/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6107 - acc: 0.8672 - val_loss: 0.8098 - val_acc: 0.8096\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.82450\n",
            "Epoch 192/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6138 - acc: 0.8674 - val_loss: 0.9057 - val_acc: 0.7788\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.82450\n",
            "Epoch 193/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6108 - acc: 0.8659 - val_loss: 0.8583 - val_acc: 0.7919\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.82450\n",
            "Epoch 194/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6064 - acc: 0.8670 - val_loss: 0.9285 - val_acc: 0.7731\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.82450\n",
            "Epoch 195/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6115 - acc: 0.8664 - val_loss: 0.8732 - val_acc: 0.7898\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.82450\n",
            "Epoch 196/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6039 - acc: 0.8685 - val_loss: 0.8984 - val_acc: 0.7855\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.82450\n",
            "Epoch 197/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6204 - acc: 0.8627 - val_loss: 1.0080 - val_acc: 0.7665\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.82450\n",
            "Epoch 198/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6022 - acc: 0.8698 - val_loss: 1.0134 - val_acc: 0.7623\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.82450\n",
            "Epoch 199/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6042 - acc: 0.8653 - val_loss: 1.2448 - val_acc: 0.6898\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.82450\n",
            "Epoch 200/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6103 - acc: 0.8690 - val_loss: 1.0747 - val_acc: 0.7481\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.82450\n",
            "Epoch 201/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6086 - acc: 0.8669 - val_loss: 0.7327 - val_acc: 0.8289\n",
            "\n",
            "Epoch 00201: val_acc improved from 0.82450 to 0.82890, saving model to /content/saved_models/cifar10_ResNet32v1_model.201.h5\n",
            "Epoch 202/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5893 - acc: 0.8722 - val_loss: 0.8528 - val_acc: 0.7920\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.82890\n",
            "Epoch 203/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5919 - acc: 0.8720 - val_loss: 1.0209 - val_acc: 0.7620\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.82890\n",
            "Epoch 204/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6035 - acc: 0.8683 - val_loss: 0.7736 - val_acc: 0.8244\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.82890\n",
            "Epoch 205/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6028 - acc: 0.8714 - val_loss: 0.9148 - val_acc: 0.7845\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.82890\n",
            "Epoch 206/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6073 - acc: 0.8636 - val_loss: 0.8615 - val_acc: 0.7926\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.82890\n",
            "Epoch 207/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6055 - acc: 0.8668 - val_loss: 0.7119 - val_acc: 0.8350\n",
            "\n",
            "Epoch 00207: val_acc improved from 0.82890 to 0.83500, saving model to /content/saved_models/cifar10_ResNet32v1_model.207.h5\n",
            "Epoch 208/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5932 - acc: 0.8718 - val_loss: 0.8136 - val_acc: 0.8046\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.83500\n",
            "Epoch 209/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6071 - acc: 0.8711 - val_loss: 0.9001 - val_acc: 0.7827\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.83500\n",
            "Epoch 210/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5940 - acc: 0.8726 - val_loss: 0.9001 - val_acc: 0.7806\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.83500\n",
            "Epoch 211/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6048 - acc: 0.8677 - val_loss: 0.8806 - val_acc: 0.7917\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.83500\n",
            "Epoch 212/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6139 - acc: 0.8642 - val_loss: 0.7037 - val_acc: 0.8365\n",
            "\n",
            "Epoch 00212: val_acc improved from 0.83500 to 0.83650, saving model to /content/saved_models/cifar10_ResNet32v1_model.212.h5\n",
            "Epoch 213/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6025 - acc: 0.8699 - val_loss: 1.1308 - val_acc: 0.7483\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.83650\n",
            "Epoch 214/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5896 - acc: 0.8710 - val_loss: 0.9204 - val_acc: 0.7778\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.83650\n",
            "Epoch 215/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5898 - acc: 0.8721 - val_loss: 1.0045 - val_acc: 0.7545\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.83650\n",
            "Epoch 216/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5850 - acc: 0.8741 - val_loss: 1.1398 - val_acc: 0.7139\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.83650\n",
            "Epoch 217/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5858 - acc: 0.8746 - val_loss: 0.7527 - val_acc: 0.8227\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.83650\n",
            "Epoch 218/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5796 - acc: 0.8762 - val_loss: 0.9019 - val_acc: 0.7788\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.83650\n",
            "Epoch 219/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5915 - acc: 0.8741 - val_loss: 0.8938 - val_acc: 0.7970\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.83650\n",
            "Epoch 220/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5849 - acc: 0.8735 - val_loss: 0.7371 - val_acc: 0.8227\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.83650\n",
            "Epoch 221/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5872 - acc: 0.8695 - val_loss: 0.9591 - val_acc: 0.7720\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.83650\n",
            "Epoch 222/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5732 - acc: 0.8776 - val_loss: 0.8364 - val_acc: 0.8004\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.83650\n",
            "Epoch 223/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5715 - acc: 0.8750 - val_loss: 0.7299 - val_acc: 0.8292\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.83650\n",
            "Epoch 224/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5904 - acc: 0.8668 - val_loss: 1.0644 - val_acc: 0.7501\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.83650\n",
            "Epoch 225/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5870 - acc: 0.8743 - val_loss: 0.8045 - val_acc: 0.8102\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.83650\n",
            "Epoch 226/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5831 - acc: 0.8743 - val_loss: 0.7955 - val_acc: 0.8105\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.83650\n",
            "Epoch 227/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5752 - acc: 0.8770 - val_loss: 0.9097 - val_acc: 0.7904\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.83650\n",
            "Epoch 228/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5881 - acc: 0.8715 - val_loss: 0.8261 - val_acc: 0.8033\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.83650\n",
            "Epoch 229/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5674 - acc: 0.8808 - val_loss: 0.8293 - val_acc: 0.8022\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.83650\n",
            "Epoch 230/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5798 - acc: 0.8745 - val_loss: 0.8974 - val_acc: 0.7734\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.83650\n",
            "Epoch 231/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5770 - acc: 0.8773 - val_loss: 0.7409 - val_acc: 0.8223\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.83650\n",
            "Epoch 232/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5746 - acc: 0.8783 - val_loss: 0.9678 - val_acc: 0.7651\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.83650\n",
            "Epoch 233/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 120ms/step - loss: 0.5777 - acc: 0.8733 - val_loss: 0.9831 - val_acc: 0.7659\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.83650\n",
            "Epoch 234/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5618 - acc: 0.8794 - val_loss: 0.7925 - val_acc: 0.8136\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.83650\n",
            "Epoch 235/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5867 - acc: 0.8684 - val_loss: 1.0536 - val_acc: 0.7626\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.83650\n",
            "Epoch 236/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5714 - acc: 0.8781 - val_loss: 0.8993 - val_acc: 0.7946\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.83650\n",
            "Epoch 237/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5788 - acc: 0.8743 - val_loss: 0.8398 - val_acc: 0.8064\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.83650\n",
            "Epoch 238/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5622 - acc: 0.8831 - val_loss: 1.0563 - val_acc: 0.7570\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.83650\n",
            "Epoch 239/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5634 - acc: 0.8785 - val_loss: 0.8242 - val_acc: 0.8081\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.83650\n",
            "Epoch 240/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5697 - acc: 0.8757 - val_loss: 0.8761 - val_acc: 0.7907\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.83650\n",
            "Epoch 241/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5634 - acc: 0.8796 - val_loss: 0.7467 - val_acc: 0.8246\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.83650\n",
            "Epoch 242/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5588 - acc: 0.8808 - val_loss: 0.9608 - val_acc: 0.7793\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.83650\n",
            "Epoch 243/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5705 - acc: 0.8746 - val_loss: 0.8912 - val_acc: 0.7913\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.83650\n",
            "Epoch 244/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5807 - acc: 0.8738 - val_loss: 1.0950 - val_acc: 0.7590\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.83650\n",
            "Epoch 245/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5672 - acc: 0.8750 - val_loss: 0.8859 - val_acc: 0.7835\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.83650\n",
            "Epoch 246/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5618 - acc: 0.8804 - val_loss: 0.8226 - val_acc: 0.8034\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.83650\n",
            "Epoch 247/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5582 - acc: 0.8802 - val_loss: 0.7285 - val_acc: 0.8303\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.83650\n",
            "Epoch 248/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5634 - acc: 0.8828 - val_loss: 0.7349 - val_acc: 0.8240\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.83650\n",
            "Epoch 249/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5505 - acc: 0.8788 - val_loss: 0.9918 - val_acc: 0.7577\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.83650\n",
            "Epoch 250/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5727 - acc: 0.8769 - val_loss: 0.7805 - val_acc: 0.8112\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.83650\n",
            "Epoch 251/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5672 - acc: 0.8778 - val_loss: 0.7610 - val_acc: 0.8122\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.83650\n",
            "Epoch 252/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5656 - acc: 0.8739 - val_loss: 0.7754 - val_acc: 0.8078\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.83650\n",
            "Epoch 253/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5504 - acc: 0.8809 - val_loss: 0.8831 - val_acc: 0.7820\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.83650\n",
            "Epoch 254/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5501 - acc: 0.8822 - val_loss: 0.8662 - val_acc: 0.7885\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.83650\n",
            "Epoch 255/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5473 - acc: 0.8814 - val_loss: 1.1031 - val_acc: 0.7464\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.83650\n",
            "Epoch 256/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5509 - acc: 0.8795 - val_loss: 0.7659 - val_acc: 0.8225\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.83650\n",
            "Epoch 257/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5503 - acc: 0.8821 - val_loss: 0.8120 - val_acc: 0.8075\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.83650\n",
            "Epoch 258/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5616 - acc: 0.8787 - val_loss: 0.8668 - val_acc: 0.7938\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.83650\n",
            "Epoch 259/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5463 - acc: 0.8818 - val_loss: 0.7946 - val_acc: 0.8069\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.83650\n",
            "Epoch 260/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5577 - acc: 0.8776 - val_loss: 0.8324 - val_acc: 0.8065\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.83650\n",
            "Epoch 261/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5671 - acc: 0.8770 - val_loss: 0.7156 - val_acc: 0.8334\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.83650\n",
            "Epoch 262/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5446 - acc: 0.8794 - val_loss: 0.8769 - val_acc: 0.7990\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.83650\n",
            "Epoch 263/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5585 - acc: 0.8796 - val_loss: 0.7005 - val_acc: 0.8365\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.83650\n",
            "Epoch 264/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5406 - acc: 0.8851 - val_loss: 0.7589 - val_acc: 0.8222\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.83650\n",
            "Epoch 265/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5681 - acc: 0.8782 - val_loss: 0.8086 - val_acc: 0.8144\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.83650\n",
            "Epoch 266/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5614 - acc: 0.8760 - val_loss: 0.8595 - val_acc: 0.7930\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.83650\n",
            "Epoch 267/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5369 - acc: 0.8862 - val_loss: 0.7460 - val_acc: 0.8254\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.83650\n",
            "Epoch 268/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5489 - acc: 0.8803 - val_loss: 0.9954 - val_acc: 0.7742\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.83650\n",
            "Epoch 269/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5397 - acc: 0.8836 - val_loss: 0.9045 - val_acc: 0.7816\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.83650\n",
            "Epoch 270/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5482 - acc: 0.8821 - val_loss: 0.9592 - val_acc: 0.7846\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.83650\n",
            "Epoch 271/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5343 - acc: 0.8868 - val_loss: 0.7353 - val_acc: 0.8291\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.83650\n",
            "Epoch 272/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5518 - acc: 0.8800 - val_loss: 0.6741 - val_acc: 0.8436\n",
            "\n",
            "Epoch 00272: val_acc improved from 0.83650 to 0.84360, saving model to /content/saved_models/cifar10_ResNet32v1_model.272.h5\n",
            "Epoch 273/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5650 - acc: 0.8766 - val_loss: 0.9787 - val_acc: 0.7661\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.84360\n",
            "Epoch 274/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5418 - acc: 0.8823 - val_loss: 0.8044 - val_acc: 0.8156\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.84360\n",
            "Epoch 275/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5474 - acc: 0.8847 - val_loss: 0.9582 - val_acc: 0.7680\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.84360\n",
            "Epoch 276/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5466 - acc: 0.8832 - val_loss: 0.7536 - val_acc: 0.8198\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.84360\n",
            "Epoch 277/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5402 - acc: 0.8818 - val_loss: 0.7562 - val_acc: 0.8219\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.84360\n",
            "Epoch 278/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5289 - acc: 0.8894 - val_loss: 0.7109 - val_acc: 0.8328\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.84360\n",
            "Epoch 279/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5327 - acc: 0.8841 - val_loss: 1.0135 - val_acc: 0.7575\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.84360\n",
            "Epoch 280/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5512 - acc: 0.8814 - val_loss: 0.9288 - val_acc: 0.7743\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.84360\n",
            "Epoch 281/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5580 - acc: 0.8744 - val_loss: 0.8474 - val_acc: 0.8041\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.84360\n",
            "Epoch 282/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5281 - acc: 0.8860 - val_loss: 1.0011 - val_acc: 0.7637\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.84360\n",
            "Epoch 283/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5270 - acc: 0.8912 - val_loss: 1.0295 - val_acc: 0.7574\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.84360\n",
            "Epoch 284/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5379 - acc: 0.8870 - val_loss: 0.8519 - val_acc: 0.7973\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.84360\n",
            "Epoch 285/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5326 - acc: 0.8857 - val_loss: 0.8966 - val_acc: 0.7865\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.84360\n",
            "Epoch 286/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5389 - acc: 0.8824 - val_loss: 0.9147 - val_acc: 0.7827\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.84360\n",
            "Epoch 287/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5387 - acc: 0.8825 - val_loss: 0.8049 - val_acc: 0.8153\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.84360\n",
            "Epoch 288/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5258 - acc: 0.8862 - val_loss: 0.7804 - val_acc: 0.8111\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.84360\n",
            "Epoch 289/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5308 - acc: 0.8853 - val_loss: 0.8234 - val_acc: 0.8029\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.84360\n",
            "Epoch 290/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5315 - acc: 0.8858 - val_loss: 0.7191 - val_acc: 0.8335\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.84360\n",
            "Epoch 291/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5244 - acc: 0.8845 - val_loss: 0.7307 - val_acc: 0.8246\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.84360\n",
            "Epoch 292/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5322 - acc: 0.8830 - val_loss: 0.7244 - val_acc: 0.8257\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.84360\n",
            "Epoch 293/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5412 - acc: 0.8832 - val_loss: 0.9899 - val_acc: 0.7708\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.84360\n",
            "Epoch 294/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5242 - acc: 0.8864 - val_loss: 0.9286 - val_acc: 0.7845\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.84360\n",
            "Epoch 295/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.5429 - acc: 0.8834 - val_loss: 0.9278 - val_acc: 0.7756\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.84360\n",
            "Epoch 296/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5430 - acc: 0.8840 - val_loss: 0.8805 - val_acc: 0.7884\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.84360\n",
            "Epoch 297/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5466 - acc: 0.8813 - val_loss: 0.7933 - val_acc: 0.8121\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.84360\n",
            "Epoch 298/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5325 - acc: 0.8789 - val_loss: 0.7257 - val_acc: 0.8236\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.84360\n",
            "Epoch 299/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5131 - acc: 0.8916 - val_loss: 0.7917 - val_acc: 0.8210\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.84360\n",
            "Epoch 300/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5396 - acc: 0.8813 - val_loss: 0.6927 - val_acc: 0.8386\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.84360\n",
            "Epoch 301/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5118 - acc: 0.8930 - val_loss: 0.9493 - val_acc: 0.7756\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.84360\n",
            "Epoch 302/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5332 - acc: 0.8869 - val_loss: 0.9636 - val_acc: 0.7903\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.84360\n",
            "Epoch 303/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5250 - acc: 0.8910 - val_loss: 0.8724 - val_acc: 0.7862\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.84360\n",
            "Epoch 304/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5300 - acc: 0.8872 - val_loss: 0.7283 - val_acc: 0.8192\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.84360\n",
            "Epoch 305/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5237 - acc: 0.8887 - val_loss: 0.9665 - val_acc: 0.7815\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.84360\n",
            "Epoch 306/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5331 - acc: 0.8835 - val_loss: 0.7704 - val_acc: 0.8172\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.84360\n",
            "Epoch 307/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5228 - acc: 0.8859 - val_loss: 0.7021 - val_acc: 0.8348\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.84360\n",
            "Epoch 308/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5196 - acc: 0.8933 - val_loss: 0.8918 - val_acc: 0.7835\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.84360\n",
            "Epoch 309/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5145 - acc: 0.8907 - val_loss: 0.8832 - val_acc: 0.7896\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.84360\n",
            "Epoch 310/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5135 - acc: 0.8938 - val_loss: 0.7328 - val_acc: 0.8225\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.84360\n",
            "Epoch 311/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5080 - acc: 0.8936 - val_loss: 0.8064 - val_acc: 0.8174\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.84360\n",
            "Epoch 312/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5226 - acc: 0.8883 - val_loss: 0.7234 - val_acc: 0.8278\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.84360\n",
            "Epoch 313/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5170 - acc: 0.8886 - val_loss: 0.9807 - val_acc: 0.7543\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.84360\n",
            "Epoch 314/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.5150 - acc: 0.8855 - val_loss: 0.8285 - val_acc: 0.8060\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.84360\n",
            "Epoch 315/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5198 - acc: 0.8877 - val_loss: 0.7815 - val_acc: 0.8097\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.84360\n",
            "Epoch 316/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5171 - acc: 0.8882 - val_loss: 0.7446 - val_acc: 0.8210\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.84360\n",
            "Epoch 317/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5230 - acc: 0.8882 - val_loss: 0.7733 - val_acc: 0.8186\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.84360\n",
            "Epoch 318/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5357 - acc: 0.8819 - val_loss: 0.9267 - val_acc: 0.7841\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.84360\n",
            "Epoch 319/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5152 - acc: 0.8896 - val_loss: 0.7521 - val_acc: 0.8299\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.84360\n",
            "Epoch 320/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5170 - acc: 0.8885 - val_loss: 0.9319 - val_acc: 0.7725\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.84360\n",
            "Epoch 321/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5158 - acc: 0.8898 - val_loss: 0.6930 - val_acc: 0.8375\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.84360\n",
            "Epoch 322/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5177 - acc: 0.8889 - val_loss: 0.8855 - val_acc: 0.7912\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.84360\n",
            "Epoch 323/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5128 - acc: 0.8897 - val_loss: 0.7012 - val_acc: 0.8349\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.84360\n",
            "Epoch 324/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5187 - acc: 0.8866 - val_loss: 0.6527 - val_acc: 0.8512\n",
            "\n",
            "Epoch 00324: val_acc improved from 0.84360 to 0.85120, saving model to /content/saved_models/cifar10_ResNet32v1_model.324.h5\n",
            "Epoch 325/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5054 - acc: 0.8931 - val_loss: 0.7163 - val_acc: 0.8334\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.85120\n",
            "Epoch 326/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5419 - acc: 0.8778 - val_loss: 0.7240 - val_acc: 0.8288\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.85120\n",
            "Epoch 327/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5155 - acc: 0.8891 - val_loss: 0.8792 - val_acc: 0.7884\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.85120\n",
            "Epoch 328/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5169 - acc: 0.8891 - val_loss: 0.9256 - val_acc: 0.7797\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.85120\n",
            "Epoch 329/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5229 - acc: 0.8840 - val_loss: 0.6913 - val_acc: 0.8366\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.85120\n",
            "Epoch 330/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5181 - acc: 0.8852 - val_loss: 0.6877 - val_acc: 0.8326\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.85120\n",
            "Epoch 331/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5221 - acc: 0.8849 - val_loss: 1.0857 - val_acc: 0.7565\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.85120\n",
            "Epoch 332/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5070 - acc: 0.8916 - val_loss: 0.8089 - val_acc: 0.8128\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.85120\n",
            "Epoch 333/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4966 - acc: 0.8984 - val_loss: 0.8954 - val_acc: 0.7921\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.85120\n",
            "Epoch 334/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5025 - acc: 0.8945 - val_loss: 0.7230 - val_acc: 0.8309\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.85120\n",
            "Epoch 335/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5387 - acc: 0.8801 - val_loss: 0.7739 - val_acc: 0.8161\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.85120\n",
            "Epoch 336/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5029 - acc: 0.8944 - val_loss: 0.6906 - val_acc: 0.8434\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.85120\n",
            "Epoch 337/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5008 - acc: 0.8952 - val_loss: 0.7355 - val_acc: 0.8279\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.85120\n",
            "Epoch 338/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4992 - acc: 0.8927 - val_loss: 0.9436 - val_acc: 0.7687\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.85120\n",
            "Epoch 339/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5092 - acc: 0.8930 - val_loss: 0.7057 - val_acc: 0.8343\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.85120\n",
            "Epoch 340/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5186 - acc: 0.8876 - val_loss: 0.7587 - val_acc: 0.8241\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.85120\n",
            "Epoch 341/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5060 - acc: 0.8884 - val_loss: 0.7578 - val_acc: 0.8242\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.85120\n",
            "Epoch 342/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5118 - acc: 0.8877 - val_loss: 0.9634 - val_acc: 0.7768\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.85120\n",
            "Epoch 343/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5058 - acc: 0.8940 - val_loss: 0.7389 - val_acc: 0.8262\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.85120\n",
            "Epoch 344/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5120 - acc: 0.8865 - val_loss: 0.7620 - val_acc: 0.8273\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.85120\n",
            "Epoch 345/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5032 - acc: 0.8924 - val_loss: 0.7479 - val_acc: 0.8271\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.85120\n",
            "Epoch 346/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5014 - acc: 0.8972 - val_loss: 0.7808 - val_acc: 0.8225\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.85120\n",
            "Epoch 347/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4994 - acc: 0.8961 - val_loss: 0.6966 - val_acc: 0.8314\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.85120\n",
            "Epoch 348/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4916 - acc: 0.8957 - val_loss: 0.9395 - val_acc: 0.7789\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.85120\n",
            "Epoch 349/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5123 - acc: 0.8889 - val_loss: 0.7085 - val_acc: 0.8320\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.85120\n",
            "Epoch 350/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5189 - acc: 0.8905 - val_loss: 0.7591 - val_acc: 0.8241\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.85120\n",
            "Epoch 351/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4981 - acc: 0.8935 - val_loss: 0.7130 - val_acc: 0.8264\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.85120\n",
            "Epoch 352/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5254 - acc: 0.8835 - val_loss: 0.8300 - val_acc: 0.7981\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.85120\n",
            "Epoch 353/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4910 - acc: 0.8997 - val_loss: 0.7565 - val_acc: 0.8137\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.85120\n",
            "Epoch 354/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4963 - acc: 0.8922 - val_loss: 0.7322 - val_acc: 0.8296\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.85120\n",
            "Epoch 355/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5059 - acc: 0.8930 - val_loss: 0.7998 - val_acc: 0.8087\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.85120\n",
            "Epoch 356/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5096 - acc: 0.8942 - val_loss: 0.7286 - val_acc: 0.8294\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.85120\n",
            "Epoch 357/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5085 - acc: 0.8899 - val_loss: 1.0356 - val_acc: 0.7524\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.85120\n",
            "Epoch 358/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5005 - acc: 0.8956 - val_loss: 0.9435 - val_acc: 0.7795\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.85120\n",
            "Epoch 359/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5025 - acc: 0.8927 - val_loss: 0.7677 - val_acc: 0.8228\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.85120\n",
            "Epoch 360/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4939 - acc: 0.8931 - val_loss: 1.0051 - val_acc: 0.7548\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.85120\n",
            "Epoch 361/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4962 - acc: 0.8927 - val_loss: 0.7813 - val_acc: 0.8071\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.85120\n",
            "Epoch 362/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4900 - acc: 0.8945 - val_loss: 0.8314 - val_acc: 0.8125\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.85120\n",
            "Epoch 363/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4976 - acc: 0.8914 - val_loss: 1.0577 - val_acc: 0.7670\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.85120\n",
            "Epoch 364/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5155 - acc: 0.8833 - val_loss: 0.7389 - val_acc: 0.8279\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.85120\n",
            "Epoch 365/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5053 - acc: 0.8929 - val_loss: 0.7271 - val_acc: 0.8338\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.85120\n",
            "Epoch 366/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4847 - acc: 0.8985 - val_loss: 0.8658 - val_acc: 0.7971\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.85120\n",
            "Epoch 367/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4973 - acc: 0.8917 - val_loss: 0.7518 - val_acc: 0.8193\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.85120\n",
            "Epoch 368/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4876 - acc: 0.8954 - val_loss: 0.6718 - val_acc: 0.8467\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.85120\n",
            "Epoch 369/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4922 - acc: 0.8970 - val_loss: 0.9385 - val_acc: 0.7828\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.85120\n",
            "Epoch 370/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4881 - acc: 0.8957 - val_loss: 0.7632 - val_acc: 0.8173\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.85120\n",
            "Epoch 371/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5049 - acc: 0.8920 - val_loss: 0.9226 - val_acc: 0.7712\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.85120\n",
            "Epoch 372/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4967 - acc: 0.8945 - val_loss: 0.6554 - val_acc: 0.8481\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.85120\n",
            "Epoch 373/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5098 - acc: 0.8904 - val_loss: 0.7509 - val_acc: 0.8292\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.85120\n",
            "Epoch 374/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5116 - acc: 0.8893 - val_loss: 0.6663 - val_acc: 0.8402\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.85120\n",
            "Epoch 375/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4980 - acc: 0.8955 - val_loss: 0.8922 - val_acc: 0.7872\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.85120\n",
            "Epoch 376/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4944 - acc: 0.8964 - val_loss: 0.7918 - val_acc: 0.8132\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.85120\n",
            "Epoch 377/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5043 - acc: 0.8898 - val_loss: 0.7589 - val_acc: 0.8308\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.85120\n",
            "Epoch 378/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4765 - acc: 0.9018 - val_loss: 0.7187 - val_acc: 0.8290\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.85120\n",
            "Epoch 379/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5086 - acc: 0.8886 - val_loss: 0.6890 - val_acc: 0.8378\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.85120\n",
            "Epoch 380/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4833 - acc: 0.8960 - val_loss: 0.6265 - val_acc: 0.8559\n",
            "\n",
            "Epoch 00380: val_acc improved from 0.85120 to 0.85590, saving model to /content/saved_models/cifar10_ResNet32v1_model.380.h5\n",
            "Epoch 381/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4858 - acc: 0.8963 - val_loss: 0.8802 - val_acc: 0.7954\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.85590\n",
            "Epoch 382/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5053 - acc: 0.8899 - val_loss: 0.9127 - val_acc: 0.7884\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.85590\n",
            "Epoch 383/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4947 - acc: 0.8961 - val_loss: 0.6998 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.85590\n",
            "Epoch 384/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4819 - acc: 0.8999 - val_loss: 1.1382 - val_acc: 0.7306\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.85590\n",
            "Epoch 385/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4968 - acc: 0.8963 - val_loss: 0.7114 - val_acc: 0.8345\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.85590\n",
            "Epoch 386/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4907 - acc: 0.8968 - val_loss: 0.7316 - val_acc: 0.8291\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.85590\n",
            "Epoch 387/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4804 - acc: 0.8993 - val_loss: 0.9222 - val_acc: 0.7860\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.85590\n",
            "Epoch 388/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4879 - acc: 0.8944 - val_loss: 0.6554 - val_acc: 0.8475\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.85590\n",
            "Epoch 389/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4908 - acc: 0.8948 - val_loss: 0.6830 - val_acc: 0.8344\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.85590\n",
            "Epoch 390/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4860 - acc: 0.8953 - val_loss: 0.7612 - val_acc: 0.8202\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.85590\n",
            "Epoch 391/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4781 - acc: 0.8986 - val_loss: 0.8073 - val_acc: 0.8024\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.85590\n",
            "Epoch 392/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4889 - acc: 0.8953 - val_loss: 0.6855 - val_acc: 0.8350\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.85590\n",
            "Epoch 393/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4940 - acc: 0.8953 - val_loss: 0.7106 - val_acc: 0.8318\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.85590\n",
            "Epoch 394/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4910 - acc: 0.8920 - val_loss: 0.7789 - val_acc: 0.8172\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.85590\n",
            "Epoch 395/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4938 - acc: 0.8938 - val_loss: 0.7981 - val_acc: 0.8125\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.85590\n",
            "Epoch 396/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4752 - acc: 0.9017 - val_loss: 0.6985 - val_acc: 0.8390\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.85590\n",
            "Epoch 397/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4810 - acc: 0.8967 - val_loss: 0.9003 - val_acc: 0.7938\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.85590\n",
            "Epoch 398/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4774 - acc: 0.8977 - val_loss: 0.8127 - val_acc: 0.8052\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.85590\n",
            "Epoch 399/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5072 - acc: 0.8860 - val_loss: 0.8080 - val_acc: 0.8045\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.85590\n",
            "Epoch 400/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4842 - acc: 0.8973 - val_loss: 0.8814 - val_acc: 0.7999\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.85590\n",
            "Epoch 401/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4898 - acc: 0.8941 - val_loss: 0.7098 - val_acc: 0.8330\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.85590\n",
            "Epoch 402/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4515 - acc: 0.9116 - val_loss: 0.5738 - val_acc: 0.8774\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.85590 to 0.87740, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4081 - acc: 0.9221 - val_loss: 0.5494 - val_acc: 0.8822\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.87740 to 0.88220, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4188 - acc: 0.9215 - val_loss: 0.5266 - val_acc: 0.8864\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.88220 to 0.88640, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4041 - acc: 0.9267 - val_loss: 0.5262 - val_acc: 0.8883\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.88640 to 0.88830, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3931 - acc: 0.9285 - val_loss: 0.5167 - val_acc: 0.8913\n",
            "\n",
            "Epoch 00406: val_acc improved from 0.88830 to 0.89130, saving model to /content/saved_models/cifar10_ResNet32v1_model.406.h5\n",
            "Epoch 407/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3867 - acc: 0.9311 - val_loss: 0.5257 - val_acc: 0.8881\n",
            "\n",
            "Epoch 00407: val_acc did not improve from 0.89130\n",
            "Epoch 408/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3865 - acc: 0.9314 - val_loss: 0.5155 - val_acc: 0.8920\n",
            "\n",
            "Epoch 00408: val_acc improved from 0.89130 to 0.89200, saving model to /content/saved_models/cifar10_ResNet32v1_model.408.h5\n",
            "Epoch 409/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3748 - acc: 0.9334 - val_loss: 0.5211 - val_acc: 0.8893\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.89200\n",
            "Epoch 410/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3833 - acc: 0.9331 - val_loss: 0.5173 - val_acc: 0.8897\n",
            "\n",
            "Epoch 00410: val_acc did not improve from 0.89200\n",
            "Epoch 411/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3730 - acc: 0.9377 - val_loss: 0.5227 - val_acc: 0.8878\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.89200\n",
            "Epoch 412/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3735 - acc: 0.9347 - val_loss: 0.5076 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00412: val_acc improved from 0.89200 to 0.89250, saving model to /content/saved_models/cifar10_ResNet32v1_model.412.h5\n",
            "Epoch 413/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3820 - acc: 0.9334 - val_loss: 0.5024 - val_acc: 0.8944\n",
            "\n",
            "Epoch 00413: val_acc improved from 0.89250 to 0.89440, saving model to /content/saved_models/cifar10_ResNet32v1_model.413.h5\n",
            "Epoch 414/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3693 - acc: 0.9384 - val_loss: 0.5058 - val_acc: 0.8931\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.89440\n",
            "Epoch 415/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3664 - acc: 0.9395 - val_loss: 0.5094 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00415: val_acc did not improve from 0.89440\n",
            "Epoch 416/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3629 - acc: 0.9407 - val_loss: 0.5288 - val_acc: 0.8887\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.89440\n",
            "Epoch 417/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3671 - acc: 0.9365 - val_loss: 0.5075 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.89440\n",
            "Epoch 418/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3580 - acc: 0.9417 - val_loss: 0.4976 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00418: val_acc improved from 0.89440 to 0.89630, saving model to /content/saved_models/cifar10_ResNet32v1_model.418.h5\n",
            "Epoch 419/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3573 - acc: 0.9396 - val_loss: 0.5126 - val_acc: 0.8915\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.89630\n",
            "Epoch 420/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3543 - acc: 0.9413 - val_loss: 0.5021 - val_acc: 0.8958\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.89630\n",
            "Epoch 421/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3511 - acc: 0.9454 - val_loss: 0.5200 - val_acc: 0.8911\n",
            "\n",
            "Epoch 00421: val_acc did not improve from 0.89630\n",
            "Epoch 422/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3561 - acc: 0.9414 - val_loss: 0.5025 - val_acc: 0.8946\n",
            "\n",
            "Epoch 00422: val_acc did not improve from 0.89630\n",
            "Epoch 423/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3569 - acc: 0.9418 - val_loss: 0.5100 - val_acc: 0.8945\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.89630\n",
            "Epoch 424/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3526 - acc: 0.9416 - val_loss: 0.5205 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.89630\n",
            "Epoch 425/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3539 - acc: 0.9419 - val_loss: 0.5058 - val_acc: 0.8927\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.89630\n",
            "Epoch 426/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3495 - acc: 0.9432 - val_loss: 0.5054 - val_acc: 0.8952\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.89630\n",
            "Epoch 427/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3602 - acc: 0.9395 - val_loss: 0.4986 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00427: val_acc improved from 0.89630 to 0.89860, saving model to /content/saved_models/cifar10_ResNet32v1_model.427.h5\n",
            "Epoch 428/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3477 - acc: 0.9433 - val_loss: 0.5118 - val_acc: 0.8932\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.89860\n",
            "Epoch 429/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3440 - acc: 0.9454 - val_loss: 0.5128 - val_acc: 0.8919\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.89860\n",
            "Epoch 430/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3360 - acc: 0.9488 - val_loss: 0.5053 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.89860\n",
            "Epoch 431/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3474 - acc: 0.9435 - val_loss: 0.5040 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.89860\n",
            "Epoch 432/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3443 - acc: 0.9456 - val_loss: 0.5080 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.89860\n",
            "Epoch 433/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3438 - acc: 0.9426 - val_loss: 0.5038 - val_acc: 0.8966\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.89860\n",
            "Epoch 434/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3385 - acc: 0.9467 - val_loss: 0.5140 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00434: val_acc did not improve from 0.89860\n",
            "Epoch 435/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3456 - acc: 0.9435 - val_loss: 0.4971 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.89860\n",
            "Epoch 436/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3443 - acc: 0.9444 - val_loss: 0.4953 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00436: val_acc improved from 0.89860 to 0.89930, saving model to /content/saved_models/cifar10_ResNet32v1_model.436.h5\n",
            "Epoch 437/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3408 - acc: 0.9475 - val_loss: 0.5002 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.89930\n",
            "Epoch 438/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3308 - acc: 0.9491 - val_loss: 0.4903 - val_acc: 0.9015\n",
            "\n",
            "Epoch 00438: val_acc improved from 0.89930 to 0.90150, saving model to /content/saved_models/cifar10_ResNet32v1_model.438.h5\n",
            "Epoch 439/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3334 - acc: 0.9494 - val_loss: 0.5174 - val_acc: 0.8901\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.90150\n",
            "Epoch 440/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3397 - acc: 0.9463 - val_loss: 0.5032 - val_acc: 0.8970\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.90150\n",
            "Epoch 441/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3347 - acc: 0.9462 - val_loss: 0.5128 - val_acc: 0.8944\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.90150\n",
            "Epoch 442/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3346 - acc: 0.9465 - val_loss: 0.4982 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.90150\n",
            "Epoch 443/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3278 - acc: 0.9494 - val_loss: 0.5081 - val_acc: 0.8947\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.90150\n",
            "Epoch 444/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3315 - acc: 0.9486 - val_loss: 0.5013 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.90150\n",
            "Epoch 445/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3290 - acc: 0.9493 - val_loss: 0.5011 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.90150\n",
            "Epoch 446/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3251 - acc: 0.9494 - val_loss: 0.5155 - val_acc: 0.8937\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.90150\n",
            "Epoch 447/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3417 - acc: 0.9419 - val_loss: 0.5129 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.90150\n",
            "Epoch 448/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3330 - acc: 0.9465 - val_loss: 0.5006 - val_acc: 0.9003\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.90150\n",
            "Epoch 449/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3305 - acc: 0.9491 - val_loss: 0.5012 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.90150\n",
            "Epoch 450/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3301 - acc: 0.9482 - val_loss: 0.5267 - val_acc: 0.8927\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.90150\n",
            "Epoch 451/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3302 - acc: 0.9474 - val_loss: 0.5048 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.90150\n",
            "Epoch 452/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3293 - acc: 0.9487 - val_loss: 0.5079 - val_acc: 0.8971\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.90150\n",
            "Epoch 453/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3220 - acc: 0.9482 - val_loss: 0.4987 - val_acc: 0.9004\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.90150\n",
            "Epoch 454/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3240 - acc: 0.9508 - val_loss: 0.5118 - val_acc: 0.8965\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.90150\n",
            "Epoch 455/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3257 - acc: 0.9492 - val_loss: 0.5061 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.90150\n",
            "Epoch 456/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3337 - acc: 0.9472 - val_loss: 0.5115 - val_acc: 0.8977\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.90150\n",
            "Epoch 457/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3261 - acc: 0.9500 - val_loss: 0.5123 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.90150\n",
            "Epoch 458/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3130 - acc: 0.9525 - val_loss: 0.5051 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.90150\n",
            "Epoch 459/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3295 - acc: 0.9469 - val_loss: 0.5040 - val_acc: 0.9003\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.90150\n",
            "Epoch 460/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3235 - acc: 0.9492 - val_loss: 0.4998 - val_acc: 0.9005\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.90150\n",
            "Epoch 461/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3252 - acc: 0.9502 - val_loss: 0.5014 - val_acc: 0.9012\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.90150\n",
            "Epoch 462/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3215 - acc: 0.9513 - val_loss: 0.4930 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00462: val_acc improved from 0.90150 to 0.90210, saving model to /content/saved_models/cifar10_ResNet32v1_model.462.h5\n",
            "Epoch 463/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3226 - acc: 0.9508 - val_loss: 0.5092 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.90210\n",
            "Epoch 464/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3195 - acc: 0.9521 - val_loss: 0.5250 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.90210\n",
            "Epoch 465/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3171 - acc: 0.9511 - val_loss: 0.5003 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.90210\n",
            "Epoch 466/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3145 - acc: 0.9533 - val_loss: 0.4983 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.90210\n",
            "Epoch 467/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3192 - acc: 0.9520 - val_loss: 0.5029 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.90210\n",
            "Epoch 468/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3188 - acc: 0.9523 - val_loss: 0.4991 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.90210\n",
            "Epoch 469/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3157 - acc: 0.9512 - val_loss: 0.5086 - val_acc: 0.8965\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.90210\n",
            "Epoch 470/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3199 - acc: 0.9516 - val_loss: 0.5014 - val_acc: 0.9020\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.90210\n",
            "Epoch 471/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3181 - acc: 0.9514 - val_loss: 0.5113 - val_acc: 0.8935\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.90210\n",
            "Epoch 472/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3112 - acc: 0.9536 - val_loss: 0.5014 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.90210\n",
            "Epoch 473/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3099 - acc: 0.9552 - val_loss: 0.5038 - val_acc: 0.9002\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.90210\n",
            "Epoch 474/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3088 - acc: 0.9537 - val_loss: 0.5188 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.90210\n",
            "Epoch 475/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3070 - acc: 0.9546 - val_loss: 0.5156 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.90210\n",
            "Epoch 476/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3216 - acc: 0.9497 - val_loss: 0.5224 - val_acc: 0.8962\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.90210\n",
            "Epoch 477/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3147 - acc: 0.9525 - val_loss: 0.5115 - val_acc: 0.8937\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.90210\n",
            "Epoch 478/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3107 - acc: 0.9525 - val_loss: 0.5160 - val_acc: 0.8937\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.90210\n",
            "Epoch 479/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3107 - acc: 0.9533 - val_loss: 0.5062 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.90210\n",
            "Epoch 480/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3041 - acc: 0.9545 - val_loss: 0.5039 - val_acc: 0.9007\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.90210\n",
            "Epoch 481/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3068 - acc: 0.9568 - val_loss: 0.4935 - val_acc: 0.9030\n",
            "\n",
            "Epoch 00481: val_acc improved from 0.90210 to 0.90300, saving model to /content/saved_models/cifar10_ResNet32v1_model.481.h5\n",
            "Epoch 482/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3048 - acc: 0.9567 - val_loss: 0.5119 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.90300\n",
            "Epoch 483/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3062 - acc: 0.9550 - val_loss: 0.5054 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.90300\n",
            "Epoch 484/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3090 - acc: 0.9563 - val_loss: 0.5059 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.90300\n",
            "Epoch 485/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3038 - acc: 0.9545 - val_loss: 0.5020 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.90300\n",
            "Epoch 486/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2990 - acc: 0.9566 - val_loss: 0.5013 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.90300\n",
            "Epoch 487/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3096 - acc: 0.9512 - val_loss: 0.5072 - val_acc: 0.8965\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.90300\n",
            "Epoch 488/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3060 - acc: 0.9530 - val_loss: 0.5102 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.90300\n",
            "Epoch 489/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3018 - acc: 0.9563 - val_loss: 0.5104 - val_acc: 0.8977\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.90300\n",
            "Epoch 490/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3073 - acc: 0.9545 - val_loss: 0.5091 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.90300\n",
            "Epoch 491/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3053 - acc: 0.9557 - val_loss: 0.5039 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.90300\n",
            "Epoch 492/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3098 - acc: 0.9536 - val_loss: 0.5090 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.90300\n",
            "Epoch 493/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2987 - acc: 0.9557 - val_loss: 0.5004 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.90300\n",
            "Epoch 494/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3002 - acc: 0.9547 - val_loss: 0.5128 - val_acc: 0.8954\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.90300\n",
            "Epoch 495/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3093 - acc: 0.9527 - val_loss: 0.5060 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.90300\n",
            "Epoch 496/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3052 - acc: 0.9557 - val_loss: 0.5065 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.90300\n",
            "Epoch 497/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3037 - acc: 0.9539 - val_loss: 0.5196 - val_acc: 0.8948\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.90300\n",
            "Epoch 498/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3039 - acc: 0.9523 - val_loss: 0.5091 - val_acc: 0.8977\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.90300\n",
            "Epoch 499/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2965 - acc: 0.9579 - val_loss: 0.5064 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.90300\n",
            "Epoch 500/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2993 - acc: 0.9551 - val_loss: 0.5087 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.90300\n",
            "Epoch 501/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2917 - acc: 0.9599 - val_loss: 0.5129 - val_acc: 0.8966\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.90300\n",
            "Epoch 502/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2976 - acc: 0.9568 - val_loss: 0.5072 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.90300\n",
            "Epoch 503/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2940 - acc: 0.9601 - val_loss: 0.5039 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.90300\n",
            "Epoch 504/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2985 - acc: 0.9563 - val_loss: 0.5161 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.90300\n",
            "Epoch 505/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2926 - acc: 0.9561 - val_loss: 0.5006 - val_acc: 0.8977\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.90300\n",
            "Epoch 506/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2953 - acc: 0.9569 - val_loss: 0.5038 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.90300\n",
            "Epoch 507/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3052 - acc: 0.9532 - val_loss: 0.5092 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.90300\n",
            "Epoch 508/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2920 - acc: 0.9576 - val_loss: 0.5118 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.90300\n",
            "Epoch 509/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3008 - acc: 0.9543 - val_loss: 0.5158 - val_acc: 0.8966\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.90300\n",
            "Epoch 510/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3054 - acc: 0.9526 - val_loss: 0.5108 - val_acc: 0.8998\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.90300\n",
            "Epoch 511/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2946 - acc: 0.9564 - val_loss: 0.5154 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.90300\n",
            "Epoch 512/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.3011 - acc: 0.9538 - val_loss: 0.4933 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.90300\n",
            "Epoch 513/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3001 - acc: 0.9538 - val_loss: 0.5100 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.90300\n",
            "Epoch 514/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2968 - acc: 0.9550 - val_loss: 0.5052 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.90300\n",
            "Epoch 515/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2924 - acc: 0.9550 - val_loss: 0.5026 - val_acc: 0.9011\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.90300\n",
            "Epoch 516/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2949 - acc: 0.9576 - val_loss: 0.5032 - val_acc: 0.9014\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.90300\n",
            "Epoch 517/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2947 - acc: 0.9559 - val_loss: 0.5172 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.90300\n",
            "Epoch 518/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2919 - acc: 0.9567 - val_loss: 0.5276 - val_acc: 0.8932\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.90300\n",
            "Epoch 519/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2893 - acc: 0.9583 - val_loss: 0.5105 - val_acc: 0.8966\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.90300\n",
            "Epoch 520/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2849 - acc: 0.9606 - val_loss: 0.5123 - val_acc: 0.8949\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.90300\n",
            "Epoch 521/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2925 - acc: 0.9571 - val_loss: 0.5015 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.90300\n",
            "Epoch 522/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2898 - acc: 0.9577 - val_loss: 0.5132 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.90300\n",
            "Epoch 523/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2905 - acc: 0.9591 - val_loss: 0.5086 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.90300\n",
            "Epoch 524/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2911 - acc: 0.9600 - val_loss: 0.4969 - val_acc: 0.9023\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.90300\n",
            "Epoch 525/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2908 - acc: 0.9571 - val_loss: 0.5015 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.90300\n",
            "Epoch 526/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2863 - acc: 0.9610 - val_loss: 0.5103 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.90300\n",
            "Epoch 527/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2951 - acc: 0.9561 - val_loss: 0.5038 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.90300\n",
            "Epoch 528/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2913 - acc: 0.9567 - val_loss: 0.5065 - val_acc: 0.9012\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.90300\n",
            "Epoch 529/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2850 - acc: 0.9596 - val_loss: 0.4940 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.90300\n",
            "Epoch 530/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2836 - acc: 0.9602 - val_loss: 0.5019 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.90300\n",
            "Epoch 531/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2888 - acc: 0.9580 - val_loss: 0.5109 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.90300\n",
            "Epoch 532/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2846 - acc: 0.9576 - val_loss: 0.4961 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.90300\n",
            "Epoch 533/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2841 - acc: 0.9593 - val_loss: 0.5151 - val_acc: 0.8971\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.90300\n",
            "Epoch 534/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2855 - acc: 0.9597 - val_loss: 0.5092 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.90300\n",
            "Epoch 535/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2820 - acc: 0.9610 - val_loss: 0.5153 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.90300\n",
            "Epoch 536/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.2786 - acc: 0.9634 - val_loss: 0.5161 - val_acc: 0.8970\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.90300\n",
            "Epoch 537/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2850 - acc: 0.9594 - val_loss: 0.5030 - val_acc: 0.9005\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.90300\n",
            "Epoch 538/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2818 - acc: 0.9599 - val_loss: 0.4972 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.90300\n",
            "Epoch 539/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2843 - acc: 0.9608 - val_loss: 0.5178 - val_acc: 0.8952\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.90300\n",
            "Epoch 540/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2940 - acc: 0.9571 - val_loss: 0.5095 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.90300\n",
            "Epoch 541/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2854 - acc: 0.9588 - val_loss: 0.5071 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.90300\n",
            "Epoch 542/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2847 - acc: 0.9590 - val_loss: 0.5140 - val_acc: 0.8971\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.90300\n",
            "Epoch 543/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2883 - acc: 0.9562 - val_loss: 0.5003 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.90300\n",
            "Epoch 544/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2839 - acc: 0.9602 - val_loss: 0.5040 - val_acc: 0.8971\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.90300\n",
            "Epoch 545/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2766 - acc: 0.9630 - val_loss: 0.5165 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.90300\n",
            "Epoch 546/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2799 - acc: 0.9590 - val_loss: 0.5235 - val_acc: 0.8953\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.90300\n",
            "Epoch 547/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2757 - acc: 0.9591 - val_loss: 0.5121 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.90300\n",
            "Epoch 548/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2749 - acc: 0.9625 - val_loss: 0.5119 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.90300\n",
            "Epoch 549/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2833 - acc: 0.9576 - val_loss: 0.5022 - val_acc: 0.9003\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.90300\n",
            "Epoch 550/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2868 - acc: 0.9566 - val_loss: 0.5087 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.90300\n",
            "Epoch 551/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2781 - acc: 0.9614 - val_loss: 0.5183 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.90300\n",
            "Epoch 552/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2770 - acc: 0.9607 - val_loss: 0.5116 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.90300\n",
            "Epoch 553/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2793 - acc: 0.9600 - val_loss: 0.5091 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.90300\n",
            "Epoch 554/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2836 - acc: 0.9587 - val_loss: 0.5089 - val_acc: 0.9006\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.90300\n",
            "Epoch 555/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.2813 - acc: 0.9615 - val_loss: 0.5247 - val_acc: 0.8970\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.90300\n",
            "Epoch 556/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2754 - acc: 0.9613 - val_loss: 0.5092 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.90300\n",
            "Epoch 557/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2751 - acc: 0.9627 - val_loss: 0.5109 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.90300\n",
            "Epoch 558/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.2727 - acc: 0.9635 - val_loss: 0.5128 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.90300\n",
            "Epoch 559/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2813 - acc: 0.9584 - val_loss: 0.5173 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.90300\n",
            "Epoch 560/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2786 - acc: 0.9590 - val_loss: 0.5081 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.90300\n",
            "Epoch 561/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2828 - acc: 0.9585 - val_loss: 0.5087 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.90300\n",
            "Epoch 562/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2780 - acc: 0.9604 - val_loss: 0.5194 - val_acc: 0.8957\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.90300\n",
            "Epoch 563/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2768 - acc: 0.9613 - val_loss: 0.5133 - val_acc: 0.8972\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.90300\n",
            "Epoch 564/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2719 - acc: 0.9647 - val_loss: 0.5121 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.90300\n",
            "Epoch 565/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2696 - acc: 0.9635 - val_loss: 0.5268 - val_acc: 0.8964\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.90300\n",
            "Epoch 566/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2740 - acc: 0.9625 - val_loss: 0.5263 - val_acc: 0.8954\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.90300\n",
            "Epoch 567/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2722 - acc: 0.9637 - val_loss: 0.5086 - val_acc: 0.9010\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.90300\n",
            "Epoch 568/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2701 - acc: 0.9606 - val_loss: 0.5321 - val_acc: 0.8937\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.90300\n",
            "Epoch 569/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2682 - acc: 0.9638 - val_loss: 0.4988 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.90300\n",
            "Epoch 570/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2790 - acc: 0.9608 - val_loss: 0.5230 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.90300\n",
            "Epoch 571/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2702 - acc: 0.9627 - val_loss: 0.5190 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.90300\n",
            "Epoch 572/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2729 - acc: 0.9617 - val_loss: 0.5019 - val_acc: 0.9005\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.90300\n",
            "Epoch 573/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2779 - acc: 0.9605 - val_loss: 0.5157 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.90300\n",
            "Epoch 574/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2708 - acc: 0.9651 - val_loss: 0.5007 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.90300\n",
            "Epoch 575/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2739 - acc: 0.9610 - val_loss: 0.4984 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.90300\n",
            "Epoch 576/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2741 - acc: 0.9596 - val_loss: 0.5040 - val_acc: 0.9020\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.90300\n",
            "Epoch 577/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2689 - acc: 0.9642 - val_loss: 0.5076 - val_acc: 0.9002\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.90300\n",
            "Epoch 578/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2720 - acc: 0.9624 - val_loss: 0.4995 - val_acc: 0.9006\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.90300\n",
            "Epoch 579/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2709 - acc: 0.9644 - val_loss: 0.5062 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.90300\n",
            "Epoch 580/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2647 - acc: 0.9651 - val_loss: 0.4968 - val_acc: 0.9005\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.90300\n",
            "Epoch 581/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2667 - acc: 0.9659 - val_loss: 0.5143 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.90300\n",
            "Epoch 582/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2658 - acc: 0.9640 - val_loss: 0.5051 - val_acc: 0.9008\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.90300\n",
            "Epoch 583/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2693 - acc: 0.9611 - val_loss: 0.4990 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.90300\n",
            "Epoch 584/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2705 - acc: 0.9626 - val_loss: 0.5309 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.90300\n",
            "Epoch 585/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2637 - acc: 0.9645 - val_loss: 0.5033 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.90300\n",
            "Epoch 586/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2672 - acc: 0.9638 - val_loss: 0.5160 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.90300\n",
            "Epoch 587/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2651 - acc: 0.9632 - val_loss: 0.5302 - val_acc: 0.8923\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.90300\n",
            "Epoch 588/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2672 - acc: 0.9639 - val_loss: 0.5101 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.90300\n",
            "Epoch 589/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2736 - acc: 0.9608 - val_loss: 0.5133 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.90300\n",
            "Epoch 590/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2674 - acc: 0.9634 - val_loss: 0.5191 - val_acc: 0.8947\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.90300\n",
            "Epoch 591/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2666 - acc: 0.9654 - val_loss: 0.5079 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.90300\n",
            "Epoch 592/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2688 - acc: 0.9615 - val_loss: 0.5094 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.90300\n",
            "Epoch 593/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2643 - acc: 0.9636 - val_loss: 0.5101 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.90300\n",
            "Epoch 594/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2680 - acc: 0.9644 - val_loss: 0.5104 - val_acc: 0.8962\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.90300\n",
            "Epoch 595/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2607 - acc: 0.9644 - val_loss: 0.5247 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.90300\n",
            "Epoch 596/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2626 - acc: 0.9639 - val_loss: 0.5105 - val_acc: 0.8972\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.90300\n",
            "Epoch 597/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.2641 - acc: 0.9654 - val_loss: 0.5045 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.90300\n",
            "Epoch 598/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2648 - acc: 0.9622 - val_loss: 0.5275 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.90300\n",
            "Epoch 599/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2663 - acc: 0.9636 - val_loss: 0.5079 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.90300\n",
            "Epoch 600/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2662 - acc: 0.9630 - val_loss: 0.5123 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.90300\n",
            "Epoch 601/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2554 - acc: 0.9656 - val_loss: 0.5207 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.90300\n",
            "Epoch 602/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2645 - acc: 0.9635 - val_loss: 0.5160 - val_acc: 0.8966\n",
            "\n",
            "Epoch 00602: val_acc did not improve from 0.90300\n",
            "Epoch 603/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2546 - acc: 0.9677 - val_loss: 0.5139 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00603: val_acc did not improve from 0.90300\n",
            "Epoch 604/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2629 - acc: 0.9662 - val_loss: 0.5149 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00604: val_acc did not improve from 0.90300\n",
            "Epoch 605/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2680 - acc: 0.9622 - val_loss: 0.5147 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00605: val_acc did not improve from 0.90300\n",
            "Epoch 606/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2668 - acc: 0.9615 - val_loss: 0.5126 - val_acc: 0.8977\n",
            "\n",
            "Epoch 00606: val_acc did not improve from 0.90300\n",
            "Epoch 607/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2635 - acc: 0.9653 - val_loss: 0.5142 - val_acc: 0.8967\n",
            "\n",
            "Epoch 00607: val_acc did not improve from 0.90300\n",
            "Epoch 608/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2598 - acc: 0.9666 - val_loss: 0.5136 - val_acc: 0.8979\n",
            "\n",
            "Epoch 00608: val_acc did not improve from 0.90300\n",
            "Epoch 609/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2597 - acc: 0.9647 - val_loss: 0.5143 - val_acc: 0.8967\n",
            "\n",
            "Epoch 00609: val_acc did not improve from 0.90300\n",
            "Epoch 610/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2583 - acc: 0.9653 - val_loss: 0.5131 - val_acc: 0.8972\n",
            "\n",
            "Epoch 00610: val_acc did not improve from 0.90300\n",
            "Epoch 611/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2580 - acc: 0.9658 - val_loss: 0.5130 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.90300\n",
            "Epoch 612/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2555 - acc: 0.9658 - val_loss: 0.5123 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00612: val_acc did not improve from 0.90300\n",
            "Epoch 613/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2581 - acc: 0.9694 - val_loss: 0.5110 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00613: val_acc did not improve from 0.90300\n",
            "Epoch 614/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2555 - acc: 0.9690 - val_loss: 0.5121 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.90300\n",
            "Epoch 615/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2621 - acc: 0.9661 - val_loss: 0.5115 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.90300\n",
            "Epoch 616/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2659 - acc: 0.9631 - val_loss: 0.5123 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00616: val_acc did not improve from 0.90300\n",
            "Epoch 617/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2613 - acc: 0.9648 - val_loss: 0.5125 - val_acc: 0.8979\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.90300\n",
            "Epoch 618/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2546 - acc: 0.9679 - val_loss: 0.5124 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00618: val_acc did not improve from 0.90300\n",
            "Epoch 619/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2588 - acc: 0.9667 - val_loss: 0.5125 - val_acc: 0.8982\n",
            "\n",
            "Epoch 00619: val_acc did not improve from 0.90300\n",
            "Epoch 620/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2599 - acc: 0.9665 - val_loss: 0.5122 - val_acc: 0.8982\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.90300\n",
            "Epoch 621/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2593 - acc: 0.9669 - val_loss: 0.5129 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00621: val_acc did not improve from 0.90300\n",
            "Epoch 622/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2611 - acc: 0.9656 - val_loss: 0.5111 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.90300\n",
            "Epoch 623/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2603 - acc: 0.9665 - val_loss: 0.5112 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.90300\n",
            "Epoch 624/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2646 - acc: 0.9635 - val_loss: 0.5121 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.90300\n",
            "Epoch 625/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2580 - acc: 0.9649 - val_loss: 0.5116 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.90300\n",
            "Epoch 626/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2598 - acc: 0.9651 - val_loss: 0.5115 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.90300\n",
            "Epoch 627/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2622 - acc: 0.9643 - val_loss: 0.5110 - val_acc: 0.8987\n",
            "\n",
            "Epoch 00627: val_acc did not improve from 0.90300\n",
            "Epoch 628/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2622 - acc: 0.9658 - val_loss: 0.5111 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00628: val_acc did not improve from 0.90300\n",
            "Epoch 629/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.2630 - acc: 0.9659 - val_loss: 0.5111 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.90300\n",
            "Epoch 630/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2613 - acc: 0.9653 - val_loss: 0.5095 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00630: val_acc did not improve from 0.90300\n",
            "Epoch 631/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2554 - acc: 0.9671 - val_loss: 0.5109 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00631: val_acc did not improve from 0.90300\n",
            "Epoch 632/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2582 - acc: 0.9657 - val_loss: 0.5095 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00632: val_acc did not improve from 0.90300\n",
            "Epoch 633/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2610 - acc: 0.9650 - val_loss: 0.5108 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.90300\n",
            "Epoch 634/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2610 - acc: 0.9651 - val_loss: 0.5100 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.90300\n",
            "Epoch 635/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2576 - acc: 0.9666 - val_loss: 0.5100 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.90300\n",
            "Epoch 636/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 0.2681 - acc: 0.9624 - val_loss: 0.5104 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.90300\n",
            "Epoch 637/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2607 - acc: 0.9646 - val_loss: 0.5097 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00637: val_acc did not improve from 0.90300\n",
            "Epoch 638/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2614 - acc: 0.9649 - val_loss: 0.5109 - val_acc: 0.8987\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.90300\n",
            "Epoch 639/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2615 - acc: 0.9642 - val_loss: 0.5105 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.90300\n",
            "Epoch 640/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2611 - acc: 0.9640 - val_loss: 0.5088 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.90300\n",
            "Epoch 641/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2574 - acc: 0.9658 - val_loss: 0.5096 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.90300\n",
            "Epoch 642/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2622 - acc: 0.9660 - val_loss: 0.5082 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.90300\n",
            "Epoch 643/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2671 - acc: 0.9614 - val_loss: 0.5091 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.90300\n",
            "Epoch 644/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.2574 - acc: 0.9686 - val_loss: 0.5081 - val_acc: 0.8998\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.90300\n",
            "Epoch 645/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2594 - acc: 0.9657 - val_loss: 0.5077 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00645: val_acc did not improve from 0.90300\n",
            "Epoch 646/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2527 - acc: 0.9690 - val_loss: 0.5080 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00646: val_acc did not improve from 0.90300\n",
            "Epoch 647/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2597 - acc: 0.9653 - val_loss: 0.5084 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00647: val_acc did not improve from 0.90300\n",
            "Epoch 648/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2656 - acc: 0.9628 - val_loss: 0.5073 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.90300\n",
            "Epoch 649/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2634 - acc: 0.9626 - val_loss: 0.5077 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.90300\n",
            "Epoch 650/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.2585 - acc: 0.9671 - val_loss: 0.5082 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00650: val_acc did not improve from 0.90300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "ZNjo2H9wVsEl",
        "outputId": "0c69b592-9658-495d-c5c9-6b380887b2ee"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('trainHistoryDict', \"rb\"))\n",
        "functions.plot_loss_acc(history, 2, 0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dccMqpCHe6hz",
        "outputId": "0e340d82-cf67-4fab-a8f4-69a46d57d592"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8992000222206116"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQMh7IJuYITD",
        "outputId": "4b394e09-86fc-44eb-9e80-94f6ae49baaa"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10079997777938843"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO9ydg0YT2e2"
      },
      "source": [
        "#### Model with clipping to 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51_MIl3rT6wF",
        "outputId": "3473a44a-ba70-4f23-9273-b745f115399a"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(\n",
        "    input_shape, conv_layer = functions.ConvDecomposed2D, decomposition_rank=29,\n",
        "    compress_first=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzzSqCDQFgjJ",
        "outputId": "c794970a-be73-40f3-ca8a-f97e57ec35e9"
      },
      "source": [
        "callbacks = functions.standard_callbacks(model_type) + [functions.Clipping(0.5)]\n",
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'trainHistoryDict_clip_05', steps_per_epoch=100, epochs=650,\n",
        "                       batch_size=100,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 48s 105ms/step - loss: 3.4640 - acc: 0.2533 - val_loss: 3.0169 - val_acc: 0.1819\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.18190, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 2.0375 - acc: 0.2965 - val_loss: 2.6853 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.18190\n",
            "Epoch 3/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.8297 - acc: 0.3810 - val_loss: 2.7341 - val_acc: 0.1001\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.18190\n",
            "Epoch 4/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.6917 - acc: 0.4348 - val_loss: 3.0174 - val_acc: 0.1007\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.18190\n",
            "Epoch 5/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.6161 - acc: 0.4656 - val_loss: 3.2814 - val_acc: 0.1294\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.18190\n",
            "Epoch 6/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.5009 - acc: 0.5193 - val_loss: 2.2613 - val_acc: 0.2352\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.18190 to 0.23520, saving model to /content/saved_models/cifar10_ResNet32v1_model.006.h5\n",
            "Epoch 7/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4509 - acc: 0.5396 - val_loss: 2.0167 - val_acc: 0.3917\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.23520 to 0.39170, saving model to /content/saved_models/cifar10_ResNet32v1_model.007.h5\n",
            "Epoch 8/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3992 - acc: 0.5601 - val_loss: 2.4167 - val_acc: 0.3656\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.39170\n",
            "Epoch 9/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3549 - acc: 0.5719 - val_loss: 2.2271 - val_acc: 0.4229\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.39170 to 0.42290, saving model to /content/saved_models/cifar10_ResNet32v1_model.009.h5\n",
            "Epoch 10/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.3127 - acc: 0.5900 - val_loss: 5.2881 - val_acc: 0.2745\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.42290\n",
            "Epoch 11/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.2574 - acc: 0.6105 - val_loss: 7.1302 - val_acc: 0.2169\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.42290\n",
            "Epoch 12/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2554 - acc: 0.6192 - val_loss: 4.2505 - val_acc: 0.3239\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.42290\n",
            "Epoch 13/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2140 - acc: 0.6297 - val_loss: 3.0584 - val_acc: 0.3619\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.42290\n",
            "Epoch 14/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.1899 - acc: 0.6392 - val_loss: 2.9235 - val_acc: 0.4088\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.42290\n",
            "Epoch 15/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.1621 - acc: 0.6502 - val_loss: 1.6387 - val_acc: 0.5279\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.42290 to 0.52790, saving model to /content/saved_models/cifar10_ResNet32v1_model.015.h5\n",
            "Epoch 16/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.1405 - acc: 0.6514 - val_loss: 3.9293 - val_acc: 0.3396\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.52790\n",
            "Epoch 17/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.1188 - acc: 0.6612 - val_loss: 2.7710 - val_acc: 0.4255\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.52790\n",
            "Epoch 18/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0972 - acc: 0.6719 - val_loss: 1.7392 - val_acc: 0.5614\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.52790 to 0.56140, saving model to /content/saved_models/cifar10_ResNet32v1_model.018.h5\n",
            "Epoch 19/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.0706 - acc: 0.6814 - val_loss: 4.8560 - val_acc: 0.2835\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.56140\n",
            "Epoch 20/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0673 - acc: 0.6838 - val_loss: 2.1178 - val_acc: 0.4775\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.56140\n",
            "Epoch 21/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0725 - acc: 0.6848 - val_loss: 4.1704 - val_acc: 0.3737\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.56140\n",
            "Epoch 22/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0547 - acc: 0.6932 - val_loss: 3.7725 - val_acc: 0.3355\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.56140\n",
            "Epoch 23/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.0465 - acc: 0.6957 - val_loss: 1.9234 - val_acc: 0.5328\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.56140\n",
            "Epoch 24/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.0163 - acc: 0.7010 - val_loss: 4.0649 - val_acc: 0.3117\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.56140\n",
            "Epoch 25/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0120 - acc: 0.7036 - val_loss: 3.1335 - val_acc: 0.4195\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.56140\n",
            "Epoch 26/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.0289 - acc: 0.7019 - val_loss: 2.8595 - val_acc: 0.4038\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.56140\n",
            "Epoch 27/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9967 - acc: 0.7115 - val_loss: 1.2964 - val_acc: 0.6059\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.56140 to 0.60590, saving model to /content/saved_models/cifar10_ResNet32v1_model.027.h5\n",
            "Epoch 28/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0109 - acc: 0.7060 - val_loss: 4.9171 - val_acc: 0.3945\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.60590\n",
            "Epoch 29/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.9983 - acc: 0.7097 - val_loss: 2.7668 - val_acc: 0.4496\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.60590\n",
            "Epoch 30/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9718 - acc: 0.7258 - val_loss: 3.2347 - val_acc: 0.3880\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.60590\n",
            "Epoch 31/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.9528 - acc: 0.7301 - val_loss: 2.5285 - val_acc: 0.4579\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.60590\n",
            "Epoch 32/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9806 - acc: 0.7179 - val_loss: 2.8591 - val_acc: 0.3925\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.60590\n",
            "Epoch 33/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.9683 - acc: 0.7238 - val_loss: 6.9404 - val_acc: 0.1955\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.60590\n",
            "Epoch 34/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.9628 - acc: 0.7259 - val_loss: 1.6017 - val_acc: 0.6035\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.60590\n",
            "Epoch 35/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.9642 - acc: 0.7199 - val_loss: 1.6841 - val_acc: 0.5826\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.60590\n",
            "Epoch 36/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.9415 - acc: 0.7311 - val_loss: 2.0926 - val_acc: 0.5179\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.60590\n",
            "Epoch 37/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.9331 - acc: 0.7311 - val_loss: 2.9880 - val_acc: 0.4280\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.60590\n",
            "Epoch 38/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.9348 - acc: 0.7332 - val_loss: 1.9601 - val_acc: 0.5361\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.60590\n",
            "Epoch 39/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.9461 - acc: 0.7274 - val_loss: 1.9224 - val_acc: 0.5233\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.60590\n",
            "Epoch 40/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9280 - acc: 0.7364 - val_loss: 3.0283 - val_acc: 0.4058\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.60590\n",
            "Epoch 41/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.9098 - acc: 0.7385 - val_loss: 6.6714 - val_acc: 0.2044\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.60590\n",
            "Epoch 42/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.9305 - acc: 0.7345 - val_loss: 2.2219 - val_acc: 0.4868\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.60590\n",
            "Epoch 43/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9069 - acc: 0.7452 - val_loss: 1.9310 - val_acc: 0.5608\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.60590\n",
            "Epoch 44/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9022 - acc: 0.7496 - val_loss: 1.9649 - val_acc: 0.5387\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.60590\n",
            "Epoch 45/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.9124 - acc: 0.7389 - val_loss: 1.9843 - val_acc: 0.5218\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.60590\n",
            "Epoch 46/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8970 - acc: 0.7509 - val_loss: 1.9366 - val_acc: 0.5610\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.60590\n",
            "Epoch 47/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8991 - acc: 0.7421 - val_loss: 2.3135 - val_acc: 0.5225\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.60590\n",
            "Epoch 48/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.9024 - acc: 0.7448 - val_loss: 2.5106 - val_acc: 0.5204\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.60590\n",
            "Epoch 49/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8958 - acc: 0.7471 - val_loss: 1.6223 - val_acc: 0.5699\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.60590\n",
            "Epoch 50/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8914 - acc: 0.7466 - val_loss: 3.6748 - val_acc: 0.3871\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.60590\n",
            "Epoch 51/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.8841 - acc: 0.7543 - val_loss: 1.7268 - val_acc: 0.5648\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.60590\n",
            "Epoch 52/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.8898 - acc: 0.7514 - val_loss: 1.5331 - val_acc: 0.5891\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.60590\n",
            "Epoch 53/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8802 - acc: 0.7531 - val_loss: 2.3442 - val_acc: 0.4855\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.60590\n",
            "Epoch 54/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9029 - acc: 0.7451 - val_loss: 3.4493 - val_acc: 0.3904\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.60590\n",
            "Epoch 55/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8943 - acc: 0.7493 - val_loss: 1.7510 - val_acc: 0.5934\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.60590\n",
            "Epoch 56/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8870 - acc: 0.7532 - val_loss: 3.4517 - val_acc: 0.4288\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.60590\n",
            "Epoch 57/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8758 - acc: 0.7556 - val_loss: 1.2937 - val_acc: 0.6411\n",
            "\n",
            "Epoch 00057: val_acc improved from 0.60590 to 0.64110, saving model to /content/saved_models/cifar10_ResNet32v1_model.057.h5\n",
            "Epoch 58/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8901 - acc: 0.7485 - val_loss: 4.6226 - val_acc: 0.3195\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.64110\n",
            "Epoch 59/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.8888 - acc: 0.7506 - val_loss: 2.6802 - val_acc: 0.5057\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.64110\n",
            "Epoch 60/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8651 - acc: 0.7635 - val_loss: 2.6373 - val_acc: 0.4653\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.64110\n",
            "Epoch 61/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8771 - acc: 0.7520 - val_loss: 4.2735 - val_acc: 0.3821\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.64110\n",
            "Epoch 62/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8714 - acc: 0.7560 - val_loss: 3.6533 - val_acc: 0.3712\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.64110\n",
            "Epoch 63/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8931 - acc: 0.7528 - val_loss: 2.3957 - val_acc: 0.5053\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.64110\n",
            "Epoch 64/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8688 - acc: 0.7600 - val_loss: 1.7069 - val_acc: 0.5816\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.64110\n",
            "Epoch 65/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8767 - acc: 0.7540 - val_loss: 1.7438 - val_acc: 0.5796\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.64110\n",
            "Epoch 66/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8722 - acc: 0.7578 - val_loss: 1.3216 - val_acc: 0.6638\n",
            "\n",
            "Epoch 00066: val_acc improved from 0.64110 to 0.66380, saving model to /content/saved_models/cifar10_ResNet32v1_model.066.h5\n",
            "Epoch 67/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8430 - acc: 0.7664 - val_loss: 1.5494 - val_acc: 0.6449\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.66380\n",
            "Epoch 68/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8544 - acc: 0.7660 - val_loss: 2.4564 - val_acc: 0.4771\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.66380\n",
            "Epoch 69/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8351 - acc: 0.7698 - val_loss: 3.8456 - val_acc: 0.4118\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.66380\n",
            "Epoch 70/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8401 - acc: 0.7732 - val_loss: 1.9875 - val_acc: 0.5675\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.66380\n",
            "Epoch 71/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8540 - acc: 0.7660 - val_loss: 1.3386 - val_acc: 0.6477\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.66380\n",
            "Epoch 72/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8454 - acc: 0.7621 - val_loss: 2.4947 - val_acc: 0.5102\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.66380\n",
            "Epoch 73/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8387 - acc: 0.7701 - val_loss: 3.2433 - val_acc: 0.4504\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.66380\n",
            "Epoch 74/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.8355 - acc: 0.7696 - val_loss: 1.5340 - val_acc: 0.6117\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.66380\n",
            "Epoch 75/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8301 - acc: 0.7705 - val_loss: 1.6597 - val_acc: 0.6234\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.66380\n",
            "Epoch 76/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8417 - acc: 0.7644 - val_loss: 1.8577 - val_acc: 0.5696\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.66380\n",
            "Epoch 77/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8421 - acc: 0.7662 - val_loss: 5.1762 - val_acc: 0.3760\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.66380\n",
            "Epoch 78/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.8722 - acc: 0.7597 - val_loss: 1.3457 - val_acc: 0.6404\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.66380\n",
            "Epoch 79/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8259 - acc: 0.7738 - val_loss: 1.6121 - val_acc: 0.6095\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.66380\n",
            "Epoch 80/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8600 - acc: 0.7600 - val_loss: 1.6119 - val_acc: 0.6172\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.66380\n",
            "Epoch 81/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.8399 - acc: 0.7684 - val_loss: 3.1412 - val_acc: 0.4638\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.66380\n",
            "Epoch 82/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.8405 - acc: 0.7669 - val_loss: 1.7821 - val_acc: 0.5741\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.66380\n",
            "Epoch 83/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8502 - acc: 0.7693 - val_loss: 3.1462 - val_acc: 0.5224\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.66380\n",
            "Epoch 84/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8322 - acc: 0.7722 - val_loss: 4.0362 - val_acc: 0.3739\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.66380\n",
            "Epoch 85/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8030 - acc: 0.7872 - val_loss: 2.4759 - val_acc: 0.5049\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.66380\n",
            "Epoch 86/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8411 - acc: 0.7722 - val_loss: 2.7707 - val_acc: 0.4052\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.66380\n",
            "Epoch 87/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8373 - acc: 0.7681 - val_loss: 3.9284 - val_acc: 0.3927\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.66380\n",
            "Epoch 88/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8314 - acc: 0.7695 - val_loss: 1.2969 - val_acc: 0.6617\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.66380\n",
            "Epoch 89/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8303 - acc: 0.7732 - val_loss: 3.6076 - val_acc: 0.4321\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.66380\n",
            "Epoch 90/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8190 - acc: 0.7769 - val_loss: 1.5374 - val_acc: 0.6158\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.66380\n",
            "Epoch 91/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8238 - acc: 0.7706 - val_loss: 1.8018 - val_acc: 0.5534\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.66380\n",
            "Epoch 92/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8157 - acc: 0.7758 - val_loss: 2.1506 - val_acc: 0.4879\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.66380\n",
            "Epoch 93/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.8381 - acc: 0.7679 - val_loss: 4.0168 - val_acc: 0.3938\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.66380\n",
            "Epoch 94/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8084 - acc: 0.7749 - val_loss: 2.4507 - val_acc: 0.4869\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.66380\n",
            "Epoch 95/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8118 - acc: 0.7805 - val_loss: 2.7825 - val_acc: 0.4776\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.66380\n",
            "Epoch 96/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8275 - acc: 0.7704 - val_loss: 2.2923 - val_acc: 0.5296\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.66380\n",
            "Epoch 97/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7830 - acc: 0.7886 - val_loss: 3.0981 - val_acc: 0.4646\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.66380\n",
            "Epoch 98/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8337 - acc: 0.7680 - val_loss: 2.1050 - val_acc: 0.5563\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.66380\n",
            "Epoch 99/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8188 - acc: 0.7773 - val_loss: 3.2373 - val_acc: 0.4273\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.66380\n",
            "Epoch 100/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8117 - acc: 0.7784 - val_loss: 4.2830 - val_acc: 0.4204\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.66380\n",
            "Epoch 101/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8000 - acc: 0.7851 - val_loss: 2.3645 - val_acc: 0.4608\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.66380\n",
            "Epoch 102/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7992 - acc: 0.7848 - val_loss: 1.5413 - val_acc: 0.6107\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.66380\n",
            "Epoch 103/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8012 - acc: 0.7840 - val_loss: 3.3019 - val_acc: 0.4275\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.66380\n",
            "Epoch 104/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8067 - acc: 0.7813 - val_loss: 3.1630 - val_acc: 0.3978\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.66380\n",
            "Epoch 105/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7989 - acc: 0.7865 - val_loss: 4.4449 - val_acc: 0.3379\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.66380\n",
            "Epoch 106/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7933 - acc: 0.7860 - val_loss: 1.9530 - val_acc: 0.5391\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.66380\n",
            "Epoch 107/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.8068 - acc: 0.7813 - val_loss: 2.6277 - val_acc: 0.4811\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.66380\n",
            "Epoch 108/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7818 - acc: 0.7880 - val_loss: 2.4450 - val_acc: 0.4515\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.66380\n",
            "Epoch 109/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8154 - acc: 0.7777 - val_loss: 2.2502 - val_acc: 0.5177\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.66380\n",
            "Epoch 110/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7931 - acc: 0.7794 - val_loss: 1.5023 - val_acc: 0.6083\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.66380\n",
            "Epoch 111/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8186 - acc: 0.7822 - val_loss: 1.1526 - val_acc: 0.7064\n",
            "\n",
            "Epoch 00111: val_acc improved from 0.66380 to 0.70640, saving model to /content/saved_models/cifar10_ResNet32v1_model.111.h5\n",
            "Epoch 112/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8100 - acc: 0.7729 - val_loss: 4.0613 - val_acc: 0.3617\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.70640\n",
            "Epoch 113/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7776 - acc: 0.7911 - val_loss: 1.4497 - val_acc: 0.6516\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.70640\n",
            "Epoch 114/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.7871 - acc: 0.7891 - val_loss: 1.6580 - val_acc: 0.5971\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.70640\n",
            "Epoch 115/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7915 - acc: 0.7839 - val_loss: 2.1664 - val_acc: 0.5316\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.70640\n",
            "Epoch 116/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7973 - acc: 0.7842 - val_loss: 1.5150 - val_acc: 0.6492\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.70640\n",
            "Epoch 117/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7740 - acc: 0.7915 - val_loss: 2.8689 - val_acc: 0.4613\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.70640\n",
            "Epoch 118/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.7762 - acc: 0.7867 - val_loss: 4.2209 - val_acc: 0.3338\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.70640\n",
            "Epoch 119/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8082 - acc: 0.7784 - val_loss: 4.9623 - val_acc: 0.3318\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.70640\n",
            "Epoch 120/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7827 - acc: 0.7843 - val_loss: 1.2721 - val_acc: 0.6590\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.70640\n",
            "Epoch 121/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7816 - acc: 0.7878 - val_loss: 1.8015 - val_acc: 0.5125\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.70640\n",
            "Epoch 122/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7743 - acc: 0.7909 - val_loss: 2.2413 - val_acc: 0.5244\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.70640\n",
            "Epoch 123/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8029 - acc: 0.7804 - val_loss: 2.0323 - val_acc: 0.5384\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.70640\n",
            "Epoch 124/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7826 - acc: 0.7886 - val_loss: 2.2893 - val_acc: 0.5673\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.70640\n",
            "Epoch 125/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7819 - acc: 0.7891 - val_loss: 2.4304 - val_acc: 0.5338\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.70640\n",
            "Epoch 126/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7752 - acc: 0.7891 - val_loss: 2.3380 - val_acc: 0.4793\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.70640\n",
            "Epoch 127/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7816 - acc: 0.7866 - val_loss: 2.3576 - val_acc: 0.5494\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.70640\n",
            "Epoch 128/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7739 - acc: 0.7917 - val_loss: 1.8204 - val_acc: 0.5874\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.70640\n",
            "Epoch 129/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7688 - acc: 0.7928 - val_loss: 1.9482 - val_acc: 0.5248\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.70640\n",
            "Epoch 130/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7706 - acc: 0.7933 - val_loss: 1.7869 - val_acc: 0.5812\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.70640\n",
            "Epoch 131/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7860 - acc: 0.7939 - val_loss: 1.6727 - val_acc: 0.6243\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.70640\n",
            "Epoch 132/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7807 - acc: 0.7886 - val_loss: 2.0495 - val_acc: 0.5130\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.70640\n",
            "Epoch 133/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7700 - acc: 0.7949 - val_loss: 1.8891 - val_acc: 0.5828\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.70640\n",
            "Epoch 134/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7885 - acc: 0.7865 - val_loss: 2.6230 - val_acc: 0.5377\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.70640\n",
            "Epoch 135/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7724 - acc: 0.7904 - val_loss: 1.5440 - val_acc: 0.5726\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.70640\n",
            "Epoch 136/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7957 - acc: 0.7806 - val_loss: 1.6136 - val_acc: 0.6448\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.70640\n",
            "Epoch 137/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7852 - acc: 0.7872 - val_loss: 2.1114 - val_acc: 0.5136\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.70640\n",
            "Epoch 138/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7696 - acc: 0.7936 - val_loss: 1.7734 - val_acc: 0.6141\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.70640\n",
            "Epoch 139/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7720 - acc: 0.7934 - val_loss: 1.3437 - val_acc: 0.6372\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.70640\n",
            "Epoch 140/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7633 - acc: 0.8014 - val_loss: 1.3007 - val_acc: 0.6729\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.70640\n",
            "Epoch 141/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7851 - acc: 0.7858 - val_loss: 1.4444 - val_acc: 0.6013\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.70640\n",
            "Epoch 142/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7856 - acc: 0.7875 - val_loss: 4.1741 - val_acc: 0.3850\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.70640\n",
            "Epoch 143/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7573 - acc: 0.7937 - val_loss: 1.3770 - val_acc: 0.6554\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.70640\n",
            "Epoch 144/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7632 - acc: 0.7947 - val_loss: 1.9179 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.70640\n",
            "Epoch 145/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7674 - acc: 0.7973 - val_loss: 2.2765 - val_acc: 0.5141\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.70640\n",
            "Epoch 146/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7701 - acc: 0.7893 - val_loss: 4.0088 - val_acc: 0.3211\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.70640\n",
            "Epoch 147/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7671 - acc: 0.7926 - val_loss: 1.6265 - val_acc: 0.6064\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.70640\n",
            "Epoch 148/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7826 - acc: 0.7913 - val_loss: 1.6907 - val_acc: 0.5810\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.70640\n",
            "Epoch 149/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7513 - acc: 0.8011 - val_loss: 2.6620 - val_acc: 0.4645\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.70640\n",
            "Epoch 150/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7787 - acc: 0.7911 - val_loss: 2.0041 - val_acc: 0.5727\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.70640\n",
            "Epoch 151/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7662 - acc: 0.7921 - val_loss: 1.9182 - val_acc: 0.6064\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.70640\n",
            "Epoch 152/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7553 - acc: 0.7967 - val_loss: 1.6861 - val_acc: 0.5974\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.70640\n",
            "Epoch 153/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7572 - acc: 0.7996 - val_loss: 1.9650 - val_acc: 0.5790\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.70640\n",
            "Epoch 154/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7688 - acc: 0.7928 - val_loss: 2.8143 - val_acc: 0.4918\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.70640\n",
            "Epoch 155/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7688 - acc: 0.7932 - val_loss: 1.4257 - val_acc: 0.6377\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.70640\n",
            "Epoch 156/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7701 - acc: 0.7938 - val_loss: 3.9836 - val_acc: 0.3045\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.70640\n",
            "Epoch 157/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7353 - acc: 0.8017 - val_loss: 1.2495 - val_acc: 0.6697\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.70640\n",
            "Epoch 158/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7773 - acc: 0.7939 - val_loss: 3.0912 - val_acc: 0.4191\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.70640\n",
            "Epoch 159/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7575 - acc: 0.7974 - val_loss: 3.2004 - val_acc: 0.4653\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.70640\n",
            "Epoch 160/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7775 - acc: 0.7880 - val_loss: 1.2463 - val_acc: 0.6878\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.70640\n",
            "Epoch 161/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7729 - acc: 0.7963 - val_loss: 3.1618 - val_acc: 0.4488\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.70640\n",
            "Epoch 162/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7484 - acc: 0.8007 - val_loss: 1.6028 - val_acc: 0.6220\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.70640\n",
            "Epoch 163/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7825 - acc: 0.7845 - val_loss: 3.0652 - val_acc: 0.4297\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.70640\n",
            "Epoch 164/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7551 - acc: 0.7988 - val_loss: 3.0911 - val_acc: 0.4360\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.70640\n",
            "Epoch 165/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7653 - acc: 0.7927 - val_loss: 3.1682 - val_acc: 0.4324\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.70640\n",
            "Epoch 166/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7681 - acc: 0.7924 - val_loss: 1.3250 - val_acc: 0.6720\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.70640\n",
            "Epoch 167/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7582 - acc: 0.8014 - val_loss: 2.3407 - val_acc: 0.5243\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.70640\n",
            "Epoch 168/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7588 - acc: 0.7981 - val_loss: 1.9333 - val_acc: 0.5631\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.70640\n",
            "Epoch 169/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7754 - acc: 0.7908 - val_loss: 1.7421 - val_acc: 0.6206\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.70640\n",
            "Epoch 170/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7550 - acc: 0.7950 - val_loss: 2.6517 - val_acc: 0.4399\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.70640\n",
            "Epoch 171/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7644 - acc: 0.7914 - val_loss: 1.8390 - val_acc: 0.5887\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.70640\n",
            "Epoch 172/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7588 - acc: 0.7959 - val_loss: 2.3602 - val_acc: 0.5348\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.70640\n",
            "Epoch 173/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7562 - acc: 0.7934 - val_loss: 2.6707 - val_acc: 0.4804\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.70640\n",
            "Epoch 174/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7379 - acc: 0.8001 - val_loss: 2.3044 - val_acc: 0.5171\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.70640\n",
            "Epoch 175/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7412 - acc: 0.8017 - val_loss: 1.8185 - val_acc: 0.5738\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.70640\n",
            "Epoch 176/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7522 - acc: 0.7988 - val_loss: 1.6286 - val_acc: 0.6192\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.70640\n",
            "Epoch 177/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7505 - acc: 0.7985 - val_loss: 1.9183 - val_acc: 0.5581\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.70640\n",
            "Epoch 178/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7371 - acc: 0.8009 - val_loss: 1.5703 - val_acc: 0.6322\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.70640\n",
            "Epoch 179/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7467 - acc: 0.8020 - val_loss: 5.8336 - val_acc: 0.2757\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.70640\n",
            "Epoch 180/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7673 - acc: 0.7911 - val_loss: 4.3744 - val_acc: 0.3673\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.70640\n",
            "Epoch 181/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7440 - acc: 0.8021 - val_loss: 2.1071 - val_acc: 0.5563\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.70640\n",
            "Epoch 182/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7569 - acc: 0.7976 - val_loss: 2.2427 - val_acc: 0.5565\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.70640\n",
            "Epoch 183/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7356 - acc: 0.8019 - val_loss: 1.4891 - val_acc: 0.6478\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.70640\n",
            "Epoch 184/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7463 - acc: 0.8039 - val_loss: 2.0350 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.70640\n",
            "Epoch 185/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7303 - acc: 0.8042 - val_loss: 1.2726 - val_acc: 0.6657\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.70640\n",
            "Epoch 186/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7325 - acc: 0.8060 - val_loss: 1.7198 - val_acc: 0.6026\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.70640\n",
            "Epoch 187/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7555 - acc: 0.8004 - val_loss: 2.6045 - val_acc: 0.4930\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.70640\n",
            "Epoch 188/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7375 - acc: 0.8002 - val_loss: 1.1349 - val_acc: 0.7035\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.70640\n",
            "Epoch 189/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7531 - acc: 0.8011 - val_loss: 1.8156 - val_acc: 0.5784\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.70640\n",
            "Epoch 190/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7439 - acc: 0.7969 - val_loss: 1.3009 - val_acc: 0.6843\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.70640\n",
            "Epoch 191/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7429 - acc: 0.8017 - val_loss: 1.6702 - val_acc: 0.6026\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.70640\n",
            "Epoch 192/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7494 - acc: 0.8057 - val_loss: 1.5936 - val_acc: 0.6441\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.70640\n",
            "Epoch 193/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7480 - acc: 0.7997 - val_loss: 1.9040 - val_acc: 0.5358\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.70640\n",
            "Epoch 194/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7419 - acc: 0.8051 - val_loss: 3.0132 - val_acc: 0.4264\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.70640\n",
            "Epoch 195/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7420 - acc: 0.8017 - val_loss: 2.9699 - val_acc: 0.4200\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.70640\n",
            "Epoch 196/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7268 - acc: 0.8115 - val_loss: 3.2997 - val_acc: 0.3732\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.70640\n",
            "Epoch 197/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7430 - acc: 0.8082 - val_loss: 1.5142 - val_acc: 0.6418\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.70640\n",
            "Epoch 198/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7593 - acc: 0.7932 - val_loss: 1.2127 - val_acc: 0.6836\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.70640\n",
            "Epoch 199/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7445 - acc: 0.7979 - val_loss: 1.6398 - val_acc: 0.6171\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.70640\n",
            "Epoch 200/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7368 - acc: 0.8082 - val_loss: 2.7674 - val_acc: 0.4637\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.70640\n",
            "Epoch 201/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7451 - acc: 0.8003 - val_loss: 1.6858 - val_acc: 0.5952\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.70640\n",
            "Epoch 202/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7274 - acc: 0.8073 - val_loss: 1.3690 - val_acc: 0.6618\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.70640\n",
            "Epoch 203/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7504 - acc: 0.7999 - val_loss: 4.5101 - val_acc: 0.3404\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.70640\n",
            "Epoch 204/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7322 - acc: 0.8075 - val_loss: 1.9475 - val_acc: 0.5847\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.70640\n",
            "Epoch 205/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7521 - acc: 0.7967 - val_loss: 1.7003 - val_acc: 0.6223\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.70640\n",
            "Epoch 206/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7469 - acc: 0.7951 - val_loss: 1.6203 - val_acc: 0.5911\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.70640\n",
            "Epoch 207/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7273 - acc: 0.8034 - val_loss: 3.4131 - val_acc: 0.4167\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.70640\n",
            "Epoch 208/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7475 - acc: 0.8009 - val_loss: 2.5755 - val_acc: 0.5024\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.70640\n",
            "Epoch 209/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7378 - acc: 0.8046 - val_loss: 2.1357 - val_acc: 0.5572\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.70640\n",
            "Epoch 210/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.7227 - acc: 0.8085 - val_loss: 1.4544 - val_acc: 0.6455\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.70640\n",
            "Epoch 211/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.7415 - acc: 0.8012 - val_loss: 1.9029 - val_acc: 0.5690\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.70640\n",
            "Epoch 212/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7375 - acc: 0.8059 - val_loss: 1.9733 - val_acc: 0.5587\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.70640\n",
            "Epoch 213/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7253 - acc: 0.8045 - val_loss: 1.9976 - val_acc: 0.5554\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.70640\n",
            "Epoch 214/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7484 - acc: 0.7950 - val_loss: 1.9319 - val_acc: 0.5536\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.70640\n",
            "Epoch 215/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7253 - acc: 0.8066 - val_loss: 2.1264 - val_acc: 0.5410\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.70640\n",
            "Epoch 216/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7392 - acc: 0.8024 - val_loss: 3.9146 - val_acc: 0.4018\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.70640\n",
            "Epoch 217/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7295 - acc: 0.8054 - val_loss: 2.6337 - val_acc: 0.4895\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.70640\n",
            "Epoch 218/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.7336 - acc: 0.8088 - val_loss: 1.2898 - val_acc: 0.6825\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.70640\n",
            "Epoch 219/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7257 - acc: 0.8092 - val_loss: 1.2214 - val_acc: 0.6743\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.70640\n",
            "Epoch 220/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7280 - acc: 0.8092 - val_loss: 4.8111 - val_acc: 0.3591\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.70640\n",
            "Epoch 221/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7500 - acc: 0.7988 - val_loss: 1.1973 - val_acc: 0.6815\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.70640\n",
            "Epoch 222/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7396 - acc: 0.8005 - val_loss: 1.9626 - val_acc: 0.5953\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.70640\n",
            "Epoch 223/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7304 - acc: 0.8079 - val_loss: 1.2440 - val_acc: 0.6575\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.70640\n",
            "Epoch 224/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7177 - acc: 0.8113 - val_loss: 2.0324 - val_acc: 0.5275\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.70640\n",
            "Epoch 225/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7293 - acc: 0.8028 - val_loss: 2.5464 - val_acc: 0.5220\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.70640\n",
            "Epoch 226/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7320 - acc: 0.8032 - val_loss: 1.8893 - val_acc: 0.5433\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.70640\n",
            "Epoch 227/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7184 - acc: 0.8075 - val_loss: 1.7330 - val_acc: 0.5701\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.70640\n",
            "Epoch 228/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7298 - acc: 0.8069 - val_loss: 2.1576 - val_acc: 0.5848\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.70640\n",
            "Epoch 229/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7149 - acc: 0.8135 - val_loss: 2.9364 - val_acc: 0.3999\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.70640\n",
            "Epoch 230/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7272 - acc: 0.8071 - val_loss: 2.4730 - val_acc: 0.4569\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.70640\n",
            "Epoch 231/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.7244 - acc: 0.8100 - val_loss: 1.2094 - val_acc: 0.7025\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.70640\n",
            "Epoch 232/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7248 - acc: 0.8093 - val_loss: 1.7730 - val_acc: 0.6192\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.70640\n",
            "Epoch 233/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7176 - acc: 0.8132 - val_loss: 2.0086 - val_acc: 0.5370\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.70640\n",
            "Epoch 234/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7306 - acc: 0.8107 - val_loss: 2.1206 - val_acc: 0.5242\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.70640\n",
            "Epoch 235/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7355 - acc: 0.8074 - val_loss: 1.4839 - val_acc: 0.6056\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.70640\n",
            "Epoch 236/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7285 - acc: 0.8108 - val_loss: 2.0128 - val_acc: 0.5392\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.70640\n",
            "Epoch 237/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7297 - acc: 0.8047 - val_loss: 1.6807 - val_acc: 0.6169\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.70640\n",
            "Epoch 238/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7194 - acc: 0.8080 - val_loss: 3.5496 - val_acc: 0.3503\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.70640\n",
            "Epoch 239/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7248 - acc: 0.8115 - val_loss: 1.7923 - val_acc: 0.5686\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.70640\n",
            "Epoch 240/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7333 - acc: 0.8077 - val_loss: 2.3511 - val_acc: 0.5087\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.70640\n",
            "Epoch 241/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7220 - acc: 0.8028 - val_loss: 1.5086 - val_acc: 0.6371\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.70640\n",
            "Epoch 242/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7162 - acc: 0.8107 - val_loss: 1.1590 - val_acc: 0.7023\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.70640\n",
            "Epoch 243/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7300 - acc: 0.8063 - val_loss: 2.4357 - val_acc: 0.5472\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.70640\n",
            "Epoch 244/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7369 - acc: 0.8052 - val_loss: 0.9526 - val_acc: 0.7388\n",
            "\n",
            "Epoch 00244: val_acc improved from 0.70640 to 0.73880, saving model to /content/saved_models/cifar10_ResNet32v1_model.244.h5\n",
            "Epoch 245/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7422 - acc: 0.8054 - val_loss: 1.4294 - val_acc: 0.6596\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.73880\n",
            "Epoch 246/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7229 - acc: 0.8088 - val_loss: 1.8011 - val_acc: 0.5610\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.73880\n",
            "Epoch 247/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7417 - acc: 0.8013 - val_loss: 1.4292 - val_acc: 0.6292\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.73880\n",
            "Epoch 248/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7303 - acc: 0.8099 - val_loss: 4.7261 - val_acc: 0.3543\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.73880\n",
            "Epoch 249/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7091 - acc: 0.8106 - val_loss: 2.8958 - val_acc: 0.4548\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.73880\n",
            "Epoch 250/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7199 - acc: 0.8072 - val_loss: 2.6446 - val_acc: 0.5404\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.73880\n",
            "Epoch 251/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7338 - acc: 0.8031 - val_loss: 2.0638 - val_acc: 0.5478\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.73880\n",
            "Epoch 252/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7139 - acc: 0.8111 - val_loss: 1.0919 - val_acc: 0.7081\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.73880\n",
            "Epoch 253/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7171 - acc: 0.8136 - val_loss: 1.7434 - val_acc: 0.5829\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.73880\n",
            "Epoch 254/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7311 - acc: 0.8091 - val_loss: 1.5296 - val_acc: 0.6362\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.73880\n",
            "Epoch 255/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7082 - acc: 0.8163 - val_loss: 2.0082 - val_acc: 0.5246\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.73880\n",
            "Epoch 256/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7228 - acc: 0.8083 - val_loss: 2.6932 - val_acc: 0.4970\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.73880\n",
            "Epoch 257/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7120 - acc: 0.8116 - val_loss: 1.7297 - val_acc: 0.5479\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.73880\n",
            "Epoch 258/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7214 - acc: 0.8068 - val_loss: 1.6783 - val_acc: 0.6098\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.73880\n",
            "Epoch 259/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7370 - acc: 0.8048 - val_loss: 3.1373 - val_acc: 0.4509\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.73880\n",
            "Epoch 260/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7265 - acc: 0.8070 - val_loss: 0.9712 - val_acc: 0.7369\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.73880\n",
            "Epoch 261/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7217 - acc: 0.8076 - val_loss: 1.6826 - val_acc: 0.5718\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.73880\n",
            "Epoch 262/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7298 - acc: 0.8065 - val_loss: 1.4530 - val_acc: 0.6294\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.73880\n",
            "Epoch 263/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7046 - acc: 0.8130 - val_loss: 1.8191 - val_acc: 0.5417\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.73880\n",
            "Epoch 264/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7225 - acc: 0.8074 - val_loss: 1.9463 - val_acc: 0.5741\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.73880\n",
            "Epoch 265/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7228 - acc: 0.8108 - val_loss: 2.0793 - val_acc: 0.5541\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.73880\n",
            "Epoch 266/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7192 - acc: 0.8080 - val_loss: 2.7996 - val_acc: 0.4668\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.73880\n",
            "Epoch 267/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7034 - acc: 0.8161 - val_loss: 1.4464 - val_acc: 0.6211\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.73880\n",
            "Epoch 268/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7217 - acc: 0.8095 - val_loss: 1.6696 - val_acc: 0.6190\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.73880\n",
            "Epoch 269/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7108 - acc: 0.8140 - val_loss: 1.5753 - val_acc: 0.6090\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.73880\n",
            "Epoch 270/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7331 - acc: 0.8013 - val_loss: 2.1464 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.73880\n",
            "Epoch 271/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7020 - acc: 0.8154 - val_loss: 2.3526 - val_acc: 0.5366\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.73880\n",
            "Epoch 272/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7153 - acc: 0.8111 - val_loss: 2.1139 - val_acc: 0.5223\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.73880\n",
            "Epoch 273/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7219 - acc: 0.8103 - val_loss: 4.0177 - val_acc: 0.3179\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.73880\n",
            "Epoch 274/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7052 - acc: 0.8151 - val_loss: 1.1497 - val_acc: 0.6944\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.73880\n",
            "Epoch 275/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7091 - acc: 0.8155 - val_loss: 1.8481 - val_acc: 0.5712\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.73880\n",
            "Epoch 276/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7096 - acc: 0.8158 - val_loss: 1.6383 - val_acc: 0.5878\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.73880\n",
            "Epoch 277/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7189 - acc: 0.8080 - val_loss: 2.1355 - val_acc: 0.5532\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.73880\n",
            "Epoch 278/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7154 - acc: 0.8121 - val_loss: 1.8138 - val_acc: 0.6120\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.73880\n",
            "Epoch 279/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7098 - acc: 0.8178 - val_loss: 2.2078 - val_acc: 0.5054\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.73880\n",
            "Epoch 280/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7378 - acc: 0.7990 - val_loss: 1.5113 - val_acc: 0.6413\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.73880\n",
            "Epoch 281/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7289 - acc: 0.8052 - val_loss: 1.5946 - val_acc: 0.6336\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.73880\n",
            "Epoch 282/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7292 - acc: 0.8078 - val_loss: 1.7690 - val_acc: 0.5778\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.73880\n",
            "Epoch 283/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7106 - acc: 0.8146 - val_loss: 1.8300 - val_acc: 0.5701\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.73880\n",
            "Epoch 284/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7129 - acc: 0.8120 - val_loss: 1.0404 - val_acc: 0.7060\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.73880\n",
            "Epoch 285/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7041 - acc: 0.8146 - val_loss: 5.3864 - val_acc: 0.3209\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.73880\n",
            "Epoch 286/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7072 - acc: 0.8145 - val_loss: 1.1699 - val_acc: 0.6982\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.73880\n",
            "Epoch 287/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7226 - acc: 0.8081 - val_loss: 1.4577 - val_acc: 0.6387\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.73880\n",
            "Epoch 288/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7240 - acc: 0.8055 - val_loss: 1.3152 - val_acc: 0.7017\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.73880\n",
            "Epoch 289/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7186 - acc: 0.8156 - val_loss: 3.9483 - val_acc: 0.3410\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.73880\n",
            "Epoch 290/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7314 - acc: 0.8050 - val_loss: 1.8360 - val_acc: 0.5623\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.73880\n",
            "Epoch 291/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7308 - acc: 0.8045 - val_loss: 1.1077 - val_acc: 0.6924\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.73880\n",
            "Epoch 292/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6956 - acc: 0.8167 - val_loss: 2.1250 - val_acc: 0.5386\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.73880\n",
            "Epoch 293/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7168 - acc: 0.8067 - val_loss: 1.3874 - val_acc: 0.6510\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.73880\n",
            "Epoch 294/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7233 - acc: 0.8097 - val_loss: 1.8575 - val_acc: 0.5883\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.73880\n",
            "Epoch 295/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7192 - acc: 0.8099 - val_loss: 2.0214 - val_acc: 0.5504\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.73880\n",
            "Epoch 296/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7168 - acc: 0.8087 - val_loss: 3.1084 - val_acc: 0.3506\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.73880\n",
            "Epoch 297/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.7057 - acc: 0.8146 - val_loss: 1.8289 - val_acc: 0.5801\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.73880\n",
            "Epoch 298/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7149 - acc: 0.8145 - val_loss: 1.9861 - val_acc: 0.5822\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.73880\n",
            "Epoch 299/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7144 - acc: 0.8145 - val_loss: 1.1744 - val_acc: 0.7038\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.73880\n",
            "Epoch 300/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7272 - acc: 0.8083 - val_loss: 2.8884 - val_acc: 0.4904\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.73880\n",
            "Epoch 301/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7038 - acc: 0.8195 - val_loss: 1.4312 - val_acc: 0.5958\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.73880\n",
            "Epoch 302/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7378 - acc: 0.8033 - val_loss: 2.6786 - val_acc: 0.4707\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.73880\n",
            "Epoch 303/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7221 - acc: 0.8080 - val_loss: 2.3487 - val_acc: 0.5228\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.73880\n",
            "Epoch 304/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7169 - acc: 0.8089 - val_loss: 3.2576 - val_acc: 0.3793\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.73880\n",
            "Epoch 305/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7265 - acc: 0.8131 - val_loss: 2.3325 - val_acc: 0.5531\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.73880\n",
            "Epoch 306/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7055 - acc: 0.8181 - val_loss: 1.5829 - val_acc: 0.6297\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.73880\n",
            "Epoch 307/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7175 - acc: 0.8122 - val_loss: 1.7887 - val_acc: 0.5763\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.73880\n",
            "Epoch 308/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7058 - acc: 0.8174 - val_loss: 1.6971 - val_acc: 0.6185\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.73880\n",
            "Epoch 309/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7176 - acc: 0.8121 - val_loss: 2.4258 - val_acc: 0.4944\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.73880\n",
            "Epoch 310/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7153 - acc: 0.8140 - val_loss: 1.4566 - val_acc: 0.6075\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.73880\n",
            "Epoch 311/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7058 - acc: 0.8191 - val_loss: 1.7101 - val_acc: 0.5950\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.73880\n",
            "Epoch 312/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6871 - acc: 0.8224 - val_loss: 1.5204 - val_acc: 0.6273\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.73880\n",
            "Epoch 313/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6928 - acc: 0.8205 - val_loss: 1.8563 - val_acc: 0.5382\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.73880\n",
            "Epoch 314/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7046 - acc: 0.8141 - val_loss: 1.9516 - val_acc: 0.5938\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.73880\n",
            "Epoch 315/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6939 - acc: 0.8151 - val_loss: 1.7747 - val_acc: 0.5591\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.73880\n",
            "Epoch 316/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7056 - acc: 0.8133 - val_loss: 2.0629 - val_acc: 0.5432\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.73880\n",
            "Epoch 317/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7063 - acc: 0.8180 - val_loss: 3.0490 - val_acc: 0.3608\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.73880\n",
            "Epoch 318/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7025 - acc: 0.8148 - val_loss: 1.9762 - val_acc: 0.5549\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.73880\n",
            "Epoch 319/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7060 - acc: 0.8120 - val_loss: 1.7175 - val_acc: 0.5907\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.73880\n",
            "Epoch 320/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7111 - acc: 0.8182 - val_loss: 1.8790 - val_acc: 0.5669\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.73880\n",
            "Epoch 321/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7085 - acc: 0.8133 - val_loss: 1.5071 - val_acc: 0.6399\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.73880\n",
            "Epoch 322/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7072 - acc: 0.8096 - val_loss: 0.9840 - val_acc: 0.7362\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.73880\n",
            "Epoch 323/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7014 - acc: 0.8187 - val_loss: 1.2126 - val_acc: 0.6766\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.73880\n",
            "Epoch 324/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6966 - acc: 0.8123 - val_loss: 3.8065 - val_acc: 0.3579\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.73880\n",
            "Epoch 325/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7093 - acc: 0.8127 - val_loss: 3.6737 - val_acc: 0.3952\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.73880\n",
            "Epoch 326/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6955 - acc: 0.8192 - val_loss: 1.2738 - val_acc: 0.6701\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.73880\n",
            "Epoch 327/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7026 - acc: 0.8145 - val_loss: 1.4026 - val_acc: 0.6480\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.73880\n",
            "Epoch 328/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7128 - acc: 0.8124 - val_loss: 1.6447 - val_acc: 0.6114\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.73880\n",
            "Epoch 329/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7209 - acc: 0.8150 - val_loss: 1.2163 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.73880\n",
            "Epoch 330/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7010 - acc: 0.8132 - val_loss: 1.2325 - val_acc: 0.6528\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.73880\n",
            "Epoch 331/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6988 - acc: 0.8153 - val_loss: 1.6464 - val_acc: 0.6198\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.73880\n",
            "Epoch 332/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7186 - acc: 0.8115 - val_loss: 1.9435 - val_acc: 0.5805\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.73880\n",
            "Epoch 333/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7075 - acc: 0.8138 - val_loss: 1.5488 - val_acc: 0.6255\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.73880\n",
            "Epoch 334/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7114 - acc: 0.8102 - val_loss: 3.0228 - val_acc: 0.4294\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.73880\n",
            "Epoch 335/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6997 - acc: 0.8147 - val_loss: 1.5602 - val_acc: 0.6447\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.73880\n",
            "Epoch 336/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6866 - acc: 0.8211 - val_loss: 1.5774 - val_acc: 0.5944\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.73880\n",
            "Epoch 337/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7126 - acc: 0.8126 - val_loss: 1.6636 - val_acc: 0.5317\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.73880\n",
            "Epoch 338/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.7059 - acc: 0.8140 - val_loss: 1.4421 - val_acc: 0.6326\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.73880\n",
            "Epoch 339/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6905 - acc: 0.8222 - val_loss: 1.6186 - val_acc: 0.6067\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.73880\n",
            "Epoch 340/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7251 - acc: 0.8100 - val_loss: 1.4089 - val_acc: 0.6576\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.73880\n",
            "Epoch 341/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7007 - acc: 0.8160 - val_loss: 1.2179 - val_acc: 0.6677\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.73880\n",
            "Epoch 342/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7274 - acc: 0.8091 - val_loss: 2.0471 - val_acc: 0.5305\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.73880\n",
            "Epoch 343/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6934 - acc: 0.8242 - val_loss: 1.4840 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.73880\n",
            "Epoch 344/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6849 - acc: 0.8205 - val_loss: 1.1215 - val_acc: 0.7076\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.73880\n",
            "Epoch 345/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6828 - acc: 0.8209 - val_loss: 2.1725 - val_acc: 0.4332\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.73880\n",
            "Epoch 346/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.7078 - acc: 0.8169 - val_loss: 1.5587 - val_acc: 0.6201\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.73880\n",
            "Epoch 347/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7183 - acc: 0.8115 - val_loss: 1.6012 - val_acc: 0.6216\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.73880\n",
            "Epoch 348/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6973 - acc: 0.8204 - val_loss: 1.1989 - val_acc: 0.6920\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.73880\n",
            "Epoch 349/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7014 - acc: 0.8179 - val_loss: 1.2606 - val_acc: 0.6763\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.73880\n",
            "Epoch 350/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7016 - acc: 0.8156 - val_loss: 3.2019 - val_acc: 0.3637\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.73880\n",
            "Epoch 351/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7153 - acc: 0.8068 - val_loss: 1.5169 - val_acc: 0.5881\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.73880\n",
            "Epoch 352/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6905 - acc: 0.8210 - val_loss: 1.2687 - val_acc: 0.6935\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.73880\n",
            "Epoch 353/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6878 - acc: 0.8237 - val_loss: 1.4497 - val_acc: 0.6234\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.73880\n",
            "Epoch 354/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7022 - acc: 0.8180 - val_loss: 1.6566 - val_acc: 0.6232\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.73880\n",
            "Epoch 355/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6756 - acc: 0.8278 - val_loss: 1.0769 - val_acc: 0.7305\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.73880\n",
            "Epoch 356/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6967 - acc: 0.8188 - val_loss: 1.8267 - val_acc: 0.5886\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.73880\n",
            "Epoch 357/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.6990 - acc: 0.8186 - val_loss: 1.1568 - val_acc: 0.6869\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.73880\n",
            "Epoch 358/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6921 - acc: 0.8178 - val_loss: 1.3155 - val_acc: 0.6665\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.73880\n",
            "Epoch 359/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6948 - acc: 0.8180 - val_loss: 1.7717 - val_acc: 0.6033\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.73880\n",
            "Epoch 360/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6987 - acc: 0.8173 - val_loss: 1.2514 - val_acc: 0.6863\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.73880\n",
            "Epoch 361/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6819 - acc: 0.8244 - val_loss: 1.7181 - val_acc: 0.5804\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.73880\n",
            "Epoch 362/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7104 - acc: 0.8129 - val_loss: 2.6052 - val_acc: 0.4680\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.73880\n",
            "Epoch 363/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7054 - acc: 0.8170 - val_loss: 1.7604 - val_acc: 0.6168\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.73880\n",
            "Epoch 364/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6937 - acc: 0.8217 - val_loss: 1.8588 - val_acc: 0.5236\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.73880\n",
            "Epoch 365/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7007 - acc: 0.8190 - val_loss: 3.2173 - val_acc: 0.3867\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.73880\n",
            "Epoch 366/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7023 - acc: 0.8171 - val_loss: 1.3990 - val_acc: 0.6432\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.73880\n",
            "Epoch 367/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7040 - acc: 0.8125 - val_loss: 2.3431 - val_acc: 0.4556\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.73880\n",
            "Epoch 368/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7061 - acc: 0.8114 - val_loss: 1.4885 - val_acc: 0.6105\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.73880\n",
            "Epoch 369/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6889 - acc: 0.8192 - val_loss: 1.8286 - val_acc: 0.5723\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.73880\n",
            "Epoch 370/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6992 - acc: 0.8162 - val_loss: 1.4191 - val_acc: 0.6498\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.73880\n",
            "Epoch 371/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.7210 - acc: 0.8087 - val_loss: 1.3155 - val_acc: 0.6715\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.73880\n",
            "Epoch 372/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6929 - acc: 0.8209 - val_loss: 1.7675 - val_acc: 0.5553\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.73880\n",
            "Epoch 373/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6819 - acc: 0.8223 - val_loss: 1.2718 - val_acc: 0.6675\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.73880\n",
            "Epoch 374/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7301 - acc: 0.8053 - val_loss: 2.5469 - val_acc: 0.4508\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.73880\n",
            "Epoch 375/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6978 - acc: 0.8169 - val_loss: 3.3117 - val_acc: 0.3897\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.73880\n",
            "Epoch 376/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.7051 - acc: 0.8125 - val_loss: 2.8434 - val_acc: 0.3891\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.73880\n",
            "Epoch 377/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7125 - acc: 0.8139 - val_loss: 1.3147 - val_acc: 0.6577\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.73880\n",
            "Epoch 378/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7066 - acc: 0.8153 - val_loss: 1.6847 - val_acc: 0.6331\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.73880\n",
            "Epoch 379/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6951 - acc: 0.8212 - val_loss: 1.3414 - val_acc: 0.6328\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.73880\n",
            "Epoch 380/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.7084 - acc: 0.8117 - val_loss: 2.2381 - val_acc: 0.4777\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.73880\n",
            "Epoch 381/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6990 - acc: 0.8131 - val_loss: 1.8596 - val_acc: 0.5645\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.73880\n",
            "Epoch 382/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6921 - acc: 0.8174 - val_loss: 2.0248 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.73880\n",
            "Epoch 383/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.7173 - acc: 0.8082 - val_loss: 3.2865 - val_acc: 0.4142\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.73880\n",
            "Epoch 384/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7015 - acc: 0.8141 - val_loss: 1.4283 - val_acc: 0.6236\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.73880\n",
            "Epoch 385/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6859 - acc: 0.8227 - val_loss: 1.1117 - val_acc: 0.7223\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.73880\n",
            "Epoch 386/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6932 - acc: 0.8185 - val_loss: 1.6871 - val_acc: 0.5798\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.73880\n",
            "Epoch 387/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.6931 - acc: 0.8151 - val_loss: 1.0829 - val_acc: 0.6997\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.73880\n",
            "Epoch 388/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6972 - acc: 0.8176 - val_loss: 1.6330 - val_acc: 0.6159\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.73880\n",
            "Epoch 389/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6745 - acc: 0.8247 - val_loss: 2.3248 - val_acc: 0.4607\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.73880\n",
            "Epoch 390/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6899 - acc: 0.8201 - val_loss: 1.8759 - val_acc: 0.5571\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.73880\n",
            "Epoch 391/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7148 - acc: 0.8102 - val_loss: 2.0530 - val_acc: 0.5197\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.73880\n",
            "Epoch 392/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6864 - acc: 0.8228 - val_loss: 1.3027 - val_acc: 0.6531\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.73880\n",
            "Epoch 393/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6920 - acc: 0.8218 - val_loss: 1.1430 - val_acc: 0.7035\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.73880\n",
            "Epoch 394/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.6898 - acc: 0.8231 - val_loss: 1.2602 - val_acc: 0.6885\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.73880\n",
            "Epoch 395/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6922 - acc: 0.8231 - val_loss: 1.1646 - val_acc: 0.7069\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.73880\n",
            "Epoch 396/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.6944 - acc: 0.8182 - val_loss: 1.4222 - val_acc: 0.6329\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.73880\n",
            "Epoch 397/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.7132 - acc: 0.8084 - val_loss: 1.5136 - val_acc: 0.6298\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.73880\n",
            "Epoch 398/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7081 - acc: 0.8164 - val_loss: 1.2451 - val_acc: 0.6871\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.73880\n",
            "Epoch 399/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6869 - acc: 0.8204 - val_loss: 1.5728 - val_acc: 0.5622\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.73880\n",
            "Epoch 400/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7041 - acc: 0.8157 - val_loss: 1.4763 - val_acc: 0.6549\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.73880\n",
            "Epoch 401/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7015 - acc: 0.8138 - val_loss: 2.0108 - val_acc: 0.5069\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.73880\n",
            "Epoch 402/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5826 - acc: 0.8589 - val_loss: 0.7707 - val_acc: 0.7949\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.73880 to 0.79490, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5376 - acc: 0.8725 - val_loss: 0.6055 - val_acc: 0.8450\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.79490 to 0.84500, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5218 - acc: 0.8790 - val_loss: 0.5935 - val_acc: 0.8553\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.84500 to 0.85530, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5131 - acc: 0.8849 - val_loss: 0.5840 - val_acc: 0.8585\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.85530 to 0.85850, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5013 - acc: 0.8901 - val_loss: 0.5676 - val_acc: 0.8639\n",
            "\n",
            "Epoch 00406: val_acc improved from 0.85850 to 0.86390, saving model to /content/saved_models/cifar10_ResNet32v1_model.406.h5\n",
            "Epoch 407/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4870 - acc: 0.8915 - val_loss: 0.5684 - val_acc: 0.8665\n",
            "\n",
            "Epoch 00407: val_acc improved from 0.86390 to 0.86650, saving model to /content/saved_models/cifar10_ResNet32v1_model.407.h5\n",
            "Epoch 408/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4752 - acc: 0.8978 - val_loss: 0.5325 - val_acc: 0.8776\n",
            "\n",
            "Epoch 00408: val_acc improved from 0.86650 to 0.87760, saving model to /content/saved_models/cifar10_ResNet32v1_model.408.h5\n",
            "Epoch 409/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4619 - acc: 0.8999 - val_loss: 0.5337 - val_acc: 0.8806\n",
            "\n",
            "Epoch 00409: val_acc improved from 0.87760 to 0.88060, saving model to /content/saved_models/cifar10_ResNet32v1_model.409.h5\n",
            "Epoch 410/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.4654 - acc: 0.8990 - val_loss: 0.5278 - val_acc: 0.8773\n",
            "\n",
            "Epoch 00410: val_acc did not improve from 0.88060\n",
            "Epoch 411/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4556 - acc: 0.9020 - val_loss: 0.5635 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.88060\n",
            "Epoch 412/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.4636 - acc: 0.9006 - val_loss: 0.5390 - val_acc: 0.8760\n",
            "\n",
            "Epoch 00412: val_acc did not improve from 0.88060\n",
            "Epoch 413/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4597 - acc: 0.9057 - val_loss: 0.6263 - val_acc: 0.8491\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.88060\n",
            "Epoch 414/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4490 - acc: 0.9043 - val_loss: 0.5343 - val_acc: 0.8779\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.88060\n",
            "Epoch 415/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.4370 - acc: 0.9060 - val_loss: 0.5573 - val_acc: 0.8721\n",
            "\n",
            "Epoch 00415: val_acc did not improve from 0.88060\n",
            "Epoch 416/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4304 - acc: 0.9096 - val_loss: 0.5127 - val_acc: 0.8866\n",
            "\n",
            "Epoch 00416: val_acc improved from 0.88060 to 0.88660, saving model to /content/saved_models/cifar10_ResNet32v1_model.416.h5\n",
            "Epoch 417/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4516 - acc: 0.9042 - val_loss: 0.5285 - val_acc: 0.8784\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.88660\n",
            "Epoch 418/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4468 - acc: 0.9060 - val_loss: 0.5645 - val_acc: 0.8679\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.88660\n",
            "Epoch 419/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.4492 - acc: 0.9035 - val_loss: 0.5123 - val_acc: 0.8827\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.88660\n",
            "Epoch 420/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.4410 - acc: 0.9072 - val_loss: 0.5327 - val_acc: 0.8751\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.88660\n",
            "Epoch 421/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4251 - acc: 0.9132 - val_loss: 0.5509 - val_acc: 0.8708\n",
            "\n",
            "Epoch 00421: val_acc did not improve from 0.88660\n",
            "Epoch 422/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4333 - acc: 0.9076 - val_loss: 0.5243 - val_acc: 0.8810\n",
            "\n",
            "Epoch 00422: val_acc did not improve from 0.88660\n",
            "Epoch 423/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4334 - acc: 0.9090 - val_loss: 0.5391 - val_acc: 0.8776\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.88660\n",
            "Epoch 424/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.4201 - acc: 0.9131 - val_loss: 0.5271 - val_acc: 0.8803\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.88660\n",
            "Epoch 425/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4261 - acc: 0.9130 - val_loss: 0.5623 - val_acc: 0.8685\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.88660\n",
            "Epoch 426/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4288 - acc: 0.9076 - val_loss: 0.5506 - val_acc: 0.8763\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.88660\n",
            "Epoch 427/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.4119 - acc: 0.9161 - val_loss: 0.5435 - val_acc: 0.8727\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.88660\n",
            "Epoch 428/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4207 - acc: 0.9128 - val_loss: 0.5497 - val_acc: 0.8712\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.88660\n",
            "Epoch 429/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4108 - acc: 0.9198 - val_loss: 0.5260 - val_acc: 0.8757\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.88660\n",
            "Epoch 430/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4142 - acc: 0.9142 - val_loss: 0.5256 - val_acc: 0.8831\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.88660\n",
            "Epoch 431/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4217 - acc: 0.9138 - val_loss: 0.5084 - val_acc: 0.8864\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.88660\n",
            "Epoch 432/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4004 - acc: 0.9202 - val_loss: 0.5063 - val_acc: 0.8876\n",
            "\n",
            "Epoch 00432: val_acc improved from 0.88660 to 0.88760, saving model to /content/saved_models/cifar10_ResNet32v1_model.432.h5\n",
            "Epoch 433/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4025 - acc: 0.9178 - val_loss: 0.5474 - val_acc: 0.8754\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.88760\n",
            "Epoch 434/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.4041 - acc: 0.9191 - val_loss: 0.4912 - val_acc: 0.8932\n",
            "\n",
            "Epoch 00434: val_acc improved from 0.88760 to 0.89320, saving model to /content/saved_models/cifar10_ResNet32v1_model.434.h5\n",
            "Epoch 435/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4093 - acc: 0.9184 - val_loss: 0.5203 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.89320\n",
            "Epoch 436/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.4059 - acc: 0.9183 - val_loss: 0.5291 - val_acc: 0.8802\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.89320\n",
            "Epoch 437/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4023 - acc: 0.9163 - val_loss: 0.5068 - val_acc: 0.8851\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.89320\n",
            "Epoch 438/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3913 - acc: 0.9213 - val_loss: 0.5451 - val_acc: 0.8761\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.89320\n",
            "Epoch 439/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3960 - acc: 0.9209 - val_loss: 0.5424 - val_acc: 0.8763\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.89320\n",
            "Epoch 440/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3958 - acc: 0.9195 - val_loss: 0.5132 - val_acc: 0.8861\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.89320\n",
            "Epoch 441/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3917 - acc: 0.9229 - val_loss: 0.5190 - val_acc: 0.8838\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.89320\n",
            "Epoch 442/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3930 - acc: 0.9233 - val_loss: 0.4996 - val_acc: 0.8904\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.89320\n",
            "Epoch 443/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3869 - acc: 0.9233 - val_loss: 0.5474 - val_acc: 0.8751\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.89320\n",
            "Epoch 444/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3903 - acc: 0.9236 - val_loss: 0.5309 - val_acc: 0.8788\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.89320\n",
            "Epoch 445/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3858 - acc: 0.9278 - val_loss: 0.5086 - val_acc: 0.8905\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.89320\n",
            "Epoch 446/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3890 - acc: 0.9262 - val_loss: 0.5312 - val_acc: 0.8801\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.89320\n",
            "Epoch 447/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3980 - acc: 0.9202 - val_loss: 0.5380 - val_acc: 0.8773\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.89320\n",
            "Epoch 448/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3797 - acc: 0.9285 - val_loss: 0.5209 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.89320\n",
            "Epoch 449/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3926 - acc: 0.9223 - val_loss: 0.5117 - val_acc: 0.8858\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.89320\n",
            "Epoch 450/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3924 - acc: 0.9243 - val_loss: 0.5258 - val_acc: 0.8808\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.89320\n",
            "Epoch 451/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3846 - acc: 0.9251 - val_loss: 0.5263 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.89320\n",
            "Epoch 452/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3812 - acc: 0.9266 - val_loss: 0.5084 - val_acc: 0.8876\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.89320\n",
            "Epoch 453/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3923 - acc: 0.9219 - val_loss: 0.5266 - val_acc: 0.8805\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.89320\n",
            "Epoch 454/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3840 - acc: 0.9239 - val_loss: 0.5165 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.89320\n",
            "Epoch 455/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3772 - acc: 0.9273 - val_loss: 0.5405 - val_acc: 0.8775\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.89320\n",
            "Epoch 456/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3782 - acc: 0.9282 - val_loss: 0.4935 - val_acc: 0.8905\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.89320\n",
            "Epoch 457/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3848 - acc: 0.9253 - val_loss: 0.5007 - val_acc: 0.8893\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.89320\n",
            "Epoch 458/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3644 - acc: 0.9317 - val_loss: 0.5031 - val_acc: 0.8895\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.89320\n",
            "Epoch 459/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3652 - acc: 0.9325 - val_loss: 0.4878 - val_acc: 0.8937\n",
            "\n",
            "Epoch 00459: val_acc improved from 0.89320 to 0.89370, saving model to /content/saved_models/cifar10_ResNet32v1_model.459.h5\n",
            "Epoch 460/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3648 - acc: 0.9327 - val_loss: 0.5349 - val_acc: 0.8805\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.89370\n",
            "Epoch 461/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3830 - acc: 0.9227 - val_loss: 0.5214 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.89370\n",
            "Epoch 462/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.3745 - acc: 0.9283 - val_loss: 0.5112 - val_acc: 0.8848\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.89370\n",
            "Epoch 463/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3674 - acc: 0.9330 - val_loss: 0.5029 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.89370\n",
            "Epoch 464/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3666 - acc: 0.9288 - val_loss: 0.5128 - val_acc: 0.8851\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.89370\n",
            "Epoch 465/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3724 - acc: 0.9303 - val_loss: 0.5178 - val_acc: 0.8868\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.89370\n",
            "Epoch 466/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3708 - acc: 0.9304 - val_loss: 0.4982 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.89370\n",
            "Epoch 467/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3665 - acc: 0.9302 - val_loss: 0.5059 - val_acc: 0.8915\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.89370\n",
            "Epoch 468/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3725 - acc: 0.9312 - val_loss: 0.5003 - val_acc: 0.8913\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.89370\n",
            "Epoch 469/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3542 - acc: 0.9356 - val_loss: 0.5106 - val_acc: 0.8882\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.89370\n",
            "Epoch 470/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3539 - acc: 0.9364 - val_loss: 0.5251 - val_acc: 0.8843\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.89370\n",
            "Epoch 471/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3634 - acc: 0.9317 - val_loss: 0.5447 - val_acc: 0.8758\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.89370\n",
            "Epoch 472/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3666 - acc: 0.9310 - val_loss: 0.5011 - val_acc: 0.8915\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.89370\n",
            "Epoch 473/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3677 - acc: 0.9288 - val_loss: 0.5009 - val_acc: 0.8901\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.89370\n",
            "Epoch 474/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3556 - acc: 0.9345 - val_loss: 0.5886 - val_acc: 0.8697\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.89370\n",
            "Epoch 475/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3666 - acc: 0.9310 - val_loss: 0.5550 - val_acc: 0.8775\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.89370\n",
            "Epoch 476/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3556 - acc: 0.9365 - val_loss: 0.4988 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.89370\n",
            "Epoch 477/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3543 - acc: 0.9356 - val_loss: 0.5107 - val_acc: 0.8855\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.89370\n",
            "Epoch 478/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3525 - acc: 0.9369 - val_loss: 0.5037 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.89370\n",
            "Epoch 479/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3496 - acc: 0.9354 - val_loss: 0.4907 - val_acc: 0.8954\n",
            "\n",
            "Epoch 00479: val_acc improved from 0.89370 to 0.89540, saving model to /content/saved_models/cifar10_ResNet32v1_model.479.h5\n",
            "Epoch 480/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3536 - acc: 0.9392 - val_loss: 0.5295 - val_acc: 0.8869\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.89540\n",
            "Epoch 481/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3472 - acc: 0.9372 - val_loss: 0.5240 - val_acc: 0.8845\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.89540\n",
            "Epoch 482/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3537 - acc: 0.9347 - val_loss: 0.5091 - val_acc: 0.8896\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.89540\n",
            "Epoch 483/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3546 - acc: 0.9335 - val_loss: 0.4999 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.89540\n",
            "Epoch 484/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3516 - acc: 0.9362 - val_loss: 0.5080 - val_acc: 0.8885\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.89540\n",
            "Epoch 485/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3517 - acc: 0.9355 - val_loss: 0.5293 - val_acc: 0.8837\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.89540\n",
            "Epoch 486/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3476 - acc: 0.9374 - val_loss: 0.5260 - val_acc: 0.8840\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.89540\n",
            "Epoch 487/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3502 - acc: 0.9368 - val_loss: 0.4842 - val_acc: 0.8962\n",
            "\n",
            "Epoch 00487: val_acc improved from 0.89540 to 0.89620, saving model to /content/saved_models/cifar10_ResNet32v1_model.487.h5\n",
            "Epoch 488/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3495 - acc: 0.9380 - val_loss: 0.5125 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.89620\n",
            "Epoch 489/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3500 - acc: 0.9353 - val_loss: 0.4993 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.89620\n",
            "Epoch 490/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3488 - acc: 0.9381 - val_loss: 0.5043 - val_acc: 0.8919\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.89620\n",
            "Epoch 491/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3467 - acc: 0.9372 - val_loss: 0.5135 - val_acc: 0.8862\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.89620\n",
            "Epoch 492/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3435 - acc: 0.9378 - val_loss: 0.4826 - val_acc: 0.8954\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.89620\n",
            "Epoch 493/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3468 - acc: 0.9349 - val_loss: 0.4826 - val_acc: 0.8939\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.89620\n",
            "Epoch 494/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3366 - acc: 0.9436 - val_loss: 0.4934 - val_acc: 0.8927\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.89620\n",
            "Epoch 495/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3344 - acc: 0.9421 - val_loss: 0.5808 - val_acc: 0.8682\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.89620\n",
            "Epoch 496/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3481 - acc: 0.9380 - val_loss: 0.5162 - val_acc: 0.8887\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.89620\n",
            "Epoch 497/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3451 - acc: 0.9370 - val_loss: 0.5189 - val_acc: 0.8846\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.89620\n",
            "Epoch 498/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3430 - acc: 0.9393 - val_loss: 0.4858 - val_acc: 0.8960\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.89620\n",
            "Epoch 499/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3368 - acc: 0.9409 - val_loss: 0.5336 - val_acc: 0.8805\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.89620\n",
            "Epoch 500/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3343 - acc: 0.9438 - val_loss: 0.4849 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00500: val_acc improved from 0.89620 to 0.89760, saving model to /content/saved_models/cifar10_ResNet32v1_model.500.h5\n",
            "Epoch 501/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3354 - acc: 0.9419 - val_loss: 0.5139 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.89760\n",
            "Epoch 502/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3354 - acc: 0.9414 - val_loss: 0.5033 - val_acc: 0.8930\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.89760\n",
            "Epoch 503/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3398 - acc: 0.9412 - val_loss: 0.5182 - val_acc: 0.8902\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.89760\n",
            "Epoch 504/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3355 - acc: 0.9413 - val_loss: 0.5457 - val_acc: 0.8804\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.89760\n",
            "Epoch 505/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3376 - acc: 0.9402 - val_loss: 0.5570 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.89760\n",
            "Epoch 506/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3358 - acc: 0.9411 - val_loss: 0.5295 - val_acc: 0.8863\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.89760\n",
            "Epoch 507/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3431 - acc: 0.9406 - val_loss: 0.5054 - val_acc: 0.8910\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.89760\n",
            "Epoch 508/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.3357 - acc: 0.9420 - val_loss: 0.5157 - val_acc: 0.8868\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.89760\n",
            "Epoch 509/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3340 - acc: 0.9423 - val_loss: 0.5223 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.89760\n",
            "Epoch 510/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3321 - acc: 0.9410 - val_loss: 0.4987 - val_acc: 0.8979\n",
            "\n",
            "Epoch 00510: val_acc improved from 0.89760 to 0.89790, saving model to /content/saved_models/cifar10_ResNet32v1_model.510.h5\n",
            "Epoch 511/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.3364 - acc: 0.9423 - val_loss: 0.4868 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00511: val_acc improved from 0.89790 to 0.89800, saving model to /content/saved_models/cifar10_ResNet32v1_model.511.h5\n",
            "Epoch 512/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3245 - acc: 0.9450 - val_loss: 0.5660 - val_acc: 0.8792\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.89800\n",
            "Epoch 513/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.3303 - acc: 0.9427 - val_loss: 0.4984 - val_acc: 0.8933\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.89800\n",
            "Epoch 514/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3357 - acc: 0.9403 - val_loss: 0.4983 - val_acc: 0.8953\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.89800\n",
            "Epoch 515/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3327 - acc: 0.9403 - val_loss: 0.5127 - val_acc: 0.8881\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.89800\n",
            "Epoch 516/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3283 - acc: 0.9462 - val_loss: 0.4836 - val_acc: 0.8962\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.89800\n",
            "Epoch 517/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3328 - acc: 0.9428 - val_loss: 0.5228 - val_acc: 0.8860\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.89800\n",
            "Epoch 518/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3304 - acc: 0.9444 - val_loss: 0.5177 - val_acc: 0.8896\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.89800\n",
            "Epoch 519/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3263 - acc: 0.9450 - val_loss: 0.5243 - val_acc: 0.8863\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.89800\n",
            "Epoch 520/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3305 - acc: 0.9441 - val_loss: 0.4900 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.89800\n",
            "Epoch 521/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3318 - acc: 0.9392 - val_loss: 0.4861 - val_acc: 0.8944\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.89800\n",
            "Epoch 522/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3259 - acc: 0.9444 - val_loss: 0.5167 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.89800\n",
            "Epoch 523/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3272 - acc: 0.9447 - val_loss: 0.4804 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.89800\n",
            "Epoch 524/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3187 - acc: 0.9493 - val_loss: 0.4922 - val_acc: 0.8948\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.89800\n",
            "Epoch 525/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.3228 - acc: 0.9452 - val_loss: 0.5349 - val_acc: 0.8846\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.89800\n",
            "Epoch 526/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3203 - acc: 0.9465 - val_loss: 0.5468 - val_acc: 0.8833\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.89800\n",
            "Epoch 527/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3263 - acc: 0.9451 - val_loss: 0.5101 - val_acc: 0.8898\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.89800\n",
            "Epoch 528/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3216 - acc: 0.9482 - val_loss: 0.5001 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.89800\n",
            "Epoch 529/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3213 - acc: 0.9463 - val_loss: 0.5321 - val_acc: 0.8841\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.89800\n",
            "Epoch 530/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3210 - acc: 0.9455 - val_loss: 0.5400 - val_acc: 0.8842\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.89800\n",
            "Epoch 531/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3194 - acc: 0.9463 - val_loss: 0.5140 - val_acc: 0.8884\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.89800\n",
            "Epoch 532/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3243 - acc: 0.9468 - val_loss: 0.5154 - val_acc: 0.8937\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.89800\n",
            "Epoch 533/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3354 - acc: 0.9403 - val_loss: 0.4895 - val_acc: 0.8947\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.89800\n",
            "Epoch 534/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3304 - acc: 0.9428 - val_loss: 0.4911 - val_acc: 0.8947\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.89800\n",
            "Epoch 535/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3179 - acc: 0.9470 - val_loss: 0.4997 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.89800\n",
            "Epoch 536/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3246 - acc: 0.9432 - val_loss: 0.5171 - val_acc: 0.8903\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.89800\n",
            "Epoch 537/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3193 - acc: 0.9465 - val_loss: 0.5413 - val_acc: 0.8851\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.89800\n",
            "Epoch 538/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3173 - acc: 0.9471 - val_loss: 0.4865 - val_acc: 0.8979\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.89800\n",
            "Epoch 539/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3231 - acc: 0.9449 - val_loss: 0.5093 - val_acc: 0.8904\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.89800\n",
            "Epoch 540/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3264 - acc: 0.9431 - val_loss: 0.5052 - val_acc: 0.8936\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.89800\n",
            "Epoch 541/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.3166 - acc: 0.9462 - val_loss: 0.5089 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.89800\n",
            "Epoch 542/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.3228 - acc: 0.9480 - val_loss: 0.4765 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00542: val_acc improved from 0.89800 to 0.89830, saving model to /content/saved_models/cifar10_ResNet32v1_model.542.h5\n",
            "Epoch 543/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.3220 - acc: 0.9453 - val_loss: 0.5579 - val_acc: 0.8791\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.89830\n",
            "Epoch 544/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3111 - acc: 0.9479 - val_loss: 0.5537 - val_acc: 0.8777\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.89830\n",
            "Epoch 545/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3137 - acc: 0.9486 - val_loss: 0.4871 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00545: val_acc improved from 0.89830 to 0.89910, saving model to /content/saved_models/cifar10_ResNet32v1_model.545.h5\n",
            "Epoch 546/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3153 - acc: 0.9484 - val_loss: 0.5324 - val_acc: 0.8868\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.89910\n",
            "Epoch 547/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3152 - acc: 0.9472 - val_loss: 0.4948 - val_acc: 0.8939\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.89910\n",
            "Epoch 548/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3145 - acc: 0.9490 - val_loss: 0.5459 - val_acc: 0.8835\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.89910\n",
            "Epoch 549/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3068 - acc: 0.9495 - val_loss: 0.5361 - val_acc: 0.8823\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.89910\n",
            "Epoch 550/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3152 - acc: 0.9481 - val_loss: 0.4973 - val_acc: 0.8923\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.89910\n",
            "Epoch 551/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3113 - acc: 0.9503 - val_loss: 0.5540 - val_acc: 0.8818\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.89910\n",
            "Epoch 552/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3126 - acc: 0.9496 - val_loss: 0.4970 - val_acc: 0.8940\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.89910\n",
            "Epoch 553/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3136 - acc: 0.9496 - val_loss: 0.5039 - val_acc: 0.8942\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.89910\n",
            "Epoch 554/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3160 - acc: 0.9473 - val_loss: 0.5105 - val_acc: 0.8910\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.89910\n",
            "Epoch 555/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3121 - acc: 0.9474 - val_loss: 0.5338 - val_acc: 0.8848\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.89910\n",
            "Epoch 556/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.3077 - acc: 0.9500 - val_loss: 0.5216 - val_acc: 0.8864\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.89910\n",
            "Epoch 557/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3073 - acc: 0.9514 - val_loss: 0.5594 - val_acc: 0.8819\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.89910\n",
            "Epoch 558/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3033 - acc: 0.9520 - val_loss: 0.5345 - val_acc: 0.8874\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.89910\n",
            "Epoch 559/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3128 - acc: 0.9484 - val_loss: 0.5132 - val_acc: 0.8921\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.89910\n",
            "Epoch 560/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3095 - acc: 0.9513 - val_loss: 0.5411 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.89910\n",
            "Epoch 561/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3196 - acc: 0.9472 - val_loss: 0.5244 - val_acc: 0.8867\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.89910\n",
            "Epoch 562/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3130 - acc: 0.9484 - val_loss: 0.5184 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.89910\n",
            "Epoch 563/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3117 - acc: 0.9487 - val_loss: 0.5726 - val_acc: 0.8781\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.89910\n",
            "Epoch 564/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3133 - acc: 0.9463 - val_loss: 0.5103 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.89910\n",
            "Epoch 565/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3059 - acc: 0.9543 - val_loss: 0.4961 - val_acc: 0.8946\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.89910\n",
            "Epoch 566/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3046 - acc: 0.9499 - val_loss: 0.5228 - val_acc: 0.8896\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.89910\n",
            "Epoch 567/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.3169 - acc: 0.9482 - val_loss: 0.4954 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.89910\n",
            "Epoch 568/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3059 - acc: 0.9511 - val_loss: 0.4889 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.89910\n",
            "Epoch 569/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3023 - acc: 0.9508 - val_loss: 0.5333 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.89910\n",
            "Epoch 570/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3110 - acc: 0.9514 - val_loss: 0.4930 - val_acc: 0.8962\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.89910\n",
            "Epoch 571/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2983 - acc: 0.9535 - val_loss: 0.6136 - val_acc: 0.8686\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.89910\n",
            "Epoch 572/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3193 - acc: 0.9464 - val_loss: 0.5199 - val_acc: 0.8904\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.89910\n",
            "Epoch 573/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.3024 - acc: 0.9509 - val_loss: 0.5031 - val_acc: 0.8970\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.89910\n",
            "Epoch 574/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3036 - acc: 0.9506 - val_loss: 0.5255 - val_acc: 0.8884\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.89910\n",
            "Epoch 575/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.3017 - acc: 0.9551 - val_loss: 0.5042 - val_acc: 0.8957\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.89910\n",
            "Epoch 576/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3003 - acc: 0.9543 - val_loss: 0.5369 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.89910\n",
            "Epoch 577/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3064 - acc: 0.9526 - val_loss: 0.5741 - val_acc: 0.8754\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.89910\n",
            "Epoch 578/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3012 - acc: 0.9514 - val_loss: 0.5537 - val_acc: 0.8820\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.89910\n",
            "Epoch 579/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3017 - acc: 0.9525 - val_loss: 0.5329 - val_acc: 0.8884\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.89910\n",
            "Epoch 580/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3041 - acc: 0.9497 - val_loss: 0.5018 - val_acc: 0.8952\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.89910\n",
            "Epoch 581/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3063 - acc: 0.9534 - val_loss: 0.5288 - val_acc: 0.8898\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.89910\n",
            "Epoch 582/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3049 - acc: 0.9510 - val_loss: 0.5234 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.89910\n",
            "Epoch 583/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3034 - acc: 0.9537 - val_loss: 0.5668 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.89910\n",
            "Epoch 584/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3037 - acc: 0.9516 - val_loss: 0.5049 - val_acc: 0.8957\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.89910\n",
            "Epoch 585/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3074 - acc: 0.9498 - val_loss: 0.5988 - val_acc: 0.8736\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.89910\n",
            "Epoch 586/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.2992 - acc: 0.9517 - val_loss: 0.4934 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.89910\n",
            "Epoch 587/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3041 - acc: 0.9526 - val_loss: 0.4988 - val_acc: 0.8967\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.89910\n",
            "Epoch 588/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3059 - acc: 0.9508 - val_loss: 0.5019 - val_acc: 0.8934\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.89910\n",
            "Epoch 589/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.3048 - acc: 0.9504 - val_loss: 0.6007 - val_acc: 0.8718\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.89910\n",
            "Epoch 590/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2982 - acc: 0.9556 - val_loss: 0.4940 - val_acc: 0.8962\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.89910\n",
            "Epoch 591/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2968 - acc: 0.9560 - val_loss: 0.5244 - val_acc: 0.8920\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.89910\n",
            "Epoch 592/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.3105 - acc: 0.9525 - val_loss: 0.5092 - val_acc: 0.8934\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.89910\n",
            "Epoch 593/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3042 - acc: 0.9513 - val_loss: 0.5615 - val_acc: 0.8807\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.89910\n",
            "Epoch 594/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3048 - acc: 0.9518 - val_loss: 0.5243 - val_acc: 0.8885\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.89910\n",
            "Epoch 595/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.3166 - acc: 0.9475 - val_loss: 0.5363 - val_acc: 0.8897\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.89910\n",
            "Epoch 596/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2967 - acc: 0.9544 - val_loss: 0.5031 - val_acc: 0.8944\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.89910\n",
            "Epoch 597/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2999 - acc: 0.9535 - val_loss: 0.5205 - val_acc: 0.8915\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.89910\n",
            "Epoch 598/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2960 - acc: 0.9533 - val_loss: 0.5243 - val_acc: 0.8930\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.89910\n",
            "Epoch 599/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3052 - acc: 0.9524 - val_loss: 0.5003 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.89910\n",
            "Epoch 600/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3027 - acc: 0.9496 - val_loss: 0.4851 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.89910\n",
            "Epoch 601/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.3018 - acc: 0.9554 - val_loss: 0.5041 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.89910\n",
            "Epoch 602/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3016 - acc: 0.9515 - val_loss: 0.4713 - val_acc: 0.9011\n",
            "\n",
            "Epoch 00602: val_acc improved from 0.89910 to 0.90110, saving model to /content/saved_models/cifar10_ResNet32v1_model.602.h5\n",
            "Epoch 603/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2893 - acc: 0.9575 - val_loss: 0.4677 - val_acc: 0.9006\n",
            "\n",
            "Epoch 00603: val_acc did not improve from 0.90110\n",
            "Epoch 604/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.2898 - acc: 0.9561 - val_loss: 0.4664 - val_acc: 0.9004\n",
            "\n",
            "Epoch 00604: val_acc did not improve from 0.90110\n",
            "Epoch 605/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2908 - acc: 0.9588 - val_loss: 0.4647 - val_acc: 0.9007\n",
            "\n",
            "Epoch 00605: val_acc did not improve from 0.90110\n",
            "Epoch 606/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2950 - acc: 0.9549 - val_loss: 0.4634 - val_acc: 0.9010\n",
            "\n",
            "Epoch 00606: val_acc did not improve from 0.90110\n",
            "Epoch 607/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.2896 - acc: 0.9611 - val_loss: 0.4626 - val_acc: 0.9009\n",
            "\n",
            "Epoch 00607: val_acc did not improve from 0.90110\n",
            "Epoch 608/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2850 - acc: 0.9607 - val_loss: 0.4609 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00608: val_acc improved from 0.90110 to 0.90130, saving model to /content/saved_models/cifar10_ResNet32v1_model.608.h5\n",
            "Epoch 609/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2936 - acc: 0.9591 - val_loss: 0.4602 - val_acc: 0.9017\n",
            "\n",
            "Epoch 00609: val_acc improved from 0.90130 to 0.90170, saving model to /content/saved_models/cifar10_ResNet32v1_model.609.h5\n",
            "Epoch 610/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.2883 - acc: 0.9574 - val_loss: 0.4601 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00610: val_acc improved from 0.90170 to 0.90190, saving model to /content/saved_models/cifar10_ResNet32v1_model.610.h5\n",
            "Epoch 611/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2917 - acc: 0.9578 - val_loss: 0.4593 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.90190\n",
            "Epoch 612/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2848 - acc: 0.9605 - val_loss: 0.4593 - val_acc: 0.9029\n",
            "\n",
            "Epoch 00612: val_acc improved from 0.90190 to 0.90290, saving model to /content/saved_models/cifar10_ResNet32v1_model.612.h5\n",
            "Epoch 613/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2859 - acc: 0.9617 - val_loss: 0.4581 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00613: val_acc did not improve from 0.90290\n",
            "Epoch 614/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2881 - acc: 0.9609 - val_loss: 0.4575 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.90290\n",
            "Epoch 615/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2911 - acc: 0.9578 - val_loss: 0.4575 - val_acc: 0.9033\n",
            "\n",
            "Epoch 00615: val_acc improved from 0.90290 to 0.90330, saving model to /content/saved_models/cifar10_ResNet32v1_model.615.h5\n",
            "Epoch 616/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2812 - acc: 0.9612 - val_loss: 0.4560 - val_acc: 0.9035\n",
            "\n",
            "Epoch 00616: val_acc improved from 0.90330 to 0.90350, saving model to /content/saved_models/cifar10_ResNet32v1_model.616.h5\n",
            "Epoch 617/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2863 - acc: 0.9611 - val_loss: 0.4555 - val_acc: 0.9039\n",
            "\n",
            "Epoch 00617: val_acc improved from 0.90350 to 0.90390, saving model to /content/saved_models/cifar10_ResNet32v1_model.617.h5\n",
            "Epoch 618/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2859 - acc: 0.9597 - val_loss: 0.4551 - val_acc: 0.9038\n",
            "\n",
            "Epoch 00618: val_acc did not improve from 0.90390\n",
            "Epoch 619/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.2797 - acc: 0.9640 - val_loss: 0.4555 - val_acc: 0.9033\n",
            "\n",
            "Epoch 00619: val_acc did not improve from 0.90390\n",
            "Epoch 620/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2881 - acc: 0.9604 - val_loss: 0.4544 - val_acc: 0.9037\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.90390\n",
            "Epoch 621/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2852 - acc: 0.9604 - val_loss: 0.4544 - val_acc: 0.9040\n",
            "\n",
            "Epoch 00621: val_acc improved from 0.90390 to 0.90400, saving model to /content/saved_models/cifar10_ResNet32v1_model.621.h5\n",
            "Epoch 622/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.2901 - acc: 0.9575 - val_loss: 0.4537 - val_acc: 0.9039\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.90400\n",
            "Epoch 623/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2825 - acc: 0.9611 - val_loss: 0.4545 - val_acc: 0.9039\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.90400\n",
            "Epoch 624/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2800 - acc: 0.9622 - val_loss: 0.4536 - val_acc: 0.9042\n",
            "\n",
            "Epoch 00624: val_acc improved from 0.90400 to 0.90420, saving model to /content/saved_models/cifar10_ResNet32v1_model.624.h5\n",
            "Epoch 625/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.2821 - acc: 0.9618 - val_loss: 0.4533 - val_acc: 0.9041\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.90420\n",
            "Epoch 626/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2876 - acc: 0.9574 - val_loss: 0.4531 - val_acc: 0.9044\n",
            "\n",
            "Epoch 00626: val_acc improved from 0.90420 to 0.90440, saving model to /content/saved_models/cifar10_ResNet32v1_model.626.h5\n",
            "Epoch 627/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2783 - acc: 0.9618 - val_loss: 0.4523 - val_acc: 0.9049\n",
            "\n",
            "Epoch 00627: val_acc improved from 0.90440 to 0.90490, saving model to /content/saved_models/cifar10_ResNet32v1_model.627.h5\n",
            "Epoch 628/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.2830 - acc: 0.9618 - val_loss: 0.4506 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00628: val_acc improved from 0.90490 to 0.90670, saving model to /content/saved_models/cifar10_ResNet32v1_model.628.h5\n",
            "Epoch 629/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2808 - acc: 0.9620 - val_loss: 0.4514 - val_acc: 0.9054\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.90670\n",
            "Epoch 630/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2758 - acc: 0.9638 - val_loss: 0.4521 - val_acc: 0.9048\n",
            "\n",
            "Epoch 00630: val_acc did not improve from 0.90670\n",
            "Epoch 631/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.2879 - acc: 0.9585 - val_loss: 0.4509 - val_acc: 0.9063\n",
            "\n",
            "Epoch 00631: val_acc did not improve from 0.90670\n",
            "Epoch 632/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2781 - acc: 0.9626 - val_loss: 0.4512 - val_acc: 0.9052\n",
            "\n",
            "Epoch 00632: val_acc did not improve from 0.90670\n",
            "Epoch 633/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2761 - acc: 0.9625 - val_loss: 0.4508 - val_acc: 0.9058\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.90670\n",
            "Epoch 634/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2891 - acc: 0.9596 - val_loss: 0.4507 - val_acc: 0.9060\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.90670\n",
            "Epoch 635/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2798 - acc: 0.9632 - val_loss: 0.4515 - val_acc: 0.9058\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.90670\n",
            "Epoch 636/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2815 - acc: 0.9596 - val_loss: 0.4498 - val_acc: 0.9063\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.90670\n",
            "Epoch 637/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.2786 - acc: 0.9619 - val_loss: 0.4507 - val_acc: 0.9060\n",
            "\n",
            "Epoch 00637: val_acc did not improve from 0.90670\n",
            "Epoch 638/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2719 - acc: 0.9648 - val_loss: 0.4499 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00638: val_acc improved from 0.90670 to 0.90690, saving model to /content/saved_models/cifar10_ResNet32v1_model.638.h5\n",
            "Epoch 639/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2869 - acc: 0.9589 - val_loss: 0.4515 - val_acc: 0.9053\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.90690\n",
            "Epoch 640/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.2828 - acc: 0.9600 - val_loss: 0.4505 - val_acc: 0.9059\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.90690\n",
            "Epoch 641/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2756 - acc: 0.9626 - val_loss: 0.4502 - val_acc: 0.9063\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.90690\n",
            "Epoch 642/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2793 - acc: 0.9622 - val_loss: 0.4491 - val_acc: 0.9066\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.90690\n",
            "Epoch 643/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2792 - acc: 0.9634 - val_loss: 0.4490 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.90690\n",
            "Epoch 644/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.2736 - acc: 0.9641 - val_loss: 0.4488 - val_acc: 0.9068\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.90690\n",
            "Epoch 645/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2773 - acc: 0.9640 - val_loss: 0.4486 - val_acc: 0.9075\n",
            "\n",
            "Epoch 00645: val_acc improved from 0.90690 to 0.90750, saving model to /content/saved_models/cifar10_ResNet32v1_model.645.h5\n",
            "Epoch 646/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2721 - acc: 0.9657 - val_loss: 0.4485 - val_acc: 0.9077\n",
            "\n",
            "Epoch 00646: val_acc improved from 0.90750 to 0.90770, saving model to /content/saved_models/cifar10_ResNet32v1_model.646.h5\n",
            "Epoch 647/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2783 - acc: 0.9621 - val_loss: 0.4488 - val_acc: 0.9075\n",
            "\n",
            "Epoch 00647: val_acc did not improve from 0.90770\n",
            "Epoch 648/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2799 - acc: 0.9622 - val_loss: 0.4488 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.90770\n",
            "Epoch 649/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2845 - acc: 0.9623 - val_loss: 0.4490 - val_acc: 0.9075\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.90770\n",
            "Epoch 650/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2720 - acc: 0.9655 - val_loss: 0.4488 - val_acc: 0.9073\n",
            "\n",
            "Epoch 00650: val_acc did not improve from 0.90770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "ULxHLRqRFnsh",
        "outputId": "f3a819c8-9022-431c-9809-d8b0d2d41b91"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('trainHistoryDict_clip_05', \"rb\"))\n",
        "functions.plot_loss_acc(history, 4, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYTjxBSYDD6A",
        "outputId": "38ad0451-5536-492d-e75f-5a97b350aeac"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9072999954223633"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IVPweW2FrJM",
        "outputId": "37272ef0-496c-4157-fe45-47c7b20d2d52"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09270000457763672"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgRj4CpUqu7P"
      },
      "source": [
        "#### Model with clipping to 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN70VdR8q2hC",
        "outputId": "15ac27f1-efd4-4c75-c3c5-6e4038a0d55b"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(\n",
        "    input_shape, conv_layer = functions.ConvDecomposed2D, compress_first=False,\n",
        "    decomposition_rank=29)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPQy5yh6ECwd",
        "outputId": "e4472326-3f6d-471a-ffdc-b12abb998251"
      },
      "source": [
        "callbacks = functions.standard_callbacks(model_type) + [functions.Clipping(1)]\n",
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'trainHistoryDict_clip_1', steps_per_epoch=100, epochs=650,\n",
        "                       batch_size=100,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 18s 108ms/step - loss: 2.8597 - acc: 0.2691 - val_loss: 8.0512 - val_acc: 0.1447\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.14470, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.9682 - acc: 0.3476 - val_loss: 2.6323 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.14470\n",
            "Epoch 3/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.6698 - acc: 0.4691 - val_loss: 2.6775 - val_acc: 0.1006\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.14470\n",
            "Epoch 4/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.5753 - acc: 0.5044 - val_loss: 2.6387 - val_acc: 0.2061\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.14470 to 0.20610, saving model to /content/saved_models/cifar10_ResNet32v1_model.004.h5\n",
            "Epoch 5/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4894 - acc: 0.5322 - val_loss: 1.8399 - val_acc: 0.4087\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.20610 to 0.40870, saving model to /content/saved_models/cifar10_ResNet32v1_model.005.h5\n",
            "Epoch 6/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4273 - acc: 0.5532 - val_loss: 1.7065 - val_acc: 0.4540\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.40870 to 0.45400, saving model to /content/saved_models/cifar10_ResNet32v1_model.006.h5\n",
            "Epoch 7/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3632 - acc: 0.5787 - val_loss: 3.2584 - val_acc: 0.2885\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.45400\n",
            "Epoch 8/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2969 - acc: 0.6040 - val_loss: 1.7947 - val_acc: 0.4840\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.45400 to 0.48400, saving model to /content/saved_models/cifar10_ResNet32v1_model.008.h5\n",
            "Epoch 9/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2883 - acc: 0.6117 - val_loss: 1.9388 - val_acc: 0.4960\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.48400 to 0.49600, saving model to /content/saved_models/cifar10_ResNet32v1_model.009.h5\n",
            "Epoch 10/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 1.2256 - acc: 0.6298 - val_loss: 1.8776 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.49600 to 0.51430, saving model to /content/saved_models/cifar10_ResNet32v1_model.010.h5\n",
            "Epoch 11/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2114 - acc: 0.6428 - val_loss: 2.1846 - val_acc: 0.5070\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.51430\n",
            "Epoch 12/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.1791 - acc: 0.6466 - val_loss: 2.2368 - val_acc: 0.4444\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.51430\n",
            "Epoch 13/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.1466 - acc: 0.6660 - val_loss: 4.2250 - val_acc: 0.3203\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.51430\n",
            "Epoch 14/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.0954 - acc: 0.6860 - val_loss: 1.8192 - val_acc: 0.5392\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.51430 to 0.53920, saving model to /content/saved_models/cifar10_ResNet32v1_model.014.h5\n",
            "Epoch 15/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.1031 - acc: 0.6781 - val_loss: 1.5495 - val_acc: 0.5647\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.53920 to 0.56470, saving model to /content/saved_models/cifar10_ResNet32v1_model.015.h5\n",
            "Epoch 16/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.0717 - acc: 0.6934 - val_loss: 2.1154 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.56470\n",
            "Epoch 17/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.0705 - acc: 0.6926 - val_loss: 1.9483 - val_acc: 0.5077\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.56470\n",
            "Epoch 18/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.0272 - acc: 0.7046 - val_loss: 1.6423 - val_acc: 0.5510\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.56470\n",
            "Epoch 19/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.0159 - acc: 0.7156 - val_loss: 1.7308 - val_acc: 0.5488\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.56470\n",
            "Epoch 20/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.9862 - acc: 0.7203 - val_loss: 1.2693 - val_acc: 0.6462\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.56470 to 0.64620, saving model to /content/saved_models/cifar10_ResNet32v1_model.020.h5\n",
            "Epoch 21/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9672 - acc: 0.7277 - val_loss: 1.3182 - val_acc: 0.6059\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.64620\n",
            "Epoch 22/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.0042 - acc: 0.7167 - val_loss: 1.3722 - val_acc: 0.6030\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.64620\n",
            "Epoch 23/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9531 - acc: 0.7352 - val_loss: 1.8615 - val_acc: 0.5502\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.64620\n",
            "Epoch 24/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9523 - acc: 0.7333 - val_loss: 1.4831 - val_acc: 0.5859\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.64620\n",
            "Epoch 25/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.9274 - acc: 0.7504 - val_loss: 1.1099 - val_acc: 0.6944\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.64620 to 0.69440, saving model to /content/saved_models/cifar10_ResNet32v1_model.025.h5\n",
            "Epoch 26/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 116ms/step - loss: 0.9368 - acc: 0.7349 - val_loss: 1.2191 - val_acc: 0.6609\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.69440\n",
            "Epoch 27/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9388 - acc: 0.7344 - val_loss: 1.5447 - val_acc: 0.6138\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.69440\n",
            "Epoch 28/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8939 - acc: 0.7558 - val_loss: 2.3997 - val_acc: 0.5076\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.69440\n",
            "Epoch 29/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9280 - acc: 0.7463 - val_loss: 2.2996 - val_acc: 0.4812\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.69440\n",
            "Epoch 30/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9337 - acc: 0.7453 - val_loss: 3.5319 - val_acc: 0.3828\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.69440\n",
            "Epoch 31/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.8878 - acc: 0.7592 - val_loss: 1.7827 - val_acc: 0.5470\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.69440\n",
            "Epoch 32/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.8934 - acc: 0.7570 - val_loss: 1.1599 - val_acc: 0.6854\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.69440\n",
            "Epoch 33/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8755 - acc: 0.7638 - val_loss: 1.8036 - val_acc: 0.5495\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.69440\n",
            "Epoch 34/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8594 - acc: 0.7656 - val_loss: 1.2733 - val_acc: 0.6649\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.69440\n",
            "Epoch 35/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8752 - acc: 0.7564 - val_loss: 2.1224 - val_acc: 0.4502\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.69440\n",
            "Epoch 36/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8525 - acc: 0.7708 - val_loss: 1.5562 - val_acc: 0.6099\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.69440\n",
            "Epoch 37/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.8427 - acc: 0.7736 - val_loss: 1.0748 - val_acc: 0.6982\n",
            "\n",
            "Epoch 00037: val_acc improved from 0.69440 to 0.69820, saving model to /content/saved_models/cifar10_ResNet32v1_model.037.h5\n",
            "Epoch 38/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8497 - acc: 0.7670 - val_loss: 1.7653 - val_acc: 0.5917\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.69820\n",
            "Epoch 39/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8430 - acc: 0.7769 - val_loss: 1.4710 - val_acc: 0.6172\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.69820\n",
            "Epoch 40/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8179 - acc: 0.7832 - val_loss: 1.8620 - val_acc: 0.5665\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.69820\n",
            "Epoch 41/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8371 - acc: 0.7773 - val_loss: 1.5127 - val_acc: 0.6190\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.69820\n",
            "Epoch 42/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8262 - acc: 0.7822 - val_loss: 2.1773 - val_acc: 0.5054\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.69820\n",
            "Epoch 43/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.8348 - acc: 0.7739 - val_loss: 1.3306 - val_acc: 0.6377\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.69820\n",
            "Epoch 44/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8305 - acc: 0.7723 - val_loss: 1.7217 - val_acc: 0.5592\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.69820\n",
            "Epoch 45/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.8274 - acc: 0.7786 - val_loss: 1.6729 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.69820\n",
            "Epoch 46/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.8056 - acc: 0.7911 - val_loss: 1.5833 - val_acc: 0.5968\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.69820\n",
            "Epoch 47/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8255 - acc: 0.7792 - val_loss: 1.3396 - val_acc: 0.6708\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.69820\n",
            "Epoch 48/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.8016 - acc: 0.7851 - val_loss: 1.7182 - val_acc: 0.5863\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.69820\n",
            "Epoch 49/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7947 - acc: 0.7877 - val_loss: 1.0684 - val_acc: 0.7169\n",
            "\n",
            "Epoch 00049: val_acc improved from 0.69820 to 0.71690, saving model to /content/saved_models/cifar10_ResNet32v1_model.049.h5\n",
            "Epoch 50/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.8101 - acc: 0.7849 - val_loss: 1.9832 - val_acc: 0.6111\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.71690\n",
            "Epoch 51/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7892 - acc: 0.7923 - val_loss: 1.0699 - val_acc: 0.7140\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.71690\n",
            "Epoch 52/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7727 - acc: 0.8018 - val_loss: 1.6442 - val_acc: 0.5936\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.71690\n",
            "Epoch 53/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.7766 - acc: 0.7943 - val_loss: 1.5996 - val_acc: 0.6178\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.71690\n",
            "Epoch 54/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7774 - acc: 0.7928 - val_loss: 1.7489 - val_acc: 0.5773\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.71690\n",
            "Epoch 55/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7740 - acc: 0.7974 - val_loss: 1.3763 - val_acc: 0.6429\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.71690\n",
            "Epoch 56/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7579 - acc: 0.8032 - val_loss: 1.5084 - val_acc: 0.6160\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.71690\n",
            "Epoch 57/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7827 - acc: 0.7949 - val_loss: 1.7726 - val_acc: 0.6124\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.71690\n",
            "Epoch 58/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7841 - acc: 0.7927 - val_loss: 1.6537 - val_acc: 0.6175\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.71690\n",
            "Epoch 59/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7718 - acc: 0.7971 - val_loss: 1.1665 - val_acc: 0.6952\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.71690\n",
            "Epoch 60/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.7690 - acc: 0.8023 - val_loss: 1.0876 - val_acc: 0.7033\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.71690\n",
            "Epoch 61/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.7640 - acc: 0.8012 - val_loss: 1.4845 - val_acc: 0.6345\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.71690\n",
            "Epoch 62/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7682 - acc: 0.7966 - val_loss: 1.2569 - val_acc: 0.6718\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.71690\n",
            "Epoch 63/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7481 - acc: 0.8036 - val_loss: 1.2309 - val_acc: 0.6920\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.71690\n",
            "Epoch 64/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7536 - acc: 0.8066 - val_loss: 1.6834 - val_acc: 0.6034\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.71690\n",
            "Epoch 65/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7489 - acc: 0.8069 - val_loss: 1.7185 - val_acc: 0.6287\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.71690\n",
            "Epoch 66/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7685 - acc: 0.7985 - val_loss: 0.9908 - val_acc: 0.7284\n",
            "\n",
            "Epoch 00066: val_acc improved from 0.71690 to 0.72840, saving model to /content/saved_models/cifar10_ResNet32v1_model.066.h5\n",
            "Epoch 67/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7327 - acc: 0.8138 - val_loss: 1.4518 - val_acc: 0.6484\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.72840\n",
            "Epoch 68/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7514 - acc: 0.8104 - val_loss: 1.2338 - val_acc: 0.6504\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.72840\n",
            "Epoch 69/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.7553 - acc: 0.8036 - val_loss: 2.3639 - val_acc: 0.5160\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.72840\n",
            "Epoch 70/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.7310 - acc: 0.8098 - val_loss: 1.2137 - val_acc: 0.7012\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.72840\n",
            "Epoch 71/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7348 - acc: 0.8129 - val_loss: 1.1908 - val_acc: 0.6779\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.72840\n",
            "Epoch 72/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.7450 - acc: 0.8110 - val_loss: 1.8098 - val_acc: 0.5676\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.72840\n",
            "Epoch 73/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.7485 - acc: 0.8082 - val_loss: 1.3668 - val_acc: 0.6592\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.72840\n",
            "Epoch 74/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7338 - acc: 0.8088 - val_loss: 1.3951 - val_acc: 0.6717\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.72840\n",
            "Epoch 75/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7105 - acc: 0.8186 - val_loss: 1.3169 - val_acc: 0.6626\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.72840\n",
            "Epoch 76/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7279 - acc: 0.8149 - val_loss: 1.5402 - val_acc: 0.6301\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.72840\n",
            "Epoch 77/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7408 - acc: 0.8095 - val_loss: 1.2780 - val_acc: 0.6664\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.72840\n",
            "Epoch 78/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7326 - acc: 0.8114 - val_loss: 2.2252 - val_acc: 0.5314\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.72840\n",
            "Epoch 79/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7135 - acc: 0.8227 - val_loss: 1.4546 - val_acc: 0.6635\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.72840\n",
            "Epoch 80/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.7370 - acc: 0.8081 - val_loss: 1.2350 - val_acc: 0.7020\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.72840\n",
            "Epoch 81/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7179 - acc: 0.8198 - val_loss: 1.9910 - val_acc: 0.5699\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.72840\n",
            "Epoch 82/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7351 - acc: 0.8108 - val_loss: 1.7834 - val_acc: 0.5566\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.72840\n",
            "Epoch 83/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7180 - acc: 0.8177 - val_loss: 0.9746 - val_acc: 0.7446\n",
            "\n",
            "Epoch 00083: val_acc improved from 0.72840 to 0.74460, saving model to /content/saved_models/cifar10_ResNet32v1_model.083.h5\n",
            "Epoch 84/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7148 - acc: 0.8179 - val_loss: 1.5667 - val_acc: 0.6538\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.74460\n",
            "Epoch 85/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7244 - acc: 0.8153 - val_loss: 1.1191 - val_acc: 0.7194\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.74460\n",
            "Epoch 86/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7087 - acc: 0.8208 - val_loss: 1.3898 - val_acc: 0.6576\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.74460\n",
            "Epoch 87/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7398 - acc: 0.8072 - val_loss: 2.5595 - val_acc: 0.5042\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.74460\n",
            "Epoch 88/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7200 - acc: 0.8181 - val_loss: 1.0796 - val_acc: 0.7108\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.74460\n",
            "Epoch 89/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6989 - acc: 0.8260 - val_loss: 1.5007 - val_acc: 0.6475\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.74460\n",
            "Epoch 90/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7119 - acc: 0.8159 - val_loss: 1.3089 - val_acc: 0.6969\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.74460\n",
            "Epoch 91/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7161 - acc: 0.8198 - val_loss: 1.4949 - val_acc: 0.6660\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.74460\n",
            "Epoch 92/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7097 - acc: 0.8196 - val_loss: 0.9999 - val_acc: 0.7448\n",
            "\n",
            "Epoch 00092: val_acc improved from 0.74460 to 0.74480, saving model to /content/saved_models/cifar10_ResNet32v1_model.092.h5\n",
            "Epoch 93/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7002 - acc: 0.8251 - val_loss: 1.9951 - val_acc: 0.5154\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.74480\n",
            "Epoch 94/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6911 - acc: 0.8280 - val_loss: 1.4240 - val_acc: 0.6392\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.74480\n",
            "Epoch 95/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6974 - acc: 0.8209 - val_loss: 1.0695 - val_acc: 0.7327\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.74480\n",
            "Epoch 96/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6803 - acc: 0.8308 - val_loss: 1.0670 - val_acc: 0.7283\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.74480\n",
            "Epoch 97/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.6968 - acc: 0.8262 - val_loss: 1.0075 - val_acc: 0.7412\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.74480\n",
            "Epoch 98/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7145 - acc: 0.8168 - val_loss: 1.3787 - val_acc: 0.6413\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.74480\n",
            "Epoch 99/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6943 - acc: 0.8245 - val_loss: 1.3326 - val_acc: 0.6844\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.74480\n",
            "Epoch 100/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7170 - acc: 0.8236 - val_loss: 1.8324 - val_acc: 0.5823\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.74480\n",
            "Epoch 101/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6766 - acc: 0.8298 - val_loss: 1.6095 - val_acc: 0.6146\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.74480\n",
            "Epoch 102/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6928 - acc: 0.8263 - val_loss: 0.9091 - val_acc: 0.7689\n",
            "\n",
            "Epoch 00102: val_acc improved from 0.74480 to 0.76890, saving model to /content/saved_models/cifar10_ResNet32v1_model.102.h5\n",
            "Epoch 103/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6969 - acc: 0.8203 - val_loss: 0.9632 - val_acc: 0.7499\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.76890\n",
            "Epoch 104/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6696 - acc: 0.8340 - val_loss: 1.1367 - val_acc: 0.7287\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.76890\n",
            "Epoch 105/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7107 - acc: 0.8215 - val_loss: 1.4362 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.76890\n",
            "Epoch 106/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7047 - acc: 0.8159 - val_loss: 1.1369 - val_acc: 0.7091\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.76890\n",
            "Epoch 107/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6916 - acc: 0.8233 - val_loss: 1.2414 - val_acc: 0.6803\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.76890\n",
            "Epoch 108/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6850 - acc: 0.8259 - val_loss: 1.4845 - val_acc: 0.6521\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.76890\n",
            "Epoch 109/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6866 - acc: 0.8307 - val_loss: 1.8482 - val_acc: 0.5768\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.76890\n",
            "Epoch 110/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6932 - acc: 0.8237 - val_loss: 1.4329 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.76890\n",
            "Epoch 111/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6797 - acc: 0.8305 - val_loss: 1.2336 - val_acc: 0.6878\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.76890\n",
            "Epoch 112/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6744 - acc: 0.8325 - val_loss: 1.4871 - val_acc: 0.6468\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.76890\n",
            "Epoch 113/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6896 - acc: 0.8222 - val_loss: 1.3927 - val_acc: 0.6503\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.76890\n",
            "Epoch 114/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6864 - acc: 0.8290 - val_loss: 1.2346 - val_acc: 0.6986\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.76890\n",
            "Epoch 115/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6668 - acc: 0.8360 - val_loss: 1.0537 - val_acc: 0.7296\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.76890\n",
            "Epoch 116/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6812 - acc: 0.8270 - val_loss: 1.0424 - val_acc: 0.7154\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.76890\n",
            "Epoch 117/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6736 - acc: 0.8344 - val_loss: 2.4293 - val_acc: 0.4565\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.76890\n",
            "Epoch 118/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6749 - acc: 0.8318 - val_loss: 1.3384 - val_acc: 0.6853\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.76890\n",
            "Epoch 119/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6945 - acc: 0.8240 - val_loss: 1.5527 - val_acc: 0.6380\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.76890\n",
            "Epoch 120/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6739 - acc: 0.8317 - val_loss: 1.2594 - val_acc: 0.7213\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.76890\n",
            "Epoch 121/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6739 - acc: 0.8333 - val_loss: 1.0474 - val_acc: 0.7364\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.76890\n",
            "Epoch 122/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6780 - acc: 0.8288 - val_loss: 0.9755 - val_acc: 0.7512\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.76890\n",
            "Epoch 123/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6540 - acc: 0.8385 - val_loss: 0.9850 - val_acc: 0.7593\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.76890\n",
            "Epoch 124/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6720 - acc: 0.8321 - val_loss: 1.0752 - val_acc: 0.7373\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.76890\n",
            "Epoch 125/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6931 - acc: 0.8253 - val_loss: 1.1546 - val_acc: 0.7096\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.76890\n",
            "Epoch 126/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6584 - acc: 0.8348 - val_loss: 1.0763 - val_acc: 0.7320\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.76890\n",
            "Epoch 127/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6736 - acc: 0.8339 - val_loss: 2.0103 - val_acc: 0.5926\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.76890\n",
            "Epoch 128/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6741 - acc: 0.8342 - val_loss: 1.0013 - val_acc: 0.7334\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.76890\n",
            "Epoch 129/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6802 - acc: 0.8286 - val_loss: 1.0316 - val_acc: 0.7288\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.76890\n",
            "Epoch 130/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6737 - acc: 0.8333 - val_loss: 1.3811 - val_acc: 0.6609\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.76890\n",
            "Epoch 131/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6594 - acc: 0.8382 - val_loss: 1.1255 - val_acc: 0.7178\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.76890\n",
            "Epoch 132/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6676 - acc: 0.8347 - val_loss: 1.6702 - val_acc: 0.6469\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.76890\n",
            "Epoch 133/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6742 - acc: 0.8307 - val_loss: 1.0233 - val_acc: 0.7328\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.76890\n",
            "Epoch 134/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6531 - acc: 0.8381 - val_loss: 1.7594 - val_acc: 0.5738\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.76890\n",
            "Epoch 135/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6706 - acc: 0.8324 - val_loss: 1.2196 - val_acc: 0.7023\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.76890\n",
            "Epoch 136/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6651 - acc: 0.8358 - val_loss: 1.2659 - val_acc: 0.6859\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.76890\n",
            "Epoch 137/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6507 - acc: 0.8399 - val_loss: 0.8444 - val_acc: 0.7851\n",
            "\n",
            "Epoch 00137: val_acc improved from 0.76890 to 0.78510, saving model to /content/saved_models/cifar10_ResNet32v1_model.137.h5\n",
            "Epoch 138/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6587 - acc: 0.8341 - val_loss: 1.5007 - val_acc: 0.6335\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.78510\n",
            "Epoch 139/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6574 - acc: 0.8347 - val_loss: 0.8481 - val_acc: 0.7813\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.78510\n",
            "Epoch 140/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6675 - acc: 0.8354 - val_loss: 1.8841 - val_acc: 0.5747\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.78510\n",
            "Epoch 141/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6671 - acc: 0.8342 - val_loss: 1.0756 - val_acc: 0.7351\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.78510\n",
            "Epoch 142/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6467 - acc: 0.8377 - val_loss: 2.0047 - val_acc: 0.5815\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.78510\n",
            "Epoch 143/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6618 - acc: 0.8379 - val_loss: 1.4083 - val_acc: 0.6526\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.78510\n",
            "Epoch 144/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6697 - acc: 0.8312 - val_loss: 1.0011 - val_acc: 0.7642\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.78510\n",
            "Epoch 145/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6727 - acc: 0.8337 - val_loss: 0.9670 - val_acc: 0.7483\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.78510\n",
            "Epoch 146/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6528 - acc: 0.8412 - val_loss: 1.2242 - val_acc: 0.6886\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.78510\n",
            "Epoch 147/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6599 - acc: 0.8399 - val_loss: 1.4484 - val_acc: 0.6798\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.78510\n",
            "Epoch 148/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6682 - acc: 0.8334 - val_loss: 1.2300 - val_acc: 0.6730\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.78510\n",
            "Epoch 149/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6496 - acc: 0.8396 - val_loss: 0.9020 - val_acc: 0.7595\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.78510\n",
            "Epoch 150/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6409 - acc: 0.8430 - val_loss: 1.0971 - val_acc: 0.7123\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.78510\n",
            "Epoch 151/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6615 - acc: 0.8312 - val_loss: 1.1098 - val_acc: 0.7329\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.78510\n",
            "Epoch 152/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6497 - acc: 0.8398 - val_loss: 1.1179 - val_acc: 0.7152\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.78510\n",
            "Epoch 153/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6447 - acc: 0.8412 - val_loss: 1.0038 - val_acc: 0.7452\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.78510\n",
            "Epoch 154/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6675 - acc: 0.8357 - val_loss: 0.8803 - val_acc: 0.7773\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.78510\n",
            "Epoch 155/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6416 - acc: 0.8446 - val_loss: 0.9488 - val_acc: 0.7509\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.78510\n",
            "Epoch 156/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6394 - acc: 0.8449 - val_loss: 1.0956 - val_acc: 0.7228\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.78510\n",
            "Epoch 157/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6729 - acc: 0.8296 - val_loss: 1.5445 - val_acc: 0.6223\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.78510\n",
            "Epoch 158/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6556 - acc: 0.8349 - val_loss: 1.0884 - val_acc: 0.7209\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.78510\n",
            "Epoch 159/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6416 - acc: 0.8437 - val_loss: 1.9593 - val_acc: 0.5918\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.78510\n",
            "Epoch 160/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6440 - acc: 0.8425 - val_loss: 1.0375 - val_acc: 0.7385\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.78510\n",
            "Epoch 161/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6461 - acc: 0.8402 - val_loss: 1.9165 - val_acc: 0.5685\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.78510\n",
            "Epoch 162/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6502 - acc: 0.8392 - val_loss: 1.0380 - val_acc: 0.7427\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.78510\n",
            "Epoch 163/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6520 - acc: 0.8391 - val_loss: 1.0160 - val_acc: 0.7509\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.78510\n",
            "Epoch 164/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6562 - acc: 0.8429 - val_loss: 1.3246 - val_acc: 0.6770\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.78510\n",
            "Epoch 165/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6473 - acc: 0.8424 - val_loss: 1.4951 - val_acc: 0.6609\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.78510\n",
            "Epoch 166/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6339 - acc: 0.8500 - val_loss: 1.5044 - val_acc: 0.6742\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.78510\n",
            "Epoch 167/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6491 - acc: 0.8354 - val_loss: 1.0890 - val_acc: 0.7254\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.78510\n",
            "Epoch 168/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6439 - acc: 0.8444 - val_loss: 1.0891 - val_acc: 0.7146\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.78510\n",
            "Epoch 169/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6378 - acc: 0.8427 - val_loss: 1.6059 - val_acc: 0.6218\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.78510\n",
            "Epoch 170/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6439 - acc: 0.8438 - val_loss: 2.3414 - val_acc: 0.5618\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.78510\n",
            "Epoch 171/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6411 - acc: 0.8406 - val_loss: 0.9101 - val_acc: 0.7617\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.78510\n",
            "Epoch 172/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6424 - acc: 0.8422 - val_loss: 1.4079 - val_acc: 0.6794\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.78510\n",
            "Epoch 173/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6357 - acc: 0.8468 - val_loss: 1.4117 - val_acc: 0.6745\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.78510\n",
            "Epoch 174/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6572 - acc: 0.8371 - val_loss: 1.3960 - val_acc: 0.6916\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.78510\n",
            "Epoch 175/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6461 - acc: 0.8466 - val_loss: 1.0678 - val_acc: 0.7190\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.78510\n",
            "Epoch 176/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6354 - acc: 0.8454 - val_loss: 1.1154 - val_acc: 0.6997\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.78510\n",
            "Epoch 177/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6459 - acc: 0.8384 - val_loss: 1.2951 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.78510\n",
            "Epoch 178/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6548 - acc: 0.8419 - val_loss: 1.3524 - val_acc: 0.6806\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.78510\n",
            "Epoch 179/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6362 - acc: 0.8465 - val_loss: 1.3985 - val_acc: 0.6566\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.78510\n",
            "Epoch 180/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6545 - acc: 0.8392 - val_loss: 1.0751 - val_acc: 0.7319\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.78510\n",
            "Epoch 181/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6333 - acc: 0.8440 - val_loss: 0.8873 - val_acc: 0.7667\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.78510\n",
            "Epoch 182/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6354 - acc: 0.8437 - val_loss: 0.8909 - val_acc: 0.7740\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.78510\n",
            "Epoch 183/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6492 - acc: 0.8393 - val_loss: 1.3818 - val_acc: 0.6754\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.78510\n",
            "Epoch 184/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6360 - acc: 0.8423 - val_loss: 1.1003 - val_acc: 0.7350\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.78510\n",
            "Epoch 185/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6319 - acc: 0.8440 - val_loss: 0.8071 - val_acc: 0.7899\n",
            "\n",
            "Epoch 00185: val_acc improved from 0.78510 to 0.78990, saving model to /content/saved_models/cifar10_ResNet32v1_model.185.h5\n",
            "Epoch 186/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6350 - acc: 0.8416 - val_loss: 1.4066 - val_acc: 0.6764\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.78990\n",
            "Epoch 187/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6464 - acc: 0.8455 - val_loss: 1.2639 - val_acc: 0.7072\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.78990\n",
            "Epoch 188/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6325 - acc: 0.8470 - val_loss: 1.6359 - val_acc: 0.6267\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.78990\n",
            "Epoch 189/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6375 - acc: 0.8446 - val_loss: 0.9530 - val_acc: 0.7673\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.78990\n",
            "Epoch 190/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6286 - acc: 0.8471 - val_loss: 1.2600 - val_acc: 0.6910\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.78990\n",
            "Epoch 191/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6214 - acc: 0.8488 - val_loss: 0.9766 - val_acc: 0.7537\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.78990\n",
            "Epoch 192/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6301 - acc: 0.8429 - val_loss: 1.2602 - val_acc: 0.6935\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.78990\n",
            "Epoch 193/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6319 - acc: 0.8493 - val_loss: 1.1119 - val_acc: 0.7454\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.78990\n",
            "Epoch 194/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6320 - acc: 0.8476 - val_loss: 1.1422 - val_acc: 0.7133\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.78990\n",
            "Epoch 195/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6418 - acc: 0.8414 - val_loss: 1.2149 - val_acc: 0.7003\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.78990\n",
            "Epoch 196/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6327 - acc: 0.8459 - val_loss: 1.2938 - val_acc: 0.6754\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.78990\n",
            "Epoch 197/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6482 - acc: 0.8385 - val_loss: 0.8778 - val_acc: 0.7731\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.78990\n",
            "Epoch 198/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6264 - acc: 0.8481 - val_loss: 1.2607 - val_acc: 0.6895\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.78990\n",
            "Epoch 199/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6375 - acc: 0.8479 - val_loss: 1.4555 - val_acc: 0.6798\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.78990\n",
            "Epoch 200/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6325 - acc: 0.8467 - val_loss: 1.0172 - val_acc: 0.7516\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.78990\n",
            "Epoch 201/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6285 - acc: 0.8503 - val_loss: 0.7726 - val_acc: 0.8033\n",
            "\n",
            "Epoch 00201: val_acc improved from 0.78990 to 0.80330, saving model to /content/saved_models/cifar10_ResNet32v1_model.201.h5\n",
            "Epoch 202/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6042 - acc: 0.8534 - val_loss: 0.9018 - val_acc: 0.7612\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.80330\n",
            "Epoch 203/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6209 - acc: 0.8467 - val_loss: 0.9931 - val_acc: 0.7464\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.80330\n",
            "Epoch 204/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6582 - acc: 0.8346 - val_loss: 1.1409 - val_acc: 0.7342\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.80330\n",
            "Epoch 205/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6308 - acc: 0.8464 - val_loss: 1.1620 - val_acc: 0.7055\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.80330\n",
            "Epoch 206/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6246 - acc: 0.8470 - val_loss: 0.8243 - val_acc: 0.7847\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.80330\n",
            "Epoch 207/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6180 - acc: 0.8524 - val_loss: 1.0981 - val_acc: 0.7295\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.80330\n",
            "Epoch 208/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6298 - acc: 0.8476 - val_loss: 1.4930 - val_acc: 0.6466\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.80330\n",
            "Epoch 209/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6346 - acc: 0.8496 - val_loss: 1.5091 - val_acc: 0.6535\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.80330\n",
            "Epoch 210/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6365 - acc: 0.8477 - val_loss: 1.1553 - val_acc: 0.7038\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.80330\n",
            "Epoch 211/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6419 - acc: 0.8400 - val_loss: 1.0003 - val_acc: 0.7466\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.80330\n",
            "Epoch 212/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6228 - acc: 0.8540 - val_loss: 2.1514 - val_acc: 0.5220\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.80330\n",
            "Epoch 213/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6215 - acc: 0.8506 - val_loss: 0.8919 - val_acc: 0.7741\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.80330\n",
            "Epoch 214/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6222 - acc: 0.8478 - val_loss: 1.3923 - val_acc: 0.6898\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.80330\n",
            "Epoch 215/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6380 - acc: 0.8465 - val_loss: 1.3310 - val_acc: 0.6646\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.80330\n",
            "Epoch 216/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6256 - acc: 0.8462 - val_loss: 1.5293 - val_acc: 0.6364\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.80330\n",
            "Epoch 217/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6232 - acc: 0.8507 - val_loss: 0.8959 - val_acc: 0.7773\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.80330\n",
            "Epoch 218/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6294 - acc: 0.8457 - val_loss: 1.7436 - val_acc: 0.6533\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.80330\n",
            "Epoch 219/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6046 - acc: 0.8552 - val_loss: 1.1084 - val_acc: 0.7233\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.80330\n",
            "Epoch 220/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6263 - acc: 0.8464 - val_loss: 1.0579 - val_acc: 0.7325\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.80330\n",
            "Epoch 221/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6112 - acc: 0.8524 - val_loss: 1.1364 - val_acc: 0.7307\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.80330\n",
            "Epoch 222/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6099 - acc: 0.8582 - val_loss: 1.2534 - val_acc: 0.6945\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.80330\n",
            "Epoch 223/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6136 - acc: 0.8554 - val_loss: 1.6701 - val_acc: 0.6225\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.80330\n",
            "Epoch 224/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6286 - acc: 0.8484 - val_loss: 0.8859 - val_acc: 0.7608\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.80330\n",
            "Epoch 225/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6110 - acc: 0.8495 - val_loss: 0.9820 - val_acc: 0.7558\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.80330\n",
            "Epoch 226/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6486 - acc: 0.8398 - val_loss: 1.2599 - val_acc: 0.6668\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.80330\n",
            "Epoch 227/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6166 - acc: 0.8500 - val_loss: 1.5508 - val_acc: 0.6640\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.80330\n",
            "Epoch 228/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6105 - acc: 0.8555 - val_loss: 1.1055 - val_acc: 0.7257\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.80330\n",
            "Epoch 229/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.6300 - acc: 0.8502 - val_loss: 1.7245 - val_acc: 0.6160\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.80330\n",
            "Epoch 230/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6354 - acc: 0.8458 - val_loss: 0.9227 - val_acc: 0.7643\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.80330\n",
            "Epoch 231/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6063 - acc: 0.8505 - val_loss: 1.3617 - val_acc: 0.6747\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.80330\n",
            "Epoch 232/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6087 - acc: 0.8537 - val_loss: 2.7907 - val_acc: 0.4831\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.80330\n",
            "Epoch 233/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6122 - acc: 0.8521 - val_loss: 0.9984 - val_acc: 0.7456\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.80330\n",
            "Epoch 234/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6027 - acc: 0.8599 - val_loss: 3.3676 - val_acc: 0.4573\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.80330\n",
            "Epoch 235/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6270 - acc: 0.8485 - val_loss: 1.0438 - val_acc: 0.7259\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.80330\n",
            "Epoch 236/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6142 - acc: 0.8519 - val_loss: 1.1882 - val_acc: 0.6969\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.80330\n",
            "Epoch 237/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6180 - acc: 0.8510 - val_loss: 1.1522 - val_acc: 0.7172\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.80330\n",
            "Epoch 238/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6139 - acc: 0.8553 - val_loss: 1.2348 - val_acc: 0.7055\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.80330\n",
            "Epoch 239/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6124 - acc: 0.8548 - val_loss: 1.3537 - val_acc: 0.6847\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.80330\n",
            "Epoch 240/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6154 - acc: 0.8505 - val_loss: 0.7936 - val_acc: 0.8033\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.80330\n",
            "Epoch 241/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6122 - acc: 0.8533 - val_loss: 1.0913 - val_acc: 0.7177\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.80330\n",
            "Epoch 242/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6082 - acc: 0.8512 - val_loss: 1.1931 - val_acc: 0.7034\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.80330\n",
            "Epoch 243/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6157 - acc: 0.8490 - val_loss: 1.3969 - val_acc: 0.6528\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.80330\n",
            "Epoch 244/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6053 - acc: 0.8583 - val_loss: 1.0515 - val_acc: 0.7408\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.80330\n",
            "Epoch 245/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6304 - acc: 0.8462 - val_loss: 0.8039 - val_acc: 0.7921\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.80330\n",
            "Epoch 246/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6191 - acc: 0.8514 - val_loss: 1.9486 - val_acc: 0.6112\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.80330\n",
            "Epoch 247/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6094 - acc: 0.8518 - val_loss: 1.1500 - val_acc: 0.7052\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.80330\n",
            "Epoch 248/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6023 - acc: 0.8558 - val_loss: 0.8798 - val_acc: 0.7799\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.80330\n",
            "Epoch 249/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5963 - acc: 0.8593 - val_loss: 0.8437 - val_acc: 0.7837\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.80330\n",
            "Epoch 250/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6028 - acc: 0.8568 - val_loss: 2.2776 - val_acc: 0.5662\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.80330\n",
            "Epoch 251/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6077 - acc: 0.8546 - val_loss: 1.6740 - val_acc: 0.6057\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.80330\n",
            "Epoch 252/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6013 - acc: 0.8578 - val_loss: 1.2778 - val_acc: 0.7029\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.80330\n",
            "Epoch 253/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6059 - acc: 0.8562 - val_loss: 1.0782 - val_acc: 0.7254\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.80330\n",
            "Epoch 254/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6132 - acc: 0.8530 - val_loss: 1.4780 - val_acc: 0.6324\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.80330\n",
            "Epoch 255/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6041 - acc: 0.8547 - val_loss: 1.4497 - val_acc: 0.6752\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.80330\n",
            "Epoch 256/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6140 - acc: 0.8511 - val_loss: 0.7699 - val_acc: 0.8081\n",
            "\n",
            "Epoch 00256: val_acc improved from 0.80330 to 0.80810, saving model to /content/saved_models/cifar10_ResNet32v1_model.256.h5\n",
            "Epoch 257/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6146 - acc: 0.8538 - val_loss: 1.3361 - val_acc: 0.6639\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.80810\n",
            "Epoch 258/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6160 - acc: 0.8500 - val_loss: 0.8610 - val_acc: 0.7815\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.80810\n",
            "Epoch 259/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6090 - acc: 0.8509 - val_loss: 1.0953 - val_acc: 0.7108\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.80810\n",
            "Epoch 260/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6182 - acc: 0.8502 - val_loss: 1.2124 - val_acc: 0.6861\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.80810\n",
            "Epoch 261/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6162 - acc: 0.8530 - val_loss: 0.8030 - val_acc: 0.7971\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.80810\n",
            "Epoch 262/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6148 - acc: 0.8543 - val_loss: 0.9478 - val_acc: 0.7495\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.80810\n",
            "Epoch 263/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5837 - acc: 0.8619 - val_loss: 1.1596 - val_acc: 0.7065\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.80810\n",
            "Epoch 264/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6121 - acc: 0.8527 - val_loss: 0.9552 - val_acc: 0.7588\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.80810\n",
            "Epoch 265/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5972 - acc: 0.8570 - val_loss: 0.8878 - val_acc: 0.7710\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.80810\n",
            "Epoch 266/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6103 - acc: 0.8545 - val_loss: 0.9320 - val_acc: 0.7672\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.80810\n",
            "Epoch 267/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6068 - acc: 0.8585 - val_loss: 0.9303 - val_acc: 0.7545\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.80810\n",
            "Epoch 268/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6077 - acc: 0.8536 - val_loss: 1.2734 - val_acc: 0.7131\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.80810\n",
            "Epoch 269/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6109 - acc: 0.8537 - val_loss: 1.3968 - val_acc: 0.6392\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.80810\n",
            "Epoch 270/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6197 - acc: 0.8496 - val_loss: 0.9988 - val_acc: 0.7532\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.80810\n",
            "Epoch 271/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6082 - acc: 0.8554 - val_loss: 1.0877 - val_acc: 0.7407\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.80810\n",
            "Epoch 272/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6024 - acc: 0.8563 - val_loss: 0.9857 - val_acc: 0.7579\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.80810\n",
            "Epoch 273/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6136 - acc: 0.8554 - val_loss: 1.1454 - val_acc: 0.7155\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.80810\n",
            "Epoch 274/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6127 - acc: 0.8543 - val_loss: 1.9299 - val_acc: 0.5443\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.80810\n",
            "Epoch 275/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5980 - acc: 0.8568 - val_loss: 0.8062 - val_acc: 0.8005\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.80810\n",
            "Epoch 276/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6101 - acc: 0.8540 - val_loss: 0.9494 - val_acc: 0.7661\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.80810\n",
            "Epoch 277/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5957 - acc: 0.8568 - val_loss: 0.9703 - val_acc: 0.7593\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.80810\n",
            "Epoch 278/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6177 - acc: 0.8506 - val_loss: 1.0730 - val_acc: 0.7436\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.80810\n",
            "Epoch 279/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5988 - acc: 0.8586 - val_loss: 1.1015 - val_acc: 0.7100\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.80810\n",
            "Epoch 280/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6088 - acc: 0.8577 - val_loss: 1.7234 - val_acc: 0.5842\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.80810\n",
            "Epoch 281/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6061 - acc: 0.8557 - val_loss: 0.8752 - val_acc: 0.7834\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.80810\n",
            "Epoch 282/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5958 - acc: 0.8559 - val_loss: 1.3659 - val_acc: 0.6505\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.80810\n",
            "Epoch 283/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6113 - acc: 0.8568 - val_loss: 0.7958 - val_acc: 0.7995\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.80810\n",
            "Epoch 284/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6051 - acc: 0.8595 - val_loss: 2.8274 - val_acc: 0.5346\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.80810\n",
            "Epoch 285/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6044 - acc: 0.8564 - val_loss: 0.8912 - val_acc: 0.7707\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.80810\n",
            "Epoch 286/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5988 - acc: 0.8542 - val_loss: 1.0482 - val_acc: 0.7542\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.80810\n",
            "Epoch 287/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6222 - acc: 0.8485 - val_loss: 1.3769 - val_acc: 0.6952\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.80810\n",
            "Epoch 288/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6021 - acc: 0.8550 - val_loss: 0.7897 - val_acc: 0.7993\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.80810\n",
            "Epoch 289/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6023 - acc: 0.8570 - val_loss: 0.9009 - val_acc: 0.7720\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.80810\n",
            "Epoch 290/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6015 - acc: 0.8567 - val_loss: 1.5904 - val_acc: 0.6353\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.80810\n",
            "Epoch 291/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6073 - acc: 0.8560 - val_loss: 3.5209 - val_acc: 0.4119\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.80810\n",
            "Epoch 292/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5954 - acc: 0.8586 - val_loss: 0.8658 - val_acc: 0.7834\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.80810\n",
            "Epoch 293/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6026 - acc: 0.8587 - val_loss: 0.8550 - val_acc: 0.7813\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.80810\n",
            "Epoch 294/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6008 - acc: 0.8546 - val_loss: 1.3917 - val_acc: 0.6939\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.80810\n",
            "Epoch 295/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6003 - acc: 0.8568 - val_loss: 1.6039 - val_acc: 0.6442\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.80810\n",
            "Epoch 296/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6001 - acc: 0.8529 - val_loss: 1.2281 - val_acc: 0.7141\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.80810\n",
            "Epoch 297/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5923 - acc: 0.8602 - val_loss: 1.1376 - val_acc: 0.7214\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.80810\n",
            "Epoch 298/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6159 - acc: 0.8536 - val_loss: 0.9706 - val_acc: 0.7471\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.80810\n",
            "Epoch 299/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5755 - acc: 0.8654 - val_loss: 1.1175 - val_acc: 0.7252\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.80810\n",
            "Epoch 300/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5973 - acc: 0.8573 - val_loss: 1.2044 - val_acc: 0.7198\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.80810\n",
            "Epoch 301/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6105 - acc: 0.8547 - val_loss: 2.7738 - val_acc: 0.5318\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.80810\n",
            "Epoch 302/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6078 - acc: 0.8516 - val_loss: 0.9295 - val_acc: 0.7707\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.80810\n",
            "Epoch 303/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6022 - acc: 0.8526 - val_loss: 0.9399 - val_acc: 0.7664\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.80810\n",
            "Epoch 304/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6017 - acc: 0.8597 - val_loss: 1.0011 - val_acc: 0.7544\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.80810\n",
            "Epoch 305/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5870 - acc: 0.8613 - val_loss: 1.1792 - val_acc: 0.7167\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.80810\n",
            "Epoch 306/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5989 - acc: 0.8598 - val_loss: 1.0466 - val_acc: 0.7410\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.80810\n",
            "Epoch 307/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6015 - acc: 0.8594 - val_loss: 0.8273 - val_acc: 0.7850\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.80810\n",
            "Epoch 308/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5997 - acc: 0.8540 - val_loss: 0.9035 - val_acc: 0.7745\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.80810\n",
            "Epoch 309/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5925 - acc: 0.8632 - val_loss: 1.5069 - val_acc: 0.6240\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.80810\n",
            "Epoch 310/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5844 - acc: 0.8633 - val_loss: 1.2723 - val_acc: 0.7090\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.80810\n",
            "Epoch 311/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5883 - acc: 0.8642 - val_loss: 1.0450 - val_acc: 0.7439\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.80810\n",
            "Epoch 312/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6132 - acc: 0.8515 - val_loss: 1.0030 - val_acc: 0.7404\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.80810\n",
            "Epoch 313/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5941 - acc: 0.8599 - val_loss: 0.8954 - val_acc: 0.7756\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.80810\n",
            "Epoch 314/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5789 - acc: 0.8651 - val_loss: 1.0230 - val_acc: 0.7642\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.80810\n",
            "Epoch 315/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5917 - acc: 0.8583 - val_loss: 1.1952 - val_acc: 0.6871\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.80810\n",
            "Epoch 316/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5824 - acc: 0.8646 - val_loss: 0.8874 - val_acc: 0.7733\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.80810\n",
            "Epoch 317/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5874 - acc: 0.8631 - val_loss: 0.9821 - val_acc: 0.7616\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.80810\n",
            "Epoch 318/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5859 - acc: 0.8636 - val_loss: 0.9524 - val_acc: 0.7712\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.80810\n",
            "Epoch 319/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6100 - acc: 0.8531 - val_loss: 1.2308 - val_acc: 0.6918\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.80810\n",
            "Epoch 320/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6039 - acc: 0.8549 - val_loss: 0.8635 - val_acc: 0.7872\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.80810\n",
            "Epoch 321/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5936 - acc: 0.8608 - val_loss: 0.8825 - val_acc: 0.7701\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.80810\n",
            "Epoch 322/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6037 - acc: 0.8553 - val_loss: 1.3289 - val_acc: 0.6709\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.80810\n",
            "Epoch 323/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5943 - acc: 0.8568 - val_loss: 0.9692 - val_acc: 0.7504\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.80810\n",
            "Epoch 324/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5979 - acc: 0.8583 - val_loss: 0.9014 - val_acc: 0.7854\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.80810\n",
            "Epoch 325/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5816 - acc: 0.8654 - val_loss: 0.9269 - val_acc: 0.7531\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.80810\n",
            "Epoch 326/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6073 - acc: 0.8562 - val_loss: 1.0572 - val_acc: 0.7325\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.80810\n",
            "Epoch 327/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5983 - acc: 0.8546 - val_loss: 1.0818 - val_acc: 0.7434\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.80810\n",
            "Epoch 328/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5943 - acc: 0.8590 - val_loss: 0.8850 - val_acc: 0.7736\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.80810\n",
            "Epoch 329/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5780 - acc: 0.8621 - val_loss: 1.9252 - val_acc: 0.5456\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.80810\n",
            "Epoch 330/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5796 - acc: 0.8618 - val_loss: 1.1262 - val_acc: 0.7290\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.80810\n",
            "Epoch 331/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6062 - acc: 0.8551 - val_loss: 1.2688 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.80810\n",
            "Epoch 332/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5951 - acc: 0.8574 - val_loss: 1.0156 - val_acc: 0.7376\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.80810\n",
            "Epoch 333/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5999 - acc: 0.8550 - val_loss: 1.0675 - val_acc: 0.7348\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.80810\n",
            "Epoch 334/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5868 - acc: 0.8603 - val_loss: 1.1808 - val_acc: 0.7178\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.80810\n",
            "Epoch 335/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5901 - acc: 0.8638 - val_loss: 1.0228 - val_acc: 0.7169\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.80810\n",
            "Epoch 336/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6002 - acc: 0.8592 - val_loss: 1.4079 - val_acc: 0.6550\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.80810\n",
            "Epoch 337/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5859 - acc: 0.8585 - val_loss: 1.6285 - val_acc: 0.6437\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.80810\n",
            "Epoch 338/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5673 - acc: 0.8641 - val_loss: 1.6669 - val_acc: 0.6126\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.80810\n",
            "Epoch 339/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5773 - acc: 0.8646 - val_loss: 1.0689 - val_acc: 0.7273\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.80810\n",
            "Epoch 340/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5998 - acc: 0.8565 - val_loss: 1.0097 - val_acc: 0.7581\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.80810\n",
            "Epoch 341/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5844 - acc: 0.8650 - val_loss: 1.1915 - val_acc: 0.7187\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.80810\n",
            "Epoch 342/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5954 - acc: 0.8616 - val_loss: 1.2124 - val_acc: 0.6746\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.80810\n",
            "Epoch 343/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5775 - acc: 0.8671 - val_loss: 1.1571 - val_acc: 0.7396\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.80810\n",
            "Epoch 344/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5905 - acc: 0.8595 - val_loss: 1.0053 - val_acc: 0.7456\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.80810\n",
            "Epoch 345/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5842 - acc: 0.8642 - val_loss: 1.3136 - val_acc: 0.6757\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.80810\n",
            "Epoch 346/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5930 - acc: 0.8594 - val_loss: 1.0921 - val_acc: 0.7325\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.80810\n",
            "Epoch 347/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5987 - acc: 0.8575 - val_loss: 0.8001 - val_acc: 0.7924\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.80810\n",
            "Epoch 348/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5821 - acc: 0.8623 - val_loss: 0.9520 - val_acc: 0.7658\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.80810\n",
            "Epoch 349/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5872 - acc: 0.8629 - val_loss: 1.2498 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.80810\n",
            "Epoch 350/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5807 - acc: 0.8647 - val_loss: 0.9070 - val_acc: 0.7823\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.80810\n",
            "Epoch 351/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5731 - acc: 0.8686 - val_loss: 0.8551 - val_acc: 0.7893\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.80810\n",
            "Epoch 352/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6053 - acc: 0.8594 - val_loss: 0.9645 - val_acc: 0.7648\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.80810\n",
            "Epoch 353/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5839 - acc: 0.8592 - val_loss: 0.8355 - val_acc: 0.7743\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.80810\n",
            "Epoch 354/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6051 - acc: 0.8531 - val_loss: 1.0499 - val_acc: 0.7329\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.80810\n",
            "Epoch 355/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5862 - acc: 0.8615 - val_loss: 1.0465 - val_acc: 0.7370\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.80810\n",
            "Epoch 356/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5764 - acc: 0.8653 - val_loss: 0.9045 - val_acc: 0.7635\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.80810\n",
            "Epoch 357/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5908 - acc: 0.8598 - val_loss: 1.3175 - val_acc: 0.6887\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.80810\n",
            "Epoch 358/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5768 - acc: 0.8696 - val_loss: 1.4672 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.80810\n",
            "Epoch 359/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5908 - acc: 0.8615 - val_loss: 1.0818 - val_acc: 0.7115\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.80810\n",
            "Epoch 360/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5743 - acc: 0.8662 - val_loss: 0.9946 - val_acc: 0.7535\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.80810\n",
            "Epoch 361/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5736 - acc: 0.8676 - val_loss: 1.2068 - val_acc: 0.6902\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.80810\n",
            "Epoch 362/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5822 - acc: 0.8612 - val_loss: 0.9379 - val_acc: 0.7667\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.80810\n",
            "Epoch 363/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5601 - acc: 0.8701 - val_loss: 1.3299 - val_acc: 0.7064\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.80810\n",
            "Epoch 364/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5798 - acc: 0.8630 - val_loss: 1.7017 - val_acc: 0.6174\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.80810\n",
            "Epoch 365/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5918 - acc: 0.8623 - val_loss: 0.8825 - val_acc: 0.7850\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.80810\n",
            "Epoch 366/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5851 - acc: 0.8607 - val_loss: 0.9590 - val_acc: 0.7606\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.80810\n",
            "Epoch 367/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5772 - acc: 0.8663 - val_loss: 1.1336 - val_acc: 0.7146\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.80810\n",
            "Epoch 368/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5960 - acc: 0.8633 - val_loss: 1.9633 - val_acc: 0.6046\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.80810\n",
            "Epoch 369/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5718 - acc: 0.8655 - val_loss: 1.0351 - val_acc: 0.7586\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.80810\n",
            "Epoch 370/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5676 - acc: 0.8696 - val_loss: 0.8349 - val_acc: 0.7886\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.80810\n",
            "Epoch 371/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5840 - acc: 0.8665 - val_loss: 1.2753 - val_acc: 0.6857\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.80810\n",
            "Epoch 372/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5690 - acc: 0.8702 - val_loss: 0.9492 - val_acc: 0.7713\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.80810\n",
            "Epoch 373/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6050 - acc: 0.8573 - val_loss: 1.0138 - val_acc: 0.7480\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.80810\n",
            "Epoch 374/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5784 - acc: 0.8614 - val_loss: 1.1417 - val_acc: 0.7133\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.80810\n",
            "Epoch 375/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5953 - acc: 0.8591 - val_loss: 0.9454 - val_acc: 0.7610\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.80810\n",
            "Epoch 376/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5759 - acc: 0.8659 - val_loss: 0.9570 - val_acc: 0.7492\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.80810\n",
            "Epoch 377/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5809 - acc: 0.8647 - val_loss: 1.2663 - val_acc: 0.7028\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.80810\n",
            "Epoch 378/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5884 - acc: 0.8624 - val_loss: 0.8323 - val_acc: 0.7890\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.80810\n",
            "Epoch 379/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5721 - acc: 0.8646 - val_loss: 0.8638 - val_acc: 0.7853\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.80810\n",
            "Epoch 380/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5813 - acc: 0.8649 - val_loss: 1.2833 - val_acc: 0.6822\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.80810\n",
            "Epoch 381/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5930 - acc: 0.8623 - val_loss: 0.8587 - val_acc: 0.7855\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.80810\n",
            "Epoch 382/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5872 - acc: 0.8612 - val_loss: 1.0291 - val_acc: 0.7330\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.80810\n",
            "Epoch 383/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5826 - acc: 0.8608 - val_loss: 0.8872 - val_acc: 0.7920\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.80810\n",
            "Epoch 384/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5857 - acc: 0.8630 - val_loss: 1.2836 - val_acc: 0.6881\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.80810\n",
            "Epoch 385/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5808 - acc: 0.8656 - val_loss: 1.0603 - val_acc: 0.7387\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.80810\n",
            "Epoch 386/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5890 - acc: 0.8637 - val_loss: 0.9943 - val_acc: 0.7461\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.80810\n",
            "Epoch 387/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5912 - acc: 0.8598 - val_loss: 0.7531 - val_acc: 0.8089\n",
            "\n",
            "Epoch 00387: val_acc improved from 0.80810 to 0.80890, saving model to /content/saved_models/cifar10_ResNet32v1_model.387.h5\n",
            "Epoch 388/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5774 - acc: 0.8662 - val_loss: 1.0986 - val_acc: 0.7261\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.80890\n",
            "Epoch 389/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5825 - acc: 0.8606 - val_loss: 1.2112 - val_acc: 0.6940\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.80890\n",
            "Epoch 390/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5575 - acc: 0.8725 - val_loss: 1.1201 - val_acc: 0.7331\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.80890\n",
            "Epoch 391/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5801 - acc: 0.8648 - val_loss: 1.3447 - val_acc: 0.6884\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.80890\n",
            "Epoch 392/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5655 - acc: 0.8694 - val_loss: 1.4099 - val_acc: 0.6476\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.80890\n",
            "Epoch 393/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5866 - acc: 0.8605 - val_loss: 1.1253 - val_acc: 0.7265\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.80890\n",
            "Epoch 394/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5821 - acc: 0.8647 - val_loss: 0.9226 - val_acc: 0.7579\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.80890\n",
            "Epoch 395/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5812 - acc: 0.8631 - val_loss: 1.0010 - val_acc: 0.7522\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.80890\n",
            "Epoch 396/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.5674 - acc: 0.8671 - val_loss: 1.2607 - val_acc: 0.7027\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.80890\n",
            "Epoch 397/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5879 - acc: 0.8575 - val_loss: 1.2207 - val_acc: 0.6948\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.80890\n",
            "Epoch 398/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5783 - acc: 0.8689 - val_loss: 0.8983 - val_acc: 0.7640\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.80890\n",
            "Epoch 399/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5902 - acc: 0.8617 - val_loss: 1.1985 - val_acc: 0.7252\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.80890\n",
            "Epoch 400/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5913 - acc: 0.8580 - val_loss: 0.9605 - val_acc: 0.7618\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.80890\n",
            "Epoch 401/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5716 - acc: 0.8674 - val_loss: 1.1293 - val_acc: 0.7276\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.80890\n",
            "Epoch 402/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5044 - acc: 0.8916 - val_loss: 0.5780 - val_acc: 0.8662\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.80890 to 0.86620, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4588 - acc: 0.9076 - val_loss: 0.5598 - val_acc: 0.8699\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.86620 to 0.86990, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.4440 - acc: 0.9128 - val_loss: 0.5289 - val_acc: 0.8836\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.86990 to 0.88360, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4442 - acc: 0.9119 - val_loss: 0.5435 - val_acc: 0.8804\n",
            "\n",
            "Epoch 00405: val_acc did not improve from 0.88360\n",
            "Epoch 406/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4293 - acc: 0.9200 - val_loss: 0.5135 - val_acc: 0.8870\n",
            "\n",
            "Epoch 00406: val_acc improved from 0.88360 to 0.88700, saving model to /content/saved_models/cifar10_ResNet32v1_model.406.h5\n",
            "Epoch 407/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4298 - acc: 0.9147 - val_loss: 0.5042 - val_acc: 0.8926\n",
            "\n",
            "Epoch 00407: val_acc improved from 0.88700 to 0.89260, saving model to /content/saved_models/cifar10_ResNet32v1_model.407.h5\n",
            "Epoch 408/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4159 - acc: 0.9233 - val_loss: 0.5044 - val_acc: 0.8933\n",
            "\n",
            "Epoch 00408: val_acc improved from 0.89260 to 0.89330, saving model to /content/saved_models/cifar10_ResNet32v1_model.408.h5\n",
            "Epoch 409/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4267 - acc: 0.9146 - val_loss: 0.5097 - val_acc: 0.8893\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.89330\n",
            "Epoch 410/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4063 - acc: 0.9241 - val_loss: 0.5064 - val_acc: 0.8936\n",
            "\n",
            "Epoch 00410: val_acc improved from 0.89330 to 0.89360, saving model to /content/saved_models/cifar10_ResNet32v1_model.410.h5\n",
            "Epoch 411/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.3999 - acc: 0.9256 - val_loss: 0.4966 - val_acc: 0.8957\n",
            "\n",
            "Epoch 00411: val_acc improved from 0.89360 to 0.89570, saving model to /content/saved_models/cifar10_ResNet32v1_model.411.h5\n",
            "Epoch 412/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.4010 - acc: 0.9256 - val_loss: 0.4852 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00412: val_acc improved from 0.89570 to 0.89950, saving model to /content/saved_models/cifar10_ResNet32v1_model.412.h5\n",
            "Epoch 413/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3977 - acc: 0.9260 - val_loss: 0.4935 - val_acc: 0.9007\n",
            "\n",
            "Epoch 00413: val_acc improved from 0.89950 to 0.90070, saving model to /content/saved_models/cifar10_ResNet32v1_model.413.h5\n",
            "Epoch 414/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4061 - acc: 0.9272 - val_loss: 0.5057 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.90070\n",
            "Epoch 415/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3989 - acc: 0.9269 - val_loss: 0.4825 - val_acc: 0.9022\n",
            "\n",
            "Epoch 00415: val_acc improved from 0.90070 to 0.90220, saving model to /content/saved_models/cifar10_ResNet32v1_model.415.h5\n",
            "Epoch 416/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3933 - acc: 0.9297 - val_loss: 0.4853 - val_acc: 0.9016\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.90220\n",
            "Epoch 417/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3872 - acc: 0.9297 - val_loss: 0.4977 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.90220\n",
            "Epoch 418/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3928 - acc: 0.9268 - val_loss: 0.4737 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00418: val_acc improved from 0.90220 to 0.90610, saving model to /content/saved_models/cifar10_ResNet32v1_model.418.h5\n",
            "Epoch 419/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3807 - acc: 0.9324 - val_loss: 0.4829 - val_acc: 0.9007\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.90610\n",
            "Epoch 420/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3777 - acc: 0.9337 - val_loss: 0.4910 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.90610\n",
            "Epoch 421/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3838 - acc: 0.9318 - val_loss: 0.4936 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00421: val_acc did not improve from 0.90610\n",
            "Epoch 422/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3777 - acc: 0.9330 - val_loss: 0.4794 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00422: val_acc did not improve from 0.90610\n",
            "Epoch 423/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.3774 - acc: 0.9334 - val_loss: 0.4870 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.90610\n",
            "Epoch 424/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3704 - acc: 0.9369 - val_loss: 0.4928 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.90610\n",
            "Epoch 425/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3718 - acc: 0.9308 - val_loss: 0.5104 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.90610\n",
            "Epoch 426/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3699 - acc: 0.9362 - val_loss: 0.4696 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.90610\n",
            "Epoch 427/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3662 - acc: 0.9387 - val_loss: 0.4807 - val_acc: 0.9048\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.90610\n",
            "Epoch 428/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3713 - acc: 0.9350 - val_loss: 0.4895 - val_acc: 0.9003\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.90610\n",
            "Epoch 429/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3635 - acc: 0.9381 - val_loss: 0.4738 - val_acc: 0.9057\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.90610\n",
            "Epoch 430/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3664 - acc: 0.9399 - val_loss: 0.4846 - val_acc: 0.9039\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.90610\n",
            "Epoch 431/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3683 - acc: 0.9366 - val_loss: 0.4789 - val_acc: 0.9042\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.90610\n",
            "Epoch 432/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3644 - acc: 0.9384 - val_loss: 0.4765 - val_acc: 0.9048\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.90610\n",
            "Epoch 433/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3683 - acc: 0.9383 - val_loss: 0.4799 - val_acc: 0.9041\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.90610\n",
            "Epoch 434/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3590 - acc: 0.9406 - val_loss: 0.4715 - val_acc: 0.9055\n",
            "\n",
            "Epoch 00434: val_acc did not improve from 0.90610\n",
            "Epoch 435/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3516 - acc: 0.9424 - val_loss: 0.4673 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00435: val_acc improved from 0.90610 to 0.90690, saving model to /content/saved_models/cifar10_ResNet32v1_model.435.h5\n",
            "Epoch 436/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3607 - acc: 0.9384 - val_loss: 0.4740 - val_acc: 0.9033\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.90690\n",
            "Epoch 437/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3597 - acc: 0.9398 - val_loss: 0.4663 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00437: val_acc improved from 0.90690 to 0.90980, saving model to /content/saved_models/cifar10_ResNet32v1_model.437.h5\n",
            "Epoch 438/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3509 - acc: 0.9422 - val_loss: 0.4924 - val_acc: 0.9034\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.90980\n",
            "Epoch 439/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3553 - acc: 0.9397 - val_loss: 0.4897 - val_acc: 0.9041\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.90980\n",
            "Epoch 440/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3642 - acc: 0.9393 - val_loss: 0.4713 - val_acc: 0.9080\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.90980\n",
            "Epoch 441/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3455 - acc: 0.9438 - val_loss: 0.4720 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.90980\n",
            "Epoch 442/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3506 - acc: 0.9437 - val_loss: 0.4873 - val_acc: 0.9017\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.90980\n",
            "Epoch 443/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3458 - acc: 0.9438 - val_loss: 0.4916 - val_acc: 0.9009\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.90980\n",
            "Epoch 444/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3549 - acc: 0.9409 - val_loss: 0.4643 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.90980\n",
            "Epoch 445/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3425 - acc: 0.9446 - val_loss: 0.4718 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.90980\n",
            "Epoch 446/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3479 - acc: 0.9429 - val_loss: 0.4846 - val_acc: 0.9005\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.90980\n",
            "Epoch 447/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3480 - acc: 0.9422 - val_loss: 0.4877 - val_acc: 0.9016\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.90980\n",
            "Epoch 448/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3378 - acc: 0.9474 - val_loss: 0.4932 - val_acc: 0.9004\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.90980\n",
            "Epoch 449/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3463 - acc: 0.9419 - val_loss: 0.4577 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00449: val_acc improved from 0.90980 to 0.91190, saving model to /content/saved_models/cifar10_ResNet32v1_model.449.h5\n",
            "Epoch 450/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3391 - acc: 0.9470 - val_loss: 0.4653 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.91190\n",
            "Epoch 451/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3380 - acc: 0.9470 - val_loss: 0.4660 - val_acc: 0.9060\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.91190\n",
            "Epoch 452/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3353 - acc: 0.9460 - val_loss: 0.4649 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.91190\n",
            "Epoch 453/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3299 - acc: 0.9492 - val_loss: 0.4651 - val_acc: 0.9071\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.91190\n",
            "Epoch 454/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3330 - acc: 0.9473 - val_loss: 0.4904 - val_acc: 0.9004\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.91190\n",
            "Epoch 455/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3347 - acc: 0.9468 - val_loss: 0.4678 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.91190\n",
            "Epoch 456/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3422 - acc: 0.9445 - val_loss: 0.4691 - val_acc: 0.9050\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.91190\n",
            "Epoch 457/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3279 - acc: 0.9493 - val_loss: 0.4907 - val_acc: 0.9015\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.91190\n",
            "Epoch 458/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3331 - acc: 0.9486 - val_loss: 0.4751 - val_acc: 0.9071\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.91190\n",
            "Epoch 459/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3330 - acc: 0.9470 - val_loss: 0.4803 - val_acc: 0.9047\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.91190\n",
            "Epoch 460/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3262 - acc: 0.9523 - val_loss: 0.4628 - val_acc: 0.9074\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.91190\n",
            "Epoch 461/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3259 - acc: 0.9505 - val_loss: 0.4876 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.91190\n",
            "Epoch 462/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3253 - acc: 0.9517 - val_loss: 0.5036 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.91190\n",
            "Epoch 463/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3278 - acc: 0.9490 - val_loss: 0.5049 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.91190\n",
            "Epoch 464/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3351 - acc: 0.9461 - val_loss: 0.4777 - val_acc: 0.9072\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.91190\n",
            "Epoch 465/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3297 - acc: 0.9485 - val_loss: 0.4726 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.91190\n",
            "Epoch 466/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3263 - acc: 0.9485 - val_loss: 0.4889 - val_acc: 0.9058\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.91190\n",
            "Epoch 467/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3252 - acc: 0.9499 - val_loss: 0.4842 - val_acc: 0.9050\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.91190\n",
            "Epoch 468/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3320 - acc: 0.9465 - val_loss: 0.4789 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.91190\n",
            "Epoch 469/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3182 - acc: 0.9553 - val_loss: 0.4730 - val_acc: 0.9083\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.91190\n",
            "Epoch 470/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3159 - acc: 0.9535 - val_loss: 0.4783 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.91190\n",
            "Epoch 471/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3256 - acc: 0.9505 - val_loss: 0.4985 - val_acc: 0.9009\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.91190\n",
            "Epoch 472/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3220 - acc: 0.9511 - val_loss: 0.4725 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.91190\n",
            "Epoch 473/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3250 - acc: 0.9486 - val_loss: 0.4861 - val_acc: 0.9042\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.91190\n",
            "Epoch 474/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3127 - acc: 0.9540 - val_loss: 0.4747 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.91190\n",
            "Epoch 475/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3098 - acc: 0.9555 - val_loss: 0.4774 - val_acc: 0.9074\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.91190\n",
            "Epoch 476/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3117 - acc: 0.9517 - val_loss: 0.4948 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.91190\n",
            "Epoch 477/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3142 - acc: 0.9535 - val_loss: 0.4937 - val_acc: 0.9046\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.91190\n",
            "Epoch 478/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3185 - acc: 0.9526 - val_loss: 0.4976 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.91190\n",
            "Epoch 479/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3230 - acc: 0.9505 - val_loss: 0.4731 - val_acc: 0.9071\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.91190\n",
            "Epoch 480/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3231 - acc: 0.9537 - val_loss: 0.5154 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.91190\n",
            "Epoch 481/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3258 - acc: 0.9478 - val_loss: 0.4659 - val_acc: 0.9090\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.91190\n",
            "Epoch 482/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3144 - acc: 0.9517 - val_loss: 0.4699 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.91190\n",
            "Epoch 483/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3113 - acc: 0.9555 - val_loss: 0.4670 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.91190\n",
            "Epoch 484/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3187 - acc: 0.9518 - val_loss: 0.4782 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.91190\n",
            "Epoch 485/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3165 - acc: 0.9525 - val_loss: 0.4890 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.91190\n",
            "Epoch 486/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3118 - acc: 0.9558 - val_loss: 0.4916 - val_acc: 0.9022\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.91190\n",
            "Epoch 487/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3095 - acc: 0.9548 - val_loss: 0.4666 - val_acc: 0.9083\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.91190\n",
            "Epoch 488/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3146 - acc: 0.9532 - val_loss: 0.4917 - val_acc: 0.9051\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.91190\n",
            "Epoch 489/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2996 - acc: 0.9594 - val_loss: 0.4755 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.91190\n",
            "Epoch 490/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3146 - acc: 0.9530 - val_loss: 0.4709 - val_acc: 0.9080\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.91190\n",
            "Epoch 491/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3118 - acc: 0.9514 - val_loss: 0.4791 - val_acc: 0.9083\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.91190\n",
            "Epoch 492/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3108 - acc: 0.9553 - val_loss: 0.5105 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.91190\n",
            "Epoch 493/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3058 - acc: 0.9565 - val_loss: 0.4890 - val_acc: 0.9040\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.91190\n",
            "Epoch 494/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3184 - acc: 0.9528 - val_loss: 0.4746 - val_acc: 0.9042\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.91190\n",
            "Epoch 495/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3024 - acc: 0.9601 - val_loss: 0.4588 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.91190\n",
            "Epoch 496/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3061 - acc: 0.9550 - val_loss: 0.4703 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.91190\n",
            "Epoch 497/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3163 - acc: 0.9540 - val_loss: 0.4627 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00497: val_acc improved from 0.91190 to 0.91280, saving model to /content/saved_models/cifar10_ResNet32v1_model.497.h5\n",
            "Epoch 498/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3089 - acc: 0.9560 - val_loss: 0.4808 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.91280\n",
            "Epoch 499/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3110 - acc: 0.9549 - val_loss: 0.4715 - val_acc: 0.9075\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.91280\n",
            "Epoch 500/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3054 - acc: 0.9558 - val_loss: 0.4798 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.91280\n",
            "Epoch 501/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3007 - acc: 0.9589 - val_loss: 0.4707 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.91280\n",
            "Epoch 502/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2994 - acc: 0.9585 - val_loss: 0.4755 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.91280\n",
            "Epoch 503/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2977 - acc: 0.9597 - val_loss: 0.4879 - val_acc: 0.9080\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.91280\n",
            "Epoch 504/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2952 - acc: 0.9611 - val_loss: 0.4697 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.91280\n",
            "Epoch 505/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3055 - acc: 0.9561 - val_loss: 0.4936 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.91280\n",
            "Epoch 506/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3091 - acc: 0.9534 - val_loss: 0.4968 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.91280\n",
            "Epoch 507/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3031 - acc: 0.9574 - val_loss: 0.4669 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.91280\n",
            "Epoch 508/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2982 - acc: 0.9611 - val_loss: 0.4614 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.91280\n",
            "Epoch 509/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3061 - acc: 0.9573 - val_loss: 0.4796 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.91280\n",
            "Epoch 510/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3032 - acc: 0.9593 - val_loss: 0.4657 - val_acc: 0.9134\n",
            "\n",
            "Epoch 00510: val_acc improved from 0.91280 to 0.91340, saving model to /content/saved_models/cifar10_ResNet32v1_model.510.h5\n",
            "Epoch 511/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2967 - acc: 0.9596 - val_loss: 0.4778 - val_acc: 0.9094\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.91340\n",
            "Epoch 512/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2965 - acc: 0.9617 - val_loss: 0.4834 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.91340\n",
            "Epoch 513/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2944 - acc: 0.9604 - val_loss: 0.4813 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.91340\n",
            "Epoch 514/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2905 - acc: 0.9610 - val_loss: 0.4954 - val_acc: 0.9051\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.91340\n",
            "Epoch 515/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2973 - acc: 0.9600 - val_loss: 0.4966 - val_acc: 0.9034\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.91340\n",
            "Epoch 516/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3062 - acc: 0.9565 - val_loss: 0.4892 - val_acc: 0.9057\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.91340\n",
            "Epoch 517/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3009 - acc: 0.9575 - val_loss: 0.4968 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.91340\n",
            "Epoch 518/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2978 - acc: 0.9579 - val_loss: 0.4774 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.91340\n",
            "Epoch 519/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2922 - acc: 0.9615 - val_loss: 0.4732 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.91340\n",
            "Epoch 520/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2952 - acc: 0.9621 - val_loss: 0.4867 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.91340\n",
            "Epoch 521/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2923 - acc: 0.9605 - val_loss: 0.4914 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.91340\n",
            "Epoch 522/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2974 - acc: 0.9583 - val_loss: 0.4945 - val_acc: 0.9078\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.91340\n",
            "Epoch 523/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2899 - acc: 0.9620 - val_loss: 0.4896 - val_acc: 0.9072\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.91340\n",
            "Epoch 524/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2899 - acc: 0.9611 - val_loss: 0.4742 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.91340\n",
            "Epoch 525/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2980 - acc: 0.9594 - val_loss: 0.4937 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.91340\n",
            "Epoch 526/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2858 - acc: 0.9637 - val_loss: 0.4803 - val_acc: 0.9085\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.91340\n",
            "Epoch 527/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3002 - acc: 0.9571 - val_loss: 0.5085 - val_acc: 0.9042\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.91340\n",
            "Epoch 528/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2994 - acc: 0.9570 - val_loss: 0.4947 - val_acc: 0.9042\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.91340\n",
            "Epoch 529/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2919 - acc: 0.9611 - val_loss: 0.4838 - val_acc: 0.9088\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.91340\n",
            "Epoch 530/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2922 - acc: 0.9609 - val_loss: 0.5000 - val_acc: 0.9038\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.91340\n",
            "Epoch 531/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2989 - acc: 0.9597 - val_loss: 0.4964 - val_acc: 0.9049\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.91340\n",
            "Epoch 532/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2903 - acc: 0.9601 - val_loss: 0.4869 - val_acc: 0.9071\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.91340\n",
            "Epoch 533/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2914 - acc: 0.9612 - val_loss: 0.4877 - val_acc: 0.9053\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.91340\n",
            "Epoch 534/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2869 - acc: 0.9631 - val_loss: 0.4737 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.91340\n",
            "Epoch 535/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2849 - acc: 0.9621 - val_loss: 0.4735 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.91340\n",
            "Epoch 536/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2781 - acc: 0.9664 - val_loss: 0.4869 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.91340\n",
            "Epoch 537/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2916 - acc: 0.9611 - val_loss: 0.4897 - val_acc: 0.9070\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.91340\n",
            "Epoch 538/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2892 - acc: 0.9626 - val_loss: 0.4835 - val_acc: 0.9096\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.91340\n",
            "Epoch 539/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2940 - acc: 0.9588 - val_loss: 0.4875 - val_acc: 0.9051\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.91340\n",
            "Epoch 540/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2815 - acc: 0.9633 - val_loss: 0.4813 - val_acc: 0.9102\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.91340\n",
            "Epoch 541/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2940 - acc: 0.9577 - val_loss: 0.4838 - val_acc: 0.9071\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.91340\n",
            "Epoch 542/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2926 - acc: 0.9622 - val_loss: 0.4987 - val_acc: 0.9018\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.91340\n",
            "Epoch 543/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2868 - acc: 0.9618 - val_loss: 0.4708 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.91340\n",
            "Epoch 544/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2882 - acc: 0.9633 - val_loss: 0.4774 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.91340\n",
            "Epoch 545/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2807 - acc: 0.9640 - val_loss: 0.5024 - val_acc: 0.9030\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.91340\n",
            "Epoch 546/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2870 - acc: 0.9608 - val_loss: 0.5088 - val_acc: 0.9029\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.91340\n",
            "Epoch 547/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2847 - acc: 0.9630 - val_loss: 0.4964 - val_acc: 0.9048\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.91340\n",
            "Epoch 548/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2853 - acc: 0.9616 - val_loss: 0.4674 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.91340\n",
            "Epoch 549/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2818 - acc: 0.9654 - val_loss: 0.4867 - val_acc: 0.9050\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.91340\n",
            "Epoch 550/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2786 - acc: 0.9645 - val_loss: 0.4734 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.91340\n",
            "Epoch 551/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2834 - acc: 0.9643 - val_loss: 0.4903 - val_acc: 0.9080\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.91340\n",
            "Epoch 552/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2785 - acc: 0.9649 - val_loss: 0.5087 - val_acc: 0.9051\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.91340\n",
            "Epoch 553/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2799 - acc: 0.9636 - val_loss: 0.4853 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.91340\n",
            "Epoch 554/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2811 - acc: 0.9641 - val_loss: 0.4844 - val_acc: 0.9079\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.91340\n",
            "Epoch 555/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2835 - acc: 0.9635 - val_loss: 0.5457 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.91340\n",
            "Epoch 556/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2754 - acc: 0.9674 - val_loss: 0.4873 - val_acc: 0.9052\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.91340\n",
            "Epoch 557/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2769 - acc: 0.9665 - val_loss: 0.4946 - val_acc: 0.9084\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.91340\n",
            "Epoch 558/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2843 - acc: 0.9626 - val_loss: 0.5256 - val_acc: 0.9007\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.91340\n",
            "Epoch 559/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2843 - acc: 0.9645 - val_loss: 0.4706 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00559: val_acc improved from 0.91340 to 0.91390, saving model to /content/saved_models/cifar10_ResNet32v1_model.559.h5\n",
            "Epoch 560/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2791 - acc: 0.9658 - val_loss: 0.4776 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.91390\n",
            "Epoch 561/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2840 - acc: 0.9650 - val_loss: 0.4834 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.91390\n",
            "Epoch 562/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2823 - acc: 0.9646 - val_loss: 0.4996 - val_acc: 0.9034\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.91390\n",
            "Epoch 563/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2741 - acc: 0.9679 - val_loss: 0.4721 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.91390\n",
            "Epoch 564/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2724 - acc: 0.9670 - val_loss: 0.4933 - val_acc: 0.9081\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.91390\n",
            "Epoch 565/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2801 - acc: 0.9648 - val_loss: 0.4900 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.91390\n",
            "Epoch 566/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2860 - acc: 0.9626 - val_loss: 0.4971 - val_acc: 0.9068\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.91390\n",
            "Epoch 567/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2838 - acc: 0.9633 - val_loss: 0.4845 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.91390\n",
            "Epoch 568/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2815 - acc: 0.9620 - val_loss: 0.4859 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.91390\n",
            "Epoch 569/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2758 - acc: 0.9664 - val_loss: 0.4858 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.91390\n",
            "Epoch 570/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2727 - acc: 0.9663 - val_loss: 0.5184 - val_acc: 0.9030\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.91390\n",
            "Epoch 571/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2843 - acc: 0.9633 - val_loss: 0.4992 - val_acc: 0.9058\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.91390\n",
            "Epoch 572/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2812 - acc: 0.9657 - val_loss: 0.4802 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.91390\n",
            "Epoch 573/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2781 - acc: 0.9663 - val_loss: 0.4747 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.91390\n",
            "Epoch 574/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2715 - acc: 0.9669 - val_loss: 0.5118 - val_acc: 0.9008\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.91390\n",
            "Epoch 575/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2745 - acc: 0.9668 - val_loss: 0.5052 - val_acc: 0.9051\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.91390\n",
            "Epoch 576/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2792 - acc: 0.9658 - val_loss: 0.4946 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.91390\n",
            "Epoch 577/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2767 - acc: 0.9662 - val_loss: 0.5012 - val_acc: 0.9072\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.91390\n",
            "Epoch 578/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2783 - acc: 0.9666 - val_loss: 0.5113 - val_acc: 0.9035\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.91390\n",
            "Epoch 579/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2736 - acc: 0.9671 - val_loss: 0.4763 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.91390\n",
            "Epoch 580/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2748 - acc: 0.9664 - val_loss: 0.5064 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.91390\n",
            "Epoch 581/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2773 - acc: 0.9651 - val_loss: 0.5095 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.91390\n",
            "Epoch 582/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2760 - acc: 0.9677 - val_loss: 0.4815 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.91390\n",
            "Epoch 583/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2741 - acc: 0.9666 - val_loss: 0.5147 - val_acc: 0.9048\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.91390\n",
            "Epoch 584/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2711 - acc: 0.9679 - val_loss: 0.5137 - val_acc: 0.9055\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.91390\n",
            "Epoch 585/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2735 - acc: 0.9667 - val_loss: 0.5089 - val_acc: 0.9018\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.91390\n",
            "Epoch 586/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2691 - acc: 0.9676 - val_loss: 0.5011 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.91390\n",
            "Epoch 587/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2750 - acc: 0.9675 - val_loss: 0.5073 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.91390\n",
            "Epoch 588/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2782 - acc: 0.9648 - val_loss: 0.5429 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.91390\n",
            "Epoch 589/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2700 - acc: 0.9700 - val_loss: 0.4948 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.91390\n",
            "Epoch 590/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2770 - acc: 0.9646 - val_loss: 0.5046 - val_acc: 0.9075\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.91390\n",
            "Epoch 591/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2732 - acc: 0.9652 - val_loss: 0.4956 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.91390\n",
            "Epoch 592/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2711 - acc: 0.9685 - val_loss: 0.4984 - val_acc: 0.9081\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.91390\n",
            "Epoch 593/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2730 - acc: 0.9674 - val_loss: 0.5323 - val_acc: 0.8977\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.91390\n",
            "Epoch 594/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2655 - acc: 0.9698 - val_loss: 0.5189 - val_acc: 0.9047\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.91390\n",
            "Epoch 595/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2829 - acc: 0.9634 - val_loss: 0.5438 - val_acc: 0.8970\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.91390\n",
            "Epoch 596/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2711 - acc: 0.9670 - val_loss: 0.5628 - val_acc: 0.8932\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.91390\n",
            "Epoch 597/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2717 - acc: 0.9697 - val_loss: 0.5212 - val_acc: 0.9046\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.91390\n",
            "Epoch 598/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2618 - acc: 0.9719 - val_loss: 0.4944 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.91390\n",
            "Epoch 599/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2663 - acc: 0.9700 - val_loss: 0.4936 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.91390\n",
            "Epoch 600/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2654 - acc: 0.9711 - val_loss: 0.5329 - val_acc: 0.9002\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.91390\n",
            "Epoch 601/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2712 - acc: 0.9689 - val_loss: 0.4855 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.91390\n",
            "Epoch 602/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2674 - acc: 0.9683 - val_loss: 0.4767 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00602: val_acc did not improve from 0.91390\n",
            "Epoch 603/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2705 - acc: 0.9680 - val_loss: 0.4731 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00603: val_acc did not improve from 0.91390\n",
            "Epoch 604/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2628 - acc: 0.9698 - val_loss: 0.4716 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00604: val_acc did not improve from 0.91390\n",
            "Epoch 605/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2678 - acc: 0.9685 - val_loss: 0.4719 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00605: val_acc did not improve from 0.91390\n",
            "Epoch 606/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2611 - acc: 0.9719 - val_loss: 0.4707 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00606: val_acc did not improve from 0.91390\n",
            "Epoch 607/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2605 - acc: 0.9740 - val_loss: 0.4692 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00607: val_acc did not improve from 0.91390\n",
            "Epoch 608/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2623 - acc: 0.9710 - val_loss: 0.4689 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00608: val_acc did not improve from 0.91390\n",
            "Epoch 609/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2660 - acc: 0.9694 - val_loss: 0.4687 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00609: val_acc did not improve from 0.91390\n",
            "Epoch 610/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2647 - acc: 0.9703 - val_loss: 0.4686 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00610: val_acc did not improve from 0.91390\n",
            "Epoch 611/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2608 - acc: 0.9724 - val_loss: 0.4678 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.91390\n",
            "Epoch 612/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2642 - acc: 0.9691 - val_loss: 0.4680 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00612: val_acc did not improve from 0.91390\n",
            "Epoch 613/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2660 - acc: 0.9714 - val_loss: 0.4671 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00613: val_acc did not improve from 0.91390\n",
            "Epoch 614/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2650 - acc: 0.9702 - val_loss: 0.4670 - val_acc: 0.9141\n",
            "\n",
            "Epoch 00614: val_acc improved from 0.91390 to 0.91410, saving model to /content/saved_models/cifar10_ResNet32v1_model.614.h5\n",
            "Epoch 615/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2667 - acc: 0.9684 - val_loss: 0.4667 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.91410\n",
            "Epoch 616/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2598 - acc: 0.9718 - val_loss: 0.4667 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00616: val_acc did not improve from 0.91410\n",
            "Epoch 617/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2544 - acc: 0.9739 - val_loss: 0.4663 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.91410\n",
            "Epoch 618/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2624 - acc: 0.9705 - val_loss: 0.4658 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00618: val_acc improved from 0.91410 to 0.91450, saving model to /content/saved_models/cifar10_ResNet32v1_model.618.h5\n",
            "Epoch 619/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2631 - acc: 0.9696 - val_loss: 0.4657 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00619: val_acc improved from 0.91450 to 0.91470, saving model to /content/saved_models/cifar10_ResNet32v1_model.619.h5\n",
            "Epoch 620/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2668 - acc: 0.9702 - val_loss: 0.4652 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.91470\n",
            "Epoch 621/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2602 - acc: 0.9749 - val_loss: 0.4650 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00621: val_acc did not improve from 0.91470\n",
            "Epoch 622/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2627 - acc: 0.9694 - val_loss: 0.4651 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.91470\n",
            "Epoch 623/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2580 - acc: 0.9743 - val_loss: 0.4643 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00623: val_acc improved from 0.91470 to 0.91530, saving model to /content/saved_models/cifar10_ResNet32v1_model.623.h5\n",
            "Epoch 624/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2601 - acc: 0.9718 - val_loss: 0.4637 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.91530\n",
            "Epoch 625/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2585 - acc: 0.9728 - val_loss: 0.4638 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.91530\n",
            "Epoch 626/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2586 - acc: 0.9712 - val_loss: 0.4638 - val_acc: 0.9150\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.91530\n",
            "Epoch 627/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2613 - acc: 0.9717 - val_loss: 0.4640 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00627: val_acc did not improve from 0.91530\n",
            "Epoch 628/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2634 - acc: 0.9720 - val_loss: 0.4637 - val_acc: 0.9150\n",
            "\n",
            "Epoch 00628: val_acc did not improve from 0.91530\n",
            "Epoch 629/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2608 - acc: 0.9719 - val_loss: 0.4635 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.91530\n",
            "Epoch 630/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2642 - acc: 0.9707 - val_loss: 0.4631 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00630: val_acc did not improve from 0.91530\n",
            "Epoch 631/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2570 - acc: 0.9723 - val_loss: 0.4626 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00631: val_acc did not improve from 0.91530\n",
            "Epoch 632/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2533 - acc: 0.9750 - val_loss: 0.4618 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00632: val_acc did not improve from 0.91530\n",
            "Epoch 633/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2558 - acc: 0.9752 - val_loss: 0.4623 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.91530\n",
            "Epoch 634/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2689 - acc: 0.9673 - val_loss: 0.4633 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.91530\n",
            "Epoch 635/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2550 - acc: 0.9751 - val_loss: 0.4623 - val_acc: 0.9150\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.91530\n",
            "Epoch 636/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2578 - acc: 0.9742 - val_loss: 0.4619 - val_acc: 0.9146\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.91530\n",
            "Epoch 637/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2608 - acc: 0.9729 - val_loss: 0.4621 - val_acc: 0.9146\n",
            "\n",
            "Epoch 00637: val_acc did not improve from 0.91530\n",
            "Epoch 638/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2597 - acc: 0.9718 - val_loss: 0.4614 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.91530\n",
            "Epoch 639/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2633 - acc: 0.9716 - val_loss: 0.4621 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.91530\n",
            "Epoch 640/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2562 - acc: 0.9745 - val_loss: 0.4618 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.91530\n",
            "Epoch 641/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2572 - acc: 0.9733 - val_loss: 0.4614 - val_acc: 0.9146\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.91530\n",
            "Epoch 642/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2579 - acc: 0.9723 - val_loss: 0.4615 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.91530\n",
            "Epoch 643/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2577 - acc: 0.9726 - val_loss: 0.4616 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.91530\n",
            "Epoch 644/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2557 - acc: 0.9743 - val_loss: 0.4615 - val_acc: 0.9146\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.91530\n",
            "Epoch 645/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2627 - acc: 0.9718 - val_loss: 0.4617 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00645: val_acc did not improve from 0.91530\n",
            "Epoch 646/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2595 - acc: 0.9726 - val_loss: 0.4614 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00646: val_acc improved from 0.91530 to 0.91550, saving model to /content/saved_models/cifar10_ResNet32v1_model.646.h5\n",
            "Epoch 647/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2620 - acc: 0.9717 - val_loss: 0.4619 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00647: val_acc did not improve from 0.91550\n",
            "Epoch 648/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2539 - acc: 0.9750 - val_loss: 0.4610 - val_acc: 0.9150\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.91550\n",
            "Epoch 649/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2613 - acc: 0.9715 - val_loss: 0.4616 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.91550\n",
            "Epoch 650/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2554 - acc: 0.9749 - val_loss: 0.4614 - val_acc: 0.9146\n",
            "\n",
            "Epoch 00650: val_acc did not improve from 0.91550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "SNgPzIq_EIzJ",
        "outputId": "44f8e530-f07c-45ae-d9c0-95d835f83dc5"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('trainHistoryDict_clip_1', \"rb\"))\n",
        "functions.plot_loss_acc(history, 4, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbngM-hVG4vh",
        "outputId": "f065386d-db56-4660-81c4-bbfbe0bb5200"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9146000146865845"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEaedUbmEL9j",
        "outputId": "04a2e5e4-47f3-42d7-925e-4af04e73efaa"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08539998531341553"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJiW0sKS4Tgp"
      },
      "source": [
        "#### Plotting final graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "Uep0tPcFpcuW",
        "outputId": "733c972e-32a5-455e-c2bf-9703453dc56a"
      },
      "source": [
        "plot_final_graph(\"compress_first_29_\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ifU-I4geZq8"
      },
      "source": [
        "### decomposition_rank=29 & compress_first = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPvHJjYAfVq8"
      },
      "source": [
        "#### Model without clipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwFJL_NgfVrA",
        "outputId": "aa714047-3a75-48a2-9412-d7d98350d691"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(\n",
        "    input_shape, conv_layer = functions.ConvDecomposed2D, decomposition_rank=29)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d (ConvDecompos (None, 32, 32, 16)   713         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv_decomposed2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_1 (ConvDecomp (None, 32, 32, 16)   2832        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv_decomposed2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_2 (ConvDecomp (None, 32, 32, 16)   2832        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv_decomposed2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 16)   0           activation[0][0]                 \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 16)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_3 (ConvDecomp (None, 32, 32, 16)   2832        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv_decomposed2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_4 (ConvDecomp (None, 32, 32, 16)   2832        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv_decomposed2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 16)   0           activation_2[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_5 (ConvDecomp (None, 32, 32, 16)   2832        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv_decomposed2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_6 (ConvDecomp (None, 32, 32, 16)   2832        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv_decomposed2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 16)   0           activation_4[0][0]               \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_7 (ConvDecomp (None, 32, 32, 16)   2832        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv_decomposed2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 16)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_8 (ConvDecomp (None, 32, 32, 16)   2832        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv_decomposed2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 16)   0           activation_6[0][0]               \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_9 (ConvDecomp (None, 32, 32, 16)   2832        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv_decomposed2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_10 (ConvDecom (None, 32, 32, 16)   2832        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          conv_decomposed2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 32, 32, 16)   0           activation_8[0][0]               \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 16)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_11 (ConvDecom (None, 16, 16, 32)   5392        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_12 (ConvDecom (None, 16, 16, 32)   9457        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_13 (ConvDecom (None, 16, 16, 32)   1680        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 32)   0           conv_decomposed2d_13[0][0]       \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_14 (ConvDecom (None, 16, 16, 32)   9457        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_15 (ConvDecom (None, 16, 16, 32)   9457        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 32)   0           activation_12[0][0]              \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_16 (ConvDecom (None, 16, 16, 32)   9457        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 32)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_17 (ConvDecom (None, 16, 16, 32)   9457        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 16, 16, 32)   0           activation_14[0][0]              \n",
            "                                                                 batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 32)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_18 (ConvDecom (None, 16, 16, 32)   9457        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_19 (ConvDecom (None, 16, 16, 32)   9457        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 16, 16, 32)   0           activation_16[0][0]              \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 32)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_20 (ConvDecom (None, 16, 16, 32)   9457        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 32)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_21 (ConvDecom (None, 16, 16, 32)   9457        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         conv_decomposed2d_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 16, 16, 32)   0           activation_18[0][0]              \n",
            "                                                                 batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_22 (ConvDecom (None, 8, 8, 64)     10417       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8, 8, 64)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_23 (ConvDecom (None, 8, 8, 64)     11345       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_24 (ConvDecom (None, 8, 8, 64)     3689        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 8, 64)     0           conv_decomposed2d_24[0][0]       \n",
            "                                                                 batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 8, 64)     0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_25 (ConvDecom (None, 8, 8, 64)     11345       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 8, 8, 64)     0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_26 (ConvDecom (None, 8, 8, 64)     11345       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 8, 8, 64)     0           activation_22[0][0]              \n",
            "                                                                 batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 8, 8, 64)     0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_27 (ConvDecom (None, 8, 8, 64)     11345       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_27[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 8, 8, 64)     0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_28 (ConvDecom (None, 8, 8, 64)     11345       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 8, 64)     0           activation_24[0][0]              \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 64)     0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_29 (ConvDecom (None, 8, 8, 64)     11345       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 64)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_30 (ConvDecom (None, 8, 8, 64)     11345       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_30[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 8, 8, 64)     0           activation_26[0][0]              \n",
            "                                                                 batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 64)     0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_31 (ConvDecom (None, 8, 8, 64)     11345       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_31[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 64)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv_decomposed2d_32 (ConvDecom (None, 8, 8, 64)     11345       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         conv_decomposed2d_32[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 8, 8, 64)     0           activation_28[0][0]              \n",
            "                                                                 batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 64)     0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 64)     0           activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 64)           0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           650         flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 242,623\n",
            "Trainable params: 240,351\n",
            "Non-trainable params: 2,272\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxG6i_vYfVrB",
        "outputId": "285bb713-3f87-442b-afde-23e4eeb95bd9"
      },
      "source": [
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'trainHistoryDict', steps_per_epoch=100, batch_size=100,\n",
        "                       epochs=650)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 51s 134ms/step - loss: 2.7297 - acc: 0.2848 - val_loss: 8.9219 - val_acc: 0.1304\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.13040, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 2.2016 - acc: 0.3899 - val_loss: 2.3514 - val_acc: 0.3609\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.13040 to 0.36090, saving model to /content/saved_models/cifar10_ResNet32v1_model.002.h5\n",
            "Epoch 3/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 2.0882 - acc: 0.4309 - val_loss: 3.3242 - val_acc: 0.2164\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.36090\n",
            "Epoch 4/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 2.0334 - acc: 0.4542 - val_loss: 2.7590 - val_acc: 0.3059\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.36090\n",
            "Epoch 5/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.9354 - acc: 0.4921 - val_loss: 2.1093 - val_acc: 0.4325\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.36090 to 0.43250, saving model to /content/saved_models/cifar10_ResNet32v1_model.005.h5\n",
            "Epoch 6/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.8484 - acc: 0.5186 - val_loss: 2.6794 - val_acc: 0.3606\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.43250\n",
            "Epoch 7/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.7984 - acc: 0.5465 - val_loss: 2.2674 - val_acc: 0.4017\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.43250\n",
            "Epoch 8/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.7422 - acc: 0.5605 - val_loss: 2.5430 - val_acc: 0.4318\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.43250\n",
            "Epoch 9/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.7106 - acc: 0.5700 - val_loss: 1.9359 - val_acc: 0.5126\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.43250 to 0.51260, saving model to /content/saved_models/cifar10_ResNet32v1_model.009.h5\n",
            "Epoch 10/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.6551 - acc: 0.5936 - val_loss: 2.6099 - val_acc: 0.4375\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.51260\n",
            "Epoch 11/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.6298 - acc: 0.5967 - val_loss: 3.6167 - val_acc: 0.3145\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.51260\n",
            "Epoch 12/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.5879 - acc: 0.6145 - val_loss: 2.1147 - val_acc: 0.4893\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.51260\n",
            "Epoch 13/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.5573 - acc: 0.6185 - val_loss: 2.8955 - val_acc: 0.3838\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.51260\n",
            "Epoch 14/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.5353 - acc: 0.6328 - val_loss: 1.8145 - val_acc: 0.5495\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.51260 to 0.54950, saving model to /content/saved_models/cifar10_ResNet32v1_model.014.h5\n",
            "Epoch 15/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 1.4930 - acc: 0.6421 - val_loss: 1.8251 - val_acc: 0.5478\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.54950\n",
            "Epoch 16/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.4724 - acc: 0.6485 - val_loss: 2.5566 - val_acc: 0.4059\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.54950\n",
            "Epoch 17/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4432 - acc: 0.6592 - val_loss: 1.6338 - val_acc: 0.5903\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.54950 to 0.59030, saving model to /content/saved_models/cifar10_ResNet32v1_model.017.h5\n",
            "Epoch 18/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4061 - acc: 0.6704 - val_loss: 1.9525 - val_acc: 0.5447\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.59030\n",
            "Epoch 19/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4106 - acc: 0.6649 - val_loss: 1.9199 - val_acc: 0.5305\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.59030\n",
            "Epoch 20/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3905 - acc: 0.6695 - val_loss: 1.6587 - val_acc: 0.6034\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.59030 to 0.60340, saving model to /content/saved_models/cifar10_ResNet32v1_model.020.h5\n",
            "Epoch 21/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3615 - acc: 0.6754 - val_loss: 1.5874 - val_acc: 0.6246\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.60340 to 0.62460, saving model to /content/saved_models/cifar10_ResNet32v1_model.021.h5\n",
            "Epoch 22/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3337 - acc: 0.6931 - val_loss: 1.5485 - val_acc: 0.6245\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.62460\n",
            "Epoch 23/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3027 - acc: 0.7002 - val_loss: 1.3952 - val_acc: 0.6728\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.62460 to 0.67280, saving model to /content/saved_models/cifar10_ResNet32v1_model.023.h5\n",
            "Epoch 24/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2952 - acc: 0.6998 - val_loss: 1.5144 - val_acc: 0.6375\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.67280\n",
            "Epoch 25/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2736 - acc: 0.7095 - val_loss: 1.6838 - val_acc: 0.5985\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.67280\n",
            "Epoch 26/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2637 - acc: 0.7110 - val_loss: 1.3107 - val_acc: 0.7036\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.67280 to 0.70360, saving model to /content/saved_models/cifar10_ResNet32v1_model.026.h5\n",
            "Epoch 27/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2510 - acc: 0.7128 - val_loss: 1.5104 - val_acc: 0.6532\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.70360\n",
            "Epoch 28/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2329 - acc: 0.7203 - val_loss: 1.6731 - val_acc: 0.6083\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.70360\n",
            "Epoch 29/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2158 - acc: 0.7241 - val_loss: 1.6924 - val_acc: 0.5810\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.70360\n",
            "Epoch 30/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.1868 - acc: 0.7347 - val_loss: 2.2617 - val_acc: 0.5185\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.70360\n",
            "Epoch 31/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.1847 - acc: 0.7315 - val_loss: 1.3941 - val_acc: 0.6624\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.70360\n",
            "Epoch 32/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.1683 - acc: 0.7398 - val_loss: 1.7189 - val_acc: 0.5715\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.70360\n",
            "Epoch 33/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.1682 - acc: 0.7398 - val_loss: 1.4293 - val_acc: 0.6511\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.70360\n",
            "Epoch 34/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.1340 - acc: 0.7516 - val_loss: 1.4170 - val_acc: 0.6759\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.70360\n",
            "Epoch 35/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.1546 - acc: 0.7431 - val_loss: 1.3704 - val_acc: 0.6656\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.70360\n",
            "Epoch 36/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.1155 - acc: 0.7524 - val_loss: 1.2533 - val_acc: 0.7084\n",
            "\n",
            "Epoch 00036: val_acc improved from 0.70360 to 0.70840, saving model to /content/saved_models/cifar10_ResNet32v1_model.036.h5\n",
            "Epoch 37/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.1303 - acc: 0.7423 - val_loss: 1.3869 - val_acc: 0.6891\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.70840\n",
            "Epoch 38/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.0962 - acc: 0.7582 - val_loss: 1.7541 - val_acc: 0.6091\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.70840\n",
            "Epoch 39/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.0971 - acc: 0.7548 - val_loss: 1.4310 - val_acc: 0.6525\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.70840\n",
            "Epoch 40/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.0890 - acc: 0.7602 - val_loss: 1.8144 - val_acc: 0.5723\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.70840\n",
            "Epoch 41/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.0609 - acc: 0.7652 - val_loss: 1.5055 - val_acc: 0.6384\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.70840\n",
            "Epoch 42/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.0758 - acc: 0.7648 - val_loss: 1.3955 - val_acc: 0.6645\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.70840\n",
            "Epoch 43/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.0718 - acc: 0.7600 - val_loss: 1.5481 - val_acc: 0.6249\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.70840\n",
            "Epoch 44/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.0314 - acc: 0.7727 - val_loss: 1.1713 - val_acc: 0.7266\n",
            "\n",
            "Epoch 00044: val_acc improved from 0.70840 to 0.72660, saving model to /content/saved_models/cifar10_ResNet32v1_model.044.h5\n",
            "Epoch 45/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.0385 - acc: 0.7730 - val_loss: 1.1401 - val_acc: 0.7399\n",
            "\n",
            "Epoch 00045: val_acc improved from 0.72660 to 0.73990, saving model to /content/saved_models/cifar10_ResNet32v1_model.045.h5\n",
            "Epoch 46/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.0313 - acc: 0.7751 - val_loss: 1.4485 - val_acc: 0.6453\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.73990\n",
            "Epoch 47/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.0336 - acc: 0.7737 - val_loss: 1.2737 - val_acc: 0.7006\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.73990\n",
            "Epoch 48/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.0346 - acc: 0.7755 - val_loss: 1.3535 - val_acc: 0.6970\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.73990\n",
            "Epoch 49/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.9902 - acc: 0.7863 - val_loss: 1.1526 - val_acc: 0.7356\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.73990\n",
            "Epoch 50/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9974 - acc: 0.7828 - val_loss: 1.4969 - val_acc: 0.6500\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.73990\n",
            "Epoch 51/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.0099 - acc: 0.7748 - val_loss: 1.2575 - val_acc: 0.7064\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.73990\n",
            "Epoch 52/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.9809 - acc: 0.7883 - val_loss: 1.2681 - val_acc: 0.7016\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.73990\n",
            "Epoch 53/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.9733 - acc: 0.7860 - val_loss: 1.1204 - val_acc: 0.7470\n",
            "\n",
            "Epoch 00053: val_acc improved from 0.73990 to 0.74700, saving model to /content/saved_models/cifar10_ResNet32v1_model.053.h5\n",
            "Epoch 54/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9703 - acc: 0.7918 - val_loss: 1.1873 - val_acc: 0.7170\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.74700\n",
            "Epoch 55/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.9744 - acc: 0.7900 - val_loss: 1.3440 - val_acc: 0.6779\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.74700\n",
            "Epoch 56/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.9518 - acc: 0.7945 - val_loss: 1.5587 - val_acc: 0.6423\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.74700\n",
            "Epoch 57/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.9655 - acc: 0.7897 - val_loss: 1.2079 - val_acc: 0.7158\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.74700\n",
            "Epoch 58/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.9510 - acc: 0.7922 - val_loss: 1.6272 - val_acc: 0.6409\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.74700\n",
            "Epoch 59/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.9440 - acc: 0.7967 - val_loss: 1.0345 - val_acc: 0.7641\n",
            "\n",
            "Epoch 00059: val_acc improved from 0.74700 to 0.76410, saving model to /content/saved_models/cifar10_ResNet32v1_model.059.h5\n",
            "Epoch 60/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.9462 - acc: 0.7986 - val_loss: 1.3233 - val_acc: 0.6914\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.76410\n",
            "Epoch 61/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.9389 - acc: 0.7978 - val_loss: 1.1411 - val_acc: 0.7351\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.76410\n",
            "Epoch 62/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.9190 - acc: 0.7979 - val_loss: 1.1722 - val_acc: 0.7253\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.76410\n",
            "Epoch 63/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9227 - acc: 0.8057 - val_loss: 1.0313 - val_acc: 0.7675\n",
            "\n",
            "Epoch 00063: val_acc improved from 0.76410 to 0.76750, saving model to /content/saved_models/cifar10_ResNet32v1_model.063.h5\n",
            "Epoch 64/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9132 - acc: 0.8008 - val_loss: 1.2185 - val_acc: 0.7250\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.76750\n",
            "Epoch 65/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.9313 - acc: 0.7933 - val_loss: 1.0575 - val_acc: 0.7629\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.76750\n",
            "Epoch 66/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.9070 - acc: 0.8046 - val_loss: 1.0261 - val_acc: 0.7737\n",
            "\n",
            "Epoch 00066: val_acc improved from 0.76750 to 0.77370, saving model to /content/saved_models/cifar10_ResNet32v1_model.066.h5\n",
            "Epoch 67/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.9080 - acc: 0.8035 - val_loss: 1.3257 - val_acc: 0.6760\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.77370\n",
            "Epoch 68/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8892 - acc: 0.8091 - val_loss: 1.0081 - val_acc: 0.7675\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.77370\n",
            "Epoch 69/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.9004 - acc: 0.8029 - val_loss: 1.2378 - val_acc: 0.7040\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.77370\n",
            "Epoch 70/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8983 - acc: 0.8004 - val_loss: 1.1508 - val_acc: 0.7320\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.77370\n",
            "Epoch 71/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8878 - acc: 0.8069 - val_loss: 1.0869 - val_acc: 0.7565\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.77370\n",
            "Epoch 72/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8796 - acc: 0.8110 - val_loss: 1.2467 - val_acc: 0.6963\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.77370\n",
            "Epoch 73/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8848 - acc: 0.8058 - val_loss: 0.9870 - val_acc: 0.7781\n",
            "\n",
            "Epoch 00073: val_acc improved from 0.77370 to 0.77810, saving model to /content/saved_models/cifar10_ResNet32v1_model.073.h5\n",
            "Epoch 74/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8734 - acc: 0.8108 - val_loss: 1.1519 - val_acc: 0.7280\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.77810\n",
            "Epoch 75/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8662 - acc: 0.8101 - val_loss: 0.9693 - val_acc: 0.7825\n",
            "\n",
            "Epoch 00075: val_acc improved from 0.77810 to 0.78250, saving model to /content/saved_models/cifar10_ResNet32v1_model.075.h5\n",
            "Epoch 76/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8461 - acc: 0.8174 - val_loss: 1.1566 - val_acc: 0.7259\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.78250\n",
            "Epoch 77/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8679 - acc: 0.8060 - val_loss: 1.0834 - val_acc: 0.7438\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.78250\n",
            "Epoch 78/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8578 - acc: 0.8142 - val_loss: 1.4028 - val_acc: 0.6679\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.78250\n",
            "Epoch 79/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8291 - acc: 0.8278 - val_loss: 1.0772 - val_acc: 0.7496\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.78250\n",
            "Epoch 80/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8662 - acc: 0.8106 - val_loss: 1.0322 - val_acc: 0.7569\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.78250\n",
            "Epoch 81/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8494 - acc: 0.8138 - val_loss: 1.0926 - val_acc: 0.7452\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.78250\n",
            "Epoch 82/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8223 - acc: 0.8230 - val_loss: 1.1525 - val_acc: 0.7309\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.78250\n",
            "Epoch 83/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8308 - acc: 0.8238 - val_loss: 1.0368 - val_acc: 0.7559\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.78250\n",
            "Epoch 84/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8386 - acc: 0.8178 - val_loss: 1.1373 - val_acc: 0.7227\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.78250\n",
            "Epoch 85/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.8166 - acc: 0.8235 - val_loss: 0.9955 - val_acc: 0.7696\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.78250\n",
            "Epoch 86/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8243 - acc: 0.8212 - val_loss: 0.9825 - val_acc: 0.7735\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.78250\n",
            "Epoch 87/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8180 - acc: 0.8214 - val_loss: 1.3462 - val_acc: 0.6682\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.78250\n",
            "Epoch 88/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8081 - acc: 0.8285 - val_loss: 1.0012 - val_acc: 0.7622\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.78250\n",
            "Epoch 89/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8023 - acc: 0.8297 - val_loss: 1.6005 - val_acc: 0.6619\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.78250\n",
            "Epoch 90/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8014 - acc: 0.8261 - val_loss: 1.3084 - val_acc: 0.6804\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.78250\n",
            "Epoch 91/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8043 - acc: 0.8290 - val_loss: 1.0101 - val_acc: 0.7642\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.78250\n",
            "Epoch 92/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7997 - acc: 0.8265 - val_loss: 0.9069 - val_acc: 0.7879\n",
            "\n",
            "Epoch 00092: val_acc improved from 0.78250 to 0.78790, saving model to /content/saved_models/cifar10_ResNet32v1_model.092.h5\n",
            "Epoch 93/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8153 - acc: 0.8241 - val_loss: 1.3339 - val_acc: 0.6918\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.78790\n",
            "Epoch 94/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7999 - acc: 0.8293 - val_loss: 1.4376 - val_acc: 0.6480\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.78790\n",
            "Epoch 95/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7955 - acc: 0.8297 - val_loss: 1.0512 - val_acc: 0.7584\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.78790\n",
            "Epoch 96/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7811 - acc: 0.8348 - val_loss: 0.9919 - val_acc: 0.7569\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.78790\n",
            "Epoch 97/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7911 - acc: 0.8295 - val_loss: 0.9574 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.78790\n",
            "Epoch 98/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7773 - acc: 0.8346 - val_loss: 1.2125 - val_acc: 0.7129\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.78790\n",
            "Epoch 99/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7724 - acc: 0.8352 - val_loss: 1.0357 - val_acc: 0.7536\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.78790\n",
            "Epoch 100/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7924 - acc: 0.8269 - val_loss: 1.0630 - val_acc: 0.7374\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.78790\n",
            "Epoch 101/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7805 - acc: 0.8279 - val_loss: 0.9459 - val_acc: 0.7794\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.78790\n",
            "Epoch 102/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7692 - acc: 0.8340 - val_loss: 1.1879 - val_acc: 0.7296\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.78790\n",
            "Epoch 103/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7674 - acc: 0.8326 - val_loss: 1.0365 - val_acc: 0.7604\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.78790\n",
            "Epoch 104/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7600 - acc: 0.8386 - val_loss: 1.1097 - val_acc: 0.7311\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.78790\n",
            "Epoch 105/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7478 - acc: 0.8414 - val_loss: 0.9625 - val_acc: 0.7734\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.78790\n",
            "Epoch 106/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7615 - acc: 0.8327 - val_loss: 1.1939 - val_acc: 0.7219\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.78790\n",
            "Epoch 107/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7691 - acc: 0.8334 - val_loss: 1.0328 - val_acc: 0.7621\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.78790\n",
            "Epoch 108/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7647 - acc: 0.8364 - val_loss: 0.8810 - val_acc: 0.8018\n",
            "\n",
            "Epoch 00108: val_acc improved from 0.78790 to 0.80180, saving model to /content/saved_models/cifar10_ResNet32v1_model.108.h5\n",
            "Epoch 109/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7384 - acc: 0.8433 - val_loss: 1.3171 - val_acc: 0.7037\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.80180\n",
            "Epoch 110/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7564 - acc: 0.8335 - val_loss: 0.9361 - val_acc: 0.7827\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.80180\n",
            "Epoch 111/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7293 - acc: 0.8465 - val_loss: 0.9710 - val_acc: 0.7690\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.80180\n",
            "Epoch 112/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7347 - acc: 0.8445 - val_loss: 1.0622 - val_acc: 0.7452\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.80180\n",
            "Epoch 113/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7311 - acc: 0.8385 - val_loss: 1.0913 - val_acc: 0.7524\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.80180\n",
            "Epoch 114/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7528 - acc: 0.8411 - val_loss: 0.8912 - val_acc: 0.7874\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.80180\n",
            "Epoch 115/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7265 - acc: 0.8432 - val_loss: 0.9819 - val_acc: 0.7691\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.80180\n",
            "Epoch 116/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7439 - acc: 0.8369 - val_loss: 1.2943 - val_acc: 0.7008\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.80180\n",
            "Epoch 117/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7308 - acc: 0.8423 - val_loss: 1.0124 - val_acc: 0.7657\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.80180\n",
            "Epoch 118/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7214 - acc: 0.8435 - val_loss: 1.0372 - val_acc: 0.7475\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.80180\n",
            "Epoch 119/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7283 - acc: 0.8445 - val_loss: 0.9860 - val_acc: 0.7643\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.80180\n",
            "Epoch 120/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7161 - acc: 0.8455 - val_loss: 1.1143 - val_acc: 0.7434\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.80180\n",
            "Epoch 121/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7258 - acc: 0.8388 - val_loss: 0.8405 - val_acc: 0.8088\n",
            "\n",
            "Epoch 00121: val_acc improved from 0.80180 to 0.80880, saving model to /content/saved_models/cifar10_ResNet32v1_model.121.h5\n",
            "Epoch 122/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7157 - acc: 0.8491 - val_loss: 0.9479 - val_acc: 0.7784\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.80880\n",
            "Epoch 123/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7278 - acc: 0.8419 - val_loss: 1.0107 - val_acc: 0.7677\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.80880\n",
            "Epoch 124/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7216 - acc: 0.8463 - val_loss: 0.9020 - val_acc: 0.7968\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.80880\n",
            "Epoch 125/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7243 - acc: 0.8423 - val_loss: 1.1383 - val_acc: 0.7182\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.80880\n",
            "Epoch 126/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7084 - acc: 0.8486 - val_loss: 0.8976 - val_acc: 0.7936\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.80880\n",
            "Epoch 127/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7041 - acc: 0.8504 - val_loss: 0.9787 - val_acc: 0.7657\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.80880\n",
            "Epoch 128/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7152 - acc: 0.8458 - val_loss: 1.0379 - val_acc: 0.7442\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.80880\n",
            "Epoch 129/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6946 - acc: 0.8457 - val_loss: 1.0120 - val_acc: 0.7703\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.80880\n",
            "Epoch 130/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6983 - acc: 0.8476 - val_loss: 0.9951 - val_acc: 0.7563\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.80880\n",
            "Epoch 131/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6989 - acc: 0.8472 - val_loss: 0.9735 - val_acc: 0.7752\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.80880\n",
            "Epoch 132/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6997 - acc: 0.8494 - val_loss: 1.0064 - val_acc: 0.7653\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.80880\n",
            "Epoch 133/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6890 - acc: 0.8536 - val_loss: 1.1312 - val_acc: 0.7371\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.80880\n",
            "Epoch 134/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7018 - acc: 0.8479 - val_loss: 0.9015 - val_acc: 0.7861\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.80880\n",
            "Epoch 135/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7110 - acc: 0.8463 - val_loss: 0.9534 - val_acc: 0.7668\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.80880\n",
            "Epoch 136/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.6844 - acc: 0.8513 - val_loss: 1.3270 - val_acc: 0.7098\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.80880\n",
            "Epoch 137/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6802 - acc: 0.8533 - val_loss: 0.8699 - val_acc: 0.7969\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.80880\n",
            "Epoch 138/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6785 - acc: 0.8557 - val_loss: 0.8864 - val_acc: 0.7897\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.80880\n",
            "Epoch 139/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6776 - acc: 0.8515 - val_loss: 0.9319 - val_acc: 0.7787\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.80880\n",
            "Epoch 140/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6827 - acc: 0.8548 - val_loss: 0.8950 - val_acc: 0.7918\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.80880\n",
            "Epoch 141/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6801 - acc: 0.8525 - val_loss: 0.8810 - val_acc: 0.7977\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.80880\n",
            "Epoch 142/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.6904 - acc: 0.8455 - val_loss: 1.0135 - val_acc: 0.7609\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.80880\n",
            "Epoch 143/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6890 - acc: 0.8506 - val_loss: 0.9409 - val_acc: 0.7734\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.80880\n",
            "Epoch 144/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6737 - acc: 0.8544 - val_loss: 1.0691 - val_acc: 0.7578\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.80880\n",
            "Epoch 145/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6553 - acc: 0.8612 - val_loss: 1.4041 - val_acc: 0.6742\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.80880\n",
            "Epoch 146/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6808 - acc: 0.8505 - val_loss: 0.8601 - val_acc: 0.7941\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.80880\n",
            "Epoch 147/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6780 - acc: 0.8567 - val_loss: 0.9108 - val_acc: 0.7792\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.80880\n",
            "Epoch 148/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6723 - acc: 0.8515 - val_loss: 1.1400 - val_acc: 0.7239\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.80880\n",
            "Epoch 149/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6786 - acc: 0.8536 - val_loss: 1.0619 - val_acc: 0.7483\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.80880\n",
            "Epoch 150/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6748 - acc: 0.8532 - val_loss: 0.8497 - val_acc: 0.8061\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.80880\n",
            "Epoch 151/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6766 - acc: 0.8515 - val_loss: 0.8641 - val_acc: 0.7900\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.80880\n",
            "Epoch 152/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6476 - acc: 0.8586 - val_loss: 0.8827 - val_acc: 0.7867\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.80880\n",
            "Epoch 153/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6823 - acc: 0.8506 - val_loss: 1.1753 - val_acc: 0.7325\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.80880\n",
            "Epoch 154/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6703 - acc: 0.8536 - val_loss: 0.9213 - val_acc: 0.7800\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.80880\n",
            "Epoch 155/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6597 - acc: 0.8573 - val_loss: 0.8341 - val_acc: 0.8030\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.80880\n",
            "Epoch 156/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6630 - acc: 0.8593 - val_loss: 0.8967 - val_acc: 0.7883\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.80880\n",
            "Epoch 157/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6620 - acc: 0.8540 - val_loss: 0.8881 - val_acc: 0.7952\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.80880\n",
            "Epoch 158/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6611 - acc: 0.8528 - val_loss: 1.6583 - val_acc: 0.6226\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.80880\n",
            "Epoch 159/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6482 - acc: 0.8576 - val_loss: 1.0987 - val_acc: 0.7430\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.80880\n",
            "Epoch 160/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6554 - acc: 0.8559 - val_loss: 0.9906 - val_acc: 0.7645\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.80880\n",
            "Epoch 161/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6534 - acc: 0.8629 - val_loss: 0.8965 - val_acc: 0.7812\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.80880\n",
            "Epoch 162/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6522 - acc: 0.8599 - val_loss: 0.9874 - val_acc: 0.7691\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.80880\n",
            "Epoch 163/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6584 - acc: 0.8556 - val_loss: 0.7942 - val_acc: 0.8205\n",
            "\n",
            "Epoch 00163: val_acc improved from 0.80880 to 0.82050, saving model to /content/saved_models/cifar10_ResNet32v1_model.163.h5\n",
            "Epoch 164/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6709 - acc: 0.8520 - val_loss: 0.9041 - val_acc: 0.7930\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.82050\n",
            "Epoch 165/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6572 - acc: 0.8555 - val_loss: 1.0038 - val_acc: 0.7642\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.82050\n",
            "Epoch 166/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6284 - acc: 0.8666 - val_loss: 0.8892 - val_acc: 0.7878\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.82050\n",
            "Epoch 167/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6460 - acc: 0.8618 - val_loss: 0.8549 - val_acc: 0.8042\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.82050\n",
            "Epoch 168/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6243 - acc: 0.8654 - val_loss: 0.8180 - val_acc: 0.8115\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.82050\n",
            "Epoch 169/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6272 - acc: 0.8641 - val_loss: 0.9063 - val_acc: 0.7853\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.82050\n",
            "Epoch 170/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6504 - acc: 0.8547 - val_loss: 0.8919 - val_acc: 0.7776\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.82050\n",
            "Epoch 171/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6260 - acc: 0.8652 - val_loss: 0.8729 - val_acc: 0.7952\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.82050\n",
            "Epoch 172/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6586 - acc: 0.8523 - val_loss: 0.8925 - val_acc: 0.7922\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.82050\n",
            "Epoch 173/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6262 - acc: 0.8675 - val_loss: 0.9339 - val_acc: 0.7855\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.82050\n",
            "Epoch 174/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6444 - acc: 0.8582 - val_loss: 0.7815 - val_acc: 0.8176\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.82050\n",
            "Epoch 175/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6122 - acc: 0.8653 - val_loss: 0.9051 - val_acc: 0.7782\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.82050\n",
            "Epoch 176/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6408 - acc: 0.8597 - val_loss: 0.8114 - val_acc: 0.8054\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.82050\n",
            "Epoch 177/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.6238 - acc: 0.8641 - val_loss: 0.9013 - val_acc: 0.7933\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.82050\n",
            "Epoch 178/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6341 - acc: 0.8596 - val_loss: 1.2102 - val_acc: 0.7188\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.82050\n",
            "Epoch 179/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6172 - acc: 0.8676 - val_loss: 0.7641 - val_acc: 0.8214\n",
            "\n",
            "Epoch 00179: val_acc improved from 0.82050 to 0.82140, saving model to /content/saved_models/cifar10_ResNet32v1_model.179.h5\n",
            "Epoch 180/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6186 - acc: 0.8671 - val_loss: 1.0110 - val_acc: 0.7642\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.82140\n",
            "Epoch 181/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6103 - acc: 0.8703 - val_loss: 0.8688 - val_acc: 0.7947\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.82140\n",
            "Epoch 182/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6193 - acc: 0.8654 - val_loss: 0.9046 - val_acc: 0.7853\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.82140\n",
            "Epoch 183/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6216 - acc: 0.8682 - val_loss: 0.9071 - val_acc: 0.7848\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.82140\n",
            "Epoch 184/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6209 - acc: 0.8653 - val_loss: 0.8483 - val_acc: 0.8000\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.82140\n",
            "Epoch 185/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6115 - acc: 0.8700 - val_loss: 0.7644 - val_acc: 0.8210\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.82140\n",
            "Epoch 186/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6225 - acc: 0.8650 - val_loss: 0.9073 - val_acc: 0.7908\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.82140\n",
            "Epoch 187/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6261 - acc: 0.8642 - val_loss: 0.7129 - val_acc: 0.8356\n",
            "\n",
            "Epoch 00187: val_acc improved from 0.82140 to 0.83560, saving model to /content/saved_models/cifar10_ResNet32v1_model.187.h5\n",
            "Epoch 188/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6206 - acc: 0.8630 - val_loss: 0.8931 - val_acc: 0.7892\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.83560\n",
            "Epoch 189/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5916 - acc: 0.8777 - val_loss: 0.7912 - val_acc: 0.8110\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.83560\n",
            "Epoch 190/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6162 - acc: 0.8685 - val_loss: 0.8950 - val_acc: 0.7801\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.83560\n",
            "Epoch 191/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6075 - acc: 0.8711 - val_loss: 0.9988 - val_acc: 0.7621\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.83560\n",
            "Epoch 192/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6252 - acc: 0.8635 - val_loss: 1.0381 - val_acc: 0.7421\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.83560\n",
            "Epoch 193/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5988 - acc: 0.8716 - val_loss: 0.9766 - val_acc: 0.7640\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.83560\n",
            "Epoch 194/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6038 - acc: 0.8689 - val_loss: 0.9028 - val_acc: 0.7795\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.83560\n",
            "Epoch 195/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6098 - acc: 0.8678 - val_loss: 0.8681 - val_acc: 0.7983\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.83560\n",
            "Epoch 196/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6095 - acc: 0.8677 - val_loss: 1.2786 - val_acc: 0.7124\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.83560\n",
            "Epoch 197/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6230 - acc: 0.8632 - val_loss: 0.8654 - val_acc: 0.7944\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.83560\n",
            "Epoch 198/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5881 - acc: 0.8768 - val_loss: 0.9246 - val_acc: 0.7849\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.83560\n",
            "Epoch 199/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6113 - acc: 0.8655 - val_loss: 1.1012 - val_acc: 0.7374\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.83560\n",
            "Epoch 200/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5933 - acc: 0.8751 - val_loss: 0.8518 - val_acc: 0.8030\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.83560\n",
            "Epoch 201/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5916 - acc: 0.8700 - val_loss: 0.8446 - val_acc: 0.8034\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.83560\n",
            "Epoch 202/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5911 - acc: 0.8727 - val_loss: 0.7809 - val_acc: 0.8224\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.83560\n",
            "Epoch 203/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5966 - acc: 0.8727 - val_loss: 0.9254 - val_acc: 0.7842\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.83560\n",
            "Epoch 204/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5998 - acc: 0.8705 - val_loss: 0.7825 - val_acc: 0.8224\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.83560\n",
            "Epoch 205/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5851 - acc: 0.8753 - val_loss: 0.7335 - val_acc: 0.8257\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.83560\n",
            "Epoch 206/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5894 - acc: 0.8761 - val_loss: 0.7947 - val_acc: 0.8146\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.83560\n",
            "Epoch 207/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6029 - acc: 0.8713 - val_loss: 0.7815 - val_acc: 0.8100\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.83560\n",
            "Epoch 208/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5974 - acc: 0.8715 - val_loss: 1.0460 - val_acc: 0.7451\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.83560\n",
            "Epoch 209/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5949 - acc: 0.8689 - val_loss: 0.8119 - val_acc: 0.8070\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.83560\n",
            "Epoch 210/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5884 - acc: 0.8713 - val_loss: 0.9374 - val_acc: 0.7819\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.83560\n",
            "Epoch 211/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6037 - acc: 0.8693 - val_loss: 0.8410 - val_acc: 0.7933\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.83560\n",
            "Epoch 212/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5894 - acc: 0.8748 - val_loss: 0.7655 - val_acc: 0.8200\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.83560\n",
            "Epoch 213/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5743 - acc: 0.8768 - val_loss: 1.0056 - val_acc: 0.7671\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.83560\n",
            "Epoch 214/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5893 - acc: 0.8722 - val_loss: 0.8096 - val_acc: 0.8080\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.83560\n",
            "Epoch 215/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5885 - acc: 0.8693 - val_loss: 0.8423 - val_acc: 0.8013\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.83560\n",
            "Epoch 216/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5796 - acc: 0.8719 - val_loss: 0.9094 - val_acc: 0.7815\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.83560\n",
            "Epoch 217/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5833 - acc: 0.8743 - val_loss: 0.9745 - val_acc: 0.7751\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.83560\n",
            "Epoch 218/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5822 - acc: 0.8750 - val_loss: 0.8470 - val_acc: 0.8045\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.83560\n",
            "Epoch 219/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5844 - acc: 0.8732 - val_loss: 0.7895 - val_acc: 0.8074\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.83560\n",
            "Epoch 220/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5768 - acc: 0.8752 - val_loss: 0.7544 - val_acc: 0.8205\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.83560\n",
            "Epoch 221/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5867 - acc: 0.8691 - val_loss: 0.8484 - val_acc: 0.7871\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.83560\n",
            "Epoch 222/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5804 - acc: 0.8734 - val_loss: 1.0779 - val_acc: 0.7539\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.83560\n",
            "Epoch 223/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5817 - acc: 0.8732 - val_loss: 1.0538 - val_acc: 0.7438\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.83560\n",
            "Epoch 224/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5852 - acc: 0.8715 - val_loss: 0.8229 - val_acc: 0.8149\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.83560\n",
            "Epoch 225/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5902 - acc: 0.8693 - val_loss: 0.8271 - val_acc: 0.8099\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.83560\n",
            "Epoch 226/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5760 - acc: 0.8789 - val_loss: 0.8414 - val_acc: 0.8022\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.83560\n",
            "Epoch 227/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5750 - acc: 0.8771 - val_loss: 0.7769 - val_acc: 0.8100\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.83560\n",
            "Epoch 228/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5805 - acc: 0.8740 - val_loss: 0.8907 - val_acc: 0.7921\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.83560\n",
            "Epoch 229/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5710 - acc: 0.8757 - val_loss: 0.8980 - val_acc: 0.7907\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.83560\n",
            "Epoch 230/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5839 - acc: 0.8738 - val_loss: 1.0798 - val_acc: 0.7532\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.83560\n",
            "Epoch 231/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5848 - acc: 0.8737 - val_loss: 0.8905 - val_acc: 0.7810\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.83560\n",
            "Epoch 232/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5668 - acc: 0.8763 - val_loss: 0.7937 - val_acc: 0.8113\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.83560\n",
            "Epoch 233/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5753 - acc: 0.8771 - val_loss: 0.7176 - val_acc: 0.8315\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.83560\n",
            "Epoch 234/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5710 - acc: 0.8755 - val_loss: 0.7460 - val_acc: 0.8223\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.83560\n",
            "Epoch 235/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5843 - acc: 0.8739 - val_loss: 0.8590 - val_acc: 0.7913\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.83560\n",
            "Epoch 236/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5637 - acc: 0.8839 - val_loss: 0.9402 - val_acc: 0.7874\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.83560\n",
            "Epoch 237/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5673 - acc: 0.8803 - val_loss: 0.8171 - val_acc: 0.8100\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.83560\n",
            "Epoch 238/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5568 - acc: 0.8791 - val_loss: 0.9546 - val_acc: 0.7640\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.83560\n",
            "Epoch 239/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5713 - acc: 0.8759 - val_loss: 0.8159 - val_acc: 0.8001\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.83560\n",
            "Epoch 240/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5820 - acc: 0.8744 - val_loss: 0.9430 - val_acc: 0.7595\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.83560\n",
            "Epoch 241/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5563 - acc: 0.8790 - val_loss: 0.7763 - val_acc: 0.8233\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.83560\n",
            "Epoch 242/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5821 - acc: 0.8746 - val_loss: 1.1430 - val_acc: 0.7240\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.83560\n",
            "Epoch 243/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5762 - acc: 0.8763 - val_loss: 1.0111 - val_acc: 0.7808\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.83560\n",
            "Epoch 244/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5645 - acc: 0.8763 - val_loss: 0.7673 - val_acc: 0.8179\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.83560\n",
            "Epoch 245/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5662 - acc: 0.8750 - val_loss: 0.7839 - val_acc: 0.8134\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.83560\n",
            "Epoch 246/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5685 - acc: 0.8809 - val_loss: 0.9173 - val_acc: 0.7714\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.83560\n",
            "Epoch 247/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5691 - acc: 0.8727 - val_loss: 0.8106 - val_acc: 0.8111\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.83560\n",
            "Epoch 248/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5527 - acc: 0.8819 - val_loss: 0.9223 - val_acc: 0.7782\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.83560\n",
            "Epoch 249/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5671 - acc: 0.8758 - val_loss: 0.7568 - val_acc: 0.8219\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.83560\n",
            "Epoch 250/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5733 - acc: 0.8746 - val_loss: 0.7964 - val_acc: 0.8088\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.83560\n",
            "Epoch 251/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5652 - acc: 0.8740 - val_loss: 0.8127 - val_acc: 0.8062\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.83560\n",
            "Epoch 252/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5638 - acc: 0.8761 - val_loss: 0.7213 - val_acc: 0.8366\n",
            "\n",
            "Epoch 00252: val_acc improved from 0.83560 to 0.83660, saving model to /content/saved_models/cifar10_ResNet32v1_model.252.h5\n",
            "Epoch 253/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5668 - acc: 0.8757 - val_loss: 0.8790 - val_acc: 0.7920\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.83660\n",
            "Epoch 254/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5460 - acc: 0.8851 - val_loss: 0.9076 - val_acc: 0.7880\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.83660\n",
            "Epoch 255/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5529 - acc: 0.8831 - val_loss: 0.8461 - val_acc: 0.7938\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.83660\n",
            "Epoch 256/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5432 - acc: 0.8834 - val_loss: 0.7244 - val_acc: 0.8328\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.83660\n",
            "Epoch 257/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5639 - acc: 0.8765 - val_loss: 0.7851 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.83660\n",
            "Epoch 258/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5622 - acc: 0.8750 - val_loss: 0.7638 - val_acc: 0.8183\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.83660\n",
            "Epoch 259/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5559 - acc: 0.8795 - val_loss: 0.9148 - val_acc: 0.7733\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.83660\n",
            "Epoch 260/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5565 - acc: 0.8815 - val_loss: 0.9656 - val_acc: 0.7815\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.83660\n",
            "Epoch 261/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5639 - acc: 0.8731 - val_loss: 0.8009 - val_acc: 0.8080\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.83660\n",
            "Epoch 262/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5670 - acc: 0.8756 - val_loss: 0.7818 - val_acc: 0.8143\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.83660\n",
            "Epoch 263/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5382 - acc: 0.8826 - val_loss: 0.8328 - val_acc: 0.7960\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.83660\n",
            "Epoch 264/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5604 - acc: 0.8752 - val_loss: 0.7780 - val_acc: 0.8154\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.83660\n",
            "Epoch 265/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5477 - acc: 0.8844 - val_loss: 0.7880 - val_acc: 0.8139\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.83660\n",
            "Epoch 266/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5593 - acc: 0.8779 - val_loss: 1.0458 - val_acc: 0.7697\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.83660\n",
            "Epoch 267/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5466 - acc: 0.8812 - val_loss: 0.7467 - val_acc: 0.8209\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.83660\n",
            "Epoch 268/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5540 - acc: 0.8791 - val_loss: 1.0214 - val_acc: 0.7508\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.83660\n",
            "Epoch 269/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5416 - acc: 0.8851 - val_loss: 0.7981 - val_acc: 0.8128\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.83660\n",
            "Epoch 270/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5522 - acc: 0.8797 - val_loss: 0.9165 - val_acc: 0.7836\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.83660\n",
            "Epoch 271/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5234 - acc: 0.8892 - val_loss: 0.8153 - val_acc: 0.8108\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.83660\n",
            "Epoch 272/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5470 - acc: 0.8842 - val_loss: 0.8622 - val_acc: 0.7887\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.83660\n",
            "Epoch 273/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5483 - acc: 0.8811 - val_loss: 0.6657 - val_acc: 0.8505\n",
            "\n",
            "Epoch 00273: val_acc improved from 0.83660 to 0.85050, saving model to /content/saved_models/cifar10_ResNet32v1_model.273.h5\n",
            "Epoch 274/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5514 - acc: 0.8779 - val_loss: 0.8747 - val_acc: 0.7969\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.85050\n",
            "Epoch 275/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5525 - acc: 0.8826 - val_loss: 0.7911 - val_acc: 0.8073\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.85050\n",
            "Epoch 276/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5523 - acc: 0.8782 - val_loss: 0.8364 - val_acc: 0.8060\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.85050\n",
            "Epoch 277/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5404 - acc: 0.8785 - val_loss: 0.7784 - val_acc: 0.8191\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.85050\n",
            "Epoch 278/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5393 - acc: 0.8826 - val_loss: 0.6802 - val_acc: 0.8375\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.85050\n",
            "Epoch 279/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5448 - acc: 0.8802 - val_loss: 0.7174 - val_acc: 0.8359\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.85050\n",
            "Epoch 280/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5370 - acc: 0.8852 - val_loss: 1.0721 - val_acc: 0.7556\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.85050\n",
            "Epoch 281/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5384 - acc: 0.8853 - val_loss: 0.7886 - val_acc: 0.8169\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.85050\n",
            "Epoch 282/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5454 - acc: 0.8826 - val_loss: 0.8199 - val_acc: 0.8106\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.85050\n",
            "Epoch 283/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5293 - acc: 0.8912 - val_loss: 0.8037 - val_acc: 0.8088\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.85050\n",
            "Epoch 284/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5316 - acc: 0.8900 - val_loss: 0.7047 - val_acc: 0.8393\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.85050\n",
            "Epoch 285/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5440 - acc: 0.8803 - val_loss: 0.9594 - val_acc: 0.7716\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.85050\n",
            "Epoch 286/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5236 - acc: 0.8893 - val_loss: 0.7570 - val_acc: 0.8189\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.85050\n",
            "Epoch 287/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5397 - acc: 0.8794 - val_loss: 0.7658 - val_acc: 0.8219\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.85050\n",
            "Epoch 288/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5420 - acc: 0.8813 - val_loss: 0.7967 - val_acc: 0.8087\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.85050\n",
            "Epoch 289/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5413 - acc: 0.8796 - val_loss: 0.8243 - val_acc: 0.8019\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.85050\n",
            "Epoch 290/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5274 - acc: 0.8852 - val_loss: 0.7619 - val_acc: 0.8170\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.85050\n",
            "Epoch 291/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5280 - acc: 0.8840 - val_loss: 0.8637 - val_acc: 0.7929\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.85050\n",
            "Epoch 292/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5458 - acc: 0.8809 - val_loss: 0.8966 - val_acc: 0.7780\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.85050\n",
            "Epoch 293/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5420 - acc: 0.8854 - val_loss: 0.9108 - val_acc: 0.7770\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.85050\n",
            "Epoch 294/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5372 - acc: 0.8846 - val_loss: 0.9269 - val_acc: 0.7873\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.85050\n",
            "Epoch 295/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5382 - acc: 0.8842 - val_loss: 0.7554 - val_acc: 0.8179\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.85050\n",
            "Epoch 296/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5416 - acc: 0.8824 - val_loss: 0.6956 - val_acc: 0.8398\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.85050\n",
            "Epoch 297/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5354 - acc: 0.8858 - val_loss: 0.7880 - val_acc: 0.8149\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.85050\n",
            "Epoch 298/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5233 - acc: 0.8907 - val_loss: 0.9197 - val_acc: 0.7793\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.85050\n",
            "Epoch 299/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5345 - acc: 0.8859 - val_loss: 1.0621 - val_acc: 0.7526\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.85050\n",
            "Epoch 300/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5360 - acc: 0.8848 - val_loss: 0.7359 - val_acc: 0.8279\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.85050\n",
            "Epoch 301/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5404 - acc: 0.8835 - val_loss: 0.7326 - val_acc: 0.8222\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.85050\n",
            "Epoch 302/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5292 - acc: 0.8873 - val_loss: 0.8340 - val_acc: 0.7941\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.85050\n",
            "Epoch 303/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5345 - acc: 0.8870 - val_loss: 0.7622 - val_acc: 0.8194\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.85050\n",
            "Epoch 304/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5352 - acc: 0.8833 - val_loss: 0.7825 - val_acc: 0.8114\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.85050\n",
            "Epoch 305/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5370 - acc: 0.8819 - val_loss: 0.8880 - val_acc: 0.7891\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.85050\n",
            "Epoch 306/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5256 - acc: 0.8880 - val_loss: 0.7768 - val_acc: 0.8217\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.85050\n",
            "Epoch 307/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5329 - acc: 0.8848 - val_loss: 0.7730 - val_acc: 0.8167\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.85050\n",
            "Epoch 308/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5085 - acc: 0.8937 - val_loss: 0.8371 - val_acc: 0.8016\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.85050\n",
            "Epoch 309/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5204 - acc: 0.8881 - val_loss: 0.7709 - val_acc: 0.8198\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.85050\n",
            "Epoch 310/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5263 - acc: 0.8856 - val_loss: 0.7133 - val_acc: 0.8324\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.85050\n",
            "Epoch 311/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5185 - acc: 0.8866 - val_loss: 0.7601 - val_acc: 0.8190\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.85050\n",
            "Epoch 312/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5324 - acc: 0.8843 - val_loss: 0.7780 - val_acc: 0.8123\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.85050\n",
            "Epoch 313/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5242 - acc: 0.8881 - val_loss: 0.7472 - val_acc: 0.8186\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.85050\n",
            "Epoch 314/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5301 - acc: 0.8859 - val_loss: 0.7251 - val_acc: 0.8228\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.85050\n",
            "Epoch 315/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5214 - acc: 0.8914 - val_loss: 1.0166 - val_acc: 0.7653\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.85050\n",
            "Epoch 316/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5282 - acc: 0.8852 - val_loss: 0.7247 - val_acc: 0.8298\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.85050\n",
            "Epoch 317/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5257 - acc: 0.8856 - val_loss: 1.3161 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.85050\n",
            "Epoch 318/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5211 - acc: 0.8883 - val_loss: 1.0666 - val_acc: 0.7451\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.85050\n",
            "Epoch 319/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5104 - acc: 0.8896 - val_loss: 0.7948 - val_acc: 0.8185\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.85050\n",
            "Epoch 320/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5280 - acc: 0.8856 - val_loss: 0.9028 - val_acc: 0.7932\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.85050\n",
            "Epoch 321/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5161 - acc: 0.8905 - val_loss: 0.9119 - val_acc: 0.7786\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.85050\n",
            "Epoch 322/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5258 - acc: 0.8866 - val_loss: 0.7183 - val_acc: 0.8351\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.85050\n",
            "Epoch 323/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5157 - acc: 0.8890 - val_loss: 0.7359 - val_acc: 0.8252\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.85050\n",
            "Epoch 324/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5173 - acc: 0.8877 - val_loss: 0.7728 - val_acc: 0.8096\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.85050\n",
            "Epoch 325/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5205 - acc: 0.8902 - val_loss: 0.8874 - val_acc: 0.7890\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.85050\n",
            "Epoch 326/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5230 - acc: 0.8855 - val_loss: 0.7385 - val_acc: 0.8335\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.85050\n",
            "Epoch 327/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5250 - acc: 0.8857 - val_loss: 0.7870 - val_acc: 0.8137\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.85050\n",
            "Epoch 328/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5123 - acc: 0.8906 - val_loss: 0.6981 - val_acc: 0.8356\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.85050\n",
            "Epoch 329/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5259 - acc: 0.8845 - val_loss: 0.8728 - val_acc: 0.8003\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.85050\n",
            "Epoch 330/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4999 - acc: 0.8925 - val_loss: 0.8874 - val_acc: 0.7866\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.85050\n",
            "Epoch 331/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5131 - acc: 0.8885 - val_loss: 0.7652 - val_acc: 0.8127\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.85050\n",
            "Epoch 332/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5083 - acc: 0.8918 - val_loss: 0.7893 - val_acc: 0.8138\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.85050\n",
            "Epoch 333/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5158 - acc: 0.8888 - val_loss: 1.0211 - val_acc: 0.7702\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.85050\n",
            "Epoch 334/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5223 - acc: 0.8882 - val_loss: 0.7185 - val_acc: 0.8364\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.85050\n",
            "Epoch 335/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5114 - acc: 0.8901 - val_loss: 0.7937 - val_acc: 0.8039\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.85050\n",
            "Epoch 336/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5181 - acc: 0.8888 - val_loss: 0.7557 - val_acc: 0.8177\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.85050\n",
            "Epoch 337/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5044 - acc: 0.8924 - val_loss: 0.7169 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.85050\n",
            "Epoch 338/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5176 - acc: 0.8899 - val_loss: 0.7408 - val_acc: 0.8251\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.85050\n",
            "Epoch 339/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5101 - acc: 0.8909 - val_loss: 0.6836 - val_acc: 0.8390\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.85050\n",
            "Epoch 340/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5180 - acc: 0.8859 - val_loss: 0.7288 - val_acc: 0.8218\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.85050\n",
            "Epoch 341/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5240 - acc: 0.8825 - val_loss: 0.7620 - val_acc: 0.8195\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.85050\n",
            "Epoch 342/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5175 - acc: 0.8912 - val_loss: 0.6739 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.85050\n",
            "Epoch 343/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5115 - acc: 0.8916 - val_loss: 0.8177 - val_acc: 0.8153\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.85050\n",
            "Epoch 344/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5147 - acc: 0.8890 - val_loss: 0.9118 - val_acc: 0.7940\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.85050\n",
            "Epoch 345/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5158 - acc: 0.8915 - val_loss: 0.9754 - val_acc: 0.7699\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.85050\n",
            "Epoch 346/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5214 - acc: 0.8855 - val_loss: 0.7791 - val_acc: 0.8172\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.85050\n",
            "Epoch 347/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5119 - acc: 0.8891 - val_loss: 0.6632 - val_acc: 0.8487\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.85050\n",
            "Epoch 348/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5045 - acc: 0.8944 - val_loss: 0.7293 - val_acc: 0.8313\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.85050\n",
            "Epoch 349/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5064 - acc: 0.8917 - val_loss: 0.8209 - val_acc: 0.8056\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.85050\n",
            "Epoch 350/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5151 - acc: 0.8894 - val_loss: 0.7058 - val_acc: 0.8244\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.85050\n",
            "Epoch 351/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5018 - acc: 0.8928 - val_loss: 0.7878 - val_acc: 0.8138\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.85050\n",
            "Epoch 352/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5105 - acc: 0.8870 - val_loss: 0.7466 - val_acc: 0.8166\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.85050\n",
            "Epoch 353/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5005 - acc: 0.8924 - val_loss: 0.8083 - val_acc: 0.8101\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.85050\n",
            "Epoch 354/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5021 - acc: 0.8904 - val_loss: 0.8944 - val_acc: 0.7882\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.85050\n",
            "Epoch 355/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5242 - acc: 0.8825 - val_loss: 0.7210 - val_acc: 0.8285\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.85050\n",
            "Epoch 356/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5179 - acc: 0.8864 - val_loss: 0.6959 - val_acc: 0.8410\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.85050\n",
            "Epoch 357/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5075 - acc: 0.8894 - val_loss: 0.6702 - val_acc: 0.8430\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.85050\n",
            "Epoch 358/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5011 - acc: 0.8940 - val_loss: 0.8068 - val_acc: 0.8147\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.85050\n",
            "Epoch 359/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4870 - acc: 0.8950 - val_loss: 0.7328 - val_acc: 0.8309\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.85050\n",
            "Epoch 360/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4986 - acc: 0.8954 - val_loss: 0.7693 - val_acc: 0.8140\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.85050\n",
            "Epoch 361/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5036 - acc: 0.8941 - val_loss: 0.7727 - val_acc: 0.8268\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.85050\n",
            "Epoch 362/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5087 - acc: 0.8864 - val_loss: 0.9524 - val_acc: 0.7741\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.85050\n",
            "Epoch 363/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5105 - acc: 0.8901 - val_loss: 1.0057 - val_acc: 0.7635\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.85050\n",
            "Epoch 364/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4957 - acc: 0.8946 - val_loss: 0.8802 - val_acc: 0.7892\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.85050\n",
            "Epoch 365/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4969 - acc: 0.8929 - val_loss: 0.7150 - val_acc: 0.8297\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.85050\n",
            "Epoch 366/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4939 - acc: 0.8947 - val_loss: 0.7761 - val_acc: 0.8149\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.85050\n",
            "Epoch 367/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4854 - acc: 0.8967 - val_loss: 0.7848 - val_acc: 0.8089\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.85050\n",
            "Epoch 368/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4955 - acc: 0.8973 - val_loss: 0.6693 - val_acc: 0.8481\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.85050\n",
            "Epoch 369/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5026 - acc: 0.8939 - val_loss: 0.6805 - val_acc: 0.8381\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.85050\n",
            "Epoch 370/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4858 - acc: 0.9018 - val_loss: 0.7755 - val_acc: 0.8143\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.85050\n",
            "Epoch 371/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4995 - acc: 0.8951 - val_loss: 0.7392 - val_acc: 0.8264\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.85050\n",
            "Epoch 372/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4954 - acc: 0.8921 - val_loss: 0.6636 - val_acc: 0.8449\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.85050\n",
            "Epoch 373/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5096 - acc: 0.8868 - val_loss: 0.7857 - val_acc: 0.8048\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.85050\n",
            "Epoch 374/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5016 - acc: 0.8925 - val_loss: 0.6765 - val_acc: 0.8450\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.85050\n",
            "Epoch 375/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5075 - acc: 0.8865 - val_loss: 0.7961 - val_acc: 0.8029\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.85050\n",
            "Epoch 376/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5068 - acc: 0.8873 - val_loss: 0.9095 - val_acc: 0.7845\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.85050\n",
            "Epoch 377/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.5014 - acc: 0.8898 - val_loss: 0.6790 - val_acc: 0.8382\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.85050\n",
            "Epoch 378/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5116 - acc: 0.8851 - val_loss: 0.7610 - val_acc: 0.8174\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.85050\n",
            "Epoch 379/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5029 - acc: 0.8928 - val_loss: 0.8799 - val_acc: 0.7912\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.85050\n",
            "Epoch 380/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.4984 - acc: 0.8926 - val_loss: 0.7921 - val_acc: 0.8103\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.85050\n",
            "Epoch 381/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4893 - acc: 0.8973 - val_loss: 0.6164 - val_acc: 0.8610\n",
            "\n",
            "Epoch 00381: val_acc improved from 0.85050 to 0.86100, saving model to /content/saved_models/cifar10_ResNet32v1_model.381.h5\n",
            "Epoch 382/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4792 - acc: 0.8979 - val_loss: 0.7622 - val_acc: 0.8241\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.86100\n",
            "Epoch 383/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4857 - acc: 0.8976 - val_loss: 0.7167 - val_acc: 0.8368\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.86100\n",
            "Epoch 384/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4989 - acc: 0.8944 - val_loss: 0.7392 - val_acc: 0.8255\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.86100\n",
            "Epoch 385/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4911 - acc: 0.8988 - val_loss: 0.7668 - val_acc: 0.8109\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.86100\n",
            "Epoch 386/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.4902 - acc: 0.8971 - val_loss: 0.7433 - val_acc: 0.8242\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.86100\n",
            "Epoch 387/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5002 - acc: 0.8949 - val_loss: 0.8252 - val_acc: 0.8099\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.86100\n",
            "Epoch 388/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4791 - acc: 0.9005 - val_loss: 0.7003 - val_acc: 0.8375\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.86100\n",
            "Epoch 389/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.4965 - acc: 0.8916 - val_loss: 0.7895 - val_acc: 0.8079\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.86100\n",
            "Epoch 390/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4963 - acc: 0.8927 - val_loss: 0.7039 - val_acc: 0.8326\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.86100\n",
            "Epoch 391/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5033 - acc: 0.8909 - val_loss: 0.6903 - val_acc: 0.8339\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.86100\n",
            "Epoch 392/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4822 - acc: 0.9007 - val_loss: 0.7417 - val_acc: 0.8278\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.86100\n",
            "Epoch 393/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4979 - acc: 0.8966 - val_loss: 0.8872 - val_acc: 0.7834\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.86100\n",
            "Epoch 394/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4960 - acc: 0.8972 - val_loss: 0.7022 - val_acc: 0.8372\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.86100\n",
            "Epoch 395/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4937 - acc: 0.8945 - val_loss: 0.6727 - val_acc: 0.8472\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.86100\n",
            "Epoch 396/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5024 - acc: 0.8949 - val_loss: 0.7955 - val_acc: 0.8187\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.86100\n",
            "Epoch 397/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4869 - acc: 0.8967 - val_loss: 0.8060 - val_acc: 0.8092\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.86100\n",
            "Epoch 398/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4846 - acc: 0.8976 - val_loss: 0.8622 - val_acc: 0.7973\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.86100\n",
            "Epoch 399/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4795 - acc: 0.8990 - val_loss: 0.6786 - val_acc: 0.8426\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.86100\n",
            "Epoch 400/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4926 - acc: 0.8928 - val_loss: 0.8099 - val_acc: 0.8148\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.86100\n",
            "Epoch 401/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5140 - acc: 0.8864 - val_loss: 0.8211 - val_acc: 0.8064\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.86100\n",
            "Epoch 402/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.4582 - acc: 0.9075 - val_loss: 0.5652 - val_acc: 0.8775\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.86100 to 0.87750, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.4241 - acc: 0.9197 - val_loss: 0.5583 - val_acc: 0.8807\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.87750 to 0.88070, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.4124 - acc: 0.9237 - val_loss: 0.5325 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.88070 to 0.88880, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.4054 - acc: 0.9254 - val_loss: 0.5278 - val_acc: 0.8903\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.88880 to 0.89030, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3942 - acc: 0.9281 - val_loss: 0.5263 - val_acc: 0.8913\n",
            "\n",
            "Epoch 00406: val_acc improved from 0.89030 to 0.89130, saving model to /content/saved_models/cifar10_ResNet32v1_model.406.h5\n",
            "Epoch 407/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3961 - acc: 0.9273 - val_loss: 0.5302 - val_acc: 0.8897\n",
            "\n",
            "Epoch 00407: val_acc did not improve from 0.89130\n",
            "Epoch 408/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3904 - acc: 0.9324 - val_loss: 0.5198 - val_acc: 0.8935\n",
            "\n",
            "Epoch 00408: val_acc improved from 0.89130 to 0.89350, saving model to /content/saved_models/cifar10_ResNet32v1_model.408.h5\n",
            "Epoch 409/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3783 - acc: 0.9347 - val_loss: 0.5178 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00409: val_acc improved from 0.89350 to 0.89510, saving model to /content/saved_models/cifar10_ResNet32v1_model.409.h5\n",
            "Epoch 410/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3873 - acc: 0.9326 - val_loss: 0.5226 - val_acc: 0.8941\n",
            "\n",
            "Epoch 00410: val_acc did not improve from 0.89510\n",
            "Epoch 411/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3803 - acc: 0.9343 - val_loss: 0.5120 - val_acc: 0.8939\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.89510\n",
            "Epoch 412/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3885 - acc: 0.9316 - val_loss: 0.5071 - val_acc: 0.8967\n",
            "\n",
            "Epoch 00412: val_acc improved from 0.89510 to 0.89670, saving model to /content/saved_models/cifar10_ResNet32v1_model.412.h5\n",
            "Epoch 413/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3812 - acc: 0.9309 - val_loss: 0.5102 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.89670\n",
            "Epoch 414/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3785 - acc: 0.9357 - val_loss: 0.5209 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.89670\n",
            "Epoch 415/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3707 - acc: 0.9372 - val_loss: 0.5105 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00415: val_acc improved from 0.89670 to 0.89730, saving model to /content/saved_models/cifar10_ResNet32v1_model.415.h5\n",
            "Epoch 416/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3687 - acc: 0.9342 - val_loss: 0.5155 - val_acc: 0.8966\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.89730\n",
            "Epoch 417/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3691 - acc: 0.9362 - val_loss: 0.5027 - val_acc: 0.8957\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.89730\n",
            "Epoch 418/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3624 - acc: 0.9396 - val_loss: 0.5185 - val_acc: 0.8913\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.89730\n",
            "Epoch 419/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3616 - acc: 0.9401 - val_loss: 0.5148 - val_acc: 0.8930\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.89730\n",
            "Epoch 420/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3704 - acc: 0.9381 - val_loss: 0.5052 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.89730\n",
            "Epoch 421/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3645 - acc: 0.9393 - val_loss: 0.4984 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00421: val_acc did not improve from 0.89730\n",
            "Epoch 422/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3669 - acc: 0.9356 - val_loss: 0.5055 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00422: val_acc did not improve from 0.89730\n",
            "Epoch 423/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3564 - acc: 0.9408 - val_loss: 0.5107 - val_acc: 0.8957\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.89730\n",
            "Epoch 424/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3547 - acc: 0.9411 - val_loss: 0.5187 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.89730\n",
            "Epoch 425/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3574 - acc: 0.9410 - val_loss: 0.4968 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00425: val_acc improved from 0.89730 to 0.89940, saving model to /content/saved_models/cifar10_ResNet32v1_model.425.h5\n",
            "Epoch 426/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3512 - acc: 0.9435 - val_loss: 0.5098 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.89940\n",
            "Epoch 427/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3595 - acc: 0.9397 - val_loss: 0.5053 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.89940\n",
            "Epoch 428/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3535 - acc: 0.9421 - val_loss: 0.5107 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.89940\n",
            "Epoch 429/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3567 - acc: 0.9400 - val_loss: 0.5105 - val_acc: 0.8954\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.89940\n",
            "Epoch 430/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3495 - acc: 0.9437 - val_loss: 0.5035 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.89940\n",
            "Epoch 431/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3440 - acc: 0.9449 - val_loss: 0.4973 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.89940\n",
            "Epoch 432/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3467 - acc: 0.9433 - val_loss: 0.5020 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.89940\n",
            "Epoch 433/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3481 - acc: 0.9443 - val_loss: 0.5012 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.89940\n",
            "Epoch 434/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3395 - acc: 0.9472 - val_loss: 0.5021 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00434: val_acc did not improve from 0.89940\n",
            "Epoch 435/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3359 - acc: 0.9468 - val_loss: 0.5044 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.89940\n",
            "Epoch 436/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3451 - acc: 0.9436 - val_loss: 0.5014 - val_acc: 0.8962\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.89940\n",
            "Epoch 437/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3410 - acc: 0.9466 - val_loss: 0.5114 - val_acc: 0.8944\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.89940\n",
            "Epoch 438/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3365 - acc: 0.9480 - val_loss: 0.4997 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.89940\n",
            "Epoch 439/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3488 - acc: 0.9408 - val_loss: 0.5028 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.89940\n",
            "Epoch 440/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3391 - acc: 0.9439 - val_loss: 0.5077 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.89940\n",
            "Epoch 441/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3385 - acc: 0.9468 - val_loss: 0.5142 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.89940\n",
            "Epoch 442/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3401 - acc: 0.9439 - val_loss: 0.5078 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.89940\n",
            "Epoch 443/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3334 - acc: 0.9466 - val_loss: 0.5109 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.89940\n",
            "Epoch 444/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3244 - acc: 0.9508 - val_loss: 0.5049 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.89940\n",
            "Epoch 445/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3446 - acc: 0.9451 - val_loss: 0.5032 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00445: val_acc improved from 0.89940 to 0.89950, saving model to /content/saved_models/cifar10_ResNet32v1_model.445.h5\n",
            "Epoch 446/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3411 - acc: 0.9429 - val_loss: 0.5183 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.89950\n",
            "Epoch 447/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3300 - acc: 0.9450 - val_loss: 0.5150 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.89950\n",
            "Epoch 448/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3325 - acc: 0.9490 - val_loss: 0.5087 - val_acc: 0.8971\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.89950\n",
            "Epoch 449/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3376 - acc: 0.9447 - val_loss: 0.4956 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00449: val_acc improved from 0.89950 to 0.89970, saving model to /content/saved_models/cifar10_ResNet32v1_model.449.h5\n",
            "Epoch 450/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3337 - acc: 0.9459 - val_loss: 0.5055 - val_acc: 0.8965\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.89970\n",
            "Epoch 451/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3327 - acc: 0.9472 - val_loss: 0.5043 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.89970\n",
            "Epoch 452/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3362 - acc: 0.9474 - val_loss: 0.5067 - val_acc: 0.8943\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.89970\n",
            "Epoch 453/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3319 - acc: 0.9461 - val_loss: 0.5011 - val_acc: 0.8970\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.89970\n",
            "Epoch 454/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3340 - acc: 0.9469 - val_loss: 0.5211 - val_acc: 0.8930\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.89970\n",
            "Epoch 455/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3228 - acc: 0.9495 - val_loss: 0.5021 - val_acc: 0.8977\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.89970\n",
            "Epoch 456/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3255 - acc: 0.9507 - val_loss: 0.5113 - val_acc: 0.8970\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.89970\n",
            "Epoch 457/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3262 - acc: 0.9494 - val_loss: 0.5096 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.89970\n",
            "Epoch 458/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3218 - acc: 0.9512 - val_loss: 0.5135 - val_acc: 0.8931\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.89970\n",
            "Epoch 459/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3356 - acc: 0.9455 - val_loss: 0.5062 - val_acc: 0.8965\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.89970\n",
            "Epoch 460/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3337 - acc: 0.9458 - val_loss: 0.5039 - val_acc: 0.8964\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.89970\n",
            "Epoch 461/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3223 - acc: 0.9502 - val_loss: 0.5085 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.89970\n",
            "Epoch 462/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3254 - acc: 0.9510 - val_loss: 0.5100 - val_acc: 0.8949\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.89970\n",
            "Epoch 463/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3268 - acc: 0.9480 - val_loss: 0.5082 - val_acc: 0.8965\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.89970\n",
            "Epoch 464/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3254 - acc: 0.9491 - val_loss: 0.5029 - val_acc: 0.8979\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.89970\n",
            "Epoch 465/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3198 - acc: 0.9520 - val_loss: 0.5058 - val_acc: 0.8964\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.89970\n",
            "Epoch 466/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3237 - acc: 0.9509 - val_loss: 0.5160 - val_acc: 0.8957\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.89970\n",
            "Epoch 467/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3225 - acc: 0.9496 - val_loss: 0.5026 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.89970\n",
            "Epoch 468/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3214 - acc: 0.9516 - val_loss: 0.5149 - val_acc: 0.8939\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.89970\n",
            "Epoch 469/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3170 - acc: 0.9534 - val_loss: 0.5019 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.89970\n",
            "Epoch 470/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3223 - acc: 0.9519 - val_loss: 0.4927 - val_acc: 0.9007\n",
            "\n",
            "Epoch 00470: val_acc improved from 0.89970 to 0.90070, saving model to /content/saved_models/cifar10_ResNet32v1_model.470.h5\n",
            "Epoch 471/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3191 - acc: 0.9519 - val_loss: 0.5090 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.90070\n",
            "Epoch 472/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3132 - acc: 0.9544 - val_loss: 0.5107 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.90070\n",
            "Epoch 473/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3239 - acc: 0.9481 - val_loss: 0.4993 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.90070\n",
            "Epoch 474/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3188 - acc: 0.9517 - val_loss: 0.4985 - val_acc: 0.9003\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.90070\n",
            "Epoch 475/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3173 - acc: 0.9506 - val_loss: 0.5096 - val_acc: 0.8971\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.90070\n",
            "Epoch 476/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3119 - acc: 0.9524 - val_loss: 0.5048 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.90070\n",
            "Epoch 477/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3213 - acc: 0.9494 - val_loss: 0.4987 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.90070\n",
            "Epoch 478/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3065 - acc: 0.9551 - val_loss: 0.5122 - val_acc: 0.8958\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.90070\n",
            "Epoch 479/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3137 - acc: 0.9510 - val_loss: 0.5037 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.90070\n",
            "Epoch 480/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3188 - acc: 0.9498 - val_loss: 0.5112 - val_acc: 0.9004\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.90070\n",
            "Epoch 481/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3100 - acc: 0.9535 - val_loss: 0.4981 - val_acc: 0.9007\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.90070\n",
            "Epoch 482/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3104 - acc: 0.9540 - val_loss: 0.5111 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.90070\n",
            "Epoch 483/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3046 - acc: 0.9554 - val_loss: 0.5184 - val_acc: 0.8972\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.90070\n",
            "Epoch 484/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3047 - acc: 0.9533 - val_loss: 0.5036 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.90070\n",
            "Epoch 485/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3158 - acc: 0.9523 - val_loss: 0.5170 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.90070\n",
            "Epoch 486/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3131 - acc: 0.9536 - val_loss: 0.5103 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.90070\n",
            "Epoch 487/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3171 - acc: 0.9501 - val_loss: 0.5103 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.90070\n",
            "Epoch 488/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3106 - acc: 0.9517 - val_loss: 0.5049 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.90070\n",
            "Epoch 489/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3129 - acc: 0.9509 - val_loss: 0.5417 - val_acc: 0.8904\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.90070\n",
            "Epoch 490/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3099 - acc: 0.9520 - val_loss: 0.5156 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.90070\n",
            "Epoch 491/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3175 - acc: 0.9510 - val_loss: 0.5135 - val_acc: 0.8964\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.90070\n",
            "Epoch 492/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3079 - acc: 0.9520 - val_loss: 0.5209 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.90070\n",
            "Epoch 493/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3110 - acc: 0.9529 - val_loss: 0.5085 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.90070\n",
            "Epoch 494/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3140 - acc: 0.9518 - val_loss: 0.5045 - val_acc: 0.8977\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.90070\n",
            "Epoch 495/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3068 - acc: 0.9551 - val_loss: 0.5056 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.90070\n",
            "Epoch 496/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3143 - acc: 0.9518 - val_loss: 0.5175 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.90070\n",
            "Epoch 497/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3074 - acc: 0.9530 - val_loss: 0.4967 - val_acc: 0.9003\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.90070\n",
            "Epoch 498/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3044 - acc: 0.9529 - val_loss: 0.5107 - val_acc: 0.8977\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.90070\n",
            "Epoch 499/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3094 - acc: 0.9518 - val_loss: 0.5079 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.90070\n",
            "Epoch 500/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3022 - acc: 0.9554 - val_loss: 0.5058 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.90070\n",
            "Epoch 501/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3000 - acc: 0.9565 - val_loss: 0.5015 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.90070\n",
            "Epoch 502/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3078 - acc: 0.9553 - val_loss: 0.5096 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.90070\n",
            "Epoch 503/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3053 - acc: 0.9545 - val_loss: 0.5075 - val_acc: 0.8971\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.90070\n",
            "Epoch 504/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3072 - acc: 0.9503 - val_loss: 0.5227 - val_acc: 0.8940\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.90070\n",
            "Epoch 505/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3016 - acc: 0.9553 - val_loss: 0.5042 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.90070\n",
            "Epoch 506/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2913 - acc: 0.9569 - val_loss: 0.5157 - val_acc: 0.8957\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.90070\n",
            "Epoch 507/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3008 - acc: 0.9578 - val_loss: 0.5052 - val_acc: 0.8979\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.90070\n",
            "Epoch 508/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2978 - acc: 0.9589 - val_loss: 0.5002 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.90070\n",
            "Epoch 509/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2993 - acc: 0.9544 - val_loss: 0.5097 - val_acc: 0.8962\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.90070\n",
            "Epoch 510/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3020 - acc: 0.9561 - val_loss: 0.5047 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.90070\n",
            "Epoch 511/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2971 - acc: 0.9575 - val_loss: 0.4976 - val_acc: 0.9015\n",
            "\n",
            "Epoch 00511: val_acc improved from 0.90070 to 0.90150, saving model to /content/saved_models/cifar10_ResNet32v1_model.511.h5\n",
            "Epoch 512/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2932 - acc: 0.9584 - val_loss: 0.5116 - val_acc: 0.8957\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.90150\n",
            "Epoch 513/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2885 - acc: 0.9611 - val_loss: 0.5174 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.90150\n",
            "Epoch 514/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2948 - acc: 0.9575 - val_loss: 0.5108 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.90150\n",
            "Epoch 515/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2984 - acc: 0.9544 - val_loss: 0.5032 - val_acc: 0.9004\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.90150\n",
            "Epoch 516/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3025 - acc: 0.9526 - val_loss: 0.5023 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.90150\n",
            "Epoch 517/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2945 - acc: 0.9563 - val_loss: 0.5041 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.90150\n",
            "Epoch 518/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3018 - acc: 0.9542 - val_loss: 0.5125 - val_acc: 0.8965\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.90150\n",
            "Epoch 519/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2959 - acc: 0.9585 - val_loss: 0.5126 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.90150\n",
            "Epoch 520/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3003 - acc: 0.9556 - val_loss: 0.5115 - val_acc: 0.8972\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.90150\n",
            "Epoch 521/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2911 - acc: 0.9597 - val_loss: 0.5013 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.90150\n",
            "Epoch 522/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.2909 - acc: 0.9560 - val_loss: 0.5105 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.90150\n",
            "Epoch 523/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2928 - acc: 0.9555 - val_loss: 0.4960 - val_acc: 0.9023\n",
            "\n",
            "Epoch 00523: val_acc improved from 0.90150 to 0.90230, saving model to /content/saved_models/cifar10_ResNet32v1_model.523.h5\n",
            "Epoch 524/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2896 - acc: 0.9580 - val_loss: 0.5033 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.90230\n",
            "Epoch 525/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2919 - acc: 0.9571 - val_loss: 0.5069 - val_acc: 0.8977\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.90230\n",
            "Epoch 526/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2936 - acc: 0.9584 - val_loss: 0.5000 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.90230\n",
            "Epoch 527/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2870 - acc: 0.9596 - val_loss: 0.5230 - val_acc: 0.8942\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.90230\n",
            "Epoch 528/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2941 - acc: 0.9566 - val_loss: 0.5157 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.90230\n",
            "Epoch 529/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2911 - acc: 0.9573 - val_loss: 0.4984 - val_acc: 0.9014\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.90230\n",
            "Epoch 530/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2900 - acc: 0.9562 - val_loss: 0.5042 - val_acc: 0.9004\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.90230\n",
            "Epoch 531/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2878 - acc: 0.9580 - val_loss: 0.5029 - val_acc: 0.9004\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.90230\n",
            "Epoch 532/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2913 - acc: 0.9577 - val_loss: 0.5140 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.90230\n",
            "Epoch 533/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2961 - acc: 0.9563 - val_loss: 0.5011 - val_acc: 0.8998\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.90230\n",
            "Epoch 534/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2882 - acc: 0.9594 - val_loss: 0.5145 - val_acc: 0.8971\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.90230\n",
            "Epoch 535/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2920 - acc: 0.9589 - val_loss: 0.5165 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.90230\n",
            "Epoch 536/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2904 - acc: 0.9590 - val_loss: 0.4980 - val_acc: 0.9020\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.90230\n",
            "Epoch 537/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2924 - acc: 0.9578 - val_loss: 0.5082 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.90230\n",
            "Epoch 538/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2756 - acc: 0.9637 - val_loss: 0.5024 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.90230\n",
            "Epoch 539/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2882 - acc: 0.9589 - val_loss: 0.4989 - val_acc: 0.9016\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.90230\n",
            "Epoch 540/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2786 - acc: 0.9610 - val_loss: 0.5129 - val_acc: 0.8971\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.90230\n",
            "Epoch 541/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2825 - acc: 0.9596 - val_loss: 0.5034 - val_acc: 0.8972\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.90230\n",
            "Epoch 542/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2910 - acc: 0.9556 - val_loss: 0.4974 - val_acc: 0.9003\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.90230\n",
            "Epoch 543/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2827 - acc: 0.9589 - val_loss: 0.5073 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.90230\n",
            "Epoch 544/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2938 - acc: 0.9560 - val_loss: 0.5092 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.90230\n",
            "Epoch 545/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2823 - acc: 0.9584 - val_loss: 0.5006 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.90230\n",
            "Epoch 546/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2842 - acc: 0.9584 - val_loss: 0.5092 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.90230\n",
            "Epoch 547/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2763 - acc: 0.9634 - val_loss: 0.5007 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.90230\n",
            "Epoch 548/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2798 - acc: 0.9615 - val_loss: 0.5061 - val_acc: 0.8979\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.90230\n",
            "Epoch 549/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2834 - acc: 0.9580 - val_loss: 0.5085 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.90230\n",
            "Epoch 550/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2815 - acc: 0.9596 - val_loss: 0.5071 - val_acc: 0.8970\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.90230\n",
            "Epoch 551/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2831 - acc: 0.9574 - val_loss: 0.5081 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.90230\n",
            "Epoch 552/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2847 - acc: 0.9572 - val_loss: 0.5031 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.90230\n",
            "Epoch 553/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2785 - acc: 0.9636 - val_loss: 0.5026 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.90230\n",
            "Epoch 554/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2808 - acc: 0.9578 - val_loss: 0.5045 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.90230\n",
            "Epoch 555/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2817 - acc: 0.9602 - val_loss: 0.5113 - val_acc: 0.8958\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.90230\n",
            "Epoch 556/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2830 - acc: 0.9601 - val_loss: 0.5044 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.90230\n",
            "Epoch 557/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2815 - acc: 0.9585 - val_loss: 0.5085 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.90230\n",
            "Epoch 558/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2759 - acc: 0.9610 - val_loss: 0.5125 - val_acc: 0.8971\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.90230\n",
            "Epoch 559/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2730 - acc: 0.9634 - val_loss: 0.5201 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.90230\n",
            "Epoch 560/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2865 - acc: 0.9574 - val_loss: 0.5085 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.90230\n",
            "Epoch 561/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2806 - acc: 0.9596 - val_loss: 0.5146 - val_acc: 0.8960\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.90230\n",
            "Epoch 562/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2842 - acc: 0.9587 - val_loss: 0.5069 - val_acc: 0.8966\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.90230\n",
            "Epoch 563/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2746 - acc: 0.9644 - val_loss: 0.5176 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.90230\n",
            "Epoch 564/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2762 - acc: 0.9614 - val_loss: 0.4983 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.90230\n",
            "Epoch 565/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2753 - acc: 0.9600 - val_loss: 0.5056 - val_acc: 0.8966\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.90230\n",
            "Epoch 566/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2785 - acc: 0.9591 - val_loss: 0.5135 - val_acc: 0.8982\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.90230\n",
            "Epoch 567/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2774 - acc: 0.9600 - val_loss: 0.5075 - val_acc: 0.8982\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.90230\n",
            "Epoch 568/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2752 - acc: 0.9611 - val_loss: 0.5171 - val_acc: 0.8982\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.90230\n",
            "Epoch 569/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2743 - acc: 0.9625 - val_loss: 0.5039 - val_acc: 0.8982\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.90230\n",
            "Epoch 570/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2789 - acc: 0.9621 - val_loss: 0.5160 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.90230\n",
            "Epoch 571/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2794 - acc: 0.9603 - val_loss: 0.5075 - val_acc: 0.8962\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.90230\n",
            "Epoch 572/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2830 - acc: 0.9584 - val_loss: 0.5032 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.90230\n",
            "Epoch 573/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2790 - acc: 0.9582 - val_loss: 0.5210 - val_acc: 0.8967\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.90230\n",
            "Epoch 574/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2712 - acc: 0.9615 - val_loss: 0.5308 - val_acc: 0.8947\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.90230\n",
            "Epoch 575/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2745 - acc: 0.9595 - val_loss: 0.5042 - val_acc: 0.9004\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.90230\n",
            "Epoch 576/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2761 - acc: 0.9598 - val_loss: 0.5013 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.90230\n",
            "Epoch 577/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2717 - acc: 0.9623 - val_loss: 0.5049 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.90230\n",
            "Epoch 578/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2671 - acc: 0.9644 - val_loss: 0.5099 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.90230\n",
            "Epoch 579/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2785 - acc: 0.9590 - val_loss: 0.5144 - val_acc: 0.8972\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.90230\n",
            "Epoch 580/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2720 - acc: 0.9618 - val_loss: 0.5276 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.90230\n",
            "Epoch 581/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2664 - acc: 0.9652 - val_loss: 0.5210 - val_acc: 0.8962\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.90230\n",
            "Epoch 582/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2706 - acc: 0.9639 - val_loss: 0.5082 - val_acc: 0.9009\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.90230\n",
            "Epoch 583/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2739 - acc: 0.9625 - val_loss: 0.5137 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.90230\n",
            "Epoch 584/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2698 - acc: 0.9622 - val_loss: 0.5065 - val_acc: 0.8987\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.90230\n",
            "Epoch 585/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2716 - acc: 0.9639 - val_loss: 0.5061 - val_acc: 0.9033\n",
            "\n",
            "Epoch 00585: val_acc improved from 0.90230 to 0.90330, saving model to /content/saved_models/cifar10_ResNet32v1_model.585.h5\n",
            "Epoch 586/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2727 - acc: 0.9599 - val_loss: 0.5161 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.90330\n",
            "Epoch 587/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2701 - acc: 0.9613 - val_loss: 0.5392 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.90330\n",
            "Epoch 588/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2794 - acc: 0.9588 - val_loss: 0.5109 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.90330\n",
            "Epoch 589/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2727 - acc: 0.9615 - val_loss: 0.5087 - val_acc: 0.8998\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.90330\n",
            "Epoch 590/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2771 - acc: 0.9592 - val_loss: 0.5167 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.90330\n",
            "Epoch 591/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2712 - acc: 0.9641 - val_loss: 0.5153 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.90330\n",
            "Epoch 592/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2654 - acc: 0.9633 - val_loss: 0.5142 - val_acc: 0.8987\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.90330\n",
            "Epoch 593/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.2710 - acc: 0.9613 - val_loss: 0.5239 - val_acc: 0.8943\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.90330\n",
            "Epoch 594/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2734 - acc: 0.9608 - val_loss: 0.5184 - val_acc: 0.8967\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.90330\n",
            "Epoch 595/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2736 - acc: 0.9601 - val_loss: 0.5159 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.90330\n",
            "Epoch 596/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2701 - acc: 0.9606 - val_loss: 0.5168 - val_acc: 0.8979\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.90330\n",
            "Epoch 597/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2712 - acc: 0.9615 - val_loss: 0.5167 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.90330\n",
            "Epoch 598/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2716 - acc: 0.9628 - val_loss: 0.5126 - val_acc: 0.8982\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.90330\n",
            "Epoch 599/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2710 - acc: 0.9610 - val_loss: 0.5198 - val_acc: 0.8954\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.90330\n",
            "Epoch 600/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2670 - acc: 0.9630 - val_loss: 0.5105 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.90330\n",
            "Epoch 601/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2645 - acc: 0.9646 - val_loss: 0.5104 - val_acc: 0.8982\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.90330\n",
            "Epoch 602/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2656 - acc: 0.9632 - val_loss: 0.5092 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00602: val_acc did not improve from 0.90330\n",
            "Epoch 603/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2650 - acc: 0.9641 - val_loss: 0.5093 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00603: val_acc did not improve from 0.90330\n",
            "Epoch 604/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2652 - acc: 0.9630 - val_loss: 0.5097 - val_acc: 0.8987\n",
            "\n",
            "Epoch 00604: val_acc did not improve from 0.90330\n",
            "Epoch 605/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2635 - acc: 0.9638 - val_loss: 0.5087 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00605: val_acc did not improve from 0.90330\n",
            "Epoch 606/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2764 - acc: 0.9577 - val_loss: 0.5089 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00606: val_acc did not improve from 0.90330\n",
            "Epoch 607/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2705 - acc: 0.9634 - val_loss: 0.5079 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00607: val_acc did not improve from 0.90330\n",
            "Epoch 608/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2657 - acc: 0.9623 - val_loss: 0.5076 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00608: val_acc did not improve from 0.90330\n",
            "Epoch 609/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.2625 - acc: 0.9679 - val_loss: 0.5077 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00609: val_acc did not improve from 0.90330\n",
            "Epoch 610/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2609 - acc: 0.9658 - val_loss: 0.5084 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00610: val_acc did not improve from 0.90330\n",
            "Epoch 611/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2644 - acc: 0.9617 - val_loss: 0.5074 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.90330\n",
            "Epoch 612/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2643 - acc: 0.9636 - val_loss: 0.5073 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00612: val_acc did not improve from 0.90330\n",
            "Epoch 613/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2663 - acc: 0.9634 - val_loss: 0.5072 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00613: val_acc did not improve from 0.90330\n",
            "Epoch 614/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2615 - acc: 0.9631 - val_loss: 0.5074 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.90330\n",
            "Epoch 615/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2631 - acc: 0.9630 - val_loss: 0.5084 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.90330\n",
            "Epoch 616/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.2653 - acc: 0.9654 - val_loss: 0.5082 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00616: val_acc did not improve from 0.90330\n",
            "Epoch 617/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2704 - acc: 0.9634 - val_loss: 0.5071 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.90330\n",
            "Epoch 618/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2608 - acc: 0.9650 - val_loss: 0.5072 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00618: val_acc did not improve from 0.90330\n",
            "Epoch 619/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2660 - acc: 0.9601 - val_loss: 0.5082 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00619: val_acc did not improve from 0.90330\n",
            "Epoch 620/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2625 - acc: 0.9640 - val_loss: 0.5070 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.90330\n",
            "Epoch 621/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2635 - acc: 0.9636 - val_loss: 0.5067 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00621: val_acc did not improve from 0.90330\n",
            "Epoch 622/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.2585 - acc: 0.9661 - val_loss: 0.5057 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.90330\n",
            "Epoch 623/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2645 - acc: 0.9645 - val_loss: 0.5055 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.90330\n",
            "Epoch 624/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2681 - acc: 0.9627 - val_loss: 0.5061 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.90330\n",
            "Epoch 625/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2614 - acc: 0.9649 - val_loss: 0.5062 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.90330\n",
            "Epoch 626/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.2669 - acc: 0.9636 - val_loss: 0.5057 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.90330\n",
            "Epoch 627/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2674 - acc: 0.9624 - val_loss: 0.5061 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00627: val_acc did not improve from 0.90330\n",
            "Epoch 628/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.2608 - acc: 0.9645 - val_loss: 0.5048 - val_acc: 0.9002\n",
            "\n",
            "Epoch 00628: val_acc did not improve from 0.90330\n",
            "Epoch 629/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2626 - acc: 0.9643 - val_loss: 0.5048 - val_acc: 0.8998\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.90330\n",
            "Epoch 630/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2708 - acc: 0.9617 - val_loss: 0.5050 - val_acc: 0.8998\n",
            "\n",
            "Epoch 00630: val_acc did not improve from 0.90330\n",
            "Epoch 631/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2693 - acc: 0.9626 - val_loss: 0.5053 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00631: val_acc did not improve from 0.90330\n",
            "Epoch 632/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2664 - acc: 0.9649 - val_loss: 0.5054 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00632: val_acc did not improve from 0.90330\n",
            "Epoch 633/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.2577 - acc: 0.9667 - val_loss: 0.5049 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.90330\n",
            "Epoch 634/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2708 - acc: 0.9627 - val_loss: 0.5039 - val_acc: 0.8998\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.90330\n",
            "Epoch 635/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2582 - acc: 0.9665 - val_loss: 0.5052 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.90330\n",
            "Epoch 636/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2587 - acc: 0.9659 - val_loss: 0.5039 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.90330\n",
            "Epoch 637/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2716 - acc: 0.9620 - val_loss: 0.5033 - val_acc: 0.9002\n",
            "\n",
            "Epoch 00637: val_acc did not improve from 0.90330\n",
            "Epoch 638/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2650 - acc: 0.9629 - val_loss: 0.5044 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.90330\n",
            "Epoch 639/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2650 - acc: 0.9625 - val_loss: 0.5044 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.90330\n",
            "Epoch 640/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2610 - acc: 0.9656 - val_loss: 0.5032 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.90330\n",
            "Epoch 641/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2619 - acc: 0.9659 - val_loss: 0.5036 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.90330\n",
            "Epoch 642/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2595 - acc: 0.9647 - val_loss: 0.5030 - val_acc: 0.9004\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.90330\n",
            "Epoch 643/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2614 - acc: 0.9633 - val_loss: 0.5033 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.90330\n",
            "Epoch 644/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2592 - acc: 0.9668 - val_loss: 0.5032 - val_acc: 0.9003\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.90330\n",
            "Epoch 645/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2578 - acc: 0.9668 - val_loss: 0.5030 - val_acc: 0.9005\n",
            "\n",
            "Epoch 00645: val_acc did not improve from 0.90330\n",
            "Epoch 646/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2690 - acc: 0.9621 - val_loss: 0.5039 - val_acc: 0.9003\n",
            "\n",
            "Epoch 00646: val_acc did not improve from 0.90330\n",
            "Epoch 647/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2629 - acc: 0.9656 - val_loss: 0.5039 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00647: val_acc did not improve from 0.90330\n",
            "Epoch 648/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2628 - acc: 0.9626 - val_loss: 0.5039 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.90330\n",
            "Epoch 649/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2614 - acc: 0.9650 - val_loss: 0.5036 - val_acc: 0.9002\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.90330\n",
            "Epoch 650/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2601 - acc: 0.9649 - val_loss: 0.5039 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00650: val_acc did not improve from 0.90330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "ktOC0SItfVrC",
        "outputId": "45aff646-9f7d-4a9e-90f8-5f878a7dc83f"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('trainHistoryDict', \"rb\"))\n",
        "functions.plot_loss_acc(history, 4, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDLkvN8ifVrC",
        "outputId": "8675b02e-02e7-4563-cbd6-39bd955c30d4"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9000999927520752"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSqSugfYfVrD",
        "outputId": "bc7febfa-5ccc-4f0d-87ca-77ce48ac6356"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0999000072479248"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCygJmhBfcNw"
      },
      "source": [
        "#### Model with clipping to 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6Tmnr3-fcNx",
        "outputId": "2a99c376-1eea-4eb1-e6f8-e806d361fd59"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(\n",
        "    input_shape, conv_layer = functions.ConvDecomposed2D, decomposition_rank=29)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKM0PP2FfcNy",
        "outputId": "6db72fb0-3160-46b5-926c-f6ea6db62eb5"
      },
      "source": [
        "callbacks = functions.standard_callbacks(model_type) + [functions.Clipping(0.5)]\n",
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'trainHistoryDict_clip_05', steps_per_epoch=100, epochs=650,\n",
        "                       batch_size=100,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 48s 106ms/step - loss: 2.7845 - acc: 0.2686 - val_loss: 13.4940 - val_acc: 0.1220\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.12200, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 2.0428 - acc: 0.2900 - val_loss: 2.7684 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.12200\n",
            "Epoch 3/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.8819 - acc: 0.3529 - val_loss: 2.9100 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.12200\n",
            "Epoch 4/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.7744 - acc: 0.4004 - val_loss: 3.1598 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.12200\n",
            "Epoch 5/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.6537 - acc: 0.4555 - val_loss: 3.4897 - val_acc: 0.1201\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.12200\n",
            "Epoch 6/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.5422 - acc: 0.4967 - val_loss: 2.7842 - val_acc: 0.1945\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.12200 to 0.19450, saving model to /content/saved_models/cifar10_ResNet32v1_model.006.h5\n",
            "Epoch 7/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.4598 - acc: 0.5345 - val_loss: 2.2739 - val_acc: 0.3620\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.19450 to 0.36200, saving model to /content/saved_models/cifar10_ResNet32v1_model.007.h5\n",
            "Epoch 8/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4033 - acc: 0.5574 - val_loss: 2.0663 - val_acc: 0.3946\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.36200 to 0.39460, saving model to /content/saved_models/cifar10_ResNet32v1_model.008.h5\n",
            "Epoch 9/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3871 - acc: 0.5616 - val_loss: 3.0632 - val_acc: 0.2895\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.39460\n",
            "Epoch 10/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3267 - acc: 0.5876 - val_loss: 3.3122 - val_acc: 0.3285\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.39460\n",
            "Epoch 11/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2695 - acc: 0.6075 - val_loss: 2.1415 - val_acc: 0.4726\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.39460 to 0.47260, saving model to /content/saved_models/cifar10_ResNet32v1_model.011.h5\n",
            "Epoch 12/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2365 - acc: 0.6146 - val_loss: 1.8644 - val_acc: 0.4670\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.47260\n",
            "Epoch 13/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2221 - acc: 0.6178 - val_loss: 2.1558 - val_acc: 0.4861\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.47260 to 0.48610, saving model to /content/saved_models/cifar10_ResNet32v1_model.013.h5\n",
            "Epoch 14/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2102 - acc: 0.6287 - val_loss: 2.9850 - val_acc: 0.4027\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.48610\n",
            "Epoch 15/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.1815 - acc: 0.6418 - val_loss: 3.6103 - val_acc: 0.2878\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.48610\n",
            "Epoch 16/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.1516 - acc: 0.6510 - val_loss: 1.9357 - val_acc: 0.4874\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.48610 to 0.48740, saving model to /content/saved_models/cifar10_ResNet32v1_model.016.h5\n",
            "Epoch 17/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.1495 - acc: 0.6465 - val_loss: 3.0376 - val_acc: 0.3622\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.48740\n",
            "Epoch 18/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.1048 - acc: 0.6783 - val_loss: 2.7090 - val_acc: 0.4315\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.48740\n",
            "Epoch 19/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.1163 - acc: 0.6661 - val_loss: 1.5296 - val_acc: 0.5642\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.48740 to 0.56420, saving model to /content/saved_models/cifar10_ResNet32v1_model.019.h5\n",
            "Epoch 20/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.0815 - acc: 0.6793 - val_loss: 4.3657 - val_acc: 0.3178\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.56420\n",
            "Epoch 21/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.0826 - acc: 0.6788 - val_loss: 1.6812 - val_acc: 0.5542\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.56420\n",
            "Epoch 22/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.0663 - acc: 0.6878 - val_loss: 4.3744 - val_acc: 0.3506\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.56420\n",
            "Epoch 23/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.0473 - acc: 0.6956 - val_loss: 4.6334 - val_acc: 0.3036\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.56420\n",
            "Epoch 24/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.0413 - acc: 0.6968 - val_loss: 3.1426 - val_acc: 0.4101\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.56420\n",
            "Epoch 25/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.0473 - acc: 0.6940 - val_loss: 2.0320 - val_acc: 0.5146\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.56420\n",
            "Epoch 26/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.0426 - acc: 0.6989 - val_loss: 6.3817 - val_acc: 0.2412\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.56420\n",
            "Epoch 27/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.0227 - acc: 0.6989 - val_loss: 3.9563 - val_acc: 0.3595\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.56420\n",
            "Epoch 28/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.0182 - acc: 0.6983 - val_loss: 7.2505 - val_acc: 0.2850\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.56420\n",
            "Epoch 29/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.0317 - acc: 0.7006 - val_loss: 3.4373 - val_acc: 0.3680\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.56420\n",
            "Epoch 30/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.0068 - acc: 0.7112 - val_loss: 4.2991 - val_acc: 0.3109\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.56420\n",
            "Epoch 31/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9929 - acc: 0.7111 - val_loss: 2.8500 - val_acc: 0.4290\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.56420\n",
            "Epoch 32/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9913 - acc: 0.7167 - val_loss: 3.4256 - val_acc: 0.3807\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.56420\n",
            "Epoch 33/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9832 - acc: 0.7153 - val_loss: 2.1677 - val_acc: 0.4698\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.56420\n",
            "Epoch 34/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9829 - acc: 0.7154 - val_loss: 2.4146 - val_acc: 0.4609\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.56420\n",
            "Epoch 35/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9756 - acc: 0.7141 - val_loss: 3.8816 - val_acc: 0.3886\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.56420\n",
            "Epoch 36/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.9678 - acc: 0.7191 - val_loss: 4.1072 - val_acc: 0.3868\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.56420\n",
            "Epoch 37/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9720 - acc: 0.7157 - val_loss: 3.3807 - val_acc: 0.4177\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.56420\n",
            "Epoch 38/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9620 - acc: 0.7196 - val_loss: 1.6857 - val_acc: 0.5741\n",
            "\n",
            "Epoch 00038: val_acc improved from 0.56420 to 0.57410, saving model to /content/saved_models/cifar10_ResNet32v1_model.038.h5\n",
            "Epoch 39/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9531 - acc: 0.7287 - val_loss: 3.3350 - val_acc: 0.4315\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.57410\n",
            "Epoch 40/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9547 - acc: 0.7252 - val_loss: 3.8145 - val_acc: 0.3408\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.57410\n",
            "Epoch 41/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9333 - acc: 0.7330 - val_loss: 2.4274 - val_acc: 0.4801\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.57410\n",
            "Epoch 42/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9550 - acc: 0.7215 - val_loss: 1.6581 - val_acc: 0.5575\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.57410\n",
            "Epoch 43/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9314 - acc: 0.7337 - val_loss: 2.3236 - val_acc: 0.4485\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.57410\n",
            "Epoch 44/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9260 - acc: 0.7339 - val_loss: 2.1321 - val_acc: 0.5292\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.57410\n",
            "Epoch 45/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9396 - acc: 0.7285 - val_loss: 3.4406 - val_acc: 0.3540\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.57410\n",
            "Epoch 46/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9129 - acc: 0.7412 - val_loss: 1.8414 - val_acc: 0.5297\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.57410\n",
            "Epoch 47/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9042 - acc: 0.7407 - val_loss: 6.3262 - val_acc: 0.2526\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.57410\n",
            "Epoch 48/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9081 - acc: 0.7452 - val_loss: 2.2313 - val_acc: 0.4987\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.57410\n",
            "Epoch 49/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8994 - acc: 0.7485 - val_loss: 3.8636 - val_acc: 0.3479\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.57410\n",
            "Epoch 50/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9051 - acc: 0.7457 - val_loss: 6.1307 - val_acc: 0.2580\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.57410\n",
            "Epoch 51/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9050 - acc: 0.7376 - val_loss: 1.4505 - val_acc: 0.6099\n",
            "\n",
            "Epoch 00051: val_acc improved from 0.57410 to 0.60990, saving model to /content/saved_models/cifar10_ResNet32v1_model.051.h5\n",
            "Epoch 52/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9021 - acc: 0.7395 - val_loss: 1.9525 - val_acc: 0.5154\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.60990\n",
            "Epoch 53/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8996 - acc: 0.7462 - val_loss: 2.0511 - val_acc: 0.5654\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.60990\n",
            "Epoch 54/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9023 - acc: 0.7475 - val_loss: 2.6446 - val_acc: 0.4642\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.60990\n",
            "Epoch 55/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8926 - acc: 0.7491 - val_loss: 2.3938 - val_acc: 0.4555\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.60990\n",
            "Epoch 56/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8874 - acc: 0.7518 - val_loss: 4.2876 - val_acc: 0.3374\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.60990\n",
            "Epoch 57/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9080 - acc: 0.7419 - val_loss: 2.0441 - val_acc: 0.5282\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.60990\n",
            "Epoch 58/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8837 - acc: 0.7556 - val_loss: 1.3095 - val_acc: 0.6469\n",
            "\n",
            "Epoch 00058: val_acc improved from 0.60990 to 0.64690, saving model to /content/saved_models/cifar10_ResNet32v1_model.058.h5\n",
            "Epoch 59/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8937 - acc: 0.7477 - val_loss: 2.2996 - val_acc: 0.4300\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.64690\n",
            "Epoch 60/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8714 - acc: 0.7607 - val_loss: 2.6383 - val_acc: 0.4808\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.64690\n",
            "Epoch 61/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8794 - acc: 0.7476 - val_loss: 7.4389 - val_acc: 0.2655\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.64690\n",
            "Epoch 62/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.9182 - acc: 0.7421 - val_loss: 3.0170 - val_acc: 0.4059\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.64690\n",
            "Epoch 63/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8795 - acc: 0.7514 - val_loss: 4.0466 - val_acc: 0.3327\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.64690\n",
            "Epoch 64/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8872 - acc: 0.7481 - val_loss: 2.3229 - val_acc: 0.4310\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.64690\n",
            "Epoch 65/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8555 - acc: 0.7586 - val_loss: 2.9032 - val_acc: 0.4593\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.64690\n",
            "Epoch 66/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8675 - acc: 0.7568 - val_loss: 3.3356 - val_acc: 0.3213\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.64690\n",
            "Epoch 67/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8540 - acc: 0.7570 - val_loss: 3.8221 - val_acc: 0.3727\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.64690\n",
            "Epoch 68/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8578 - acc: 0.7598 - val_loss: 2.8427 - val_acc: 0.4046\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.64690\n",
            "Epoch 69/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8795 - acc: 0.7544 - val_loss: 4.0326 - val_acc: 0.2975\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.64690\n",
            "Epoch 70/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8674 - acc: 0.7535 - val_loss: 2.0161 - val_acc: 0.5599\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.64690\n",
            "Epoch 71/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8759 - acc: 0.7538 - val_loss: 2.4539 - val_acc: 0.5259\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.64690\n",
            "Epoch 72/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8657 - acc: 0.7601 - val_loss: 1.8250 - val_acc: 0.5922\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.64690\n",
            "Epoch 73/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8610 - acc: 0.7603 - val_loss: 2.5407 - val_acc: 0.4547\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.64690\n",
            "Epoch 74/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8533 - acc: 0.7599 - val_loss: 4.1777 - val_acc: 0.3338\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.64690\n",
            "Epoch 75/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8744 - acc: 0.7559 - val_loss: 1.5870 - val_acc: 0.5970\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.64690\n",
            "Epoch 76/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8546 - acc: 0.7589 - val_loss: 3.5183 - val_acc: 0.3523\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.64690\n",
            "Epoch 77/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8608 - acc: 0.7583 - val_loss: 2.3685 - val_acc: 0.5355\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.64690\n",
            "Epoch 78/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8347 - acc: 0.7651 - val_loss: 1.7445 - val_acc: 0.5391\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.64690\n",
            "Epoch 79/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8472 - acc: 0.7623 - val_loss: 2.6612 - val_acc: 0.4879\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.64690\n",
            "Epoch 80/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8492 - acc: 0.7650 - val_loss: 2.8945 - val_acc: 0.4420\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.64690\n",
            "Epoch 81/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8251 - acc: 0.7698 - val_loss: 5.2927 - val_acc: 0.2679\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.64690\n",
            "Epoch 82/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8420 - acc: 0.7664 - val_loss: 1.8796 - val_acc: 0.5617\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.64690\n",
            "Epoch 83/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8311 - acc: 0.7705 - val_loss: 2.6293 - val_acc: 0.4594\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.64690\n",
            "Epoch 84/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8398 - acc: 0.7698 - val_loss: 2.0787 - val_acc: 0.5577\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.64690\n",
            "Epoch 85/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8455 - acc: 0.7671 - val_loss: 1.7329 - val_acc: 0.5645\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.64690\n",
            "Epoch 86/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8407 - acc: 0.7656 - val_loss: 3.2078 - val_acc: 0.4348\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.64690\n",
            "Epoch 87/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8537 - acc: 0.7620 - val_loss: 1.4450 - val_acc: 0.6229\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.64690\n",
            "Epoch 88/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8404 - acc: 0.7627 - val_loss: 2.0287 - val_acc: 0.5205\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.64690\n",
            "Epoch 89/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8231 - acc: 0.7738 - val_loss: 2.1261 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.64690\n",
            "Epoch 90/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8417 - acc: 0.7677 - val_loss: 2.6949 - val_acc: 0.4525\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.64690\n",
            "Epoch 91/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8344 - acc: 0.7655 - val_loss: 5.3364 - val_acc: 0.2655\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.64690\n",
            "Epoch 92/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8291 - acc: 0.7731 - val_loss: 6.1362 - val_acc: 0.2679\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.64690\n",
            "Epoch 93/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8356 - acc: 0.7681 - val_loss: 2.0685 - val_acc: 0.5357\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.64690\n",
            "Epoch 94/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8187 - acc: 0.7704 - val_loss: 9.9950 - val_acc: 0.1649\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.64690\n",
            "Epoch 95/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8239 - acc: 0.7707 - val_loss: 3.4797 - val_acc: 0.3926\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.64690\n",
            "Epoch 96/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8198 - acc: 0.7744 - val_loss: 1.4593 - val_acc: 0.6280\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.64690\n",
            "Epoch 97/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8247 - acc: 0.7733 - val_loss: 4.6325 - val_acc: 0.3775\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.64690\n",
            "Epoch 98/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8112 - acc: 0.7799 - val_loss: 2.0209 - val_acc: 0.5157\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.64690\n",
            "Epoch 99/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8217 - acc: 0.7772 - val_loss: 2.6632 - val_acc: 0.4456\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.64690\n",
            "Epoch 100/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8284 - acc: 0.7748 - val_loss: 1.7984 - val_acc: 0.5958\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.64690\n",
            "Epoch 101/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8208 - acc: 0.7714 - val_loss: 1.7189 - val_acc: 0.5662\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.64690\n",
            "Epoch 102/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8238 - acc: 0.7726 - val_loss: 2.1136 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.64690\n",
            "Epoch 103/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8152 - acc: 0.7759 - val_loss: 4.6972 - val_acc: 0.3170\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.64690\n",
            "Epoch 104/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8303 - acc: 0.7723 - val_loss: 1.5230 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.64690\n",
            "Epoch 105/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8175 - acc: 0.7774 - val_loss: 2.3060 - val_acc: 0.5256\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.64690\n",
            "Epoch 106/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8156 - acc: 0.7718 - val_loss: 1.7474 - val_acc: 0.5448\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.64690\n",
            "Epoch 107/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8306 - acc: 0.7713 - val_loss: 5.4228 - val_acc: 0.2871\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.64690\n",
            "Epoch 108/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8134 - acc: 0.7770 - val_loss: 2.4643 - val_acc: 0.4716\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.64690\n",
            "Epoch 109/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8173 - acc: 0.7761 - val_loss: 2.4216 - val_acc: 0.5502\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.64690\n",
            "Epoch 110/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8146 - acc: 0.7748 - val_loss: 1.6436 - val_acc: 0.6059\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.64690\n",
            "Epoch 111/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8273 - acc: 0.7702 - val_loss: 3.3722 - val_acc: 0.4417\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.64690\n",
            "Epoch 112/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7972 - acc: 0.7832 - val_loss: 1.3531 - val_acc: 0.6535\n",
            "\n",
            "Epoch 00112: val_acc improved from 0.64690 to 0.65350, saving model to /content/saved_models/cifar10_ResNet32v1_model.112.h5\n",
            "Epoch 113/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7979 - acc: 0.7834 - val_loss: 1.2053 - val_acc: 0.6679\n",
            "\n",
            "Epoch 00113: val_acc improved from 0.65350 to 0.66790, saving model to /content/saved_models/cifar10_ResNet32v1_model.113.h5\n",
            "Epoch 114/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7881 - acc: 0.7843 - val_loss: 1.6618 - val_acc: 0.6207\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.66790\n",
            "Epoch 115/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7957 - acc: 0.7836 - val_loss: 3.1813 - val_acc: 0.4410\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.66790\n",
            "Epoch 116/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7958 - acc: 0.7822 - val_loss: 3.3645 - val_acc: 0.4249\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.66790\n",
            "Epoch 117/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8244 - acc: 0.7717 - val_loss: 4.7007 - val_acc: 0.3736\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.66790\n",
            "Epoch 118/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7939 - acc: 0.7845 - val_loss: 2.4302 - val_acc: 0.4571\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.66790\n",
            "Epoch 119/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7922 - acc: 0.7831 - val_loss: 1.6606 - val_acc: 0.6235\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.66790\n",
            "Epoch 120/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7941 - acc: 0.7851 - val_loss: 1.9809 - val_acc: 0.5655\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.66790\n",
            "Epoch 121/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8068 - acc: 0.7787 - val_loss: 2.0568 - val_acc: 0.5085\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.66790\n",
            "Epoch 122/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8117 - acc: 0.7772 - val_loss: 1.5303 - val_acc: 0.6048\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.66790\n",
            "Epoch 123/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7870 - acc: 0.7848 - val_loss: 3.0522 - val_acc: 0.4385\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.66790\n",
            "Epoch 124/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7830 - acc: 0.7885 - val_loss: 5.0385 - val_acc: 0.3360\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.66790\n",
            "Epoch 125/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7794 - acc: 0.7872 - val_loss: 8.3490 - val_acc: 0.2075\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.66790\n",
            "Epoch 126/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7916 - acc: 0.7864 - val_loss: 1.9557 - val_acc: 0.5656\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.66790\n",
            "Epoch 127/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7796 - acc: 0.7885 - val_loss: 2.8249 - val_acc: 0.4126\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.66790\n",
            "Epoch 128/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7856 - acc: 0.7913 - val_loss: 1.5472 - val_acc: 0.5690\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.66790\n",
            "Epoch 129/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7889 - acc: 0.7842 - val_loss: 3.1372 - val_acc: 0.4017\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.66790\n",
            "Epoch 130/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7666 - acc: 0.7933 - val_loss: 3.3164 - val_acc: 0.3488\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.66790\n",
            "Epoch 131/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7792 - acc: 0.7899 - val_loss: 1.8875 - val_acc: 0.5502\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.66790\n",
            "Epoch 132/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7792 - acc: 0.7904 - val_loss: 4.7555 - val_acc: 0.2844\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.66790\n",
            "Epoch 133/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7872 - acc: 0.7844 - val_loss: 5.4901 - val_acc: 0.2579\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.66790\n",
            "Epoch 134/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7817 - acc: 0.7884 - val_loss: 1.4274 - val_acc: 0.6481\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.66790\n",
            "Epoch 135/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8099 - acc: 0.7828 - val_loss: 1.6238 - val_acc: 0.5598\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.66790\n",
            "Epoch 136/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7831 - acc: 0.7824 - val_loss: 2.4914 - val_acc: 0.4358\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.66790\n",
            "Epoch 137/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8012 - acc: 0.7804 - val_loss: 1.4522 - val_acc: 0.5962\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.66790\n",
            "Epoch 138/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8028 - acc: 0.7799 - val_loss: 3.6381 - val_acc: 0.3077\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.66790\n",
            "Epoch 139/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7846 - acc: 0.7906 - val_loss: 2.8763 - val_acc: 0.3720\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.66790\n",
            "Epoch 140/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7829 - acc: 0.7871 - val_loss: 4.1806 - val_acc: 0.4445\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.66790\n",
            "Epoch 141/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8047 - acc: 0.7822 - val_loss: 4.3175 - val_acc: 0.3902\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.66790\n",
            "Epoch 142/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7797 - acc: 0.7877 - val_loss: 3.9207 - val_acc: 0.3558\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.66790\n",
            "Epoch 143/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7924 - acc: 0.7847 - val_loss: 2.2284 - val_acc: 0.5081\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.66790\n",
            "Epoch 144/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7523 - acc: 0.7979 - val_loss: 2.9205 - val_acc: 0.4528\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.66790\n",
            "Epoch 145/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7717 - acc: 0.7938 - val_loss: 2.2550 - val_acc: 0.5065\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.66790\n",
            "Epoch 146/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7640 - acc: 0.7950 - val_loss: 1.7568 - val_acc: 0.5683\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.66790\n",
            "Epoch 147/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7679 - acc: 0.7934 - val_loss: 2.4575 - val_acc: 0.5132\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.66790\n",
            "Epoch 148/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7800 - acc: 0.7914 - val_loss: 3.5771 - val_acc: 0.3315\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.66790\n",
            "Epoch 149/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7844 - acc: 0.7875 - val_loss: 2.2105 - val_acc: 0.5149\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.66790\n",
            "Epoch 150/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7654 - acc: 0.7900 - val_loss: 2.4215 - val_acc: 0.5008\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.66790\n",
            "Epoch 151/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7861 - acc: 0.7889 - val_loss: 3.3801 - val_acc: 0.3344\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.66790\n",
            "Epoch 152/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7836 - acc: 0.7865 - val_loss: 1.9697 - val_acc: 0.5678\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.66790\n",
            "Epoch 153/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7624 - acc: 0.7957 - val_loss: 1.4810 - val_acc: 0.5966\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.66790\n",
            "Epoch 154/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7494 - acc: 0.8027 - val_loss: 1.2621 - val_acc: 0.6821\n",
            "\n",
            "Epoch 00154: val_acc improved from 0.66790 to 0.68210, saving model to /content/saved_models/cifar10_ResNet32v1_model.154.h5\n",
            "Epoch 155/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7814 - acc: 0.7878 - val_loss: 2.0962 - val_acc: 0.5376\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.68210\n",
            "Epoch 156/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7753 - acc: 0.7924 - val_loss: 2.3448 - val_acc: 0.4782\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.68210\n",
            "Epoch 157/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7686 - acc: 0.7955 - val_loss: 2.4074 - val_acc: 0.4782\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.68210\n",
            "Epoch 158/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7798 - acc: 0.7898 - val_loss: 1.6704 - val_acc: 0.5919\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.68210\n",
            "Epoch 159/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7698 - acc: 0.7916 - val_loss: 4.1365 - val_acc: 0.3230\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.68210\n",
            "Epoch 160/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7773 - acc: 0.7890 - val_loss: 1.9245 - val_acc: 0.5778\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.68210\n",
            "Epoch 161/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7823 - acc: 0.7908 - val_loss: 2.4088 - val_acc: 0.5197\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.68210\n",
            "Epoch 162/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7525 - acc: 0.7930 - val_loss: 3.0009 - val_acc: 0.4833\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.68210\n",
            "Epoch 163/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7817 - acc: 0.7907 - val_loss: 8.4983 - val_acc: 0.1764\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.68210\n",
            "Epoch 164/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7954 - acc: 0.7838 - val_loss: 1.3060 - val_acc: 0.6506\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.68210\n",
            "Epoch 165/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7809 - acc: 0.7854 - val_loss: 1.9144 - val_acc: 0.5453\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.68210\n",
            "Epoch 166/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7685 - acc: 0.7932 - val_loss: 1.7626 - val_acc: 0.5440\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.68210\n",
            "Epoch 167/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7839 - acc: 0.7876 - val_loss: 1.9613 - val_acc: 0.5852\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.68210\n",
            "Epoch 168/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7722 - acc: 0.7902 - val_loss: 2.1419 - val_acc: 0.5275\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.68210\n",
            "Epoch 169/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7854 - acc: 0.7847 - val_loss: 3.7993 - val_acc: 0.3495\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.68210\n",
            "Epoch 170/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7650 - acc: 0.7946 - val_loss: 1.7470 - val_acc: 0.5761\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.68210\n",
            "Epoch 171/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7721 - acc: 0.7895 - val_loss: 1.4326 - val_acc: 0.6237\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.68210\n",
            "Epoch 172/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7627 - acc: 0.7968 - val_loss: 4.0558 - val_acc: 0.3790\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.68210\n",
            "Epoch 173/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7680 - acc: 0.7973 - val_loss: 2.0757 - val_acc: 0.5534\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.68210\n",
            "Epoch 174/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7589 - acc: 0.7966 - val_loss: 5.2581 - val_acc: 0.3265\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.68210\n",
            "Epoch 175/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7463 - acc: 0.8008 - val_loss: 2.2082 - val_acc: 0.5141\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.68210\n",
            "Epoch 176/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7621 - acc: 0.7962 - val_loss: 1.6383 - val_acc: 0.5397\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.68210\n",
            "Epoch 177/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7594 - acc: 0.7945 - val_loss: 1.4403 - val_acc: 0.6530\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.68210\n",
            "Epoch 178/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7648 - acc: 0.7954 - val_loss: 2.0370 - val_acc: 0.4418\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.68210\n",
            "Epoch 179/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7693 - acc: 0.7906 - val_loss: 3.4312 - val_acc: 0.4357\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.68210\n",
            "Epoch 180/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7530 - acc: 0.7921 - val_loss: 1.9077 - val_acc: 0.5458\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.68210\n",
            "Epoch 181/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7630 - acc: 0.7913 - val_loss: 2.7583 - val_acc: 0.4367\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.68210\n",
            "Epoch 182/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7448 - acc: 0.8007 - val_loss: 2.4436 - val_acc: 0.4983\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.68210\n",
            "Epoch 183/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7543 - acc: 0.8003 - val_loss: 2.0299 - val_acc: 0.5443\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.68210\n",
            "Epoch 184/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7625 - acc: 0.7934 - val_loss: 1.2655 - val_acc: 0.6798\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.68210\n",
            "Epoch 185/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7674 - acc: 0.7944 - val_loss: 1.5363 - val_acc: 0.6328\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.68210\n",
            "Epoch 186/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7511 - acc: 0.7979 - val_loss: 1.5405 - val_acc: 0.6058\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.68210\n",
            "Epoch 187/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7786 - acc: 0.7874 - val_loss: 2.4587 - val_acc: 0.5328\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.68210\n",
            "Epoch 188/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7487 - acc: 0.7991 - val_loss: 2.5045 - val_acc: 0.4634\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.68210\n",
            "Epoch 189/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7634 - acc: 0.7949 - val_loss: 2.5222 - val_acc: 0.3940\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.68210\n",
            "Epoch 190/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7652 - acc: 0.7916 - val_loss: 1.2855 - val_acc: 0.6773\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.68210\n",
            "Epoch 191/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7424 - acc: 0.7993 - val_loss: 3.0442 - val_acc: 0.3910\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.68210\n",
            "Epoch 192/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7497 - acc: 0.8001 - val_loss: 4.6477 - val_acc: 0.3285\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.68210\n",
            "Epoch 193/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7493 - acc: 0.7980 - val_loss: 2.3471 - val_acc: 0.5338\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.68210\n",
            "Epoch 194/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7473 - acc: 0.8004 - val_loss: 2.4051 - val_acc: 0.5674\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.68210\n",
            "Epoch 195/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7676 - acc: 0.7916 - val_loss: 1.6537 - val_acc: 0.5877\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.68210\n",
            "Epoch 196/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7571 - acc: 0.7965 - val_loss: 2.3406 - val_acc: 0.4052\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.68210\n",
            "Epoch 197/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7295 - acc: 0.8062 - val_loss: 1.1999 - val_acc: 0.7065\n",
            "\n",
            "Epoch 00197: val_acc improved from 0.68210 to 0.70650, saving model to /content/saved_models/cifar10_ResNet32v1_model.197.h5\n",
            "Epoch 198/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7717 - acc: 0.7932 - val_loss: 1.8026 - val_acc: 0.5811\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.70650\n",
            "Epoch 199/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7561 - acc: 0.7965 - val_loss: 4.6188 - val_acc: 0.3700\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.70650\n",
            "Epoch 200/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7542 - acc: 0.7989 - val_loss: 2.5355 - val_acc: 0.4774\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.70650\n",
            "Epoch 201/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7482 - acc: 0.8021 - val_loss: 2.8582 - val_acc: 0.4038\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.70650\n",
            "Epoch 202/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7533 - acc: 0.7969 - val_loss: 1.9000 - val_acc: 0.5515\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.70650\n",
            "Epoch 203/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7378 - acc: 0.8074 - val_loss: 2.1324 - val_acc: 0.5580\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.70650\n",
            "Epoch 204/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7683 - acc: 0.7980 - val_loss: 1.9592 - val_acc: 0.5455\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.70650\n",
            "Epoch 205/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7631 - acc: 0.7922 - val_loss: 1.6015 - val_acc: 0.6162\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.70650\n",
            "Epoch 206/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7492 - acc: 0.7952 - val_loss: 2.2984 - val_acc: 0.5126\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.70650\n",
            "Epoch 207/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7426 - acc: 0.7986 - val_loss: 2.1422 - val_acc: 0.4670\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.70650\n",
            "Epoch 208/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7417 - acc: 0.8054 - val_loss: 2.6132 - val_acc: 0.4254\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.70650\n",
            "Epoch 209/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7807 - acc: 0.7901 - val_loss: 1.9154 - val_acc: 0.5017\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.70650\n",
            "Epoch 210/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7417 - acc: 0.8017 - val_loss: 2.3153 - val_acc: 0.5276\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.70650\n",
            "Epoch 211/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7639 - acc: 0.7940 - val_loss: 2.3492 - val_acc: 0.4915\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.70650\n",
            "Epoch 212/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7388 - acc: 0.8050 - val_loss: 3.0293 - val_acc: 0.4778\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.70650\n",
            "Epoch 213/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7473 - acc: 0.7987 - val_loss: 2.1755 - val_acc: 0.4884\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.70650\n",
            "Epoch 214/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7390 - acc: 0.8037 - val_loss: 2.7240 - val_acc: 0.4385\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.70650\n",
            "Epoch 215/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7669 - acc: 0.7914 - val_loss: 3.6257 - val_acc: 0.3871\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.70650\n",
            "Epoch 216/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7383 - acc: 0.8004 - val_loss: 1.6962 - val_acc: 0.5897\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.70650\n",
            "Epoch 217/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7554 - acc: 0.7942 - val_loss: 3.3618 - val_acc: 0.4326\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.70650\n",
            "Epoch 218/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7456 - acc: 0.8021 - val_loss: 1.6747 - val_acc: 0.5605\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.70650\n",
            "Epoch 219/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7646 - acc: 0.7949 - val_loss: 4.4682 - val_acc: 0.3241\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.70650\n",
            "Epoch 220/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7647 - acc: 0.7884 - val_loss: 1.9208 - val_acc: 0.5930\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.70650\n",
            "Epoch 221/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7353 - acc: 0.8031 - val_loss: 1.6349 - val_acc: 0.5782\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.70650\n",
            "Epoch 222/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7418 - acc: 0.8019 - val_loss: 1.2524 - val_acc: 0.6954\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.70650\n",
            "Epoch 223/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7386 - acc: 0.8033 - val_loss: 4.7792 - val_acc: 0.2624\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.70650\n",
            "Epoch 224/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7522 - acc: 0.7993 - val_loss: 1.4403 - val_acc: 0.6180\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.70650\n",
            "Epoch 225/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7345 - acc: 0.8038 - val_loss: 2.5734 - val_acc: 0.4887\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.70650\n",
            "Epoch 226/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7472 - acc: 0.8002 - val_loss: 1.9970 - val_acc: 0.5290\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.70650\n",
            "Epoch 227/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7489 - acc: 0.8005 - val_loss: 4.3538 - val_acc: 0.2492\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.70650\n",
            "Epoch 228/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7635 - acc: 0.7981 - val_loss: 3.6883 - val_acc: 0.3856\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.70650\n",
            "Epoch 229/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7368 - acc: 0.8051 - val_loss: 3.3063 - val_acc: 0.4170\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.70650\n",
            "Epoch 230/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7538 - acc: 0.7979 - val_loss: 2.0063 - val_acc: 0.5655\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.70650\n",
            "Epoch 231/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7507 - acc: 0.7961 - val_loss: 2.7654 - val_acc: 0.4637\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.70650\n",
            "Epoch 232/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7464 - acc: 0.8051 - val_loss: 1.9113 - val_acc: 0.5372\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.70650\n",
            "Epoch 233/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7435 - acc: 0.8002 - val_loss: 1.6388 - val_acc: 0.5720\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.70650\n",
            "Epoch 234/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7412 - acc: 0.8035 - val_loss: 1.5148 - val_acc: 0.6234\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.70650\n",
            "Epoch 235/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7496 - acc: 0.8003 - val_loss: 3.1089 - val_acc: 0.4127\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.70650\n",
            "Epoch 236/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7406 - acc: 0.8015 - val_loss: 1.3747 - val_acc: 0.6714\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.70650\n",
            "Epoch 237/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7487 - acc: 0.7975 - val_loss: 2.7474 - val_acc: 0.4037\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.70650\n",
            "Epoch 238/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7542 - acc: 0.8018 - val_loss: 2.5971 - val_acc: 0.4806\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.70650\n",
            "Epoch 239/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7354 - acc: 0.8091 - val_loss: 1.7921 - val_acc: 0.5587\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.70650\n",
            "Epoch 240/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7308 - acc: 0.8064 - val_loss: 1.2837 - val_acc: 0.6681\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.70650\n",
            "Epoch 241/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7526 - acc: 0.8005 - val_loss: 1.8580 - val_acc: 0.5391\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.70650\n",
            "Epoch 242/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7469 - acc: 0.7985 - val_loss: 2.0470 - val_acc: 0.5482\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.70650\n",
            "Epoch 243/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7305 - acc: 0.8037 - val_loss: 1.2487 - val_acc: 0.6686\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.70650\n",
            "Epoch 244/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7432 - acc: 0.8009 - val_loss: 4.5153 - val_acc: 0.3138\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.70650\n",
            "Epoch 245/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7523 - acc: 0.7983 - val_loss: 3.0420 - val_acc: 0.4173\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.70650\n",
            "Epoch 246/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7588 - acc: 0.7943 - val_loss: 1.9939 - val_acc: 0.5842\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.70650\n",
            "Epoch 247/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7499 - acc: 0.8022 - val_loss: 2.2507 - val_acc: 0.4753\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.70650\n",
            "Epoch 248/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7324 - acc: 0.8042 - val_loss: 1.3969 - val_acc: 0.6123\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.70650\n",
            "Epoch 249/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7142 - acc: 0.8132 - val_loss: 2.1070 - val_acc: 0.5723\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.70650\n",
            "Epoch 250/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7735 - acc: 0.7947 - val_loss: 1.6273 - val_acc: 0.5717\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.70650\n",
            "Epoch 251/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7581 - acc: 0.7931 - val_loss: 1.4543 - val_acc: 0.5852\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.70650\n",
            "Epoch 252/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7273 - acc: 0.8112 - val_loss: 1.4225 - val_acc: 0.6498\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.70650\n",
            "Epoch 253/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7245 - acc: 0.8062 - val_loss: 2.3089 - val_acc: 0.5615\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.70650\n",
            "Epoch 254/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7317 - acc: 0.8054 - val_loss: 2.6651 - val_acc: 0.4112\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.70650\n",
            "Epoch 255/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7369 - acc: 0.8004 - val_loss: 4.1431 - val_acc: 0.3693\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.70650\n",
            "Epoch 256/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7210 - acc: 0.8090 - val_loss: 2.7110 - val_acc: 0.4715\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.70650\n",
            "Epoch 257/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7372 - acc: 0.8055 - val_loss: 1.6188 - val_acc: 0.6104\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.70650\n",
            "Epoch 258/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7302 - acc: 0.8011 - val_loss: 1.7432 - val_acc: 0.5990\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.70650\n",
            "Epoch 259/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7169 - acc: 0.8108 - val_loss: 1.9297 - val_acc: 0.5300\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.70650\n",
            "Epoch 260/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7400 - acc: 0.8054 - val_loss: 1.5806 - val_acc: 0.6060\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.70650\n",
            "Epoch 261/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7320 - acc: 0.8051 - val_loss: 2.6075 - val_acc: 0.3972\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.70650\n",
            "Epoch 262/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7498 - acc: 0.8012 - val_loss: 1.7484 - val_acc: 0.5618\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.70650\n",
            "Epoch 263/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7460 - acc: 0.8020 - val_loss: 2.5247 - val_acc: 0.5248\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.70650\n",
            "Epoch 264/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7427 - acc: 0.8006 - val_loss: 1.4074 - val_acc: 0.6354\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.70650\n",
            "Epoch 265/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7377 - acc: 0.8043 - val_loss: 1.5652 - val_acc: 0.6080\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.70650\n",
            "Epoch 266/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7232 - acc: 0.8093 - val_loss: 1.3394 - val_acc: 0.6607\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.70650\n",
            "Epoch 267/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7519 - acc: 0.8008 - val_loss: 2.4489 - val_acc: 0.4548\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.70650\n",
            "Epoch 268/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7334 - acc: 0.8047 - val_loss: 1.8095 - val_acc: 0.5501\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.70650\n",
            "Epoch 269/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7387 - acc: 0.8025 - val_loss: 3.4132 - val_acc: 0.3978\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.70650\n",
            "Epoch 270/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7394 - acc: 0.8047 - val_loss: 2.4012 - val_acc: 0.4854\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.70650\n",
            "Epoch 271/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7389 - acc: 0.8029 - val_loss: 4.5613 - val_acc: 0.3665\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.70650\n",
            "Epoch 272/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7394 - acc: 0.8042 - val_loss: 2.1115 - val_acc: 0.5134\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.70650\n",
            "Epoch 273/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7493 - acc: 0.7976 - val_loss: 3.6181 - val_acc: 0.4130\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.70650\n",
            "Epoch 274/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7384 - acc: 0.8031 - val_loss: 1.2356 - val_acc: 0.6541\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.70650\n",
            "Epoch 275/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7266 - acc: 0.8068 - val_loss: 1.3725 - val_acc: 0.6345\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.70650\n",
            "Epoch 276/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7220 - acc: 0.8063 - val_loss: 1.8395 - val_acc: 0.5369\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.70650\n",
            "Epoch 277/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7189 - acc: 0.8130 - val_loss: 1.5433 - val_acc: 0.6071\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.70650\n",
            "Epoch 278/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7552 - acc: 0.7988 - val_loss: 3.7185 - val_acc: 0.3729\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.70650\n",
            "Epoch 279/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7009 - acc: 0.8154 - val_loss: 1.5197 - val_acc: 0.6145\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.70650\n",
            "Epoch 280/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7440 - acc: 0.8070 - val_loss: 2.3343 - val_acc: 0.4673\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.70650\n",
            "Epoch 281/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7275 - acc: 0.8067 - val_loss: 1.7018 - val_acc: 0.5950\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.70650\n",
            "Epoch 282/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7281 - acc: 0.8079 - val_loss: 1.6768 - val_acc: 0.5855\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.70650\n",
            "Epoch 283/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7324 - acc: 0.8054 - val_loss: 1.3733 - val_acc: 0.6486\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.70650\n",
            "Epoch 284/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7373 - acc: 0.8055 - val_loss: 1.4828 - val_acc: 0.6268\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.70650\n",
            "Epoch 285/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7388 - acc: 0.8061 - val_loss: 2.2714 - val_acc: 0.5047\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.70650\n",
            "Epoch 286/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7394 - acc: 0.7991 - val_loss: 5.2210 - val_acc: 0.2981\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.70650\n",
            "Epoch 287/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7166 - acc: 0.8137 - val_loss: 1.6646 - val_acc: 0.6026\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.70650\n",
            "Epoch 288/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7331 - acc: 0.8079 - val_loss: 1.4759 - val_acc: 0.6382\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.70650\n",
            "Epoch 289/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7371 - acc: 0.8011 - val_loss: 2.3118 - val_acc: 0.4474\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.70650\n",
            "Epoch 290/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7549 - acc: 0.7954 - val_loss: 1.1893 - val_acc: 0.6902\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.70650\n",
            "Epoch 291/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7232 - acc: 0.8050 - val_loss: 1.2422 - val_acc: 0.6637\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.70650\n",
            "Epoch 292/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7310 - acc: 0.8084 - val_loss: 2.8956 - val_acc: 0.4899\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.70650\n",
            "Epoch 293/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7284 - acc: 0.8026 - val_loss: 2.9718 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.70650\n",
            "Epoch 294/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7186 - acc: 0.8115 - val_loss: 1.5887 - val_acc: 0.5977\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.70650\n",
            "Epoch 295/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7233 - acc: 0.8066 - val_loss: 3.1453 - val_acc: 0.4154\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.70650\n",
            "Epoch 296/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7261 - acc: 0.8059 - val_loss: 1.5088 - val_acc: 0.6393\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.70650\n",
            "Epoch 297/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7231 - acc: 0.8078 - val_loss: 1.8141 - val_acc: 0.5688\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.70650\n",
            "Epoch 298/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7421 - acc: 0.7977 - val_loss: 1.6018 - val_acc: 0.6161\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.70650\n",
            "Epoch 299/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7264 - acc: 0.8049 - val_loss: 3.1970 - val_acc: 0.3943\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.70650\n",
            "Epoch 300/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7324 - acc: 0.8016 - val_loss: 2.2847 - val_acc: 0.5510\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.70650\n",
            "Epoch 301/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7103 - acc: 0.8087 - val_loss: 1.8940 - val_acc: 0.5408\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.70650\n",
            "Epoch 302/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7396 - acc: 0.8032 - val_loss: 1.8258 - val_acc: 0.5720\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.70650\n",
            "Epoch 303/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7344 - acc: 0.8059 - val_loss: 1.3538 - val_acc: 0.6214\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.70650\n",
            "Epoch 304/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7288 - acc: 0.8090 - val_loss: 3.2319 - val_acc: 0.4517\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.70650\n",
            "Epoch 305/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7163 - acc: 0.8128 - val_loss: 3.0912 - val_acc: 0.5272\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.70650\n",
            "Epoch 306/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7170 - acc: 0.8119 - val_loss: 1.5666 - val_acc: 0.5948\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.70650\n",
            "Epoch 307/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7231 - acc: 0.8086 - val_loss: 5.0125 - val_acc: 0.3156\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.70650\n",
            "Epoch 308/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7283 - acc: 0.8064 - val_loss: 1.6689 - val_acc: 0.5886\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.70650\n",
            "Epoch 309/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7274 - acc: 0.8068 - val_loss: 4.6042 - val_acc: 0.2474\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.70650\n",
            "Epoch 310/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7073 - acc: 0.8122 - val_loss: 1.9035 - val_acc: 0.5479\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.70650\n",
            "Epoch 311/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7462 - acc: 0.8004 - val_loss: 1.5942 - val_acc: 0.5790\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.70650\n",
            "Epoch 312/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7150 - acc: 0.8119 - val_loss: 1.8974 - val_acc: 0.5649\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.70650\n",
            "Epoch 313/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7196 - acc: 0.8102 - val_loss: 1.0842 - val_acc: 0.7035\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.70650\n",
            "Epoch 314/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7397 - acc: 0.8024 - val_loss: 2.2525 - val_acc: 0.4867\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.70650\n",
            "Epoch 315/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7282 - acc: 0.8073 - val_loss: 2.4718 - val_acc: 0.5339\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.70650\n",
            "Epoch 316/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7172 - acc: 0.8119 - val_loss: 2.9541 - val_acc: 0.3872\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.70650\n",
            "Epoch 317/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7271 - acc: 0.8053 - val_loss: 1.4606 - val_acc: 0.6459\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.70650\n",
            "Epoch 318/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7169 - acc: 0.8093 - val_loss: 2.3394 - val_acc: 0.5267\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.70650\n",
            "Epoch 319/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7260 - acc: 0.8072 - val_loss: 1.9986 - val_acc: 0.5343\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.70650\n",
            "Epoch 320/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7237 - acc: 0.8053 - val_loss: 2.6565 - val_acc: 0.4695\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.70650\n",
            "Epoch 321/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7337 - acc: 0.8040 - val_loss: 4.4307 - val_acc: 0.3693\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.70650\n",
            "Epoch 322/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7261 - acc: 0.8122 - val_loss: 2.9550 - val_acc: 0.4624\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.70650\n",
            "Epoch 323/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7287 - acc: 0.8077 - val_loss: 1.6506 - val_acc: 0.5818\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.70650\n",
            "Epoch 324/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7497 - acc: 0.7983 - val_loss: 2.1751 - val_acc: 0.5067\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.70650\n",
            "Epoch 325/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7031 - acc: 0.8131 - val_loss: 2.1893 - val_acc: 0.5186\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.70650\n",
            "Epoch 326/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7310 - acc: 0.8033 - val_loss: 2.5158 - val_acc: 0.5061\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.70650\n",
            "Epoch 327/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7105 - acc: 0.8155 - val_loss: 2.0021 - val_acc: 0.4923\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.70650\n",
            "Epoch 328/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7468 - acc: 0.8012 - val_loss: 1.5867 - val_acc: 0.6298\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.70650\n",
            "Epoch 329/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7257 - acc: 0.8058 - val_loss: 2.1599 - val_acc: 0.5368\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.70650\n",
            "Epoch 330/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7242 - acc: 0.8079 - val_loss: 1.4414 - val_acc: 0.6296\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.70650\n",
            "Epoch 331/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7220 - acc: 0.8076 - val_loss: 2.8887 - val_acc: 0.4182\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.70650\n",
            "Epoch 332/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7177 - acc: 0.8139 - val_loss: 1.6871 - val_acc: 0.6055\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.70650\n",
            "Epoch 333/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7077 - acc: 0.8184 - val_loss: 1.9701 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.70650\n",
            "Epoch 334/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7125 - acc: 0.8117 - val_loss: 1.9691 - val_acc: 0.5702\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.70650\n",
            "Epoch 335/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7204 - acc: 0.8097 - val_loss: 1.9423 - val_acc: 0.5446\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.70650\n",
            "Epoch 336/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.6988 - acc: 0.8187 - val_loss: 2.6959 - val_acc: 0.3996\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.70650\n",
            "Epoch 337/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7132 - acc: 0.8125 - val_loss: 1.2607 - val_acc: 0.6729\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.70650\n",
            "Epoch 338/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7204 - acc: 0.8075 - val_loss: 1.2974 - val_acc: 0.6612\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.70650\n",
            "Epoch 339/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7221 - acc: 0.8056 - val_loss: 1.7341 - val_acc: 0.5979\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.70650\n",
            "Epoch 340/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7160 - acc: 0.8066 - val_loss: 1.2071 - val_acc: 0.6654\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.70650\n",
            "Epoch 341/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7106 - acc: 0.8140 - val_loss: 1.2863 - val_acc: 0.6618\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.70650\n",
            "Epoch 342/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7248 - acc: 0.8079 - val_loss: 1.3487 - val_acc: 0.6194\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.70650\n",
            "Epoch 343/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7174 - acc: 0.8075 - val_loss: 1.5786 - val_acc: 0.5941\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.70650\n",
            "Epoch 344/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7354 - acc: 0.8002 - val_loss: 2.0793 - val_acc: 0.5152\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.70650\n",
            "Epoch 345/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7189 - acc: 0.8112 - val_loss: 1.3931 - val_acc: 0.6344\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.70650\n",
            "Epoch 346/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7105 - acc: 0.8151 - val_loss: 3.3466 - val_acc: 0.4346\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.70650\n",
            "Epoch 347/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7197 - acc: 0.8106 - val_loss: 3.0300 - val_acc: 0.4765\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.70650\n",
            "Epoch 348/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7090 - acc: 0.8140 - val_loss: 2.3276 - val_acc: 0.4584\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.70650\n",
            "Epoch 349/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7287 - acc: 0.8084 - val_loss: 2.7672 - val_acc: 0.4228\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.70650\n",
            "Epoch 350/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7192 - acc: 0.8087 - val_loss: 2.4664 - val_acc: 0.4754\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.70650\n",
            "Epoch 351/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7187 - acc: 0.8069 - val_loss: 1.9227 - val_acc: 0.5498\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.70650\n",
            "Epoch 352/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7213 - acc: 0.8075 - val_loss: 1.4439 - val_acc: 0.5842\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.70650\n",
            "Epoch 353/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7103 - acc: 0.8134 - val_loss: 2.1159 - val_acc: 0.5103\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.70650\n",
            "Epoch 354/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7125 - acc: 0.8103 - val_loss: 2.8603 - val_acc: 0.4301\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.70650\n",
            "Epoch 355/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.7197 - acc: 0.8092 - val_loss: 2.7480 - val_acc: 0.4635\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.70650\n",
            "Epoch 356/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7182 - acc: 0.8076 - val_loss: 2.8213 - val_acc: 0.3785\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.70650\n",
            "Epoch 357/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7275 - acc: 0.8107 - val_loss: 2.0021 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.70650\n",
            "Epoch 358/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7160 - acc: 0.8082 - val_loss: 2.1269 - val_acc: 0.4963\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.70650\n",
            "Epoch 359/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7222 - acc: 0.8101 - val_loss: 2.4891 - val_acc: 0.5176\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.70650\n",
            "Epoch 360/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7107 - acc: 0.8090 - val_loss: 1.5924 - val_acc: 0.6156\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.70650\n",
            "Epoch 361/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7159 - acc: 0.8104 - val_loss: 1.3362 - val_acc: 0.6264\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.70650\n",
            "Epoch 362/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7205 - acc: 0.8104 - val_loss: 1.6202 - val_acc: 0.5507\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.70650\n",
            "Epoch 363/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7211 - acc: 0.8151 - val_loss: 1.3595 - val_acc: 0.6368\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.70650\n",
            "Epoch 364/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.7189 - acc: 0.8127 - val_loss: 1.5759 - val_acc: 0.6208\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.70650\n",
            "Epoch 365/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7079 - acc: 0.8108 - val_loss: 2.3583 - val_acc: 0.5215\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.70650\n",
            "Epoch 366/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7165 - acc: 0.8127 - val_loss: 2.0801 - val_acc: 0.5364\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.70650\n",
            "Epoch 367/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7161 - acc: 0.8095 - val_loss: 1.9969 - val_acc: 0.5504\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.70650\n",
            "Epoch 368/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.7201 - acc: 0.8072 - val_loss: 1.5516 - val_acc: 0.5897\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.70650\n",
            "Epoch 369/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7298 - acc: 0.8006 - val_loss: 2.9941 - val_acc: 0.3718\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.70650\n",
            "Epoch 370/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7219 - acc: 0.8096 - val_loss: 2.0409 - val_acc: 0.5174\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.70650\n",
            "Epoch 371/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7154 - acc: 0.8111 - val_loss: 1.3818 - val_acc: 0.6347\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.70650\n",
            "Epoch 372/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7223 - acc: 0.8113 - val_loss: 2.9725 - val_acc: 0.4323\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.70650\n",
            "Epoch 373/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7132 - acc: 0.8137 - val_loss: 2.0826 - val_acc: 0.5481\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.70650\n",
            "Epoch 374/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7058 - acc: 0.8132 - val_loss: 2.2230 - val_acc: 0.5248\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.70650\n",
            "Epoch 375/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7259 - acc: 0.8034 - val_loss: 1.4265 - val_acc: 0.6424\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.70650\n",
            "Epoch 376/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6945 - acc: 0.8153 - val_loss: 1.3337 - val_acc: 0.6655\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.70650\n",
            "Epoch 377/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7202 - acc: 0.8078 - val_loss: 3.1167 - val_acc: 0.4020\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.70650\n",
            "Epoch 378/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7203 - acc: 0.8095 - val_loss: 1.5823 - val_acc: 0.6002\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.70650\n",
            "Epoch 379/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7235 - acc: 0.8062 - val_loss: 1.7111 - val_acc: 0.5737\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.70650\n",
            "Epoch 380/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7332 - acc: 0.8042 - val_loss: 1.2294 - val_acc: 0.6643\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.70650\n",
            "Epoch 381/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7301 - acc: 0.8070 - val_loss: 4.4180 - val_acc: 0.3874\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.70650\n",
            "Epoch 382/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7027 - acc: 0.8164 - val_loss: 2.9676 - val_acc: 0.4686\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.70650\n",
            "Epoch 383/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6821 - acc: 0.8269 - val_loss: 2.1873 - val_acc: 0.5180\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.70650\n",
            "Epoch 384/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7183 - acc: 0.8089 - val_loss: 2.8995 - val_acc: 0.4641\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.70650\n",
            "Epoch 385/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6942 - acc: 0.8213 - val_loss: 1.7564 - val_acc: 0.5409\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.70650\n",
            "Epoch 386/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7062 - acc: 0.8153 - val_loss: 1.7168 - val_acc: 0.5941\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.70650\n",
            "Epoch 387/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7106 - acc: 0.8125 - val_loss: 1.7895 - val_acc: 0.5623\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.70650\n",
            "Epoch 388/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7104 - acc: 0.8136 - val_loss: 1.7373 - val_acc: 0.5437\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.70650\n",
            "Epoch 389/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7063 - acc: 0.8118 - val_loss: 1.7960 - val_acc: 0.5498\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.70650\n",
            "Epoch 390/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7052 - acc: 0.8111 - val_loss: 1.7134 - val_acc: 0.5910\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.70650\n",
            "Epoch 391/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7146 - acc: 0.8103 - val_loss: 1.5467 - val_acc: 0.6296\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.70650\n",
            "Epoch 392/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7023 - acc: 0.8118 - val_loss: 1.5319 - val_acc: 0.6258\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.70650\n",
            "Epoch 393/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6948 - acc: 0.8216 - val_loss: 1.6308 - val_acc: 0.5980\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.70650\n",
            "Epoch 394/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7309 - acc: 0.8056 - val_loss: 2.1449 - val_acc: 0.5611\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.70650\n",
            "Epoch 395/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7208 - acc: 0.8145 - val_loss: 1.9980 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.70650\n",
            "Epoch 396/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.7155 - acc: 0.8128 - val_loss: 2.1015 - val_acc: 0.4574\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.70650\n",
            "Epoch 397/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7158 - acc: 0.8080 - val_loss: 1.4938 - val_acc: 0.6373\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.70650\n",
            "Epoch 398/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.7243 - acc: 0.8083 - val_loss: 1.8794 - val_acc: 0.4837\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.70650\n",
            "Epoch 399/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7275 - acc: 0.8077 - val_loss: 2.5872 - val_acc: 0.4219\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.70650\n",
            "Epoch 400/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.7188 - acc: 0.8127 - val_loss: 1.4000 - val_acc: 0.6271\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.70650\n",
            "Epoch 401/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7020 - acc: 0.8171 - val_loss: 1.7450 - val_acc: 0.5667\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.70650\n",
            "Epoch 402/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6054 - acc: 0.8491 - val_loss: 0.7155 - val_acc: 0.8131\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.70650 to 0.81310, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5516 - acc: 0.8671 - val_loss: 0.6359 - val_acc: 0.8370\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.81310 to 0.83700, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5203 - acc: 0.8785 - val_loss: 0.5955 - val_acc: 0.8528\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.83700 to 0.85280, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.5106 - acc: 0.8831 - val_loss: 0.5821 - val_acc: 0.8544\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.85280 to 0.85440, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5119 - acc: 0.8822 - val_loss: 0.5753 - val_acc: 0.8618\n",
            "\n",
            "Epoch 00406: val_acc improved from 0.85440 to 0.86180, saving model to /content/saved_models/cifar10_ResNet32v1_model.406.h5\n",
            "Epoch 407/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4951 - acc: 0.8880 - val_loss: 0.5674 - val_acc: 0.8627\n",
            "\n",
            "Epoch 00407: val_acc improved from 0.86180 to 0.86270, saving model to /content/saved_models/cifar10_ResNet32v1_model.407.h5\n",
            "Epoch 408/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4805 - acc: 0.8924 - val_loss: 0.5584 - val_acc: 0.8688\n",
            "\n",
            "Epoch 00408: val_acc improved from 0.86270 to 0.86880, saving model to /content/saved_models/cifar10_ResNet32v1_model.408.h5\n",
            "Epoch 409/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4876 - acc: 0.8881 - val_loss: 0.5689 - val_acc: 0.8664\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.86880\n",
            "Epoch 410/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4885 - acc: 0.8872 - val_loss: 0.5454 - val_acc: 0.8723\n",
            "\n",
            "Epoch 00410: val_acc improved from 0.86880 to 0.87230, saving model to /content/saved_models/cifar10_ResNet32v1_model.410.h5\n",
            "Epoch 411/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4568 - acc: 0.9031 - val_loss: 0.5416 - val_acc: 0.8730\n",
            "\n",
            "Epoch 00411: val_acc improved from 0.87230 to 0.87300, saving model to /content/saved_models/cifar10_ResNet32v1_model.411.h5\n",
            "Epoch 412/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4662 - acc: 0.8969 - val_loss: 0.5476 - val_acc: 0.8741\n",
            "\n",
            "Epoch 00412: val_acc improved from 0.87300 to 0.87410, saving model to /content/saved_models/cifar10_ResNet32v1_model.412.h5\n",
            "Epoch 413/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4529 - acc: 0.9019 - val_loss: 0.5229 - val_acc: 0.8794\n",
            "\n",
            "Epoch 00413: val_acc improved from 0.87410 to 0.87940, saving model to /content/saved_models/cifar10_ResNet32v1_model.413.h5\n",
            "Epoch 414/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4675 - acc: 0.8992 - val_loss: 0.5528 - val_acc: 0.8721\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.87940\n",
            "Epoch 415/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4543 - acc: 0.9004 - val_loss: 0.5481 - val_acc: 0.8738\n",
            "\n",
            "Epoch 00415: val_acc did not improve from 0.87940\n",
            "Epoch 416/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4649 - acc: 0.8974 - val_loss: 0.5748 - val_acc: 0.8645\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.87940\n",
            "Epoch 417/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4504 - acc: 0.9077 - val_loss: 0.5511 - val_acc: 0.8692\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.87940\n",
            "Epoch 418/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4657 - acc: 0.9003 - val_loss: 0.5444 - val_acc: 0.8743\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.87940\n",
            "Epoch 419/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4379 - acc: 0.9065 - val_loss: 0.5487 - val_acc: 0.8716\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.87940\n",
            "Epoch 420/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.4435 - acc: 0.9041 - val_loss: 0.5831 - val_acc: 0.8585\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.87940\n",
            "Epoch 421/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4344 - acc: 0.9051 - val_loss: 0.5451 - val_acc: 0.8744\n",
            "\n",
            "Epoch 00421: val_acc did not improve from 0.87940\n",
            "Epoch 422/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.4376 - acc: 0.9069 - val_loss: 0.5283 - val_acc: 0.8816\n",
            "\n",
            "Epoch 00422: val_acc improved from 0.87940 to 0.88160, saving model to /content/saved_models/cifar10_ResNet32v1_model.422.h5\n",
            "Epoch 423/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4369 - acc: 0.9100 - val_loss: 0.5216 - val_acc: 0.8799\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.88160\n",
            "Epoch 424/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.4267 - acc: 0.9091 - val_loss: 0.5171 - val_acc: 0.8847\n",
            "\n",
            "Epoch 00424: val_acc improved from 0.88160 to 0.88470, saving model to /content/saved_models/cifar10_ResNet32v1_model.424.h5\n",
            "Epoch 425/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4225 - acc: 0.9113 - val_loss: 0.5622 - val_acc: 0.8656\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.88470\n",
            "Epoch 426/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4179 - acc: 0.9163 - val_loss: 0.5163 - val_acc: 0.8838\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.88470\n",
            "Epoch 427/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.4211 - acc: 0.9133 - val_loss: 0.5421 - val_acc: 0.8716\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.88470\n",
            "Epoch 428/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4145 - acc: 0.9178 - val_loss: 0.5473 - val_acc: 0.8729\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.88470\n",
            "Epoch 429/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.4312 - acc: 0.9089 - val_loss: 0.5376 - val_acc: 0.8751\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.88470\n",
            "Epoch 430/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4245 - acc: 0.9091 - val_loss: 0.5162 - val_acc: 0.8809\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.88470\n",
            "Epoch 431/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4233 - acc: 0.9121 - val_loss: 0.5166 - val_acc: 0.8792\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.88470\n",
            "Epoch 432/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.4133 - acc: 0.9164 - val_loss: 0.5071 - val_acc: 0.8813\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.88470\n",
            "Epoch 433/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4109 - acc: 0.9190 - val_loss: 0.5457 - val_acc: 0.8748\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.88470\n",
            "Epoch 434/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.4124 - acc: 0.9151 - val_loss: 0.5012 - val_acc: 0.8858\n",
            "\n",
            "Epoch 00434: val_acc improved from 0.88470 to 0.88580, saving model to /content/saved_models/cifar10_ResNet32v1_model.434.h5\n",
            "Epoch 435/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4174 - acc: 0.9145 - val_loss: 0.5342 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.88580\n",
            "Epoch 436/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4116 - acc: 0.9160 - val_loss: 0.5088 - val_acc: 0.8859\n",
            "\n",
            "Epoch 00436: val_acc improved from 0.88580 to 0.88590, saving model to /content/saved_models/cifar10_ResNet32v1_model.436.h5\n",
            "Epoch 437/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.4045 - acc: 0.9178 - val_loss: 0.5289 - val_acc: 0.8787\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.88590\n",
            "Epoch 438/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4094 - acc: 0.9158 - val_loss: 0.5158 - val_acc: 0.8819\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.88590\n",
            "Epoch 439/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.4031 - acc: 0.9190 - val_loss: 0.5342 - val_acc: 0.8773\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.88590\n",
            "Epoch 440/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4130 - acc: 0.9163 - val_loss: 0.5371 - val_acc: 0.8775\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.88590\n",
            "Epoch 441/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4190 - acc: 0.9128 - val_loss: 0.5353 - val_acc: 0.8784\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.88590\n",
            "Epoch 442/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.4020 - acc: 0.9182 - val_loss: 0.5046 - val_acc: 0.8885\n",
            "\n",
            "Epoch 00442: val_acc improved from 0.88590 to 0.88850, saving model to /content/saved_models/cifar10_ResNet32v1_model.442.h5\n",
            "Epoch 443/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4040 - acc: 0.9150 - val_loss: 0.5068 - val_acc: 0.8852\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.88850\n",
            "Epoch 444/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4026 - acc: 0.9178 - val_loss: 0.5229 - val_acc: 0.8818\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.88850\n",
            "Epoch 445/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3862 - acc: 0.9240 - val_loss: 0.5546 - val_acc: 0.8709\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.88850\n",
            "Epoch 446/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3976 - acc: 0.9190 - val_loss: 0.5198 - val_acc: 0.8828\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.88850\n",
            "Epoch 447/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3887 - acc: 0.9240 - val_loss: 0.5073 - val_acc: 0.8879\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.88850\n",
            "Epoch 448/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3964 - acc: 0.9212 - val_loss: 0.5294 - val_acc: 0.8799\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.88850\n",
            "Epoch 449/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3793 - acc: 0.9260 - val_loss: 0.4976 - val_acc: 0.8864\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.88850\n",
            "Epoch 450/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3833 - acc: 0.9240 - val_loss: 0.5260 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.88850\n",
            "Epoch 451/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4001 - acc: 0.9191 - val_loss: 0.5033 - val_acc: 0.8870\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.88850\n",
            "Epoch 452/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3789 - acc: 0.9243 - val_loss: 0.5323 - val_acc: 0.8777\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.88850\n",
            "Epoch 453/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3824 - acc: 0.9250 - val_loss: 0.5116 - val_acc: 0.8865\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.88850\n",
            "Epoch 454/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3867 - acc: 0.9274 - val_loss: 0.5473 - val_acc: 0.8733\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.88850\n",
            "Epoch 455/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3769 - acc: 0.9310 - val_loss: 0.5274 - val_acc: 0.8795\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.88850\n",
            "Epoch 456/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3825 - acc: 0.9239 - val_loss: 0.5439 - val_acc: 0.8807\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.88850\n",
            "Epoch 457/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3862 - acc: 0.9242 - val_loss: 0.5290 - val_acc: 0.8803\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.88850\n",
            "Epoch 458/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3874 - acc: 0.9252 - val_loss: 0.4878 - val_acc: 0.8940\n",
            "\n",
            "Epoch 00458: val_acc improved from 0.88850 to 0.89400, saving model to /content/saved_models/cifar10_ResNet32v1_model.458.h5\n",
            "Epoch 459/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3866 - acc: 0.9239 - val_loss: 0.5031 - val_acc: 0.8881\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.89400\n",
            "Epoch 460/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3791 - acc: 0.9253 - val_loss: 0.5038 - val_acc: 0.8870\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.89400\n",
            "Epoch 461/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3748 - acc: 0.9307 - val_loss: 0.5393 - val_acc: 0.8812\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.89400\n",
            "Epoch 462/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3741 - acc: 0.9280 - val_loss: 0.5138 - val_acc: 0.8877\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.89400\n",
            "Epoch 463/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3615 - acc: 0.9324 - val_loss: 0.5168 - val_acc: 0.8848\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.89400\n",
            "Epoch 464/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3734 - acc: 0.9259 - val_loss: 0.5118 - val_acc: 0.8857\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.89400\n",
            "Epoch 465/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3671 - acc: 0.9276 - val_loss: 0.5651 - val_acc: 0.8745\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.89400\n",
            "Epoch 466/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3712 - acc: 0.9279 - val_loss: 0.5199 - val_acc: 0.8842\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.89400\n",
            "Epoch 467/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3802 - acc: 0.9250 - val_loss: 0.5007 - val_acc: 0.8922\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.89400\n",
            "Epoch 468/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3707 - acc: 0.9293 - val_loss: 0.5109 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.89400\n",
            "Epoch 469/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3708 - acc: 0.9311 - val_loss: 0.5110 - val_acc: 0.8848\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.89400\n",
            "Epoch 470/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3636 - acc: 0.9337 - val_loss: 0.5109 - val_acc: 0.8876\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.89400\n",
            "Epoch 471/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3635 - acc: 0.9290 - val_loss: 0.5261 - val_acc: 0.8849\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.89400\n",
            "Epoch 472/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3613 - acc: 0.9312 - val_loss: 0.4955 - val_acc: 0.8919\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.89400\n",
            "Epoch 473/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3680 - acc: 0.9278 - val_loss: 0.5112 - val_acc: 0.8877\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.89400\n",
            "Epoch 474/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3571 - acc: 0.9368 - val_loss: 0.5113 - val_acc: 0.8875\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.89400\n",
            "Epoch 475/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3601 - acc: 0.9344 - val_loss: 0.5292 - val_acc: 0.8811\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.89400\n",
            "Epoch 476/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3633 - acc: 0.9316 - val_loss: 0.4971 - val_acc: 0.8904\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.89400\n",
            "Epoch 477/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.3633 - acc: 0.9318 - val_loss: 0.5177 - val_acc: 0.8858\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.89400\n",
            "Epoch 478/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3613 - acc: 0.9292 - val_loss: 0.5310 - val_acc: 0.8819\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.89400\n",
            "Epoch 479/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3548 - acc: 0.9345 - val_loss: 0.5060 - val_acc: 0.8902\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.89400\n",
            "Epoch 480/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3609 - acc: 0.9324 - val_loss: 0.4926 - val_acc: 0.8931\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.89400\n",
            "Epoch 481/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3547 - acc: 0.9354 - val_loss: 0.5263 - val_acc: 0.8843\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.89400\n",
            "Epoch 482/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3551 - acc: 0.9360 - val_loss: 0.5569 - val_acc: 0.8757\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.89400\n",
            "Epoch 483/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3504 - acc: 0.9327 - val_loss: 0.5178 - val_acc: 0.8875\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.89400\n",
            "Epoch 484/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3537 - acc: 0.9351 - val_loss: 0.6264 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.89400\n",
            "Epoch 485/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3453 - acc: 0.9381 - val_loss: 0.5256 - val_acc: 0.8827\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.89400\n",
            "Epoch 486/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3559 - acc: 0.9370 - val_loss: 0.5068 - val_acc: 0.8866\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.89400\n",
            "Epoch 487/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3437 - acc: 0.9371 - val_loss: 0.5200 - val_acc: 0.8831\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.89400\n",
            "Epoch 488/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3502 - acc: 0.9360 - val_loss: 0.4975 - val_acc: 0.8906\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.89400\n",
            "Epoch 489/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3528 - acc: 0.9374 - val_loss: 0.5168 - val_acc: 0.8866\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.89400\n",
            "Epoch 490/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3659 - acc: 0.9301 - val_loss: 0.5327 - val_acc: 0.8844\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.89400\n",
            "Epoch 491/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3576 - acc: 0.9333 - val_loss: 0.5639 - val_acc: 0.8757\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.89400\n",
            "Epoch 492/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3491 - acc: 0.9378 - val_loss: 0.5426 - val_acc: 0.8801\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.89400\n",
            "Epoch 493/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3404 - acc: 0.9392 - val_loss: 0.5112 - val_acc: 0.8853\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.89400\n",
            "Epoch 494/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3498 - acc: 0.9360 - val_loss: 0.5058 - val_acc: 0.8878\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.89400\n",
            "Epoch 495/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3491 - acc: 0.9353 - val_loss: 0.5328 - val_acc: 0.8807\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.89400\n",
            "Epoch 496/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3526 - acc: 0.9323 - val_loss: 0.5438 - val_acc: 0.8783\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.89400\n",
            "Epoch 497/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3451 - acc: 0.9382 - val_loss: 0.5007 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.89400\n",
            "Epoch 498/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3498 - acc: 0.9368 - val_loss: 0.4926 - val_acc: 0.8907\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.89400\n",
            "Epoch 499/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3441 - acc: 0.9406 - val_loss: 0.5101 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.89400\n",
            "Epoch 500/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3519 - acc: 0.9339 - val_loss: 0.5210 - val_acc: 0.8849\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.89400\n",
            "Epoch 501/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3425 - acc: 0.9375 - val_loss: 0.5138 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.89400\n",
            "Epoch 502/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3360 - acc: 0.9407 - val_loss: 0.4929 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.89400\n",
            "Epoch 503/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3425 - acc: 0.9370 - val_loss: 0.5486 - val_acc: 0.8784\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.89400\n",
            "Epoch 504/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3431 - acc: 0.9375 - val_loss: 0.5048 - val_acc: 0.8904\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.89400\n",
            "Epoch 505/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3466 - acc: 0.9370 - val_loss: 0.5018 - val_acc: 0.8901\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.89400\n",
            "Epoch 506/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3377 - acc: 0.9389 - val_loss: 0.5877 - val_acc: 0.8735\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.89400\n",
            "Epoch 507/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3487 - acc: 0.9358 - val_loss: 0.5047 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.89400\n",
            "Epoch 508/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3449 - acc: 0.9363 - val_loss: 0.5009 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.89400\n",
            "Epoch 509/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3470 - acc: 0.9374 - val_loss: 0.5004 - val_acc: 0.8895\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.89400\n",
            "Epoch 510/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3443 - acc: 0.9371 - val_loss: 0.5444 - val_acc: 0.8812\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.89400\n",
            "Epoch 511/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3406 - acc: 0.9415 - val_loss: 0.5200 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.89400\n",
            "Epoch 512/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3341 - acc: 0.9427 - val_loss: 0.5457 - val_acc: 0.8798\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.89400\n",
            "Epoch 513/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3353 - acc: 0.9394 - val_loss: 0.4979 - val_acc: 0.8921\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.89400\n",
            "Epoch 514/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3286 - acc: 0.9411 - val_loss: 0.5119 - val_acc: 0.8885\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.89400\n",
            "Epoch 515/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3376 - acc: 0.9370 - val_loss: 0.5315 - val_acc: 0.8841\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.89400\n",
            "Epoch 516/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3336 - acc: 0.9414 - val_loss: 0.4878 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00516: val_acc improved from 0.89400 to 0.89680, saving model to /content/saved_models/cifar10_ResNet32v1_model.516.h5\n",
            "Epoch 517/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.3292 - acc: 0.9419 - val_loss: 0.5804 - val_acc: 0.8748\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.89680\n",
            "Epoch 518/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3312 - acc: 0.9429 - val_loss: 0.4951 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.89680\n",
            "Epoch 519/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3247 - acc: 0.9433 - val_loss: 0.4809 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00519: val_acc improved from 0.89680 to 0.89920, saving model to /content/saved_models/cifar10_ResNet32v1_model.519.h5\n",
            "Epoch 520/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3332 - acc: 0.9429 - val_loss: 0.5021 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.89920\n",
            "Epoch 521/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3396 - acc: 0.9383 - val_loss: 0.5297 - val_acc: 0.8873\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.89920\n",
            "Epoch 522/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3309 - acc: 0.9417 - val_loss: 0.5319 - val_acc: 0.8827\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.89920\n",
            "Epoch 523/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3349 - acc: 0.9422 - val_loss: 0.4991 - val_acc: 0.8964\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.89920\n",
            "Epoch 524/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3298 - acc: 0.9435 - val_loss: 0.4807 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.89920\n",
            "Epoch 525/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3334 - acc: 0.9446 - val_loss: 0.5285 - val_acc: 0.8863\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.89920\n",
            "Epoch 526/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3257 - acc: 0.9443 - val_loss: 0.6123 - val_acc: 0.8671\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.89920\n",
            "Epoch 527/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3326 - acc: 0.9414 - val_loss: 0.5013 - val_acc: 0.8935\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.89920\n",
            "Epoch 528/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3259 - acc: 0.9444 - val_loss: 0.5089 - val_acc: 0.8926\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.89920\n",
            "Epoch 529/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3305 - acc: 0.9408 - val_loss: 0.5605 - val_acc: 0.8777\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.89920\n",
            "Epoch 530/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3326 - acc: 0.9404 - val_loss: 0.5318 - val_acc: 0.8822\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.89920\n",
            "Epoch 531/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3274 - acc: 0.9441 - val_loss: 0.5112 - val_acc: 0.8903\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.89920\n",
            "Epoch 532/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3381 - acc: 0.9399 - val_loss: 0.5752 - val_acc: 0.8693\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.89920\n",
            "Epoch 533/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3320 - acc: 0.9417 - val_loss: 0.5270 - val_acc: 0.8841\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.89920\n",
            "Epoch 534/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3319 - acc: 0.9405 - val_loss: 0.5139 - val_acc: 0.8887\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.89920\n",
            "Epoch 535/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3251 - acc: 0.9456 - val_loss: 0.5459 - val_acc: 0.8823\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.89920\n",
            "Epoch 536/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3240 - acc: 0.9447 - val_loss: 0.5196 - val_acc: 0.8856\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.89920\n",
            "Epoch 537/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3334 - acc: 0.9401 - val_loss: 0.4962 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.89920\n",
            "Epoch 538/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3214 - acc: 0.9474 - val_loss: 0.5014 - val_acc: 0.8920\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.89920\n",
            "Epoch 539/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3257 - acc: 0.9455 - val_loss: 0.5072 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.89920\n",
            "Epoch 540/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3214 - acc: 0.9448 - val_loss: 0.5470 - val_acc: 0.8787\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.89920\n",
            "Epoch 541/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3205 - acc: 0.9442 - val_loss: 0.4946 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.89920\n",
            "Epoch 542/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3201 - acc: 0.9463 - val_loss: 0.5025 - val_acc: 0.8905\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.89920\n",
            "Epoch 543/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3176 - acc: 0.9449 - val_loss: 0.5778 - val_acc: 0.8726\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.89920\n",
            "Epoch 544/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3228 - acc: 0.9449 - val_loss: 0.5062 - val_acc: 0.8916\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.89920\n",
            "Epoch 545/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3189 - acc: 0.9472 - val_loss: 0.5239 - val_acc: 0.8844\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.89920\n",
            "Epoch 546/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3245 - acc: 0.9455 - val_loss: 0.5115 - val_acc: 0.8893\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.89920\n",
            "Epoch 547/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3223 - acc: 0.9442 - val_loss: 0.5299 - val_acc: 0.8871\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.89920\n",
            "Epoch 548/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3236 - acc: 0.9465 - val_loss: 0.5171 - val_acc: 0.8868\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.89920\n",
            "Epoch 549/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3155 - acc: 0.9479 - val_loss: 0.5191 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.89920\n",
            "Epoch 550/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3184 - acc: 0.9490 - val_loss: 0.4998 - val_acc: 0.8946\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.89920\n",
            "Epoch 551/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3162 - acc: 0.9470 - val_loss: 0.5318 - val_acc: 0.8851\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.89920\n",
            "Epoch 552/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3187 - acc: 0.9448 - val_loss: 0.5038 - val_acc: 0.8935\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.89920\n",
            "Epoch 553/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3138 - acc: 0.9490 - val_loss: 0.5857 - val_acc: 0.8694\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.89920\n",
            "Epoch 554/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.3152 - acc: 0.9488 - val_loss: 0.5049 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.89920\n",
            "Epoch 555/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3173 - acc: 0.9473 - val_loss: 0.5569 - val_acc: 0.8775\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.89920\n",
            "Epoch 556/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3158 - acc: 0.9462 - val_loss: 0.5125 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.89920\n",
            "Epoch 557/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.3166 - acc: 0.9475 - val_loss: 0.5315 - val_acc: 0.8848\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.89920\n",
            "Epoch 558/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3171 - acc: 0.9493 - val_loss: 0.5221 - val_acc: 0.8872\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.89920\n",
            "Epoch 559/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3111 - acc: 0.9482 - val_loss: 0.5173 - val_acc: 0.8884\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.89920\n",
            "Epoch 560/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3120 - acc: 0.9470 - val_loss: 0.5090 - val_acc: 0.8911\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.89920\n",
            "Epoch 561/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.3186 - acc: 0.9466 - val_loss: 0.4944 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.89920\n",
            "Epoch 562/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3204 - acc: 0.9450 - val_loss: 0.5397 - val_acc: 0.8855\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.89920\n",
            "Epoch 563/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3134 - acc: 0.9511 - val_loss: 0.5341 - val_acc: 0.8864\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.89920\n",
            "Epoch 564/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3200 - acc: 0.9469 - val_loss: 0.4950 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.89920\n",
            "Epoch 565/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3144 - acc: 0.9471 - val_loss: 0.4851 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.89920\n",
            "Epoch 566/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3159 - acc: 0.9465 - val_loss: 0.5097 - val_acc: 0.8937\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.89920\n",
            "Epoch 567/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3176 - acc: 0.9459 - val_loss: 0.5284 - val_acc: 0.8872\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.89920\n",
            "Epoch 568/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3130 - acc: 0.9470 - val_loss: 0.5120 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.89920\n",
            "Epoch 569/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3058 - acc: 0.9506 - val_loss: 0.5119 - val_acc: 0.8930\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.89920\n",
            "Epoch 570/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3139 - acc: 0.9489 - val_loss: 0.5062 - val_acc: 0.8947\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.89920\n",
            "Epoch 571/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.3153 - acc: 0.9463 - val_loss: 0.5399 - val_acc: 0.8860\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.89920\n",
            "Epoch 572/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3112 - acc: 0.9504 - val_loss: 0.5293 - val_acc: 0.8875\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.89920\n",
            "Epoch 573/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3219 - acc: 0.9439 - val_loss: 0.4945 - val_acc: 0.8954\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.89920\n",
            "Epoch 574/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.3141 - acc: 0.9494 - val_loss: 0.4903 - val_acc: 0.8965\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.89920\n",
            "Epoch 575/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3182 - acc: 0.9472 - val_loss: 0.5102 - val_acc: 0.8899\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.89920\n",
            "Epoch 576/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3124 - acc: 0.9466 - val_loss: 0.5457 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.89920\n",
            "Epoch 577/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.3110 - acc: 0.9488 - val_loss: 0.5310 - val_acc: 0.8859\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.89920\n",
            "Epoch 578/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3110 - acc: 0.9486 - val_loss: 0.5498 - val_acc: 0.8826\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.89920\n",
            "Epoch 579/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3152 - acc: 0.9475 - val_loss: 0.5209 - val_acc: 0.8902\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.89920\n",
            "Epoch 580/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3068 - acc: 0.9521 - val_loss: 0.5384 - val_acc: 0.8858\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.89920\n",
            "Epoch 581/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.3011 - acc: 0.9520 - val_loss: 0.5339 - val_acc: 0.8875\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.89920\n",
            "Epoch 582/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3137 - acc: 0.9482 - val_loss: 0.5153 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.89920\n",
            "Epoch 583/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3108 - acc: 0.9515 - val_loss: 0.6092 - val_acc: 0.8723\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.89920\n",
            "Epoch 584/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.3096 - acc: 0.9482 - val_loss: 0.5482 - val_acc: 0.8843\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.89920\n",
            "Epoch 585/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3129 - acc: 0.9470 - val_loss: 0.5235 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.89920\n",
            "Epoch 586/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3029 - acc: 0.9495 - val_loss: 0.5307 - val_acc: 0.8898\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.89920\n",
            "Epoch 587/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.3065 - acc: 0.9494 - val_loss: 0.4871 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00587: val_acc improved from 0.89920 to 0.89960, saving model to /content/saved_models/cifar10_ResNet32v1_model.587.h5\n",
            "Epoch 588/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3062 - acc: 0.9513 - val_loss: 0.5026 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.89960\n",
            "Epoch 589/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3064 - acc: 0.9519 - val_loss: 0.5225 - val_acc: 0.8897\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.89960\n",
            "Epoch 590/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.3036 - acc: 0.9506 - val_loss: 0.5592 - val_acc: 0.8807\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.89960\n",
            "Epoch 591/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3050 - acc: 0.9491 - val_loss: 0.5910 - val_acc: 0.8714\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.89960\n",
            "Epoch 592/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3081 - acc: 0.9523 - val_loss: 0.5679 - val_acc: 0.8756\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.89960\n",
            "Epoch 593/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2949 - acc: 0.9535 - val_loss: 0.5134 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.89960\n",
            "Epoch 594/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.2984 - acc: 0.9513 - val_loss: 0.5006 - val_acc: 0.8962\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.89960\n",
            "Epoch 595/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3064 - acc: 0.9505 - val_loss: 0.5082 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.89960\n",
            "Epoch 596/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3096 - acc: 0.9483 - val_loss: 0.6054 - val_acc: 0.8684\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.89960\n",
            "Epoch 597/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.2950 - acc: 0.9530 - val_loss: 0.5002 - val_acc: 0.8940\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.89960\n",
            "Epoch 598/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2963 - acc: 0.9558 - val_loss: 0.5335 - val_acc: 0.8872\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.89960\n",
            "Epoch 599/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2963 - acc: 0.9524 - val_loss: 0.4916 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.89960\n",
            "Epoch 600/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3001 - acc: 0.9546 - val_loss: 0.5082 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.89960\n",
            "Epoch 601/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2999 - acc: 0.9519 - val_loss: 0.5039 - val_acc: 0.8939\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.89960\n",
            "Epoch 602/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2966 - acc: 0.9555 - val_loss: 0.4850 - val_acc: 0.9006\n",
            "\n",
            "Epoch 00602: val_acc improved from 0.89960 to 0.90060, saving model to /content/saved_models/cifar10_ResNet32v1_model.602.h5\n",
            "Epoch 603/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2936 - acc: 0.9526 - val_loss: 0.4819 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00603: val_acc improved from 0.90060 to 0.90190, saving model to /content/saved_models/cifar10_ResNet32v1_model.603.h5\n",
            "Epoch 604/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.2970 - acc: 0.9547 - val_loss: 0.4802 - val_acc: 0.9012\n",
            "\n",
            "Epoch 00604: val_acc did not improve from 0.90190\n",
            "Epoch 605/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3040 - acc: 0.9494 - val_loss: 0.4793 - val_acc: 0.9017\n",
            "\n",
            "Epoch 00605: val_acc did not improve from 0.90190\n",
            "Epoch 606/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2839 - acc: 0.9576 - val_loss: 0.4768 - val_acc: 0.9029\n",
            "\n",
            "Epoch 00606: val_acc improved from 0.90190 to 0.90290, saving model to /content/saved_models/cifar10_ResNet32v1_model.606.h5\n",
            "Epoch 607/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3014 - acc: 0.9513 - val_loss: 0.4752 - val_acc: 0.9038\n",
            "\n",
            "Epoch 00607: val_acc improved from 0.90290 to 0.90380, saving model to /content/saved_models/cifar10_ResNet32v1_model.607.h5\n",
            "Epoch 608/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2915 - acc: 0.9549 - val_loss: 0.4748 - val_acc: 0.9036\n",
            "\n",
            "Epoch 00608: val_acc did not improve from 0.90380\n",
            "Epoch 609/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2888 - acc: 0.9585 - val_loss: 0.4727 - val_acc: 0.9042\n",
            "\n",
            "Epoch 00609: val_acc improved from 0.90380 to 0.90420, saving model to /content/saved_models/cifar10_ResNet32v1_model.609.h5\n",
            "Epoch 610/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2954 - acc: 0.9549 - val_loss: 0.4717 - val_acc: 0.9046\n",
            "\n",
            "Epoch 00610: val_acc improved from 0.90420 to 0.90460, saving model to /content/saved_models/cifar10_ResNet32v1_model.610.h5\n",
            "Epoch 611/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2950 - acc: 0.9546 - val_loss: 0.4717 - val_acc: 0.9044\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.90460\n",
            "Epoch 612/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2897 - acc: 0.9561 - val_loss: 0.4710 - val_acc: 0.9050\n",
            "\n",
            "Epoch 00612: val_acc improved from 0.90460 to 0.90500, saving model to /content/saved_models/cifar10_ResNet32v1_model.612.h5\n",
            "Epoch 613/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2888 - acc: 0.9573 - val_loss: 0.4693 - val_acc: 0.9057\n",
            "\n",
            "Epoch 00613: val_acc improved from 0.90500 to 0.90570, saving model to /content/saved_models/cifar10_ResNet32v1_model.613.h5\n",
            "Epoch 614/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2941 - acc: 0.9557 - val_loss: 0.4689 - val_acc: 0.9057\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.90570\n",
            "Epoch 615/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.2891 - acc: 0.9560 - val_loss: 0.4676 - val_acc: 0.9053\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.90570\n",
            "Epoch 616/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2906 - acc: 0.9572 - val_loss: 0.4670 - val_acc: 0.9060\n",
            "\n",
            "Epoch 00616: val_acc improved from 0.90570 to 0.90600, saving model to /content/saved_models/cifar10_ResNet32v1_model.616.h5\n",
            "Epoch 617/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2882 - acc: 0.9567 - val_loss: 0.4671 - val_acc: 0.9057\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.90600\n",
            "Epoch 618/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.2897 - acc: 0.9582 - val_loss: 0.4655 - val_acc: 0.9066\n",
            "\n",
            "Epoch 00618: val_acc improved from 0.90600 to 0.90660, saving model to /content/saved_models/cifar10_ResNet32v1_model.618.h5\n",
            "Epoch 619/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2882 - acc: 0.9607 - val_loss: 0.4655 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00619: val_acc did not improve from 0.90660\n",
            "Epoch 620/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2810 - acc: 0.9601 - val_loss: 0.4653 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.90660\n",
            "Epoch 621/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2828 - acc: 0.9609 - val_loss: 0.4658 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00621: val_acc improved from 0.90660 to 0.90690, saving model to /content/saved_models/cifar10_ResNet32v1_model.621.h5\n",
            "Epoch 622/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.2918 - acc: 0.9560 - val_loss: 0.4659 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.90690\n",
            "Epoch 623/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2889 - acc: 0.9588 - val_loss: 0.4641 - val_acc: 0.9066\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.90690\n",
            "Epoch 624/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2908 - acc: 0.9564 - val_loss: 0.4642 - val_acc: 0.9063\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.90690\n",
            "Epoch 625/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2886 - acc: 0.9590 - val_loss: 0.4635 - val_acc: 0.9072\n",
            "\n",
            "Epoch 00625: val_acc improved from 0.90690 to 0.90720, saving model to /content/saved_models/cifar10_ResNet32v1_model.625.h5\n",
            "Epoch 626/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.2823 - acc: 0.9605 - val_loss: 0.4628 - val_acc: 0.9077\n",
            "\n",
            "Epoch 00626: val_acc improved from 0.90720 to 0.90770, saving model to /content/saved_models/cifar10_ResNet32v1_model.626.h5\n",
            "Epoch 627/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2834 - acc: 0.9608 - val_loss: 0.4619 - val_acc: 0.9085\n",
            "\n",
            "Epoch 00627: val_acc improved from 0.90770 to 0.90850, saving model to /content/saved_models/cifar10_ResNet32v1_model.627.h5\n",
            "Epoch 628/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2892 - acc: 0.9572 - val_loss: 0.4629 - val_acc: 0.9080\n",
            "\n",
            "Epoch 00628: val_acc did not improve from 0.90850\n",
            "Epoch 629/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.2841 - acc: 0.9598 - val_loss: 0.4630 - val_acc: 0.9083\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.90850\n",
            "Epoch 630/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2846 - acc: 0.9591 - val_loss: 0.4637 - val_acc: 0.9081\n",
            "\n",
            "Epoch 00630: val_acc did not improve from 0.90850\n",
            "Epoch 631/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2848 - acc: 0.9590 - val_loss: 0.4618 - val_acc: 0.9089\n",
            "\n",
            "Epoch 00631: val_acc improved from 0.90850 to 0.90890, saving model to /content/saved_models/cifar10_ResNet32v1_model.631.h5\n",
            "Epoch 632/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2866 - acc: 0.9582 - val_loss: 0.4612 - val_acc: 0.9081\n",
            "\n",
            "Epoch 00632: val_acc did not improve from 0.90890\n",
            "Epoch 633/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.2852 - acc: 0.9604 - val_loss: 0.4602 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.90890\n",
            "Epoch 634/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2815 - acc: 0.9604 - val_loss: 0.4595 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00634: val_acc improved from 0.90890 to 0.90930, saving model to /content/saved_models/cifar10_ResNet32v1_model.634.h5\n",
            "Epoch 635/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2835 - acc: 0.9607 - val_loss: 0.4607 - val_acc: 0.9089\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.90930\n",
            "Epoch 636/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2797 - acc: 0.9613 - val_loss: 0.4599 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.90930\n",
            "Epoch 637/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2874 - acc: 0.9577 - val_loss: 0.4591 - val_acc: 0.9096\n",
            "\n",
            "Epoch 00637: val_acc improved from 0.90930 to 0.90960, saving model to /content/saved_models/cifar10_ResNet32v1_model.637.h5\n",
            "Epoch 638/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2846 - acc: 0.9600 - val_loss: 0.4594 - val_acc: 0.9096\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.90960\n",
            "Epoch 639/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2840 - acc: 0.9586 - val_loss: 0.4585 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.90960\n",
            "Epoch 640/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.2792 - acc: 0.9622 - val_loss: 0.4587 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00640: val_acc improved from 0.90960 to 0.90990, saving model to /content/saved_models/cifar10_ResNet32v1_model.640.h5\n",
            "Epoch 641/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2794 - acc: 0.9617 - val_loss: 0.4584 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00641: val_acc improved from 0.90990 to 0.91070, saving model to /content/saved_models/cifar10_ResNet32v1_model.641.h5\n",
            "Epoch 642/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2810 - acc: 0.9610 - val_loss: 0.4587 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.91070\n",
            "Epoch 643/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2800 - acc: 0.9620 - val_loss: 0.4585 - val_acc: 0.9102\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.91070\n",
            "Epoch 644/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.2745 - acc: 0.9640 - val_loss: 0.4592 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.91070\n",
            "Epoch 645/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2804 - acc: 0.9634 - val_loss: 0.4590 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00645: val_acc did not improve from 0.91070\n",
            "Epoch 646/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2769 - acc: 0.9639 - val_loss: 0.4581 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00646: val_acc did not improve from 0.91070\n",
            "Epoch 647/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2824 - acc: 0.9614 - val_loss: 0.4583 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00647: val_acc did not improve from 0.91070\n",
            "Epoch 648/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.2757 - acc: 0.9636 - val_loss: 0.4577 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.91070\n",
            "Epoch 649/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2799 - acc: 0.9640 - val_loss: 0.4571 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.91070\n",
            "Epoch 650/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2778 - acc: 0.9619 - val_loss: 0.4570 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00650: val_acc improved from 0.91070 to 0.91090, saving model to /content/saved_models/cifar10_ResNet32v1_model.650.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "p3rZAX3sfcNz",
        "outputId": "19a08009-f8c0-42db-8fc9-7f01c83e3d97"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('trainHistoryDict_clip_05', \"rb\"))\n",
        "functions.plot_loss_acc(history, 4, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UexJ03SfcNz",
        "outputId": "018d7f06-ba68-467b-daff-d632960c635d"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9108999967575073"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4EhINxSfcNz",
        "outputId": "d5bdda2d-6bf5-4ede-bba4-bb1a359d67e6"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08910000324249268"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDiiZG682ca2"
      },
      "source": [
        "#### Model with clipping to 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xCRmjzt2cbA",
        "outputId": "8c9ac92a-256e-4871-dfa5-68aa901c587c"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(\n",
        "    input_shape, conv_layer = functions.ConvDecomposed2D, decomposition_rank=29)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWTE23pr2cbD",
        "outputId": "e5f3a46f-2a2e-4d0e-ad38-f0d7a57ee3fe"
      },
      "source": [
        "callbacks = functions.standard_callbacks(model_type) + [functions.Clipping(1)]\n",
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'trainHistoryDict_clip_1', steps_per_epoch=100, epochs=650,\n",
        "                       batch_size=100,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 18s 108ms/step - loss: 2.5880 - acc: 0.2920 - val_loss: 3.4721 - val_acc: 0.1739\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.17390, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.9442 - acc: 0.3508 - val_loss: 3.0492 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.17390\n",
            "Epoch 3/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.7350 - acc: 0.4354 - val_loss: 3.2060 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.17390\n",
            "Epoch 4/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.6028 - acc: 0.4902 - val_loss: 3.1807 - val_acc: 0.1308\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.17390\n",
            "Epoch 5/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.5080 - acc: 0.5206 - val_loss: 2.8558 - val_acc: 0.1944\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.17390 to 0.19440, saving model to /content/saved_models/cifar10_ResNet32v1_model.005.h5\n",
            "Epoch 6/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.4522 - acc: 0.5473 - val_loss: 2.0366 - val_acc: 0.3712\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.19440 to 0.37120, saving model to /content/saved_models/cifar10_ResNet32v1_model.006.h5\n",
            "Epoch 7/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3801 - acc: 0.5798 - val_loss: 1.7848 - val_acc: 0.4696\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.37120 to 0.46960, saving model to /content/saved_models/cifar10_ResNet32v1_model.007.h5\n",
            "Epoch 8/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3023 - acc: 0.6082 - val_loss: 5.0262 - val_acc: 0.2636\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.46960\n",
            "Epoch 9/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2756 - acc: 0.6163 - val_loss: 1.9168 - val_acc: 0.4827\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.46960 to 0.48270, saving model to /content/saved_models/cifar10_ResNet32v1_model.009.h5\n",
            "Epoch 10/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.2340 - acc: 0.6310 - val_loss: 1.6063 - val_acc: 0.5516\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.48270 to 0.55160, saving model to /content/saved_models/cifar10_ResNet32v1_model.010.h5\n",
            "Epoch 11/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.1527 - acc: 0.6629 - val_loss: 1.6843 - val_acc: 0.4998\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.55160\n",
            "Epoch 12/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.1389 - acc: 0.6586 - val_loss: 1.5974 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.55160 to 0.55260, saving model to /content/saved_models/cifar10_ResNet32v1_model.012.h5\n",
            "Epoch 13/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.1367 - acc: 0.6636 - val_loss: 2.3714 - val_acc: 0.4410\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.55260\n",
            "Epoch 14/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.1028 - acc: 0.6807 - val_loss: 1.9380 - val_acc: 0.5194\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.55260\n",
            "Epoch 15/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.0614 - acc: 0.6951 - val_loss: 1.9754 - val_acc: 0.5100\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.55260\n",
            "Epoch 16/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.0682 - acc: 0.6943 - val_loss: 1.4426 - val_acc: 0.5935\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.55260 to 0.59350, saving model to /content/saved_models/cifar10_ResNet32v1_model.016.h5\n",
            "Epoch 17/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.0450 - acc: 0.7067 - val_loss: 1.5553 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.59350\n",
            "Epoch 18/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.0414 - acc: 0.7012 - val_loss: 1.3338 - val_acc: 0.6413\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.59350 to 0.64130, saving model to /content/saved_models/cifar10_ResNet32v1_model.018.h5\n",
            "Epoch 19/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.9922 - acc: 0.7182 - val_loss: 1.2812 - val_acc: 0.6383\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.64130\n",
            "Epoch 20/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.0011 - acc: 0.7148 - val_loss: 2.2108 - val_acc: 0.4741\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.64130\n",
            "Epoch 21/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.9909 - acc: 0.7218 - val_loss: 1.9602 - val_acc: 0.5056\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.64130\n",
            "Epoch 22/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.9714 - acc: 0.7332 - val_loss: 1.5265 - val_acc: 0.6175\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.64130\n",
            "Epoch 23/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9627 - acc: 0.7351 - val_loss: 1.9977 - val_acc: 0.5148\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.64130\n",
            "Epoch 24/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9743 - acc: 0.7267 - val_loss: 2.7842 - val_acc: 0.4141\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.64130\n",
            "Epoch 25/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9608 - acc: 0.7307 - val_loss: 1.0626 - val_acc: 0.6903\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.64130 to 0.69030, saving model to /content/saved_models/cifar10_ResNet32v1_model.025.h5\n",
            "Epoch 26/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.9361 - acc: 0.7359 - val_loss: 1.4797 - val_acc: 0.6164\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.69030\n",
            "Epoch 27/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9229 - acc: 0.7463 - val_loss: 1.8332 - val_acc: 0.5239\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.69030\n",
            "Epoch 28/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.9047 - acc: 0.7497 - val_loss: 2.0406 - val_acc: 0.4855\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.69030\n",
            "Epoch 29/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.9347 - acc: 0.7413 - val_loss: 1.6798 - val_acc: 0.5909\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.69030\n",
            "Epoch 30/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.9222 - acc: 0.7466 - val_loss: 2.3605 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.69030\n",
            "Epoch 31/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.9091 - acc: 0.7473 - val_loss: 3.9368 - val_acc: 0.3663\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.69030\n",
            "Epoch 32/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8709 - acc: 0.7594 - val_loss: 2.3685 - val_acc: 0.4236\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.69030\n",
            "Epoch 33/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8837 - acc: 0.7566 - val_loss: 1.8644 - val_acc: 0.5385\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.69030\n",
            "Epoch 34/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8652 - acc: 0.7606 - val_loss: 1.1549 - val_acc: 0.6979\n",
            "\n",
            "Epoch 00034: val_acc improved from 0.69030 to 0.69790, saving model to /content/saved_models/cifar10_ResNet32v1_model.034.h5\n",
            "Epoch 35/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8592 - acc: 0.7686 - val_loss: 1.6617 - val_acc: 0.6145\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.69790\n",
            "Epoch 36/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.8617 - acc: 0.7677 - val_loss: 1.5854 - val_acc: 0.6136\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.69790\n",
            "Epoch 37/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8453 - acc: 0.7729 - val_loss: 1.3248 - val_acc: 0.6538\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.69790\n",
            "Epoch 38/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8487 - acc: 0.7709 - val_loss: 1.5262 - val_acc: 0.6045\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.69790\n",
            "Epoch 39/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8526 - acc: 0.7709 - val_loss: 1.5414 - val_acc: 0.6046\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.69790\n",
            "Epoch 40/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8355 - acc: 0.7723 - val_loss: 1.6532 - val_acc: 0.5869\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.69790\n",
            "Epoch 41/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8502 - acc: 0.7674 - val_loss: 2.8141 - val_acc: 0.4467\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.69790\n",
            "Epoch 42/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8511 - acc: 0.7680 - val_loss: 1.2651 - val_acc: 0.6508\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.69790\n",
            "Epoch 43/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8267 - acc: 0.7737 - val_loss: 1.6918 - val_acc: 0.5997\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.69790\n",
            "Epoch 44/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8349 - acc: 0.7770 - val_loss: 1.3196 - val_acc: 0.6369\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.69790\n",
            "Epoch 45/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8079 - acc: 0.7831 - val_loss: 1.4810 - val_acc: 0.6157\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.69790\n",
            "Epoch 46/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8184 - acc: 0.7786 - val_loss: 1.3971 - val_acc: 0.6647\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.69790\n",
            "Epoch 47/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8131 - acc: 0.7819 - val_loss: 1.5229 - val_acc: 0.6120\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.69790\n",
            "Epoch 48/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8064 - acc: 0.7866 - val_loss: 2.5917 - val_acc: 0.4712\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.69790\n",
            "Epoch 49/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8060 - acc: 0.7844 - val_loss: 1.1066 - val_acc: 0.7002\n",
            "\n",
            "Epoch 00049: val_acc improved from 0.69790 to 0.70020, saving model to /content/saved_models/cifar10_ResNet32v1_model.049.h5\n",
            "Epoch 50/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7966 - acc: 0.7882 - val_loss: 1.2182 - val_acc: 0.6745\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.70020\n",
            "Epoch 51/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.8117 - acc: 0.7857 - val_loss: 1.4316 - val_acc: 0.6405\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.70020\n",
            "Epoch 52/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7943 - acc: 0.7880 - val_loss: 1.8527 - val_acc: 0.5596\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.70020\n",
            "Epoch 53/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7766 - acc: 0.7915 - val_loss: 1.3943 - val_acc: 0.6402\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.70020\n",
            "Epoch 54/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7713 - acc: 0.7967 - val_loss: 1.3499 - val_acc: 0.6412\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.70020\n",
            "Epoch 55/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7866 - acc: 0.7892 - val_loss: 2.4956 - val_acc: 0.4990\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.70020\n",
            "Epoch 56/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7971 - acc: 0.7922 - val_loss: 1.9637 - val_acc: 0.5488\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.70020\n",
            "Epoch 57/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7712 - acc: 0.7953 - val_loss: 1.3104 - val_acc: 0.6416\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.70020\n",
            "Epoch 58/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7658 - acc: 0.7979 - val_loss: 1.2346 - val_acc: 0.7004\n",
            "\n",
            "Epoch 00058: val_acc improved from 0.70020 to 0.70040, saving model to /content/saved_models/cifar10_ResNet32v1_model.058.h5\n",
            "Epoch 59/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7930 - acc: 0.7888 - val_loss: 1.2431 - val_acc: 0.6657\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.70040\n",
            "Epoch 60/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7955 - acc: 0.7872 - val_loss: 1.0040 - val_acc: 0.7217\n",
            "\n",
            "Epoch 00060: val_acc improved from 0.70040 to 0.72170, saving model to /content/saved_models/cifar10_ResNet32v1_model.060.h5\n",
            "Epoch 61/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7419 - acc: 0.8063 - val_loss: 1.2511 - val_acc: 0.6833\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.72170\n",
            "Epoch 62/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7817 - acc: 0.7954 - val_loss: 2.1932 - val_acc: 0.4940\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.72170\n",
            "Epoch 63/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7549 - acc: 0.8045 - val_loss: 1.8589 - val_acc: 0.5948\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.72170\n",
            "Epoch 64/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7812 - acc: 0.7943 - val_loss: 1.6478 - val_acc: 0.5817\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.72170\n",
            "Epoch 65/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7488 - acc: 0.8069 - val_loss: 1.1673 - val_acc: 0.6672\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.72170\n",
            "Epoch 66/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7506 - acc: 0.8026 - val_loss: 0.9528 - val_acc: 0.7538\n",
            "\n",
            "Epoch 00066: val_acc improved from 0.72170 to 0.75380, saving model to /content/saved_models/cifar10_ResNet32v1_model.066.h5\n",
            "Epoch 67/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7504 - acc: 0.8029 - val_loss: 1.2895 - val_acc: 0.6704\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.75380\n",
            "Epoch 68/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7552 - acc: 0.8023 - val_loss: 0.9176 - val_acc: 0.7650\n",
            "\n",
            "Epoch 00068: val_acc improved from 0.75380 to 0.76500, saving model to /content/saved_models/cifar10_ResNet32v1_model.068.h5\n",
            "Epoch 69/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7702 - acc: 0.7962 - val_loss: 4.2030 - val_acc: 0.3639\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.76500\n",
            "Epoch 70/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7641 - acc: 0.7995 - val_loss: 1.0993 - val_acc: 0.7012\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.76500\n",
            "Epoch 71/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7500 - acc: 0.8057 - val_loss: 3.9181 - val_acc: 0.4041\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.76500\n",
            "Epoch 72/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.7522 - acc: 0.8025 - val_loss: 0.9680 - val_acc: 0.7407\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.76500\n",
            "Epoch 73/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.7497 - acc: 0.8045 - val_loss: 1.7135 - val_acc: 0.6072\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.76500\n",
            "Epoch 74/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7325 - acc: 0.8101 - val_loss: 1.5281 - val_acc: 0.6173\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.76500\n",
            "Epoch 75/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7322 - acc: 0.8127 - val_loss: 1.5010 - val_acc: 0.6459\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.76500\n",
            "Epoch 76/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7508 - acc: 0.8032 - val_loss: 1.0626 - val_acc: 0.7262\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.76500\n",
            "Epoch 77/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7598 - acc: 0.8031 - val_loss: 1.5486 - val_acc: 0.6237\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.76500\n",
            "Epoch 78/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.7437 - acc: 0.8053 - val_loss: 1.2715 - val_acc: 0.6740\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.76500\n",
            "Epoch 79/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7285 - acc: 0.8163 - val_loss: 1.1943 - val_acc: 0.6929\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.76500\n",
            "Epoch 80/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7245 - acc: 0.8145 - val_loss: 1.7477 - val_acc: 0.5654\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.76500\n",
            "Epoch 81/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7467 - acc: 0.8082 - val_loss: 1.1943 - val_acc: 0.6868\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.76500\n",
            "Epoch 82/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7347 - acc: 0.8110 - val_loss: 1.3247 - val_acc: 0.6578\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.76500\n",
            "Epoch 83/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7328 - acc: 0.8066 - val_loss: 1.1247 - val_acc: 0.7053\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.76500\n",
            "Epoch 84/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7277 - acc: 0.8137 - val_loss: 1.4539 - val_acc: 0.6164\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.76500\n",
            "Epoch 85/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7127 - acc: 0.8155 - val_loss: 1.8591 - val_acc: 0.5491\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.76500\n",
            "Epoch 86/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7270 - acc: 0.8096 - val_loss: 1.0287 - val_acc: 0.7281\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.76500\n",
            "Epoch 87/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7309 - acc: 0.8151 - val_loss: 1.4781 - val_acc: 0.6084\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.76500\n",
            "Epoch 88/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7269 - acc: 0.8134 - val_loss: 1.1533 - val_acc: 0.6928\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.76500\n",
            "Epoch 89/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7102 - acc: 0.8162 - val_loss: 1.7684 - val_acc: 0.6035\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.76500\n",
            "Epoch 90/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7118 - acc: 0.8162 - val_loss: 1.0624 - val_acc: 0.7256\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.76500\n",
            "Epoch 91/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7062 - acc: 0.8231 - val_loss: 1.0762 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.76500\n",
            "Epoch 92/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7177 - acc: 0.8144 - val_loss: 1.9905 - val_acc: 0.5937\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.76500\n",
            "Epoch 93/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7204 - acc: 0.8195 - val_loss: 1.4567 - val_acc: 0.6196\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.76500\n",
            "Epoch 94/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7142 - acc: 0.8139 - val_loss: 1.0335 - val_acc: 0.7310\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.76500\n",
            "Epoch 95/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7300 - acc: 0.8104 - val_loss: 1.2231 - val_acc: 0.6703\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.76500\n",
            "Epoch 96/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6900 - acc: 0.8287 - val_loss: 1.8813 - val_acc: 0.5693\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.76500\n",
            "Epoch 97/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7215 - acc: 0.8185 - val_loss: 0.9759 - val_acc: 0.7493\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.76500\n",
            "Epoch 98/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7098 - acc: 0.8195 - val_loss: 0.9675 - val_acc: 0.7498\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.76500\n",
            "Epoch 99/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6885 - acc: 0.8269 - val_loss: 2.0959 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.76500\n",
            "Epoch 100/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7092 - acc: 0.8177 - val_loss: 1.7891 - val_acc: 0.5908\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.76500\n",
            "Epoch 101/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6854 - acc: 0.8268 - val_loss: 1.1199 - val_acc: 0.7099\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.76500\n",
            "Epoch 102/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7007 - acc: 0.8191 - val_loss: 1.0809 - val_acc: 0.7049\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.76500\n",
            "Epoch 103/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6835 - acc: 0.8297 - val_loss: 1.1636 - val_acc: 0.7128\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.76500\n",
            "Epoch 104/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6835 - acc: 0.8251 - val_loss: 1.3352 - val_acc: 0.6536\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.76500\n",
            "Epoch 105/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6988 - acc: 0.8199 - val_loss: 1.5127 - val_acc: 0.6410\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.76500\n",
            "Epoch 106/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7030 - acc: 0.8249 - val_loss: 1.1243 - val_acc: 0.7202\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.76500\n",
            "Epoch 107/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7117 - acc: 0.8160 - val_loss: 1.0951 - val_acc: 0.7223\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.76500\n",
            "Epoch 108/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7047 - acc: 0.8220 - val_loss: 1.2672 - val_acc: 0.6765\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.76500\n",
            "Epoch 109/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6884 - acc: 0.8261 - val_loss: 1.1655 - val_acc: 0.6955\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.76500\n",
            "Epoch 110/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7143 - acc: 0.8176 - val_loss: 1.4921 - val_acc: 0.6440\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.76500\n",
            "Epoch 111/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6758 - acc: 0.8337 - val_loss: 0.9894 - val_acc: 0.7495\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.76500\n",
            "Epoch 112/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7009 - acc: 0.8197 - val_loss: 1.1577 - val_acc: 0.7020\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.76500\n",
            "Epoch 113/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6812 - acc: 0.8291 - val_loss: 1.5521 - val_acc: 0.6396\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.76500\n",
            "Epoch 114/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6715 - acc: 0.8279 - val_loss: 1.2717 - val_acc: 0.6690\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.76500\n",
            "Epoch 115/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6883 - acc: 0.8271 - val_loss: 1.1512 - val_acc: 0.7045\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.76500\n",
            "Epoch 116/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6863 - acc: 0.8254 - val_loss: 1.3888 - val_acc: 0.6722\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.76500\n",
            "Epoch 117/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6793 - acc: 0.8331 - val_loss: 1.0721 - val_acc: 0.7384\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.76500\n",
            "Epoch 118/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6861 - acc: 0.8250 - val_loss: 1.4731 - val_acc: 0.6286\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.76500\n",
            "Epoch 119/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6759 - acc: 0.8304 - val_loss: 2.3873 - val_acc: 0.4982\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.76500\n",
            "Epoch 120/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6820 - acc: 0.8297 - val_loss: 1.5073 - val_acc: 0.6228\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.76500\n",
            "Epoch 121/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6615 - acc: 0.8311 - val_loss: 1.1432 - val_acc: 0.6892\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.76500\n",
            "Epoch 122/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6696 - acc: 0.8332 - val_loss: 1.2977 - val_acc: 0.6993\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.76500\n",
            "Epoch 123/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7039 - acc: 0.8210 - val_loss: 1.8459 - val_acc: 0.5910\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.76500\n",
            "Epoch 124/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6682 - acc: 0.8365 - val_loss: 1.5433 - val_acc: 0.6279\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.76500\n",
            "Epoch 125/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6623 - acc: 0.8361 - val_loss: 0.9828 - val_acc: 0.7458\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.76500\n",
            "Epoch 126/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6809 - acc: 0.8319 - val_loss: 1.0463 - val_acc: 0.7289\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.76500\n",
            "Epoch 127/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6813 - acc: 0.8279 - val_loss: 1.2833 - val_acc: 0.6653\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.76500\n",
            "Epoch 128/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6690 - acc: 0.8332 - val_loss: 1.0583 - val_acc: 0.7284\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.76500\n",
            "Epoch 129/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6760 - acc: 0.8287 - val_loss: 1.3429 - val_acc: 0.6898\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.76500\n",
            "Epoch 130/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6735 - acc: 0.8328 - val_loss: 1.4597 - val_acc: 0.6418\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.76500\n",
            "Epoch 131/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6638 - acc: 0.8390 - val_loss: 1.6522 - val_acc: 0.5537\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.76500\n",
            "Epoch 132/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6899 - acc: 0.8278 - val_loss: 0.8742 - val_acc: 0.7755\n",
            "\n",
            "Epoch 00132: val_acc improved from 0.76500 to 0.77550, saving model to /content/saved_models/cifar10_ResNet32v1_model.132.h5\n",
            "Epoch 133/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6806 - acc: 0.8282 - val_loss: 1.0546 - val_acc: 0.7132\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.77550\n",
            "Epoch 134/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6634 - acc: 0.8375 - val_loss: 1.8141 - val_acc: 0.6206\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.77550\n",
            "Epoch 135/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6690 - acc: 0.8317 - val_loss: 1.3721 - val_acc: 0.6700\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.77550\n",
            "Epoch 136/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6650 - acc: 0.8332 - val_loss: 0.9546 - val_acc: 0.7563\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.77550\n",
            "Epoch 137/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6553 - acc: 0.8375 - val_loss: 1.7075 - val_acc: 0.6061\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.77550\n",
            "Epoch 138/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6648 - acc: 0.8335 - val_loss: 1.1982 - val_acc: 0.6762\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.77550\n",
            "Epoch 139/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6784 - acc: 0.8284 - val_loss: 1.1052 - val_acc: 0.7446\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.77550\n",
            "Epoch 140/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6501 - acc: 0.8387 - val_loss: 1.0035 - val_acc: 0.7408\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.77550\n",
            "Epoch 141/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6720 - acc: 0.8306 - val_loss: 0.9086 - val_acc: 0.7672\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.77550\n",
            "Epoch 142/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6776 - acc: 0.8300 - val_loss: 1.3612 - val_acc: 0.6739\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.77550\n",
            "Epoch 143/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6534 - acc: 0.8400 - val_loss: 0.8090 - val_acc: 0.8036\n",
            "\n",
            "Epoch 00143: val_acc improved from 0.77550 to 0.80360, saving model to /content/saved_models/cifar10_ResNet32v1_model.143.h5\n",
            "Epoch 144/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6619 - acc: 0.8363 - val_loss: 1.3818 - val_acc: 0.6758\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.80360\n",
            "Epoch 145/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6464 - acc: 0.8440 - val_loss: 1.1513 - val_acc: 0.7085\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.80360\n",
            "Epoch 146/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6629 - acc: 0.8312 - val_loss: 1.0690 - val_acc: 0.7274\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.80360\n",
            "Epoch 147/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6666 - acc: 0.8323 - val_loss: 1.0986 - val_acc: 0.7089\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.80360\n",
            "Epoch 148/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6613 - acc: 0.8338 - val_loss: 1.2182 - val_acc: 0.7056\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.80360\n",
            "Epoch 149/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6638 - acc: 0.8360 - val_loss: 1.3720 - val_acc: 0.6663\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.80360\n",
            "Epoch 150/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6724 - acc: 0.8314 - val_loss: 1.2827 - val_acc: 0.7058\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.80360\n",
            "Epoch 151/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6494 - acc: 0.8421 - val_loss: 1.3268 - val_acc: 0.6910\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.80360\n",
            "Epoch 152/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6558 - acc: 0.8353 - val_loss: 0.8800 - val_acc: 0.7709\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.80360\n",
            "Epoch 153/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6382 - acc: 0.8462 - val_loss: 0.9104 - val_acc: 0.7611\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.80360\n",
            "Epoch 154/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6661 - acc: 0.8365 - val_loss: 1.3140 - val_acc: 0.6671\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.80360\n",
            "Epoch 155/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6427 - acc: 0.8398 - val_loss: 1.5795 - val_acc: 0.6264\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.80360\n",
            "Epoch 156/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6595 - acc: 0.8353 - val_loss: 0.9498 - val_acc: 0.7704\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.80360\n",
            "Epoch 157/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6555 - acc: 0.8368 - val_loss: 1.1540 - val_acc: 0.7027\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.80360\n",
            "Epoch 158/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6398 - acc: 0.8415 - val_loss: 1.0718 - val_acc: 0.7249\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.80360\n",
            "Epoch 159/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6499 - acc: 0.8402 - val_loss: 1.2092 - val_acc: 0.7032\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.80360\n",
            "Epoch 160/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6357 - acc: 0.8443 - val_loss: 1.3428 - val_acc: 0.6702\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.80360\n",
            "Epoch 161/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6344 - acc: 0.8458 - val_loss: 1.3372 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.80360\n",
            "Epoch 162/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6542 - acc: 0.8382 - val_loss: 0.8465 - val_acc: 0.7813\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.80360\n",
            "Epoch 163/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6462 - acc: 0.8392 - val_loss: 0.7914 - val_acc: 0.7955\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.80360\n",
            "Epoch 164/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6397 - acc: 0.8426 - val_loss: 1.1770 - val_acc: 0.6915\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.80360\n",
            "Epoch 165/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6404 - acc: 0.8460 - val_loss: 0.8917 - val_acc: 0.7668\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.80360\n",
            "Epoch 166/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6570 - acc: 0.8323 - val_loss: 1.1282 - val_acc: 0.7222\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.80360\n",
            "Epoch 167/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6422 - acc: 0.8397 - val_loss: 1.5172 - val_acc: 0.6143\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.80360\n",
            "Epoch 168/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6358 - acc: 0.8436 - val_loss: 1.2406 - val_acc: 0.6998\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.80360\n",
            "Epoch 169/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6408 - acc: 0.8473 - val_loss: 0.9330 - val_acc: 0.7609\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.80360\n",
            "Epoch 170/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6443 - acc: 0.8412 - val_loss: 1.7375 - val_acc: 0.5736\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.80360\n",
            "Epoch 171/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6386 - acc: 0.8411 - val_loss: 1.4943 - val_acc: 0.6410\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.80360\n",
            "Epoch 172/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6352 - acc: 0.8487 - val_loss: 0.9435 - val_acc: 0.7461\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.80360\n",
            "Epoch 173/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6610 - acc: 0.8369 - val_loss: 1.0911 - val_acc: 0.7226\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.80360\n",
            "Epoch 174/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6467 - acc: 0.8382 - val_loss: 0.9454 - val_acc: 0.7547\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.80360\n",
            "Epoch 175/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6336 - acc: 0.8466 - val_loss: 1.7061 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.80360\n",
            "Epoch 176/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6539 - acc: 0.8355 - val_loss: 1.9594 - val_acc: 0.5888\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.80360\n",
            "Epoch 177/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.6357 - acc: 0.8427 - val_loss: 1.1535 - val_acc: 0.7055\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.80360\n",
            "Epoch 178/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6498 - acc: 0.8389 - val_loss: 1.2495 - val_acc: 0.6765\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.80360\n",
            "Epoch 179/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6294 - acc: 0.8477 - val_loss: 1.3819 - val_acc: 0.6779\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.80360\n",
            "Epoch 180/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6383 - acc: 0.8464 - val_loss: 1.1724 - val_acc: 0.7006\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.80360\n",
            "Epoch 181/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6203 - acc: 0.8515 - val_loss: 0.9519 - val_acc: 0.7550\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.80360\n",
            "Epoch 182/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6561 - acc: 0.8379 - val_loss: 1.0582 - val_acc: 0.7421\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.80360\n",
            "Epoch 183/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6325 - acc: 0.8462 - val_loss: 1.1423 - val_acc: 0.7155\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.80360\n",
            "Epoch 184/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6428 - acc: 0.8451 - val_loss: 1.1154 - val_acc: 0.7412\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.80360\n",
            "Epoch 185/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.6276 - acc: 0.8475 - val_loss: 1.2296 - val_acc: 0.7090\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.80360\n",
            "Epoch 186/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.6532 - acc: 0.8415 - val_loss: 1.5760 - val_acc: 0.6284\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.80360\n",
            "Epoch 187/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6300 - acc: 0.8432 - val_loss: 1.5139 - val_acc: 0.5956\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.80360\n",
            "Epoch 188/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6263 - acc: 0.8484 - val_loss: 1.1566 - val_acc: 0.7103\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.80360\n",
            "Epoch 189/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6305 - acc: 0.8524 - val_loss: 1.0578 - val_acc: 0.7349\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.80360\n",
            "Epoch 190/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6435 - acc: 0.8438 - val_loss: 1.7160 - val_acc: 0.6125\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.80360\n",
            "Epoch 191/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6344 - acc: 0.8419 - val_loss: 1.0938 - val_acc: 0.7037\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.80360\n",
            "Epoch 192/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6405 - acc: 0.8433 - val_loss: 1.2926 - val_acc: 0.7075\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.80360\n",
            "Epoch 193/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6456 - acc: 0.8418 - val_loss: 1.1123 - val_acc: 0.7316\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.80360\n",
            "Epoch 194/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6441 - acc: 0.8428 - val_loss: 1.1371 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.80360\n",
            "Epoch 195/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6440 - acc: 0.8422 - val_loss: 1.2036 - val_acc: 0.6966\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.80360\n",
            "Epoch 196/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6217 - acc: 0.8480 - val_loss: 1.6954 - val_acc: 0.5914\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.80360\n",
            "Epoch 197/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.6363 - acc: 0.8430 - val_loss: 1.0853 - val_acc: 0.7330\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.80360\n",
            "Epoch 198/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6429 - acc: 0.8393 - val_loss: 1.0107 - val_acc: 0.7293\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.80360\n",
            "Epoch 199/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6477 - acc: 0.8426 - val_loss: 1.1819 - val_acc: 0.7094\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.80360\n",
            "Epoch 200/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6129 - acc: 0.8524 - val_loss: 0.9895 - val_acc: 0.7624\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.80360\n",
            "Epoch 201/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6303 - acc: 0.8482 - val_loss: 0.9378 - val_acc: 0.7630\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.80360\n",
            "Epoch 202/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6478 - acc: 0.8353 - val_loss: 1.1549 - val_acc: 0.7311\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.80360\n",
            "Epoch 203/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6117 - acc: 0.8500 - val_loss: 0.9994 - val_acc: 0.7496\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.80360\n",
            "Epoch 204/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6223 - acc: 0.8532 - val_loss: 1.2526 - val_acc: 0.6891\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.80360\n",
            "Epoch 205/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6352 - acc: 0.8451 - val_loss: 1.0919 - val_acc: 0.7146\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.80360\n",
            "Epoch 206/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6329 - acc: 0.8468 - val_loss: 1.4257 - val_acc: 0.6604\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.80360\n",
            "Epoch 207/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6318 - acc: 0.8466 - val_loss: 1.6273 - val_acc: 0.6289\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.80360\n",
            "Epoch 208/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6223 - acc: 0.8452 - val_loss: 0.9955 - val_acc: 0.7396\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.80360\n",
            "Epoch 209/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6458 - acc: 0.8419 - val_loss: 1.5738 - val_acc: 0.6192\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.80360\n",
            "Epoch 210/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6345 - acc: 0.8458 - val_loss: 1.3105 - val_acc: 0.6950\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.80360\n",
            "Epoch 211/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6326 - acc: 0.8449 - val_loss: 1.2918 - val_acc: 0.6942\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.80360\n",
            "Epoch 212/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6134 - acc: 0.8472 - val_loss: 1.2285 - val_acc: 0.6947\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.80360\n",
            "Epoch 213/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6286 - acc: 0.8481 - val_loss: 2.1892 - val_acc: 0.5683\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.80360\n",
            "Epoch 214/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6233 - acc: 0.8485 - val_loss: 1.6474 - val_acc: 0.6259\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.80360\n",
            "Epoch 215/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6395 - acc: 0.8396 - val_loss: 0.9700 - val_acc: 0.7589\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.80360\n",
            "Epoch 216/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6269 - acc: 0.8531 - val_loss: 0.9995 - val_acc: 0.7509\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.80360\n",
            "Epoch 217/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6311 - acc: 0.8476 - val_loss: 1.0657 - val_acc: 0.7259\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.80360\n",
            "Epoch 218/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6250 - acc: 0.8475 - val_loss: 0.9572 - val_acc: 0.7560\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.80360\n",
            "Epoch 219/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6214 - acc: 0.8464 - val_loss: 1.3497 - val_acc: 0.6956\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.80360\n",
            "Epoch 220/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6190 - acc: 0.8503 - val_loss: 1.0929 - val_acc: 0.7160\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.80360\n",
            "Epoch 221/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6265 - acc: 0.8470 - val_loss: 0.9265 - val_acc: 0.7599\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.80360\n",
            "Epoch 222/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6314 - acc: 0.8456 - val_loss: 1.3587 - val_acc: 0.6358\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.80360\n",
            "Epoch 223/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6151 - acc: 0.8525 - val_loss: 1.1615 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.80360\n",
            "Epoch 224/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6360 - acc: 0.8448 - val_loss: 0.9305 - val_acc: 0.7566\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.80360\n",
            "Epoch 225/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6103 - acc: 0.8564 - val_loss: 0.9074 - val_acc: 0.7727\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.80360\n",
            "Epoch 226/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6432 - acc: 0.8381 - val_loss: 1.6990 - val_acc: 0.6203\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.80360\n",
            "Epoch 227/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6398 - acc: 0.8436 - val_loss: 1.2102 - val_acc: 0.6747\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.80360\n",
            "Epoch 228/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6289 - acc: 0.8495 - val_loss: 1.0534 - val_acc: 0.7390\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.80360\n",
            "Epoch 229/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6207 - acc: 0.8514 - val_loss: 1.1597 - val_acc: 0.7319\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.80360\n",
            "Epoch 230/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6070 - acc: 0.8563 - val_loss: 0.7776 - val_acc: 0.8011\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.80360\n",
            "Epoch 231/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6236 - acc: 0.8484 - val_loss: 0.9485 - val_acc: 0.7443\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.80360\n",
            "Epoch 232/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6179 - acc: 0.8513 - val_loss: 1.6273 - val_acc: 0.6297\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.80360\n",
            "Epoch 233/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6195 - acc: 0.8489 - val_loss: 1.0641 - val_acc: 0.7214\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.80360\n",
            "Epoch 234/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6154 - acc: 0.8504 - val_loss: 1.6128 - val_acc: 0.6153\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.80360\n",
            "Epoch 235/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6310 - acc: 0.8481 - val_loss: 0.9460 - val_acc: 0.7607\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.80360\n",
            "Epoch 236/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6204 - acc: 0.8521 - val_loss: 1.1693 - val_acc: 0.7164\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.80360\n",
            "Epoch 237/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6097 - acc: 0.8504 - val_loss: 1.5620 - val_acc: 0.6177\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.80360\n",
            "Epoch 238/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6038 - acc: 0.8554 - val_loss: 0.9072 - val_acc: 0.7626\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.80360\n",
            "Epoch 239/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6108 - acc: 0.8533 - val_loss: 0.9265 - val_acc: 0.7569\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.80360\n",
            "Epoch 240/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6318 - acc: 0.8469 - val_loss: 1.4382 - val_acc: 0.6598\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.80360\n",
            "Epoch 241/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6047 - acc: 0.8573 - val_loss: 1.1714 - val_acc: 0.7063\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.80360\n",
            "Epoch 242/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6170 - acc: 0.8516 - val_loss: 1.7145 - val_acc: 0.6344\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.80360\n",
            "Epoch 243/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6075 - acc: 0.8543 - val_loss: 1.2385 - val_acc: 0.6930\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.80360\n",
            "Epoch 244/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6175 - acc: 0.8482 - val_loss: 1.6803 - val_acc: 0.6113\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.80360\n",
            "Epoch 245/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6078 - acc: 0.8542 - val_loss: 0.9014 - val_acc: 0.7669\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.80360\n",
            "Epoch 246/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.6208 - acc: 0.8481 - val_loss: 1.0857 - val_acc: 0.7269\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.80360\n",
            "Epoch 247/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6249 - acc: 0.8535 - val_loss: 1.8301 - val_acc: 0.6028\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.80360\n",
            "Epoch 248/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6174 - acc: 0.8521 - val_loss: 1.4696 - val_acc: 0.6579\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.80360\n",
            "Epoch 249/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6124 - acc: 0.8495 - val_loss: 0.9478 - val_acc: 0.7615\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.80360\n",
            "Epoch 250/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6248 - acc: 0.8503 - val_loss: 1.0739 - val_acc: 0.6988\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.80360\n",
            "Epoch 251/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6167 - acc: 0.8492 - val_loss: 1.1155 - val_acc: 0.7175\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.80360\n",
            "Epoch 252/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6113 - acc: 0.8460 - val_loss: 1.2178 - val_acc: 0.6888\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.80360\n",
            "Epoch 253/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6147 - acc: 0.8527 - val_loss: 0.7831 - val_acc: 0.7946\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.80360\n",
            "Epoch 254/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6282 - acc: 0.8452 - val_loss: 1.2598 - val_acc: 0.6880\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.80360\n",
            "Epoch 255/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6195 - acc: 0.8522 - val_loss: 1.2595 - val_acc: 0.6825\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.80360\n",
            "Epoch 256/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6131 - acc: 0.8514 - val_loss: 1.0469 - val_acc: 0.7369\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.80360\n",
            "Epoch 257/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5959 - acc: 0.8585 - val_loss: 1.0752 - val_acc: 0.7167\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.80360\n",
            "Epoch 258/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6268 - acc: 0.8489 - val_loss: 1.0522 - val_acc: 0.7299\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.80360\n",
            "Epoch 259/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6204 - acc: 0.8504 - val_loss: 2.0283 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.80360\n",
            "Epoch 260/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6237 - acc: 0.8506 - val_loss: 1.3224 - val_acc: 0.6788\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.80360\n",
            "Epoch 261/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6075 - acc: 0.8520 - val_loss: 1.3991 - val_acc: 0.6553\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.80360\n",
            "Epoch 262/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6099 - acc: 0.8496 - val_loss: 1.7015 - val_acc: 0.5970\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.80360\n",
            "Epoch 263/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.6225 - acc: 0.8505 - val_loss: 0.8207 - val_acc: 0.7908\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.80360\n",
            "Epoch 264/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6162 - acc: 0.8497 - val_loss: 1.2252 - val_acc: 0.6980\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.80360\n",
            "Epoch 265/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6132 - acc: 0.8519 - val_loss: 1.3794 - val_acc: 0.6762\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.80360\n",
            "Epoch 266/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6071 - acc: 0.8558 - val_loss: 1.2778 - val_acc: 0.7110\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.80360\n",
            "Epoch 267/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5973 - acc: 0.8617 - val_loss: 1.0621 - val_acc: 0.7393\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.80360\n",
            "Epoch 268/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6177 - acc: 0.8498 - val_loss: 1.0232 - val_acc: 0.7440\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.80360\n",
            "Epoch 269/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6288 - acc: 0.8501 - val_loss: 1.2759 - val_acc: 0.6412\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.80360\n",
            "Epoch 270/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6276 - acc: 0.8465 - val_loss: 0.9092 - val_acc: 0.7710\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.80360\n",
            "Epoch 271/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6237 - acc: 0.8453 - val_loss: 1.1146 - val_acc: 0.7270\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.80360\n",
            "Epoch 272/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6109 - acc: 0.8512 - val_loss: 1.1659 - val_acc: 0.7062\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.80360\n",
            "Epoch 273/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5961 - acc: 0.8600 - val_loss: 0.9405 - val_acc: 0.7546\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.80360\n",
            "Epoch 274/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6025 - acc: 0.8596 - val_loss: 1.1253 - val_acc: 0.7253\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.80360\n",
            "Epoch 275/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6158 - acc: 0.8532 - val_loss: 0.8197 - val_acc: 0.7914\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.80360\n",
            "Epoch 276/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6008 - acc: 0.8578 - val_loss: 0.9203 - val_acc: 0.7804\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.80360\n",
            "Epoch 277/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5992 - acc: 0.8537 - val_loss: 0.8511 - val_acc: 0.7783\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.80360\n",
            "Epoch 278/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5998 - acc: 0.8586 - val_loss: 1.4520 - val_acc: 0.6363\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.80360\n",
            "Epoch 279/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6025 - acc: 0.8548 - val_loss: 1.0901 - val_acc: 0.7315\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.80360\n",
            "Epoch 280/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6159 - acc: 0.8510 - val_loss: 1.3470 - val_acc: 0.6741\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.80360\n",
            "Epoch 281/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5948 - acc: 0.8620 - val_loss: 1.0311 - val_acc: 0.7473\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.80360\n",
            "Epoch 282/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6115 - acc: 0.8545 - val_loss: 0.9081 - val_acc: 0.7895\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.80360\n",
            "Epoch 283/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5907 - acc: 0.8605 - val_loss: 0.9509 - val_acc: 0.7643\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.80360\n",
            "Epoch 284/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5968 - acc: 0.8588 - val_loss: 1.0854 - val_acc: 0.7273\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.80360\n",
            "Epoch 285/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6118 - acc: 0.8562 - val_loss: 0.9769 - val_acc: 0.7501\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.80360\n",
            "Epoch 286/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5909 - acc: 0.8577 - val_loss: 1.4406 - val_acc: 0.6420\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.80360\n",
            "Epoch 287/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6103 - acc: 0.8543 - val_loss: 1.0584 - val_acc: 0.7266\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.80360\n",
            "Epoch 288/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5960 - acc: 0.8572 - val_loss: 1.1321 - val_acc: 0.7264\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.80360\n",
            "Epoch 289/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6276 - acc: 0.8453 - val_loss: 1.2288 - val_acc: 0.6920\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.80360\n",
            "Epoch 290/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6091 - acc: 0.8551 - val_loss: 0.9921 - val_acc: 0.7444\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.80360\n",
            "Epoch 291/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5927 - acc: 0.8637 - val_loss: 0.9181 - val_acc: 0.7697\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.80360\n",
            "Epoch 292/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5898 - acc: 0.8580 - val_loss: 1.0016 - val_acc: 0.7401\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.80360\n",
            "Epoch 293/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6089 - acc: 0.8555 - val_loss: 0.9194 - val_acc: 0.7544\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.80360\n",
            "Epoch 294/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6116 - acc: 0.8536 - val_loss: 1.2377 - val_acc: 0.7008\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.80360\n",
            "Epoch 295/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5996 - acc: 0.8567 - val_loss: 0.9978 - val_acc: 0.7479\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.80360\n",
            "Epoch 296/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6051 - acc: 0.8554 - val_loss: 1.0037 - val_acc: 0.7441\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.80360\n",
            "Epoch 297/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5991 - acc: 0.8540 - val_loss: 1.0397 - val_acc: 0.7431\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.80360\n",
            "Epoch 298/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6172 - acc: 0.8485 - val_loss: 1.3433 - val_acc: 0.6729\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.80360\n",
            "Epoch 299/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6012 - acc: 0.8536 - val_loss: 1.0096 - val_acc: 0.7492\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.80360\n",
            "Epoch 300/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5964 - acc: 0.8578 - val_loss: 1.3579 - val_acc: 0.6378\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.80360\n",
            "Epoch 301/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.6057 - acc: 0.8551 - val_loss: 1.2993 - val_acc: 0.6735\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.80360\n",
            "Epoch 302/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5856 - acc: 0.8628 - val_loss: 1.2615 - val_acc: 0.6930\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.80360\n",
            "Epoch 303/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5981 - acc: 0.8573 - val_loss: 0.9214 - val_acc: 0.7644\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.80360\n",
            "Epoch 304/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5912 - acc: 0.8593 - val_loss: 1.0640 - val_acc: 0.7460\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.80360\n",
            "Epoch 305/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6176 - acc: 0.8503 - val_loss: 1.1004 - val_acc: 0.7158\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.80360\n",
            "Epoch 306/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6026 - acc: 0.8549 - val_loss: 1.3049 - val_acc: 0.6593\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.80360\n",
            "Epoch 307/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6099 - acc: 0.8532 - val_loss: 1.1884 - val_acc: 0.6834\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.80360\n",
            "Epoch 308/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5949 - acc: 0.8653 - val_loss: 1.0798 - val_acc: 0.7327\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.80360\n",
            "Epoch 309/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6031 - acc: 0.8565 - val_loss: 1.0289 - val_acc: 0.7277\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.80360\n",
            "Epoch 310/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5920 - acc: 0.8606 - val_loss: 0.9555 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.80360\n",
            "Epoch 311/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.6114 - acc: 0.8520 - val_loss: 1.3000 - val_acc: 0.6934\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.80360\n",
            "Epoch 312/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6061 - acc: 0.8531 - val_loss: 0.9764 - val_acc: 0.7494\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.80360\n",
            "Epoch 313/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6011 - acc: 0.8559 - val_loss: 1.0147 - val_acc: 0.7350\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.80360\n",
            "Epoch 314/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5874 - acc: 0.8609 - val_loss: 1.5093 - val_acc: 0.6360\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.80360\n",
            "Epoch 315/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5875 - acc: 0.8619 - val_loss: 0.9206 - val_acc: 0.7739\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.80360\n",
            "Epoch 316/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6142 - acc: 0.8513 - val_loss: 1.2333 - val_acc: 0.7018\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.80360\n",
            "Epoch 317/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5994 - acc: 0.8530 - val_loss: 1.0670 - val_acc: 0.7331\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.80360\n",
            "Epoch 318/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5828 - acc: 0.8627 - val_loss: 0.9583 - val_acc: 0.7563\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.80360\n",
            "Epoch 319/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.5987 - acc: 0.8561 - val_loss: 0.8118 - val_acc: 0.7922\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.80360\n",
            "Epoch 320/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6101 - acc: 0.8519 - val_loss: 1.2132 - val_acc: 0.7044\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.80360\n",
            "Epoch 321/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.5887 - acc: 0.8600 - val_loss: 1.0172 - val_acc: 0.7578\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.80360\n",
            "Epoch 322/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.6064 - acc: 0.8528 - val_loss: 1.0225 - val_acc: 0.7483\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.80360\n",
            "Epoch 323/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5925 - acc: 0.8576 - val_loss: 1.3920 - val_acc: 0.6993\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.80360\n",
            "Epoch 324/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6020 - acc: 0.8553 - val_loss: 0.9292 - val_acc: 0.7729\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.80360\n",
            "Epoch 325/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6026 - acc: 0.8558 - val_loss: 1.0977 - val_acc: 0.7331\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.80360\n",
            "Epoch 326/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.5853 - acc: 0.8650 - val_loss: 1.0614 - val_acc: 0.7312\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.80360\n",
            "Epoch 327/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.5889 - acc: 0.8634 - val_loss: 1.1164 - val_acc: 0.7369\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.80360\n",
            "Epoch 328/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.6012 - acc: 0.8601 - val_loss: 1.0612 - val_acc: 0.7485\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.80360\n",
            "Epoch 329/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.5915 - acc: 0.8593 - val_loss: 1.7545 - val_acc: 0.6336\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.80360\n",
            "Epoch 330/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5903 - acc: 0.8575 - val_loss: 1.0189 - val_acc: 0.7347\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.80360\n",
            "Epoch 331/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5980 - acc: 0.8589 - val_loss: 1.1182 - val_acc: 0.7290\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.80360\n",
            "Epoch 332/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.6157 - acc: 0.8524 - val_loss: 1.1885 - val_acc: 0.7043\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.80360\n",
            "Epoch 333/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5913 - acc: 0.8576 - val_loss: 0.8183 - val_acc: 0.7994\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.80360\n",
            "Epoch 334/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5957 - acc: 0.8608 - val_loss: 1.3738 - val_acc: 0.6838\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.80360\n",
            "Epoch 335/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5890 - acc: 0.8626 - val_loss: 1.1434 - val_acc: 0.7071\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.80360\n",
            "Epoch 336/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.6017 - acc: 0.8548 - val_loss: 1.1559 - val_acc: 0.7102\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.80360\n",
            "Epoch 337/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6010 - acc: 0.8571 - val_loss: 0.8859 - val_acc: 0.7785\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.80360\n",
            "Epoch 338/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6110 - acc: 0.8512 - val_loss: 2.2298 - val_acc: 0.5141\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.80360\n",
            "Epoch 339/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5792 - acc: 0.8629 - val_loss: 1.3664 - val_acc: 0.6610\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.80360\n",
            "Epoch 340/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.5994 - acc: 0.8599 - val_loss: 0.9732 - val_acc: 0.7635\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.80360\n",
            "Epoch 341/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5869 - acc: 0.8599 - val_loss: 0.9897 - val_acc: 0.7469\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.80360\n",
            "Epoch 342/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5951 - acc: 0.8569 - val_loss: 1.4945 - val_acc: 0.6473\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.80360\n",
            "Epoch 343/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5967 - acc: 0.8582 - val_loss: 0.9346 - val_acc: 0.7773\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.80360\n",
            "Epoch 344/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5918 - acc: 0.8591 - val_loss: 1.6137 - val_acc: 0.6419\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.80360\n",
            "Epoch 345/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5872 - acc: 0.8616 - val_loss: 1.5860 - val_acc: 0.6338\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.80360\n",
            "Epoch 346/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5861 - acc: 0.8589 - val_loss: 0.9778 - val_acc: 0.7486\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.80360\n",
            "Epoch 347/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.6124 - acc: 0.8556 - val_loss: 1.3378 - val_acc: 0.6689\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.80360\n",
            "Epoch 348/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5959 - acc: 0.8544 - val_loss: 0.9760 - val_acc: 0.7429\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.80360\n",
            "Epoch 349/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5926 - acc: 0.8597 - val_loss: 1.2493 - val_acc: 0.7071\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.80360\n",
            "Epoch 350/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5755 - acc: 0.8646 - val_loss: 0.7801 - val_acc: 0.8012\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.80360\n",
            "Epoch 351/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5790 - acc: 0.8683 - val_loss: 1.2386 - val_acc: 0.6894\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.80360\n",
            "Epoch 352/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.6082 - acc: 0.8520 - val_loss: 1.6954 - val_acc: 0.6018\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.80360\n",
            "Epoch 353/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.6000 - acc: 0.8615 - val_loss: 1.0800 - val_acc: 0.7322\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.80360\n",
            "Epoch 354/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5906 - acc: 0.8629 - val_loss: 1.0222 - val_acc: 0.7337\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.80360\n",
            "Epoch 355/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5886 - acc: 0.8582 - val_loss: 0.9855 - val_acc: 0.7517\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.80360\n",
            "Epoch 356/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5980 - acc: 0.8571 - val_loss: 1.0303 - val_acc: 0.7510\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.80360\n",
            "Epoch 357/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5780 - acc: 0.8661 - val_loss: 0.9050 - val_acc: 0.7660\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.80360\n",
            "Epoch 358/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5864 - acc: 0.8615 - val_loss: 1.0938 - val_acc: 0.7191\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.80360\n",
            "Epoch 359/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5949 - acc: 0.8605 - val_loss: 1.0171 - val_acc: 0.7250\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.80360\n",
            "Epoch 360/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.5770 - acc: 0.8674 - val_loss: 1.0392 - val_acc: 0.7376\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.80360\n",
            "Epoch 361/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5958 - acc: 0.8559 - val_loss: 1.0195 - val_acc: 0.7379\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.80360\n",
            "Epoch 362/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.5983 - acc: 0.8568 - val_loss: 0.8581 - val_acc: 0.7816\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.80360\n",
            "Epoch 363/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5877 - acc: 0.8636 - val_loss: 1.2159 - val_acc: 0.6974\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.80360\n",
            "Epoch 364/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.6036 - acc: 0.8565 - val_loss: 1.1021 - val_acc: 0.6975\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.80360\n",
            "Epoch 365/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5893 - acc: 0.8608 - val_loss: 1.1904 - val_acc: 0.7001\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.80360\n",
            "Epoch 366/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5963 - acc: 0.8553 - val_loss: 1.0800 - val_acc: 0.7339\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.80360\n",
            "Epoch 367/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5952 - acc: 0.8626 - val_loss: 1.9326 - val_acc: 0.5988\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.80360\n",
            "Epoch 368/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5857 - acc: 0.8573 - val_loss: 2.1754 - val_acc: 0.5884\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.80360\n",
            "Epoch 369/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.6086 - acc: 0.8599 - val_loss: 1.0437 - val_acc: 0.7367\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.80360\n",
            "Epoch 370/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5652 - acc: 0.8710 - val_loss: 0.9751 - val_acc: 0.7673\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.80360\n",
            "Epoch 371/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5838 - acc: 0.8582 - val_loss: 0.8881 - val_acc: 0.7824\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.80360\n",
            "Epoch 372/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6025 - acc: 0.8573 - val_loss: 1.0536 - val_acc: 0.7219\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.80360\n",
            "Epoch 373/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5916 - acc: 0.8570 - val_loss: 1.0995 - val_acc: 0.7402\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.80360\n",
            "Epoch 374/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6049 - acc: 0.8518 - val_loss: 0.8458 - val_acc: 0.7857\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.80360\n",
            "Epoch 375/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5997 - acc: 0.8551 - val_loss: 0.9567 - val_acc: 0.7475\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.80360\n",
            "Epoch 376/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5912 - acc: 0.8618 - val_loss: 0.8385 - val_acc: 0.7819\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.80360\n",
            "Epoch 377/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5866 - acc: 0.8609 - val_loss: 1.3959 - val_acc: 0.6693\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.80360\n",
            "Epoch 378/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5885 - acc: 0.8599 - val_loss: 1.0821 - val_acc: 0.7209\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.80360\n",
            "Epoch 379/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5943 - acc: 0.8606 - val_loss: 0.9501 - val_acc: 0.7615\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.80360\n",
            "Epoch 380/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5800 - acc: 0.8585 - val_loss: 1.1738 - val_acc: 0.7219\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.80360\n",
            "Epoch 381/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5914 - acc: 0.8620 - val_loss: 1.0764 - val_acc: 0.7446\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.80360\n",
            "Epoch 382/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5956 - acc: 0.8566 - val_loss: 0.9214 - val_acc: 0.7599\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.80360\n",
            "Epoch 383/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5759 - acc: 0.8651 - val_loss: 1.1448 - val_acc: 0.7056\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.80360\n",
            "Epoch 384/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.5888 - acc: 0.8587 - val_loss: 1.3077 - val_acc: 0.6550\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.80360\n",
            "Epoch 385/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5807 - acc: 0.8625 - val_loss: 0.8694 - val_acc: 0.7732\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.80360\n",
            "Epoch 386/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5788 - acc: 0.8622 - val_loss: 1.1583 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.80360\n",
            "Epoch 387/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5797 - acc: 0.8636 - val_loss: 0.8307 - val_acc: 0.7871\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.80360\n",
            "Epoch 388/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5752 - acc: 0.8644 - val_loss: 1.0864 - val_acc: 0.7262\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.80360\n",
            "Epoch 389/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5874 - acc: 0.8611 - val_loss: 0.9823 - val_acc: 0.7657\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.80360\n",
            "Epoch 390/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5925 - acc: 0.8657 - val_loss: 1.1131 - val_acc: 0.6979\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.80360\n",
            "Epoch 391/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.5897 - acc: 0.8630 - val_loss: 1.1844 - val_acc: 0.7153\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.80360\n",
            "Epoch 392/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5692 - acc: 0.8663 - val_loss: 1.0997 - val_acc: 0.7238\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.80360\n",
            "Epoch 393/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5790 - acc: 0.8648 - val_loss: 0.8079 - val_acc: 0.7940\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.80360\n",
            "Epoch 394/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5839 - acc: 0.8618 - val_loss: 0.9757 - val_acc: 0.7477\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.80360\n",
            "Epoch 395/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5979 - acc: 0.8579 - val_loss: 1.1136 - val_acc: 0.7431\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.80360\n",
            "Epoch 396/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5881 - acc: 0.8622 - val_loss: 0.9515 - val_acc: 0.7601\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.80360\n",
            "Epoch 397/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.5700 - acc: 0.8686 - val_loss: 0.9545 - val_acc: 0.7505\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.80360\n",
            "Epoch 398/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.5891 - acc: 0.8603 - val_loss: 1.0917 - val_acc: 0.7111\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.80360\n",
            "Epoch 399/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5993 - acc: 0.8561 - val_loss: 1.0246 - val_acc: 0.7403\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.80360\n",
            "Epoch 400/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5959 - acc: 0.8591 - val_loss: 0.9319 - val_acc: 0.7722\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.80360\n",
            "Epoch 401/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5831 - acc: 0.8645 - val_loss: 1.2540 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.80360\n",
            "Epoch 402/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.5066 - acc: 0.8891 - val_loss: 0.5964 - val_acc: 0.8624\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.80360 to 0.86240, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.4523 - acc: 0.9056 - val_loss: 0.5239 - val_acc: 0.8850\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.86240 to 0.88500, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.4537 - acc: 0.9093 - val_loss: 0.5309 - val_acc: 0.8817\n",
            "\n",
            "Epoch 00404: val_acc did not improve from 0.88500\n",
            "Epoch 405/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4328 - acc: 0.9149 - val_loss: 0.5099 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.88500 to 0.88940, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4250 - acc: 0.9196 - val_loss: 0.5066 - val_acc: 0.8882\n",
            "\n",
            "Epoch 00406: val_acc did not improve from 0.88940\n",
            "Epoch 407/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4276 - acc: 0.9185 - val_loss: 0.4983 - val_acc: 0.8920\n",
            "\n",
            "Epoch 00407: val_acc improved from 0.88940 to 0.89200, saving model to /content/saved_models/cifar10_ResNet32v1_model.407.h5\n",
            "Epoch 408/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4285 - acc: 0.9177 - val_loss: 0.4905 - val_acc: 0.8965\n",
            "\n",
            "Epoch 00408: val_acc improved from 0.89200 to 0.89650, saving model to /content/saved_models/cifar10_ResNet32v1_model.408.h5\n",
            "Epoch 409/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4168 - acc: 0.9210 - val_loss: 0.5006 - val_acc: 0.8930\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.89650\n",
            "Epoch 410/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4153 - acc: 0.9232 - val_loss: 0.5013 - val_acc: 0.8923\n",
            "\n",
            "Epoch 00410: val_acc did not improve from 0.89650\n",
            "Epoch 411/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4058 - acc: 0.9235 - val_loss: 0.4992 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.89650\n",
            "Epoch 412/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4074 - acc: 0.9233 - val_loss: 0.5113 - val_acc: 0.8876\n",
            "\n",
            "Epoch 00412: val_acc did not improve from 0.89650\n",
            "Epoch 413/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3982 - acc: 0.9279 - val_loss: 0.4931 - val_acc: 0.8952\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.89650\n",
            "Epoch 414/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3970 - acc: 0.9271 - val_loss: 0.5038 - val_acc: 0.8933\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.89650\n",
            "Epoch 415/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3938 - acc: 0.9300 - val_loss: 0.4884 - val_acc: 0.8958\n",
            "\n",
            "Epoch 00415: val_acc did not improve from 0.89650\n",
            "Epoch 416/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3959 - acc: 0.9283 - val_loss: 0.4980 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.89650\n",
            "Epoch 417/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3929 - acc: 0.9289 - val_loss: 0.4953 - val_acc: 0.8937\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.89650\n",
            "Epoch 418/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3817 - acc: 0.9306 - val_loss: 0.4882 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00418: val_acc improved from 0.89650 to 0.89900, saving model to /content/saved_models/cifar10_ResNet32v1_model.418.h5\n",
            "Epoch 419/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3881 - acc: 0.9281 - val_loss: 0.4925 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.89900\n",
            "Epoch 420/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3789 - acc: 0.9325 - val_loss: 0.5034 - val_acc: 0.8935\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.89900\n",
            "Epoch 421/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3913 - acc: 0.9296 - val_loss: 0.4873 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00421: val_acc improved from 0.89900 to 0.89970, saving model to /content/saved_models/cifar10_ResNet32v1_model.421.h5\n",
            "Epoch 422/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3790 - acc: 0.9326 - val_loss: 0.5229 - val_acc: 0.8878\n",
            "\n",
            "Epoch 00422: val_acc did not improve from 0.89970\n",
            "Epoch 423/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3703 - acc: 0.9363 - val_loss: 0.4974 - val_acc: 0.8947\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.89970\n",
            "Epoch 424/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3685 - acc: 0.9367 - val_loss: 0.4842 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00424: val_acc improved from 0.89970 to 0.89990, saving model to /content/saved_models/cifar10_ResNet32v1_model.424.h5\n",
            "Epoch 425/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3765 - acc: 0.9342 - val_loss: 0.4980 - val_acc: 0.8946\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.89990\n",
            "Epoch 426/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3671 - acc: 0.9349 - val_loss: 0.5101 - val_acc: 0.8921\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.89990\n",
            "Epoch 427/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3730 - acc: 0.9364 - val_loss: 0.4845 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.89990\n",
            "Epoch 428/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3697 - acc: 0.9344 - val_loss: 0.4904 - val_acc: 0.9007\n",
            "\n",
            "Epoch 00428: val_acc improved from 0.89990 to 0.90070, saving model to /content/saved_models/cifar10_ResNet32v1_model.428.h5\n",
            "Epoch 429/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3582 - acc: 0.9405 - val_loss: 0.4945 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.90070\n",
            "Epoch 430/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3614 - acc: 0.9438 - val_loss: 0.4940 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.90070\n",
            "Epoch 431/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3571 - acc: 0.9383 - val_loss: 0.4998 - val_acc: 0.8958\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.90070\n",
            "Epoch 432/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3684 - acc: 0.9374 - val_loss: 0.4971 - val_acc: 0.8935\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.90070\n",
            "Epoch 433/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3646 - acc: 0.9370 - val_loss: 0.4887 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.90070\n",
            "Epoch 434/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3606 - acc: 0.9370 - val_loss: 0.4769 - val_acc: 0.9018\n",
            "\n",
            "Epoch 00434: val_acc improved from 0.90070 to 0.90180, saving model to /content/saved_models/cifar10_ResNet32v1_model.434.h5\n",
            "Epoch 435/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3619 - acc: 0.9380 - val_loss: 0.4793 - val_acc: 0.9014\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.90180\n",
            "Epoch 436/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3586 - acc: 0.9377 - val_loss: 0.4924 - val_acc: 0.8964\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.90180\n",
            "Epoch 437/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3577 - acc: 0.9413 - val_loss: 0.5019 - val_acc: 0.8967\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.90180\n",
            "Epoch 438/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3550 - acc: 0.9421 - val_loss: 0.5013 - val_acc: 0.8962\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.90180\n",
            "Epoch 439/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3574 - acc: 0.9402 - val_loss: 0.4855 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00439: val_acc improved from 0.90180 to 0.90210, saving model to /content/saved_models/cifar10_ResNet32v1_model.439.h5\n",
            "Epoch 440/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3492 - acc: 0.9411 - val_loss: 0.5199 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.90210\n",
            "Epoch 441/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3540 - acc: 0.9396 - val_loss: 0.4855 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00441: val_acc improved from 0.90210 to 0.90280, saving model to /content/saved_models/cifar10_ResNet32v1_model.441.h5\n",
            "Epoch 442/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3511 - acc: 0.9398 - val_loss: 0.4862 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.90280\n",
            "Epoch 443/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3532 - acc: 0.9419 - val_loss: 0.4859 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.90280\n",
            "Epoch 444/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3552 - acc: 0.9419 - val_loss: 0.4746 - val_acc: 0.9015\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.90280\n",
            "Epoch 445/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3455 - acc: 0.9438 - val_loss: 0.4889 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.90280\n",
            "Epoch 446/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3478 - acc: 0.9424 - val_loss: 0.5055 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.90280\n",
            "Epoch 447/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3473 - acc: 0.9446 - val_loss: 0.4846 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.90280\n",
            "Epoch 448/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3468 - acc: 0.9423 - val_loss: 0.4749 - val_acc: 0.9002\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.90280\n",
            "Epoch 449/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3461 - acc: 0.9453 - val_loss: 0.4669 - val_acc: 0.9046\n",
            "\n",
            "Epoch 00449: val_acc improved from 0.90280 to 0.90460, saving model to /content/saved_models/cifar10_ResNet32v1_model.449.h5\n",
            "Epoch 450/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3480 - acc: 0.9421 - val_loss: 0.4896 - val_acc: 0.9004\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.90460\n",
            "Epoch 451/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3389 - acc: 0.9446 - val_loss: 0.4819 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.90460\n",
            "Epoch 452/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3381 - acc: 0.9483 - val_loss: 0.4716 - val_acc: 0.9036\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.90460\n",
            "Epoch 453/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3397 - acc: 0.9455 - val_loss: 0.4902 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.90460\n",
            "Epoch 454/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3404 - acc: 0.9430 - val_loss: 0.4815 - val_acc: 0.9016\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.90460\n",
            "Epoch 455/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3374 - acc: 0.9462 - val_loss: 0.4744 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.90460\n",
            "Epoch 456/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3369 - acc: 0.9434 - val_loss: 0.4840 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.90460\n",
            "Epoch 457/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3337 - acc: 0.9475 - val_loss: 0.4743 - val_acc: 0.9043\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.90460\n",
            "Epoch 458/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3324 - acc: 0.9468 - val_loss: 0.4762 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.90460\n",
            "Epoch 459/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3356 - acc: 0.9467 - val_loss: 0.4856 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.90460\n",
            "Epoch 460/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3309 - acc: 0.9478 - val_loss: 0.4765 - val_acc: 0.9043\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.90460\n",
            "Epoch 461/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3292 - acc: 0.9486 - val_loss: 0.4726 - val_acc: 0.9073\n",
            "\n",
            "Epoch 00461: val_acc improved from 0.90460 to 0.90730, saving model to /content/saved_models/cifar10_ResNet32v1_model.461.h5\n",
            "Epoch 462/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3402 - acc: 0.9450 - val_loss: 0.4898 - val_acc: 0.9007\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.90730\n",
            "Epoch 463/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3306 - acc: 0.9487 - val_loss: 0.4986 - val_acc: 0.8970\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.90730\n",
            "Epoch 464/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3328 - acc: 0.9465 - val_loss: 0.4918 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.90730\n",
            "Epoch 465/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3249 - acc: 0.9501 - val_loss: 0.4927 - val_acc: 0.9010\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.90730\n",
            "Epoch 466/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3277 - acc: 0.9474 - val_loss: 0.4789 - val_acc: 0.9039\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.90730\n",
            "Epoch 467/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3149 - acc: 0.9530 - val_loss: 0.4739 - val_acc: 0.9043\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.90730\n",
            "Epoch 468/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3245 - acc: 0.9505 - val_loss: 0.4735 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.90730\n",
            "Epoch 469/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3286 - acc: 0.9500 - val_loss: 0.4839 - val_acc: 0.9014\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.90730\n",
            "Epoch 470/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3278 - acc: 0.9475 - val_loss: 0.4846 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.90730\n",
            "Epoch 471/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3209 - acc: 0.9517 - val_loss: 0.4918 - val_acc: 0.9036\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.90730\n",
            "Epoch 472/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3247 - acc: 0.9512 - val_loss: 0.4815 - val_acc: 0.9032\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.90730\n",
            "Epoch 473/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3224 - acc: 0.9504 - val_loss: 0.4718 - val_acc: 0.9042\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.90730\n",
            "Epoch 474/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3227 - acc: 0.9534 - val_loss: 0.4635 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00474: val_acc improved from 0.90730 to 0.90820, saving model to /content/saved_models/cifar10_ResNet32v1_model.474.h5\n",
            "Epoch 475/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3185 - acc: 0.9548 - val_loss: 0.4950 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.90820\n",
            "Epoch 476/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3148 - acc: 0.9535 - val_loss: 0.4651 - val_acc: 0.9070\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.90820\n",
            "Epoch 477/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3188 - acc: 0.9520 - val_loss: 0.4964 - val_acc: 0.9003\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.90820\n",
            "Epoch 478/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3103 - acc: 0.9565 - val_loss: 0.4887 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.90820\n",
            "Epoch 479/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3156 - acc: 0.9539 - val_loss: 0.4718 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.90820\n",
            "Epoch 480/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3205 - acc: 0.9519 - val_loss: 0.4732 - val_acc: 0.9047\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.90820\n",
            "Epoch 481/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3301 - acc: 0.9455 - val_loss: 0.4832 - val_acc: 0.9020\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.90820\n",
            "Epoch 482/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3142 - acc: 0.9543 - val_loss: 0.4790 - val_acc: 0.9030\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.90820\n",
            "Epoch 483/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3198 - acc: 0.9501 - val_loss: 0.4729 - val_acc: 0.9059\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.90820\n",
            "Epoch 484/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3125 - acc: 0.9536 - val_loss: 0.4701 - val_acc: 0.9038\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.90820\n",
            "Epoch 485/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3108 - acc: 0.9533 - val_loss: 0.4952 - val_acc: 0.8982\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.90820\n",
            "Epoch 486/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3147 - acc: 0.9534 - val_loss: 0.4660 - val_acc: 0.9063\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.90820\n",
            "Epoch 487/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3035 - acc: 0.9600 - val_loss: 0.4906 - val_acc: 0.9032\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.90820\n",
            "Epoch 488/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3060 - acc: 0.9566 - val_loss: 0.5132 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.90820\n",
            "Epoch 489/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3217 - acc: 0.9523 - val_loss: 0.4873 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.90820\n",
            "Epoch 490/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.3106 - acc: 0.9549 - val_loss: 0.4717 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.90820\n",
            "Epoch 491/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3093 - acc: 0.9550 - val_loss: 0.4917 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.90820\n",
            "Epoch 492/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3144 - acc: 0.9535 - val_loss: 0.4973 - val_acc: 0.9005\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.90820\n",
            "Epoch 493/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3081 - acc: 0.9556 - val_loss: 0.4756 - val_acc: 0.9059\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.90820\n",
            "Epoch 494/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3108 - acc: 0.9552 - val_loss: 0.4812 - val_acc: 0.9051\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.90820\n",
            "Epoch 495/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3144 - acc: 0.9522 - val_loss: 0.4882 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.90820\n",
            "Epoch 496/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3089 - acc: 0.9573 - val_loss: 0.4821 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.90820\n",
            "Epoch 497/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.3044 - acc: 0.9540 - val_loss: 0.5028 - val_acc: 0.8977\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.90820\n",
            "Epoch 498/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3065 - acc: 0.9579 - val_loss: 0.4858 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.90820\n",
            "Epoch 499/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3054 - acc: 0.9557 - val_loss: 0.4957 - val_acc: 0.9016\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.90820\n",
            "Epoch 500/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3136 - acc: 0.9539 - val_loss: 0.4799 - val_acc: 0.9034\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.90820\n",
            "Epoch 501/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3121 - acc: 0.9532 - val_loss: 0.4745 - val_acc: 0.9085\n",
            "\n",
            "Epoch 00501: val_acc improved from 0.90820 to 0.90850, saving model to /content/saved_models/cifar10_ResNet32v1_model.501.h5\n",
            "Epoch 502/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3041 - acc: 0.9584 - val_loss: 0.4641 - val_acc: 0.9075\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.90850\n",
            "Epoch 503/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3054 - acc: 0.9570 - val_loss: 0.4744 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.90850\n",
            "Epoch 504/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2959 - acc: 0.9616 - val_loss: 0.4791 - val_acc: 0.9060\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.90850\n",
            "Epoch 505/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3063 - acc: 0.9567 - val_loss: 0.4926 - val_acc: 0.9014\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.90850\n",
            "Epoch 506/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3063 - acc: 0.9566 - val_loss: 0.4802 - val_acc: 0.9038\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.90850\n",
            "Epoch 507/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2966 - acc: 0.9592 - val_loss: 0.4711 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.90850\n",
            "Epoch 508/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.2981 - acc: 0.9581 - val_loss: 0.5068 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.90850\n",
            "Epoch 509/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.2895 - acc: 0.9628 - val_loss: 0.4717 - val_acc: 0.9071\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.90850\n",
            "Epoch 510/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3037 - acc: 0.9570 - val_loss: 0.5612 - val_acc: 0.8860\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.90850\n",
            "Epoch 511/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2952 - acc: 0.9591 - val_loss: 0.4872 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.90850\n",
            "Epoch 512/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2999 - acc: 0.9570 - val_loss: 0.5121 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.90850\n",
            "Epoch 513/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2973 - acc: 0.9589 - val_loss: 0.4858 - val_acc: 0.9038\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.90850\n",
            "Epoch 514/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.3050 - acc: 0.9557 - val_loss: 0.5093 - val_acc: 0.8957\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.90850\n",
            "Epoch 515/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.2973 - acc: 0.9586 - val_loss: 0.4984 - val_acc: 0.9020\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.90850\n",
            "Epoch 516/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.3081 - acc: 0.9549 - val_loss: 0.5082 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.90850\n",
            "Epoch 517/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2965 - acc: 0.9600 - val_loss: 0.4885 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.90850\n",
            "Epoch 518/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 0.2959 - acc: 0.9600 - val_loss: 0.5125 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.90850\n",
            "Epoch 519/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2960 - acc: 0.9599 - val_loss: 0.4815 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.90850\n",
            "Epoch 520/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2889 - acc: 0.9605 - val_loss: 0.5008 - val_acc: 0.9016\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.90850\n",
            "Epoch 521/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2965 - acc: 0.9553 - val_loss: 0.4841 - val_acc: 0.9015\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.90850\n",
            "Epoch 522/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2917 - acc: 0.9606 - val_loss: 0.5006 - val_acc: 0.9012\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.90850\n",
            "Epoch 523/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2903 - acc: 0.9626 - val_loss: 0.5022 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.90850\n",
            "Epoch 524/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2985 - acc: 0.9589 - val_loss: 0.4762 - val_acc: 0.9056\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.90850\n",
            "Epoch 525/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2925 - acc: 0.9596 - val_loss: 0.4911 - val_acc: 0.9012\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.90850\n",
            "Epoch 526/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2839 - acc: 0.9636 - val_loss: 0.4877 - val_acc: 0.9052\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.90850\n",
            "Epoch 527/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2976 - acc: 0.9588 - val_loss: 0.4838 - val_acc: 0.9042\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.90850\n",
            "Epoch 528/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2910 - acc: 0.9595 - val_loss: 0.4841 - val_acc: 0.9078\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.90850\n",
            "Epoch 529/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2965 - acc: 0.9589 - val_loss: 0.4963 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.90850\n",
            "Epoch 530/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2909 - acc: 0.9614 - val_loss: 0.5228 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.90850\n",
            "Epoch 531/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2974 - acc: 0.9594 - val_loss: 0.5006 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.90850\n",
            "Epoch 532/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2861 - acc: 0.9613 - val_loss: 0.4759 - val_acc: 0.9075\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.90850\n",
            "Epoch 533/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2943 - acc: 0.9608 - val_loss: 0.5062 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.90850\n",
            "Epoch 534/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2894 - acc: 0.9618 - val_loss: 0.4887 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.90850\n",
            "Epoch 535/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2952 - acc: 0.9591 - val_loss: 0.5357 - val_acc: 0.8987\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.90850\n",
            "Epoch 536/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2950 - acc: 0.9602 - val_loss: 0.4878 - val_acc: 0.9051\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.90850\n",
            "Epoch 537/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2858 - acc: 0.9625 - val_loss: 0.4707 - val_acc: 0.9079\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.90850\n",
            "Epoch 538/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2883 - acc: 0.9640 - val_loss: 0.5082 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.90850\n",
            "Epoch 539/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2906 - acc: 0.9619 - val_loss: 0.4792 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00539: val_acc improved from 0.90850 to 0.90980, saving model to /content/saved_models/cifar10_ResNet32v1_model.539.h5\n",
            "Epoch 540/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2886 - acc: 0.9626 - val_loss: 0.4839 - val_acc: 0.9037\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.90980\n",
            "Epoch 541/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2894 - acc: 0.9623 - val_loss: 0.5114 - val_acc: 0.9016\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.90980\n",
            "Epoch 542/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2869 - acc: 0.9627 - val_loss: 0.4924 - val_acc: 0.9020\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.90980\n",
            "Epoch 543/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2870 - acc: 0.9616 - val_loss: 0.4960 - val_acc: 0.9018\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.90980\n",
            "Epoch 544/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.2904 - acc: 0.9620 - val_loss: 0.4928 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.90980\n",
            "Epoch 545/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2853 - acc: 0.9628 - val_loss: 0.5102 - val_acc: 0.9002\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.90980\n",
            "Epoch 546/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2799 - acc: 0.9634 - val_loss: 0.5078 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.90980\n",
            "Epoch 547/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2906 - acc: 0.9633 - val_loss: 0.4980 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.90980\n",
            "Epoch 548/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2847 - acc: 0.9632 - val_loss: 0.4851 - val_acc: 0.9043\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.90980\n",
            "Epoch 549/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2833 - acc: 0.9646 - val_loss: 0.4964 - val_acc: 0.9051\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.90980\n",
            "Epoch 550/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2864 - acc: 0.9624 - val_loss: 0.5040 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.90980\n",
            "Epoch 551/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2882 - acc: 0.9618 - val_loss: 0.4873 - val_acc: 0.9073\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.90980\n",
            "Epoch 552/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2863 - acc: 0.9612 - val_loss: 0.5022 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.90980\n",
            "Epoch 553/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2857 - acc: 0.9616 - val_loss: 0.4820 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.90980\n",
            "Epoch 554/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2897 - acc: 0.9608 - val_loss: 0.5372 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.90980\n",
            "Epoch 555/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2835 - acc: 0.9637 - val_loss: 0.5119 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.90980\n",
            "Epoch 556/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2790 - acc: 0.9656 - val_loss: 0.4789 - val_acc: 0.9070\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.90980\n",
            "Epoch 557/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2845 - acc: 0.9633 - val_loss: 0.5036 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.90980\n",
            "Epoch 558/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.2826 - acc: 0.9633 - val_loss: 0.4940 - val_acc: 0.9032\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.90980\n",
            "Epoch 559/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2749 - acc: 0.9673 - val_loss: 0.4921 - val_acc: 0.9080\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.90980\n",
            "Epoch 560/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2752 - acc: 0.9654 - val_loss: 0.5016 - val_acc: 0.9053\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.90980\n",
            "Epoch 561/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.2815 - acc: 0.9631 - val_loss: 0.5004 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.90980\n",
            "Epoch 562/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2791 - acc: 0.9663 - val_loss: 0.4752 - val_acc: 0.9079\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.90980\n",
            "Epoch 563/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2821 - acc: 0.9623 - val_loss: 0.4873 - val_acc: 0.9041\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.90980\n",
            "Epoch 564/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2806 - acc: 0.9643 - val_loss: 0.4835 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.90980\n",
            "Epoch 565/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2803 - acc: 0.9660 - val_loss: 0.4909 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.90980\n",
            "Epoch 566/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2846 - acc: 0.9631 - val_loss: 0.4919 - val_acc: 0.9071\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.90980\n",
            "Epoch 567/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2734 - acc: 0.9658 - val_loss: 0.5014 - val_acc: 0.9058\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.90980\n",
            "Epoch 568/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.2761 - acc: 0.9640 - val_loss: 0.4937 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.90980\n",
            "Epoch 569/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2811 - acc: 0.9632 - val_loss: 0.4787 - val_acc: 0.9090\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.90980\n",
            "Epoch 570/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2806 - acc: 0.9652 - val_loss: 0.4861 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00570: val_acc improved from 0.90980 to 0.91000, saving model to /content/saved_models/cifar10_ResNet32v1_model.570.h5\n",
            "Epoch 571/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2768 - acc: 0.9667 - val_loss: 0.5167 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.91000\n",
            "Epoch 572/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2767 - acc: 0.9650 - val_loss: 0.4984 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.91000\n",
            "Epoch 573/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2771 - acc: 0.9670 - val_loss: 0.5108 - val_acc: 0.9022\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.91000\n",
            "Epoch 574/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2723 - acc: 0.9674 - val_loss: 0.5010 - val_acc: 0.9083\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.91000\n",
            "Epoch 575/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.2692 - acc: 0.9695 - val_loss: 0.4858 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00575: val_acc improved from 0.91000 to 0.91160, saving model to /content/saved_models/cifar10_ResNet32v1_model.575.h5\n",
            "Epoch 576/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2775 - acc: 0.9669 - val_loss: 0.4867 - val_acc: 0.9083\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.91160\n",
            "Epoch 577/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2791 - acc: 0.9652 - val_loss: 0.4966 - val_acc: 0.9053\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.91160\n",
            "Epoch 578/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2781 - acc: 0.9639 - val_loss: 0.5108 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.91160\n",
            "Epoch 579/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.2668 - acc: 0.9702 - val_loss: 0.4841 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.91160\n",
            "Epoch 580/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2715 - acc: 0.9663 - val_loss: 0.4912 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.91160\n",
            "Epoch 581/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2775 - acc: 0.9642 - val_loss: 0.4827 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.91160\n",
            "Epoch 582/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2770 - acc: 0.9674 - val_loss: 0.4869 - val_acc: 0.9050\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.91160\n",
            "Epoch 583/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.2685 - acc: 0.9684 - val_loss: 0.5106 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.91160\n",
            "Epoch 584/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2680 - acc: 0.9702 - val_loss: 0.4905 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.91160\n",
            "Epoch 585/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2767 - acc: 0.9651 - val_loss: 0.5236 - val_acc: 0.9016\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.91160\n",
            "Epoch 586/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2708 - acc: 0.9662 - val_loss: 0.4862 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.91160\n",
            "Epoch 587/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2725 - acc: 0.9692 - val_loss: 0.4923 - val_acc: 0.9084\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.91160\n",
            "Epoch 588/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2712 - acc: 0.9692 - val_loss: 0.4885 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.91160\n",
            "Epoch 589/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2733 - acc: 0.9678 - val_loss: 0.4980 - val_acc: 0.9037\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.91160\n",
            "Epoch 590/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2647 - acc: 0.9701 - val_loss: 0.5131 - val_acc: 0.9002\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.91160\n",
            "Epoch 591/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2655 - acc: 0.9704 - val_loss: 0.5035 - val_acc: 0.9094\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.91160\n",
            "Epoch 592/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2720 - acc: 0.9682 - val_loss: 0.4939 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.91160\n",
            "Epoch 593/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2638 - acc: 0.9688 - val_loss: 0.5085 - val_acc: 0.9043\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.91160\n",
            "Epoch 594/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.2709 - acc: 0.9668 - val_loss: 0.5108 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.91160\n",
            "Epoch 595/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2688 - acc: 0.9675 - val_loss: 0.4861 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00595: val_acc improved from 0.91160 to 0.91330, saving model to /content/saved_models/cifar10_ResNet32v1_model.595.h5\n",
            "Epoch 596/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2770 - acc: 0.9642 - val_loss: 0.4963 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.91330\n",
            "Epoch 597/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.2745 - acc: 0.9661 - val_loss: 0.4869 - val_acc: 0.9080\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.91330\n",
            "Epoch 598/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2706 - acc: 0.9670 - val_loss: 0.5339 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.91330\n",
            "Epoch 599/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2733 - acc: 0.9665 - val_loss: 0.5009 - val_acc: 0.9074\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.91330\n",
            "Epoch 600/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2716 - acc: 0.9674 - val_loss: 0.4982 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.91330\n",
            "Epoch 601/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.2652 - acc: 0.9684 - val_loss: 0.4843 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.91330\n",
            "Epoch 602/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2673 - acc: 0.9689 - val_loss: 0.4770 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00602: val_acc did not improve from 0.91330\n",
            "Epoch 603/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2586 - acc: 0.9712 - val_loss: 0.4763 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00603: val_acc did not improve from 0.91330\n",
            "Epoch 604/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2694 - acc: 0.9673 - val_loss: 0.4751 - val_acc: 0.9123\n",
            "\n",
            "Epoch 00604: val_acc did not improve from 0.91330\n",
            "Epoch 605/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.2754 - acc: 0.9650 - val_loss: 0.4743 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00605: val_acc did not improve from 0.91330\n",
            "Epoch 606/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2676 - acc: 0.9678 - val_loss: 0.4746 - val_acc: 0.9114\n",
            "\n",
            "Epoch 00606: val_acc did not improve from 0.91330\n",
            "Epoch 607/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2671 - acc: 0.9683 - val_loss: 0.4738 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00607: val_acc did not improve from 0.91330\n",
            "Epoch 608/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2591 - acc: 0.9717 - val_loss: 0.4734 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00608: val_acc did not improve from 0.91330\n",
            "Epoch 609/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.2576 - acc: 0.9711 - val_loss: 0.4725 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00609: val_acc did not improve from 0.91330\n",
            "Epoch 610/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2712 - acc: 0.9651 - val_loss: 0.4720 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00610: val_acc did not improve from 0.91330\n",
            "Epoch 611/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2636 - acc: 0.9706 - val_loss: 0.4721 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.91330\n",
            "Epoch 612/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2577 - acc: 0.9705 - val_loss: 0.4710 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00612: val_acc did not improve from 0.91330\n",
            "Epoch 613/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2600 - acc: 0.9692 - val_loss: 0.4700 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00613: val_acc did not improve from 0.91330\n",
            "Epoch 614/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2624 - acc: 0.9703 - val_loss: 0.4700 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.91330\n",
            "Epoch 615/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2623 - acc: 0.9710 - val_loss: 0.4696 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.91330\n",
            "Epoch 616/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2648 - acc: 0.9706 - val_loss: 0.4694 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00616: val_acc improved from 0.91330 to 0.91350, saving model to /content/saved_models/cifar10_ResNet32v1_model.616.h5\n",
            "Epoch 617/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.2579 - acc: 0.9735 - val_loss: 0.4686 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.91350\n",
            "Epoch 618/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2589 - acc: 0.9717 - val_loss: 0.4682 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00618: val_acc improved from 0.91350 to 0.91360, saving model to /content/saved_models/cifar10_ResNet32v1_model.618.h5\n",
            "Epoch 619/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2632 - acc: 0.9715 - val_loss: 0.4684 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00619: val_acc did not improve from 0.91360\n",
            "Epoch 620/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2604 - acc: 0.9740 - val_loss: 0.4676 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.91360\n",
            "Epoch 621/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2655 - acc: 0.9707 - val_loss: 0.4677 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00621: val_acc improved from 0.91360 to 0.91450, saving model to /content/saved_models/cifar10_ResNet32v1_model.621.h5\n",
            "Epoch 622/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2642 - acc: 0.9682 - val_loss: 0.4671 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.91450\n",
            "Epoch 623/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.2560 - acc: 0.9729 - val_loss: 0.4673 - val_acc: 0.9141\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.91450\n",
            "Epoch 624/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2595 - acc: 0.9705 - val_loss: 0.4661 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.91450\n",
            "Epoch 625/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2625 - acc: 0.9709 - val_loss: 0.4659 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.91450\n",
            "Epoch 626/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2606 - acc: 0.9717 - val_loss: 0.4658 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.91450\n",
            "Epoch 627/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2552 - acc: 0.9745 - val_loss: 0.4650 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00627: val_acc improved from 0.91450 to 0.91470, saving model to /content/saved_models/cifar10_ResNet32v1_model.627.h5\n",
            "Epoch 628/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.2564 - acc: 0.9746 - val_loss: 0.4671 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00628: val_acc did not improve from 0.91470\n",
            "Epoch 629/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2606 - acc: 0.9727 - val_loss: 0.4661 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.91470\n",
            "Epoch 630/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2575 - acc: 0.9715 - val_loss: 0.4654 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00630: val_acc improved from 0.91470 to 0.91510, saving model to /content/saved_models/cifar10_ResNet32v1_model.630.h5\n",
            "Epoch 631/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2584 - acc: 0.9728 - val_loss: 0.4649 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00631: val_acc improved from 0.91510 to 0.91560, saving model to /content/saved_models/cifar10_ResNet32v1_model.631.h5\n",
            "Epoch 632/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.2522 - acc: 0.9740 - val_loss: 0.4651 - val_acc: 0.9150\n",
            "\n",
            "Epoch 00632: val_acc did not improve from 0.91560\n",
            "Epoch 633/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2568 - acc: 0.9743 - val_loss: 0.4656 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.91560\n",
            "Epoch 634/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2575 - acc: 0.9722 - val_loss: 0.4644 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.91560\n",
            "Epoch 635/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2595 - acc: 0.9707 - val_loss: 0.4648 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.91560\n",
            "Epoch 636/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.2587 - acc: 0.9721 - val_loss: 0.4658 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.91560\n",
            "Epoch 637/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2605 - acc: 0.9715 - val_loss: 0.4657 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00637: val_acc improved from 0.91560 to 0.91570, saving model to /content/saved_models/cifar10_ResNet32v1_model.637.h5\n",
            "Epoch 638/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.2586 - acc: 0.9717 - val_loss: 0.4644 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.91570\n",
            "Epoch 639/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2615 - acc: 0.9707 - val_loss: 0.4640 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.91570\n",
            "Epoch 640/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.2571 - acc: 0.9727 - val_loss: 0.4635 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.91570\n",
            "Epoch 641/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2590 - acc: 0.9729 - val_loss: 0.4639 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.91570\n",
            "Epoch 642/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2584 - acc: 0.9712 - val_loss: 0.4637 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.91570\n",
            "Epoch 643/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2521 - acc: 0.9754 - val_loss: 0.4634 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.91570\n",
            "Epoch 644/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.2557 - acc: 0.9732 - val_loss: 0.4634 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.91570\n",
            "Epoch 645/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.2538 - acc: 0.9751 - val_loss: 0.4636 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00645: val_acc did not improve from 0.91570\n",
            "Epoch 646/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2541 - acc: 0.9732 - val_loss: 0.4629 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00646: val_acc improved from 0.91570 to 0.91620, saving model to /content/saved_models/cifar10_ResNet32v1_model.646.h5\n",
            "Epoch 647/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2565 - acc: 0.9716 - val_loss: 0.4632 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00647: val_acc did not improve from 0.91620\n",
            "Epoch 648/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.2515 - acc: 0.9761 - val_loss: 0.4635 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.91620\n",
            "Epoch 649/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2580 - acc: 0.9729 - val_loss: 0.4635 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.91620\n",
            "Epoch 650/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2492 - acc: 0.9770 - val_loss: 0.4626 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00650: val_acc did not improve from 0.91620\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "qZj-CrLz2cbE",
        "outputId": "f2d8a600-db6a-4a99-8c56-76bf23b9d73a"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('trainHistoryDict_clip_1', \"rb\"))\n",
        "functions.plot_loss_acc(history, 4, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAAGDCAYAAAAh/naNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhkV3kn/u9bi1SltbulbvXutmnvNrZx4yV2oIEw8RLb+YXFJpCE/AhO8oMBEkjGJASIf8wMmRBCGCCO2Rcb8INjMKQdgwfLC3hr2227N/fmbrd6ldStXSWVVGf+OPfUPXXr3lqkKlXdru/nefpRqerWrVMCn3rrve95jyilQERERETUaCK1HgARERERUS0wECYiIiKihsRAmIiIiIgaEgNhIiIiImpIDISJiIiIqCExECYiIiKihsRAmIiIiIgaEgNhCgUR2S8iv1XrcRARUWHOfD0pImPWvy/VelxEfmK1HgARERGdcm5QSj1U6AARiSmlZjz3RZVSs6W+SLnHE3kxI0yhJSLNIvIFETns/PuCiDQ7j3WLyM9EZEhETojIYyIScR77byJySERGReRlEXlLbd8JEdGpT0TeKyK/EpF/FpFBAJ8WkW+JyL+KyCYRGQfwJhE5V0R6nfl7m4jcaJ0j7/iavSE6JTAjTGH2twCuAHAxAAXgJwA+AeDvAHwUQB+Apc6xVwBQInI2gA8CeL1S6rCIrAMQXdhhExE1rMsB/ABAD4A4gH8F8PsArgPwOwBaATwP4BsA/guAqwH8REQ2KKVeds5hH9+0oKOnUw4zwhRm7wZwu1LquFKqH8DfA/gD57E0gBUATlNKpZVSjymlFIBZAM0AzhORuFJqv1Jqb01GT0R06vqxk9E1/97v3H9YKfW/lVIzSqlJ576fKKV+pZTKQCc22gB8Vik1rZT6JYCfAXiXde7s8Uqp1MK9JToVMRCmMFsJ4ID1+wHnPgD4RwB7APxcRPaJyG0AoJTaA+AjAD4N4LiI/EBEVoKIiCrpd5VSi6x/X3XuP+hzrH3fSgAHnaDYOABgVcDxRPPCQJjC7DCA06zf1zr3QSk1qpT6qFLqDAA3AvhLUwuslLpbKXW181wF4B8WdthERA1LFbnvMIA1Zk2HYy2AQ0XOQTQnDIQpTOIikjD/AHwfwCdEZKmIdAP4JIDvAYCI/I6IrBcRATAMXRKREZGzReTNzqK6FIBJABn/lyMiogX2FIAJAH8tInER2QjgBui6YqKKYyBMYbIJOnA1/xIANgN4EcBLAJ4D8Bnn2DMBPARgDMATAL6ilHoYuj74swAGABwFsAzAxxfuLRARNYSfevoI31fKk5RS09CB77XQ8/RXAPyhUmpnFcdKDUz0+iEiIiIiosbCjDARERERNaSSA2ERiYrI8yLyM5/HmkXkhyKyR0SecnqzEhFRDYjIN0TkuIhsDXhcROSLzpz9ooi8bqHHSERUD8rJCH8YwI6Ax94H4KRSaj2AfwZX4RMR1dK3AFxT4PFroevozwRwK/SmBkREDaekQFhEVgO4HsDXAg65CcC3nds/AvAWZ7U+EREtMKXUowBOFDjkJgDfUdqTABaJyIqFGR0RUf0oNSP8BQB/jeA2U6vgNLhWSs1At6vqmvfoiIioGrJztqMPuRsWEBE1hFixA0TkdwAcV0o96/TzmzMRuRX6MhySyeSla9asKfscmUwGkUg41vhxrNXBsVZHWMZaL+PctWvXgFJqaa3HUU2cs+sXx1odHGt11MNYA+dspVTBfwD+J3S2YD9039UJAN/zHPMggCud2zHo3n9S6LyXXnqpmouHH354Ts+rBY61OjjW6gjLWOtlnAA2qyLzZy3/AVgHYGvAY/8G4F3W7y8DWFHofJyz6wvHWh0ca3XUw1iD5uyi4blS6uNKqdVKqXUAbgHwS6XUezyH3Q/gj5zbb3eOYYNiIqL6dD+AP3S6R1wBYFgpdaTWgyIiWmhFSyOCiMjt0NH1/QC+DuC7IrIHeoHGLRUaHxERlUlEvg9gI4BuEekD8CkAcQBQSt0BvUvjdQD2QF/l++PajJSIqLbKCoSVUr0Aep3bn7TuTwF4RyUHRkREc6OUeleRxxWADyzQcIiI6tacM8JE1LjS6TT6+vqQSqUW/LU7OzuxY0dQS/PKSyQSWL16NeLx+IK9JhFRJdVyzgYWdt4ud85mIExEZevr60N7ezvWrVuHhW4ZPjo6ivb29gV5LaUUBgcH0dfXh9NPP31BXpOIqNJqOWcDCzdvz2XODkffDSKqK6lUCl1dXTWZUBeSiKCrq6tmWRQiokrgnB2MgTARzcmpPqEajfI+iejU1ihzWbnvk4EwEYXO0NAQvvKVr5T9vOuuuw5DQ0NVGBERERVSr/M2A2EiCp2gCXVmZqbg8zZt2oRFixZVa1hERBSgXudtLpYjotC57bbbsHfvXlx88cWIx+NIJBJYvHgxdu7ciV27duF3f/d3cfDgQaRSKXz4wx/GrbfeCgBYt24dNm/ejLGxMVx77bW4+uqr8etf/xqrVq3CT37yEySTyRq/MyKiU1O9ztsMhIloXv7+p9uw/fBIRc953soOfOqG8wMf/+xnP4utW7diy5Yt6O3txfXXX4+tW7dmVwl/4xvfwJIlSzA5OYnXv/71eNvb3oaurq6cc+zevRvf//738dWvfhXvfOc7ce+99+I97/FumklEdGqpxZwN1O+8zUCYiELvsssuy2mV88UvfhH33XcfAODgwYPYvXt33oR6+umn4+KLLwYAXHrppdi/f/+CjZeIqNHVy7zNQJiI5qVYFmAhtLa2Zm/39vbioYcewhNPPIGWlhZs3LjRt5VOc3Nz9nY0GsXk5OSCjJWIqJbqYc4G6mfe5mI5Igqd9vZ2jI6O+j42PDyMxYsXo6WlBTt37sSTTz65wKMjIiKvep23mREmotDp6urCVVddhQsuuADJZBI9PT3Zx6655hrccccdOPfcc3H22WfjiiuuqOFIiYgIqN95m4EwEYXS3Xff7Xt/c3MzHnjgAd/HTD1Zd3c3tm7dmr3/Yx/7WMXHR0REuepx3mZpBBERERE1JAbCRERERNSQGAgTERERUUNiIExEREREDYmBMBERERE1JAbCRERERNSQGAgT0Smvra2t1kMgIqIyLNS8zUCYiIiIiBoSN9QgotC57bbbsGbNGnzgAx8AAHz6059GLBbDww8/jJMnTyKdTuMzn/kMbrrpphqPlIiIgPqdtxkIE9H8PHAbcPSlyp5z+YXAtZ8NfPjmm2/GRz7ykeyEes899+DBBx/Ehz70IXR0dGBgYABXXHEFbrzxRohIZcdGRBRmNZizgfqdtxkIE1HoXHLJJTh+/DgOHz6M/v5+LF68GMuXL8df/MVf4NFHH0UkEsGhQ4dw7NgxLF++vNbDJSJqePU6bzMQJqL5KZIFqJZ3vOMd+NGPfoSjR4/i5ptvxl133YX+/n48++yziMfjWLduHVKpVE3GRkRUt2o0ZwP1OW8zECaiULr55pvx/ve/HwMDA3jkkUdwzz33YNmyZYjH43j44Ydx4MCBWg+RiIgs9ThvMxAmolA6//zzMTo6ilWrVmHFihV497vfjRtuuAEXXnghNmzYgHPOOafWQyQiIks9ztsMhIkotF56yV3w0d3djSeeeML3uLGxsYUaEhERFVBv8zb7CBMRERFRQ2IgTEREREQNiYEwERERETUkBsJENCdKqVoPYUE0yvskolNbo8xl5b7PooGwiCRE5GkReUFEtonI3/sc814R6ReRLc6/PylrFEQUKolEAoODg6f8xKqUwuDgIBKJRK2HQkQ0Z5yzg5XSNWIKwJuVUmMiEgfwuIg8oJR60nPcD5VSHyxjvEQUUqtXr0ZfXx/6+/sX/LVTqdSCBqaJRAKrV69esNcjIqq0Ws7ZwMLO2+XO2UUDYaW/PpgeFnHn36n9lYKICorH4zj99NNr8tq9vb245JJLavLaRERhVMs5G6jvebukPsIiEgXwLID1AL6slHrK57C3icgbAOwC8BdKqYM+57kVwK0A0NPTg97e3rIHPDY2Nqfn1QLHWh0ca3WEZaxhGScREdW/kgJhpdQsgItFZBGA+0TkAqXUVuuQnwL4vlJqSkT+FMC3AbzZ5zx3ArgTADZs2KA2btxY9oB7e3sxl+fVAsdaHRxrdYRlrGEZJxER1b+yukYopYYAPAzgGs/9g0qpKefXrwG4tDLDIyIiIiKqjlK6Rix1MsEQkSSAtwLY6TlmhfXrjQB2VHKQRERERESVVkppxAoA33bqhCMA7lFK/UxEbgewWSl1P4APiciNAGYAnADw3moNmIiIiIioEkrpGvEigLylfkqpT1q3Pw7g45UdGhERERFR9XBnOSIiIiJqSAyEiYiIiKghMRAmIiIioobEQJiIiIiIGhIDYSIiIiJqSAyEiYiIiKghMRAmIiIioobEQJiIiIiIGhIDYSIiIiJqSAyEiYiIiKghMRAmIiIioobEQJiIiIiIGhIDYSIiIiJqSAyEiYiIiKghMRAmIiIioobEQJiI6BQjIteIyMsiskdEbvN5fK2IPCwiz4vIiyJyXS3GSURUawyEiYhOISISBfBlANcCOA/Au0TkPM9hnwBwj1LqEgC3APhKVQaz9V5c+OLtQGa2KqcnIpovBsJERKeWywDsUUrtU0pNA/gBgJs8xygAHc7tTgCHqzKSk/vRdeJZYDZdldMTEc1XrNYDICKiiloF4KD1ex+Ayz3HfBrAz0XkvwJoBfBbVRlJxPmIycxU5fRERPPFQJiIqPG8C8C3lFL/JCJXAviuiFyglMrYB4nIrQBuBYCenh709vaW9SKrDx7AegCPP9qLmXhbZUZeRWNjY2W/x1rhWKuDY62Oeh4rA2EiolPLIQBrrN9XO/fZ3gfgGgBQSj0hIgkA3QCO2wcppe4EcCcAbNiwQW3cuLG8kTy9G9gLXH3l5UDb0vKeWwO9vb0o+z3WCMdaHRxrddTzWFkjTER0ankGwJkicrqINEEvhrvfc8yrAN4CACJyLoAEgP6Kj4SlEURU5xgIExGdQpRSMwA+COBBADugu0NsE5HbReRG57CPAni/iLwA4PsA3quUUhUfTDYQ5mI5IqpPLI0gIjrFKKU2Adjkue+T1u3tAK6q+kCicf2TXSOIqE4xI0xERNXB0ggiqnMMhImIqDoYCBNRnWMgTERE1cHSCCKqcwyEiYioOiJOIMyMMBHVKQbCRERUHVGWRhBRfWMgTERE1WFqhFkaQUR1ioEwERFVR7Y0goEwEdUnBsJERFQd2cVyLI0govpUNBAWkYSIPC0iL4jINhH5e59jmkXkhyKyR0SeEpF11RgsERGFCNunEVGdKyUjPAXgzUqpiwBcDOAaEbnCc8z7AJxUSq0H8M8A/qGywyQiotDhFstEVOeKBsJKG3N+jTv/vHvS3wTg287tHwF4i4hIxUZJREThwz7CRFTnYqUcJCJRAM8CWA/gy0qppzyHrAJwEACUUjMiMgygC8CA5zy3ArgVAHp6etDb21v2gMfGxub0vFrgWKuDY62OsIw1LOMkWBnh2dqOg4goQEmBsFJqFsDFIrIIwH0icoFSamu5L6aUuhPAnQCwYcMGtXHjxnJPgd7eXszlebXAsVYHx1odYRlrWMZJYGkEEdW9srpGKKWGADwM4BrPQ4cArAEAEYkB6AQwWIkBEhFRSLE0gojqXCldI5Y6mWCISBLAWwHs9Bx2P4A/cm6/HcAvlVLeOmIiImok3GKZiOpcKaURKwB826kTjgC4Ryn1MxG5HcBmpdT9AL4O4LsisgfACQC3VG3EREQUDtximYjqXNFAWCn1IoBLfO7/pHU7BeAdlR0aERGFGrdYJqI6x53liIioOrjFMhHVOQbCRERUHWaxHNunEVGdYiBMRETVIc5HDEsjiKhOMRAmIqLqEEFGYiyNIKK6xUCYiIiqRkmUXSOIqG6FKxD+j4/i3O2fr/UoiIioREpiwCwDYSKqT+EKhIdeRctEX61HQUREJVISYWkEEdWtcAXC0SaI4upjIqKwyERiXCxHRHUrXIFwJAZRvMRGRBQWukaYCQwiqk/hCoSjcUS46IKIKDR0IMyMMBHVp5AFwiyNICIKEyVRlkYQUd0KVyDM0ggiolBREmP7NCKqW+EKhKNNLI0gIgqRTIR9hImofoUsEI4zI0xEFCIsjSCiehauQDgSY40wEVGIcLEcEdWzcAXCLI0gIgoVXSPMBAYR1aeQBcJxCDJAJlPrkRARUQlYGkFE9SxcgXAkpn/yMhsRUSiwNIKI6lm4AuFok/45O13bcRARUUkyEbZPI6L6FbJAOK5/8jIbEVEo6NIIBsJEVJ/CGQgzu0BEFAosjSCiehauQDhiMsIsjSAiCgMuliOiehauQJilEUREocL2aURUz0IWCDuL5VgaQUQUCkoiLI0goroVrkDYtE9jaQQRUShkIjFexSOiuhWuQDjbPo2TKhFRGOjFcryKR0T1KWSBMGuEiYjCRNcIMxAmovoUrkCYO8sREYUKu0YQUT0LVyDM0ggiolBhaQQR1bOQBcIsjSAiCpNMJAaoWUCpWg+FiChPuAJhlkYQEYWKEudjhgkMIqpD4QqEs6URbJ9GRBQGSpjAIKL6VTQQFpE1IvKwiGwXkW0i8mGfYzaKyLCIbHH+fbIqo2VpBBFRqCiJ6husEyaiOhQr4ZgZAB9VSj0nIu0AnhWRXyiltnuOe0wp9TuVH6LFBMKcUImIQiGbEZ7lvE1E9adoRlgpdUQp9ZxzexTADgCrqj0wXxGTEa5gaUQmA+z4KRdyEBFVQbZGmKURRFSHSskIZ4nIOgCXAHjK5+ErReQFAIcBfEwptc3n+bcCuBUAenp60NvbW9Zgm6ZO4DcA7NqxDYdHyntukM6hrbhky9/i2df9L4x2nF2RcxpjY2Nlv8da4Virg2OtvLCMk7RMdpEzM8JEVH9KDoRFpA3AvQA+opQa8Tz8HIDTlFJjInIdgB8DONN7DqXUnQDuBIANGzaojRs3ljfaiRPAE8BZ68/AWZeX+dwgu6aALcClF54LnP6GypzT0dvbi7LfY41wrNXBsVZeWMZJWrZGmGs7iKgOldQ1QkTi0EHwXUqpf/c+rpQaUUqNObc3AYiLSHdFRwq47dMqWRphzsVJmoio4rhYjojqWSldIwTA1wHsUEp9PuCY5c5xEJHLnPMOVnKgAKqzs5w5V2a2cuckIiIA9mI5JhuIqP6UUhpxFYA/APCSiGxx7vsbAGsBQCl1B4C3A/hzEZkBMAngFqWqsPqsGu3TTJaCCzmIiCqOGWEiqmdFA2Gl1OMApMgxXwLwpUoNKlAkCgWBVDJozWaEOUkT0alBRK4B8C8AogC+ppT6rM8x7wTwaQAKwAtKqd+vxlgy3BGUiOpYWV0j6oGSGKSipRGsESaiU4eIRAF8GcBbAfQBeEZE7rd7v4vImQA+DuAqpdRJEVlWrfG4Wywz2UBE9SdcWywDyESiVSqNYI0wEZ0SLgOwRym1Tyk1DeAHAG7yHPN+AF9WSp0EAKXU8WoNxt1imYEwEdWfEGaE45W9xJYtjWBGmIhOCasAHLR+7wNwueeYswBARH4FXT7xaaXUf3pPNN/e7wDQlNJX3bY8vxlD++t7ng1Tj2qOtTo41uqo57GGMBCOVnhnOdYIE1HDiUH3et8IYDWAR0XkQqXUkH3QvHu/A3juJzsBABdfcD5wZvnPX0hh6lHNsVYHx1od9TzWkJZGlBC0HnhCb8BRDGuEiejUcgjAGuv31c59tj4A9yul0kqpVwDsgs8mSJXgdo3gHEtE9Sd0gXBJpRFKAd+5CXj6q8VPOMsaYSI6pTwD4EwROV1EmgDcAuB+zzE/hs4Gw9n86CwA+6oxGG6xTET1LISBcAmlEZkZYHYKmPLuBO13LGuEiejUoZSaAfBBAA8C2AHgHqXUNhG5XURudA57EMCgiGwH8DCAv1JKVX4TJHCLZSKqb6GrEc5EYsUnVPN4eqL4CU1QzWwFEZ0inK3uN3nu+6R1WwH4S+dfdcfCDTWIqI6FMCMcKz6hmuxuerL4CU1pBHtcEhFVHNunEVE9C2EgXEJpxGwZgTC7RhARVQ1LI4ionoUuEC6vNKKUjDBrhImIqoVdI4ionoUuEFZSQiBsJtyZcgJhZoSJiCotEzEZYc6xRFR/QhgIR4tnFuZSGsFJmoio4lgjTET1LHSBcEmlEWbCLas0gpM0EVGlsTSCiOpZ6ALhkkojWCNMRFQX3MVyTDYQUf0JXSCcicRKKI1wukqwawQRUU2xjzAR1bPQBcK6fZpPIDxyxL2dLY0oZUMN1ggTEVWNCFBKAoOIqAZCGAj7lEa8+hTw+XOAgd36d/P4TKr4CU3QzEmaiKg6SlnbQURUA6ELhH1LI45v1z/H+52DrEA4kyl8Qm6xTERUXZE4kJmt9SiIiPKELhD23Vlu5LD+ae63yxyK9RLOlkYwW0FEVBVRlkYQUX0KYSAcz6/nHTmkf2aDWitQThcpj8gulmO2goioKiJxJhuIqC6FLhDORHw21Bju0z+zZQ7W48UWzM2yRpiIqKq4WI6I6lToAuFsaYRS7p15pRHWhFtswRxrhImIqisa41U3IqpLIQyE4/qGmVSVyi+NsIPaYhlhbrFMRFRdLI0gojoVukA4EzG7FDmZ3NSQG+z6ZYSLbaqRLY1gIExEVBXROEsjiKguhS4QVhLTN8ykOnzIfdBvu+SigbBPXTEREVVOxKc0YucmYHywNuMhInKENxA2mVxTHwz4t0IrFghzi2UiourybqgxehT4wbuAF+6u3ZiIiBDCQDivNGKkz33QtzSixK4RrBEmIqoOb2nE0Zf0z+ki8zMRUZWFLhAuXBrhU+ZQrGsEM8JERNXlzQibQLjY/ExEVGXhDYTNpDpyGGhfkXufnd0tVBqhFGuEiYiqzVsjfGyr/jkzVZvxEBE5QhcIu6URJhDuAzrXAPbWy6VuqGFPzMwIExFVR15phAmErYxwahhIjSzsuIio4RUNhEVkjYg8LCLbRWSbiHzY5xgRkS+KyB4ReVFEXled4fqURowcBjpWAtGm3Bphcd5aoS2W7YmZNcJERNVh9xFOTwKDu/XtWSsj/OP/D/jxny/82IiooZWSEZ4B8FGl1HkArgDwARE5z3PMtQDOdP7dCuBfKzpKi1sa4ewuN3wI6FztBMJp97FYQt9XKCNs16wxI0xEVB12acTxHYDK6Nt2acTIYWC4L/+5RERVVDQQVkodUUo959weBbADwCrPYTcB+I7SngSwSERWVHy0ADIRq33a5ElgZhLoWJV76S0zozMQ8WThxRg5gTBrhImIqiIac+dYUx8cb8mdn2dSwNRoaec78gIwNVbZMRJRQyqrRlhE1gG4BMBTnodWATho/d6H/GC5IpQ4NcKZtLu1csdKHQjbpRHRmJ5oC9YIOxNzLJHf7J2IiCrDLo04tg2ItwJd63MzwqUGwjNTwNfeCjz/3eqMlYgaSqzUA0WkDcC9AD6ilJrTigYRuRW6dAI9PT3o7e0t+xzxlJ5MX3huMyKZNC4E8OzeYzgvPYvhQwexs7cXZx16FV0zGWQyCiN9+7Ej4HWaU/24EkAacUTSKTw2h/EUMjY2Nqf3WAsca3VwrJUXlnGSJWJlhI9uBXrO0wucczLCU8B0CVne6XFdWzw5VJ2xElFDKSkQFpE4dBB8l1Lq330OOQRgjfX7aue+HEqpOwHcCQAbNmxQGzduLHe8ePb+XQCAiy44Dxg+CGwFLt14A3DgTiSXLsHyjRuBkz8EJtqA5g4kl3SgJ+h1BvcCTwLxlg5g7DjmMp5Cent7K37OauFYq4NjrbywjJMsUadGWCng2EvA+b8HnNiXmxFOT+oreLMz+vggpiUmexATUQWU0jVCAHwdwA6l1OcDDrsfwB863SOuADCslDpSwXFm5SyWmzihb7d0e7pGTOtSiXiycB9hs0AuntTZCqWqMWQiosZmSiOG+3SbtJ7zdUmaNyMMFM8KmzndzPdERPNQSkb4KgB/AOAlEdni3Pc3ANYCgFLqDgCbAFwHYA+ACQB/XPmhajk1wpMngaZ2INbk1Ain3cciJQTC5vhY0jl5Rl+uIyKiyjGLmft36t97zgdeecQNfpXSC58BXSecXBR8rhlmhImocooGwkqpxwFIkWMUgA9UalCF5HaNOAEkF+vfczLCM25GeLy/wMmcQDjuBMKzaSDCQJiIqKJM+7QBXdqG7rNzM8KZGbelWqkZYe5KR0QVELqd5XJKIyZPupkDu49wJq0n3lIzwiYQZi9hIqKK2dc/hmeOzuj5eDYN9L8MJJcArV1ArNlNXtjZ3WKdI0wnIAbCRFQBoQuEsxlhUxphMsJmogWc9mlxXfJQyoYa8Rb3nEREVBGbXjqCL2+Zwow4XSMGdgNLz9YP2hnhdDmBsHMsSyOIqAJCFwhna4RnnUC4ZYn+3S6NyMzo3+PJ0rZYjiec39lLmIioUtoTcQDAdEb0vDzwMtB9pn4wlnCzunPJCHOxHBFVQAgDYVMakdZdI3JqhK0tliNmQ41SSiNacn8nIqJ5a0/o+Xoq4yQwJgZ1fTCg5+wZn+xusRphv+cQEc1R6AJhd7HcdG5pRN7OcnGd6Z1hjTARUS10OBnhyVnro6b7LP0zltBzbmZ2jjXCzAgT0fyFLhDOlkZMngDUrH/XCLt9WmYmONPr7RpRao3wxAlg8zfn9gaIiBqEyQinMtZHzVITCDfrnzNTnhrhUrtGMCNMRPMXwkDYyQiPOW3RknaNsCmNcHYmMiUPQQvmvH2ES60RfuZrwM8+AowcLm/wREQNxNQIp8zUGksAnWvc24AOaHMywiOFT5pdLMeuEUQ0f6ELhCGi63/HjunfsxnhWG5GONrkTrRBC+a8pRGl1gi/+oRz3gJlF0REDc5khLOlEV3r3V7tdkbYDmqL9hE2i+UYCBPR/IUvEAZ02cPYcX3bd0MNUxpRJCOc8bZPK6FGeHYGOPi0vs1Lc0REgTqSOiM8MePsyWTqgwErEE7lruUoViM8w4wwEVVOOAPhaBMw7hMIm0B2Nu2URjiZ3qDMbd5iuRIywse2uhmLQq3ZiIgaXFuzzgiPFwqEZ6fdoDaWLPX6APsAACAASURBVKFGmBtqEFHlhDQQjrlbJ/t1jbAXywHBnSNM4Bwvo0b41Sfd28wIExEFikYEiaiVEV5qB8JWjbBJVrQuLaFrxBy2WD55APinc4G+Z0t/DhE1hJAGwk3uvvTe0gilrPZpxTLCTuBcTo3wq792b/sF2Pd/CNj9i+LnISJqAC1xwYlMq/6l50L3gZwaYSep0NoNTJcYCJdTI7z5G8DoYWBgV+nPIaKGEM5AOKLrztDUBsSa9O2oc19mRv+LxN1uEJUqjVBKZ4SXnqt/92YklAKe+w6w82elvxciolNYSwx4JnoJ8OdP5GaEo3aNsAmEy8gIz04DmUzxAcxMA89/z3luwHoRImpY4QyEo04LNZMNBnRGGNCTY6kZ4WxpRImL5U7s090qXvMm//OmJwEodyEfEVGDS8YEI1MZoOe83AeypRHTnkC4xJ3lgNK2Wd75U2BiIP+5REQIbSDsBL3JRe59Jks8O63/lVMaYTITs0UCYVMffIYTCHszwtPj+qdp7UZE1OCSccHolM/VtpyuEVMABGhZXPrOcua5xWz+JtCxKv+5REQIayBsgl6zmQbglkakUwBUaYvlZp1+wybDXCwjfOQFXY6x4rX+5zXdJEZrEAg//VXgwBML/7pERAW0xIDRlM/c6l0sF08CzR16Xi2UlLATG8UWzA3uBfY/Bmz4fwGJstMPEeUJZyBcqDTCfOMvpX2aqSU2gXWxGuGRQ0DnaivALpARVqr4+6ikhz4N3PUO4PiOhX1dIqICWmKCkclCGWFnQ41Ys040AIUXzNnzebEFc4ef1z/Pvk7P29wEiYg8QhoIm9KIAoFwKRtqmH7DEZMRLtI+bfQI0L7C2rHOWyPsvE4mDUyeLP4+KmkmpT887r4ZGB/If7z/ZeDbN7jBOhHRAkjGBKOpGShvcsC7oUYsCTS36/sK1QmnJ4G404WiWEbYzIVtPToQDro6SEQNK5yBcLY0wg6EnfumTUa4yQmOpcAWy9O5pRHF2qeNHAE6VrrnzcsIW5P3QtYJzzqdMs66Vr/uz/8u/5hXnwReeRQ48crCjYuIGl4yDsxkFFJpT4cH74YasWag2ckIF6oTnpl014cUC4QnBgCJ6M+KessI/+JTwL1/UutREDW8WK0HMCcm6G2xa4RNRtjJeEZjgIjOChfaYjkStzLCBerSZmeAsaM6Iyyis8LehRp2tnVBA2Hnw+C0K/UHyNCB/GPMB8t0kRXZREQV1BLTm2mMptJINkXdB+wa4ZmU/j2bES5SGtGxWpeqFQ2EB/VakkhEZ5zrabHckReAoy/WehREDS+cGeGoX0bYCYRNMGqyxoWyALMzTmlECTXC48f1Jh4dK/XvseYigfACtlAzHwbRZqCp1T/YNfcVa01ERFRBJhAeSXnm16hVI5xOAfEE0OQEwkE1wplZnUE2GeFiNcLjA0BLl74dT9bXYrmZlA7UU8O1HglRQwtnIOxbGuFkdbOlEVYgPHrEP3MwO+3JCBeoER45on+aQDie9AmErSBz9Gjx91Ep5r2ZS4t+wW42I1ykNRERUQUlnal4xNs5IhLR8285GWGT1DBzf7H2aRODerc6wAmE6ygjbMbOcjWimgpnIFwoI5z2ZISXnA68vAn4X68BHvun3PNk0qXXCI8c0j/bV+ifseb87ILJCEtkYUsjzIQaS+hV134Z4akR5yczwkS0cNzSiIAWamZDjVjCqhEeA45tBx76+9wOPCYQTpRYI+zNCNfThhrm8+PEvtqOg6jBhTwQ9qkR9maE330v8O4fAV1nAM98I/c82dKIEmqER01G2GnMHvPLCDuBcOfq2pRGmPZDfp0hWCNMRDWQtGqE85gSM7+M8NN3Ao9/Hhjc4x5vuj6Us1jOZIRjAWVyA3t0V52FZt7LSWaEiWoppIGwX/s0s6HGZO7vsSbgzLcC59wAjPTlBonZxXIl1AiPHNbHmexCUI1wvFVnjccWsjTCygg3OxnhjGeFtgmEi+3aREShJyLXiMjLIrJHRG4rcNzbRESJyIZqjaXFmV6DM8JOjXCs2aoRHgNedTYIMjt6AuVlhDOzwMQJoMUujfAJhB/4K+C+Pyv9DVWKGTszwkQ1Fc5A2GRw7S2Wg0ojjO71+ufgXvc+sxVzKTXCpodwxPmTBdUIN7XqnpW1zAgD+bVwDISJGoKIRAF8GcC1AM4D8C4ROc/nuHYAHwbwVDXHYzLCgZtqmC2W40l9hS6WBE4eAPp36mMOWsMz81opi+UmTwJQVo1wwj8QHjkCnNibf3+1mbGwRpiopsIZCJuAz/ShBPK7RkQ9neG6z9I/B3e7983O6OdFnJY+BWuEDwMdK3LH4FcjnA2Ea1Uj7DSa95ZAmNpglkYQneouA7BHKbVPKTUN4AcAbvI57v8H8A8Aqlo4m4gCEQnKCNulEc583twG7HlI325dBhx82j3ezLnZxXIFAmGzmUa2RrjFf0ONiQHduaEWmyABDISJaiycfYQ3vA9Ye2Xufd4NNbwZ4SVnABBdD2Zk0nryFdHHF6oRHjkMrHit+3ssqS+72abHdYDe1gNMnoQU27K5UrIZ4UTuzkzt1jHZjDADYYwe09mnREetR0JUDasAHLR+7wNwuX2AiLwOwBql1H+IyF8FnUhEbgVwKwD09PSgt7e37MGMj48jERXs2Lsfvb1Hch573eQ00sePoDM1hqNHB7GntxeXZWJomTyCjMTwavebsO7AD/H4L36KmXg7Fp94HhcBeHHXq3gtgD0vb0ffhP+YOoe24hIAW/YcwtBgL8440o9VU+N4zH4PKoM3jg9CAGx+6N8xJnN7j2VTChtnUshIDJHRw3j0/zyITLS5+PMsY2NjCzPWCuBYq4NjrYxwBsLLztH/bCbwzW6o0ZT7eDwJLFoDDOxy75tNuwF0JBZcI6yULo046xr3vqAa4aZWoL0HANA0PVTGmyrByQO688V1n9O1z0Y2I9xcICM84n9/I7rr7cCay4HrP1frkRAtOBGJAPg8gPcWO1YpdSeAOwFgw4YNauPGjWW/Xm9vL5a0Z9DZtQQbN16c++C+pXoOHp7B6nWvweqNG4GXlwGTRxBZ83qse9MfAt/6Ia4+rQk4ayOwcxx4EXjt5W8AXgLWn7YK698QMKZtQ8AW4OIr3wIsvwBQTwAH78PGN7zBLXGbOAE8otdTbDijC739bZjLeyxbOgU8AkSWnQMc24o3XLgWWHZuWafo7e1dmLFWAMdaHRxrZYSzNMJPXtcInxi/60xPaUTaDaCj8eAa4dSwrk2zSyN8a4THgaYWnREG0DTtyRjP1+6fA899G+jfkXu/nRE2NcJ2wKsUa4Rto0f0BilEp6ZDANZYv6927jPaAVwAoFdE9gO4AsD91Vww156I52+oAegv79MTer1GPKnvMwvm1l4JrHydTlKYBXOmrrbZuZpTqDRiwimNsGuEgdx5e7zfve23I2e1mBINE/xywRxRzZxCgbDJCAeURgBA95l6sZzpS5mxM8LR4BrhkcP6Z3upNcLLAFQhI2wmbTMew84I2304jfQkoJwgnxlh/cFbTztMEVXWMwDOFJHTRaQJwC0A7jcPKqWGlVLdSql1Sql1AJ4EcKNSanO1BtSeiOVvqAHoL+/malW2RtgJhE/7DZ1YWP5at07YzO/xpH5uocVy44P6p10jDHgC4QH39sn9Jb+feTPzzzJnDWNQIHz4+cJrV4ho3k6hQNhkhJ1AL+oTCHet14+bnsA5pREFaoRHncDT9BAG3LY/tmyN8HIAQNN0hRdfmE4Uw32593s31AByA147C9zoGWGl9IdpPTXWJ6ogpdQMgA8CeBDADgD3KKW2icjtInJjLcbUkYj5L5aLNgEpEwg7GdvmNgACrLlM/772CuDQs3q+NgFkvEVv0VwwIzwINHdarTSd89sddUzWOJbQpWcLxcw/7St0Kzi/BXMjR4A73wRsu2/hxkXUgIoGwiLyDRE5LiJbAx7fKCLDIrLF+ffJyg+zBNn2ac4lp6CMMAAMOOURdmlEoRrh7PbKdkY4Edw+rbUbgKB5qsKBcGBG2Kd9ml8gHEtysVx6EoAq3oifKMSUUpuUUmcppV6jlPrvzn2fVErd73PsxmpmgwGgIxEP2FAjAaSG3NsAcM7vAFd+AEh06t9Xb9ClBP07rYxwwlmnUaQ0orXL/d1khNM+GeEVFy9sRti+irfkDP+M8NhRAMrd1ZSIqqKUjPC3AFxT5JjHlFIXO/9un/+w5sDbNcI3I+wEwqZO2C6NiMaCa4RNBrndEwjPTuVuXGFKI6J6442KZ4SzgbBnYvRuqGHGkh2XEwh3rGBphPkg9WujRERV0Z6IFe4jDLiB8Pm/C/z2f3ePWbRO/xzus45N+l+Vs40PuJtpAG6NcE5G2CmfWPU6YPigW0JWbSZhE08CS073311ucih3jERUFUUDYaXUowAqvOprbj5493P43OaAS9qmBVq2a4RPINyxUu/8ZlqoebtGBNYIH9ITqt232EyqpkZtNq1vm4xs13os7f8VsPuh3HMd2w7c9c651aia0gjfjLDo9xJ3ukZM+WSE21f47zrXSMwXBGaEiRZMeyKOsakZKLM+wzDBL+DOqV6dTknacJ8OYqPNuutDrKlwjfDEoLtQDnAX43kXyyU69dXC2Wk0T/l81E0OAV96va7XrRQ7+F+0Vr8379/GZMq9bTqJqKIq1T7tShF5AcBhAB9TSm3zO2i+PSmPH0/h2NhM4PN+ExEgNYoogF89+TTSTYvyjrm0uQfTu5/CS8leXD2dwtHDx7CntxevT01j/NgRbPc59wX7tyEhbdhsPbaqrw9nAni89yHMxNsRS4/hagB7Xj2Cvt5eJFa+F+cN/A/E7no7dp/5fhxedb3zvJ/izD0P4qlf3IvJllV5r1XI1SNHEAMweXQ3nrLGcsYru7EqEsdjjzyi/w6RJhzaux37oI/pGngKFwI4NhlFD4DHfvmfmI215Jy7nnv8ec1nrC3jr+IyAJOjJ3P+htXSKH/XhRSWcZKrPRFDRgHj07Noa7Y+duzkQiwgEG5dphMVI4d1JtUEtKVkhFdeYp3feZ6dETZZ40WnAQASKZ9uMoN7ddvNIy/mnq8U6RRw358Cb/6EW5oH5AbCLd16fUpqOHe3VLPBBzPCRFVViUD4OQCnKaXGROQ6AD8GcKbfgfPtSfnI6Da8+OT+4F50Tyb0ZALgqt98o7v7kG3gEqDvGX2OxzNYfdo63btyeydalyzGMr9z7/ss0L4m93U3vwLsAa6+fIMuORg+BPwKWH/eRVh/qT7u0aYleMMrn8NZgw/hrHf/o37ew78G9gCXX3xeeZPq9ATQmwIiMSTTJ7HxjW/UWXAAmNgE9Le443u6A2t7lmCt+f2Fo8BWoGf9RcDxR/Gbl12SW++M+u7x5zWvsfY9Czyjt31diPfbMH/XBRSWcZKrI6mvvI2m0gUC4YANJSIRoH2lvjIXbXJrfaNNwYtelQrOCNvbLE8M6GMWrwMAJCeP5p/LLKiby0Ljwd3A9h/r0ovuD7v3Zxf9JdwxTgx6AmEnI2x3tiCiipt31wil1IhSasy5vQlAXES6izxtTpa2NyM1C4xPBXR3sDfR8FssBwCLT9dBa2bWKY1wnhONBXeNmBxyF24YJnthak3NJXdTGgHonYJWXpL7jd5c5ip30ZqpD156rr4caF8um0nlZlOa2/xLI0zXi0auEzalM+waQbRgOhJ6Ph6a8JSf2fOWydj66Vyl5+30pFtCUSgjnBrWa0ByaoTNYjkrEB4f1Md0rgEgSKSO5Z/LzN9zCYRNEDuwO/d+87kRS7pj9Aa8zAi7Ro4Ax3wvNBPN27wDYRFZLqJTkyJymXPOqvyXu6xdT4D9owGTnx0I+9UIA0D7cr0gYrxf/4yUUCOcGsr9pg5YzdmdsZjg0uzsZrR06Ul51gmyJ0/kHp+eBL5yJbD3l/6vbZhAeOVF+ueI1UJtZio3m9LU7uka4bQnMov9zO+NyCymZCBMtGCWdej56bh37i4lIwzo9R0jh/R/tyagjTUFB8ImeGz1WyznzQh36XN1rvYPhE2AOpcEghnH4N7c+8244wm3s8WEJxBmjbCr938AP/yDWo+CTlGltE/7PoAnAJwtIn0i8j4R+TMR+TPnkLcD2OrUCH8RwC0qb0VEZSxt1xNl/1hQIGwFv0EZ4Xbd4xdDB53nxNzjC2aEPYFwzDOpmrqzvEB4iXMO8+3eBMJOZnL0KHB8O/Dcd/1f2zAL5Uw5hb1gzpsRbmr1BMJj+v2ZD4VKtlCbOJH7wVLv7Ixwdf5vSkQeyzv0/HRsxPMFNGexXIGMcMcqPedNj7vPKbShhgle/TLCJhubyTjlE0v174tOQ3KyUEZ4DgkEk8AY3JN7v5kzTY2wPWbDfGZMDYdzU407rgZ+9S+VOdf4oPvFgKjCSuka8S6l1AqlVFwptVop9XWl1B1KqTucx7+klDpfKXWRUuoKpdSvqzXYZU4gfHykSEZYou5e8l4mKzrsBMI5fYR9AuGZKT1xBgXC2YywKY0ICITNZGoywtktj53Jdc//KTzZmS2BVziB8HCBjLBfaURzu3+P4fn6xm8Dj/xD5c5XbdPWQpnZ6dqNg6iBLM3O3Z5A2L6KVygj3LlaB73DfdZiuQJ9hLPbK1t9hL3Ji9SQnvNNINp1BtpH9wC//IybeLDPZZdGPPqPwNZ7g8drmOB2/Hh2/QqA3MVyJkFhb/cMuDXCQPiywkoBx3cAR1+qzPmmR8OVcKFQCdXOctlAeDTgsna23jcgGwwAbT36pwmEi9UIm8nLWxqRVyNsSiPaco8z23uaQHjiZO7x2YB4GDhQ4DuEmSSXneuuoDZmp3wywlYf4alRHRybrUsrmREeOqhr98LCXjHOiZVoQSTiUSxqieNooYxwUNcIQJdGALrfbnaxXIFA2DcjbBbLOWPwlk+84a8x2PU64NHP6WymmR/MVs32vPnM14Envhw8XsMud7CzwiYQjiedf635tcA5gXDI6oTTE/rz1Bvcz9XUmD4nr+JRFYQqEF7c0oSoFKgRjlhlDkFMIJwtjShSI2wmo7yMsJO98GaE47ltyfIC4UnPYjk7y7DrP4PHPdavtwttanFXUBtFa4RHgeYOKyNcoW2WZ2f0F4EwLb6zvyCwlzDRglnekcAx79W8UtqnAe5C38yMtViuUCDsZHTtGuFoXM/z5stwNlh25uhFa7Dtgr8BbvgCMHbMvermt1guNQwceSF3PvEdx4D7vgasQDidgu797iRiWrvySyNSQ0DH6twxhIXZNnu8QuM2nzFc20FVEKpAOBIRdDRJ/oILw87uBok16SxBtjSiSI2wqUvKWyznacUTVBqRNDXCJ4CZafc/aG9GeMkZwMsPBH/jHT8OtDm1bB0rfWqEC5VGjOhssNl1rlIZYRNQz2U1da3YGWFOqkQLZllHIr80ouSMsNVzPbtYrjn4v+HhPj3Pe+uO4y3uc7LlE54mR13r9U+TbPCWRsxMuxnPQ88GjxnQAeyKiwCJeDLCk/r9mhaYrUvzF8tNDgFdr3HPEyam5K+SGWGAV/GoKkIVCANAZ7MU7xph1535aV/ukxGOFi6NyGuf5s0IB5VGWDXCk1adl7dG+MJ36Mt+3jY7xviAu6ijc5VPRthnsZwJqk2NcLxFT8iVyuCa91AsKwLohSk7/6P2WdhpBsJEtdDT3jz3jHDrUvdKX85iuYA6/6GDwKI1+ffHEj4ZYU8gbMowTLLBmxG2F829+mTwmM1rdKzUG3YMWnN7OpW7k15Ld25GeDatEw1hDYTN5+bEQGXKGbIJpBI+a4jKFMpAODgjbILaAqURgA6EzWUvu67YLxAOLI3wbNc5Pa5fN+YJwrP1XydyFzyY/6DN5HrhO/TPoPKIseNuIGwywmaC8WaEm9p0a7js2MZ0ICyiH6tUBnfKk90uZPt9wA9+H9j9i8q89lyl7dIIBsJEC6WnI4H+sSnMZqzAyMxb0abgBc6AfsxsAlTKhhrDfXqBnVc86dYIjwdkhNtNIHxIB6QmqDNXwOza3aKBcL8OcrvW59cI232TW7tzg13zmktMIByyxXKmNCIzM/9uD0rlthslqrBQBsL9RRfLFdkwr325XpwGWKURATXCQaUR2YywFQh7yyKMlq78jLBdGhGJ6YmypRs4sc//HOPHgbZl+nbHav26ZnL0ZoS9i+JMRtg8VqnSiFIzwkq5bXQm5zChz6aBn3+iMjss5WSEWSNMtFB6OhOYzSgM2u0vs9ndAq3TDFMva2+xnJnRmyPZlNKlb51r888RT7oZ4YkBvXbC260intAlbSOH3eA00annO6XcILVjNXDw6fzXN2bT+vOjtVtvrzy4Nzh50eLUCJvHTeu0tmV6jJXMCD95B/DAf6vc+fxMWR0y5lsnnJ4AVMa9TVRhoQuEFzULBsenMTObyX+w1Ixw23L/55STEY77ZIS9ZRFGy2InEHYmt+YONxhNjbjZ2pYl/oHibFo/184IA+6mGnkZYScgn/YJhJvaKrdYLnupsEhg/cojemGJ/Rzb5m8Cz3wt+PlHXwJ+/b91DfV8sWsEUU30OF1/csojzLxVqHWa0enUCWcXyzmJD+8X2smT+r/zoIzwjJURNgvlvEzfYhOALl6nPx9mUm5y5Kzf1nNp0I5nJlHR0qVLHNITbrlFejK3frm1W3f/MXO2/bnTsqSygfDunwM7N1XufH5SVvnIfOuE7c8XztlUBaEMhJUCBsd9asNKaZ8GuJtq2M8JrBEe0pfivCUPUWfiTlvlBwUzwlZpxKK1uQvNTJCaXOwGy7bsJTwnEDa9kEed5u95NcJWv+DZGT0BN5mMcFvlF8vZ9ch+Hv+C260j5dOUfsvdwPPfC36++ZuMHp3bOG3T47rPNMCMMNEC6vHbVMOu9y3GJACyi+Wc58xOAYeeA/qchWtDr+qfvjXCSTeYmhjIL4uwX2vkkDv3Lj5d/5waczPCZ12jfx58yv8c9mK8rjP1bVMe4Z2zvZtqmDkvudi9olgpqeHcjG012D2T5xsI26V3zAhTFYQuEO5s1qtsfRfMmQC4nEDYlEZE48GlEd6FcoCuWYtaq5anJ0ovjVi01lO20KFvBwbCTisgUxphxmMWbQRmhMfdYDUnI1zh0gi7HtnryIvAvoeBy/8suD55esz/fRvZQPjI/MYL6Ik0uVjfnmF2gWihLO90AmG7tM0kIuKlBMLe0ghrwfJ/3gb89EP6d7P+I7BG2OoP7F0ol32tlcDIkdyMMKDnXBPkLb9A1xMH9X+3EximE4VZMDeTys8IA+7r2SV5FQ+Eh3RCIuNzVbVS7AWF3m4YZZ/L+sxgRpiqILSBsO+mGiUvllvh85yADTX8tlc2YokyaoSdjHC0WU+M2cVyI1ZGeEnuQgxjzPlGbTLCCSdwTg3ryWx2OrhGeMoTCBeqEf71l3Sj+FLZE1RQnfDT/6YzOBv+2Hltn4zw1Ji70Ygfk0mvSEZ4wr0cyoww0YLpam1CRIBjw34Z4RJKI0xG2NQTR61A+OQBvZNZOuW2xgysEXaCqbFjbkvKvNdapQM4U8qQDYRHrU5Ci4CVFwP9O/3PYTKhLd167JG4260oPempES6WEa7gYrnJIQBqfiVyM1P6i0KQ1Ih7ZXK+azumWRpB1RW+QLipUEZ4DqURkSI1wqnh/IVyRjyR25khsEa4S1+KGu/X9V7N7f71u8nF/hNetjm8M2mbDPLUiL4sCOR3jQD0RGeCXjsjHNQ1YvM3gBd/6P+YH+82zl4TJ4CXfqQ7YiQXBwfC06P67zPr8/cHKpwRHndb2rFrBNGCiUUj6G5rDqgRLmGx3BKnPMHMx+a5UyPA2FF9Zer4Np0RjiXd/85t8aS+EpRO6XnVL1gG3KD72Fb9c/FpzmuN6oxqJK7P1daTux2zzd65TkTPgSbTm9c1wvlyboLnbI1wZ2UzwvZiv1SR8oihgzo50r8r/7Gn/g34yhXBWeXUsB53c+f8A+EplkZQdRVpr1B/shlhbz9KwKr3LfK2Wpf5PCegRnhyyP8SG6An4nQJGWFzKX5wj876mj6/mYyeWE2vyORiHah5d4ozk6MpjYgn9XtMjeTuWW/YpRF5GeGAxXIqoz9ATIP3UthBrV+5xZa79Pgue787Bt/SCCebnBp2PxBskxXOCJtNTtIMhIkWUk9HIrc0opyMcM/5wB/9FFj7G7nPsTvtHHlR1wgvWuM/l8USOqto+rAHze0mED7yos78mquC006NcKJTn7+tRweps+n8BMz4AABx5//kIvdL/YxPH2HALSNIDemkRTSuA/r0eP4Cu7lITwAZpwTQb70GoBcn//IzwK4HASjg5H7g+s/lHjPcp8c4edJ/zp4a0X+jSMxJAM1jzMwIU5WFLiPcFBV0JuP+vYRLrRE2u8sBbqu1cmuEAf2NvtTSCEBvltGyxM3Ypsc9GWFnsvWWR5x4xdle2XmeiNN5YsS9vJ+zs5xfaYSTRW7yXywXTzvZ5XIuwRUqjchkdJnF2iuB5Re6Y/AGwjPTblP8oDphM6axY8GtikqVnmBGmKhGerzbLGczwiXUCAPA6W9w5+zs1sXWRhVHXgjuIQzoMq30hLugLjAQdjpUDLysM7rZq3CjbiAMOMkJ5Z/1nBjQc03EWZybXOzO7WlPRripVb8fuzTCBNDm86MS5RH2Z4s3IzwzBdz/X4E7flMvAHzDx3QNtN+8bObxoIVwKScQ9tsxr1w5NcLMCFPlhS4QBoCl7c1FSiOK7CwHuHXCEatGWM3mdz8oVBphb/FZsH2aM5GlhpwSAWur46kRd5I1AZp34jmyBVjx2twMR3N7CRnhUTdra9cIZ9J59bGJ1HH3tUsNNu1v6t7geu8v9U55r/+T/DEHnSMoEDb3q9n5rUBWSv/vlA2EWSNMtJB6Oppzu0aI6Pm6lMVyXmaeH9yrfy5aCxx90ekhHBQIOxtqmAV1C1qm+gAAIABJREFUfp0lAHfzjsyMc4nfJBdGPIGw0w1n3Kc8YnwgdzFews4Ie2qERZyg0SmBsNemZAPhCpRH2MGvNxDecjfw3Hf0wuYPPQ+8+RO6jNA3EC6yhXJqWH+utXazRpjqXigD4WXtzQGL5UosjQCAdmcC8y6ws8sjMrPOJZ4ii+XMzjdNAdd/7F6VLUvcVmaTJ/Xz7a4RQG4v4Zlp3ady5cW550wUyAjHmvX78S2N8Gy2YU6XMhOa8l+w52dq1F2w4i2N2P+o/t/j3Bvd+/wywvbvQZttTJ4A4HwJmE+d8Oy0DqabO3QLNXaNIFpQPR0JnBifxtSM9WU7lig9I2wzzxncDUCAs64Fjm7VwVlQ7W88qa98DR3QzzG7yHk1t1sJiu7c5IWdHDHlan51wuMD7roOwFMjPJVf5mA21QCcjHA1AmFrbrdL25TSa0SWnQ9c8z+tco7F8N0ZLhsIB9RHm9KI1u7K9RG2t8cmqqBQBsJL25vRP+aTzbNboRVjFsxlA2Hn8pUdCJtvzIUWy6VTzrdUVaA0wlq0YWeETVBnL5YDcr+B9+/QAdzKS3LP2dwZnBEG3H7B2UDYeU17IZ0lmxEGSp9wp0bdv6M3ED6xT/fetPsvJ3wCYbukolBphFkoM586YfNaTa3OohlmhIkW0nKnl3DOFb140u0NXA7z5X9wj77Ct3qDu3i4UEYY0OUU7Svy+8PbTJ1wa5cen0QCSiOgy7a8JgZy62eTi6zSiMn8Obu1O7dGuBqBcFBpxOHndDZ9wx/nXnkMaumZLY0IyPamRvR83+JsHa3m0aptekz//ZvamBGmqghlILyiM4mjw6n83eWyGeFSAmFPaYQJiO06YTMBBNYIOxnhbIAVUBqRXJJ72wTMeYGwT2nE4S365wq/jPCof0bYjGV6XJcnROLu2OzMhqV5yvrWXuo2yFOj7t/RWyM8uA9Yckbufc3tOgC3Sy9KKo04ASw7T9+eT0bYZBPiLbllLUS0IJZ1+Owud+OXgCs/WP7JzJw3eVIHvisuch8LKnmIWYFwULBsmEC4pctZl+Es9p201o20FgiEvaURycU6U5pO6StT3kC4pdvdjrjUGuGx48D+xwu/D1tQacTmb+p58bXvzD2+aCDsk+3NZNySv9algMognp5H73rTkSnewkCYqiKUgfAZ3a1Izyr0nfT8R1Fq+zQA6D5bT0QmCDXZZL+McMHSiClg1Ok1GbRLUTzhBqL2YrmREjLCR7bo7G9eUNmhW44FZYSb2nSt3JbvAxf8npvxNq895c0I97s7rpWTETa1dPb5lNIZYb9AGPDUFtulET4TbmZW/++w9BwAEpwRfulHwI8/UHi8004gbBamsGsE0YJas0RnfncetS7Ln/VfgKVnlX8y+8v/ojV60wqTWS6WER7cU0Yg7MzrTe25XSMAXQ7X3OH2ejcys05HBU+NMKBbvQH5ddEmI6xUbo1wcjEA8V909uDfAt97W+mbY6R8MsKpYWDrvcAFb8tP+pgstvf8qQI1wtOjAJRO1jjvP56ex052U2M6gRNPVqY0Ip0CXvhh4d1QqaGEMxBeqjOq+wY83zJL7RoB6P/oP/yiuzmFbyBs7e7jJ5bQdab9L+vfl54T/HqmPCK5xA0ITQBt1+9KNPeb/+Hn8xfKAXrcKbtG2Kc0Yv9jujPFb3zIut/qQWyfLtUPLDtX/1JOINzSpf92dkZ49Kj+u5hyhrzXtrtNFMkIm0t5bcv0v6CM8MsPAFu+52ZU/KSdMcZbcjdDIaIFcUZ3K07vbsUDL1WgFWLUCoQ71+gv+z0XABC364OXCYRnp4KzxoY5h8nINrfrwG92KjdgbF2anxGeOAFAeTLCzueI+TKflxHu0oHe+IB+DXN8JKof89QhR2angJc36Xms1DnbzKety9xAeNeD+nVf90f5xycX6/fh3ZK5UGmECZJNjTDmGQhnM8LJ4IxwZhb46UfcK6iF7HoAuO9W4NCzcx8TnVJCGgjrrOa+fs/l+HJKIyIRd8Ec4AbPdiCcbWpeaEONKb2zkESBJa8Jfj1T9uCbEXYCRNN0Pbuy2CyU89QHm+dMjboTQ15phFN+sf639Faghsngmh2TzOmmjrvlF+UEws3t+ds2m76eXZ6/hwn47c4RpkQjEvO/9GfKNJKLdT1yUEbYLNroezp4vNmMcJFA+Nh24HNnuy2WiKgiRATXX7gCv947gEG/dR7lsANJE9S+5k26XWNQMsReoNZZLBA2NcJOMNvc7nabsD8T/DbVMNnbnBph54qf+TLvXSy36lL9c9NHc48HdAmaZ+5bcuJ5d94ttWTMdHNILnYDYTPP2Z8T3jHbtcWzaXehsV9G2JzXlEYAaJr2CYRn08CBJ4qPeWpM/+1N6zs/J/YBz34T2Pmz4uczf0e77R41tFAGwktam7CoJY69QYFwKRlhL5MRnk3r4DKTKS0jnHYywl2vKbzwwmQVkkvcOl3T1N1kpQEdKJtAOLtQzlMfbJ6jZt1j/UojgNxsMKAn1EgsN8hLjSA+Mw50n6nPU0ogPDOl27CZQNiuOT7htDPyK+cA/PsPd6wKyAibrUaX6LEHbetpLk0efCp4zNka4dbCNcKvPKovX/plF7bcDex7JPg1iKig6y5cgYwC/nPbPLPC9nxrukRs/Dhwa4H/Pu15slggvOx8vUDOzGM5gbCVEW5blpsRPr4T+NW/6Nve9mmAO4d55+wz3qhrpbf/JPd4QCcBxnL/Xkv7f+X+UnIg7JRcJDrdgHXsmC6/89usw69cz56//bplmKuNZrEcAjLCO+4HvnmN3sDDa+/Dun8+oEstimWEj23TP0tZTG2Cd/M5RQ0vlIEwoC+x7esPKI0opX2aV8RaLPcvFwOP/mPuNpd+TI1w/8vA0rMLn98Ewi1LdCAGuP/RmkwpkJsRDlooB7hBpcmEejPCa68Ezr5eN6C3RaI66Bw+6N5n99Rs6QImAhat2cxk2NTu7FbnyQhH4kCHpwYv4RcIO7cXrfUPhE2WuMVkhAMmfPN3eLVAIJxd1NhSuGvE8e36p/03Mn7xKeDJfw1+DSIq6NwV7TijuxWbXprnlul+GWERfbUviN2doliN8JrXA3/9intlq7nNCvICMsK7HgS+crmuuX3tLbqTheHNCPu1jPutTwOnXeUcbwfCPblBXnoS3QNPA+vfmnvOYsxCv0Sn+17GjrndL7zM+8wJhE1v+oDtk+3SCOdzzzcjPOTMrwd+nXv/zBTw/VuAx5zd7HJqhAMC4eM73PdSjAmEBxkIkxbeQHhpG/YNeDPCZdQIe5nFZCdf0d+8N39dZ0Yj8eDWPqZG+MS+wvXBgBsIJxbpiTre6v4HmRcIO8Ff0EI5wA0qTSbUO6n+xgeBd93tv83oorW5GWET8HWu1YF6KRlhe6MOv9KIxae5O0AZ2R7G1qQ4Naa/uLT1BGSE7dKIlcDEACTj2QFwdkYHzBLVbYBmpnMfH3cWoGQzwklne+ygSdUJhIc8gXA6pQPu+e6URNTARATXXbgCT+wdxMB8yiMiMWT7ixfL7hpxn+C5EDsYtedpb0Z4aljPDy9v0o/95Q7g9/4tt6Wmt0bYbxORaBx4x7eAqz4MrLncvb99Re7Omrt/gWgmBVz+p7nnLMb0QLYzwqPH3DaYXoUywl1n6ESGdx61A+VoDEgu8c8Imy8P3qt4h57TV+vM/JvTNSKgNOJ4GRlh85k5uKf4sdQQQhwIt6J/dAqjKSsoKqdG2MsEz8e26p9jx4BtP9aThl8wCbgTmZotHghfdAvw1tvd4LC5DYDSl97sQDu5xM1EH92q6938Xt+bES5lNz1j0drcIM8ExdmMcCmBsBP4Nrfryd5eLDe4z79eOhsIexbLNbXlloTYckoj9GTdNO1p8D4xAEAB667SE6h9qe3kfuCfzgZ2/9wdY7zV2R7b50NYKTe74M0Im8z5fBvEEzW461+ryyMemE9WWEQnAOze7MWYuba5I/hKX5Bmq4TNGwgDei4+/Lxe0+HXQchkVwtlhM353np7bhDd1qN78ZoM7M7/wHS8AzjjTboO16z5mJkCHv9C8NWulMkId1ilEUfdHfK8TCCc023CCXTNHO/NCme7LTl/r9bugEDYCVq9V/FedTLEZr7N1ggX6BpxzElelJMRPrGPnSMIQJgD4W6fBXPzygg7AaqpNUouBkb6ghfKAbkTWbHSiJUX62/5Rravb7t/A/NMRmcme873P19zkYxwIZ1r9GRsMqfDB5GRmF5JXHIgbG3U0dzuBsZBrdPsMXtrhJva3MUb3u2dTaY30ZntWdw85VlUZzIL59ygfx580n3s1Sf1AshDz7mTaFOBPsJDr7rZ7aEDuY8NO18Y5rtlKFGDO2d5O85b0YG7nnoVaj7BSKy59Gww4M6Txcoi/Nh94pOe0ghAzx3HtvsvbgZ0TXO81QqEfWpyg5h+7ea5/Tsw2r5eJ1bshXR7HgIe+hSwr9f/PJOeGmGl9PwZmBH2K41w5m8zx3sTA/ZiOQDoWJm7YZNh5u2RPjfoBdwFdMN9+vMgPV64j/D0hP7MiTbpsXg/Q7zMeKfH/GucqeGENhB+jV8LtXktljMZ4W36G7ZpJVMoa2AmVYnoHpblMBkMO8sA6IBwekwX8k+PAT3n+T8/UaRGuJBFawAoPQEBwHAfppq7dclGcklpG2rYWzc3tbrB49hxPXH5BcLmgySna8So/lskl+gxpTyZg8kTblY+mxH2jM/8DZZfqLPd9qW2vs3658Aut2tEofZppixi+YX5pRH2pTpzrlceA777e8C3bwB+9D5dpkFEBYkI/uDK07Dz6CiePVDCmoQgsWb933ypsn2GywieDbs0wp63TUZ478N6AXFQIAzo+b1QaUQQE6iOHXOSDfuRSjj3ta9wA2TTCcFvfQOQWxqRmXHm64ngGuFYs/6b2V0j8gJhT2JgakS3tjPvb+k5aB3vy8++jh0DFp2mb5s5OzOrb0ebra2wUbiPcP9OAApYe4WTNfcE5vt/pTcMMcb7gaVOq1AumCOEOBBe29WCiHgzwvMojTA1wgO7dJnDJe/Rvwd1jADcQHjxOv8Vt4XYGWGbeb39j+mfPT4tbQArI3xcTxpB5Rt+zAeHCeyGDiKVcCbCli496RUL6Ezg29yRWyNsWqf5BcKRiF5c51ca4VeLZn43reecdkbNU56MtcmKty0D1lwBHHzanXRNr8jB3TpAjyX0/9bxIoHwmb+tLwfaY7U/XMxk++IP9M5Oo8eArT/Sr0NERd108Uq0N8fwvScPFD84yOv/BLj490s/Pj6PjLCZq2OJ3CDWZIR3P6h/FgyEF7lzZTlX8UwgPHpEXyWbGsZk0rmvwy8QPpR/jtm0ngMTne7nx4DTA78tICMM5O8uZ9Z4mEWE456samo4txNS91m6ntnO+gI6EF7/Fp0lN+URx7frQPqs33Z+36l/NrXpK3mZmdzdX81zAOA1b9Y/vXXCj3wW+Pnf6c+E6XEdTK+9Qj/GOmFCiAPh5lgUa5a0VK40wu4j3H2WbiV2yXt0DVYQk4XtLlIW4ScoEDYbb5htM4Nqj81Ekxoqb0IF3GzI0Kt6chg6gFRiqfP6XdCZ2SHgue8Anz8/f+IB3AURTW25NcLmG3aXTyBsxm0Hl2ZFcFAgPHEidzOSpjYkJz11hWYibl0KnHal/lDo36nr5I6+pDP2A3v0GE1GyHT88Dq2Xf99TCY+p5baDoSdLMjIEV2+8v84nSS4EpmoJC1NMbzt0tXY9NLRuS+ae+NfA+dcX/rx8RZd22ovRCuVmau9VwmdXrk4+pKePwtlm+1Su3LmbRNsjx7TC7oBNxBuX+Fs9JF2v4h7g04gty++eQ8Du5xzBNQIA04gXCgj7C2NGMnNmJvPMBN0A3phYWpYJzdWX+pmhE1ZhNnqud9Zr2H6CAP5WeFj23WZydor9e92nXA6pYPs6VH92WJKIVZeohNmnK8JIQ6EAd1CbW+/T2nEnNqnWc8x9b43fVl3XwhissDF6oP9FCqNAPTlnMWnBy8CaWrTAR5QXlkEoNunSURnOE/uB8aOYbTd+XZvgs6JQd0KaKTP/zKbXRrR3K6zq7MzTuu0mNvX06u5PbdrRNGM8An3sUgEWHYe2sb25x4zdtzdLvvs6wGIXuh4dKu+VHnGm3R3j4Hd7gKUoK4Rx3cAy85zx+/trmEmYzP5jxzWk7lZOMIMA1HJ3nPFWkzPZnDP5oBL+ZUWiQIfeg646ObynxsUCP9f9s46Oq7retvPGdaImdGSzCBbZk7ixmEGh9OkSQNt2rRN25TT0K/tlzbQNMzMcRIHnSh2zGzLjLIssJh5dL8/zlzNiNmi86ylJc2dO/fuGUln3tn33Xsbza6rVhFTO746536FsTtXEY1m2ZO3PKepv261h9M33JQtznXLCLchhHXbmYefS5Dr+3crI1wu6zbsgXI9bMsa4f4a6UI4300I68kLr1D5oSR3l0yKHF8r227GzJH3u2eE9der5bqdt0e+B+sDUNwzwic2SosFyPc6PVbvcHklV1kjFAx1IRzsxbHCShobnZfBdUtEdzoo6LjbKYK6OPdeF6CddYxoi3atEU7RV5HbfqEcyMXW/VJddzBZ5EJQclwOjwBK/CbJ+/Q2b1WFbraCI62PUVsOCCksdXFZVy6FoF9M69ZpOtbuWiNKXG8yAKHj8aw81txvVpkvC/2EkJmNuHmw+0PIcvqDJ18pv+fsdMsIe0iR7F5Y4aiXGZKQsa7WSqUtMsLhk13nBKcQjpRvLvYgtbAqFN0gMcSb2QmBvL7+OI7GQV7B3ySE27DL6RnbjmwR0FwId3fd1ovinBnhGpvznN5OAXhyt6u+o6wtIezWF18Xqro4bc8jrMfsvi7XlMkre0LIbHhbxXLu1gjPQOrMvk4vr5NyZ9bWK1Ta2TQHvLAUDn0rr+rZA+Qa3ZQR9mo/I6wXleu/A/eMsPP9DZB+Yz1Wr2BZ19PWe5tixDGkhfDESF9q6hvZcNT5z+8bKT9JdrYYtYXuEYauC9uQcVIYxc3r/vn0RbWVEG4u+jo+hnMx625GGFwt1I6uAq9QquxOz5wuhHPTXb6zoraEcIWr44Uu6usqpQUhMKmDmNuxRjRlolsUwrlbIwDCJmBuqHBN5QOZEXZfyMddIC/DbX9dZjriFzrPVSp9ZuB6zdztEQUHpTgOHS+FtdHqygg7GuQ5I6bK25X5MvbaUtfY6sBRamFVKLrJtbNjySqpJm3/IK/g19e5tgqo9fWnUyHsNja520I4VCZIio6AdwSNRucapmeE9bqSsInyA3rL7gnNrBG6R/igXOfc42qJza91Rlh/32pTCJe1utJZZY9qnhHWxapXiJyot/gPrmmpY86R7yu+Ua6MdXsZ4cpCeayQsXJNdy9GBPn+plsXizOa2+gCR8nERWNj+89dMSIY0kJ46YQw/O1mXlzjHMVo8YQff95+p4WO0D3CVp/2W8m0xCcCbl3VtcbsLeksIwxSaHeEvph1d0EF6WPTM8LxC1yX83TRqRd+QDtC2G0xtLp1gyg6LP3V7WH1bt41Qs8I628u7gtuQ60s7nB/TfTiwdx017bK/OZCeOz5gICcHRA5Td6nf2jQp/rpi6p7wZxedBEyTtowfKNcGeHyHGe/6GTnMJQC1wcFn0j5PWCUyggrFN1kybhQQrytvNqborlTQXvWCOh6RljPJhstHU/AawvvMCnyio5CQLzbducHcT37mbDI2RGiRU9dPSPs4eYRLjshY+/QztGGNUJfT9sSwrVlzTPCQKVntBTC+pW8JiEcJt97F94DN66Ae7Ng/EXyPt9I1/rczCPsJoT3OsdRR81wHU8/dm2FvKo55hz5HNwzwvYg6XFuqIHy7Pafu2JE0Ol/ohDiBSFEnhAivZ37hRDiMSHEISHETiHE1L4Ps21sZiNXz4zl670nOV7YTqPtrqJ7hIOSu9eBoafodoKWHmGrt/RfQfsdI5r21YVwDzPCpcflJ+S4+a7tekb66GppFwlKblvc1Za53hh0UZ+/Ty4sHbWSc7dGNNSBo04KaYOzV7D7gts0TKONDwcn3f4cK/JcBSvgskcARDo9e7o4b5URdhPC216VmWDdGuMX7SqQa5q+FyWb5Vfmu5rY629EgQlSHNe1mHioUCjaxWw0sGxGDN8fyO/9Ot6f6OttW0I4Zqa8xK9fHWoPfS3rTg9hHa8wudYVHW4uhO2Bcq3O3SUFtj6iuaVPuC1rBHRcKKfH7Kh1CVD3td8zSHbtaWyUo5Ibap3WiOb2kSp7tDy/XqxWkQeItgeP6Lh39miWEXb+jTQ6YM1jMtkRPcP1XPSMsN5DPn6+bNNWnCETGFZf2fUjUNV1KCRd+Uj6ErC0g/vPApKcX7cA/+t9WF3n2tmxGIXgpbXHencg3SPck8K3nmBtJyMshFx4TB7NF7u26E1G2D2LHb/A9bPFLj95O2rlJbaQsW1nhPVMLri+52yX3zvMCLtZI/Q2QvrjW2YedJuEuzXC5kO1LdQlhBsdcrJcS4/buAvk98hpzpic4ta9awS4hHDmRtmEfs7PpIcamo+i1gWxb4wzC5LnEsJ6kYZeMNfW66VQKNpl2YwYDELw+oZBnBW2dmCNmH4z3PRl6+0t0T3C3ekhrOMdJq9KVebLQmodg8F5FVOTa5Dem7elEHa3Rphsrve89qbKNcXcon6jmRAOluvvezfCi2fB46lSqFrbyAiDyydccVIK+I46PLl337C2YY3Y87H0S8/9hSt55Z4RPvq9fI7Rs5xreYYzaeIU3yFO62HOzo6fv2LY06kQ1jRtFdDRhIULgFc0yXrATwjRycfiviPUx8Y5k8J5Z3MmZTVttPnqKrpHuKuFcr3F0o5HGKTwCxnT3LfcFk3Fcj3MCIMUdv5xLc7v9AlHpcrLR8UZrfsKu1sj9Ox29jb5vaPX0OYj7Q6Oho6FsD6hDpr7poFKzzjXBMCqQtlE3bOFEJ56HVz0jMsfHJTYPFZdCNc7hfD3/5DnSf2x6xi+MVLw1te4psr5RknRXVng8inrQrgpw6DsEQpFdwjztbF4dDCf7Mju3aS5/sRkhaUPw+RlPT9GU0a4B2u2t9vbasskiX5fUKK0FEAbGeFSVw9kIVyCvlMh3GK6XG252/jkYJl13fMRzL7TlbRokWVuqkHRfcIVJzs/b1NGWMgEhnuxnKbBD/+WVx/d2+fpGWFNg0MrZUcKix38Y2Uyw/3qoVew/EDhPoBJMSLpQZ+xVkQC7r1vTji3tRoiL4S4BZk1JjQ0lLS0tG6frKKiotXjptodLK9t4K7nv+X68T1YYAC0RhKiLySrIoraHsTVFm3FqhNYcJSJwO5Dx8kva75PeMASGkx28juJI6mwgkigoKSC9G7G7FGVw0wgxyOJ/d9/3yzWaQ4L3sDeMk+E1sCYxnrWf/UeNR4u7/T0olyq7FHsTkvDoyqbmUDD8S1g9OSHTbtB7GnzvFGZJ0kEfvj2C6y1hUx3ew0mVYOl9CAFL95CRPYXWJzz6Tfsy6L6uOv5RVgiCMzZxOqVX+JRnSOPkZFPfnXL1yAUVknfXFB+HROArLxiDqalEVhwkInAlg1rgDVMO/Q1R+Kv5fi6za5H51YwFtjw9ftEZ24kyOzL2rUbSS6rJ7A4i4J9mwkxebNmjVxIjQ1VzAeObP6G4/nyzaOjv4HBxlCJdajEqegeS8aF8s3ePPblljM23KfzBwwEs27r3eN1y0BPrBHutSv+8VBQ1vq+wCTXwIy2rBHu2Wybr8zmdlYT0zIjXOOWEQ6bIK0G5z8G4y+UAjRrq9zuRp0lQO7nnhHuzJKhC2GLlxTu7hnhjLWQuxPOe6x5wsg7XBY8Z26EvN3ygwvILLmjVl5JjHezAkbPhMPfyrhPhSVSMSjpCyHcZTRNewZ4BiA1NVVbtGhRt4+RlpZGW4/LNOzhuR+OcvOZ05ib2IHvqCMWn0Y3hnV2SnuxApBph/QHGD9jYRtdJ9p5TEsa0iD7c4LCIts/T3s46qH4I8Ln3U147OzmsR6PgYrDjD3jGrlg7X+cWUnBkOh2jq0anlGj5GPKc2EjmByVEDmNRYs7GEKy9TgchnnTJ8nHbYbxKTMhaREUjIL09/CqPCb7ASeeBjFzmNmi+DE9fy0ip5EFY4KhxiyPMWMRxM1t/7x5YbD7YSLjk4hctAgOa5AO0yaPh/QPwOxJwhUPkuBe5JFhgX3/YWZSCBQ2QHCCfL6OVZD7LZFeGjhim7/220NJ8NVIcG7r8G9gkDFUYh0qcSq6x+Ix8qrOyr0nB68Q7i29tUboBMQDO9zu0zPCTluab1TzzjogrRHu3t0uZ4R1Iey0VrhfDYxfAL895ir8E0IOyGiJENJ2qA/wqMjr/Oqrj1MI65YU94xwrtPO0HKYiv5cNj4tv489X37Xr3rWlDSvJ4meLqeDlmS0vjKqGDH0RdeILMC9bUKUc9sp5ddnjiYhyJN73ttJRW0n44EHA1HT4er3XI3De4K1Fx5hoxmuflf2bGyJV6hc/AJHuaYHtfS91pa7Fijd2gAdt05zj7m23OUV1u0KSUtkxfONX8CyN6Tvro0OIJWezsuCJ9Obj1fuiIAE+Sag+87cu0YUHZFvIC0qnQkeI5/bh7dK24f+WM9g6dU7ucdli2g6j+ocoVD0hBBvG5OjfPlm7yBvo9YbelMsp9u/PPxbtzvTi/R0cekT2XoQUk1p8z7G+nrXHY9wQ63MrLp7gLva/SJ8suziUFvutEZ0smbrFg/9/cU9I1x8TNoLdRufjv5hYc/HMturH0P3TUNzG50+YTBzY9eeg2JY0hdCeDlwnbN7xCygVNO0VraI/sZmNvLPyyaRXVrNQyv2nurTdx8hpPDrbgsdd2y96BrREYt+B1e94xxQESY/ibsLYU2TwzP0rID+SR1cXtz20B9TU+bqrqAL6slXwnUfty3O3aj2CHXOp1/fvC/UDh97AAAgAElEQVRkR5gs8PNtMO1G5223PsIlGS7PtDv2ALh5pXxTqS527aOfq/R4c98eyM4RyiOsUPSI08eGsuNECfnlPRy5PNix+gKiZ2u2ySLbfvm3UUQdt0AWhelddXyj2iiWK25tjYDOLQo2N49w00TRHmTsJ14qs7lbX5XdgjoT4GYP+Xz19wdTCyHsH9fazqAfs7EBxl3o2u5eHO7eqSJknBTayic8oulK+7Q3gXXAaCHECSHETUKInwohfurcZQVwBDgEPAvc3m/RdsK02ABunhfP6xuOs+ZQQecPGOo0DdToQUa4IwLiXe1ohJDZVHchXFsuC9R0UWswuD61dycj3LJYrqsIA0xZJgdmpH8gWwa1VcndEnuAa+Kdya0VT0mmLKZoi5AxUgyf/zjMdP7Juy+keg9hnYBRUpy790pWKBRd4rQxIWgafDfYh2v0FINBrlXdGa/sTvSMti1gUdNk1wq9PaRvlCwk1jssaJrsP+wuopusEZ14hPWWntXFsmMEtL561qXYZ8rzr/uv87ydCGGQYlcvljaa5FpfX+UUwm2s2e72Eb1zEMjXWz+fe9LEYJRF4UoIj2i60jVimaZp4ZqmmTVNi9I07XlN057SNO0p5/2apml3aJo2StO0iZqmbe7smP3Jr340xCwSvaG/MsItCYhvLoSdIz6bXW7SxWxHrdPAFXNtmWx4Dm13zuiMH90v+yxnb3WNV+4O+mtWnCEv9fm1I4RBZmKmXufKKrgvpC2tEYGqhZpC0VPGR/gQ5mPjy/Tcwds9ord4BrnsYN1l2Zty7esM3cZV6nQplmXLq3jBbr5cD38pcDu7mqa39Kwudn3A78maLYTsuKGPf+6KEL7wSTj7n67bZg+oq3JlhFti8ZSWiagZLluEjr7Gt7RkRM+UXYj09yPFiGNIT5ZrC3eLxJPfDfNG2b3xCHeHgAS58OgjO/Wxl+7FDhZPQLg8xe2hL6C1ZXJhhu5nhEEuiJe9LB/b2aW9ttBfM714ozuFEs2EcAtrhJ5dqRoBVyQUij5GCMEFUyJYuS+PS59ax47MkoEOqe+54L+w8Lf9e46mFmpOn7DerSF4jGuf6TfD5a+4rpJ1hC6Em6wRPRDCAJOvcP3cFSEcPNqVXABpwys+Kms72luzf3QfLPlb6+16Brml8I+aIa9wZm3pPB7FsGTYCWGQFoklY0N5c+NxauodnT9gqHLKMsKjpKdLHy5RcEDaE9xFr9VLZkw7u+Sni/fKQukRFsaexx+UKD3FS/+v+4/Vq7b1vpYdZYRbYg8EnBnoltYI/XJjTWn3Y1IoFNyzdAwPXzyRjMIqLn1qLQdPlg90SH1LzKz+H9yktx4rcQ4o0dc5dyHsFwNjz+3a8QISZMGwbo3oiUcYpHjVJ991VizXFmYPyHPWALXllQbZCz62jSJ0v/aEsLPLhT4QSjHiGJZCGOC62XEUV9WzYtcpr9s7dZyqjHCocwKPPs2t4IBcVNxbAIVObD6hrj2sXrJA4ej38lKU1at3/RujUmULnO7SMiPsXkzRGQajq1q5pTVCCWGFolcYDYIrZ8TwxS/mY7eY+ONH6cPXJtFf+MbILO4Jp1OxYL/02nY00rgjxpwjRXXGWnm7pxlhkNnwKVd3ra6jJWa7K8vd3XZn026QfYfdO2eALAY0mJpPNVWMKIatEJ6bGEhCsCevrBvEIzt7i3e4LAho69NvXxI6Xi4U+uS4goOte0Be+F95ya8rJP0Ijq+D8mzXhL1TjdGZha6rkJfoulu84hksO1e0zIwoIaxQ9AlBXlZ+u3QMG44W8dH2U96Rc2hjMEjvq14Elr+/eTa4u4w5R14F3Pm2vN3TjDBAwkLp/e1JAqRpnRbdS16A3H/a9a23CyGfT+0wu/Kg6DLDVggLIbh2VizbM0vYdWKYihKjSXq8Iqb073nMHhA8VgrhRgcUHuq8KK4jks+U7W0OrXS1xjnVGAwuMdwdW4SOZ5D0B7dczM0ecr696hqhUPSaK6dHMznajwc+28vxwqqBDmdoET1TXvGqLJQe4d7YMTyDpKWh0tm3vSddI/oCXQj7RPatJdDqrYTwCGbYCmGAi6dG4WE28sCKPVQO9w4S/U3EFMjeLn3CDTWdTwXqiKgZ8nJUfVXPq6f7At0e0V7rtI6Yexcsvrf1diFkVlhlhBWKXmMwCB6+eCJ1DY2c+/hqVu492XRfbYODtYcKyCuvGcAIBzExs+T3fZ/Ky/699SXrU9qMlv6vS2kPvWd9X0+Bs/qo5MUIZlgLYV8PM/ddMJ6NR4u46rkNFFXWDXRIQ5eIFKgugsMr5e3eCGGjCRLPkD/3pGNEX6Ev5m0N0+iMpCUw4ZK271NCWKHoM8aG+/DZz+cTHWDnppc3M/2Bb7joyTWk3Pc1Vz23gT98mD7QIQ5OIqZK0br1ZXm710LYWVjXG1tEb9Ezwn0thG3KGjGSGdZCGOCy1GieumYa+3LKuPzpdRRWDNOJRf1NRIr8vvMd+b03QhikPQJ6V3TRW/Riv55YIzpCCWHFACOEWCqE2C+EOCSE+F0b998thNgjhNgphFgphOjjf4K+JTrAzvu3zeHP545jUXIwZqOBi1IiWTIulO/351NWUz/QIQ4+zDYIn+JqC9YbjzDIwuCo6T0rcusr+i0j7O3qiKEYcXShgeDQ50fjw3j5xzO44cWNXPv8Rt78ySx87eaBDmtoETpeel8zNzirjwM7f0xHJJ4hiy8GNCPcC2tERyghrBhAhBBG4L/AEuAEsEkIsVzTtD1uu20DUjVNqxJC3Ab8A7ii9dEGDzazkR/Pa94ya0tGMV/vOcnKvSe5KCVqgCIbxMTMhBMbZVFyy3HwPeHc/wxsj/T+yggrITyiGfYZYZ1ZCYE8fW0qh/IquPzpdXy47cTw7jHc15isrjZqvc0Ggxx3fMZfYfKVvT9WTzGpjLBiWDIDOKRp2hFN0+qAt4AL3HfQNO07TdP06rP1wJBUkSnRfoT72vhsp2yTWVxZx6E8NSGsiWinTzh4dO/aVOqETYCERb0/Tk/pT4+wskaMWEaMEAZYmBzM09dOo87RyC/f3sGsh1Zy/6d72Hi0iCe+PciVz6xj+3CcZNRX6PaI3nSMcGfuXTBqcd8cqyeYbDIr7dvHGkAJYcXAEglkut0+4dzWHjcBn/drRP2EwSA4a0I4qw4UcKygkoueXMN5j/9AgbLASfSCud7aIgYL/WqNUEJ4pDIirBHuLB4TwsLkYNYfKeT1Dcd5ae0xnvvhKABWk4E/frSL5XfMw2Dog0/Pw42IKbCFvskIDwZMVtmGx9jHNhklhBVDBCHENUAqsLCd+28BbgEIDQ0lLS2t2+eoqKjo0eO6SkSDgzpHI+c8mkadAxoa4U+vf88Voy3dPlZ/x9qXdDXW6ITrKTFMoHwAn1dfva6eleGExFzG0U3pfZPhdhKTXUiCo45VK7+iorpu2P0NDAYGc6wjTgiDzCLMSQxiTmIQeeU1rD9SRGqsP5uOFXHXW9v5YFsWl06LIqe0GrvFhK+H8hMDso+kwSQLJoYD8QsgbFLfH9fmAw3V0KCyUooBIQtwnzYQ5dzWDCHEGcAfgIWaprX5x6pp2jPAMwCpqanaokWLuh1MWloaPXlcV1nQqPH8vm85WVbDU9dM47NdOXy1+yT3Xz2bQK/utfnq71j7kq7H2pV9+pe+fV1voM8rOzcehKOvsmBmCmmbdw/Dv4GBZzDHOiKFsDsh3jbOnyzH5J43KYIX1hzjn1/uY29OGS+vPUZsoJ0P75iLj02JYYKS4LfHBrbTQ1+y8J7+Oa7NOcJT9aVUDAybgCQhRDxSAF8JXOW+gxAiBXgaWKppWt6pD7HvMBgEj1w+hdoGB4tGh5AQ7MXyHdk8s/oIvz9rbJuPqapr4O+f7mFsuA/XzY47tQErBh/6e5oqmBuRjHgh7I7BIPjTOWO59Kl1vLDmKGdNCOOr3Sf5+ZvbeP766RiVXWL4iOD+RI1ZVgwgmqY1CCHuBL4EjMALmqbtFkLcB2zWNG058E/AC3hXyEvMxzVNO3/Agu4ls0e5utgkhnhx/uQInlt9lJ2ZpcxNDCQh2ItofzvRAR40NGrc9NImdjgnjtrMRi5P7ea4XsXwQu+NrITwiEQJ4RakxgXw1DVTifK3MyHSl9fWZ/DHj9L5+VvbuHJ6NDPiA7CajM0eU1PvYPn2bBaODibUxzZAkSsGDUoIKwYYTdNWACtabPuz289nnPKgTiF/PW88YT42Vh0s4F9fHWh2n9EgMBsFT149lTc3Huf3H+zCIATnT45A0zR2nighq7iapRPCEH3oQ1UMYpoywqpgbiSihHAbLJ3g6rd4zaxYckqreXb1UT7bmYOvh5mrZsZw1YwYQnysHM6r5O53trMvt5wgLytPXj2VGfEBTY+vrG2g3tGIn737hRuKIUqTEC5BJuQUCsWpxN/Twu/PHsvvgdLqejKLqjhRXEVmUTUny2o4f0oEk6L8WJAczNXPrufX7+7gvk92YxUO8r9cA8B/rpjChSkdNdtQDBtszoxwTRnyQoliJKGEcBf4zZljuHNxEmsPF/DelhM8/f1h/pd2uOn+YG8rD140kWdXH+GqZ9dz7exYls2I4fvMeu5e/R0Ab/xkJmPCBnA0peLU0SwjHNDhrgqFon/x9TDjG+nLhMjWE9G8rCbe/ekc1hwq4NOdORzMzOHXZ4/j3c0n+NPH6cyIDyDCz2MAolacUpplhJUQHmkoIdxFPCxGTh8byuljQ8korOTbfXlU1TkQAq6cHkOAp4VzJ4fz1+W7eW19Bi+uOQZAaqw/J4qrWfbMel6/eRbjIpQYHvYoIaxQDBksJgOLx4SweEwIaWnFLJoew+yEIM56dBW/fncHz16XiqdVvVUOa5o8wuVAH0zgUwwp1H93D4gN9OTGufGttvvYzDxy+RTuPXssn+zIJv/4YX5z5WwyCqtY9ux6znviB8ZH+DAvMYjbFyfipRbX4YnyCCsUQ5qYQDt/OW8897y/k5kPruSCKRHcvSS52+3YFEOEpoywWrNHIkqJ9QNBXlZunBtPWn0GQgjigjx5/7Y5vLHhOBuPFfHU94f5PD2Xhy+eyK6sUj7anoWPzUxyqDeXTotqdQnvkx3ZpO3P5+8XjsduUb+yQY/ZLvst15Sq/zCFYohy+fRoRoV48saGTN7dfIINR4t44+aZ+Hta+HRnNhuPFnMor5xx4T786dxxmIyuQa3pWaXc895OHrx4IlOi/QbwWSi6hMkKRqvMCKtOqSMO9TZ9iojw8+DXZ44GYP2RQu56axtXPLMegCnRflTVOXh7Uyavb8jg1z8azU/mJ2AwCN7ZnMlv39+JpkFpdR1PXTOt2YKrGIQI4Zoup+xmCsWQZVpsANNiA7gsNYofv7SJy55eB0BGYRV+djMxAXZeXpdBZZ2Df1wyqWki6YMr9rInp4zbX9vCJz+bpzLJQwF9zLISwiMOJYQHgFkJgaz4+Xw+2p7NzPiApgxwSVUdv3t/Fw99vo/nfzhKTICdLceLmZcYxMLkYO7/bC/3friL35w5hmBvK42NGtml1RzMq+BIfiXJoV7MHRXU5njowopaPk/PpabegdVs5JKpke1ml+sdjQhQgrs32HxlT0olhBWKIc+shEBevWkGN764iZhAO89dl8rpY0MQQvDvrw/w6MqDeFqM/Pm88aw/Usjaw4VcOT2aD7dl8bM3t/HKj2f063pa72gku6Sa2EDPfjvHsMfmI7tGqDV7xKGE8AAR6GXlpnnNfcZ+dgv/u2YqH2/PZvXBAo4VVnLJ1Cjuv3ACNrORoso6nkw7zDubTxATYKegopaqOkezY8QG2okJsLMvtxyL0cDlqdH42c088vUBSqvrm/b7fn8eT1+bSk29gwdX7GX7oWpePrqRvPJaDp6swM9u5omrmreC09E0jW/25nGiuIp6RyOnjQkhMaTrgzZqGxyYDYY2BfuwQc8IKxSKYcG02AA2/fEMLEZDs/7Cvzgjiaq6Bp5dfZTM4moKK2oJ97Xx1/PHMy3Wn9+8t5Orn9vAvy6bTHSAHZDC9cnvDlNV38CvlozGYmpbJGuaRmZRNdsyi5mVENhmn/rqOge3vraFVQfyeeMnM5kzKqh/XoDhjp4RVow4lBAeZAghuDAlss3+lfcsHcPZE8NZdTCfnZmlhPnaSAr1IjnUm9hAO+sOF/LWxkyKq+pYkBRMXnkN//5GNpOflRDAn84dR3SAnQ+3ZvGX5bv540e72JFZyr7cMuJ9DBRU1BHgaeHGuXF8tecky55dz91LkrlqRgz+nrIPsqNR42+f7OaVdRlNcT228hDPXDeNsWE+PPT5XnZkljIuwodwXxtHCyopqqzjzPFhLBodzCvrMnh9QwYxAXZumpdAapw/mgZeNhNhPrZOp/elZ5VS06D14SveTyghrFAMO1oOUwK5Zt979lhiAz356/LdNDRqPHzxRGxmI5c5J9b97ZM9LP3PKi5LjWZarD8vrDnKtuMlAGzLKOHJa6bibTM1naOxUeODbVk8uvIAmUXVAEyN8ePdn87BaBDszSnj62P1VO3K4cU1R9mSUUyAp4U/fZTO53ctaFdY9xRN05qe67DF6qOE8AhFCeEhxoR2+mECXDAlkgumNBfQxwoqyS2rYWZ8QNMidv2cOI4WVPLS2mN4WU08f8N0RM4eFi2a1/S4O05L5Dfv7uCfX+7nka8PMD3On8QQL7KKq/lufz4/mR/P7YsSKaup5yevbOaGFzbhZTNRVl3PrIRA1h4uIL+8lthAT6wmA/d9uof7PgWDgAunRHIgr5x7P9zVLFazURDh50G0v53EEC/OmRROaqw/QggcjRr/+HIfT39/hDgfA7Pm1DUbUvLpzmzWHCpgVkIgC5KCm4T7gGHzhfLcgY1BoVCcEoQQXDMrltFh3ny3L49LpkU13XdZajSzRwXy90/38Nam47y09hjeVhOPL0uhUdO4572dpN7/TdP+Uf4eWIwGjhRUMjnKl1vmJ1BV5+Chz/fx6rpjpMYFcMXT66isc/D6vq2YjYLHl03FbjVy44ubeHb1Ee5YnNgqxu8P5LNiZw57c8sYFezFw5dMbFPYtySzqIrbX99KoJeF/109DQ/LMB0SZPWBkozO91MMO5QQHubEBXkSF9TaN/bHc8YS5e/BguRgkkO9ScvZ0+x+H5uZp66ZRnpWGSvSc/jhoGw4X1nbwO/OGsNPF44C5ASnd26dzW2vbaXO0cj9F05gbLjsyeho1JoyvHuyy0g7kMeSsaEkhXqjaRpbjxeTU1qDQMjpT8VVZBZVkVlc3fSGEeFrY1SIFxW1DWw7XsKZ40NZufcky57dwJNXTyU2wM5/vjnAY98ewmI08ObGTMxGwcUpUdw8P57oADv1jkY+2ZHDZ7uySQ715qZ58UT527v8GlbWNnDXW9tJifHjtoWjmlk6SqrqWHWwgJ2ZJWQWV+FtMxPua+Muiw8mlRFWKEYU0+MCmB7X2k4W5W/n6WtTqW1wkJ5VRrS/ByFOm0NSiDdf7s7FYjJQ72jkUF4F+eW13HVGEudNisBgEGiaxprDhfzjy/3YLUb87Bb+MAOmTE3F22ZqslycNSGMx1YeZGFycLOEyYYjhdz0kkxWJIV48eG2LOodjfzniil8sDWLL3bnkhLtx7Q4fw7lVbA9s4QQbxuR/h488tV+Ghwa6dml3PLqZh69MoUfDhVQUdPA5alRHXqfNU3j398cpDC7nkUt7mts1DicX0FiiNfgyDRbvWVdh2LEoYTwCMVkNHDz/IQO9xFCMDHKl4lRvvx2qdzW4GhstfD52S28ecusVo93tzmMi/BpNkxECMG02PaHTVTUNvBlei7f7ssjs7iKkqp6Hrp4IstmxPDEe9/w+PYKFv8rDYvJQF1DI5enRnHfBRPYl1vO+1tO8M7mTN7enNnsmLGBdjYcKeKVdRmcPTGcWxck0KhpPLbyEJlFVVw+XV62fGXtMVbuy+P+Cydw7qRw7v1wF9/sPck3e0+y/kghtyxIoN7RSNr+fN7dfILqegcWk4GYADtl1fXklddy2RQLMUoIKxQKN6wmI9Ni/Ztta7k2toUQggcvmsCP/r0KR6PGKzfNIHP35laP+8t549mRWcKyZ9bz/A3TmREfQHZJNbe/vpWYQDsf3TFXJjm+P8zDn+9j07EiTpbVEuZj49t9eU3HCfKyUlpdR71DY1SwJ89dP53Nx4q45/2dTP371037fbIjmyeuSsFiMpBdUkNsoB2b2ZUxfnTlQR5beRABXJ5ZwmS3VnKPrjzIoysPMj8piL+cN57EkL6tUiurqUfT5GTBLmFT1oiRihLCim5xqjpJeFlNXDItqtklRp0JQSa++MVs1h8pZH9uOcmh3iybEY0QginRfkyJ9uPnpyfx5e5cymrqqWtoZEFyMCnRfuSU1vDS2mO8seE4n+zIBuRCGRfkyd8/lVlxu8VIhJ8HP39rGyt25fB5ei6/WpJMkLeVvyzfzeqDBYC0clwwJZKrZ8YwIdIXs9FAcWUdKX//mpN1NmLqqxCN9a3iVygUiu4S5W/nnVtn420zERvoSWYb+4T52nj3tjlc+/wGrn1+A4khXpwsq6W2oZFnrk3FxyZF4a0LEiipqueTHdk8cvlkLkqJpKCijl1ZJSSFeBPl70Gdo5GjBZXEBXpiMxuJD/LEYjKwPbOEpePDyCyu5g8f7mLOw99S29AIyCl9U6L8GBfhg9Vk4OlVR7hgSgTf783hdx/sYvmdczEbDezJLuO/3x1iSrQf2zNLOPM/q0iJ9mNOYhDXzIohxLt1UaA7mqZRUFFHsHfbbek0TeO65zeyP7ecG+bGccv8hFZ2OU3T2J1dhqfVRGyAHYPVW3aN0IZADYqiT1FCWDEkiQ/yJL4Ny4dOsLeVa2bFttoe4efBvWeP5c7TEnl38wk0TeOK6dF428zsyCxhd3YZZ08Mw2Y2cucbW/k8PZeFycHcsTgRg0GwIDmYE0VVTRnglv1B/T0tBHlZyKo2MR0wNVT19VPvN0RjA3z2K0i9CULHDXQ4CoWiBe3Vh7gT6efBu7fO5sEV+yipqiPa3871c+KaZVyFEPzurDH87qwxTduCva2cNia06bbVZGRMWPOMs3sdykxgTJg3b206TrivB5F+HuzOLmXjsWLe3pRJdb2D+UlB/OuyyTz2XiGPbyvjwRV7WTYjht+8twM/u4UXb5iOQ9N4cc1RfjhUyBPfHuTNjcd5YlkK0QF23tmcSU19I7NHBTI9zh+7xURjo8a9H+7i7c2ZPHNtKkvGyZi3Hi9mbJgPHhYj2zNL2J5ZwvgIH576/jCvr8/gnqVjWDYjpulK5XOrj/LAir0AeFqMfJxiIFFzYGis69kvRzFkUUJYMSLxsZlbta+bHO3X7NLd/66Zxmc7c1g8JqTJFxzpJxf8jhgV7MWxSpl5MTVU9nHk/UdA0RZIfw4qTsIVrw10OAqFoocEeln5f5dP7vfzTIj05f7IiU239W5HjY0aeeW1hPpYpQ0u1MQFUwJ5cc0xXlxzDICnrpnalKX9zZlj+M2ZcOBkOT99dQtXPbcBTdPQAJNB8NT3h/G2mlg2M4b88lo+3JaFv93Mb9/fyeSo+Xy4LYuHPt/HOZPC+e9VU3l1fQZeVhNv3zqbrOJq/rp8N3/8KJ23N2XyyyVJOBrhwc/3cub4UE4fE8qfPk7nQDEkMrSSF4q+QQlhhaIdzEZDm23sOiMxxItDO6RPbigJ4fAcp/dv32dQegJ8W9tSAHnp8PBKyFgLC+4Bc8eXMRUKxcjCYBCE+TZfF/59+RRuWzSK9KwyNE1j6YTwVo9LDvXm4zvn8ug3B7GaDVw5PYYgLyubjhXx7pYTPLf6CI0a3L0kmbMnhnPu46u5+H9rOVFcTWygnc925rAwKZNPd+Zw5fRovKwmRod588ZPZvLx9mz++eV+fvzSZgAmRfnynytS8LAYeWrVYXJrpSg3OobOmq3oG7okhIUQS4FHASPwnKZpD7e4/wbgn0CWc9MTmqY914dxKhRDhqQQLz6ttYK1F0I4ayuEjDt1IrM8l8DCLTD+Ytj9IWx+EU7/U+v9cnfBJ3dB1hZ52zMEZv20b2LQNFj7GBhMMHkZ2NsvplQoFEMLg0EwJsynld2iJd42M388t7k1a0FyMAuSg7nnzNFkFFYxL0kODfnTueP4w4fpnDc5gn9eOokL/7uGe97fCdDMGqf35z9nUjgfbsti1YF8/nTuuKZWcJF+Hpwo1a/iVffZc1YMDToVwkIII/BfYAlwAtgkhFiuadqeFru+rWnanf0Qo0IxpEgM8aYM6V/2Lj8ADXVg6kZf472fwttXQ/JZcOXrYDgFfTt3vIWgERbfC/XVsOUlWHgPmNw80GXZ8Nql8ufzHoWd78APj8DU68BogS0vgskG0TOh5Dgc/Aosdki5FgJHdR7D+ifh6z/Ln7/5G8y+HU7/CwyG1koKhWLAiQ6wN7WKA7hqRgwp0f4kh3phMhr4h1MMp8YFkBzaetqp2Tlt9XLnoBOdSD8PjmfLddboUNaIkUZXMsIzgEOaph0BEEK8BVwAtBTCCoUCaY3I1gKptviTcPR1+OenkHI1zL0LijPgqz9C0WEInwLhkyEoCUInQPgkqC6Gz+4GeyAc+FwKwzMfaP9kmgZ1lWB1FsI4GiB3J4SMBbPTy1xwUP7ckdVh22uU+I7DLygJZvxEnvu1S+R9vpEw8XL47n6oq4CbvoLQ8RCYBC+dDRufgextsOej5sc1eYCjDn74N8QvgGk3wJhzm4trncPfytdl7PlSgK99XD6uoRZ+9IAU1fn7YPYd3f59KBSK4YkQolkLuUlRfjx/w3RiA7reJx5kEfX2KrPzKp4SwiONrgjhSGjWqeUEsmC0JZcIIRYAB4BfaprWqruLEOIW4BaA0NBQ0tLSuh1wRUVFjx43EKhY+4fBHqumaTQY7fzC93Fu8t1GbBuE2F8AAB0/SURBVNkmQtY/hbbhGQxaA7WWAIr9p+CVewT7kTQMmgOAgsDpaMJEUEU+W6b9i7DclUSte4Kq7R8gtEbKfJI5knAttbYQADyqskk6+DQBxdup8IynzCeZwMKNWOuKKfcaRfqEe/EtTWfMvidwGK2kT/gDpb6jicxagW/pHor9J1NjCyPqxHICiw5yLO4WStLSQBNM8k/BdvIwdRY/PLO2Yd75NhqC9Am/p3BvPuxNA2CS/2QCvvkLAIdG3UhRwDR8yvZTZ/GjxG8SpoYKwnJXEp7zFR7v/ZgGo41Kzziq7FE0GiwIzYFn5TG8yw9TZY9mW+BVOPYVgv8yEiOriFr/JLVb38JaVwRA4dblVMfePqh//wqFYuBYPDqk24+J8POgApk4UEJ45NFXxXKfAG9qmlYrhLgVeBk4reVOmqY9AzwDkJqaqi1atKjbJ0pLS6MnjxsIVKz9w1CIdcyeNZRbjFRFLSB00Z+h6Chiw9NgD8A663bCmjK49dJGsPcTglb/PznZaO4vSF1yEziuh7QHsRcdAcBj/xeEFm2EhMVyvxObZXZ11h14ZW/DK+s7eV/8fLzT/o/Z2+6G2lKInYuh4iQpu/4qs88n08EeREj+WhmDPRBO/zMlDVNcr+ti+e9rB6ivgQNfIIxmJo45p/kTTXwEXrkAFt9LYrvZ2ouhsRGOfIvpwJf45qbjW7gTGusBAcGjYfwSvGbdznxft+LERYvgqz9izVgLMx+G+koCP/sV8+rux3vSuTJue5D87un8bg+U462VnUKhUHSRCD8b5ZoUwsoaMfLoihDOAtwNNVG4iuIA0DSt0O3mc8A/eh+aQjF0SQzx4vsD+ZDk/BcLiIezHm69o9Es/bPzfgEp18CBL2DiZc77THD6n137lp6AlX+HnO1S8KVcDQt/C95h8n5NcwnAxDPgvZsg5hJY+n9yYtJby6D4GFz6Ioy/CPL2QP5+SD4TLJ7QXpbVbIPxF7Z9X1Qq/DZDxtoRBoOMKfGMjvdzR4jWthDPEEwf/wo2PgsNNe2cywQWL/khwWiRr7HR0vzL5PbzxMvaf34KhWLYEzmUM8L11XLNM3Zxgp6iFV0RwpuAJCFEPFIAXwlc5b6DECJc07Qc583zgb19GqVCMcRIDPHivS0nqKzvRqGbZ5AUw+3hGwUXP93+/e5Z0JCxcPta121TINz4BWgO14IZOl5+9ZbORHBfMvZcNpz0kpnrukqoKpRflc7vVQVQWSDvc9Q1/2pw+7m+GmpK5baaklMXv0KhGHSE+dpoFEbqDbahlRHWGuHZ02SNySXPDnQ0Q5ZO38E0TWsQQtwJfIlsn/aCpmm7hRD3AZs1TVsO/FwIcT7QABQBN/RjzArFoCcxWFofcioaBzgSNwwG4NSMyD4lWDzll1/MQEeiUCiGMFaTkWAvK1WaF8H5a2Hb6zDx0rYLe9sjcyN4hYB/XL/F2ZKAom2uK3tL7gOf1r2ZFZ3TpXdFTdNWaJqWrGnaKE3THnBu+7NTBKNp2u81TRuvadpkTdMWa5q2rz+DVigGO2MjfDAIeG1vHftzywc6HIVCoVB0QISfBy/63k6jwQYf3w6PpcDWV6SdbM2j8P7N8N1Dsr1lQ4sxzHn74MWz4cVzoKrolMUcmfUpePjLK31bXzll5x1uDKP0kEIxeIj08+DJq6dSWNPIuY+v5oUfjqJp2kCHpVAoFIo2iPTzYHntNDZNfwyu+UDWXiz/GTw6WbaxPPYDfP9/ssf741OddQq10OiQ+1nscjz98p/Jeo3e0Ngo6zo6ouAQgUVbYeZtMOo02fvd0dB6v5oy2PkuHF8PtRW9i2uYokYsKxT9xNIJ4dRn21me6819n+5hT04ZD1w0AavpFAzIUCgUCkWXifCz8c3ek2jYIPF0KS73r4DCQ7L/eeAoWVtwdBWs/n+w4tey33ncfDixES56WtYpfHkvfHS77NDjFQrRMyAw0VXDoWnSyuATATYfOL4Bvv07BI+BpQ/JGoY3roCTu+En38pC67bY+AyNwoRh2g2y1uPtq2X/99Fny65CNaVw5Ht57Mp8+RhhlP3sF/9B3t77sXxO8QukYN76itz33EdkprkraJp8jU5slvUnEy/t1e9hIFBCWKHoR7wtgqevmcajKw/y6MqD7Mgs4U/njmNBcvBAh6ZQKBQKJ5F+HtQ2NFJe79wgBLRsF2n2kF12kn4khwB9/RfY/prshjPpCrlPzk7Y+ZYsZNPxDIEJF0NkKmx8Gk5skqI0KEkOCvLwh2OrpaB01MHxdWD2hLevlQOMSjNh59sgDPLr6Co4vp680IWEeYdC8lLwiYR3rpc2CXeiZ8pOQXWVcujRD49Axlo5vKlgf/N9jRaXUL/m/c49xwWH4MNbIGuLa1tgIkRM6fLrPhhQQlih6GcMBsEvlyQzOdqXv32yh+te2EhyqBehPjZGh3rz00WjCPLqRlGGQqFQKPqUCD/ZPq2wugsFzkLIrHHCYimIo6a5Mr4XPw0XPSXbOxZnyGzxwa9h8wuw4SnwiYIzH5Re4hMbYdyFMPfnkP4BfPoLKUQveQ6svvD6pfD0AjmJFOEU1xqETYQFv+GQYzJhIDv3XPCEPI/VR/ZSt/nITkPxC12xjV4KCYvg019K4Xz5qzLTfXQ1GIww4RI5mfStq+V5ExbK6aeTrwLPwOavwZaX4YvfyYLCs/8FkVPh1YulfWTZm9LecWITRE47tZ2FesDgjk6hGEacNiaUuYlBvLb+OGsPFVBQUctLa4/x9qZMbpgbh6+HGaNBcM7EcEJ8bAMdrkKhUIwYXEK4G/5egwGS2uiNLoTMHoeMkV9Tr5MZ2JydEDNb9jFvydRrZdvLhlqImyu3nfFXKSxn3wlzfwH2AJkxdnazaHDv/T7qNPnVGZOvhNFnyV7rBqdNz72NZsIiuOEzSHsYMtbBrnfh+3/AnJ/D5CvAOxw+v0cK+4RFcOFTrszx7Dvhu/vhxBbY/Dxsf10+34sHd2s3JYQVilOI1WTkpnnx3DRP+r4O51fwwGd7efzbQ037PPT5Pq5IjWZuYhCxgXYcjRr55bXEBNoZ5WzLplAoFIq+I1IXwjX9VNTs4S8zrB0Rldr89rxfSAFqcOtr0J2Wbu1h8+34/ogpcNVb8ue8vXKQ03f3yy+LN9SVS2F++p9dYhpg5i2w7gk5bbSuXA4r2v8FPDWXifYkKHxdtpcLmwCewdDYIDPYIWP75nn1ECWEFYoBZFSwFy/cMJ3S6nqEgPzyWp5ddYS3Nh3n1fUZrfafER/AxSmRzEwIJC7QjlCjhBUKhaLX+NnNeJiN5FUNot7v0FwEDwQhY2HZG7JF3NFV0g+cfKb0PLfE5gtzfiYL9E7/C8y/G4qOwFd/wnJiL2RugPT3mvunAQzOCauewfIDgz0APALAZGs+BVSfFuoTCfHz++wpKiGsUAwCfD3ktDcfm5mHL5nEH84Zy7GCKjKKKjEbDQR6Wth0rJg3Nx7ndx/sAiDIy8qMeH9Gh/pQVFlLaXU9cxKDWDohDG+riYraBjwtJgwGJZYVCoWiI4QQLEgOYuWek2w7XkxKTBe7JowUdJtHZ8y7W/qegxLl7YAEuPJ1tqSlyYmg9dWyQLCmVBYMVuZDzg5ZKFhVJAv1qovkzy0L/3QSlyghrFAMd7xtZiZG+TIxynUJKzUugFsXJHA4v4KNx4rYfKyYjUeLWLErF2+bCZvZyEfbs7n3g11ogKNRI8rfg4tTIpkS44cQgrLqeo4VVFFQUYvVZMDHw8zM+ACmxqpFX6FQjGwevngSS458w22vbeWTn80j2FsVMXcbg8ElgtvC7AERKc23tZVdBtmjuaFW+qL1r4baPrdRKCGsUAwhDAZBUqg3SaHeXD0zFoCaegc2sxFN09iWWcLXe05iEOBlNbP2cAFPfHeIxha2N18PMw2ORqrqHWga2C1G/MyNxB9az4RIX2bEBTAzIRAva/tLhKZpypqhUCiGDf6eFn6WYuWhTXXc+upmXr1pJp4drIGKfsZglINKsPfradRvWKEY4tjMslhBCMHUGH+mul3Su23RKPLKasgurUHTNOwWE7GB9qbHlFbXs+5wAeuPFLHrcCYVNQ288MNRnv7+CBaTgQVJQYT42DheWEVFbQPeNhOaJov8CipqmRTlx4z4AEYFexHhJztd1NQ78LKaCfe1EeHngVFZMxQKxRAh1sfIvy+fwh1vbOXmlzfz4o3Tm9ZLxfBECWGFYpgT4mNrtx2br4eZpRPCWTohnLS0fBYtmkdNvYOtGcV8szePL3fnsiWjmJhAT3xsJsprGtCA2QmB+NktbMss5plVR3C0TDk78bebOX1sKLEBdvbklJFRWIWjUcNmMXLRlAgumRaFp8VEUVUd+3PL2ZtTxqgQLxYlBzfLNtc7GskqruZoYSU/nKjHdqSQpBAvAlX/ZYVC0cecNTGcRy6fwi/f2c6yZ9dzy/wETh8bisU0wIVrin5BCWGFQtEMm9nInMQg5iQG8efzxnW6f22Dg5ySGrJLqhFC4GExUlZdT1ZJNRuOFPLl7lzKaxqIC7STEOyF2SjILqnhr5/s4cEV+3BoWishnRTixZRoP04UV3O8qIqc0upm9o7n09cDMDnKl7MnhpMc6o2f3Uy9Q6Oosha7xcS4CB8CPS1U1jmorXfgb7eowkGFQtElLkyJBODhz/dx2+tb8bGZmD0qkEWjQ7g8NVpd6RpGKCGsUCh6hdVkJC7Ik7ggz1b3LZsRQ72jkdqGxlZ+4+2ZJXy2MxuryUigl4XEEC9Gh3mz5lABz/9wlLQD+UT7e5Aa509MQCTRAXbigzw5vHs74UkTSc8q5cvduTz0+b52YzMZBA1OBW02CkK8bYT5yq/EYC/GhHkzJcaPcF+Pvn1RFArFkOfClEjOmxzB6oP5rNiVw9rDhXy5+yQlVfXctmgUAIUVtfh4mDEbVbZ4qKKEsEKh6FfMRkObbxJTov2YEu3XavtFKVFclBLV7vEqjxlYmBzMwuRg7licSG5pDdml1ZRU1WE2GvC3WyirqWdPdhkFFXUEeJqxGA3kldeSW1pDblkNu7NK+XxXDo0a/GpJMj87PalPn7NCoRgeGA2CRaNDWDQ6BE3TuO21rfz76wMsGh3MwbwKfv3ODoK9rdyyIIHLU6PxsCg/8VBDCWGFQjGk0TO8LZkzKqjDx1XXOTiYV06AZxvjThUKhaIFQggeuGgCZ/5nFde/sJG88lqmOVtP/mX5bv7fV/u5dFo0Uf4erD1cCMBvl44mKdR7IMNWdIISwgqFYkTiYTEyKap1RlqhUCjaI9DLykMXT+Inr2zmnEnhPHL5ZCxGA5uOFfPKumO8uv4Y9Q6N2EA7JVX1nP3Yam6YE8ePxocxKcoXq8mVMa5raMRsFKoN5QCjhLBCoVAoFApFF1kyLpR1vz+NUG9bUwHujPgAZsQHUFRZR029gwg/Dwoqannws708u/ooz64+is1s4PSxoSxKDmbNoQJWpOdyeWoUf79gghLDA4gSwgqFQqFQKBTdoL0CW3erVZCXlUeumMIfzx3HpmNFrDqQz+fpuXy2Mwdvq4lpMf68tv44QV5Wrp8dx9ubMykor2VqrD/TYv0Jdba93JFZwqoD+YwN92FGQgA+NvMpeY4jBSWEFQqFQqFQKPqJAE8LZ44P48zxYfz1/PHsyS4jOdQbm9nAPe/t5D/fHOR/aYepbWjEYjLw3A9HAYjy98DLamJfbnnTsYwGwRljQ7h+Thy1DZqa8NkHKCGsUCgUCoVCcQowGw1MduuW89DFEzEZpZC9YU488UGe7M4uZUtGMVuPF5NXVsvfzh/POZPCOXiygu/25/HO5ky+3H0SALFyBfFBnsxLDGJuYhCzEgLx9TBTU++gqs7RlKGudzQ2CXDV2aI5SggrFAqFQqFQDAAmo4GHLp7UbFtKjD8pMf6t9g3ysjJ7VCB3L0nmy925rNm6m9CoWNKzSnlvywleWZeBQcj98itq0TQYFezJ2HAf1hwqoLiqnlAfK3ednsz8pCCsJgN1jkbKqhuwW4zEBNhH5NAhJYQVCoVCoVAohgg2s5ELpkTiW3KQRYtGA7IDxfbMEn44VEBWcTXRAR7YzEbWHS5kw9Ei5icFMy8xiLc2HefeD3e1eVxvq4mJUb7MGRVIalwA4b42fGxm8itqKaioJSXav1k2ubS6nn05ZQR5WxkV7NXmMavqGlh9sIAt2Q1U7sxhzqhA/AdZy0olhBUKhUKhUCiGMBaToalzhTs/XTiq2e3LUqNYd6SQ7JIaauodWEwGfGwmSqvrSc8qY0tGMf/66kCb54gLtPPgxRMpqarnybRDpGeVAXKC52+XjuHH8+JZd7iQVQfzqWtopKCilm/35VFV55AH2LmVSD8PXrlpRrvCeSBQQlihUCgUCoViBCCEaHfY0BXT5feiyjp2ZZWSX15LaXU9wd5WDAL+8cV+rnp2AwAJwZ785szRjA335u1NmTywYi9PfHeI0up6LEYDNrMBD4uR8ydHcMGUSDL27SAyeSK/eGs7l/5vLY8vm8rcxECEEOzNKWNzRjEBdgueViO5pTUUVdUxNcaf1Fh/TP08vloJYYVCoVAoFAoFILtcLEwObrX9tDEhvLHhOKE+Ns6eGI7R6SdePDqEV9ZlsPZwAWdPDOfM8WHYzM0L8mozDcxPCub92+Zw/Ysbueb5DaTE+OHnYea7/fntxuLrYeasCWFclBLJ9LiAfvEwKyGsUCgUCoVCoegQu8XEzfMTWm0XQnD9nDiunxPX6THigjz54q4FvLslk+dWH+VYQSV3L0nmopRIKusaqKhpINRHepPXHSngy90nWb4jm7c2ZRLkZWXR6GDOHB/GknGhffa8lBBWKBQKhUKhUJwSPCxGrpsdx7WzYjvsgbx0QjhLJ4RTVdfAV7tPsnJfHl/tzqW0ul4JYYVCoVAoFArF0KWrg0DsFhMXpkRyYUokDY5GSqvr+zSO/nUgKxQKhUKhUCgUfYDJaCDQy9qnx1RCWKFQKBQKhUIxIumSEBZCLBVC7BdCHBJC/K6N+61CiLed928QQsT1daAKhUKh6BpqzVYoFIqu0akQFkIYgf8CZwHjgGVCiHEtdrsJKNY0LRH4N/B/fR2oQqFQKDpHrdkKhULRdbqSEZ4BHNI07YimaXXAW8AFLfa5AHjZ+fN7wOmiqy5ohUKhUPQlas1WKBSKLtIVIRwJZLrdPuHc1uY+mqY1AKVAYF8EqFAoFIpuodZshUKh6CKntH2aEOIW4BbnzQohxP4eHCYIKOi7qPoVFWv/oGLtH4ZKrIMlztiBDqC/UWv2oEbF2j+oWPuHwRBrm2t2V4RwFhDtdjvKua2tfU4IIUyAL1DY8kCapj0DPNOVaNtDCLFZ07TU3hzjVKFi7R9UrP3DUIl1qMQ5gKg1u4eoWPsHFWv/oGLtG7pijdgEJAkh4oUQFuBKYHmLfZYD1zt/vhT4VtM0re/CVCgUCkUXUWu2QqFQdJFOM8KapjUIIe4EvgSMwAuapu0WQtwHbNY0bTnwPPCqEOIQUIRceBUKhUJxilFrtkKhUHSdLnmENU1bAaxose3Pbj/XAJf1bWjt0qvLdKcYFWv/oGLtH4ZKrEMlzgFDrdk9RsXaP6hY+wcVax8g1NUwhUKhUCgUCsVIRI1YVigUCoVCoVCMSIaUEO5sbOhAIYSIFkJ8J4TYI4TYLYS4y7k9QAjxtRDioPO7/0DHqiOEMAohtgkhPnXejneOWj3kHL1qGegYAYQQfkKI94QQ+4QQe4UQswfr6yqE+KXz958uhHhTCGEbLK+rEOIFIUSeECLdbVubr6OQPOaMeacQYuogiPWfzr+BnUKID4UQfm73/d4Z634hxJmnMlZFxwzWNRuG3rqt1uy+R63Z/RrrkFmzh4wQFl0bGzpQNAC/0jRtHDALuMMZ2++AlZqmJQErnbcHC3cBe91u/x/wb+fI1WLkCNbBwKPAF5qmjQEmI2MedK+rECIS+DmQqmnaBGSR0pUMntf1JWBpi23tvY5nAUnOr1uA/52iGHVeonWsXwMTNE2bBBwAfg/g/D+7EhjvfMyTzrVCMcAM8jUbht66rdbsPkSt2X3KSwzhNXvICGG6NjZ0QNA0LUfTtK3On8uR//iRNB9j+jJw4cBE2BwhRBRwDvCc87aA/9/evYVYVcVxHP/+UpFRQc1ADIsxkh6iUulBKiKshzKxhx40hG6+5EOXl9LwKegpIsSKogvSRRIqMwkSS6WCUkswbxVpShljjg9jWGFi/x7WGtqNTo40Z/bac34fOMw+65zZ8z//c86fNXutvRdzSEutQiGxShoP3Eg6w52I+DMieig0r6STTzuUrss6BuiikLxGxKekqwNU9ZfHO4DXI9kKTJA0ZWgiPXusEbExr4AGsJV0bdzeWNdExMmIOAjsJ9UKq1+xNRuaVbdds1vGNXsQNL1mN6kjPJBlQ2snqROYCWwDJkdEV37oCDC5prD6WgE8BvyV708Ceiof2lJyOw3oBlblIcFXJI2lwLxGxM/A08CPpGJ6HNhBmXnt1V8eS/+u3Q98mLdLj7WdNea9aUDdds0eZK7ZQ6romt2kjnDxJI0D3gUeiYhfq4/li9XXfokOSfOAoxGxo+5YBmAkMAt4ISJmAr/RZ0itoLxOJP2nOw24GBjLmUNFxSolj+ciaTlpSHt13bHY8FB63XbNbg3X7KHRhJrdpI7wQJYNrY2kUaRiujoi1ubmX3qHJ/LPo3XFV3E9MF/SIdJQ5RzSnK4JeXgIysntYeBwRGzL998hFdkS83oLcDAiuiPiFLCWlOsS89qrvzwW+V2TdC8wD1hUWQWtyFgNaMB705C67ZrdGq7ZLdaUmt2kjvBAlg2tRZ6v9SrwTUQ8U3mouozpPcD7Qx1bXxHxeERMjYhOUg43R8QiYAtpqVUoJ9YjwE+SrshNNwP7KDCvpOG12ZLG5M9Db6zF5bWivzyuB+7OZyLPBo5XhuNqIelW0tDw/Ij4vfLQemChpNGSppFOFtleR4x2hmJrNjSnbrtmt4xrdgs1qmZHRGNuwFzS2YcHgOV1x1OJ6wbSEMUuYGe+zSXN49oEfA98DFxYd6x94r4J+CBvX0b6MO4H3gZG1x1fjmsG8FXO7TpgYql5BZ4AvgX2AG8Ao0vJK/AWaR7cKdJRm8X95REQ6Wz/A8Bu0lnVdce6nzSvrPf79WLl+ctzrN8Bt9X9OfDtX+9lkTU7x9a4uu2aPeixuma3LtbG1GyvLGdmZmZmbalJUyPMzMzMzAaNO8JmZmZm1pbcETYzMzOztuSOsJmZmZm1JXeEzczMzKwtuSNsRZJ0WtLOym3ZuX9rwPvulLRnsPZnZtbuXLOtqUae+ylmtfgjImbUHYSZmQ2Ia7Y1ko8IW6NIOiTpKUm7JW2XdHlu75S0WdIuSZskXZrbJ0t6T9LX+XZd3tUISS9L2itpo6SO/PyHJO3L+1lT08s0MxsWXLOtdO4IW6k6+gyzLag8djwirgKeA1bktmeB1yLiamA1sDK3rwQ+iYhrSGve783t04HnI+JKoAe4M7cvA2bm/TzQqhdnZjbMuGZbI3llOSuSpBMRMe4s7YeAORHxg6RRwJGImCTpGDAlIk7l9q6IuEhSNzA1Ik5W9tEJfBQR0/P9pcCoiHhS0gbgBGlp0HURcaLFL9XMrPFcs62pfETYmij62T4fJyvbp/lnvvztpDXbZwFfSvI8ejOz/8c124rljrA10YLKzy/y9ufAwry9CPgsb28ClgBIGiFpfH87lXQBcElEbAGWAuOBM45wmJnZeXHNtmL5PycrVYeknZX7GyKi93I8EyXtIh0huCu3PQiskvQo0A3cl9sfBl6StJh0FGEJ0NXP3xwBvJkLr4CVEdEzaK/IzGz4cs22RvIcYWuUPN/s2og4VncsZmb231yzrXSeGmFmZmZmbclHhM3MzMysLfmIsJmZmZm1JXeEzczMzKwtuSNsZmZmZm3JHWEzMzMza0vuCJuZmZlZW3JH2MzMzMza0t/Pai69Jg6rcAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYHGqeZm2cbG",
        "outputId": "1ca0fbea-ed7c-459b-8076-554e9c19ebbc"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9160000085830688"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJf12ZWC2cbG",
        "outputId": "3243dd19-3957-44de-bf12-472161eccaf8"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08399999141693115"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3-mnyHm2rRi"
      },
      "source": [
        "#### Plotting final graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akEmN5FH2szJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "cf019562-79c1-49b9-8d7c-8cbc7e12f5a7"
      },
      "source": [
        "plot_final_graph(\"R_29_\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
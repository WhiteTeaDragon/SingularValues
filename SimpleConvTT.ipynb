{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleConvTT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4AT4gyNuDQaA",
        "ZIOsm1xkDbtG",
        "KSatFAHUVVZM",
        "wfvhZ-l0rsUd",
        "Xmr9s-v4rJu8",
        "NRChluDlrVYz",
        "J3VcnSJ9rahO"
      ],
      "authorship_tag": "ABX9TyOfa6UsojWo0iTlcCbvDhGU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WhiteTeaDragon/SingularValues/blob/main/SimpleConvTT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "praf7vwRHu5P"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import regularizers\n",
        "import numpy as np\n",
        "import random as rn\n",
        "from tensorflow.python.framework import tensor_shape\n",
        "from tensorflow.python.keras.engine.input_spec import InputSpec\n",
        "import six\n",
        "import functools\n",
        "from tensorflow.python.ops import nn, nn_ops\n",
        "\n",
        "np.random.seed(1)   \n",
        "rn.seed(1)   \n",
        "tf.random.set_seed(1234)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AT4gyNuDQaA"
      },
      "source": [
        "### Проверка функции, превращающей тензорное разложение в ядро"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8De736fxe_G"
      },
      "source": [
        "def full_tt(K1, K2, K3):\n",
        "    \"\"\"Converts a TensorTrain into a regular tensor or matrix (tf.Tensor).\"\"\"\n",
        "    res = K1\n",
        "    K2_reshaped = tf.reshape(K2, (K2.shape[0], -1))\n",
        "    res = tf.matmul(res, K2_reshaped)\n",
        "    res = tf.reshape(res, (-1, K3.shape[0]))\n",
        "    res = tf.matmul(res, K3)\n",
        "    res = tf.reshape(res, (K1.shape[0],) + K2.shape[1:-1] + (K3.shape[-1],))\n",
        "    num_dims = len(K2.shape[1:-1])\n",
        "    return tf.transpose(res, list(range(1, num_dims + 1)) + [0, num_dims + 1])\n",
        "\n",
        "def simple_full_tt(K1, K2, K3):\n",
        "    kernel_shape = K2.shape[1:-1]\n",
        "    filters_shape = (K1.shape[0], K3.shape[-1])\n",
        "    res = np.zeros(kernel_shape + filters_shape)\n",
        "    if len(kernel_shape) == 2:\n",
        "        for a in range(kernel_shape[0]):\n",
        "            for b in range(kernel_shape[1]):\n",
        "                for i in range(filters_shape[0]):\n",
        "                    for j in range(filters_shape[1]):\n",
        "                        for alpha in range(K1.shape[1]):\n",
        "                            for beta in range(K2.shape[-1]):\n",
        "                                res[a, b, i, j] += K1[i, alpha] * K2[alpha, a, b, beta] * K3[beta, j]\n",
        "    elif len(kernel_shape) == 3:\n",
        "        for a in range(kernel_shape[0]):\n",
        "            for b in range(kernel_shape[1]):\n",
        "                for c in range(kernel_shape[2]):\n",
        "                    for i in range(filters_shape[0]):\n",
        "                        for j in range(filters_shape[1]):\n",
        "                            for alpha in range(K1.shape[1]):\n",
        "                                for beta in range(K2.shape[-1]):\n",
        "                                    res[a, b, c, i, j] += K1[i, alpha] * K2[alpha, a, b, c, beta] * K3[beta, j]\n",
        "    else:\n",
        "        raise ValueError(\"Only for 2D and 3D images.\")\n",
        "    return res"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee5KnbQ60Q6m"
      },
      "source": [
        "def check_funcs(rank, kernel_shape, filter_shape):\n",
        "    K1 = np.random.rand(*(filter_shape[0], rank))\n",
        "    K2 = np.random.rand(*((rank,) + kernel_shape + (rank,)))\n",
        "    K3 = np.random.rand(*(rank, filter_shape[1]))\n",
        "    clever_wrong = full_tt(K1, K2, K3)\n",
        "    simple_right = simple_full_tt(K1, K2, K3)\n",
        "    return np.allclose(clever_wrong, simple_right)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL76zZBw0-cN",
        "outputId": "a8a2a505-639e-41b2-d843-2dbc69b27252"
      },
      "source": [
        "check_funcs(2, (2, 2), (2, 2))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFhAZR1qDsH0",
        "outputId": "939238f5-db63-4df5-fe35-453f68ed2796"
      },
      "source": [
        "check_funcs(2, (2, 2, 1), (2, 2))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLMZGS2hDvbp",
        "outputId": "a37653f5-9ccc-45e4-8c73-452159bb28bc"
      },
      "source": [
        "check_funcs(2, (2, 2, 2), (2, 2))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWpcGgf627IK",
        "outputId": "137b00fc-d728-495c-ba3d-7426004aeecf"
      },
      "source": [
        "check_funcs(4, (7, 7), (32, 32))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8dTpq07DxzB",
        "outputId": "21add8d0-c6fc-4c11-bc1d-35c34017043d"
      },
      "source": [
        "check_funcs(4, (7, 7, 7), (32, 32))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hggAxE9ZCzxW",
        "outputId": "296628d8-b680-4ba4-8b43-520150155374"
      },
      "source": [
        "check_funcs(4, (7, 7), (16, 32))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAJGqwRMD30K",
        "outputId": "2f53e8c4-8e43-4531-a9fe-c995461d9551"
      },
      "source": [
        "check_funcs(4, (5, 5, 5), (16, 32))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIOsm1xkDbtG"
      },
      "source": [
        "### Свёрточный 2D слой с ТТ-разложением"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwjwq1q3FtSB"
      },
      "source": [
        "class ConvDecomposed2D(tf.keras.layers.Conv2D):\n",
        "    def __init__(self,\n",
        "               filters,\n",
        "               kernel_size,\n",
        "               decomposition_rank,\n",
        "               strides=(1, 1),\n",
        "               padding='valid',\n",
        "               data_format=None,\n",
        "               dilation_rate=(1, 1),\n",
        "               activation=None,\n",
        "               use_bias=True,\n",
        "               kernel_initializer='glorot_uniform',\n",
        "               bias_initializer='zeros',\n",
        "               kernel_regularizer=None,\n",
        "               bias_regularizer=None,\n",
        "               activity_regularizer=None,\n",
        "               kernel_constraint=None,\n",
        "               bias_constraint=None,\n",
        "               **kwargs):\n",
        "        super(ConvDecomposed2D, self).__init__(\n",
        "               filters=filters,\n",
        "               kernel_size=kernel_size,\n",
        "               strides=strides,\n",
        "               padding=padding,\n",
        "               data_format=data_format,\n",
        "               dilation_rate=dilation_rate,\n",
        "               groups=1, # does not support groups!\n",
        "               activation=activation,\n",
        "               use_bias=use_bias,\n",
        "               kernel_initializer=kernel_initializer,\n",
        "               bias_initializer=bias_initializer,\n",
        "               kernel_regularizer=kernel_regularizer,\n",
        "               bias_regularizer=bias_regularizer,\n",
        "               activity_regularizer=activity_regularizer,\n",
        "               kernel_constraint=kernel_constraint,\n",
        "               bias_constraint=bias_constraint,\n",
        "               **kwargs)\n",
        "        self.decomposition_rank = decomposition_rank\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_shape = tensor_shape.TensorShape(input_shape)\n",
        "        input_channel = self._get_input_channel(input_shape)\n",
        "        kernel_shape = self.kernel_size + (input_channel, self.filters)\n",
        "    \n",
        "        self.K1 = self.add_weight(\n",
        "            name='K1',\n",
        "            shape=(input_channel, self.decomposition_rank),\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "            trainable=True,\n",
        "            dtype=self.dtype)\n",
        "        self.K2 = self.add_weight(\n",
        "            name='K2',\n",
        "            shape=(self.decomposition_rank,) + self.kernel_size + (\n",
        "                                                    self.decomposition_rank,),\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "            trainable=True,\n",
        "            dtype=self.dtype)\n",
        "        self.K3 = self.add_weight(\n",
        "            name='K3',\n",
        "            shape=(self.decomposition_rank, self.filters),\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "            trainable=True,\n",
        "            dtype=self.dtype)\n",
        "        \n",
        "        # the rest is copied from Conv build function\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "              name='bias',\n",
        "              shape=(self.filters,),\n",
        "              initializer=self.bias_initializer,\n",
        "              regularizer=self.bias_regularizer,\n",
        "              constraint=self.bias_constraint,\n",
        "              trainable=True,\n",
        "              dtype=self.dtype)\n",
        "        else:\n",
        "            self.bias = None\n",
        "        channel_axis = self._get_channel_axis()\n",
        "        self.input_spec = InputSpec(min_ndim=self.rank + 2,\n",
        "                                    axes={channel_axis: input_channel})\n",
        "    \n",
        "        # Convert Keras formats to TF native formats.\n",
        "        if self.padding == 'causal':\n",
        "            tf_padding = 'VALID'  # Causal padding handled in `call`.\n",
        "        elif isinstance(self.padding, six.string_types):\n",
        "            tf_padding = self.padding.upper()\n",
        "        else:\n",
        "            tf_padding = self.padding\n",
        "        tf_dilations = list(self.dilation_rate)\n",
        "        tf_strides = list(self.strides)\n",
        "    \n",
        "        tf_op_name = self.__class__.__name__\n",
        "        if tf_op_name == 'Conv1D':\n",
        "            tf_op_name = 'conv1d'  # Backwards compat.\n",
        "    \n",
        "        self._convolution_op = functools.partial(\n",
        "            nn_ops.convolution_v2,\n",
        "            strides=tf_strides,\n",
        "            padding=tf_padding,\n",
        "            dilations=tf_dilations,\n",
        "            data_format=self._tf_data_format,\n",
        "            name=tf_op_name)\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        outputs = self._convolution_op(inputs, full_tt(self.K1, self.K2, self.K3))\n",
        "        if self.use_bias:\n",
        "            output_rank = outputs.shape.rank\n",
        "            if self.rank == 1 and self._channels_first:\n",
        "                # nn.bias_add does not accept a 1D input tensor.\n",
        "                bias = array_ops.reshape(self.bias, (1, self.filters, 1))\n",
        "                outputs += bias\n",
        "            else:\n",
        "                # Handle multiple batch dimensions.\n",
        "                if output_rank is not None and output_rank > 2 + self.rank:\n",
        "    \n",
        "                    def _apply_fn(o):\n",
        "                        return nn.bias_add(o, self.bias, data_format=self._tf_data_format)\n",
        "    \n",
        "                    outputs = nn_ops.squeeze_batch_dims(\n",
        "                      outputs, _apply_fn, inner_rank=self.rank + 1)\n",
        "                else:\n",
        "                    outputs = nn.bias_add(\n",
        "                      outputs, self.bias, data_format=self._tf_data_format)\n",
        "        if self.activation is not None:\n",
        "            return self.activation(outputs)\n",
        "        return outputs        "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSatFAHUVVZM"
      },
      "source": [
        "### Проверка работоспособности слоя на наборе данных из букв (одна из наших домашек)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfvhZ-l0rsUd"
      },
      "source": [
        "#### Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3tYiEG_VTGT",
        "outputId": "fc20fba6-92ca-44ed-d02f-90ae757686fd"
      },
      "source": [
        "!wget http://yaroslavvb.com/upload/notMNIST/notMNIST_large.tar.gz\n",
        "!tar -xvf notMNIST_large.tar.gz >> /dev/null"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-21 12:39:50--  http://yaroslavvb.com/upload/notMNIST/notMNIST_large.tar.gz\n",
            "Resolving yaroslavvb.com (yaroslavvb.com)... 129.121.4.193\n",
            "Connecting to yaroslavvb.com (yaroslavvb.com)|129.121.4.193|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 247336696 (236M) [application/x-gzip]\n",
            "Saving to: ‘notMNIST_large.tar.gz’\n",
            "\n",
            "notMNIST_large.tar. 100%[===================>] 235.88M  98.1MB/s    in 2.4s    \n",
            "\n",
            "2021-04-21 12:39:53 (98.1 MB/s) - ‘notMNIST_large.tar.gz’ saved [247336696/247336696]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxgpV6QQVeQU"
      },
      "source": [
        "DATA_DIR = 'notMNIST_large/'"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo8NwEd7Vrcu"
      },
      "source": [
        "from glob import glob\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "for img_path in glob(f'{DATA_DIR}/**/*.png'):\n",
        "  try:\n",
        "    img = Image.open(img_path)\n",
        "  except:\n",
        "      os.remove(img_path)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "PAIaOAt4Vvji",
        "outputId": "bbf81667-1f5f-4f29-983e-69599b69abf7"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "plt.figure(figsize=(17,10))\n",
        "letter = 'A'\n",
        "img = cv2.imread(os.path.join(DATA_DIR, letter, os.listdir(f'{DATA_DIR}/{letter}/')[0]))\n",
        "plt.imshow(img)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f629fe9ec90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1224x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v28-MI9WWPLn"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import image\n",
        "from keras.layers.core import Activation, Reshape, Dense, Flatten\n",
        "from keras.layers import Conv2D, MaxPool2D, InputLayer, BatchNormalization, Dropout, GlobalAveragePooling2D, GlobalMaxPool2D\n",
        "from keras.models import Model\n",
        "\n",
        "pic_size = 28\n",
        "n_classes = len(os.listdir(DATA_DIR))\n",
        "\n",
        "def build_model(decomposition_rank):\n",
        "    model = keras.Sequential([\n",
        "        ConvDecomposed2D(32, 3, decomposition_rank=decomposition_rank,\n",
        "                        input_shape=(pic_size, pic_size, 3),\n",
        "                            data_format=\"channels_last\", activation='relu',\n",
        "                            padding='same'),\n",
        "        keras.layers.MaxPooling2D(),\n",
        "        ConvDecomposed2D(32, 3, decomposition_rank=decomposition_rank,\n",
        "                        activation='relu', padding='same'),\n",
        "        keras.layers.MaxPooling2D(),\n",
        "        ConvDecomposed2D(32, 3, decomposition_rank=decomposition_rank,\n",
        "                        activation='relu', padding='same'),\n",
        "        keras.layers.MaxPooling2D(),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3EyzG5DWuER",
        "outputId": "81138869-fa62-43dd-b6df-25823a32103f"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Подсказка: train/val split удобно делать вот так https://stackoverflow.com/questions/53037510/can-flow-from-directory-get-train-and-validation-data-from-the-same-directory-in (самый залайканый ответ)\n",
        "\n",
        "\"\"\" Data generators initialization: for train and validation sets \"\"\"\n",
        "# generator = ImageDataGenerator(shear_range=0.2, width_shift_range=0.1,\n",
        "#                                height_shift_range=0.1, rotation_range=20,\n",
        "#                                validation_split=0.1, rescale=1./255)\n",
        "generator = ImageDataGenerator(validation_split=0.1, rescale=1./255)\n",
        "train_gen = generator.flow_from_directory(DATA_DIR,\n",
        "                                          target_size=(pic_size, pic_size),\n",
        "                                          class_mode='categorical',\n",
        "                                          subset='training', seed=1)\n",
        "val_gen = generator.flow_from_directory(DATA_DIR,\n",
        "                                        target_size=(pic_size, pic_size),\n",
        "                                        class_mode='categorical',\n",
        "                                        subset='validation', seed=1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 476205 images belonging to 10 classes.\n",
            "Found 52909 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmr9s-v4rJu8"
      },
      "source": [
        "#### Модель с обычными свёрточными слоями"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvWuVxCgjTTM",
        "outputId": "8b860e33-8c5d-4e5a-8040-72b15cfdc0f2"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, 3, input_shape=(pic_size, pic_size, 3),\n",
        "                        data_format=\"channels_last\", activation='relu',\n",
        "                        padding='same'),\n",
        "    keras.layers.MaxPooling2D(),\n",
        "    keras.layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
        "    keras.layers.MaxPooling2D(),\n",
        "    keras.layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
        "    keras.layers.MaxPooling2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(n_classes, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 128)               36992     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 57,674\n",
            "Trainable params: 57,674\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzA9v2bEoWgE",
        "outputId": "20cb2ce5-0920-40a7-8381-086decfe1bca"
      },
      "source": [
        "step_size_train = (train_gen.n // train_gen.batch_size)\n",
        "step_size_valid = (val_gen.n // val_gen.batch_size)\n",
        "\n",
        "history2 = model.fit(train_gen, steps_per_epoch=step_size_train, epochs=2,\n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=step_size_valid)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "14881/14881 [==============================] - 223s 15ms/step - loss: 0.4202 - accuracy: 0.8750 - val_loss: 0.2355 - val_accuracy: 0.9287\n",
            "Epoch 2/2\n",
            "14881/14881 [==============================] - 222s 15ms/step - loss: 0.2631 - accuracy: 0.9186 - val_loss: 0.2264 - val_accuracy: 0.9323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRChluDlrVYz"
      },
      "source": [
        "#### decomposition_rank = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUuo_lwPigPL",
        "outputId": "ce8c0085-35aa-4309-c355-1a83fed06ead"
      },
      "source": [
        "model1 = build_model(1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_decomposed2d_27 (ConvDe (None, 28, 28, 32)        76        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_decomposed2d_28 (ConvDe (None, 14, 14, 32)        105       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv_decomposed2d_29 (ConvDe (None, 7, 7, 32)          105       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 128)               36992     \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 38,568\n",
            "Trainable params: 38,568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR4MyUYOburL",
        "outputId": "53d0e319-8ecb-4e90-c428-9244bb78f28a"
      },
      "source": [
        "step_size_train = (train_gen.n // train_gen.batch_size)\n",
        "step_size_valid = (val_gen.n // val_gen.batch_size)\n",
        "\n",
        "history2 = model1.fit(train_gen, steps_per_epoch=step_size_train, epochs=2,\n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=step_size_valid)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "14881/14881 [==============================] - 228s 15ms/step - loss: 0.7763 - accuracy: 0.7734 - val_loss: 0.4791 - val_accuracy: 0.8571\n",
            "Epoch 2/2\n",
            "14881/14881 [==============================] - 227s 15ms/step - loss: 0.5480 - accuracy: 0.8331 - val_loss: 0.4496 - val_accuracy: 0.8643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3VcnSJ9rahO"
      },
      "source": [
        "#### decomposition_rank = 15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxOR56Sji3XJ",
        "outputId": "8c5fd5c3-c60b-4b86-8589-f7dc25db7db1"
      },
      "source": [
        "model15 = build_model(15)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_decomposed2d_30 (ConvDe (None, 28, 28, 32)        2582      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_decomposed2d_31 (ConvDe (None, 14, 14, 32)        3017      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv_decomposed2d_32 (ConvDe (None, 7, 7, 32)          3017      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 128)               36992     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 46,898\n",
            "Trainable params: 46,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a5QMldUb09e",
        "outputId": "5520fbae-677f-4fd2-9d73-efc4b20b917e"
      },
      "source": [
        "step_size_train = (train_gen.n // train_gen.batch_size)\n",
        "step_size_valid = (val_gen.n // val_gen.batch_size)\n",
        "\n",
        "history2 = model15.fit(train_gen, steps_per_epoch=step_size_train, epochs=2,\n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=step_size_valid)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "14881/14881 [==============================] - 230s 15ms/step - loss: 0.4524 - accuracy: 0.8653 - val_loss: 0.2450 - val_accuracy: 0.9244\n",
            "Epoch 2/2\n",
            "14881/14881 [==============================] - 228s 15ms/step - loss: 0.2863 - accuracy: 0.9121 - val_loss: 0.2415 - val_accuracy: 0.9261\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
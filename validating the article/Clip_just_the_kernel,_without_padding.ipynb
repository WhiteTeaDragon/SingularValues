{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clip just the kernel, without padding",
      "provenance": [],
      "collapsed_sections": [
        "Q2gf23x1rHE7",
        "aZVJDAmRzfzc",
        "EBFMbHvLIf5g",
        "npx7NtMb2D0_",
        "4GGdi8wX0XLv",
        "FXKrbbvBu5j9",
        "SYsweyOS3wPM"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WhiteTeaDragon/SingularValues/blob/main/validating%20the%20article/Clip_just_the_kernel%2C_without_padding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFqGu4P1VFlm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "020f141e-5d5f-4561-a3a2-8f4a9ce24a13"
      },
      "source": [
        "!pip install tensorflow-determinism"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-determinism\n",
            "  Downloading https://files.pythonhosted.org/packages/76/56/79d74f25b326d8719753172496abc524980fa67d1d98bb247021376e370a/tensorflow-determinism-0.3.0.tar.gz\n",
            "Building wheels for collected packages: tensorflow-determinism\n",
            "  Building wheel for tensorflow-determinism (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-determinism: filename=tensorflow_determinism-0.3.0-cp37-none-any.whl size=9158 sha256=9fb77eba2423fc27d43f79d3e8e5d4462448ad15016d3a27e6872f8eff848331\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/c3/18/13959a90d3e0d10182a99866d6ff4d0119e9daed6ce014b54c\n",
            "Successfully built tensorflow-determinism\n",
            "Installing collected packages: tensorflow-determinism\n",
            "Successfully installed tensorflow-determinism-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "praf7vwRHu5P"
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWOFa_uBGS8u"
      },
      "source": [
        "import functions"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWn7MN-iaAXi",
        "outputId": "5d8131b7-32df-4c6f-ae67-5b9ac9f5f14a"
      },
      "source": [
        "import importlib\n",
        "importlib.reload(functions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'functions' from '/content/functions.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfKVz1MXUZc1"
      },
      "source": [
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "SEED = 123\n",
        "os.environ['PYTHONHASHSEED']=str(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PBmtSgLffdr"
      },
      "source": [
        "Время на обучение у разных моделей может отличаться -- это происходит из-за того, что они обучались в разных сессиях Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2gf23x1rHE7"
      },
      "source": [
        "### Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceD49furq4ux",
        "outputId": "ad8be5c2-6fc8-4567-e8e7-b120c878f56a"
      },
      "source": [
        "num_classes = 10\n",
        "\n",
        "# load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# if subtract pixel mean is enabled\n",
        "x_train_mean = np.mean(x_train, axis=0)\n",
        "x_train -= x_train_mean\n",
        "x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# convert class vectors to binary class matrices.\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUSAJEF5zZCK"
      },
      "source": [
        "### Without decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZVJDAmRzfzc"
      },
      "source": [
        "#### Model without clipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYSrjJb-1409",
        "outputId": "de5f7c86-6ad1-4141-8565-d3862580b444"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(input_shape)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 16)   2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 16)   0           activation[0][0]                 \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 16)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 16)   0           activation_2[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 16)   0           activation_4[0][0]               \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 16)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 16)   2320        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 16)   0           activation_6[0][0]               \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 16)   2320        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 32, 32, 16)   0           activation_8[0][0]               \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 16)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   4640        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 32)   544         activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 32)   0           conv2d_13[0][0]                  \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 32)   9248        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 32)   128         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 32)   0           activation_12[0][0]              \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 32)   9248        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 32)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 16, 16, 32)   0           activation_14[0][0]              \n",
            "                                                                 batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 32)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 32)   9248        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 32)   128         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 16, 16, 32)   0           activation_16[0][0]              \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 32)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 32)   9248        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 32)   128         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 32)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 32)   9248        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 16, 16, 32)   0           activation_18[0][0]              \n",
            "                                                                 batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 8, 64)     18496       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 64)     256         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8, 8, 64)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 8, 8, 64)     36928       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 8, 8, 64)     2112        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 8, 8, 64)     256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 8, 64)     0           conv2d_24[0][0]                  \n",
            "                                                                 batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 8, 64)     0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 8, 8, 64)     36928       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 8, 8, 64)     256         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 8, 8, 64)     0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 8, 8, 64)     36928       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 8, 8, 64)     256         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 8, 8, 64)     0           activation_22[0][0]              \n",
            "                                                                 batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 8, 8, 64)     0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 64)     36928       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 8, 8, 64)     256         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 8, 8, 64)     0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 64)     36928       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 8, 64)     0           activation_24[0][0]              \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 64)     0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 64)     36928       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 64)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 64)     36928       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 8, 8, 64)     0           activation_26[0][0]              \n",
            "                                                                 batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 64)     0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 64)     36928       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 64)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 64)     36928       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 8, 8, 64)     0           activation_28[0][0]              \n",
            "                                                                 batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 64)     0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 64)     0           activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 64)           0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           650         flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 470,218\n",
            "Trainable params: 467,946\n",
            "Non-trainable params: 2,272\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjID6DOf2F36",
        "outputId": "1efd5543-d1db-4765-ecc0-15b1005b7b44"
      },
      "source": [
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'simple_trainHistoryDict', steps_per_epoch=100,\n",
        "                       batch_size=100, epochs=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Epoch 1/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 41s 83ms/step - loss: 2.7917 - acc: 0.2219 - val_loss: 2.3573 - val_acc: 0.2291\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.22910, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.8881 - acc: 0.3917 - val_loss: 2.0455 - val_acc: 0.3656\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.22910 to 0.36560, saving model to /content/saved_models/cifar10_ResNet32v1_model.002.h5\n",
            "Epoch 3/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.7052 - acc: 0.4599 - val_loss: 2.1614 - val_acc: 0.3371\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.36560\n",
            "Epoch 4/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.6138 - acc: 0.5131 - val_loss: 1.8819 - val_acc: 0.4220\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.36560 to 0.42200, saving model to /content/saved_models/cifar10_ResNet32v1_model.004.h5\n",
            "Epoch 5/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.5030 - acc: 0.5427 - val_loss: 1.5544 - val_acc: 0.5389\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.42200 to 0.53890, saving model to /content/saved_models/cifar10_ResNet32v1_model.005.h5\n",
            "Epoch 6/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.4443 - acc: 0.5735 - val_loss: 2.3545 - val_acc: 0.3883\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.53890\n",
            "Epoch 7/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.3409 - acc: 0.6062 - val_loss: 1.8422 - val_acc: 0.4894\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.53890\n",
            "Epoch 8/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.2782 - acc: 0.6317 - val_loss: 2.1510 - val_acc: 0.4281\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.53890\n",
            "Epoch 9/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.2750 - acc: 0.6320 - val_loss: 2.0645 - val_acc: 0.4674\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.53890\n",
            "Epoch 10/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.2217 - acc: 0.6419 - val_loss: 1.6657 - val_acc: 0.5276\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.53890\n",
            "Epoch 11/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.1674 - acc: 0.6763 - val_loss: 1.5014 - val_acc: 0.5551\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.53890 to 0.55510, saving model to /content/saved_models/cifar10_ResNet32v1_model.011.h5\n",
            "Epoch 12/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.1179 - acc: 0.6789 - val_loss: 1.9582 - val_acc: 0.5055\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.55510\n",
            "Epoch 13/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.0905 - acc: 0.6958 - val_loss: 1.7686 - val_acc: 0.5308\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.55510\n",
            "Epoch 14/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.0857 - acc: 0.7006 - val_loss: 2.2155 - val_acc: 0.4995\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.55510\n",
            "Epoch 15/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.0401 - acc: 0.7178 - val_loss: 1.2924 - val_acc: 0.6301\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.55510 to 0.63010, saving model to /content/saved_models/cifar10_ResNet32v1_model.015.h5\n",
            "Epoch 16/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 1.0120 - acc: 0.7213 - val_loss: 1.0936 - val_acc: 0.6955\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.63010 to 0.69550, saving model to /content/saved_models/cifar10_ResNet32v1_model.016.h5\n",
            "Epoch 17/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.9839 - acc: 0.7299 - val_loss: 1.2644 - val_acc: 0.6521\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.69550\n",
            "Epoch 18/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9804 - acc: 0.7338 - val_loss: 1.4880 - val_acc: 0.5987\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.69550\n",
            "Epoch 19/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.9635 - acc: 0.7352 - val_loss: 1.5609 - val_acc: 0.5911\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.69550\n",
            "Epoch 20/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9496 - acc: 0.7411 - val_loss: 1.2798 - val_acc: 0.6422\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.69550\n",
            "Epoch 21/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.9427 - acc: 0.7443 - val_loss: 1.3395 - val_acc: 0.6167\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.69550\n",
            "Epoch 22/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.9248 - acc: 0.7502 - val_loss: 1.1253 - val_acc: 0.6956\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.69550 to 0.69560, saving model to /content/saved_models/cifar10_ResNet32v1_model.022.h5\n",
            "Epoch 23/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.9006 - acc: 0.7614 - val_loss: 1.3942 - val_acc: 0.6477\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.69560\n",
            "Epoch 24/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9245 - acc: 0.7488 - val_loss: 1.2264 - val_acc: 0.6819\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.69560\n",
            "Epoch 25/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8584 - acc: 0.7723 - val_loss: 2.2518 - val_acc: 0.5116\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.69560\n",
            "Epoch 26/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8688 - acc: 0.7654 - val_loss: 1.9974 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.69560\n",
            "Epoch 27/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8264 - acc: 0.7894 - val_loss: 1.0888 - val_acc: 0.7157\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.69560 to 0.71570, saving model to /content/saved_models/cifar10_ResNet32v1_model.027.h5\n",
            "Epoch 28/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8369 - acc: 0.7831 - val_loss: 1.0199 - val_acc: 0.7212\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.71570 to 0.72120, saving model to /content/saved_models/cifar10_ResNet32v1_model.028.h5\n",
            "Epoch 29/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8358 - acc: 0.7797 - val_loss: 1.1612 - val_acc: 0.6783\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.72120\n",
            "Epoch 30/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.8279 - acc: 0.7840 - val_loss: 1.5258 - val_acc: 0.6003\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.72120\n",
            "Epoch 31/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8344 - acc: 0.7854 - val_loss: 1.3518 - val_acc: 0.6287\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.72120\n",
            "Epoch 32/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8262 - acc: 0.7791 - val_loss: 1.2475 - val_acc: 0.6609\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.72120\n",
            "Epoch 33/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.8167 - acc: 0.7864 - val_loss: 1.1745 - val_acc: 0.6987\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.72120\n",
            "Epoch 34/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7594 - acc: 0.8101 - val_loss: 0.9930 - val_acc: 0.7396\n",
            "\n",
            "Epoch 00034: val_acc improved from 0.72120 to 0.73960, saving model to /content/saved_models/cifar10_ResNet32v1_model.034.h5\n",
            "Epoch 35/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7827 - acc: 0.8033 - val_loss: 0.9648 - val_acc: 0.7471\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.73960 to 0.74710, saving model to /content/saved_models/cifar10_ResNet32v1_model.035.h5\n",
            "Epoch 36/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.7772 - acc: 0.7983 - val_loss: 1.2062 - val_acc: 0.6843\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.74710\n",
            "Epoch 37/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7632 - acc: 0.8054 - val_loss: 1.0416 - val_acc: 0.7114\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.74710\n",
            "Epoch 38/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.7672 - acc: 0.8077 - val_loss: 0.9819 - val_acc: 0.7333\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.74710\n",
            "Epoch 39/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7513 - acc: 0.8055 - val_loss: 1.0230 - val_acc: 0.7176\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.74710\n",
            "Epoch 40/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7381 - acc: 0.8110 - val_loss: 0.9133 - val_acc: 0.7546\n",
            "\n",
            "Epoch 00040: val_acc improved from 0.74710 to 0.75460, saving model to /content/saved_models/cifar10_ResNet32v1_model.040.h5\n",
            "Epoch 41/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7403 - acc: 0.8142 - val_loss: 1.0525 - val_acc: 0.7259\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.75460\n",
            "Epoch 42/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7462 - acc: 0.8073 - val_loss: 0.9765 - val_acc: 0.7513\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.75460\n",
            "Epoch 43/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7166 - acc: 0.8170 - val_loss: 1.1618 - val_acc: 0.6971\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.75460\n",
            "Epoch 44/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7271 - acc: 0.8185 - val_loss: 1.1486 - val_acc: 0.7115\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.75460\n",
            "Epoch 45/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6986 - acc: 0.8225 - val_loss: 1.0484 - val_acc: 0.7133\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.75460\n",
            "Epoch 46/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.7148 - acc: 0.8224 - val_loss: 0.9758 - val_acc: 0.7404\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.75460\n",
            "Epoch 47/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7076 - acc: 0.8225 - val_loss: 1.1730 - val_acc: 0.7137\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.75460\n",
            "Epoch 48/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6986 - acc: 0.8315 - val_loss: 0.9340 - val_acc: 0.7537\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.75460\n",
            "Epoch 49/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6911 - acc: 0.8283 - val_loss: 0.9484 - val_acc: 0.7501\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.75460\n",
            "Epoch 50/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6969 - acc: 0.8259 - val_loss: 1.1239 - val_acc: 0.6992\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.75460\n",
            "Epoch 51/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6651 - acc: 0.8352 - val_loss: 1.0633 - val_acc: 0.7376\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.75460\n",
            "Epoch 52/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6918 - acc: 0.8290 - val_loss: 1.7289 - val_acc: 0.5983\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.75460\n",
            "Epoch 53/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.7092 - acc: 0.8220 - val_loss: 0.9287 - val_acc: 0.7595\n",
            "\n",
            "Epoch 00053: val_acc improved from 0.75460 to 0.75950, saving model to /content/saved_models/cifar10_ResNet32v1_model.053.h5\n",
            "Epoch 54/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6614 - acc: 0.8382 - val_loss: 0.8823 - val_acc: 0.7569\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.75950\n",
            "Epoch 55/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6732 - acc: 0.8315 - val_loss: 0.9849 - val_acc: 0.7507\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.75950\n",
            "Epoch 56/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6568 - acc: 0.8379 - val_loss: 1.0759 - val_acc: 0.7228\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.75950\n",
            "Epoch 57/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6423 - acc: 0.8436 - val_loss: 0.7996 - val_acc: 0.7952\n",
            "\n",
            "Epoch 00057: val_acc improved from 0.75950 to 0.79520, saving model to /content/saved_models/cifar10_ResNet32v1_model.057.h5\n",
            "Epoch 58/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6656 - acc: 0.8365 - val_loss: 1.1049 - val_acc: 0.7299\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.79520\n",
            "Epoch 59/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6688 - acc: 0.8321 - val_loss: 1.1031 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.79520\n",
            "Epoch 60/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6562 - acc: 0.8358 - val_loss: 0.9279 - val_acc: 0.7509\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.79520\n",
            "Epoch 61/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6351 - acc: 0.8459 - val_loss: 0.8573 - val_acc: 0.7828\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.79520\n",
            "Epoch 62/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6722 - acc: 0.8383 - val_loss: 0.8526 - val_acc: 0.7857\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.79520\n",
            "Epoch 63/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6282 - acc: 0.8525 - val_loss: 1.1547 - val_acc: 0.7238\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.79520\n",
            "Epoch 64/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6216 - acc: 0.8509 - val_loss: 1.2750 - val_acc: 0.6902\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.79520\n",
            "Epoch 65/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6225 - acc: 0.8452 - val_loss: 0.9463 - val_acc: 0.7652\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.79520\n",
            "Epoch 66/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6105 - acc: 0.8559 - val_loss: 1.0440 - val_acc: 0.7389\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.79520\n",
            "Epoch 67/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6377 - acc: 0.8429 - val_loss: 0.9184 - val_acc: 0.7619\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.79520\n",
            "Epoch 68/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6319 - acc: 0.8482 - val_loss: 0.9735 - val_acc: 0.7557\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.79520\n",
            "Epoch 69/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6197 - acc: 0.8514 - val_loss: 0.9155 - val_acc: 0.7615\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.79520\n",
            "Epoch 70/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6120 - acc: 0.8591 - val_loss: 0.7543 - val_acc: 0.8140\n",
            "\n",
            "Epoch 00070: val_acc improved from 0.79520 to 0.81400, saving model to /content/saved_models/cifar10_ResNet32v1_model.070.h5\n",
            "Epoch 71/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5971 - acc: 0.8611 - val_loss: 0.8425 - val_acc: 0.7731\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.81400\n",
            "Epoch 72/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6074 - acc: 0.8568 - val_loss: 0.8468 - val_acc: 0.7850\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.81400\n",
            "Epoch 73/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5760 - acc: 0.8677 - val_loss: 0.8759 - val_acc: 0.7760\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.81400\n",
            "Epoch 74/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6146 - acc: 0.8532 - val_loss: 0.8554 - val_acc: 0.7742\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.81400\n",
            "Epoch 75/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.6088 - acc: 0.8545 - val_loss: 0.8282 - val_acc: 0.7934\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.81400\n",
            "Epoch 76/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5966 - acc: 0.8554 - val_loss: 0.9090 - val_acc: 0.7688\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.81400\n",
            "Epoch 77/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5903 - acc: 0.8648 - val_loss: 0.7742 - val_acc: 0.8100\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.81400\n",
            "Epoch 78/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5912 - acc: 0.8579 - val_loss: 0.8025 - val_acc: 0.7937\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.81400\n",
            "Epoch 79/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5773 - acc: 0.8680 - val_loss: 0.9038 - val_acc: 0.7771\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.81400\n",
            "Epoch 80/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.5794 - acc: 0.8671 - val_loss: 1.0124 - val_acc: 0.7430\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.81400\n",
            "Epoch 81/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5986 - acc: 0.8608 - val_loss: 0.8916 - val_acc: 0.7776\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.81400\n",
            "Epoch 82/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5762 - acc: 0.8732 - val_loss: 0.7365 - val_acc: 0.8209\n",
            "\n",
            "Epoch 00082: val_acc improved from 0.81400 to 0.82090, saving model to /content/saved_models/cifar10_ResNet32v1_model.082.h5\n",
            "Epoch 83/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5882 - acc: 0.8599 - val_loss: 1.0098 - val_acc: 0.7403\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.82090\n",
            "Epoch 84/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5827 - acc: 0.8684 - val_loss: 0.9415 - val_acc: 0.7613\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.82090\n",
            "Epoch 85/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5644 - acc: 0.8680 - val_loss: 0.8748 - val_acc: 0.7851\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.82090\n",
            "Epoch 86/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5539 - acc: 0.8719 - val_loss: 0.9657 - val_acc: 0.7689\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.82090\n",
            "Epoch 87/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5804 - acc: 0.8656 - val_loss: 0.9822 - val_acc: 0.7619\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.82090\n",
            "Epoch 88/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5751 - acc: 0.8674 - val_loss: 0.9051 - val_acc: 0.7776\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.82090\n",
            "Epoch 89/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5549 - acc: 0.8748 - val_loss: 0.8442 - val_acc: 0.7955\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.82090\n",
            "Epoch 90/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5683 - acc: 0.8692 - val_loss: 1.1180 - val_acc: 0.7201\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.82090\n",
            "Epoch 91/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5652 - acc: 0.8732 - val_loss: 1.1057 - val_acc: 0.7166\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.82090\n",
            "Epoch 92/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5621 - acc: 0.8713 - val_loss: 0.9378 - val_acc: 0.7802\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.82090\n",
            "Epoch 93/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5689 - acc: 0.8691 - val_loss: 0.7497 - val_acc: 0.8035\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.82090\n",
            "Epoch 94/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5688 - acc: 0.8698 - val_loss: 1.3253 - val_acc: 0.7030\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.82090\n",
            "Epoch 95/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5558 - acc: 0.8699 - val_loss: 0.8225 - val_acc: 0.7998\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.82090\n",
            "Epoch 96/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5746 - acc: 0.8657 - val_loss: 1.3325 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.82090\n",
            "Epoch 97/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5341 - acc: 0.8841 - val_loss: 0.9161 - val_acc: 0.7655\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.82090\n",
            "Epoch 98/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5373 - acc: 0.8822 - val_loss: 1.0970 - val_acc: 0.7383\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.82090\n",
            "Epoch 99/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5248 - acc: 0.8869 - val_loss: 0.9046 - val_acc: 0.7894\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.82090\n",
            "Epoch 100/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5588 - acc: 0.8760 - val_loss: 1.0311 - val_acc: 0.7412\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.82090\n",
            "Epoch 101/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5630 - acc: 0.8715 - val_loss: 0.8098 - val_acc: 0.8020\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.82090\n",
            "Epoch 102/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5373 - acc: 0.8823 - val_loss: 0.7706 - val_acc: 0.8120\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.82090\n",
            "Epoch 103/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.5653 - acc: 0.8721 - val_loss: 1.3472 - val_acc: 0.6967\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.82090\n",
            "Epoch 104/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5269 - acc: 0.8829 - val_loss: 0.8820 - val_acc: 0.7846\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.82090\n",
            "Epoch 105/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5453 - acc: 0.8758 - val_loss: 1.2220 - val_acc: 0.7181\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.82090\n",
            "Epoch 106/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5362 - acc: 0.8845 - val_loss: 0.8292 - val_acc: 0.7927\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.82090\n",
            "Epoch 107/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5491 - acc: 0.8788 - val_loss: 0.7816 - val_acc: 0.8091\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.82090\n",
            "Epoch 108/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5050 - acc: 0.8957 - val_loss: 0.9262 - val_acc: 0.7885\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.82090\n",
            "Epoch 109/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5302 - acc: 0.8863 - val_loss: 0.7075 - val_acc: 0.8296\n",
            "\n",
            "Epoch 00109: val_acc improved from 0.82090 to 0.82960, saving model to /content/saved_models/cifar10_ResNet32v1_model.109.h5\n",
            "Epoch 110/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5297 - acc: 0.8836 - val_loss: 0.7696 - val_acc: 0.8230\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.82960\n",
            "Epoch 111/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5269 - acc: 0.8808 - val_loss: 0.8664 - val_acc: 0.7837\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.82960\n",
            "Epoch 112/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5254 - acc: 0.8888 - val_loss: 0.7935 - val_acc: 0.8070\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.82960\n",
            "Epoch 113/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5228 - acc: 0.8916 - val_loss: 0.9615 - val_acc: 0.7609\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.82960\n",
            "Epoch 114/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5223 - acc: 0.8847 - val_loss: 0.8401 - val_acc: 0.7914\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.82960\n",
            "Epoch 115/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5179 - acc: 0.8894 - val_loss: 0.9835 - val_acc: 0.7684\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.82960\n",
            "Epoch 116/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5260 - acc: 0.8790 - val_loss: 0.9361 - val_acc: 0.7727\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.82960\n",
            "Epoch 117/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5447 - acc: 0.8812 - val_loss: 0.8277 - val_acc: 0.7964\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.82960\n",
            "Epoch 118/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5195 - acc: 0.8837 - val_loss: 0.8952 - val_acc: 0.7940\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.82960\n",
            "Epoch 119/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5145 - acc: 0.8891 - val_loss: 0.9242 - val_acc: 0.7765\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.82960\n",
            "Epoch 120/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5411 - acc: 0.8795 - val_loss: 0.8581 - val_acc: 0.7855\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.82960\n",
            "Epoch 121/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4897 - acc: 0.8982 - val_loss: 0.8325 - val_acc: 0.7953\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.82960\n",
            "Epoch 122/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5198 - acc: 0.8849 - val_loss: 0.9437 - val_acc: 0.7736\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.82960\n",
            "Epoch 123/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5209 - acc: 0.8873 - val_loss: 0.6966 - val_acc: 0.8291\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.82960\n",
            "Epoch 124/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4914 - acc: 0.8961 - val_loss: 0.8602 - val_acc: 0.7831\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.82960\n",
            "Epoch 125/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4789 - acc: 0.9040 - val_loss: 0.9890 - val_acc: 0.7588\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.82960\n",
            "Epoch 126/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5059 - acc: 0.8934 - val_loss: 1.1877 - val_acc: 0.7301\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.82960\n",
            "Epoch 127/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5032 - acc: 0.8927 - val_loss: 0.7272 - val_acc: 0.8276\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.82960\n",
            "Epoch 128/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5057 - acc: 0.8890 - val_loss: 0.8406 - val_acc: 0.7930\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.82960\n",
            "Epoch 129/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.5083 - acc: 0.8893 - val_loss: 0.9669 - val_acc: 0.7580\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.82960\n",
            "Epoch 130/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5065 - acc: 0.8937 - val_loss: 0.9088 - val_acc: 0.7781\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.82960\n",
            "Epoch 131/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4956 - acc: 0.8935 - val_loss: 0.8971 - val_acc: 0.7866\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.82960\n",
            "Epoch 132/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5186 - acc: 0.8900 - val_loss: 1.0260 - val_acc: 0.7619\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.82960\n",
            "Epoch 133/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4906 - acc: 0.8940 - val_loss: 1.0400 - val_acc: 0.7622\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.82960\n",
            "Epoch 134/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.4809 - acc: 0.9007 - val_loss: 1.0715 - val_acc: 0.7609\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.82960\n",
            "Epoch 135/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4914 - acc: 0.8949 - val_loss: 0.7459 - val_acc: 0.8255\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.82960\n",
            "Epoch 136/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5035 - acc: 0.8890 - val_loss: 0.7743 - val_acc: 0.8150\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.82960\n",
            "Epoch 137/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4865 - acc: 0.9008 - val_loss: 0.7608 - val_acc: 0.8164\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.82960\n",
            "Epoch 138/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4812 - acc: 0.8983 - val_loss: 0.9314 - val_acc: 0.7780\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.82960\n",
            "Epoch 139/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5142 - acc: 0.8911 - val_loss: 0.8120 - val_acc: 0.8020\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.82960\n",
            "Epoch 140/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.5089 - acc: 0.8908 - val_loss: 0.7798 - val_acc: 0.8084\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.82960\n",
            "Epoch 141/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4779 - acc: 0.9021 - val_loss: 0.9337 - val_acc: 0.7783\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.82960\n",
            "Epoch 142/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4869 - acc: 0.8981 - val_loss: 0.8430 - val_acc: 0.8041\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.82960\n",
            "Epoch 143/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4882 - acc: 0.8990 - val_loss: 0.8237 - val_acc: 0.8087\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.82960\n",
            "Epoch 144/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4785 - acc: 0.9018 - val_loss: 0.9233 - val_acc: 0.7832\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.82960\n",
            "Epoch 145/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4765 - acc: 0.9002 - val_loss: 1.1600 - val_acc: 0.7402\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.82960\n",
            "Epoch 146/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4901 - acc: 0.8928 - val_loss: 0.7021 - val_acc: 0.8317\n",
            "\n",
            "Epoch 00146: val_acc improved from 0.82960 to 0.83170, saving model to /content/saved_models/cifar10_ResNet32v1_model.146.h5\n",
            "Epoch 147/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4995 - acc: 0.8913 - val_loss: 0.7749 - val_acc: 0.8172\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.83170\n",
            "Epoch 148/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4732 - acc: 0.9042 - val_loss: 0.7311 - val_acc: 0.8245\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.83170\n",
            "Epoch 149/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4961 - acc: 0.8947 - val_loss: 0.8270 - val_acc: 0.8012\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.83170\n",
            "Epoch 150/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4734 - acc: 0.9026 - val_loss: 0.7302 - val_acc: 0.8274\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.83170\n",
            "Epoch 151/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4731 - acc: 0.9017 - val_loss: 0.8536 - val_acc: 0.7943\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.83170\n",
            "Epoch 152/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4983 - acc: 0.8927 - val_loss: 0.7299 - val_acc: 0.8291\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.83170\n",
            "Epoch 153/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4778 - acc: 0.9010 - val_loss: 0.8402 - val_acc: 0.7999\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.83170\n",
            "Epoch 154/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4681 - acc: 0.9032 - val_loss: 0.7196 - val_acc: 0.8288\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.83170\n",
            "Epoch 155/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4692 - acc: 0.9029 - val_loss: 0.8495 - val_acc: 0.8062\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.83170\n",
            "Epoch 156/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4677 - acc: 0.9046 - val_loss: 0.8068 - val_acc: 0.8127\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.83170\n",
            "Epoch 157/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4790 - acc: 0.8996 - val_loss: 0.9271 - val_acc: 0.7934\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.83170\n",
            "Epoch 158/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4873 - acc: 0.8995 - val_loss: 0.7201 - val_acc: 0.8386\n",
            "\n",
            "Epoch 00158: val_acc improved from 0.83170 to 0.83860, saving model to /content/saved_models/cifar10_ResNet32v1_model.158.h5\n",
            "Epoch 159/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4977 - acc: 0.8962 - val_loss: 0.7495 - val_acc: 0.8277\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.83860\n",
            "Epoch 160/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4959 - acc: 0.8978 - val_loss: 0.8236 - val_acc: 0.7985\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.83860\n",
            "Epoch 161/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4538 - acc: 0.9088 - val_loss: 0.8986 - val_acc: 0.7990\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.83860\n",
            "Epoch 162/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4625 - acc: 0.9080 - val_loss: 0.8518 - val_acc: 0.7915\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.83860\n",
            "Epoch 163/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4642 - acc: 0.9046 - val_loss: 0.9348 - val_acc: 0.7882\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.83860\n",
            "Epoch 164/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4658 - acc: 0.9070 - val_loss: 1.0637 - val_acc: 0.7704\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.83860\n",
            "Epoch 165/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4677 - acc: 0.9071 - val_loss: 0.8199 - val_acc: 0.8084\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.83860\n",
            "Epoch 166/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4765 - acc: 0.9042 - val_loss: 0.8807 - val_acc: 0.8067\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.83860\n",
            "Epoch 167/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4673 - acc: 0.9040 - val_loss: 0.7487 - val_acc: 0.8218\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.83860\n",
            "Epoch 168/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4513 - acc: 0.9088 - val_loss: 0.7737 - val_acc: 0.8245\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.83860\n",
            "Epoch 169/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4581 - acc: 0.9126 - val_loss: 0.7371 - val_acc: 0.8291\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.83860\n",
            "Epoch 170/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4495 - acc: 0.9091 - val_loss: 0.8816 - val_acc: 0.8043\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.83860\n",
            "Epoch 171/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4701 - acc: 0.9044 - val_loss: 0.6588 - val_acc: 0.8497\n",
            "\n",
            "Epoch 00171: val_acc improved from 0.83860 to 0.84970, saving model to /content/saved_models/cifar10_ResNet32v1_model.171.h5\n",
            "Epoch 172/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4610 - acc: 0.9040 - val_loss: 0.7604 - val_acc: 0.8282\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.84970\n",
            "Epoch 173/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4544 - acc: 0.9085 - val_loss: 0.8683 - val_acc: 0.8029\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.84970\n",
            "Epoch 174/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4669 - acc: 0.9134 - val_loss: 0.8301 - val_acc: 0.8103\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.84970\n",
            "Epoch 175/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4806 - acc: 0.9014 - val_loss: 0.7030 - val_acc: 0.8351\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.84970\n",
            "Epoch 176/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4697 - acc: 0.9025 - val_loss: 0.8812 - val_acc: 0.7968\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.84970\n",
            "Epoch 177/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4681 - acc: 0.9033 - val_loss: 0.8154 - val_acc: 0.8079\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.84970\n",
            "Epoch 178/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4693 - acc: 0.9051 - val_loss: 0.8587 - val_acc: 0.8034\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.84970\n",
            "Epoch 179/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4426 - acc: 0.9138 - val_loss: 0.9660 - val_acc: 0.7787\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.84970\n",
            "Epoch 180/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.4440 - acc: 0.9144 - val_loss: 0.9526 - val_acc: 0.7892\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.84970\n",
            "Epoch 181/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4419 - acc: 0.9126 - val_loss: 0.7180 - val_acc: 0.8328\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.84970\n",
            "Epoch 182/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4610 - acc: 0.9087 - val_loss: 0.7263 - val_acc: 0.8292\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.84970\n",
            "Epoch 183/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4705 - acc: 0.9043 - val_loss: 0.8446 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.84970\n",
            "Epoch 184/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4466 - acc: 0.9106 - val_loss: 0.7262 - val_acc: 0.8328\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.84970\n",
            "Epoch 185/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4609 - acc: 0.9112 - val_loss: 0.6703 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00185: val_acc improved from 0.84970 to 0.85000, saving model to /content/saved_models/cifar10_ResNet32v1_model.185.h5\n",
            "Epoch 186/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4387 - acc: 0.9123 - val_loss: 0.8192 - val_acc: 0.8144\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.85000\n",
            "Epoch 187/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4553 - acc: 0.9111 - val_loss: 1.0692 - val_acc: 0.7623\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.85000\n",
            "Epoch 188/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4572 - acc: 0.9108 - val_loss: 0.8220 - val_acc: 0.8052\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.85000\n",
            "Epoch 189/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4495 - acc: 0.9137 - val_loss: 0.7167 - val_acc: 0.8391\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.85000\n",
            "Epoch 190/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4503 - acc: 0.9089 - val_loss: 0.8382 - val_acc: 0.8042\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.85000\n",
            "Epoch 191/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4474 - acc: 0.9151 - val_loss: 0.6204 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00191: val_acc improved from 0.85000 to 0.85810, saving model to /content/saved_models/cifar10_ResNet32v1_model.191.h5\n",
            "Epoch 192/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4498 - acc: 0.9143 - val_loss: 0.8123 - val_acc: 0.8079\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.85810\n",
            "Epoch 193/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4365 - acc: 0.9165 - val_loss: 0.6374 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00193: val_acc improved from 0.85810 to 0.86010, saving model to /content/saved_models/cifar10_ResNet32v1_model.193.h5\n",
            "Epoch 194/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4471 - acc: 0.9134 - val_loss: 0.6900 - val_acc: 0.8460\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.86010\n",
            "Epoch 195/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4484 - acc: 0.9120 - val_loss: 0.8432 - val_acc: 0.8099\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.86010\n",
            "Epoch 196/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4501 - acc: 0.9057 - val_loss: 0.7940 - val_acc: 0.8231\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.86010\n",
            "Epoch 197/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4460 - acc: 0.9086 - val_loss: 0.7361 - val_acc: 0.8226\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.86010\n",
            "Epoch 198/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4447 - acc: 0.9131 - val_loss: 0.7736 - val_acc: 0.8182\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.86010\n",
            "Epoch 199/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4606 - acc: 0.9075 - val_loss: 0.7063 - val_acc: 0.8369\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.86010\n",
            "Epoch 200/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4434 - acc: 0.9110 - val_loss: 0.7136 - val_acc: 0.8332\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.86010\n",
            "Epoch 201/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4494 - acc: 0.9067 - val_loss: 0.7989 - val_acc: 0.8190\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.86010\n",
            "Epoch 202/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4424 - acc: 0.9131 - val_loss: 0.7216 - val_acc: 0.8392\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.86010\n",
            "Epoch 203/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4397 - acc: 0.9100 - val_loss: 0.7417 - val_acc: 0.8380\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.86010\n",
            "Epoch 204/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4593 - acc: 0.9071 - val_loss: 0.7866 - val_acc: 0.8113\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.86010\n",
            "Epoch 205/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4590 - acc: 0.9113 - val_loss: 0.8348 - val_acc: 0.7975\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.86010\n",
            "Epoch 206/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4383 - acc: 0.9119 - val_loss: 1.0811 - val_acc: 0.7607\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.86010\n",
            "Epoch 207/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4593 - acc: 0.9031 - val_loss: 0.8669 - val_acc: 0.7993\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.86010\n",
            "Epoch 208/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4427 - acc: 0.9110 - val_loss: 0.7251 - val_acc: 0.8355\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.86010\n",
            "Epoch 209/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4531 - acc: 0.9112 - val_loss: 0.6023 - val_acc: 0.8655\n",
            "\n",
            "Epoch 00209: val_acc improved from 0.86010 to 0.86550, saving model to /content/saved_models/cifar10_ResNet32v1_model.209.h5\n",
            "Epoch 210/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4415 - acc: 0.9203 - val_loss: 0.6972 - val_acc: 0.8403\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.86550\n",
            "Epoch 211/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4659 - acc: 0.9029 - val_loss: 0.6098 - val_acc: 0.8633\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.86550\n",
            "Epoch 212/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4302 - acc: 0.9149 - val_loss: 0.7294 - val_acc: 0.8327\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.86550\n",
            "Epoch 213/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4279 - acc: 0.9198 - val_loss: 0.7086 - val_acc: 0.8465\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.86550\n",
            "Epoch 214/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4285 - acc: 0.9154 - val_loss: 0.7279 - val_acc: 0.8394\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.86550\n",
            "Epoch 215/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4193 - acc: 0.9224 - val_loss: 0.7462 - val_acc: 0.8335\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.86550\n",
            "Epoch 216/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4281 - acc: 0.9153 - val_loss: 0.7239 - val_acc: 0.8391\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.86550\n",
            "Epoch 217/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4456 - acc: 0.9100 - val_loss: 0.8837 - val_acc: 0.8055\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.86550\n",
            "Epoch 218/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4479 - acc: 0.9143 - val_loss: 0.7663 - val_acc: 0.8259\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.86550\n",
            "Epoch 219/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4367 - acc: 0.9168 - val_loss: 0.7876 - val_acc: 0.8261\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.86550\n",
            "Epoch 220/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4143 - acc: 0.9267 - val_loss: 0.6897 - val_acc: 0.8408\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.86550\n",
            "Epoch 221/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4466 - acc: 0.9133 - val_loss: 1.0710 - val_acc: 0.7682\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.86550\n",
            "Epoch 222/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4437 - acc: 0.9121 - val_loss: 1.0323 - val_acc: 0.7762\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.86550\n",
            "Epoch 223/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4357 - acc: 0.9167 - val_loss: 0.7241 - val_acc: 0.8345\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.86550\n",
            "Epoch 224/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4350 - acc: 0.9209 - val_loss: 1.1035 - val_acc: 0.7658\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.86550\n",
            "Epoch 225/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4199 - acc: 0.9222 - val_loss: 0.6989 - val_acc: 0.8348\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.86550\n",
            "Epoch 226/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4383 - acc: 0.9162 - val_loss: 0.9680 - val_acc: 0.7969\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.86550\n",
            "Epoch 227/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4209 - acc: 0.9233 - val_loss: 0.7857 - val_acc: 0.8209\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.86550\n",
            "Epoch 228/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4177 - acc: 0.9246 - val_loss: 0.8170 - val_acc: 0.8146\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.86550\n",
            "Epoch 229/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4326 - acc: 0.9155 - val_loss: 0.8537 - val_acc: 0.8159\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.86550\n",
            "Epoch 230/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4303 - acc: 0.9205 - val_loss: 0.6620 - val_acc: 0.8585\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.86550\n",
            "Epoch 231/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4255 - acc: 0.9204 - val_loss: 0.6730 - val_acc: 0.8485\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.86550\n",
            "Epoch 232/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4182 - acc: 0.9226 - val_loss: 0.9119 - val_acc: 0.7989\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.86550\n",
            "Epoch 233/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4563 - acc: 0.9088 - val_loss: 0.8876 - val_acc: 0.8038\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.86550\n",
            "Epoch 234/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4277 - acc: 0.9195 - val_loss: 0.8444 - val_acc: 0.8043\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.86550\n",
            "Epoch 235/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4420 - acc: 0.9117 - val_loss: 0.6828 - val_acc: 0.8419\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.86550\n",
            "Epoch 236/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4291 - acc: 0.9182 - val_loss: 1.0152 - val_acc: 0.7731\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.86550\n",
            "Epoch 237/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4258 - acc: 0.9204 - val_loss: 0.7825 - val_acc: 0.8184\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.86550\n",
            "Epoch 238/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4218 - acc: 0.9190 - val_loss: 0.8518 - val_acc: 0.8235\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.86550\n",
            "Epoch 239/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4398 - acc: 0.9141 - val_loss: 0.6856 - val_acc: 0.8474\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.86550\n",
            "Epoch 240/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4159 - acc: 0.9224 - val_loss: 0.6561 - val_acc: 0.8541\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.86550\n",
            "Epoch 241/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4400 - acc: 0.9137 - val_loss: 0.8374 - val_acc: 0.8102\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.86550\n",
            "Epoch 242/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4258 - acc: 0.9191 - val_loss: 0.6482 - val_acc: 0.8538\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.86550\n",
            "Epoch 243/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4199 - acc: 0.9204 - val_loss: 0.7434 - val_acc: 0.8358\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.86550\n",
            "Epoch 244/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4353 - acc: 0.9118 - val_loss: 0.8859 - val_acc: 0.7981\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.86550\n",
            "Epoch 245/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4211 - acc: 0.9212 - val_loss: 0.7258 - val_acc: 0.8387\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.86550\n",
            "Epoch 246/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4151 - acc: 0.9219 - val_loss: 0.7559 - val_acc: 0.8278\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.86550\n",
            "Epoch 247/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4248 - acc: 0.9230 - val_loss: 1.0486 - val_acc: 0.7895\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.86550\n",
            "Epoch 248/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4077 - acc: 0.9270 - val_loss: 0.7507 - val_acc: 0.8370\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.86550\n",
            "Epoch 249/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4250 - acc: 0.9222 - val_loss: 0.8364 - val_acc: 0.8136\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.86550\n",
            "Epoch 250/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4193 - acc: 0.9211 - val_loss: 0.6665 - val_acc: 0.8502\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.86550\n",
            "Epoch 251/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4284 - acc: 0.9177 - val_loss: 0.6926 - val_acc: 0.8426\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.86550\n",
            "Epoch 252/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4220 - acc: 0.9218 - val_loss: 0.7518 - val_acc: 0.8228\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.86550\n",
            "Epoch 253/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4452 - acc: 0.9135 - val_loss: 0.6986 - val_acc: 0.8528\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.86550\n",
            "Epoch 254/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4274 - acc: 0.9178 - val_loss: 0.7380 - val_acc: 0.8436\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.86550\n",
            "Epoch 255/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4267 - acc: 0.9178 - val_loss: 0.8221 - val_acc: 0.8115\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.86550\n",
            "Epoch 256/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4229 - acc: 0.9203 - val_loss: 0.7467 - val_acc: 0.8365\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.86550\n",
            "Epoch 257/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4163 - acc: 0.9224 - val_loss: 0.6297 - val_acc: 0.8641\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.86550\n",
            "Epoch 258/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4078 - acc: 0.9276 - val_loss: 0.9440 - val_acc: 0.7851\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.86550\n",
            "Epoch 259/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4297 - acc: 0.9146 - val_loss: 0.7340 - val_acc: 0.8426\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.86550\n",
            "Epoch 260/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4127 - acc: 0.9217 - val_loss: 0.8861 - val_acc: 0.8107\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.86550\n",
            "Epoch 261/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4294 - acc: 0.9183 - val_loss: 0.7869 - val_acc: 0.8248\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.86550\n",
            "Epoch 262/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4129 - acc: 0.9248 - val_loss: 0.8131 - val_acc: 0.8160\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.86550\n",
            "Epoch 263/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4113 - acc: 0.9243 - val_loss: 0.9338 - val_acc: 0.8025\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.86550\n",
            "Epoch 264/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4060 - acc: 0.9274 - val_loss: 0.6378 - val_acc: 0.8582\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.86550\n",
            "Epoch 265/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4265 - acc: 0.9205 - val_loss: 0.7049 - val_acc: 0.8459\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.86550\n",
            "Epoch 266/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4258 - acc: 0.9196 - val_loss: 0.9061 - val_acc: 0.7979\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.86550\n",
            "Epoch 267/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4216 - acc: 0.9210 - val_loss: 0.8370 - val_acc: 0.8155\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.86550\n",
            "Epoch 268/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4209 - acc: 0.9209 - val_loss: 0.9583 - val_acc: 0.7982\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.86550\n",
            "Epoch 269/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4204 - acc: 0.9198 - val_loss: 0.8543 - val_acc: 0.8028\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.86550\n",
            "Epoch 270/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4099 - acc: 0.9235 - val_loss: 0.8079 - val_acc: 0.8212\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.86550\n",
            "Epoch 271/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4248 - acc: 0.9201 - val_loss: 0.7229 - val_acc: 0.8410\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.86550\n",
            "Epoch 272/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4199 - acc: 0.9193 - val_loss: 0.6114 - val_acc: 0.8690\n",
            "\n",
            "Epoch 00272: val_acc improved from 0.86550 to 0.86900, saving model to /content/saved_models/cifar10_ResNet32v1_model.272.h5\n",
            "Epoch 273/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4211 - acc: 0.9191 - val_loss: 0.8919 - val_acc: 0.7899\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.86900\n",
            "Epoch 274/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4062 - acc: 0.9273 - val_loss: 0.6616 - val_acc: 0.8579\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.86900\n",
            "Epoch 275/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4137 - acc: 0.9248 - val_loss: 0.6413 - val_acc: 0.8604\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.86900\n",
            "Epoch 276/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4093 - acc: 0.9234 - val_loss: 0.7534 - val_acc: 0.8334\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.86900\n",
            "Epoch 277/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4209 - acc: 0.9231 - val_loss: 0.9096 - val_acc: 0.8024\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.86900\n",
            "Epoch 278/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4131 - acc: 0.9240 - val_loss: 0.7036 - val_acc: 0.8453\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.86900\n",
            "Epoch 279/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4039 - acc: 0.9259 - val_loss: 0.6245 - val_acc: 0.8635\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.86900\n",
            "Epoch 280/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4256 - acc: 0.9222 - val_loss: 0.6674 - val_acc: 0.8481\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.86900\n",
            "Epoch 281/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4053 - acc: 0.9273 - val_loss: 0.7677 - val_acc: 0.8260\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.86900\n",
            "Epoch 282/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4122 - acc: 0.9267 - val_loss: 0.7833 - val_acc: 0.8266\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.86900\n",
            "Epoch 283/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4147 - acc: 0.9209 - val_loss: 0.8242 - val_acc: 0.8152\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.86900\n",
            "Epoch 284/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4052 - acc: 0.9254 - val_loss: 0.6536 - val_acc: 0.8626\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.86900\n",
            "Epoch 285/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4244 - acc: 0.9199 - val_loss: 0.8916 - val_acc: 0.8071\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.86900\n",
            "Epoch 286/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4033 - acc: 0.9260 - val_loss: 0.6169 - val_acc: 0.8680\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.86900\n",
            "Epoch 287/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3905 - acc: 0.9354 - val_loss: 0.7379 - val_acc: 0.8289\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.86900\n",
            "Epoch 288/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4108 - acc: 0.9282 - val_loss: 0.7330 - val_acc: 0.8370\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.86900\n",
            "Epoch 289/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4220 - acc: 0.9227 - val_loss: 0.8740 - val_acc: 0.8187\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.86900\n",
            "Epoch 290/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3964 - acc: 0.9316 - val_loss: 0.8740 - val_acc: 0.8039\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.86900\n",
            "Epoch 291/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4302 - acc: 0.9166 - val_loss: 0.8048 - val_acc: 0.8341\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.86900\n",
            "Epoch 292/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4063 - acc: 0.9241 - val_loss: 0.6558 - val_acc: 0.8621\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.86900\n",
            "Epoch 293/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4190 - acc: 0.9212 - val_loss: 0.7952 - val_acc: 0.8353\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.86900\n",
            "Epoch 294/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4065 - acc: 0.9286 - val_loss: 0.9838 - val_acc: 0.7820\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.86900\n",
            "Epoch 295/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4098 - acc: 0.9282 - val_loss: 0.8247 - val_acc: 0.8179\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.86900\n",
            "Epoch 296/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4102 - acc: 0.9252 - val_loss: 0.6500 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.86900\n",
            "Epoch 297/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3929 - acc: 0.9299 - val_loss: 0.6600 - val_acc: 0.8557\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.86900\n",
            "Epoch 298/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4218 - acc: 0.9193 - val_loss: 0.6776 - val_acc: 0.8573\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.86900\n",
            "Epoch 299/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4293 - acc: 0.9166 - val_loss: 0.7496 - val_acc: 0.8328\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.86900\n",
            "Epoch 300/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3890 - acc: 0.9317 - val_loss: 0.7389 - val_acc: 0.8335\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.86900\n",
            "Epoch 301/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4018 - acc: 0.9297 - val_loss: 0.7384 - val_acc: 0.8349\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.86900\n",
            "Epoch 302/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4055 - acc: 0.9265 - val_loss: 0.7357 - val_acc: 0.8402\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.86900\n",
            "Epoch 303/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4211 - acc: 0.9225 - val_loss: 0.5812 - val_acc: 0.8761\n",
            "\n",
            "Epoch 00303: val_acc improved from 0.86900 to 0.87610, saving model to /content/saved_models/cifar10_ResNet32v1_model.303.h5\n",
            "Epoch 304/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3940 - acc: 0.9309 - val_loss: 0.6540 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.87610\n",
            "Epoch 305/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4045 - acc: 0.9252 - val_loss: 0.8987 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.87610\n",
            "Epoch 306/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4109 - acc: 0.9262 - val_loss: 0.9759 - val_acc: 0.7995\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.87610\n",
            "Epoch 307/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4194 - acc: 0.9228 - val_loss: 0.7730 - val_acc: 0.8303\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.87610\n",
            "Epoch 308/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4288 - acc: 0.9192 - val_loss: 0.8661 - val_acc: 0.8134\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.87610\n",
            "Epoch 309/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4032 - acc: 0.9238 - val_loss: 0.7824 - val_acc: 0.8243\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.87610\n",
            "Epoch 310/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4014 - acc: 0.9280 - val_loss: 0.6714 - val_acc: 0.8483\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.87610\n",
            "Epoch 311/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3916 - acc: 0.9319 - val_loss: 0.6655 - val_acc: 0.8570\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.87610\n",
            "Epoch 312/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4062 - acc: 0.9296 - val_loss: 0.7274 - val_acc: 0.8394\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.87610\n",
            "Epoch 313/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3995 - acc: 0.9283 - val_loss: 0.8081 - val_acc: 0.8247\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.87610\n",
            "Epoch 314/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4084 - acc: 0.9260 - val_loss: 0.6616 - val_acc: 0.8569\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.87610\n",
            "Epoch 315/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4286 - acc: 0.9202 - val_loss: 0.6767 - val_acc: 0.8519\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.87610\n",
            "Epoch 316/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4058 - acc: 0.9233 - val_loss: 0.7170 - val_acc: 0.8390\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.87610\n",
            "Epoch 317/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4041 - acc: 0.9268 - val_loss: 0.7393 - val_acc: 0.8402\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.87610\n",
            "Epoch 318/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4051 - acc: 0.9244 - val_loss: 0.7704 - val_acc: 0.8386\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.87610\n",
            "Epoch 319/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3993 - acc: 0.9303 - val_loss: 0.7250 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.87610\n",
            "Epoch 320/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3967 - acc: 0.9294 - val_loss: 0.6212 - val_acc: 0.8671\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.87610\n",
            "Epoch 321/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4090 - acc: 0.9271 - val_loss: 0.7982 - val_acc: 0.8268\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.87610\n",
            "Epoch 322/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4062 - acc: 0.9286 - val_loss: 1.0962 - val_acc: 0.7685\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.87610\n",
            "Epoch 323/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4119 - acc: 0.9212 - val_loss: 0.7772 - val_acc: 0.8372\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.87610\n",
            "Epoch 324/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3956 - acc: 0.9279 - val_loss: 0.7862 - val_acc: 0.8282\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.87610\n",
            "Epoch 325/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3934 - acc: 0.9316 - val_loss: 0.6037 - val_acc: 0.8733\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.87610\n",
            "Epoch 326/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4120 - acc: 0.9258 - val_loss: 0.6404 - val_acc: 0.8621\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.87610\n",
            "Epoch 327/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4028 - acc: 0.9275 - val_loss: 0.6496 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.87610\n",
            "Epoch 328/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3904 - acc: 0.9321 - val_loss: 0.7076 - val_acc: 0.8561\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.87610\n",
            "Epoch 329/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3965 - acc: 0.9279 - val_loss: 0.9304 - val_acc: 0.8078\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.87610\n",
            "Epoch 330/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4102 - acc: 0.9238 - val_loss: 0.7075 - val_acc: 0.8351\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.87610\n",
            "Epoch 331/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3874 - acc: 0.9345 - val_loss: 0.6343 - val_acc: 0.8608\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.87610\n",
            "Epoch 332/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4024 - acc: 0.9275 - val_loss: 0.8051 - val_acc: 0.8257\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.87610\n",
            "Epoch 333/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3974 - acc: 0.9274 - val_loss: 0.6907 - val_acc: 0.8527\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.87610\n",
            "Epoch 334/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4089 - acc: 0.9235 - val_loss: 0.6992 - val_acc: 0.8460\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.87610\n",
            "Epoch 335/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3878 - acc: 0.9308 - val_loss: 0.8030 - val_acc: 0.8258\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.87610\n",
            "Epoch 336/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4027 - acc: 0.9302 - val_loss: 0.6839 - val_acc: 0.8459\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.87610\n",
            "Epoch 337/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3942 - acc: 0.9292 - val_loss: 0.9495 - val_acc: 0.8070\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.87610\n",
            "Epoch 338/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3972 - acc: 0.9277 - val_loss: 0.8858 - val_acc: 0.8087\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.87610\n",
            "Epoch 339/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4033 - acc: 0.9250 - val_loss: 0.7892 - val_acc: 0.8279\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.87610\n",
            "Epoch 340/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4085 - acc: 0.9278 - val_loss: 0.6984 - val_acc: 0.8452\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.87610\n",
            "Epoch 341/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3877 - acc: 0.9334 - val_loss: 0.7476 - val_acc: 0.8340\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.87610\n",
            "Epoch 342/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4124 - acc: 0.9227 - val_loss: 0.5957 - val_acc: 0.8746\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.87610\n",
            "Epoch 343/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3835 - acc: 0.9338 - val_loss: 0.6549 - val_acc: 0.8647\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.87610\n",
            "Epoch 344/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3840 - acc: 0.9348 - val_loss: 0.6656 - val_acc: 0.8564\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.87610\n",
            "Epoch 345/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3928 - acc: 0.9344 - val_loss: 0.8340 - val_acc: 0.8188\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.87610\n",
            "Epoch 346/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3858 - acc: 0.9328 - val_loss: 0.9548 - val_acc: 0.7966\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.87610\n",
            "Epoch 347/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3900 - acc: 0.9336 - val_loss: 0.6740 - val_acc: 0.8579\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.87610\n",
            "Epoch 348/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3869 - acc: 0.9326 - val_loss: 0.6302 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.87610\n",
            "Epoch 349/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4021 - acc: 0.9307 - val_loss: 0.6634 - val_acc: 0.8610\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.87610\n",
            "Epoch 350/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3923 - acc: 0.9352 - val_loss: 0.9078 - val_acc: 0.7977\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.87610\n",
            "Epoch 351/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4107 - acc: 0.9233 - val_loss: 0.7160 - val_acc: 0.8532\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.87610\n",
            "Epoch 352/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4034 - acc: 0.9261 - val_loss: 0.8320 - val_acc: 0.8162\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.87610\n",
            "Epoch 353/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3990 - acc: 0.9253 - val_loss: 0.7263 - val_acc: 0.8394\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.87610\n",
            "Epoch 354/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3888 - acc: 0.9346 - val_loss: 0.6705 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.87610\n",
            "Epoch 355/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3903 - acc: 0.9281 - val_loss: 0.9279 - val_acc: 0.8021\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.87610\n",
            "Epoch 356/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3859 - acc: 0.9307 - val_loss: 0.9692 - val_acc: 0.7914\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.87610\n",
            "Epoch 357/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3984 - acc: 0.9289 - val_loss: 0.6689 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.87610\n",
            "Epoch 358/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3836 - acc: 0.9345 - val_loss: 0.6116 - val_acc: 0.8653\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.87610\n",
            "Epoch 359/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3920 - acc: 0.9290 - val_loss: 0.8064 - val_acc: 0.8290\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.87610\n",
            "Epoch 360/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3975 - acc: 0.9303 - val_loss: 0.9404 - val_acc: 0.8059\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.87610\n",
            "Epoch 361/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3826 - acc: 0.9348 - val_loss: 0.7362 - val_acc: 0.8415\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.87610\n",
            "Epoch 362/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3835 - acc: 0.9349 - val_loss: 0.7913 - val_acc: 0.8265\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.87610\n",
            "Epoch 363/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4075 - acc: 0.9226 - val_loss: 0.6932 - val_acc: 0.8446\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.87610\n",
            "Epoch 364/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4175 - acc: 0.9244 - val_loss: 0.6743 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.87610\n",
            "Epoch 365/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3941 - acc: 0.9283 - val_loss: 0.6941 - val_acc: 0.8541\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.87610\n",
            "Epoch 366/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3858 - acc: 0.9325 - val_loss: 0.7486 - val_acc: 0.8320\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.87610\n",
            "Epoch 367/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4006 - acc: 0.9300 - val_loss: 0.7177 - val_acc: 0.8468\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.87610\n",
            "Epoch 368/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3900 - acc: 0.9329 - val_loss: 0.6551 - val_acc: 0.8657\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.87610\n",
            "Epoch 369/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3763 - acc: 0.9356 - val_loss: 0.6471 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.87610\n",
            "Epoch 370/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3754 - acc: 0.9374 - val_loss: 0.8011 - val_acc: 0.8410\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.87610\n",
            "Epoch 371/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3758 - acc: 0.9354 - val_loss: 0.8980 - val_acc: 0.8016\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.87610\n",
            "Epoch 372/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3899 - acc: 0.9300 - val_loss: 0.9133 - val_acc: 0.8018\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.87610\n",
            "Epoch 373/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3807 - acc: 0.9351 - val_loss: 0.7631 - val_acc: 0.8254\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.87610\n",
            "Epoch 374/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3905 - acc: 0.9301 - val_loss: 0.6738 - val_acc: 0.8633\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.87610\n",
            "Epoch 375/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3924 - acc: 0.9285 - val_loss: 0.5876 - val_acc: 0.8767\n",
            "\n",
            "Epoch 00375: val_acc improved from 0.87610 to 0.87670, saving model to /content/saved_models/cifar10_ResNet32v1_model.375.h5\n",
            "Epoch 376/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3895 - acc: 0.9340 - val_loss: 0.8150 - val_acc: 0.8214\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.87670\n",
            "Epoch 377/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3944 - acc: 0.9339 - val_loss: 0.7022 - val_acc: 0.8507\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.87670\n",
            "Epoch 378/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4037 - acc: 0.9253 - val_loss: 0.7304 - val_acc: 0.8461\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.87670\n",
            "Epoch 379/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3957 - acc: 0.9255 - val_loss: 0.8451 - val_acc: 0.8169\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.87670\n",
            "Epoch 380/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3855 - acc: 0.9304 - val_loss: 0.7484 - val_acc: 0.8373\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.87670\n",
            "Epoch 381/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4016 - acc: 0.9312 - val_loss: 0.8304 - val_acc: 0.8277\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.87670\n",
            "Epoch 382/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3944 - acc: 0.9282 - val_loss: 0.6126 - val_acc: 0.8750\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.87670\n",
            "Epoch 383/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3855 - acc: 0.9291 - val_loss: 0.7216 - val_acc: 0.8457\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.87670\n",
            "Epoch 384/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4017 - acc: 0.9316 - val_loss: 0.7278 - val_acc: 0.8428\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.87670\n",
            "Epoch 385/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3739 - acc: 0.9340 - val_loss: 0.7416 - val_acc: 0.8388\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.87670\n",
            "Epoch 386/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3953 - acc: 0.9314 - val_loss: 0.6210 - val_acc: 0.8680\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.87670\n",
            "Epoch 387/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3898 - acc: 0.9332 - val_loss: 0.6925 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.87670\n",
            "Epoch 388/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3914 - acc: 0.9290 - val_loss: 0.6547 - val_acc: 0.8626\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.87670\n",
            "Epoch 389/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3870 - acc: 0.9287 - val_loss: 0.7419 - val_acc: 0.8447\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.87670\n",
            "Epoch 390/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3845 - acc: 0.9316 - val_loss: 0.7843 - val_acc: 0.8294\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.87670\n",
            "Epoch 391/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3872 - acc: 0.9317 - val_loss: 0.7000 - val_acc: 0.8514\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.87670\n",
            "Epoch 392/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3847 - acc: 0.9341 - val_loss: 0.7841 - val_acc: 0.8400\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.87670\n",
            "Epoch 393/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3900 - acc: 0.9331 - val_loss: 0.6740 - val_acc: 0.8605\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.87670\n",
            "Epoch 394/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3769 - acc: 0.9366 - val_loss: 0.7212 - val_acc: 0.8437\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.87670\n",
            "Epoch 395/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3775 - acc: 0.9353 - val_loss: 1.0603 - val_acc: 0.7890\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.87670\n",
            "Epoch 396/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3910 - acc: 0.9315 - val_loss: 0.5970 - val_acc: 0.8697\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.87670\n",
            "Epoch 397/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3802 - acc: 0.9320 - val_loss: 0.8151 - val_acc: 0.8148\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.87670\n",
            "Epoch 398/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4083 - acc: 0.9221 - val_loss: 0.6908 - val_acc: 0.8476\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.87670\n",
            "Epoch 399/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3922 - acc: 0.9301 - val_loss: 0.8437 - val_acc: 0.8161\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.87670\n",
            "Epoch 400/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3892 - acc: 0.9316 - val_loss: 0.6420 - val_acc: 0.8624\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.87670\n",
            "Epoch 401/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3752 - acc: 0.9359 - val_loss: 0.7343 - val_acc: 0.8503\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.87670\n",
            "Epoch 402/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3686 - acc: 0.9395 - val_loss: 0.5192 - val_acc: 0.9009\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.87670 to 0.90090, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3371 - acc: 0.9506 - val_loss: 0.5078 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.90090 to 0.90310, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3193 - acc: 0.9604 - val_loss: 0.4944 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.90310 to 0.90650, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3282 - acc: 0.9570 - val_loss: 0.4922 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.90650 to 0.90870, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3144 - acc: 0.9603 - val_loss: 0.4899 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00406: val_acc did not improve from 0.90870\n",
            "Epoch 407/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3080 - acc: 0.9597 - val_loss: 0.4844 - val_acc: 0.9106\n",
            "\n",
            "Epoch 00407: val_acc improved from 0.90870 to 0.91060, saving model to /content/saved_models/cifar10_ResNet32v1_model.407.h5\n",
            "Epoch 408/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3048 - acc: 0.9645 - val_loss: 0.4796 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00408: val_acc improved from 0.91060 to 0.91190, saving model to /content/saved_models/cifar10_ResNet32v1_model.408.h5\n",
            "Epoch 409/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3037 - acc: 0.9621 - val_loss: 0.4845 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.91190\n",
            "Epoch 410/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3016 - acc: 0.9623 - val_loss: 0.4827 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00410: val_acc did not improve from 0.91190\n",
            "Epoch 411/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2921 - acc: 0.9661 - val_loss: 0.4818 - val_acc: 0.9096\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.91190\n",
            "Epoch 412/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2938 - acc: 0.9648 - val_loss: 0.4855 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00412: val_acc did not improve from 0.91190\n",
            "Epoch 413/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2888 - acc: 0.9675 - val_loss: 0.4822 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.91190\n",
            "Epoch 414/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2818 - acc: 0.9680 - val_loss: 0.4790 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.91190\n",
            "Epoch 415/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2801 - acc: 0.9695 - val_loss: 0.4769 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00415: val_acc improved from 0.91190 to 0.91280, saving model to /content/saved_models/cifar10_ResNet32v1_model.415.h5\n",
            "Epoch 416/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2834 - acc: 0.9681 - val_loss: 0.4845 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.91280\n",
            "Epoch 417/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2903 - acc: 0.9704 - val_loss: 0.4862 - val_acc: 0.9094\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.91280\n",
            "Epoch 418/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2812 - acc: 0.9707 - val_loss: 0.4902 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.91280\n",
            "Epoch 419/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2711 - acc: 0.9719 - val_loss: 0.4873 - val_acc: 0.9102\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.91280\n",
            "Epoch 420/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2748 - acc: 0.9709 - val_loss: 0.4884 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.91280\n",
            "Epoch 421/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2788 - acc: 0.9691 - val_loss: 0.4766 - val_acc: 0.9134\n",
            "\n",
            "Epoch 00421: val_acc improved from 0.91280 to 0.91340, saving model to /content/saved_models/cifar10_ResNet32v1_model.421.h5\n",
            "Epoch 422/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2723 - acc: 0.9703 - val_loss: 0.4791 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00422: val_acc did not improve from 0.91340\n",
            "Epoch 423/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2681 - acc: 0.9719 - val_loss: 0.4798 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.91340\n",
            "Epoch 424/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2626 - acc: 0.9747 - val_loss: 0.4822 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.91340\n",
            "Epoch 425/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2658 - acc: 0.9718 - val_loss: 0.4845 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.91340\n",
            "Epoch 426/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2633 - acc: 0.9732 - val_loss: 0.4857 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.91340\n",
            "Epoch 427/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2702 - acc: 0.9701 - val_loss: 0.4886 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.91340\n",
            "Epoch 428/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2621 - acc: 0.9757 - val_loss: 0.4850 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.91340\n",
            "Epoch 429/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2683 - acc: 0.9698 - val_loss: 0.4800 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.91340\n",
            "Epoch 430/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2677 - acc: 0.9730 - val_loss: 0.4829 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.91340\n",
            "Epoch 431/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2655 - acc: 0.9706 - val_loss: 0.4855 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.91340\n",
            "Epoch 432/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2549 - acc: 0.9743 - val_loss: 0.4802 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.91340\n",
            "Epoch 433/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2605 - acc: 0.9751 - val_loss: 0.4808 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.91340\n",
            "Epoch 434/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2624 - acc: 0.9723 - val_loss: 0.4874 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00434: val_acc did not improve from 0.91340\n",
            "Epoch 435/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2623 - acc: 0.9705 - val_loss: 0.4789 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.91340\n",
            "Epoch 436/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2557 - acc: 0.9733 - val_loss: 0.4796 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00436: val_acc improved from 0.91340 to 0.91370, saving model to /content/saved_models/cifar10_ResNet32v1_model.436.h5\n",
            "Epoch 437/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2555 - acc: 0.9730 - val_loss: 0.4960 - val_acc: 0.9091\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.91370\n",
            "Epoch 438/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2522 - acc: 0.9751 - val_loss: 0.4822 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.91370\n",
            "Epoch 439/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2584 - acc: 0.9738 - val_loss: 0.4777 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00439: val_acc improved from 0.91370 to 0.91600, saving model to /content/saved_models/cifar10_ResNet32v1_model.439.h5\n",
            "Epoch 440/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2507 - acc: 0.9755 - val_loss: 0.4875 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.91600\n",
            "Epoch 441/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2513 - acc: 0.9772 - val_loss: 0.4758 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.91600\n",
            "Epoch 442/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2560 - acc: 0.9741 - val_loss: 0.4842 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.91600\n",
            "Epoch 443/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2455 - acc: 0.9773 - val_loss: 0.4845 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.91600\n",
            "Epoch 444/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2430 - acc: 0.9776 - val_loss: 0.4935 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.91600\n",
            "Epoch 445/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2425 - acc: 0.9779 - val_loss: 0.4873 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.91600\n",
            "Epoch 446/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2491 - acc: 0.9753 - val_loss: 0.4884 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.91600\n",
            "Epoch 447/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.2533 - acc: 0.9731 - val_loss: 0.4857 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.91600\n",
            "Epoch 448/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2376 - acc: 0.9792 - val_loss: 0.4804 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.91600\n",
            "Epoch 449/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2433 - acc: 0.9773 - val_loss: 0.4812 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.91600\n",
            "Epoch 450/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2407 - acc: 0.9763 - val_loss: 0.4869 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.91600\n",
            "Epoch 451/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2386 - acc: 0.9788 - val_loss: 0.4854 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.91600\n",
            "Epoch 452/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2382 - acc: 0.9769 - val_loss: 0.4826 - val_acc: 0.9141\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.91600\n",
            "Epoch 453/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2345 - acc: 0.9808 - val_loss: 0.4892 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.91600\n",
            "Epoch 454/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2314 - acc: 0.9814 - val_loss: 0.4858 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.91600\n",
            "Epoch 455/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2341 - acc: 0.9795 - val_loss: 0.4862 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.91600\n",
            "Epoch 456/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2356 - acc: 0.9792 - val_loss: 0.4914 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.91600\n",
            "Epoch 457/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2297 - acc: 0.9794 - val_loss: 0.4986 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.91600\n",
            "Epoch 458/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2314 - acc: 0.9800 - val_loss: 0.4843 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.91600\n",
            "Epoch 459/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2379 - acc: 0.9782 - val_loss: 0.4841 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.91600\n",
            "Epoch 460/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2349 - acc: 0.9799 - val_loss: 0.4942 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.91600\n",
            "Epoch 461/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2317 - acc: 0.9809 - val_loss: 0.4860 - val_acc: 0.9146\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.91600\n",
            "Epoch 462/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2293 - acc: 0.9791 - val_loss: 0.4892 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.91600\n",
            "Epoch 463/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2322 - acc: 0.9802 - val_loss: 0.4841 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.91600\n",
            "Epoch 464/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2212 - acc: 0.9837 - val_loss: 0.4751 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.91600\n",
            "Epoch 465/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2247 - acc: 0.9819 - val_loss: 0.4849 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.91600\n",
            "Epoch 466/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2265 - acc: 0.9799 - val_loss: 0.5108 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.91600\n",
            "Epoch 467/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2251 - acc: 0.9808 - val_loss: 0.4922 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.91600\n",
            "Epoch 468/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2303 - acc: 0.9816 - val_loss: 0.4852 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.91600\n",
            "Epoch 469/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2213 - acc: 0.9814 - val_loss: 0.4902 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.91600\n",
            "Epoch 470/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2235 - acc: 0.9804 - val_loss: 0.4900 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.91600\n",
            "Epoch 471/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2205 - acc: 0.9822 - val_loss: 0.4941 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.91600\n",
            "Epoch 472/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2249 - acc: 0.9807 - val_loss: 0.4889 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.91600\n",
            "Epoch 473/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2118 - acc: 0.9852 - val_loss: 0.4872 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.91600\n",
            "Epoch 474/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2216 - acc: 0.9809 - val_loss: 0.4864 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.91600\n",
            "Epoch 475/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2184 - acc: 0.9827 - val_loss: 0.4809 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.91600\n",
            "Epoch 476/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2206 - acc: 0.9820 - val_loss: 0.5168 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.91600\n",
            "Epoch 477/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2209 - acc: 0.9813 - val_loss: 0.4950 - val_acc: 0.9106\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.91600\n",
            "Epoch 478/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2192 - acc: 0.9839 - val_loss: 0.5112 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.91600\n",
            "Epoch 479/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2249 - acc: 0.9792 - val_loss: 0.5007 - val_acc: 0.9085\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.91600\n",
            "Epoch 480/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2165 - acc: 0.9834 - val_loss: 0.5050 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.91600\n",
            "Epoch 481/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2116 - acc: 0.9852 - val_loss: 0.5015 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.91600\n",
            "Epoch 482/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2139 - acc: 0.9834 - val_loss: 0.5092 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.91600\n",
            "Epoch 483/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2143 - acc: 0.9821 - val_loss: 0.4949 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.91600\n",
            "Epoch 484/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2137 - acc: 0.9835 - val_loss: 0.4893 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.91600\n",
            "Epoch 485/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2142 - acc: 0.9817 - val_loss: 0.4913 - val_acc: 0.9146\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.91600\n",
            "Epoch 486/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2189 - acc: 0.9816 - val_loss: 0.4996 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.91600\n",
            "Epoch 487/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2106 - acc: 0.9851 - val_loss: 0.4971 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.91600\n",
            "Epoch 488/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2103 - acc: 0.9834 - val_loss: 0.5069 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.91600\n",
            "Epoch 489/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2078 - acc: 0.9848 - val_loss: 0.5195 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.91600\n",
            "Epoch 490/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2063 - acc: 0.9863 - val_loss: 0.4976 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.91600\n",
            "Epoch 491/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2053 - acc: 0.9873 - val_loss: 0.5055 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.91600\n",
            "Epoch 492/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2142 - acc: 0.9813 - val_loss: 0.5056 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.91600\n",
            "Epoch 493/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2128 - acc: 0.9834 - val_loss: 0.4994 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.91600\n",
            "Epoch 494/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2138 - acc: 0.9830 - val_loss: 0.4969 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.91600\n",
            "Epoch 495/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2062 - acc: 0.9848 - val_loss: 0.4953 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.91600\n",
            "Epoch 496/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2076 - acc: 0.9832 - val_loss: 0.5261 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.91600\n",
            "Epoch 497/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2050 - acc: 0.9851 - val_loss: 0.5012 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.91600\n",
            "Epoch 498/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2046 - acc: 0.9839 - val_loss: 0.5050 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.91600\n",
            "Epoch 499/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2065 - acc: 0.9864 - val_loss: 0.4925 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.91600\n",
            "Epoch 500/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2050 - acc: 0.9860 - val_loss: 0.4919 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.91600\n",
            "Epoch 501/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2071 - acc: 0.9844 - val_loss: 0.5037 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.91600\n",
            "Epoch 502/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1996 - acc: 0.9864 - val_loss: 0.5065 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.91600\n",
            "Epoch 503/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2016 - acc: 0.9862 - val_loss: 0.5050 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.91600\n",
            "Epoch 504/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2031 - acc: 0.9851 - val_loss: 0.4894 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.91600\n",
            "Epoch 505/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2120 - acc: 0.9830 - val_loss: 0.4769 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.91600\n",
            "Epoch 506/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2069 - acc: 0.9838 - val_loss: 0.5093 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.91600\n",
            "Epoch 507/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2063 - acc: 0.9834 - val_loss: 0.5116 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.91600\n",
            "Epoch 508/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2035 - acc: 0.9844 - val_loss: 0.5057 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.91600\n",
            "Epoch 509/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1994 - acc: 0.9865 - val_loss: 0.4964 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.91600\n",
            "Epoch 510/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2005 - acc: 0.9851 - val_loss: 0.5046 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.91600\n",
            "Epoch 511/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1989 - acc: 0.9861 - val_loss: 0.5215 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.91600\n",
            "Epoch 512/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1937 - acc: 0.9883 - val_loss: 0.5091 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.91600\n",
            "Epoch 513/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1983 - acc: 0.9863 - val_loss: 0.5247 - val_acc: 0.9078\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.91600\n",
            "Epoch 514/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1979 - acc: 0.9858 - val_loss: 0.5145 - val_acc: 0.9095\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.91600\n",
            "Epoch 515/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1965 - acc: 0.9860 - val_loss: 0.5166 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.91600\n",
            "Epoch 516/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1991 - acc: 0.9850 - val_loss: 0.5081 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.91600\n",
            "Epoch 517/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1986 - acc: 0.9862 - val_loss: 0.5098 - val_acc: 0.9114\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.91600\n",
            "Epoch 518/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1975 - acc: 0.9857 - val_loss: 0.5138 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.91600\n",
            "Epoch 519/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1974 - acc: 0.9859 - val_loss: 0.5366 - val_acc: 0.9077\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.91600\n",
            "Epoch 520/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1942 - acc: 0.9847 - val_loss: 0.4999 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.91600\n",
            "Epoch 521/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1919 - acc: 0.9885 - val_loss: 0.5169 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.91600\n",
            "Epoch 522/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1910 - acc: 0.9869 - val_loss: 0.4992 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.91600\n",
            "Epoch 523/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2011 - acc: 0.9858 - val_loss: 0.5100 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.91600\n",
            "Epoch 524/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1946 - acc: 0.9859 - val_loss: 0.5109 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.91600\n",
            "Epoch 525/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1908 - acc: 0.9879 - val_loss: 0.4969 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.91600\n",
            "Epoch 526/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1928 - acc: 0.9863 - val_loss: 0.5121 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.91600\n",
            "Epoch 527/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1892 - acc: 0.9874 - val_loss: 0.5115 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.91600\n",
            "Epoch 528/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1900 - acc: 0.9885 - val_loss: 0.5082 - val_acc: 0.9123\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.91600\n",
            "Epoch 529/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1923 - acc: 0.9874 - val_loss: 0.5133 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.91600\n",
            "Epoch 530/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1972 - acc: 0.9838 - val_loss: 0.5249 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.91600\n",
            "Epoch 531/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1877 - acc: 0.9888 - val_loss: 0.5239 - val_acc: 0.9089\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.91600\n",
            "Epoch 532/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1929 - acc: 0.9861 - val_loss: 0.5001 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.91600\n",
            "Epoch 533/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1925 - acc: 0.9842 - val_loss: 0.5277 - val_acc: 0.9068\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.91600\n",
            "Epoch 534/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1871 - acc: 0.9878 - val_loss: 0.5049 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.91600\n",
            "Epoch 535/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1856 - acc: 0.9894 - val_loss: 0.5054 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.91600\n",
            "Epoch 536/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1915 - acc: 0.9866 - val_loss: 0.5117 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.91600\n",
            "Epoch 537/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1899 - acc: 0.9890 - val_loss: 0.4988 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.91600\n",
            "Epoch 538/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1871 - acc: 0.9881 - val_loss: 0.5066 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00538: val_acc improved from 0.91600 to 0.91610, saving model to /content/saved_models/cifar10_ResNet32v1_model.538.h5\n",
            "Epoch 539/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1807 - acc: 0.9901 - val_loss: 0.5023 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.91610\n",
            "Epoch 540/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1901 - acc: 0.9860 - val_loss: 0.5528 - val_acc: 0.9068\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.91610\n",
            "Epoch 541/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1849 - acc: 0.9890 - val_loss: 0.4992 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.91610\n",
            "Epoch 542/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1862 - acc: 0.9894 - val_loss: 0.5118 - val_acc: 0.9114\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.91610\n",
            "Epoch 543/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1923 - acc: 0.9858 - val_loss: 0.5015 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.91610\n",
            "Epoch 544/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1822 - acc: 0.9897 - val_loss: 0.5084 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.91610\n",
            "Epoch 545/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1850 - acc: 0.9892 - val_loss: 0.5043 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.91610\n",
            "Epoch 546/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1876 - acc: 0.9871 - val_loss: 0.4984 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.91610\n",
            "Epoch 547/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1856 - acc: 0.9883 - val_loss: 0.5319 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.91610\n",
            "Epoch 548/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1851 - acc: 0.9873 - val_loss: 0.5076 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.91610\n",
            "Epoch 549/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1832 - acc: 0.9864 - val_loss: 0.5002 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.91610\n",
            "Epoch 550/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1825 - acc: 0.9893 - val_loss: 0.5027 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.91610\n",
            "Epoch 551/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1819 - acc: 0.9886 - val_loss: 0.5041 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.91610\n",
            "Epoch 552/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1817 - acc: 0.9890 - val_loss: 0.5398 - val_acc: 0.9066\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.91610\n",
            "Epoch 553/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1869 - acc: 0.9876 - val_loss: 0.5152 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.91610\n",
            "Epoch 554/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1803 - acc: 0.9895 - val_loss: 0.5052 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.91610\n",
            "Epoch 555/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1875 - acc: 0.9864 - val_loss: 0.5072 - val_acc: 0.9123\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.91610\n",
            "Epoch 556/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1758 - acc: 0.9913 - val_loss: 0.5078 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.91610\n",
            "Epoch 557/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1878 - acc: 0.9842 - val_loss: 0.5275 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.91610\n",
            "Epoch 558/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1810 - acc: 0.9894 - val_loss: 0.5094 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.91610\n",
            "Epoch 559/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1790 - acc: 0.9891 - val_loss: 0.5042 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.91610\n",
            "Epoch 560/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1758 - acc: 0.9903 - val_loss: 0.5091 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.91610\n",
            "Epoch 561/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1730 - acc: 0.9910 - val_loss: 0.5201 - val_acc: 0.9102\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.91610\n",
            "Epoch 562/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1814 - acc: 0.9883 - val_loss: 0.4936 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.91610\n",
            "Epoch 563/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1761 - acc: 0.9882 - val_loss: 0.5118 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.91610\n",
            "Epoch 564/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1761 - acc: 0.9897 - val_loss: 0.5207 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.91610\n",
            "Epoch 565/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1796 - acc: 0.9880 - val_loss: 0.5029 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.91610\n",
            "Epoch 566/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1815 - acc: 0.9870 - val_loss: 0.4993 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.91610\n",
            "Epoch 567/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1785 - acc: 0.9888 - val_loss: 0.5082 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.91610\n",
            "Epoch 568/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1806 - acc: 0.9886 - val_loss: 0.5070 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.91610\n",
            "Epoch 569/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1754 - acc: 0.9878 - val_loss: 0.5071 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.91610\n",
            "Epoch 570/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1776 - acc: 0.9895 - val_loss: 0.5162 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.91610\n",
            "Epoch 571/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1790 - acc: 0.9880 - val_loss: 0.5201 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.91610\n",
            "Epoch 572/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1762 - acc: 0.9879 - val_loss: 0.5182 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.91610\n",
            "Epoch 573/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1757 - acc: 0.9880 - val_loss: 0.5154 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.91610\n",
            "Epoch 574/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1779 - acc: 0.9888 - val_loss: 0.5188 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.91610\n",
            "Epoch 575/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1739 - acc: 0.9877 - val_loss: 0.5057 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.91610\n",
            "Epoch 576/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1726 - acc: 0.9889 - val_loss: 0.5182 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.91610\n",
            "Epoch 577/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1766 - acc: 0.9882 - val_loss: 0.5223 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.91610\n",
            "Epoch 578/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1769 - acc: 0.9876 - val_loss: 0.5188 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.91610\n",
            "Epoch 579/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1733 - acc: 0.9890 - val_loss: 0.5235 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.91610\n",
            "Epoch 580/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1667 - acc: 0.9929 - val_loss: 0.5231 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.91610\n",
            "Epoch 581/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1707 - acc: 0.9897 - val_loss: 0.5363 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.91610\n",
            "Epoch 582/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1758 - acc: 0.9888 - val_loss: 0.5306 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.91610\n",
            "Epoch 583/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1789 - acc: 0.9872 - val_loss: 0.5380 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.91610\n",
            "Epoch 584/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1729 - acc: 0.9894 - val_loss: 0.5069 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.91610\n",
            "Epoch 585/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1697 - acc: 0.9909 - val_loss: 0.5131 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.91610\n",
            "Epoch 586/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1735 - acc: 0.9881 - val_loss: 0.5221 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.91610\n",
            "Epoch 587/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1742 - acc: 0.9881 - val_loss: 0.5340 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.91610\n",
            "Epoch 588/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1770 - acc: 0.9871 - val_loss: 0.5305 - val_acc: 0.9083\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.91610\n",
            "Epoch 589/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1712 - acc: 0.9906 - val_loss: 0.5167 - val_acc: 0.9138\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.91610\n",
            "Epoch 590/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1707 - acc: 0.9904 - val_loss: 0.5065 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.91610\n",
            "Epoch 591/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1703 - acc: 0.9900 - val_loss: 0.5019 - val_acc: 0.9138\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.91610\n",
            "Epoch 592/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1718 - acc: 0.9891 - val_loss: 0.5121 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.91610\n",
            "Epoch 593/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1736 - acc: 0.9896 - val_loss: 0.5157 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.91610\n",
            "Epoch 594/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1706 - acc: 0.9880 - val_loss: 0.5084 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.91610\n",
            "Epoch 595/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1671 - acc: 0.9893 - val_loss: 0.5304 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.91610\n",
            "Epoch 596/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1643 - acc: 0.9921 - val_loss: 0.5157 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.91610\n",
            "Epoch 597/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1685 - acc: 0.9901 - val_loss: 0.5042 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.91610\n",
            "Epoch 598/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1720 - acc: 0.9889 - val_loss: 0.5076 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.91610\n",
            "Epoch 599/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1680 - acc: 0.9903 - val_loss: 0.5071 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.91610\n",
            "Epoch 600/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1707 - acc: 0.9879 - val_loss: 0.5286 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.91610\n",
            "Epoch 601/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1657 - acc: 0.9907 - val_loss: 0.5260 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.91610\n",
            "Epoch 602/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1666 - acc: 0.9911 - val_loss: 0.5080 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00602: val_acc did not improve from 0.91610\n",
            "Epoch 603/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1722 - acc: 0.9891 - val_loss: 0.5028 - val_acc: 0.9134\n",
            "\n",
            "Epoch 00603: val_acc did not improve from 0.91610\n",
            "Epoch 604/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1660 - acc: 0.9905 - val_loss: 0.5016 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00604: val_acc did not improve from 0.91610\n",
            "Epoch 605/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1682 - acc: 0.9894 - val_loss: 0.5002 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00605: val_acc did not improve from 0.91610\n",
            "Epoch 606/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1652 - acc: 0.9923 - val_loss: 0.5000 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00606: val_acc did not improve from 0.91610\n",
            "Epoch 607/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1621 - acc: 0.9926 - val_loss: 0.4988 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00607: val_acc did not improve from 0.91610\n",
            "Epoch 608/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1599 - acc: 0.9923 - val_loss: 0.4996 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00608: val_acc improved from 0.91610 to 0.91640, saving model to /content/saved_models/cifar10_ResNet32v1_model.608.h5\n",
            "Epoch 609/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1580 - acc: 0.9945 - val_loss: 0.4982 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00609: val_acc did not improve from 0.91640\n",
            "Epoch 610/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1640 - acc: 0.9911 - val_loss: 0.4986 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00610: val_acc did not improve from 0.91640\n",
            "Epoch 611/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1630 - acc: 0.9911 - val_loss: 0.4976 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.91640\n",
            "Epoch 612/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1644 - acc: 0.9903 - val_loss: 0.4964 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00612: val_acc improved from 0.91640 to 0.91670, saving model to /content/saved_models/cifar10_ResNet32v1_model.612.h5\n",
            "Epoch 613/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1638 - acc: 0.9911 - val_loss: 0.4958 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00613: val_acc did not improve from 0.91670\n",
            "Epoch 614/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1617 - acc: 0.9923 - val_loss: 0.4945 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.91670\n",
            "Epoch 615/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1641 - acc: 0.9908 - val_loss: 0.4985 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.91670\n",
            "Epoch 616/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1589 - acc: 0.9938 - val_loss: 0.4984 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00616: val_acc did not improve from 0.91670\n",
            "Epoch 617/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1620 - acc: 0.9905 - val_loss: 0.4968 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.91670\n",
            "Epoch 618/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1603 - acc: 0.9932 - val_loss: 0.4963 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00618: val_acc improved from 0.91670 to 0.91740, saving model to /content/saved_models/cifar10_ResNet32v1_model.618.h5\n",
            "Epoch 619/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1648 - acc: 0.9909 - val_loss: 0.4966 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00619: val_acc did not improve from 0.91740\n",
            "Epoch 620/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1601 - acc: 0.9923 - val_loss: 0.4959 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.91740\n",
            "Epoch 621/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1631 - acc: 0.9910 - val_loss: 0.4939 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00621: val_acc did not improve from 0.91740\n",
            "Epoch 622/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1586 - acc: 0.9923 - val_loss: 0.4951 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.91740\n",
            "Epoch 623/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1586 - acc: 0.9931 - val_loss: 0.4979 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.91740\n",
            "Epoch 624/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1631 - acc: 0.9920 - val_loss: 0.4984 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.91740\n",
            "Epoch 625/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1590 - acc: 0.9925 - val_loss: 0.4956 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.91740\n",
            "Epoch 626/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1607 - acc: 0.9913 - val_loss: 0.4957 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.91740\n",
            "Epoch 627/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1579 - acc: 0.9930 - val_loss: 0.4948 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00627: val_acc did not improve from 0.91740\n",
            "Epoch 628/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1560 - acc: 0.9940 - val_loss: 0.4929 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00628: val_acc did not improve from 0.91740\n",
            "Epoch 629/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1593 - acc: 0.9926 - val_loss: 0.4951 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.91740\n",
            "Epoch 630/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1616 - acc: 0.9918 - val_loss: 0.4941 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00630: val_acc did not improve from 0.91740\n",
            "Epoch 631/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1602 - acc: 0.9923 - val_loss: 0.4954 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00631: val_acc did not improve from 0.91740\n",
            "Epoch 632/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1625 - acc: 0.9918 - val_loss: 0.4944 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00632: val_acc did not improve from 0.91740\n",
            "Epoch 633/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1584 - acc: 0.9929 - val_loss: 0.4940 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.91740\n",
            "Epoch 634/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1609 - acc: 0.9912 - val_loss: 0.4931 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.91740\n",
            "Epoch 635/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1599 - acc: 0.9927 - val_loss: 0.4927 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.91740\n",
            "Epoch 636/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1615 - acc: 0.9924 - val_loss: 0.4927 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.91740\n",
            "Epoch 637/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1603 - acc: 0.9936 - val_loss: 0.4946 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00637: val_acc did not improve from 0.91740\n",
            "Epoch 638/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1582 - acc: 0.9934 - val_loss: 0.4948 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.91740\n",
            "Epoch 639/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1581 - acc: 0.9936 - val_loss: 0.4908 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.91740\n",
            "Epoch 640/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1570 - acc: 0.9939 - val_loss: 0.4915 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.91740\n",
            "Epoch 641/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1579 - acc: 0.9929 - val_loss: 0.4945 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.91740\n",
            "Epoch 642/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1589 - acc: 0.9930 - val_loss: 0.4972 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.91740\n",
            "Epoch 643/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1578 - acc: 0.9927 - val_loss: 0.4964 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.91740\n",
            "Epoch 644/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1595 - acc: 0.9922 - val_loss: 0.4944 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.91740\n",
            "Epoch 645/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1585 - acc: 0.9930 - val_loss: 0.4936 - val_acc: 0.9173\n",
            "\n",
            "Epoch 00645: val_acc did not improve from 0.91740\n",
            "Epoch 646/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1554 - acc: 0.9937 - val_loss: 0.4935 - val_acc: 0.9173\n",
            "\n",
            "Epoch 00646: val_acc did not improve from 0.91740\n",
            "Epoch 647/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1555 - acc: 0.9951 - val_loss: 0.4938 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00647: val_acc improved from 0.91740 to 0.91790, saving model to /content/saved_models/cifar10_ResNet32v1_model.647.h5\n",
            "Epoch 648/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1574 - acc: 0.9940 - val_loss: 0.4953 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.91790\n",
            "Epoch 649/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1561 - acc: 0.9937 - val_loss: 0.4991 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.91790\n",
            "Epoch 650/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1551 - acc: 0.9943 - val_loss: 0.4975 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00650: val_acc did not improve from 0.91790\n",
            "Epoch 651/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1569 - acc: 0.9936 - val_loss: 0.4948 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00651: val_acc did not improve from 0.91790\n",
            "Epoch 652/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1591 - acc: 0.9930 - val_loss: 0.4985 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00652: val_acc did not improve from 0.91790\n",
            "Epoch 653/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1580 - acc: 0.9917 - val_loss: 0.4984 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00653: val_acc did not improve from 0.91790\n",
            "Epoch 654/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1527 - acc: 0.9960 - val_loss: 0.4962 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00654: val_acc did not improve from 0.91790\n",
            "Epoch 655/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1563 - acc: 0.9942 - val_loss: 0.4956 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00655: val_acc did not improve from 0.91790\n",
            "Epoch 656/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1539 - acc: 0.9968 - val_loss: 0.4949 - val_acc: 0.9181\n",
            "\n",
            "Epoch 00656: val_acc improved from 0.91790 to 0.91810, saving model to /content/saved_models/cifar10_ResNet32v1_model.656.h5\n",
            "Epoch 657/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1562 - acc: 0.9947 - val_loss: 0.4942 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00657: val_acc improved from 0.91810 to 0.91860, saving model to /content/saved_models/cifar10_ResNet32v1_model.657.h5\n",
            "Epoch 658/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1560 - acc: 0.9931 - val_loss: 0.4956 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00658: val_acc did not improve from 0.91860\n",
            "Epoch 659/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1548 - acc: 0.9943 - val_loss: 0.4960 - val_acc: 0.9173\n",
            "\n",
            "Epoch 00659: val_acc did not improve from 0.91860\n",
            "Epoch 660/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1566 - acc: 0.9950 - val_loss: 0.4958 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00660: val_acc did not improve from 0.91860\n",
            "Epoch 661/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1548 - acc: 0.9950 - val_loss: 0.4957 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00661: val_acc did not improve from 0.91860\n",
            "Epoch 662/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1592 - acc: 0.9926 - val_loss: 0.4957 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00662: val_acc did not improve from 0.91860\n",
            "Epoch 663/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1578 - acc: 0.9940 - val_loss: 0.4964 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00663: val_acc did not improve from 0.91860\n",
            "Epoch 664/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1566 - acc: 0.9931 - val_loss: 0.4985 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00664: val_acc did not improve from 0.91860\n",
            "Epoch 665/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1548 - acc: 0.9942 - val_loss: 0.4973 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00665: val_acc did not improve from 0.91860\n",
            "Epoch 666/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1561 - acc: 0.9948 - val_loss: 0.4965 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00666: val_acc did not improve from 0.91860\n",
            "Epoch 667/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1583 - acc: 0.9934 - val_loss: 0.4976 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00667: val_acc did not improve from 0.91860\n",
            "Epoch 668/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1517 - acc: 0.9956 - val_loss: 0.4973 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00668: val_acc did not improve from 0.91860\n",
            "Epoch 669/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1541 - acc: 0.9950 - val_loss: 0.4961 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00669: val_acc did not improve from 0.91860\n",
            "Epoch 670/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1533 - acc: 0.9944 - val_loss: 0.4961 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00670: val_acc did not improve from 0.91860\n",
            "Epoch 671/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1547 - acc: 0.9942 - val_loss: 0.4960 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00671: val_acc did not improve from 0.91860\n",
            "Epoch 672/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1571 - acc: 0.9936 - val_loss: 0.4960 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00672: val_acc did not improve from 0.91860\n",
            "Epoch 673/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1539 - acc: 0.9942 - val_loss: 0.4977 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00673: val_acc did not improve from 0.91860\n",
            "Epoch 674/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1560 - acc: 0.9943 - val_loss: 0.5027 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00674: val_acc did not improve from 0.91860\n",
            "Epoch 675/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1553 - acc: 0.9936 - val_loss: 0.5009 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00675: val_acc did not improve from 0.91860\n",
            "Epoch 676/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1567 - acc: 0.9946 - val_loss: 0.4971 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00676: val_acc did not improve from 0.91860\n",
            "Epoch 677/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1549 - acc: 0.9948 - val_loss: 0.4983 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00677: val_acc did not improve from 0.91860\n",
            "Epoch 678/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1526 - acc: 0.9955 - val_loss: 0.4999 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00678: val_acc did not improve from 0.91860\n",
            "Epoch 679/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1531 - acc: 0.9940 - val_loss: 0.4997 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00679: val_acc did not improve from 0.91860\n",
            "Epoch 680/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1546 - acc: 0.9950 - val_loss: 0.4959 - val_acc: 0.9175\n",
            "\n",
            "Epoch 00680: val_acc did not improve from 0.91860\n",
            "Epoch 681/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1557 - acc: 0.9949 - val_loss: 0.4938 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00681: val_acc did not improve from 0.91860\n",
            "Epoch 682/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1543 - acc: 0.9931 - val_loss: 0.4966 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00682: val_acc did not improve from 0.91860\n",
            "Epoch 683/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1542 - acc: 0.9944 - val_loss: 0.4955 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00683: val_acc did not improve from 0.91860\n",
            "Epoch 684/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1538 - acc: 0.9946 - val_loss: 0.4967 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00684: val_acc did not improve from 0.91860\n",
            "Epoch 685/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1568 - acc: 0.9929 - val_loss: 0.4957 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00685: val_acc did not improve from 0.91860\n",
            "Epoch 686/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1571 - acc: 0.9925 - val_loss: 0.4969 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00686: val_acc did not improve from 0.91860\n",
            "Epoch 687/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1580 - acc: 0.9923 - val_loss: 0.5001 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00687: val_acc did not improve from 0.91860\n",
            "Epoch 688/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1547 - acc: 0.9933 - val_loss: 0.4991 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00688: val_acc did not improve from 0.91860\n",
            "Epoch 689/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1541 - acc: 0.9945 - val_loss: 0.4981 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00689: val_acc did not improve from 0.91860\n",
            "Epoch 690/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1523 - acc: 0.9946 - val_loss: 0.4959 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00690: val_acc did not improve from 0.91860\n",
            "Epoch 691/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1574 - acc: 0.9908 - val_loss: 0.4990 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00691: val_acc did not improve from 0.91860\n",
            "Epoch 692/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1497 - acc: 0.9959 - val_loss: 0.5001 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00692: val_acc did not improve from 0.91860\n",
            "Epoch 693/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1523 - acc: 0.9940 - val_loss: 0.4983 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00693: val_acc did not improve from 0.91860\n",
            "Epoch 694/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1558 - acc: 0.9935 - val_loss: 0.4997 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00694: val_acc did not improve from 0.91860\n",
            "Epoch 695/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1571 - acc: 0.9924 - val_loss: 0.4990 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00695: val_acc did not improve from 0.91860\n",
            "Epoch 696/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1564 - acc: 0.9926 - val_loss: 0.4983 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00696: val_acc did not improve from 0.91860\n",
            "Epoch 697/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1548 - acc: 0.9939 - val_loss: 0.4981 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00697: val_acc did not improve from 0.91860\n",
            "Epoch 698/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1574 - acc: 0.9924 - val_loss: 0.4980 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00698: val_acc did not improve from 0.91860\n",
            "Epoch 699/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1543 - acc: 0.9941 - val_loss: 0.5005 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00699: val_acc did not improve from 0.91860\n",
            "Epoch 700/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1542 - acc: 0.9925 - val_loss: 0.5021 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00700: val_acc did not improve from 0.91860\n",
            "Epoch 701/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1568 - acc: 0.9929 - val_loss: 0.5015 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00701: val_acc did not improve from 0.91860\n",
            "Epoch 702/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1527 - acc: 0.9955 - val_loss: 0.5027 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00702: val_acc did not improve from 0.91860\n",
            "Epoch 703/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1519 - acc: 0.9941 - val_loss: 0.5008 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00703: val_acc did not improve from 0.91860\n",
            "Epoch 704/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1529 - acc: 0.9942 - val_loss: 0.5023 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00704: val_acc did not improve from 0.91860\n",
            "Epoch 705/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1529 - acc: 0.9949 - val_loss: 0.5015 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00705: val_acc did not improve from 0.91860\n",
            "Epoch 706/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1543 - acc: 0.9943 - val_loss: 0.4983 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00706: val_acc did not improve from 0.91860\n",
            "Epoch 707/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1525 - acc: 0.9944 - val_loss: 0.5006 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00707: val_acc did not improve from 0.91860\n",
            "Epoch 708/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1539 - acc: 0.9946 - val_loss: 0.4992 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00708: val_acc did not improve from 0.91860\n",
            "Epoch 709/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1492 - acc: 0.9960 - val_loss: 0.5002 - val_acc: 0.9175\n",
            "\n",
            "Epoch 00709: val_acc did not improve from 0.91860\n",
            "Epoch 710/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1524 - acc: 0.9946 - val_loss: 0.5016 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00710: val_acc did not improve from 0.91860\n",
            "Epoch 711/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1534 - acc: 0.9921 - val_loss: 0.5022 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00711: val_acc did not improve from 0.91860\n",
            "Epoch 712/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1502 - acc: 0.9956 - val_loss: 0.5056 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00712: val_acc did not improve from 0.91860\n",
            "Epoch 713/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1555 - acc: 0.9925 - val_loss: 0.5044 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00713: val_acc did not improve from 0.91860\n",
            "Epoch 714/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1501 - acc: 0.9957 - val_loss: 0.5047 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00714: val_acc did not improve from 0.91860\n",
            "Epoch 715/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1572 - acc: 0.9928 - val_loss: 0.5056 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00715: val_acc did not improve from 0.91860\n",
            "Epoch 716/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1569 - acc: 0.9931 - val_loss: 0.5057 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00716: val_acc did not improve from 0.91860\n",
            "Epoch 717/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1526 - acc: 0.9938 - val_loss: 0.5060 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00717: val_acc did not improve from 0.91860\n",
            "Epoch 718/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1548 - acc: 0.9947 - val_loss: 0.5047 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00718: val_acc did not improve from 0.91860\n",
            "Epoch 719/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1530 - acc: 0.9944 - val_loss: 0.5031 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00719: val_acc did not improve from 0.91860\n",
            "Epoch 720/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1549 - acc: 0.9924 - val_loss: 0.5055 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00720: val_acc did not improve from 0.91860\n",
            "Epoch 721/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1539 - acc: 0.9939 - val_loss: 0.5047 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00721: val_acc did not improve from 0.91860\n",
            "Epoch 722/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1553 - acc: 0.9933 - val_loss: 0.5028 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00722: val_acc did not improve from 0.91860\n",
            "Epoch 723/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1530 - acc: 0.9942 - val_loss: 0.5043 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00723: val_acc did not improve from 0.91860\n",
            "Epoch 724/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1485 - acc: 0.9960 - val_loss: 0.5043 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00724: val_acc did not improve from 0.91860\n",
            "Epoch 725/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1549 - acc: 0.9922 - val_loss: 0.5061 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00725: val_acc did not improve from 0.91860\n",
            "Epoch 726/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1495 - acc: 0.9962 - val_loss: 0.5072 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00726: val_acc did not improve from 0.91860\n",
            "Epoch 727/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1539 - acc: 0.9929 - val_loss: 0.5055 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00727: val_acc did not improve from 0.91860\n",
            "Epoch 728/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1517 - acc: 0.9937 - val_loss: 0.5071 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00728: val_acc did not improve from 0.91860\n",
            "Epoch 729/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1552 - acc: 0.9942 - val_loss: 0.5058 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00729: val_acc did not improve from 0.91860\n",
            "Epoch 730/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1523 - acc: 0.9946 - val_loss: 0.5050 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00730: val_acc did not improve from 0.91860\n",
            "Epoch 731/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1489 - acc: 0.9960 - val_loss: 0.5030 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00731: val_acc did not improve from 0.91860\n",
            "Epoch 732/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1495 - acc: 0.9953 - val_loss: 0.5053 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00732: val_acc did not improve from 0.91860\n",
            "Epoch 733/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1499 - acc: 0.9957 - val_loss: 0.5058 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00733: val_acc did not improve from 0.91860\n",
            "Epoch 734/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1510 - acc: 0.9953 - val_loss: 0.5054 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00734: val_acc did not improve from 0.91860\n",
            "Epoch 735/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1511 - acc: 0.9955 - val_loss: 0.5067 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00735: val_acc did not improve from 0.91860\n",
            "Epoch 736/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1534 - acc: 0.9932 - val_loss: 0.5032 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00736: val_acc did not improve from 0.91860\n",
            "Epoch 737/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1478 - acc: 0.9963 - val_loss: 0.5046 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00737: val_acc did not improve from 0.91860\n",
            "Epoch 738/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1533 - acc: 0.9945 - val_loss: 0.5041 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00738: val_acc did not improve from 0.91860\n",
            "Epoch 739/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1506 - acc: 0.9957 - val_loss: 0.5008 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00739: val_acc did not improve from 0.91860\n",
            "Epoch 740/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1556 - acc: 0.9928 - val_loss: 0.5004 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00740: val_acc did not improve from 0.91860\n",
            "Epoch 741/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1488 - acc: 0.9948 - val_loss: 0.5000 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00741: val_acc did not improve from 0.91860\n",
            "Epoch 742/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1513 - acc: 0.9952 - val_loss: 0.5027 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00742: val_acc did not improve from 0.91860\n",
            "Epoch 743/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1529 - acc: 0.9939 - val_loss: 0.5028 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00743: val_acc did not improve from 0.91860\n",
            "Epoch 744/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1547 - acc: 0.9938 - val_loss: 0.5037 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00744: val_acc did not improve from 0.91860\n",
            "Epoch 745/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1498 - acc: 0.9950 - val_loss: 0.5016 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00745: val_acc did not improve from 0.91860\n",
            "Epoch 746/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1522 - acc: 0.9938 - val_loss: 0.5006 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00746: val_acc did not improve from 0.91860\n",
            "Epoch 747/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1497 - acc: 0.9952 - val_loss: 0.5016 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00747: val_acc did not improve from 0.91860\n",
            "Epoch 748/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1490 - acc: 0.9950 - val_loss: 0.5034 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00748: val_acc did not improve from 0.91860\n",
            "Epoch 749/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1515 - acc: 0.9947 - val_loss: 0.5007 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00749: val_acc did not improve from 0.91860\n",
            "Epoch 750/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1550 - acc: 0.9936 - val_loss: 0.4990 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00750: val_acc did not improve from 0.91860\n",
            "Epoch 751/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1502 - acc: 0.9943 - val_loss: 0.4987 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00751: val_acc did not improve from 0.91860\n",
            "Epoch 752/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1489 - acc: 0.9952 - val_loss: 0.5021 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00752: val_acc did not improve from 0.91860\n",
            "Epoch 753/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1493 - acc: 0.9956 - val_loss: 0.5023 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00753: val_acc did not improve from 0.91860\n",
            "Epoch 754/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1516 - acc: 0.9946 - val_loss: 0.5028 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00754: val_acc did not improve from 0.91860\n",
            "Epoch 755/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1523 - acc: 0.9925 - val_loss: 0.5035 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00755: val_acc did not improve from 0.91860\n",
            "Epoch 756/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1472 - acc: 0.9961 - val_loss: 0.5040 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00756: val_acc did not improve from 0.91860\n",
            "Epoch 757/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1493 - acc: 0.9958 - val_loss: 0.5024 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00757: val_acc did not improve from 0.91860\n",
            "Epoch 758/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1507 - acc: 0.9939 - val_loss: 0.5014 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00758: val_acc did not improve from 0.91860\n",
            "Epoch 759/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1553 - acc: 0.9912 - val_loss: 0.5045 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00759: val_acc did not improve from 0.91860\n",
            "Epoch 760/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1543 - acc: 0.9932 - val_loss: 0.5063 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00760: val_acc did not improve from 0.91860\n",
            "Epoch 761/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1525 - acc: 0.9940 - val_loss: 0.5045 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00761: val_acc did not improve from 0.91860\n",
            "Epoch 762/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1486 - acc: 0.9953 - val_loss: 0.5031 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00762: val_acc did not improve from 0.91860\n",
            "Epoch 763/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1522 - acc: 0.9948 - val_loss: 0.5050 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00763: val_acc did not improve from 0.91860\n",
            "Epoch 764/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1483 - acc: 0.9956 - val_loss: 0.5041 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00764: val_acc did not improve from 0.91860\n",
            "Epoch 765/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1509 - acc: 0.9949 - val_loss: 0.5029 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00765: val_acc did not improve from 0.91860\n",
            "Epoch 766/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1522 - acc: 0.9929 - val_loss: 0.5037 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00766: val_acc did not improve from 0.91860\n",
            "Epoch 767/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1509 - acc: 0.9937 - val_loss: 0.5041 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00767: val_acc did not improve from 0.91860\n",
            "Epoch 768/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1485 - acc: 0.9950 - val_loss: 0.5032 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00768: val_acc did not improve from 0.91860\n",
            "Epoch 769/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1512 - acc: 0.9933 - val_loss: 0.5067 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00769: val_acc did not improve from 0.91860\n",
            "Epoch 770/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1485 - acc: 0.9956 - val_loss: 0.5069 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00770: val_acc did not improve from 0.91860\n",
            "Epoch 771/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1464 - acc: 0.9970 - val_loss: 0.5033 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00771: val_acc did not improve from 0.91860\n",
            "Epoch 772/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1483 - acc: 0.9948 - val_loss: 0.5051 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00772: val_acc did not improve from 0.91860\n",
            "Epoch 773/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1545 - acc: 0.9929 - val_loss: 0.5084 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00773: val_acc did not improve from 0.91860\n",
            "Epoch 774/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1508 - acc: 0.9947 - val_loss: 0.5059 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00774: val_acc did not improve from 0.91860\n",
            "Epoch 775/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1498 - acc: 0.9947 - val_loss: 0.5039 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00775: val_acc did not improve from 0.91860\n",
            "Epoch 776/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1493 - acc: 0.9947 - val_loss: 0.5056 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00776: val_acc did not improve from 0.91860\n",
            "Epoch 777/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1480 - acc: 0.9966 - val_loss: 0.5060 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00777: val_acc did not improve from 0.91860\n",
            "Epoch 778/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1516 - acc: 0.9949 - val_loss: 0.5070 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00778: val_acc did not improve from 0.91860\n",
            "Epoch 779/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1487 - acc: 0.9953 - val_loss: 0.5061 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00779: val_acc did not improve from 0.91860\n",
            "Epoch 780/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1464 - acc: 0.9962 - val_loss: 0.5071 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00780: val_acc did not improve from 0.91860\n",
            "Epoch 781/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1535 - acc: 0.9926 - val_loss: 0.5059 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00781: val_acc did not improve from 0.91860\n",
            "Epoch 782/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1519 - acc: 0.9937 - val_loss: 0.5036 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00782: val_acc did not improve from 0.91860\n",
            "Epoch 783/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1504 - acc: 0.9935 - val_loss: 0.5045 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00783: val_acc did not improve from 0.91860\n",
            "Epoch 784/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1538 - acc: 0.9926 - val_loss: 0.5088 - val_acc: 0.9150\n",
            "\n",
            "Epoch 00784: val_acc did not improve from 0.91860\n",
            "Epoch 785/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1477 - acc: 0.9964 - val_loss: 0.5079 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00785: val_acc did not improve from 0.91860\n",
            "Epoch 786/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1481 - acc: 0.9948 - val_loss: 0.5046 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00786: val_acc did not improve from 0.91860\n",
            "Epoch 787/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1481 - acc: 0.9954 - val_loss: 0.5046 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00787: val_acc did not improve from 0.91860\n",
            "Epoch 788/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1516 - acc: 0.9931 - val_loss: 0.5029 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00788: val_acc did not improve from 0.91860\n",
            "Epoch 789/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1498 - acc: 0.9935 - val_loss: 0.5036 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00789: val_acc did not improve from 0.91860\n",
            "Epoch 790/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1482 - acc: 0.9953 - val_loss: 0.5059 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00790: val_acc did not improve from 0.91860\n",
            "Epoch 791/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1466 - acc: 0.9960 - val_loss: 0.5054 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00791: val_acc did not improve from 0.91860\n",
            "Epoch 792/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1489 - acc: 0.9949 - val_loss: 0.5046 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00792: val_acc did not improve from 0.91860\n",
            "Epoch 793/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1441 - acc: 0.9966 - val_loss: 0.5041 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00793: val_acc did not improve from 0.91860\n",
            "Epoch 794/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1462 - acc: 0.9963 - val_loss: 0.5076 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00794: val_acc did not improve from 0.91860\n",
            "Epoch 795/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1441 - acc: 0.9974 - val_loss: 0.5053 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00795: val_acc did not improve from 0.91860\n",
            "Epoch 796/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1498 - acc: 0.9943 - val_loss: 0.5081 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00796: val_acc did not improve from 0.91860\n",
            "Epoch 797/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1503 - acc: 0.9951 - val_loss: 0.5062 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00797: val_acc did not improve from 0.91860\n",
            "Epoch 798/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1474 - acc: 0.9964 - val_loss: 0.5041 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00798: val_acc did not improve from 0.91860\n",
            "Epoch 799/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1441 - acc: 0.9966 - val_loss: 0.5062 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00799: val_acc did not improve from 0.91860\n",
            "Epoch 800/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1487 - acc: 0.9954 - val_loss: 0.5072 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00800: val_acc did not improve from 0.91860\n",
            "Epoch 801/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1478 - acc: 0.9943 - val_loss: 0.5039 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00801: val_acc did not improve from 0.91860\n",
            "Epoch 802/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1491 - acc: 0.9940 - val_loss: 0.5045 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00802: val_acc did not improve from 0.91860\n",
            "Epoch 803/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1464 - acc: 0.9969 - val_loss: 0.5045 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00803: val_acc did not improve from 0.91860\n",
            "Epoch 804/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1477 - acc: 0.9948 - val_loss: 0.5052 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00804: val_acc did not improve from 0.91860\n",
            "Epoch 805/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1501 - acc: 0.9938 - val_loss: 0.5057 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00805: val_acc did not improve from 0.91860\n",
            "Epoch 806/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1520 - acc: 0.9939 - val_loss: 0.5053 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00806: val_acc did not improve from 0.91860\n",
            "Epoch 807/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1498 - acc: 0.9938 - val_loss: 0.5050 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00807: val_acc did not improve from 0.91860\n",
            "Epoch 808/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1531 - acc: 0.9938 - val_loss: 0.5050 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00808: val_acc did not improve from 0.91860\n",
            "Epoch 809/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1480 - acc: 0.9955 - val_loss: 0.5051 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00809: val_acc did not improve from 0.91860\n",
            "Epoch 810/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1520 - acc: 0.9935 - val_loss: 0.5051 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00810: val_acc did not improve from 0.91860\n",
            "Epoch 811/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1495 - acc: 0.9945 - val_loss: 0.5053 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00811: val_acc did not improve from 0.91860\n",
            "Epoch 812/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1478 - acc: 0.9953 - val_loss: 0.5053 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00812: val_acc did not improve from 0.91860\n",
            "Epoch 813/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1508 - acc: 0.9935 - val_loss: 0.5061 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00813: val_acc did not improve from 0.91860\n",
            "Epoch 814/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1489 - acc: 0.9951 - val_loss: 0.5066 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00814: val_acc did not improve from 0.91860\n",
            "Epoch 815/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1485 - acc: 0.9950 - val_loss: 0.5061 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00815: val_acc did not improve from 0.91860\n",
            "Epoch 816/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1468 - acc: 0.9954 - val_loss: 0.5060 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00816: val_acc did not improve from 0.91860\n",
            "Epoch 817/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1484 - acc: 0.9946 - val_loss: 0.5057 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00817: val_acc did not improve from 0.91860\n",
            "Epoch 818/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1490 - acc: 0.9945 - val_loss: 0.5064 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00818: val_acc did not improve from 0.91860\n",
            "Epoch 819/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1474 - acc: 0.9957 - val_loss: 0.5074 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00819: val_acc did not improve from 0.91860\n",
            "Epoch 820/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1488 - acc: 0.9942 - val_loss: 0.5066 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00820: val_acc did not improve from 0.91860\n",
            "Epoch 821/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1491 - acc: 0.9944 - val_loss: 0.5070 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00821: val_acc did not improve from 0.91860\n",
            "Epoch 822/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1483 - acc: 0.9945 - val_loss: 0.5063 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00822: val_acc did not improve from 0.91860\n",
            "Epoch 823/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1460 - acc: 0.9969 - val_loss: 0.5065 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00823: val_acc did not improve from 0.91860\n",
            "Epoch 824/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1473 - acc: 0.9949 - val_loss: 0.5066 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00824: val_acc did not improve from 0.91860\n",
            "Epoch 825/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1464 - acc: 0.9960 - val_loss: 0.5076 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00825: val_acc did not improve from 0.91860\n",
            "Epoch 826/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1481 - acc: 0.9948 - val_loss: 0.5075 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00826: val_acc did not improve from 0.91860\n",
            "Epoch 827/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1497 - acc: 0.9942 - val_loss: 0.5074 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00827: val_acc did not improve from 0.91860\n",
            "Epoch 828/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1480 - acc: 0.9951 - val_loss: 0.5071 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00828: val_acc did not improve from 0.91860\n",
            "Epoch 829/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1491 - acc: 0.9936 - val_loss: 0.5066 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00829: val_acc did not improve from 0.91860\n",
            "Epoch 830/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1475 - acc: 0.9942 - val_loss: 0.5060 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00830: val_acc did not improve from 0.91860\n",
            "Epoch 831/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1459 - acc: 0.9959 - val_loss: 0.5064 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00831: val_acc did not improve from 0.91860\n",
            "Epoch 832/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1470 - acc: 0.9954 - val_loss: 0.5061 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00832: val_acc did not improve from 0.91860\n",
            "Epoch 833/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1487 - acc: 0.9952 - val_loss: 0.5060 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00833: val_acc did not improve from 0.91860\n",
            "Epoch 834/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1462 - acc: 0.9971 - val_loss: 0.5062 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00834: val_acc did not improve from 0.91860\n",
            "Epoch 835/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1470 - acc: 0.9958 - val_loss: 0.5067 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00835: val_acc did not improve from 0.91860\n",
            "Epoch 836/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1499 - acc: 0.9951 - val_loss: 0.5057 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00836: val_acc did not improve from 0.91860\n",
            "Epoch 837/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1475 - acc: 0.9952 - val_loss: 0.5061 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00837: val_acc did not improve from 0.91860\n",
            "Epoch 838/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1492 - acc: 0.9937 - val_loss: 0.5062 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00838: val_acc did not improve from 0.91860\n",
            "Epoch 839/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1495 - acc: 0.9941 - val_loss: 0.5063 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00839: val_acc did not improve from 0.91860\n",
            "Epoch 840/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1486 - acc: 0.9945 - val_loss: 0.5065 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00840: val_acc did not improve from 0.91860\n",
            "Epoch 841/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1492 - acc: 0.9948 - val_loss: 0.5064 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00841: val_acc did not improve from 0.91860\n",
            "Epoch 842/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1515 - acc: 0.9940 - val_loss: 0.5063 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00842: val_acc did not improve from 0.91860\n",
            "Epoch 843/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1473 - acc: 0.9958 - val_loss: 0.5054 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00843: val_acc did not improve from 0.91860\n",
            "Epoch 844/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1515 - acc: 0.9940 - val_loss: 0.5075 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00844: val_acc did not improve from 0.91860\n",
            "Epoch 845/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1494 - acc: 0.9954 - val_loss: 0.5066 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00845: val_acc did not improve from 0.91860\n",
            "Epoch 846/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1520 - acc: 0.9936 - val_loss: 0.5065 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00846: val_acc did not improve from 0.91860\n",
            "Epoch 847/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1503 - acc: 0.9928 - val_loss: 0.5065 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00847: val_acc did not improve from 0.91860\n",
            "Epoch 848/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1489 - acc: 0.9954 - val_loss: 0.5070 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00848: val_acc did not improve from 0.91860\n",
            "Epoch 849/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1471 - acc: 0.9957 - val_loss: 0.5064 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00849: val_acc did not improve from 0.91860\n",
            "Epoch 850/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1485 - acc: 0.9954 - val_loss: 0.5067 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00850: val_acc did not improve from 0.91860\n",
            "Epoch 851/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1484 - acc: 0.9956 - val_loss: 0.5064 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00851: val_acc did not improve from 0.91860\n",
            "Epoch 852/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1458 - acc: 0.9961 - val_loss: 0.5068 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00852: val_acc did not improve from 0.91860\n",
            "Epoch 853/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1494 - acc: 0.9937 - val_loss: 0.5061 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00853: val_acc did not improve from 0.91860\n",
            "Epoch 854/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1481 - acc: 0.9951 - val_loss: 0.5068 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00854: val_acc did not improve from 0.91860\n",
            "Epoch 855/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1477 - acc: 0.9957 - val_loss: 0.5069 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00855: val_acc did not improve from 0.91860\n",
            "Epoch 856/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1493 - acc: 0.9945 - val_loss: 0.5064 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00856: val_acc did not improve from 0.91860\n",
            "Epoch 857/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1496 - acc: 0.9940 - val_loss: 0.5062 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00857: val_acc did not improve from 0.91860\n",
            "Epoch 858/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1500 - acc: 0.9954 - val_loss: 0.5065 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00858: val_acc did not improve from 0.91860\n",
            "Epoch 859/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1482 - acc: 0.9939 - val_loss: 0.5074 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00859: val_acc did not improve from 0.91860\n",
            "Epoch 860/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1495 - acc: 0.9943 - val_loss: 0.5067 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00860: val_acc did not improve from 0.91860\n",
            "Epoch 861/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1474 - acc: 0.9953 - val_loss: 0.5056 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00861: val_acc did not improve from 0.91860\n",
            "Epoch 862/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1498 - acc: 0.9952 - val_loss: 0.5058 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00862: val_acc did not improve from 0.91860\n",
            "Epoch 863/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1476 - acc: 0.9956 - val_loss: 0.5056 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00863: val_acc did not improve from 0.91860\n",
            "Epoch 864/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1472 - acc: 0.9959 - val_loss: 0.5064 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00864: val_acc did not improve from 0.91860\n",
            "Epoch 865/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1471 - acc: 0.9953 - val_loss: 0.5070 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00865: val_acc did not improve from 0.91860\n",
            "Epoch 866/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1462 - acc: 0.9959 - val_loss: 0.5083 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00866: val_acc did not improve from 0.91860\n",
            "Epoch 867/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1482 - acc: 0.9948 - val_loss: 0.5070 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00867: val_acc did not improve from 0.91860\n",
            "Epoch 868/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1508 - acc: 0.9928 - val_loss: 0.5069 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00868: val_acc did not improve from 0.91860\n",
            "Epoch 869/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1470 - acc: 0.9958 - val_loss: 0.5070 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00869: val_acc did not improve from 0.91860\n",
            "Epoch 870/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1460 - acc: 0.9958 - val_loss: 0.5071 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00870: val_acc did not improve from 0.91860\n",
            "Epoch 871/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1492 - acc: 0.9940 - val_loss: 0.5076 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00871: val_acc did not improve from 0.91860\n",
            "Epoch 872/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1468 - acc: 0.9953 - val_loss: 0.5070 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00872: val_acc did not improve from 0.91860\n",
            "Epoch 873/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1492 - acc: 0.9940 - val_loss: 0.5075 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00873: val_acc did not improve from 0.91860\n",
            "Epoch 874/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1469 - acc: 0.9946 - val_loss: 0.5067 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00874: val_acc did not improve from 0.91860\n",
            "Epoch 875/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1428 - acc: 0.9977 - val_loss: 0.5069 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00875: val_acc did not improve from 0.91860\n",
            "Epoch 876/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1465 - acc: 0.9953 - val_loss: 0.5068 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00876: val_acc did not improve from 0.91860\n",
            "Epoch 877/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1452 - acc: 0.9970 - val_loss: 0.5069 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00877: val_acc did not improve from 0.91860\n",
            "Epoch 878/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1468 - acc: 0.9951 - val_loss: 0.5071 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00878: val_acc did not improve from 0.91860\n",
            "Epoch 879/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1538 - acc: 0.9928 - val_loss: 0.5072 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00879: val_acc did not improve from 0.91860\n",
            "Epoch 880/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1477 - acc: 0.9954 - val_loss: 0.5061 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00880: val_acc did not improve from 0.91860\n",
            "Epoch 881/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1460 - acc: 0.9959 - val_loss: 0.5073 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00881: val_acc did not improve from 0.91860\n",
            "Epoch 882/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1495 - acc: 0.9948 - val_loss: 0.5070 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00882: val_acc did not improve from 0.91860\n",
            "Epoch 883/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1482 - acc: 0.9949 - val_loss: 0.5067 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00883: val_acc did not improve from 0.91860\n",
            "Epoch 884/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1490 - acc: 0.9943 - val_loss: 0.5075 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00884: val_acc did not improve from 0.91860\n",
            "Epoch 885/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1481 - acc: 0.9953 - val_loss: 0.5074 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00885: val_acc did not improve from 0.91860\n",
            "Epoch 886/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1470 - acc: 0.9954 - val_loss: 0.5076 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00886: val_acc did not improve from 0.91860\n",
            "Epoch 887/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1460 - acc: 0.9954 - val_loss: 0.5067 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00887: val_acc did not improve from 0.91860\n",
            "Epoch 888/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1471 - acc: 0.9958 - val_loss: 0.5070 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00888: val_acc did not improve from 0.91860\n",
            "Epoch 889/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1482 - acc: 0.9946 - val_loss: 0.5068 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00889: val_acc did not improve from 0.91860\n",
            "Epoch 890/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1476 - acc: 0.9954 - val_loss: 0.5080 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00890: val_acc did not improve from 0.91860\n",
            "Epoch 891/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1479 - acc: 0.9945 - val_loss: 0.5075 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00891: val_acc did not improve from 0.91860\n",
            "Epoch 892/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1487 - acc: 0.9946 - val_loss: 0.5079 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00892: val_acc did not improve from 0.91860\n",
            "Epoch 893/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1456 - acc: 0.9969 - val_loss: 0.5074 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00893: val_acc did not improve from 0.91860\n",
            "Epoch 894/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1485 - acc: 0.9941 - val_loss: 0.5076 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00894: val_acc did not improve from 0.91860\n",
            "Epoch 895/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1463 - acc: 0.9962 - val_loss: 0.5073 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00895: val_acc did not improve from 0.91860\n",
            "Epoch 896/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1476 - acc: 0.9945 - val_loss: 0.5084 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00896: val_acc did not improve from 0.91860\n",
            "Epoch 897/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1495 - acc: 0.9953 - val_loss: 0.5079 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00897: val_acc did not improve from 0.91860\n",
            "Epoch 898/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1499 - acc: 0.9945 - val_loss: 0.5066 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00898: val_acc did not improve from 0.91860\n",
            "Epoch 899/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1468 - acc: 0.9953 - val_loss: 0.5067 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00899: val_acc did not improve from 0.91860\n",
            "Epoch 900/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1481 - acc: 0.9954 - val_loss: 0.5082 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00900: val_acc did not improve from 0.91860\n",
            "Epoch 901/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1478 - acc: 0.9955 - val_loss: 0.5073 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00901: val_acc did not improve from 0.91860\n",
            "Epoch 902/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1528 - acc: 0.9935 - val_loss: 0.5077 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00902: val_acc did not improve from 0.91860\n",
            "Epoch 903/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1472 - acc: 0.9947 - val_loss: 0.5073 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00903: val_acc did not improve from 0.91860\n",
            "Epoch 904/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1488 - acc: 0.9944 - val_loss: 0.5059 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00904: val_acc did not improve from 0.91860\n",
            "Epoch 905/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1445 - acc: 0.9968 - val_loss: 0.5072 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00905: val_acc did not improve from 0.91860\n",
            "Epoch 906/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1449 - acc: 0.9962 - val_loss: 0.5060 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00906: val_acc did not improve from 0.91860\n",
            "Epoch 907/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1466 - acc: 0.9958 - val_loss: 0.5066 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00907: val_acc did not improve from 0.91860\n",
            "Epoch 908/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1475 - acc: 0.9960 - val_loss: 0.5071 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00908: val_acc did not improve from 0.91860\n",
            "Epoch 909/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1475 - acc: 0.9959 - val_loss: 0.5066 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00909: val_acc did not improve from 0.91860\n",
            "Epoch 910/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1462 - acc: 0.9961 - val_loss: 0.5068 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00910: val_acc did not improve from 0.91860\n",
            "Epoch 911/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1446 - acc: 0.9969 - val_loss: 0.5060 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00911: val_acc did not improve from 0.91860\n",
            "Epoch 912/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1449 - acc: 0.9963 - val_loss: 0.5054 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00912: val_acc did not improve from 0.91860\n",
            "Epoch 913/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1485 - acc: 0.9941 - val_loss: 0.5068 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00913: val_acc did not improve from 0.91860\n",
            "Epoch 914/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1479 - acc: 0.9953 - val_loss: 0.5065 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00914: val_acc did not improve from 0.91860\n",
            "Epoch 915/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1481 - acc: 0.9950 - val_loss: 0.5074 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00915: val_acc did not improve from 0.91860\n",
            "Epoch 916/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1460 - acc: 0.9967 - val_loss: 0.5067 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00916: val_acc did not improve from 0.91860\n",
            "Epoch 917/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1440 - acc: 0.9971 - val_loss: 0.5078 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00917: val_acc did not improve from 0.91860\n",
            "Epoch 918/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1446 - acc: 0.9969 - val_loss: 0.5066 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00918: val_acc did not improve from 0.91860\n",
            "Epoch 919/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1460 - acc: 0.9969 - val_loss: 0.5060 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00919: val_acc did not improve from 0.91860\n",
            "Epoch 920/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1475 - acc: 0.9944 - val_loss: 0.5063 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00920: val_acc did not improve from 0.91860\n",
            "Epoch 921/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1471 - acc: 0.9957 - val_loss: 0.5072 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00921: val_acc did not improve from 0.91860\n",
            "Epoch 922/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1486 - acc: 0.9929 - val_loss: 0.5070 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00922: val_acc did not improve from 0.91860\n",
            "Epoch 923/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1448 - acc: 0.9960 - val_loss: 0.5077 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00923: val_acc did not improve from 0.91860\n",
            "Epoch 924/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1482 - acc: 0.9948 - val_loss: 0.5059 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00924: val_acc did not improve from 0.91860\n",
            "Epoch 925/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1484 - acc: 0.9951 - val_loss: 0.5077 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00925: val_acc did not improve from 0.91860\n",
            "Epoch 926/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1469 - acc: 0.9957 - val_loss: 0.5081 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00926: val_acc did not improve from 0.91860\n",
            "Epoch 927/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1492 - acc: 0.9932 - val_loss: 0.5072 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00927: val_acc did not improve from 0.91860\n",
            "Epoch 928/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1502 - acc: 0.9947 - val_loss: 0.5071 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00928: val_acc did not improve from 0.91860\n",
            "Epoch 929/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1465 - acc: 0.9960 - val_loss: 0.5075 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00929: val_acc did not improve from 0.91860\n",
            "Epoch 930/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1447 - acc: 0.9965 - val_loss: 0.5085 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00930: val_acc did not improve from 0.91860\n",
            "Epoch 931/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1488 - acc: 0.9953 - val_loss: 0.5081 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00931: val_acc did not improve from 0.91860\n",
            "Epoch 932/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1477 - acc: 0.9952 - val_loss: 0.5076 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00932: val_acc did not improve from 0.91860\n",
            "Epoch 933/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1471 - acc: 0.9958 - val_loss: 0.5078 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00933: val_acc did not improve from 0.91860\n",
            "Epoch 934/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1469 - acc: 0.9959 - val_loss: 0.5071 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00934: val_acc did not improve from 0.91860\n",
            "Epoch 935/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1480 - acc: 0.9947 - val_loss: 0.5069 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00935: val_acc did not improve from 0.91860\n",
            "Epoch 936/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1453 - acc: 0.9954 - val_loss: 0.5084 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00936: val_acc did not improve from 0.91860\n",
            "Epoch 937/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1472 - acc: 0.9955 - val_loss: 0.5079 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00937: val_acc did not improve from 0.91860\n",
            "Epoch 938/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1488 - acc: 0.9944 - val_loss: 0.5076 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00938: val_acc did not improve from 0.91860\n",
            "Epoch 939/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1496 - acc: 0.9942 - val_loss: 0.5070 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00939: val_acc did not improve from 0.91860\n",
            "Epoch 940/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1501 - acc: 0.9937 - val_loss: 0.5078 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00940: val_acc did not improve from 0.91860\n",
            "Epoch 941/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1461 - acc: 0.9958 - val_loss: 0.5082 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00941: val_acc did not improve from 0.91860\n",
            "Epoch 942/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1471 - acc: 0.9962 - val_loss: 0.5082 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00942: val_acc did not improve from 0.91860\n",
            "Epoch 943/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1484 - acc: 0.9958 - val_loss: 0.5083 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00943: val_acc did not improve from 0.91860\n",
            "Epoch 944/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1431 - acc: 0.9974 - val_loss: 0.5075 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00944: val_acc did not improve from 0.91860\n",
            "Epoch 945/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1462 - acc: 0.9959 - val_loss: 0.5074 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00945: val_acc did not improve from 0.91860\n",
            "Epoch 946/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1481 - acc: 0.9957 - val_loss: 0.5075 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00946: val_acc did not improve from 0.91860\n",
            "Epoch 947/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1493 - acc: 0.9947 - val_loss: 0.5078 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00947: val_acc did not improve from 0.91860\n",
            "Epoch 948/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1457 - acc: 0.9967 - val_loss: 0.5067 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00948: val_acc did not improve from 0.91860\n",
            "Epoch 949/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1479 - acc: 0.9945 - val_loss: 0.5064 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00949: val_acc did not improve from 0.91860\n",
            "Epoch 950/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1464 - acc: 0.9957 - val_loss: 0.5060 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00950: val_acc did not improve from 0.91860\n",
            "Epoch 951/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1459 - acc: 0.9965 - val_loss: 0.5072 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00951: val_acc did not improve from 0.91860\n",
            "Epoch 952/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1461 - acc: 0.9960 - val_loss: 0.5064 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00952: val_acc did not improve from 0.91860\n",
            "Epoch 953/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1471 - acc: 0.9940 - val_loss: 0.5066 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00953: val_acc did not improve from 0.91860\n",
            "Epoch 954/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1498 - acc: 0.9954 - val_loss: 0.5066 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00954: val_acc did not improve from 0.91860\n",
            "Epoch 955/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1510 - acc: 0.9939 - val_loss: 0.5078 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00955: val_acc did not improve from 0.91860\n",
            "Epoch 956/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1483 - acc: 0.9954 - val_loss: 0.5068 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00956: val_acc did not improve from 0.91860\n",
            "Epoch 957/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1503 - acc: 0.9934 - val_loss: 0.5072 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00957: val_acc did not improve from 0.91860\n",
            "Epoch 958/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1446 - acc: 0.9963 - val_loss: 0.5070 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00958: val_acc did not improve from 0.91860\n",
            "Epoch 959/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1471 - acc: 0.9955 - val_loss: 0.5082 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00959: val_acc did not improve from 0.91860\n",
            "Epoch 960/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1473 - acc: 0.9952 - val_loss: 0.5069 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00960: val_acc did not improve from 0.91860\n",
            "Epoch 961/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1466 - acc: 0.9958 - val_loss: 0.5071 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00961: val_acc did not improve from 0.91860\n",
            "Epoch 962/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1502 - acc: 0.9945 - val_loss: 0.5074 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00962: val_acc did not improve from 0.91860\n",
            "Epoch 963/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1505 - acc: 0.9944 - val_loss: 0.5083 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00963: val_acc did not improve from 0.91860\n",
            "Epoch 964/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1464 - acc: 0.9954 - val_loss: 0.5061 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00964: val_acc did not improve from 0.91860\n",
            "Epoch 965/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1492 - acc: 0.9948 - val_loss: 0.5062 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00965: val_acc did not improve from 0.91860\n",
            "Epoch 966/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1471 - acc: 0.9950 - val_loss: 0.5070 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00966: val_acc did not improve from 0.91860\n",
            "Epoch 967/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1465 - acc: 0.9946 - val_loss: 0.5066 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00967: val_acc did not improve from 0.91860\n",
            "Epoch 968/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1477 - acc: 0.9952 - val_loss: 0.5065 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00968: val_acc did not improve from 0.91860\n",
            "Epoch 969/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1483 - acc: 0.9950 - val_loss: 0.5076 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00969: val_acc did not improve from 0.91860\n",
            "Epoch 970/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1477 - acc: 0.9941 - val_loss: 0.5071 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00970: val_acc did not improve from 0.91860\n",
            "Epoch 971/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1448 - acc: 0.9967 - val_loss: 0.5084 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00971: val_acc did not improve from 0.91860\n",
            "Epoch 972/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1461 - acc: 0.9959 - val_loss: 0.5065 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00972: val_acc did not improve from 0.91860\n",
            "Epoch 973/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1494 - acc: 0.9941 - val_loss: 0.5084 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00973: val_acc did not improve from 0.91860\n",
            "Epoch 974/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1464 - acc: 0.9967 - val_loss: 0.5068 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00974: val_acc did not improve from 0.91860\n",
            "Epoch 975/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1454 - acc: 0.9963 - val_loss: 0.5075 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00975: val_acc did not improve from 0.91860\n",
            "Epoch 976/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1490 - acc: 0.9947 - val_loss: 0.5076 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00976: val_acc did not improve from 0.91860\n",
            "Epoch 977/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1475 - acc: 0.9951 - val_loss: 0.5074 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00977: val_acc did not improve from 0.91860\n",
            "Epoch 978/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1462 - acc: 0.9948 - val_loss: 0.5071 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00978: val_acc did not improve from 0.91860\n",
            "Epoch 979/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1456 - acc: 0.9960 - val_loss: 0.5073 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00979: val_acc did not improve from 0.91860\n",
            "Epoch 980/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1468 - acc: 0.9954 - val_loss: 0.5071 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00980: val_acc did not improve from 0.91860\n",
            "Epoch 981/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1478 - acc: 0.9949 - val_loss: 0.5082 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00981: val_acc did not improve from 0.91860\n",
            "Epoch 982/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1424 - acc: 0.9974 - val_loss: 0.5074 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00982: val_acc did not improve from 0.91860\n",
            "Epoch 983/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1460 - acc: 0.9953 - val_loss: 0.5068 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00983: val_acc did not improve from 0.91860\n",
            "Epoch 984/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1436 - acc: 0.9968 - val_loss: 0.5071 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00984: val_acc did not improve from 0.91860\n",
            "Epoch 985/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1458 - acc: 0.9950 - val_loss: 0.5074 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00985: val_acc did not improve from 0.91860\n",
            "Epoch 986/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1483 - acc: 0.9950 - val_loss: 0.5064 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00986: val_acc did not improve from 0.91860\n",
            "Epoch 987/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1466 - acc: 0.9964 - val_loss: 0.5065 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00987: val_acc did not improve from 0.91860\n",
            "Epoch 988/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1446 - acc: 0.9962 - val_loss: 0.5059 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00988: val_acc did not improve from 0.91860\n",
            "Epoch 989/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1478 - acc: 0.9956 - val_loss: 0.5065 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00989: val_acc did not improve from 0.91860\n",
            "Epoch 990/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1484 - acc: 0.9948 - val_loss: 0.5063 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00990: val_acc did not improve from 0.91860\n",
            "Epoch 991/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1487 - acc: 0.9955 - val_loss: 0.5065 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00991: val_acc did not improve from 0.91860\n",
            "Epoch 992/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1476 - acc: 0.9955 - val_loss: 0.5076 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00992: val_acc did not improve from 0.91860\n",
            "Epoch 993/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1506 - acc: 0.9932 - val_loss: 0.5058 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00993: val_acc did not improve from 0.91860\n",
            "Epoch 994/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1483 - acc: 0.9942 - val_loss: 0.5064 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00994: val_acc did not improve from 0.91860\n",
            "Epoch 995/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1510 - acc: 0.9944 - val_loss: 0.5069 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00995: val_acc did not improve from 0.91860\n",
            "Epoch 996/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1465 - acc: 0.9960 - val_loss: 0.5062 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00996: val_acc did not improve from 0.91860\n",
            "Epoch 997/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1484 - acc: 0.9958 - val_loss: 0.5076 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00997: val_acc did not improve from 0.91860\n",
            "Epoch 998/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1451 - acc: 0.9965 - val_loss: 0.5070 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00998: val_acc did not improve from 0.91860\n",
            "Epoch 999/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1434 - acc: 0.9972 - val_loss: 0.5078 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00999: val_acc did not improve from 0.91860\n",
            "Epoch 1000/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1444 - acc: 0.9973 - val_loss: 0.5084 - val_acc: 0.9164\n",
            "\n",
            "Epoch 01000: val_acc did not improve from 0.91860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "x2NvLySCxHCC",
        "outputId": "55090288-1ad1-44c6-b1f0-952514c1fd70"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('simple_trainHistoryDict', \"rb\"))\n",
        "functions.plot_loss_acc(history, 2, 0.4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXfd0FQq4UHz",
        "outputId": "07867d01-b23e-4960-f4b4-2d97a5f80677"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9164000153541565"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv0kNxrQxlFN",
        "outputId": "eeb47724-f441-4ebe-cc92-52ec4333bfdb"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0835999846458435"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBFMbHvLIf5g"
      },
      "source": [
        "#### Model with clipping to 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8s3DicMIfMr",
        "outputId": "c58de7d9-ef61-433f-8f94-eaec54ab900e"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ju7AUyp1rfh",
        "outputId": "01908cff-b5aa-468a-ddcf-c5def0dce235"
      },
      "source": [
        "callbacks = functions.standard_callbacks(model_type) + [functions.Clipping(0.5, \"simple\")]\n",
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'simple_trainHistoryDict_clip_05', steps_per_epoch=100, epochs=1000,\n",
        "                       batch_size=100,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Epoch 1/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 80ms/step - loss: 2.4961 - acc: 0.2745 - val_loss: 2.3687 - val_acc: 0.2634\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.26340, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 2.0267 - acc: 0.2734 - val_loss: 3.5508 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.26340\n",
            "Epoch 3/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.6703 - acc: 0.3801 - val_loss: 4.0442 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.26340\n",
            "Epoch 4/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.4953 - acc: 0.4573 - val_loss: 3.7763 - val_acc: 0.1020\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.26340\n",
            "Epoch 5/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 1.4011 - acc: 0.4952 - val_loss: 1.8179 - val_acc: 0.3784\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.26340 to 0.37840, saving model to /content/saved_models/cifar10_ResNet32v1_model.005.h5\n",
            "Epoch 6/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.3052 - acc: 0.5429 - val_loss: 2.0324 - val_acc: 0.4364\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.37840 to 0.43640, saving model to /content/saved_models/cifar10_ResNet32v1_model.006.h5\n",
            "Epoch 7/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 1.2558 - acc: 0.5547 - val_loss: 3.6933 - val_acc: 0.2808\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.43640\n",
            "Epoch 8/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.1894 - acc: 0.5800 - val_loss: 4.1107 - val_acc: 0.3053\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.43640\n",
            "Epoch 9/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.1473 - acc: 0.6001 - val_loss: 4.9442 - val_acc: 0.2951\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.43640\n",
            "Epoch 10/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 1.1280 - acc: 0.5991 - val_loss: 3.3506 - val_acc: 0.3538\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.43640\n",
            "Epoch 11/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 1.0914 - acc: 0.6218 - val_loss: 4.2881 - val_acc: 0.2564\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.43640\n",
            "Epoch 12/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.0249 - acc: 0.6402 - val_loss: 2.0313 - val_acc: 0.5011\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.43640 to 0.50110, saving model to /content/saved_models/cifar10_ResNet32v1_model.012.h5\n",
            "Epoch 13/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.0595 - acc: 0.6340 - val_loss: 3.0947 - val_acc: 0.4379\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.50110\n",
            "Epoch 14/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.0442 - acc: 0.6330 - val_loss: 2.6556 - val_acc: 0.4220\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.50110\n",
            "Epoch 15/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 1.0126 - acc: 0.6508 - val_loss: 3.9034 - val_acc: 0.3024\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.50110\n",
            "Epoch 16/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9848 - acc: 0.6557 - val_loss: 2.4264 - val_acc: 0.4552\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.50110\n",
            "Epoch 17/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 1.0260 - acc: 0.6438 - val_loss: 4.8315 - val_acc: 0.2737\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.50110\n",
            "Epoch 18/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9841 - acc: 0.6528 - val_loss: 2.3878 - val_acc: 0.4344\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.50110\n",
            "Epoch 19/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9305 - acc: 0.6768 - val_loss: 4.7044 - val_acc: 0.3144\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.50110\n",
            "Epoch 20/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.9517 - acc: 0.6677 - val_loss: 2.1569 - val_acc: 0.4595\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.50110\n",
            "Epoch 21/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.9211 - acc: 0.6837 - val_loss: 1.7206 - val_acc: 0.5643\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.50110 to 0.56430, saving model to /content/saved_models/cifar10_ResNet32v1_model.021.h5\n",
            "Epoch 22/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.9175 - acc: 0.6909 - val_loss: 2.9203 - val_acc: 0.3961\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.56430\n",
            "Epoch 23/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.9362 - acc: 0.6752 - val_loss: 3.9322 - val_acc: 0.3250\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.56430\n",
            "Epoch 24/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.9154 - acc: 0.6836 - val_loss: 2.4561 - val_acc: 0.4656\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.56430\n",
            "Epoch 25/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.9021 - acc: 0.6843 - val_loss: 1.2974 - val_acc: 0.6201\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.56430 to 0.62010, saving model to /content/saved_models/cifar10_ResNet32v1_model.025.h5\n",
            "Epoch 26/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8966 - acc: 0.6969 - val_loss: 3.3461 - val_acc: 0.3886\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.62010\n",
            "Epoch 27/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8932 - acc: 0.6899 - val_loss: 4.7853 - val_acc: 0.3065\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.62010\n",
            "Epoch 28/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8397 - acc: 0.7107 - val_loss: 2.3325 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.62010\n",
            "Epoch 29/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.8786 - acc: 0.7018 - val_loss: 1.4734 - val_acc: 0.5560\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.62010\n",
            "Epoch 30/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.8694 - acc: 0.6908 - val_loss: 1.9378 - val_acc: 0.5679\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.62010\n",
            "Epoch 31/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8614 - acc: 0.7023 - val_loss: 2.4650 - val_acc: 0.4922\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.62010\n",
            "Epoch 32/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8578 - acc: 0.7136 - val_loss: 2.2796 - val_acc: 0.4821\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.62010\n",
            "Epoch 33/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8174 - acc: 0.7155 - val_loss: 2.1179 - val_acc: 0.4913\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.62010\n",
            "Epoch 34/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8661 - acc: 0.6988 - val_loss: 1.9174 - val_acc: 0.5322\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.62010\n",
            "Epoch 35/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8364 - acc: 0.7091 - val_loss: 2.1190 - val_acc: 0.5181\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.62010\n",
            "Epoch 36/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.8305 - acc: 0.7152 - val_loss: 2.5887 - val_acc: 0.4977\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.62010\n",
            "Epoch 37/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.8387 - acc: 0.7138 - val_loss: 5.2942 - val_acc: 0.3438\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.62010\n",
            "Epoch 38/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.8284 - acc: 0.7165 - val_loss: 1.6969 - val_acc: 0.5744\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.62010\n",
            "Epoch 39/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.8161 - acc: 0.7218 - val_loss: 2.7154 - val_acc: 0.4759\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.62010\n",
            "Epoch 40/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.7992 - acc: 0.7326 - val_loss: 2.6493 - val_acc: 0.4489\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.62010\n",
            "Epoch 41/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.7874 - acc: 0.7391 - val_loss: 3.1118 - val_acc: 0.4197\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.62010\n",
            "Epoch 42/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.7658 - acc: 0.7398 - val_loss: 2.3187 - val_acc: 0.4810\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.62010\n",
            "Epoch 43/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.8074 - acc: 0.7273 - val_loss: 3.2401 - val_acc: 0.4447\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.62010\n",
            "Epoch 44/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7875 - acc: 0.7301 - val_loss: 1.9602 - val_acc: 0.5172\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.62010\n",
            "Epoch 45/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.7887 - acc: 0.7345 - val_loss: 3.1250 - val_acc: 0.3818\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.62010\n",
            "Epoch 46/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.7728 - acc: 0.7372 - val_loss: 3.4557 - val_acc: 0.3807\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.62010\n",
            "Epoch 47/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7780 - acc: 0.7411 - val_loss: 2.7777 - val_acc: 0.4120\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.62010\n",
            "Epoch 48/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7853 - acc: 0.7330 - val_loss: 2.8838 - val_acc: 0.4745\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.62010\n",
            "Epoch 49/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7502 - acc: 0.7377 - val_loss: 2.5999 - val_acc: 0.4906\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.62010\n",
            "Epoch 50/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7720 - acc: 0.7377 - val_loss: 2.9383 - val_acc: 0.4290\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.62010\n",
            "Epoch 51/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7724 - acc: 0.7384 - val_loss: 2.3470 - val_acc: 0.5034\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.62010\n",
            "Epoch 52/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7605 - acc: 0.7416 - val_loss: 2.0470 - val_acc: 0.4949\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.62010\n",
            "Epoch 53/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.7902 - acc: 0.7321 - val_loss: 3.5146 - val_acc: 0.3746\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.62010\n",
            "Epoch 54/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7530 - acc: 0.7498 - val_loss: 2.3436 - val_acc: 0.5069\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.62010\n",
            "Epoch 55/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7350 - acc: 0.7451 - val_loss: 1.3898 - val_acc: 0.6162\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.62010\n",
            "Epoch 56/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7797 - acc: 0.7425 - val_loss: 4.1654 - val_acc: 0.3071\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.62010\n",
            "Epoch 57/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7844 - acc: 0.7365 - val_loss: 4.0516 - val_acc: 0.3953\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.62010\n",
            "Epoch 58/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7515 - acc: 0.7501 - val_loss: 1.0983 - val_acc: 0.6634\n",
            "\n",
            "Epoch 00058: val_acc improved from 0.62010 to 0.66340, saving model to /content/saved_models/cifar10_ResNet32v1_model.058.h5\n",
            "Epoch 59/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7350 - acc: 0.7496 - val_loss: 5.5268 - val_acc: 0.3554\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.66340\n",
            "Epoch 60/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7341 - acc: 0.7522 - val_loss: 4.3813 - val_acc: 0.4069\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.66340\n",
            "Epoch 61/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7265 - acc: 0.7510 - val_loss: 1.7946 - val_acc: 0.5661\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.66340\n",
            "Epoch 62/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7352 - acc: 0.7509 - val_loss: 2.0315 - val_acc: 0.5437\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.66340\n",
            "Epoch 63/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7598 - acc: 0.7484 - val_loss: 3.8254 - val_acc: 0.3514\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.66340\n",
            "Epoch 64/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7375 - acc: 0.7489 - val_loss: 1.7266 - val_acc: 0.5577\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.66340\n",
            "Epoch 65/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.7357 - acc: 0.7536 - val_loss: 2.7573 - val_acc: 0.4146\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.66340\n",
            "Epoch 66/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7480 - acc: 0.7445 - val_loss: 1.9116 - val_acc: 0.5623\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.66340\n",
            "Epoch 67/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7207 - acc: 0.7584 - val_loss: 6.1730 - val_acc: 0.2538\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.66340\n",
            "Epoch 68/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.7296 - acc: 0.7533 - val_loss: 3.3845 - val_acc: 0.3965\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.66340\n",
            "Epoch 69/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7311 - acc: 0.7528 - val_loss: 1.7301 - val_acc: 0.5771\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.66340\n",
            "Epoch 70/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7277 - acc: 0.7517 - val_loss: 1.9728 - val_acc: 0.5540\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.66340\n",
            "Epoch 71/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7291 - acc: 0.7494 - val_loss: 3.1997 - val_acc: 0.4128\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.66340\n",
            "Epoch 72/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7041 - acc: 0.7644 - val_loss: 2.5316 - val_acc: 0.4585\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.66340\n",
            "Epoch 73/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6877 - acc: 0.7699 - val_loss: 2.5004 - val_acc: 0.4269\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.66340\n",
            "Epoch 74/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7207 - acc: 0.7628 - val_loss: 1.6933 - val_acc: 0.5724\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.66340\n",
            "Epoch 75/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7260 - acc: 0.7570 - val_loss: 1.8037 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.66340\n",
            "Epoch 76/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7424 - acc: 0.7499 - val_loss: 2.4706 - val_acc: 0.5157\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.66340\n",
            "Epoch 77/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7107 - acc: 0.7571 - val_loss: 4.5954 - val_acc: 0.4142\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.66340\n",
            "Epoch 78/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7373 - acc: 0.7564 - val_loss: 2.0356 - val_acc: 0.5575\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.66340\n",
            "Epoch 79/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6824 - acc: 0.7698 - val_loss: 1.6400 - val_acc: 0.6090\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.66340\n",
            "Epoch 80/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7469 - acc: 0.7494 - val_loss: 4.3057 - val_acc: 0.4344\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.66340\n",
            "Epoch 81/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7116 - acc: 0.7624 - val_loss: 2.8942 - val_acc: 0.4213\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.66340\n",
            "Epoch 82/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7060 - acc: 0.7593 - val_loss: 2.0561 - val_acc: 0.5449\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.66340\n",
            "Epoch 83/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7019 - acc: 0.7662 - val_loss: 10.3437 - val_acc: 0.2668\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.66340\n",
            "Epoch 84/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6747 - acc: 0.7702 - val_loss: 5.4969 - val_acc: 0.3671\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.66340\n",
            "Epoch 85/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6900 - acc: 0.7636 - val_loss: 1.8250 - val_acc: 0.6034\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.66340\n",
            "Epoch 86/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7001 - acc: 0.7633 - val_loss: 2.6402 - val_acc: 0.4252\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.66340\n",
            "Epoch 87/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7045 - acc: 0.7577 - val_loss: 2.6103 - val_acc: 0.4811\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.66340\n",
            "Epoch 88/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6850 - acc: 0.7675 - val_loss: 1.4544 - val_acc: 0.6028\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.66340\n",
            "Epoch 89/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7185 - acc: 0.7545 - val_loss: 3.1104 - val_acc: 0.4451\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.66340\n",
            "Epoch 90/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6524 - acc: 0.7839 - val_loss: 1.4566 - val_acc: 0.5993\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.66340\n",
            "Epoch 91/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6876 - acc: 0.7691 - val_loss: 2.7292 - val_acc: 0.4948\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.66340\n",
            "Epoch 92/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6919 - acc: 0.7643 - val_loss: 2.3936 - val_acc: 0.4968\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.66340\n",
            "Epoch 93/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7156 - acc: 0.7553 - val_loss: 1.5716 - val_acc: 0.6295\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.66340\n",
            "Epoch 94/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6711 - acc: 0.7793 - val_loss: 1.6036 - val_acc: 0.5593\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.66340\n",
            "Epoch 95/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6549 - acc: 0.7826 - val_loss: 1.7167 - val_acc: 0.5193\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.66340\n",
            "Epoch 96/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6876 - acc: 0.7709 - val_loss: 1.6980 - val_acc: 0.5813\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.66340\n",
            "Epoch 97/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6702 - acc: 0.7719 - val_loss: 1.9412 - val_acc: 0.5434\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.66340\n",
            "Epoch 98/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6847 - acc: 0.7656 - val_loss: 2.4018 - val_acc: 0.5269\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.66340\n",
            "Epoch 99/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6812 - acc: 0.7701 - val_loss: 2.6139 - val_acc: 0.4216\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.66340\n",
            "Epoch 100/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6760 - acc: 0.7658 - val_loss: 1.7783 - val_acc: 0.5635\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.66340\n",
            "Epoch 101/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6947 - acc: 0.7663 - val_loss: 1.3618 - val_acc: 0.6297\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.66340\n",
            "Epoch 102/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6693 - acc: 0.7735 - val_loss: 4.6574 - val_acc: 0.3744\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.66340\n",
            "Epoch 103/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6976 - acc: 0.7629 - val_loss: 1.2257 - val_acc: 0.6568\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.66340\n",
            "Epoch 104/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6267 - acc: 0.7988 - val_loss: 2.6044 - val_acc: 0.4638\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.66340\n",
            "Epoch 105/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6564 - acc: 0.7760 - val_loss: 1.6351 - val_acc: 0.6113\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.66340\n",
            "Epoch 106/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6730 - acc: 0.7730 - val_loss: 2.3879 - val_acc: 0.4939\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.66340\n",
            "Epoch 107/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6977 - acc: 0.7590 - val_loss: 1.3455 - val_acc: 0.6405\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.66340\n",
            "Epoch 108/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6712 - acc: 0.7821 - val_loss: 2.6905 - val_acc: 0.3703\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.66340\n",
            "Epoch 109/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7090 - acc: 0.7608 - val_loss: 1.6855 - val_acc: 0.6194\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.66340\n",
            "Epoch 110/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6512 - acc: 0.7785 - val_loss: 2.0857 - val_acc: 0.5295\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.66340\n",
            "Epoch 111/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6704 - acc: 0.7758 - val_loss: 2.4000 - val_acc: 0.4602\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.66340\n",
            "Epoch 112/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6846 - acc: 0.7743 - val_loss: 8.3181 - val_acc: 0.2301\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.66340\n",
            "Epoch 113/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6554 - acc: 0.7814 - val_loss: 2.0810 - val_acc: 0.5046\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.66340\n",
            "Epoch 114/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6707 - acc: 0.7749 - val_loss: 2.3973 - val_acc: 0.5226\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.66340\n",
            "Epoch 115/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6701 - acc: 0.7783 - val_loss: 6.5143 - val_acc: 0.3131\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.66340\n",
            "Epoch 116/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7006 - acc: 0.7664 - val_loss: 1.9892 - val_acc: 0.5652\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.66340\n",
            "Epoch 117/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6631 - acc: 0.7757 - val_loss: 1.4318 - val_acc: 0.6420\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.66340\n",
            "Epoch 118/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6576 - acc: 0.7770 - val_loss: 2.3878 - val_acc: 0.5089\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.66340\n",
            "Epoch 119/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6729 - acc: 0.7768 - val_loss: 2.9909 - val_acc: 0.4171\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.66340\n",
            "Epoch 120/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6605 - acc: 0.7715 - val_loss: 1.2225 - val_acc: 0.6462\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.66340\n",
            "Epoch 121/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6516 - acc: 0.7817 - val_loss: 3.1772 - val_acc: 0.4651\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.66340\n",
            "Epoch 122/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6365 - acc: 0.7907 - val_loss: 1.4915 - val_acc: 0.6266\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.66340\n",
            "Epoch 123/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6792 - acc: 0.7679 - val_loss: 4.1000 - val_acc: 0.4084\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.66340\n",
            "Epoch 124/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6401 - acc: 0.7826 - val_loss: 1.3431 - val_acc: 0.6536\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.66340\n",
            "Epoch 125/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6990 - acc: 0.7647 - val_loss: 3.9881 - val_acc: 0.3819\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.66340\n",
            "Epoch 126/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6728 - acc: 0.7784 - val_loss: 2.3656 - val_acc: 0.5148\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.66340\n",
            "Epoch 127/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6553 - acc: 0.7787 - val_loss: 1.3877 - val_acc: 0.6183\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.66340\n",
            "Epoch 128/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6567 - acc: 0.7774 - val_loss: 1.7049 - val_acc: 0.6174\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.66340\n",
            "Epoch 129/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6882 - acc: 0.7773 - val_loss: 2.2733 - val_acc: 0.5099\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.66340\n",
            "Epoch 130/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6412 - acc: 0.7829 - val_loss: 4.4648 - val_acc: 0.3565\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.66340\n",
            "Epoch 131/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6414 - acc: 0.7857 - val_loss: 2.1474 - val_acc: 0.5083\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.66340\n",
            "Epoch 132/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6430 - acc: 0.7848 - val_loss: 1.7463 - val_acc: 0.5747\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.66340\n",
            "Epoch 133/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6649 - acc: 0.7770 - val_loss: 1.1431 - val_acc: 0.6917\n",
            "\n",
            "Epoch 00133: val_acc improved from 0.66340 to 0.69170, saving model to /content/saved_models/cifar10_ResNet32v1_model.133.h5\n",
            "Epoch 134/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6580 - acc: 0.7820 - val_loss: 2.3627 - val_acc: 0.5073\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.69170\n",
            "Epoch 135/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6460 - acc: 0.7826 - val_loss: 2.4779 - val_acc: 0.4771\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.69170\n",
            "Epoch 136/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6598 - acc: 0.7847 - val_loss: 2.3029 - val_acc: 0.5100\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.69170\n",
            "Epoch 137/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6723 - acc: 0.7708 - val_loss: 1.6440 - val_acc: 0.6060\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.69170\n",
            "Epoch 138/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6519 - acc: 0.7798 - val_loss: 2.7246 - val_acc: 0.5317\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.69170\n",
            "Epoch 139/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6475 - acc: 0.7776 - val_loss: 3.1578 - val_acc: 0.4554\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.69170\n",
            "Epoch 140/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6684 - acc: 0.7755 - val_loss: 2.6267 - val_acc: 0.4506\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.69170\n",
            "Epoch 141/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6585 - acc: 0.7747 - val_loss: 3.3063 - val_acc: 0.3966\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.69170\n",
            "Epoch 142/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6586 - acc: 0.7779 - val_loss: 1.1619 - val_acc: 0.6746\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.69170\n",
            "Epoch 143/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6501 - acc: 0.7788 - val_loss: 2.2481 - val_acc: 0.5708\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.69170\n",
            "Epoch 144/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6457 - acc: 0.7870 - val_loss: 2.2965 - val_acc: 0.3690\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.69170\n",
            "Epoch 145/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6307 - acc: 0.7879 - val_loss: 1.5660 - val_acc: 0.6141\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.69170\n",
            "Epoch 146/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6578 - acc: 0.7819 - val_loss: 2.9671 - val_acc: 0.4481\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.69170\n",
            "Epoch 147/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6237 - acc: 0.7938 - val_loss: 1.5742 - val_acc: 0.5697\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.69170\n",
            "Epoch 148/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6608 - acc: 0.7802 - val_loss: 3.3719 - val_acc: 0.4391\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.69170\n",
            "Epoch 149/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6496 - acc: 0.7820 - val_loss: 1.9456 - val_acc: 0.4997\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.69170\n",
            "Epoch 150/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6423 - acc: 0.7886 - val_loss: 1.5872 - val_acc: 0.5693\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.69170\n",
            "Epoch 151/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6243 - acc: 0.7952 - val_loss: 5.5867 - val_acc: 0.3654\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.69170\n",
            "Epoch 152/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6512 - acc: 0.7818 - val_loss: 1.2946 - val_acc: 0.6089\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.69170\n",
            "Epoch 153/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6537 - acc: 0.7864 - val_loss: 4.1899 - val_acc: 0.2853\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.69170\n",
            "Epoch 154/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6399 - acc: 0.7947 - val_loss: 3.7695 - val_acc: 0.4140\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.69170\n",
            "Epoch 155/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6429 - acc: 0.7862 - val_loss: 1.7939 - val_acc: 0.5874\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.69170\n",
            "Epoch 156/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6513 - acc: 0.7850 - val_loss: 2.3602 - val_acc: 0.5066\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.69170\n",
            "Epoch 157/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6607 - acc: 0.7784 - val_loss: 2.0345 - val_acc: 0.5062\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.69170\n",
            "Epoch 158/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6332 - acc: 0.7888 - val_loss: 1.6904 - val_acc: 0.6227\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.69170\n",
            "Epoch 159/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6165 - acc: 0.7952 - val_loss: 2.5651 - val_acc: 0.4154\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.69170\n",
            "Epoch 160/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6395 - acc: 0.7815 - val_loss: 2.0289 - val_acc: 0.5428\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.69170\n",
            "Epoch 161/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6412 - acc: 0.7866 - val_loss: 2.0601 - val_acc: 0.5388\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.69170\n",
            "Epoch 162/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6439 - acc: 0.7908 - val_loss: 2.9921 - val_acc: 0.4384\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.69170\n",
            "Epoch 163/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6364 - acc: 0.7903 - val_loss: 2.8969 - val_acc: 0.4656\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.69170\n",
            "Epoch 164/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6728 - acc: 0.7732 - val_loss: 1.5135 - val_acc: 0.6002\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.69170\n",
            "Epoch 165/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6671 - acc: 0.7774 - val_loss: 2.1561 - val_acc: 0.5476\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.69170\n",
            "Epoch 166/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6578 - acc: 0.7838 - val_loss: 5.2662 - val_acc: 0.2926\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.69170\n",
            "Epoch 167/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6335 - acc: 0.7870 - val_loss: 1.4008 - val_acc: 0.6141\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.69170\n",
            "Epoch 168/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6473 - acc: 0.7834 - val_loss: 1.7361 - val_acc: 0.5695\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.69170\n",
            "Epoch 169/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6141 - acc: 0.7922 - val_loss: 2.3658 - val_acc: 0.5148\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.69170\n",
            "Epoch 170/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6319 - acc: 0.7877 - val_loss: 1.2719 - val_acc: 0.6118\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.69170\n",
            "Epoch 171/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6538 - acc: 0.7794 - val_loss: 2.4754 - val_acc: 0.5353\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.69170\n",
            "Epoch 172/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6274 - acc: 0.7861 - val_loss: 1.6644 - val_acc: 0.5259\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.69170\n",
            "Epoch 173/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6553 - acc: 0.7778 - val_loss: 1.4066 - val_acc: 0.6292\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.69170\n",
            "Epoch 174/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6141 - acc: 0.7933 - val_loss: 3.0938 - val_acc: 0.5025\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.69170\n",
            "Epoch 175/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6335 - acc: 0.7890 - val_loss: 1.8985 - val_acc: 0.5387\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.69170\n",
            "Epoch 176/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6119 - acc: 0.7990 - val_loss: 1.2695 - val_acc: 0.6654\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.69170\n",
            "Epoch 177/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6439 - acc: 0.7885 - val_loss: 3.0810 - val_acc: 0.4167\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.69170\n",
            "Epoch 178/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6377 - acc: 0.7890 - val_loss: 1.7960 - val_acc: 0.5597\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.69170\n",
            "Epoch 179/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6347 - acc: 0.7890 - val_loss: 2.6293 - val_acc: 0.4685\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.69170\n",
            "Epoch 180/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6073 - acc: 0.7974 - val_loss: 4.1391 - val_acc: 0.3201\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.69170\n",
            "Epoch 181/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6257 - acc: 0.7947 - val_loss: 4.9447 - val_acc: 0.3682\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.69170\n",
            "Epoch 182/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6183 - acc: 0.7932 - val_loss: 1.6037 - val_acc: 0.5827\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.69170\n",
            "Epoch 183/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6490 - acc: 0.7840 - val_loss: 1.5900 - val_acc: 0.5673\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.69170\n",
            "Epoch 184/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6272 - acc: 0.7916 - val_loss: 1.4930 - val_acc: 0.6191\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.69170\n",
            "Epoch 185/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5993 - acc: 0.8026 - val_loss: 1.9081 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.69170\n",
            "Epoch 186/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6209 - acc: 0.7949 - val_loss: 2.5313 - val_acc: 0.4212\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.69170\n",
            "Epoch 187/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6215 - acc: 0.7946 - val_loss: 6.2979 - val_acc: 0.2941\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.69170\n",
            "Epoch 188/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6494 - acc: 0.7778 - val_loss: 3.2742 - val_acc: 0.4697\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.69170\n",
            "Epoch 189/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6468 - acc: 0.7881 - val_loss: 1.1341 - val_acc: 0.6736\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.69170\n",
            "Epoch 190/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5929 - acc: 0.8012 - val_loss: 1.4528 - val_acc: 0.6195\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.69170\n",
            "Epoch 191/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6182 - acc: 0.7928 - val_loss: 1.7220 - val_acc: 0.5864\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.69170\n",
            "Epoch 192/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6238 - acc: 0.7916 - val_loss: 1.4044 - val_acc: 0.6153\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.69170\n",
            "Epoch 193/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5995 - acc: 0.7991 - val_loss: 2.2870 - val_acc: 0.4959\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.69170\n",
            "Epoch 194/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6140 - acc: 0.7971 - val_loss: 2.1232 - val_acc: 0.4841\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.69170\n",
            "Epoch 195/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6403 - acc: 0.7821 - val_loss: 2.6390 - val_acc: 0.4173\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.69170\n",
            "Epoch 196/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6023 - acc: 0.7998 - val_loss: 2.7887 - val_acc: 0.4825\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.69170\n",
            "Epoch 197/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6173 - acc: 0.7903 - val_loss: 3.0014 - val_acc: 0.4111\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.69170\n",
            "Epoch 198/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6331 - acc: 0.7895 - val_loss: 0.9907 - val_acc: 0.6918\n",
            "\n",
            "Epoch 00198: val_acc improved from 0.69170 to 0.69180, saving model to /content/saved_models/cifar10_ResNet32v1_model.198.h5\n",
            "Epoch 199/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6270 - acc: 0.7892 - val_loss: 1.5638 - val_acc: 0.5842\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.69180\n",
            "Epoch 200/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6059 - acc: 0.7989 - val_loss: 2.9976 - val_acc: 0.4557\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.69180\n",
            "Epoch 201/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6377 - acc: 0.7959 - val_loss: 2.5037 - val_acc: 0.4776\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.69180\n",
            "Epoch 202/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6275 - acc: 0.7885 - val_loss: 4.7550 - val_acc: 0.3258\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.69180\n",
            "Epoch 203/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6012 - acc: 0.8011 - val_loss: 1.3699 - val_acc: 0.6517\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.69180\n",
            "Epoch 204/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6005 - acc: 0.8010 - val_loss: 2.4978 - val_acc: 0.4068\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.69180\n",
            "Epoch 205/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5955 - acc: 0.8056 - val_loss: 5.1404 - val_acc: 0.3082\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.69180\n",
            "Epoch 206/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6117 - acc: 0.7948 - val_loss: 1.8549 - val_acc: 0.5799\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.69180\n",
            "Epoch 207/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6013 - acc: 0.8016 - val_loss: 1.7712 - val_acc: 0.5473\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.69180\n",
            "Epoch 208/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6265 - acc: 0.7894 - val_loss: 3.1182 - val_acc: 0.3801\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.69180\n",
            "Epoch 209/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6274 - acc: 0.7925 - val_loss: 1.2982 - val_acc: 0.6286\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.69180\n",
            "Epoch 210/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6198 - acc: 0.7948 - val_loss: 2.1144 - val_acc: 0.5363\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.69180\n",
            "Epoch 211/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5937 - acc: 0.8003 - val_loss: 2.6071 - val_acc: 0.4458\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.69180\n",
            "Epoch 212/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6218 - acc: 0.7990 - val_loss: 2.9722 - val_acc: 0.4295\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.69180\n",
            "Epoch 213/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6046 - acc: 0.7925 - val_loss: 7.6109 - val_acc: 0.2049\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.69180\n",
            "Epoch 214/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5975 - acc: 0.8020 - val_loss: 1.8052 - val_acc: 0.5266\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.69180\n",
            "Epoch 215/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6243 - acc: 0.7939 - val_loss: 1.9337 - val_acc: 0.5853\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.69180\n",
            "Epoch 216/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6309 - acc: 0.7861 - val_loss: 1.9327 - val_acc: 0.5561\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.69180\n",
            "Epoch 217/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6106 - acc: 0.7958 - val_loss: 1.7930 - val_acc: 0.5421\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.69180\n",
            "Epoch 218/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6156 - acc: 0.7954 - val_loss: 2.2368 - val_acc: 0.4413\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.69180\n",
            "Epoch 219/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5847 - acc: 0.8054 - val_loss: 1.7478 - val_acc: 0.5871\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.69180\n",
            "Epoch 220/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6301 - acc: 0.7918 - val_loss: 1.5144 - val_acc: 0.5806\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.69180\n",
            "Epoch 221/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6291 - acc: 0.7883 - val_loss: 2.6389 - val_acc: 0.4226\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.69180\n",
            "Epoch 222/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5910 - acc: 0.8043 - val_loss: 1.3919 - val_acc: 0.6376\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.69180\n",
            "Epoch 223/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6114 - acc: 0.7949 - val_loss: 2.9768 - val_acc: 0.4033\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.69180\n",
            "Epoch 224/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5739 - acc: 0.8102 - val_loss: 1.4338 - val_acc: 0.6063\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.69180\n",
            "Epoch 225/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6223 - acc: 0.7921 - val_loss: 1.3874 - val_acc: 0.6007\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.69180\n",
            "Epoch 226/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6149 - acc: 0.7925 - val_loss: 2.5943 - val_acc: 0.4615\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.69180\n",
            "Epoch 227/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6280 - acc: 0.7929 - val_loss: 1.1415 - val_acc: 0.6617\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.69180\n",
            "Epoch 228/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6229 - acc: 0.7945 - val_loss: 1.4958 - val_acc: 0.5621\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.69180\n",
            "Epoch 229/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5877 - acc: 0.7991 - val_loss: 1.3681 - val_acc: 0.6438\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.69180\n",
            "Epoch 230/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6097 - acc: 0.7938 - val_loss: 3.8865 - val_acc: 0.3117\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.69180\n",
            "Epoch 231/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6243 - acc: 0.7906 - val_loss: 1.0872 - val_acc: 0.7102\n",
            "\n",
            "Epoch 00231: val_acc improved from 0.69180 to 0.71020, saving model to /content/saved_models/cifar10_ResNet32v1_model.231.h5\n",
            "Epoch 232/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5901 - acc: 0.8062 - val_loss: 2.5271 - val_acc: 0.5217\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.71020\n",
            "Epoch 233/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5682 - acc: 0.8098 - val_loss: 2.0462 - val_acc: 0.5206\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.71020\n",
            "Epoch 234/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6475 - acc: 0.7824 - val_loss: 1.6540 - val_acc: 0.5950\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.71020\n",
            "Epoch 235/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6176 - acc: 0.7956 - val_loss: 1.9222 - val_acc: 0.5535\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.71020\n",
            "Epoch 236/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6213 - acc: 0.7930 - val_loss: 1.9829 - val_acc: 0.5246\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.71020\n",
            "Epoch 237/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6072 - acc: 0.7991 - val_loss: 2.3507 - val_acc: 0.4579\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.71020\n",
            "Epoch 238/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6146 - acc: 0.7964 - val_loss: 1.9330 - val_acc: 0.5414\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.71020\n",
            "Epoch 239/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6272 - acc: 0.7945 - val_loss: 1.7059 - val_acc: 0.6011\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.71020\n",
            "Epoch 240/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5913 - acc: 0.8026 - val_loss: 2.5509 - val_acc: 0.5207\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.71020\n",
            "Epoch 241/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6149 - acc: 0.7964 - val_loss: 1.3931 - val_acc: 0.5961\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.71020\n",
            "Epoch 242/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6464 - acc: 0.7821 - val_loss: 1.5056 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.71020\n",
            "Epoch 243/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6296 - acc: 0.7999 - val_loss: 1.6235 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.71020\n",
            "Epoch 244/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6106 - acc: 0.8014 - val_loss: 1.7001 - val_acc: 0.5367\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.71020\n",
            "Epoch 245/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5904 - acc: 0.8035 - val_loss: 1.3767 - val_acc: 0.6060\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.71020\n",
            "Epoch 246/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5925 - acc: 0.8027 - val_loss: 1.7549 - val_acc: 0.5371\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.71020\n",
            "Epoch 247/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6088 - acc: 0.7934 - val_loss: 1.3621 - val_acc: 0.5975\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.71020\n",
            "Epoch 248/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6175 - acc: 0.7911 - val_loss: 1.5804 - val_acc: 0.5824\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.71020\n",
            "Epoch 249/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5971 - acc: 0.7992 - val_loss: 2.9954 - val_acc: 0.4453\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.71020\n",
            "Epoch 250/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6109 - acc: 0.7917 - val_loss: 2.9152 - val_acc: 0.4067\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.71020\n",
            "Epoch 251/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6053 - acc: 0.8017 - val_loss: 2.2472 - val_acc: 0.5096\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.71020\n",
            "Epoch 252/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5872 - acc: 0.8062 - val_loss: 0.8816 - val_acc: 0.7278\n",
            "\n",
            "Epoch 00252: val_acc improved from 0.71020 to 0.72780, saving model to /content/saved_models/cifar10_ResNet32v1_model.252.h5\n",
            "Epoch 253/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5951 - acc: 0.8010 - val_loss: 1.4704 - val_acc: 0.6347\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.72780\n",
            "Epoch 254/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5964 - acc: 0.8053 - val_loss: 2.4353 - val_acc: 0.4869\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.72780\n",
            "Epoch 255/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6118 - acc: 0.7892 - val_loss: 1.3419 - val_acc: 0.6462\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.72780\n",
            "Epoch 256/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6001 - acc: 0.7996 - val_loss: 0.9697 - val_acc: 0.7157\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.72780\n",
            "Epoch 257/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6015 - acc: 0.7937 - val_loss: 1.3868 - val_acc: 0.6178\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.72780\n",
            "Epoch 258/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6049 - acc: 0.8006 - val_loss: 1.1362 - val_acc: 0.6472\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.72780\n",
            "Epoch 259/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6379 - acc: 0.7879 - val_loss: 1.3539 - val_acc: 0.5961\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.72780\n",
            "Epoch 260/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6047 - acc: 0.8015 - val_loss: 3.8199 - val_acc: 0.3318\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.72780\n",
            "Epoch 261/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5903 - acc: 0.8074 - val_loss: 1.4824 - val_acc: 0.6075\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.72780\n",
            "Epoch 262/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6011 - acc: 0.8001 - val_loss: 2.9282 - val_acc: 0.4127\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.72780\n",
            "Epoch 263/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6034 - acc: 0.7949 - val_loss: 2.1544 - val_acc: 0.5097\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.72780\n",
            "Epoch 264/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6023 - acc: 0.7981 - val_loss: 3.1177 - val_acc: 0.4653\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.72780\n",
            "Epoch 265/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5871 - acc: 0.8044 - val_loss: 1.3019 - val_acc: 0.6139\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.72780\n",
            "Epoch 266/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6083 - acc: 0.7987 - val_loss: 3.5199 - val_acc: 0.4483\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.72780\n",
            "Epoch 267/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5911 - acc: 0.8004 - val_loss: 1.8136 - val_acc: 0.5414\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.72780\n",
            "Epoch 268/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6066 - acc: 0.7992 - val_loss: 1.4310 - val_acc: 0.6277\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.72780\n",
            "Epoch 269/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6069 - acc: 0.7963 - val_loss: 1.5166 - val_acc: 0.5606\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.72780\n",
            "Epoch 270/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5617 - acc: 0.8149 - val_loss: 2.5040 - val_acc: 0.4400\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.72780\n",
            "Epoch 271/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5831 - acc: 0.8091 - val_loss: 1.2345 - val_acc: 0.6453\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.72780\n",
            "Epoch 272/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6349 - acc: 0.7914 - val_loss: 2.2920 - val_acc: 0.5211\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.72780\n",
            "Epoch 273/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6023 - acc: 0.8037 - val_loss: 1.4362 - val_acc: 0.5896\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.72780\n",
            "Epoch 274/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5834 - acc: 0.8099 - val_loss: 1.4102 - val_acc: 0.5840\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.72780\n",
            "Epoch 275/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6058 - acc: 0.8011 - val_loss: 1.9957 - val_acc: 0.5447\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.72780\n",
            "Epoch 276/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5953 - acc: 0.8009 - val_loss: 4.9922 - val_acc: 0.3036\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.72780\n",
            "Epoch 277/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5832 - acc: 0.8015 - val_loss: 1.2450 - val_acc: 0.6281\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.72780\n",
            "Epoch 278/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5965 - acc: 0.8019 - val_loss: 1.5689 - val_acc: 0.5923\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.72780\n",
            "Epoch 279/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6012 - acc: 0.8048 - val_loss: 1.9127 - val_acc: 0.5453\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.72780\n",
            "Epoch 280/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5768 - acc: 0.8087 - val_loss: 1.9382 - val_acc: 0.5508\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.72780\n",
            "Epoch 281/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5813 - acc: 0.8108 - val_loss: 2.0631 - val_acc: 0.5384\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.72780\n",
            "Epoch 282/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6100 - acc: 0.7906 - val_loss: 2.1296 - val_acc: 0.4725\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.72780\n",
            "Epoch 283/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6107 - acc: 0.7938 - val_loss: 1.9705 - val_acc: 0.5461\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.72780\n",
            "Epoch 284/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5953 - acc: 0.8040 - val_loss: 1.1999 - val_acc: 0.6411\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.72780\n",
            "Epoch 285/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6025 - acc: 0.8034 - val_loss: 3.1651 - val_acc: 0.4301\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.72780\n",
            "Epoch 286/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5942 - acc: 0.8043 - val_loss: 1.8694 - val_acc: 0.5248\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.72780\n",
            "Epoch 287/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5874 - acc: 0.8023 - val_loss: 1.0919 - val_acc: 0.6722\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.72780\n",
            "Epoch 288/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5869 - acc: 0.8036 - val_loss: 2.1337 - val_acc: 0.4886\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.72780\n",
            "Epoch 289/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5767 - acc: 0.8053 - val_loss: 1.7048 - val_acc: 0.5736\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.72780\n",
            "Epoch 290/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5943 - acc: 0.7972 - val_loss: 0.9614 - val_acc: 0.7099\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.72780\n",
            "Epoch 291/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5855 - acc: 0.8063 - val_loss: 4.2043 - val_acc: 0.3645\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.72780\n",
            "Epoch 292/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6119 - acc: 0.7972 - val_loss: 1.5635 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.72780\n",
            "Epoch 293/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5870 - acc: 0.8026 - val_loss: 1.4180 - val_acc: 0.6314\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.72780\n",
            "Epoch 294/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5954 - acc: 0.8008 - val_loss: 2.1236 - val_acc: 0.5136\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.72780\n",
            "Epoch 295/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5911 - acc: 0.8058 - val_loss: 1.2742 - val_acc: 0.6164\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.72780\n",
            "Epoch 296/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5924 - acc: 0.8014 - val_loss: 2.7390 - val_acc: 0.4188\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.72780\n",
            "Epoch 297/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5887 - acc: 0.8065 - val_loss: 1.1740 - val_acc: 0.6423\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.72780\n",
            "Epoch 298/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5689 - acc: 0.8044 - val_loss: 1.3817 - val_acc: 0.6216\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.72780\n",
            "Epoch 299/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5787 - acc: 0.8059 - val_loss: 1.8981 - val_acc: 0.5466\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.72780\n",
            "Epoch 300/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6141 - acc: 0.7954 - val_loss: 2.2859 - val_acc: 0.5039\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.72780\n",
            "Epoch 301/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5633 - acc: 0.8118 - val_loss: 1.7002 - val_acc: 0.5585\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.72780\n",
            "Epoch 302/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5808 - acc: 0.8055 - val_loss: 2.3638 - val_acc: 0.5349\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.72780\n",
            "Epoch 303/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6063 - acc: 0.8010 - val_loss: 1.4752 - val_acc: 0.6044\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.72780\n",
            "Epoch 304/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5733 - acc: 0.8080 - val_loss: 1.3228 - val_acc: 0.6113\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.72780\n",
            "Epoch 305/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5912 - acc: 0.8022 - val_loss: 2.4445 - val_acc: 0.5038\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.72780\n",
            "Epoch 306/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5856 - acc: 0.8091 - val_loss: 2.3870 - val_acc: 0.4796\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.72780\n",
            "Epoch 307/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5719 - acc: 0.8078 - val_loss: 3.7578 - val_acc: 0.4270\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.72780\n",
            "Epoch 308/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6114 - acc: 0.7942 - val_loss: 1.8929 - val_acc: 0.5441\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.72780\n",
            "Epoch 309/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5880 - acc: 0.8043 - val_loss: 1.7630 - val_acc: 0.5440\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.72780\n",
            "Epoch 310/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5944 - acc: 0.8043 - val_loss: 1.5889 - val_acc: 0.5767\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.72780\n",
            "Epoch 311/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5692 - acc: 0.8058 - val_loss: 1.5342 - val_acc: 0.6191\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.72780\n",
            "Epoch 312/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5936 - acc: 0.8073 - val_loss: 1.7177 - val_acc: 0.5569\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.72780\n",
            "Epoch 313/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5720 - acc: 0.8098 - val_loss: 1.2869 - val_acc: 0.6061\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.72780\n",
            "Epoch 314/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5959 - acc: 0.8003 - val_loss: 1.9485 - val_acc: 0.5829\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.72780\n",
            "Epoch 315/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5826 - acc: 0.8102 - val_loss: 3.5614 - val_acc: 0.3873\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.72780\n",
            "Epoch 316/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6051 - acc: 0.7940 - val_loss: 1.5267 - val_acc: 0.5092\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.72780\n",
            "Epoch 317/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6001 - acc: 0.8013 - val_loss: 1.9882 - val_acc: 0.5319\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.72780\n",
            "Epoch 318/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5895 - acc: 0.8068 - val_loss: 1.3238 - val_acc: 0.6555\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.72780\n",
            "Epoch 319/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5650 - acc: 0.8122 - val_loss: 2.1049 - val_acc: 0.4287\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.72780\n",
            "Epoch 320/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5615 - acc: 0.8112 - val_loss: 1.9728 - val_acc: 0.5050\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.72780\n",
            "Epoch 321/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5936 - acc: 0.7994 - val_loss: 2.4259 - val_acc: 0.4611\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.72780\n",
            "Epoch 322/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6028 - acc: 0.8038 - val_loss: 5.6012 - val_acc: 0.2765\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.72780\n",
            "Epoch 323/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6124 - acc: 0.7950 - val_loss: 1.3729 - val_acc: 0.5974\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.72780\n",
            "Epoch 324/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5986 - acc: 0.8040 - val_loss: 1.2291 - val_acc: 0.6525\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.72780\n",
            "Epoch 325/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5722 - acc: 0.8086 - val_loss: 1.9663 - val_acc: 0.5254\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.72780\n",
            "Epoch 326/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5750 - acc: 0.8140 - val_loss: 1.8282 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.72780\n",
            "Epoch 327/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5859 - acc: 0.8082 - val_loss: 1.9824 - val_acc: 0.5192\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.72780\n",
            "Epoch 328/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5878 - acc: 0.7995 - val_loss: 0.9289 - val_acc: 0.7149\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.72780\n",
            "Epoch 329/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5812 - acc: 0.8034 - val_loss: 4.1726 - val_acc: 0.3703\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.72780\n",
            "Epoch 330/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5703 - acc: 0.8088 - val_loss: 1.6336 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.72780\n",
            "Epoch 331/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5899 - acc: 0.8058 - val_loss: 1.5631 - val_acc: 0.5531\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.72780\n",
            "Epoch 332/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5540 - acc: 0.8214 - val_loss: 2.0044 - val_acc: 0.5300\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.72780\n",
            "Epoch 333/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5771 - acc: 0.8061 - val_loss: 4.1627 - val_acc: 0.3348\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.72780\n",
            "Epoch 334/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5905 - acc: 0.8082 - val_loss: 1.7538 - val_acc: 0.5641\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.72780\n",
            "Epoch 335/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5773 - acc: 0.8053 - val_loss: 1.4825 - val_acc: 0.5753\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.72780\n",
            "Epoch 336/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5781 - acc: 0.8071 - val_loss: 1.3363 - val_acc: 0.6479\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.72780\n",
            "Epoch 337/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5890 - acc: 0.8024 - val_loss: 2.0779 - val_acc: 0.5182\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.72780\n",
            "Epoch 338/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5877 - acc: 0.7981 - val_loss: 1.7753 - val_acc: 0.5536\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.72780\n",
            "Epoch 339/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5772 - acc: 0.8095 - val_loss: 0.9296 - val_acc: 0.7014\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.72780\n",
            "Epoch 340/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5832 - acc: 0.8043 - val_loss: 1.3184 - val_acc: 0.6108\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.72780\n",
            "Epoch 341/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5881 - acc: 0.8074 - val_loss: 1.4240 - val_acc: 0.5974\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.72780\n",
            "Epoch 342/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5764 - acc: 0.8047 - val_loss: 1.1765 - val_acc: 0.6634\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.72780\n",
            "Epoch 343/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5943 - acc: 0.8061 - val_loss: 2.9630 - val_acc: 0.4227\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.72780\n",
            "Epoch 344/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5791 - acc: 0.8122 - val_loss: 3.2062 - val_acc: 0.4172\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.72780\n",
            "Epoch 345/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5796 - acc: 0.8106 - val_loss: 3.7268 - val_acc: 0.4420\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.72780\n",
            "Epoch 346/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5759 - acc: 0.8070 - val_loss: 2.7452 - val_acc: 0.4944\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.72780\n",
            "Epoch 347/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6029 - acc: 0.8016 - val_loss: 1.4150 - val_acc: 0.5922\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.72780\n",
            "Epoch 348/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6145 - acc: 0.7974 - val_loss: 3.6222 - val_acc: 0.3705\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.72780\n",
            "Epoch 349/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5876 - acc: 0.8022 - val_loss: 4.2642 - val_acc: 0.4307\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.72780\n",
            "Epoch 350/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5971 - acc: 0.8037 - val_loss: 1.4335 - val_acc: 0.6173\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.72780\n",
            "Epoch 351/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5782 - acc: 0.8101 - val_loss: 1.3298 - val_acc: 0.6478\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.72780\n",
            "Epoch 352/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5978 - acc: 0.8098 - val_loss: 1.0485 - val_acc: 0.7010\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.72780\n",
            "Epoch 353/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5834 - acc: 0.8093 - val_loss: 1.6674 - val_acc: 0.5848\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.72780\n",
            "Epoch 354/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5921 - acc: 0.7993 - val_loss: 1.2266 - val_acc: 0.6431\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.72780\n",
            "Epoch 355/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6044 - acc: 0.7962 - val_loss: 6.9729 - val_acc: 0.3361\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.72780\n",
            "Epoch 356/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6043 - acc: 0.8031 - val_loss: 2.8183 - val_acc: 0.4400\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.72780\n",
            "Epoch 357/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5922 - acc: 0.8056 - val_loss: 5.7500 - val_acc: 0.3289\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.72780\n",
            "Epoch 358/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5835 - acc: 0.8085 - val_loss: 1.3585 - val_acc: 0.5976\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.72780\n",
            "Epoch 359/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5386 - acc: 0.8216 - val_loss: 4.3435 - val_acc: 0.3499\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.72780\n",
            "Epoch 360/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5714 - acc: 0.8054 - val_loss: 3.9870 - val_acc: 0.3782\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.72780\n",
            "Epoch 361/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5781 - acc: 0.8104 - val_loss: 1.1735 - val_acc: 0.6839\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.72780\n",
            "Epoch 362/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5826 - acc: 0.8059 - val_loss: 2.0534 - val_acc: 0.5482\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.72780\n",
            "Epoch 363/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5971 - acc: 0.8049 - val_loss: 1.9416 - val_acc: 0.5797\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.72780\n",
            "Epoch 364/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5854 - acc: 0.8033 - val_loss: 1.3020 - val_acc: 0.6477\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.72780\n",
            "Epoch 365/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5917 - acc: 0.8045 - val_loss: 2.4504 - val_acc: 0.5078\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.72780\n",
            "Epoch 366/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5989 - acc: 0.7978 - val_loss: 1.1581 - val_acc: 0.6465\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.72780\n",
            "Epoch 367/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5943 - acc: 0.8027 - val_loss: 2.0930 - val_acc: 0.5060\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.72780\n",
            "Epoch 368/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5702 - acc: 0.8069 - val_loss: 1.6041 - val_acc: 0.5054\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.72780\n",
            "Epoch 369/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5771 - acc: 0.8059 - val_loss: 1.2024 - val_acc: 0.6228\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.72780\n",
            "Epoch 370/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5899 - acc: 0.8027 - val_loss: 1.6400 - val_acc: 0.5395\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.72780\n",
            "Epoch 371/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5650 - acc: 0.8105 - val_loss: 0.8564 - val_acc: 0.7240\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.72780\n",
            "Epoch 372/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6026 - acc: 0.7959 - val_loss: 2.0871 - val_acc: 0.5480\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.72780\n",
            "Epoch 373/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5747 - acc: 0.8069 - val_loss: 1.2657 - val_acc: 0.6467\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.72780\n",
            "Epoch 374/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5823 - acc: 0.8064 - val_loss: 2.3315 - val_acc: 0.4802\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.72780\n",
            "Epoch 375/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6042 - acc: 0.7956 - val_loss: 2.2245 - val_acc: 0.5212\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.72780\n",
            "Epoch 376/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5856 - acc: 0.8095 - val_loss: 2.0866 - val_acc: 0.4717\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.72780\n",
            "Epoch 377/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5874 - acc: 0.8020 - val_loss: 1.9544 - val_acc: 0.5408\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.72780\n",
            "Epoch 378/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5905 - acc: 0.8095 - val_loss: 1.7435 - val_acc: 0.5292\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.72780\n",
            "Epoch 379/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5723 - acc: 0.8144 - val_loss: 4.5223 - val_acc: 0.3098\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.72780\n",
            "Epoch 380/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5625 - acc: 0.8088 - val_loss: 3.1188 - val_acc: 0.4243\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.72780\n",
            "Epoch 381/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5793 - acc: 0.8041 - val_loss: 3.7055 - val_acc: 0.4129\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.72780\n",
            "Epoch 382/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5849 - acc: 0.8053 - val_loss: 3.8679 - val_acc: 0.3452\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.72780\n",
            "Epoch 383/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5902 - acc: 0.8061 - val_loss: 2.5600 - val_acc: 0.4807\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.72780\n",
            "Epoch 384/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5640 - acc: 0.8157 - val_loss: 2.2177 - val_acc: 0.4888\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.72780\n",
            "Epoch 385/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5765 - acc: 0.8090 - val_loss: 1.1294 - val_acc: 0.6526\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.72780\n",
            "Epoch 386/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5586 - acc: 0.8174 - val_loss: 1.7658 - val_acc: 0.5340\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.72780\n",
            "Epoch 387/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6047 - acc: 0.8019 - val_loss: 1.2524 - val_acc: 0.6576\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.72780\n",
            "Epoch 388/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5926 - acc: 0.8045 - val_loss: 2.4131 - val_acc: 0.4949\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.72780\n",
            "Epoch 389/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5780 - acc: 0.8072 - val_loss: 7.1386 - val_acc: 0.2403\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.72780\n",
            "Epoch 390/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5844 - acc: 0.8086 - val_loss: 1.0555 - val_acc: 0.6784\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.72780\n",
            "Epoch 391/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5971 - acc: 0.8049 - val_loss: 1.6941 - val_acc: 0.5489\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.72780\n",
            "Epoch 392/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5973 - acc: 0.7996 - val_loss: 1.7943 - val_acc: 0.5326\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.72780\n",
            "Epoch 393/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5677 - acc: 0.8088 - val_loss: 2.5399 - val_acc: 0.4899\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.72780\n",
            "Epoch 394/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5812 - acc: 0.8081 - val_loss: 1.7366 - val_acc: 0.5767\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.72780\n",
            "Epoch 395/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5869 - acc: 0.8048 - val_loss: 1.7830 - val_acc: 0.5379\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.72780\n",
            "Epoch 396/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6046 - acc: 0.8060 - val_loss: 1.6148 - val_acc: 0.5737\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.72780\n",
            "Epoch 397/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5613 - acc: 0.8182 - val_loss: 1.7874 - val_acc: 0.5692\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.72780\n",
            "Epoch 398/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5937 - acc: 0.8028 - val_loss: 1.6979 - val_acc: 0.5597\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.72780\n",
            "Epoch 399/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5906 - acc: 0.8029 - val_loss: 2.3462 - val_acc: 0.4702\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.72780\n",
            "Epoch 400/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6078 - acc: 0.7960 - val_loss: 1.7247 - val_acc: 0.5436\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.72780\n",
            "Epoch 401/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5876 - acc: 0.8006 - val_loss: 3.8131 - val_acc: 0.4011\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.72780\n",
            "Epoch 402/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5054 - acc: 0.8388 - val_loss: 0.5592 - val_acc: 0.8161\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.72780 to 0.81610, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4066 - acc: 0.8691 - val_loss: 0.4887 - val_acc: 0.8373\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.81610 to 0.83730, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3742 - acc: 0.8864 - val_loss: 0.4482 - val_acc: 0.8504\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.83730 to 0.85040, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3427 - acc: 0.8939 - val_loss: 0.4037 - val_acc: 0.8678\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.85040 to 0.86780, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3441 - acc: 0.8875 - val_loss: 0.3950 - val_acc: 0.8708\n",
            "\n",
            "Epoch 00406: val_acc improved from 0.86780 to 0.87080, saving model to /content/saved_models/cifar10_ResNet32v1_model.406.h5\n",
            "Epoch 407/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3343 - acc: 0.8904 - val_loss: 0.4339 - val_acc: 0.8569\n",
            "\n",
            "Epoch 00407: val_acc did not improve from 0.87080\n",
            "Epoch 408/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3421 - acc: 0.8869 - val_loss: 0.4342 - val_acc: 0.8602\n",
            "\n",
            "Epoch 00408: val_acc did not improve from 0.87080\n",
            "Epoch 409/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3319 - acc: 0.8922 - val_loss: 0.4007 - val_acc: 0.8694\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.87080\n",
            "Epoch 410/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3169 - acc: 0.8960 - val_loss: 0.3786 - val_acc: 0.8764\n",
            "\n",
            "Epoch 00410: val_acc improved from 0.87080 to 0.87640, saving model to /content/saved_models/cifar10_ResNet32v1_model.410.h5\n",
            "Epoch 411/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3126 - acc: 0.9011 - val_loss: 0.4027 - val_acc: 0.8674\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.87640\n",
            "Epoch 412/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3054 - acc: 0.8996 - val_loss: 0.4097 - val_acc: 0.8686\n",
            "\n",
            "Epoch 00412: val_acc did not improve from 0.87640\n",
            "Epoch 413/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3045 - acc: 0.9020 - val_loss: 0.4241 - val_acc: 0.8598\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.87640\n",
            "Epoch 414/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2790 - acc: 0.9101 - val_loss: 0.3678 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00414: val_acc improved from 0.87640 to 0.87780, saving model to /content/saved_models/cifar10_ResNet32v1_model.414.h5\n",
            "Epoch 415/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2871 - acc: 0.9075 - val_loss: 0.3734 - val_acc: 0.8820\n",
            "\n",
            "Epoch 00415: val_acc improved from 0.87780 to 0.88200, saving model to /content/saved_models/cifar10_ResNet32v1_model.415.h5\n",
            "Epoch 416/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2997 - acc: 0.9047 - val_loss: 0.4263 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.88200\n",
            "Epoch 417/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2841 - acc: 0.9057 - val_loss: 0.3763 - val_acc: 0.8753\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.88200\n",
            "Epoch 418/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2762 - acc: 0.9112 - val_loss: 0.4179 - val_acc: 0.8671\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.88200\n",
            "Epoch 419/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2653 - acc: 0.9143 - val_loss: 0.3671 - val_acc: 0.8819\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.88200\n",
            "Epoch 420/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2886 - acc: 0.9049 - val_loss: 0.3931 - val_acc: 0.8710\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.88200\n",
            "Epoch 421/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2766 - acc: 0.9077 - val_loss: 0.4148 - val_acc: 0.8693\n",
            "\n",
            "Epoch 00421: val_acc did not improve from 0.88200\n",
            "Epoch 422/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2609 - acc: 0.9147 - val_loss: 0.3692 - val_acc: 0.8852\n",
            "\n",
            "Epoch 00422: val_acc improved from 0.88200 to 0.88520, saving model to /content/saved_models/cifar10_ResNet32v1_model.422.h5\n",
            "Epoch 423/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2553 - acc: 0.9173 - val_loss: 0.3680 - val_acc: 0.8824\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.88520\n",
            "Epoch 424/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2687 - acc: 0.9131 - val_loss: 0.3712 - val_acc: 0.8827\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.88520\n",
            "Epoch 425/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2689 - acc: 0.9154 - val_loss: 0.3686 - val_acc: 0.8781\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.88520\n",
            "Epoch 426/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2548 - acc: 0.9197 - val_loss: 0.3619 - val_acc: 0.8858\n",
            "\n",
            "Epoch 00426: val_acc improved from 0.88520 to 0.88580, saving model to /content/saved_models/cifar10_ResNet32v1_model.426.h5\n",
            "Epoch 427/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2596 - acc: 0.9205 - val_loss: 0.3679 - val_acc: 0.8820\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.88580\n",
            "Epoch 428/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2687 - acc: 0.9091 - val_loss: 0.4027 - val_acc: 0.8737\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.88580\n",
            "Epoch 429/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2573 - acc: 0.9193 - val_loss: 0.3977 - val_acc: 0.8714\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.88580\n",
            "Epoch 430/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2465 - acc: 0.9204 - val_loss: 0.3648 - val_acc: 0.8766\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.88580\n",
            "Epoch 431/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2528 - acc: 0.9146 - val_loss: 0.4329 - val_acc: 0.8646\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.88580\n",
            "Epoch 432/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2454 - acc: 0.9241 - val_loss: 0.3735 - val_acc: 0.8781\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.88580\n",
            "Epoch 433/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2505 - acc: 0.9200 - val_loss: 0.3690 - val_acc: 0.8822\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.88580\n",
            "Epoch 434/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2239 - acc: 0.9283 - val_loss: 0.3248 - val_acc: 0.8935\n",
            "\n",
            "Epoch 00434: val_acc improved from 0.88580 to 0.89350, saving model to /content/saved_models/cifar10_ResNet32v1_model.434.h5\n",
            "Epoch 435/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2326 - acc: 0.9258 - val_loss: 0.4357 - val_acc: 0.8638\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.89350\n",
            "Epoch 436/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2427 - acc: 0.9228 - val_loss: 0.3603 - val_acc: 0.8864\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.89350\n",
            "Epoch 437/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2383 - acc: 0.9275 - val_loss: 0.3491 - val_acc: 0.8856\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.89350\n",
            "Epoch 438/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2358 - acc: 0.9247 - val_loss: 0.3782 - val_acc: 0.8798\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.89350\n",
            "Epoch 439/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2188 - acc: 0.9283 - val_loss: 0.3496 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.89350\n",
            "Epoch 440/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2136 - acc: 0.9296 - val_loss: 0.3451 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.89350\n",
            "Epoch 441/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2302 - acc: 0.9248 - val_loss: 0.3965 - val_acc: 0.8732\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.89350\n",
            "Epoch 442/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2334 - acc: 0.9260 - val_loss: 0.4086 - val_acc: 0.8735\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.89350\n",
            "Epoch 443/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2268 - acc: 0.9244 - val_loss: 0.3425 - val_acc: 0.8913\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.89350\n",
            "Epoch 444/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2112 - acc: 0.9334 - val_loss: 0.3643 - val_acc: 0.8837\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.89350\n",
            "Epoch 445/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2242 - acc: 0.9283 - val_loss: 0.3251 - val_acc: 0.8934\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.89350\n",
            "Epoch 446/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2214 - acc: 0.9254 - val_loss: 0.3457 - val_acc: 0.8863\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.89350\n",
            "Epoch 447/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2196 - acc: 0.9285 - val_loss: 0.3833 - val_acc: 0.8782\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.89350\n",
            "Epoch 448/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2158 - acc: 0.9324 - val_loss: 0.3954 - val_acc: 0.8754\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.89350\n",
            "Epoch 449/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2232 - acc: 0.9255 - val_loss: 0.3640 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.89350\n",
            "Epoch 450/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2111 - acc: 0.9336 - val_loss: 0.4462 - val_acc: 0.8639\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.89350\n",
            "Epoch 451/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2061 - acc: 0.9337 - val_loss: 0.4065 - val_acc: 0.8710\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.89350\n",
            "Epoch 452/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2266 - acc: 0.9228 - val_loss: 0.3788 - val_acc: 0.8791\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.89350\n",
            "Epoch 453/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2146 - acc: 0.9312 - val_loss: 0.3581 - val_acc: 0.8874\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.89350\n",
            "Epoch 454/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2002 - acc: 0.9355 - val_loss: 0.3630 - val_acc: 0.8813\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.89350\n",
            "Epoch 455/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2161 - acc: 0.9281 - val_loss: 0.3615 - val_acc: 0.8876\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.89350\n",
            "Epoch 456/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1986 - acc: 0.9350 - val_loss: 0.3455 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.89350\n",
            "Epoch 457/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2110 - acc: 0.9331 - val_loss: 0.3457 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.89350\n",
            "Epoch 458/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2020 - acc: 0.9348 - val_loss: 0.3395 - val_acc: 0.8891\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.89350\n",
            "Epoch 459/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1981 - acc: 0.9363 - val_loss: 0.3788 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.89350\n",
            "Epoch 460/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1951 - acc: 0.9383 - val_loss: 0.3497 - val_acc: 0.8926\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.89350\n",
            "Epoch 461/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2017 - acc: 0.9373 - val_loss: 0.3400 - val_acc: 0.8937\n",
            "\n",
            "Epoch 00461: val_acc improved from 0.89350 to 0.89370, saving model to /content/saved_models/cifar10_ResNet32v1_model.461.h5\n",
            "Epoch 462/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2005 - acc: 0.9380 - val_loss: 0.3973 - val_acc: 0.8785\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.89370\n",
            "Epoch 463/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1982 - acc: 0.9337 - val_loss: 0.3619 - val_acc: 0.8870\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.89370\n",
            "Epoch 464/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2045 - acc: 0.9359 - val_loss: 0.3882 - val_acc: 0.8788\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.89370\n",
            "Epoch 465/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2055 - acc: 0.9326 - val_loss: 0.3942 - val_acc: 0.8788\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.89370\n",
            "Epoch 466/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1881 - acc: 0.9386 - val_loss: 0.3937 - val_acc: 0.8794\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.89370\n",
            "Epoch 467/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1852 - acc: 0.9401 - val_loss: 0.3495 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.89370\n",
            "Epoch 468/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1919 - acc: 0.9355 - val_loss: 0.3912 - val_acc: 0.8779\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.89370\n",
            "Epoch 469/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1855 - acc: 0.9424 - val_loss: 0.3454 - val_acc: 0.8908\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.89370\n",
            "Epoch 470/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1863 - acc: 0.9417 - val_loss: 0.3484 - val_acc: 0.8898\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.89370\n",
            "Epoch 471/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1796 - acc: 0.9484 - val_loss: 0.3923 - val_acc: 0.8799\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.89370\n",
            "Epoch 472/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1834 - acc: 0.9406 - val_loss: 0.3221 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00472: val_acc improved from 0.89370 to 0.89810, saving model to /content/saved_models/cifar10_ResNet32v1_model.472.h5\n",
            "Epoch 473/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1940 - acc: 0.9350 - val_loss: 0.3540 - val_acc: 0.8882\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.89810\n",
            "Epoch 474/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1875 - acc: 0.9416 - val_loss: 0.4083 - val_acc: 0.8728\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.89810\n",
            "Epoch 475/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1944 - acc: 0.9365 - val_loss: 0.3651 - val_acc: 0.8857\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.89810\n",
            "Epoch 476/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1806 - acc: 0.9412 - val_loss: 0.3838 - val_acc: 0.8810\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.89810\n",
            "Epoch 477/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1875 - acc: 0.9409 - val_loss: 0.3689 - val_acc: 0.8895\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.89810\n",
            "Epoch 478/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1752 - acc: 0.9444 - val_loss: 0.3176 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00478: val_acc improved from 0.89810 to 0.89970, saving model to /content/saved_models/cifar10_ResNet32v1_model.478.h5\n",
            "Epoch 479/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1830 - acc: 0.9435 - val_loss: 0.4146 - val_acc: 0.8748\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.89970\n",
            "Epoch 480/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1829 - acc: 0.9411 - val_loss: 0.3288 - val_acc: 0.8954\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.89970\n",
            "Epoch 481/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1802 - acc: 0.9428 - val_loss: 0.3758 - val_acc: 0.8850\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.89970\n",
            "Epoch 482/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1789 - acc: 0.9410 - val_loss: 0.3383 - val_acc: 0.8930\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.89970\n",
            "Epoch 483/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1701 - acc: 0.9463 - val_loss: 0.3429 - val_acc: 0.8906\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.89970\n",
            "Epoch 484/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1891 - acc: 0.9392 - val_loss: 0.3503 - val_acc: 0.8902\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.89970\n",
            "Epoch 485/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1838 - acc: 0.9419 - val_loss: 0.3799 - val_acc: 0.8840\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.89970\n",
            "Epoch 486/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1982 - acc: 0.9324 - val_loss: 0.3255 - val_acc: 0.8934\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.89970\n",
            "Epoch 487/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1829 - acc: 0.9398 - val_loss: 0.4175 - val_acc: 0.8744\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.89970\n",
            "Epoch 488/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1745 - acc: 0.9450 - val_loss: 0.4021 - val_acc: 0.8767\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.89970\n",
            "Epoch 489/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1700 - acc: 0.9479 - val_loss: 0.3254 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.89970\n",
            "Epoch 490/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1751 - acc: 0.9451 - val_loss: 0.3701 - val_acc: 0.8868\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.89970\n",
            "Epoch 491/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1736 - acc: 0.9412 - val_loss: 0.3517 - val_acc: 0.8905\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.89970\n",
            "Epoch 492/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1729 - acc: 0.9444 - val_loss: 0.3938 - val_acc: 0.8792\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.89970\n",
            "Epoch 493/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1728 - acc: 0.9484 - val_loss: 0.3973 - val_acc: 0.8812\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.89970\n",
            "Epoch 494/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1695 - acc: 0.9454 - val_loss: 0.4391 - val_acc: 0.8665\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.89970\n",
            "Epoch 495/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1623 - acc: 0.9492 - val_loss: 0.3261 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.89970\n",
            "Epoch 496/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1633 - acc: 0.9503 - val_loss: 0.3271 - val_acc: 0.8965\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.89970\n",
            "Epoch 497/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1737 - acc: 0.9439 - val_loss: 0.3882 - val_acc: 0.8834\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.89970\n",
            "Epoch 498/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1774 - acc: 0.9416 - val_loss: 0.3702 - val_acc: 0.8879\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.89970\n",
            "Epoch 499/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1547 - acc: 0.9520 - val_loss: 0.3757 - val_acc: 0.8851\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.89970\n",
            "Epoch 500/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1689 - acc: 0.9482 - val_loss: 0.3624 - val_acc: 0.8918\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.89970\n",
            "Epoch 501/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1635 - acc: 0.9479 - val_loss: 0.3325 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.89970\n",
            "Epoch 502/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1616 - acc: 0.9466 - val_loss: 0.3283 - val_acc: 0.8964\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.89970\n",
            "Epoch 503/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1495 - acc: 0.9523 - val_loss: 0.3819 - val_acc: 0.8825\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.89970\n",
            "Epoch 504/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1609 - acc: 0.9523 - val_loss: 0.3505 - val_acc: 0.8904\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.89970\n",
            "Epoch 505/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1674 - acc: 0.9421 - val_loss: 0.4030 - val_acc: 0.8799\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.89970\n",
            "Epoch 506/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1511 - acc: 0.9524 - val_loss: 0.3270 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.89970\n",
            "Epoch 507/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1731 - acc: 0.9473 - val_loss: 0.3382 - val_acc: 0.8966\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.89970\n",
            "Epoch 508/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1594 - acc: 0.9504 - val_loss: 0.4659 - val_acc: 0.8692\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.89970\n",
            "Epoch 509/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1582 - acc: 0.9496 - val_loss: 0.4282 - val_acc: 0.8746\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.89970\n",
            "Epoch 510/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1569 - acc: 0.9521 - val_loss: 0.4871 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.89970\n",
            "Epoch 511/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1582 - acc: 0.9474 - val_loss: 0.3335 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.89970\n",
            "Epoch 512/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1566 - acc: 0.9479 - val_loss: 0.3564 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.89970\n",
            "Epoch 513/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1591 - acc: 0.9487 - val_loss: 0.5226 - val_acc: 0.8473\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.89970\n",
            "Epoch 514/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1674 - acc: 0.9440 - val_loss: 0.3468 - val_acc: 0.8915\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.89970\n",
            "Epoch 515/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1626 - acc: 0.9468 - val_loss: 0.4318 - val_acc: 0.8742\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.89970\n",
            "Epoch 516/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1646 - acc: 0.9441 - val_loss: 0.4265 - val_acc: 0.8738\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.89970\n",
            "Epoch 517/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1568 - acc: 0.9504 - val_loss: 0.3423 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.89970\n",
            "Epoch 518/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1409 - acc: 0.9566 - val_loss: 0.3741 - val_acc: 0.8840\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.89970\n",
            "Epoch 519/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1734 - acc: 0.9448 - val_loss: 0.3384 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.89970\n",
            "Epoch 520/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1655 - acc: 0.9432 - val_loss: 0.3415 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.89970\n",
            "Epoch 521/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1476 - acc: 0.9548 - val_loss: 0.3241 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.89970\n",
            "Epoch 522/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1488 - acc: 0.9520 - val_loss: 0.3979 - val_acc: 0.8807\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.89970\n",
            "Epoch 523/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1539 - acc: 0.9512 - val_loss: 0.3567 - val_acc: 0.8918\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.89970\n",
            "Epoch 524/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1414 - acc: 0.9554 - val_loss: 0.3427 - val_acc: 0.8933\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.89970\n",
            "Epoch 525/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1575 - acc: 0.9518 - val_loss: 0.3487 - val_acc: 0.8967\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.89970\n",
            "Epoch 526/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1492 - acc: 0.9530 - val_loss: 0.3894 - val_acc: 0.8856\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.89970\n",
            "Epoch 527/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1519 - acc: 0.9507 - val_loss: 0.3596 - val_acc: 0.8899\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.89970\n",
            "Epoch 528/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1635 - acc: 0.9485 - val_loss: 0.3817 - val_acc: 0.8847\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.89970\n",
            "Epoch 529/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1627 - acc: 0.9482 - val_loss: 0.4022 - val_acc: 0.8838\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.89970\n",
            "Epoch 530/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1445 - acc: 0.9559 - val_loss: 0.3528 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.89970\n",
            "Epoch 531/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1555 - acc: 0.9513 - val_loss: 0.3792 - val_acc: 0.8858\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.89970\n",
            "Epoch 532/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1419 - acc: 0.9558 - val_loss: 0.3579 - val_acc: 0.8952\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.89970\n",
            "Epoch 533/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1491 - acc: 0.9531 - val_loss: 0.4207 - val_acc: 0.8768\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.89970\n",
            "Epoch 534/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1334 - acc: 0.9561 - val_loss: 0.4017 - val_acc: 0.8827\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.89970\n",
            "Epoch 535/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1527 - acc: 0.9517 - val_loss: 0.3788 - val_acc: 0.8864\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.89970\n",
            "Epoch 536/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1378 - acc: 0.9587 - val_loss: 0.3362 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.89970\n",
            "Epoch 537/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1456 - acc: 0.9569 - val_loss: 0.4381 - val_acc: 0.8688\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.89970\n",
            "Epoch 538/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1400 - acc: 0.9564 - val_loss: 0.3868 - val_acc: 0.8853\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.89970\n",
            "Epoch 539/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1469 - acc: 0.9588 - val_loss: 0.3909 - val_acc: 0.8848\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.89970\n",
            "Epoch 540/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1476 - acc: 0.9522 - val_loss: 0.4637 - val_acc: 0.8697\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.89970\n",
            "Epoch 541/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1424 - acc: 0.9547 - val_loss: 0.3964 - val_acc: 0.8812\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.89970\n",
            "Epoch 542/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1491 - acc: 0.9539 - val_loss: 0.3711 - val_acc: 0.8871\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.89970\n",
            "Epoch 543/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1268 - acc: 0.9597 - val_loss: 0.3702 - val_acc: 0.8875\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.89970\n",
            "Epoch 544/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1364 - acc: 0.9554 - val_loss: 0.3735 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.89970\n",
            "Epoch 545/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1456 - acc: 0.9584 - val_loss: 0.3608 - val_acc: 0.8928\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.89970\n",
            "Epoch 546/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1405 - acc: 0.9604 - val_loss: 0.4043 - val_acc: 0.8815\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.89970\n",
            "Epoch 547/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1464 - acc: 0.9532 - val_loss: 0.3861 - val_acc: 0.8824\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.89970\n",
            "Epoch 548/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1389 - acc: 0.9567 - val_loss: 0.3144 - val_acc: 0.9016\n",
            "\n",
            "Epoch 00548: val_acc improved from 0.89970 to 0.90160, saving model to /content/saved_models/cifar10_ResNet32v1_model.548.h5\n",
            "Epoch 549/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1445 - acc: 0.9529 - val_loss: 0.3447 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.90160\n",
            "Epoch 550/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1443 - acc: 0.9567 - val_loss: 0.3353 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.90160\n",
            "Epoch 551/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1313 - acc: 0.9569 - val_loss: 0.3524 - val_acc: 0.8932\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.90160\n",
            "Epoch 552/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1421 - acc: 0.9548 - val_loss: 0.3453 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.90160\n",
            "Epoch 553/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1373 - acc: 0.9546 - val_loss: 0.4278 - val_acc: 0.8767\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.90160\n",
            "Epoch 554/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1456 - acc: 0.9532 - val_loss: 0.3496 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.90160\n",
            "Epoch 555/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1369 - acc: 0.9569 - val_loss: 0.3217 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.90160\n",
            "Epoch 556/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1449 - acc: 0.9531 - val_loss: 0.3400 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.90160\n",
            "Epoch 557/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1393 - acc: 0.9567 - val_loss: 0.3992 - val_acc: 0.8855\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.90160\n",
            "Epoch 558/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1365 - acc: 0.9600 - val_loss: 0.3298 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.90160\n",
            "Epoch 559/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1304 - acc: 0.9586 - val_loss: 0.4002 - val_acc: 0.8817\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.90160\n",
            "Epoch 560/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1360 - acc: 0.9562 - val_loss: 0.4003 - val_acc: 0.8857\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.90160\n",
            "Epoch 561/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1361 - acc: 0.9576 - val_loss: 0.4453 - val_acc: 0.8733\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.90160\n",
            "Epoch 562/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1282 - acc: 0.9586 - val_loss: 0.3825 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.90160\n",
            "Epoch 563/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1188 - acc: 0.9643 - val_loss: 0.3698 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.90160\n",
            "Epoch 564/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1437 - acc: 0.9565 - val_loss: 0.3383 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.90160\n",
            "Epoch 565/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1383 - acc: 0.9559 - val_loss: 0.3901 - val_acc: 0.8884\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.90160\n",
            "Epoch 566/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1433 - acc: 0.9534 - val_loss: 0.4001 - val_acc: 0.8843\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.90160\n",
            "Epoch 567/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1249 - acc: 0.9615 - val_loss: 0.4231 - val_acc: 0.8800\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.90160\n",
            "Epoch 568/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1365 - acc: 0.9605 - val_loss: 0.3212 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.90160\n",
            "Epoch 569/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1317 - acc: 0.9590 - val_loss: 0.3847 - val_acc: 0.8846\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.90160\n",
            "Epoch 570/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1376 - acc: 0.9547 - val_loss: 0.3750 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.90160\n",
            "Epoch 571/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1218 - acc: 0.9645 - val_loss: 0.4024 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.90160\n",
            "Epoch 572/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1279 - acc: 0.9593 - val_loss: 0.3724 - val_acc: 0.8909\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.90160\n",
            "Epoch 573/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1281 - acc: 0.9607 - val_loss: 0.4688 - val_acc: 0.8681\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.90160\n",
            "Epoch 574/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1367 - acc: 0.9600 - val_loss: 0.3693 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.90160\n",
            "Epoch 575/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1267 - acc: 0.9608 - val_loss: 0.4588 - val_acc: 0.8701\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.90160\n",
            "Epoch 576/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1362 - acc: 0.9562 - val_loss: 0.3457 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.90160\n",
            "Epoch 577/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1324 - acc: 0.9571 - val_loss: 0.3622 - val_acc: 0.8910\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.90160\n",
            "Epoch 578/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1260 - acc: 0.9617 - val_loss: 0.3413 - val_acc: 0.8998\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.90160\n",
            "Epoch 579/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1273 - acc: 0.9602 - val_loss: 0.3713 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.90160\n",
            "Epoch 580/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1223 - acc: 0.9623 - val_loss: 0.3778 - val_acc: 0.8926\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.90160\n",
            "Epoch 581/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1286 - acc: 0.9589 - val_loss: 0.3530 - val_acc: 0.8966\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.90160\n",
            "Epoch 582/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1195 - acc: 0.9640 - val_loss: 0.3975 - val_acc: 0.8872\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.90160\n",
            "Epoch 583/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1263 - acc: 0.9595 - val_loss: 0.4278 - val_acc: 0.8783\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.90160\n",
            "Epoch 584/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1241 - acc: 0.9597 - val_loss: 0.3469 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.90160\n",
            "Epoch 585/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1201 - acc: 0.9630 - val_loss: 0.4126 - val_acc: 0.8810\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.90160\n",
            "Epoch 586/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1273 - acc: 0.9589 - val_loss: 0.3600 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.90160\n",
            "Epoch 587/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1269 - acc: 0.9619 - val_loss: 0.4083 - val_acc: 0.8830\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.90160\n",
            "Epoch 588/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1253 - acc: 0.9659 - val_loss: 0.3412 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.90160\n",
            "Epoch 589/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1213 - acc: 0.9626 - val_loss: 0.4309 - val_acc: 0.8777\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.90160\n",
            "Epoch 590/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1259 - acc: 0.9604 - val_loss: 0.4039 - val_acc: 0.8877\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.90160\n",
            "Epoch 591/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1254 - acc: 0.9616 - val_loss: 0.3991 - val_acc: 0.8845\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.90160\n",
            "Epoch 592/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1272 - acc: 0.9592 - val_loss: 0.3911 - val_acc: 0.8871\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.90160\n",
            "Epoch 593/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1302 - acc: 0.9573 - val_loss: 0.4658 - val_acc: 0.8699\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.90160\n",
            "Epoch 594/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1392 - acc: 0.9555 - val_loss: 0.3575 - val_acc: 0.8953\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.90160\n",
            "Epoch 595/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1219 - acc: 0.9629 - val_loss: 0.3239 - val_acc: 0.9022\n",
            "\n",
            "Epoch 00595: val_acc improved from 0.90160 to 0.90220, saving model to /content/saved_models/cifar10_ResNet32v1_model.595.h5\n",
            "Epoch 596/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1134 - acc: 0.9657 - val_loss: 0.3244 - val_acc: 0.9043\n",
            "\n",
            "Epoch 00596: val_acc improved from 0.90220 to 0.90430, saving model to /content/saved_models/cifar10_ResNet32v1_model.596.h5\n",
            "Epoch 597/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1138 - acc: 0.9640 - val_loss: 0.3498 - val_acc: 0.8953\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.90430\n",
            "Epoch 598/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1257 - acc: 0.9591 - val_loss: 0.3464 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.90430\n",
            "Epoch 599/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1373 - acc: 0.9554 - val_loss: 0.4347 - val_acc: 0.8826\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.90430\n",
            "Epoch 600/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1276 - acc: 0.9584 - val_loss: 0.3903 - val_acc: 0.8882\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.90430\n",
            "Epoch 601/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1338 - acc: 0.9603 - val_loss: 0.4808 - val_acc: 0.8686\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.90430\n",
            "Epoch 602/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1242 - acc: 0.9622 - val_loss: 0.2935 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00602: val_acc improved from 0.90430 to 0.91330, saving model to /content/saved_models/cifar10_ResNet32v1_model.602.h5\n",
            "Epoch 603/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1075 - acc: 0.9681 - val_loss: 0.2803 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00603: val_acc improved from 0.91330 to 0.91700, saving model to /content/saved_models/cifar10_ResNet32v1_model.603.h5\n",
            "Epoch 604/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1046 - acc: 0.9694 - val_loss: 0.2781 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00604: val_acc did not improve from 0.91700\n",
            "Epoch 605/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0974 - acc: 0.9731 - val_loss: 0.2741 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00605: val_acc improved from 0.91700 to 0.91890, saving model to /content/saved_models/cifar10_ResNet32v1_model.605.h5\n",
            "Epoch 606/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0954 - acc: 0.9748 - val_loss: 0.2714 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00606: val_acc did not improve from 0.91890\n",
            "Epoch 607/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0861 - acc: 0.9794 - val_loss: 0.2732 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00607: val_acc did not improve from 0.91890\n",
            "Epoch 608/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0963 - acc: 0.9719 - val_loss: 0.2698 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00608: val_acc did not improve from 0.91890\n",
            "Epoch 609/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0868 - acc: 0.9754 - val_loss: 0.2699 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00609: val_acc improved from 0.91890 to 0.92020, saving model to /content/saved_models/cifar10_ResNet32v1_model.609.h5\n",
            "Epoch 610/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0838 - acc: 0.9751 - val_loss: 0.2726 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00610: val_acc did not improve from 0.92020\n",
            "Epoch 611/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0864 - acc: 0.9755 - val_loss: 0.2710 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.92020\n",
            "Epoch 612/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0942 - acc: 0.9756 - val_loss: 0.2699 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00612: val_acc did not improve from 0.92020\n",
            "Epoch 613/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0847 - acc: 0.9774 - val_loss: 0.2692 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00613: val_acc improved from 0.92020 to 0.92130, saving model to /content/saved_models/cifar10_ResNet32v1_model.613.h5\n",
            "Epoch 614/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0877 - acc: 0.9760 - val_loss: 0.2689 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.92130\n",
            "Epoch 615/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0804 - acc: 0.9795 - val_loss: 0.2759 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.92130\n",
            "Epoch 616/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0834 - acc: 0.9775 - val_loss: 0.2664 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00616: val_acc improved from 0.92130 to 0.92140, saving model to /content/saved_models/cifar10_ResNet32v1_model.616.h5\n",
            "Epoch 617/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.0935 - acc: 0.9737 - val_loss: 0.2707 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.92140\n",
            "Epoch 618/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0859 - acc: 0.9770 - val_loss: 0.2683 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00618: val_acc did not improve from 0.92140\n",
            "Epoch 619/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0784 - acc: 0.9779 - val_loss: 0.2824 - val_acc: 0.9181\n",
            "\n",
            "Epoch 00619: val_acc did not improve from 0.92140\n",
            "Epoch 620/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0813 - acc: 0.9798 - val_loss: 0.2731 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.92140\n",
            "Epoch 621/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0714 - acc: 0.9839 - val_loss: 0.2684 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00621: val_acc improved from 0.92140 to 0.92200, saving model to /content/saved_models/cifar10_ResNet32v1_model.621.h5\n",
            "Epoch 622/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0816 - acc: 0.9796 - val_loss: 0.2733 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.92200\n",
            "Epoch 623/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0758 - acc: 0.9824 - val_loss: 0.2774 - val_acc: 0.9190\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.92200\n",
            "Epoch 624/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0782 - acc: 0.9808 - val_loss: 0.2713 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.92200\n",
            "Epoch 625/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0797 - acc: 0.9791 - val_loss: 0.2705 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.92200\n",
            "Epoch 626/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0787 - acc: 0.9789 - val_loss: 0.2704 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.92200\n",
            "Epoch 627/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0710 - acc: 0.9807 - val_loss: 0.2712 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00627: val_acc did not improve from 0.92200\n",
            "Epoch 628/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0763 - acc: 0.9812 - val_loss: 0.2695 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00628: val_acc did not improve from 0.92200\n",
            "Epoch 629/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.0759 - acc: 0.9780 - val_loss: 0.2792 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.92200\n",
            "Epoch 630/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0814 - acc: 0.9771 - val_loss: 0.2691 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00630: val_acc improved from 0.92200 to 0.92280, saving model to /content/saved_models/cifar10_ResNet32v1_model.630.h5\n",
            "Epoch 631/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0766 - acc: 0.9796 - val_loss: 0.2688 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00631: val_acc did not improve from 0.92280\n",
            "Epoch 632/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0768 - acc: 0.9779 - val_loss: 0.2705 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00632: val_acc did not improve from 0.92280\n",
            "Epoch 633/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0807 - acc: 0.9764 - val_loss: 0.2698 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.92280\n",
            "Epoch 634/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0691 - acc: 0.9821 - val_loss: 0.2705 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.92280\n",
            "Epoch 635/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.0710 - acc: 0.9817 - val_loss: 0.2765 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.92280\n",
            "Epoch 636/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.0736 - acc: 0.9807 - val_loss: 0.2729 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.92280\n",
            "Epoch 637/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0742 - acc: 0.9794 - val_loss: 0.2711 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00637: val_acc did not improve from 0.92280\n",
            "Epoch 638/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0652 - acc: 0.9846 - val_loss: 0.2734 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.92280\n",
            "Epoch 639/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0731 - acc: 0.9814 - val_loss: 0.2694 - val_acc: 0.9208\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.92280\n",
            "Epoch 640/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0708 - acc: 0.9825 - val_loss: 0.2694 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.92280\n",
            "Epoch 641/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0694 - acc: 0.9830 - val_loss: 0.2713 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.92280\n",
            "Epoch 642/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0705 - acc: 0.9827 - val_loss: 0.2738 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.92280\n",
            "Epoch 643/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0756 - acc: 0.9808 - val_loss: 0.2717 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.92280\n",
            "Epoch 644/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0663 - acc: 0.9840 - val_loss: 0.2730 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.92280\n",
            "Epoch 645/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0671 - acc: 0.9849 - val_loss: 0.2728 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00645: val_acc did not improve from 0.92280\n",
            "Epoch 646/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0696 - acc: 0.9826 - val_loss: 0.2789 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00646: val_acc did not improve from 0.92280\n",
            "Epoch 647/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0675 - acc: 0.9831 - val_loss: 0.2736 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00647: val_acc did not improve from 0.92280\n",
            "Epoch 648/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0771 - acc: 0.9785 - val_loss: 0.2740 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.92280\n",
            "Epoch 649/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0730 - acc: 0.9793 - val_loss: 0.2799 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.92280\n",
            "Epoch 650/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0625 - acc: 0.9832 - val_loss: 0.2716 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00650: val_acc improved from 0.92280 to 0.92300, saving model to /content/saved_models/cifar10_ResNet32v1_model.650.h5\n",
            "Epoch 651/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0662 - acc: 0.9829 - val_loss: 0.2741 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00651: val_acc did not improve from 0.92300\n",
            "Epoch 652/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0764 - acc: 0.9784 - val_loss: 0.2751 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00652: val_acc did not improve from 0.92300\n",
            "Epoch 653/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0713 - acc: 0.9817 - val_loss: 0.2759 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00653: val_acc did not improve from 0.92300\n",
            "Epoch 654/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0713 - acc: 0.9809 - val_loss: 0.2742 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00654: val_acc did not improve from 0.92300\n",
            "Epoch 655/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0634 - acc: 0.9830 - val_loss: 0.2769 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00655: val_acc did not improve from 0.92300\n",
            "Epoch 656/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0672 - acc: 0.9819 - val_loss: 0.2762 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00656: val_acc did not improve from 0.92300\n",
            "Epoch 657/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0643 - acc: 0.9821 - val_loss: 0.2760 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00657: val_acc did not improve from 0.92300\n",
            "Epoch 658/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0644 - acc: 0.9836 - val_loss: 0.2769 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00658: val_acc did not improve from 0.92300\n",
            "Epoch 659/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0632 - acc: 0.9840 - val_loss: 0.2776 - val_acc: 0.9208\n",
            "\n",
            "Epoch 00659: val_acc did not improve from 0.92300\n",
            "Epoch 660/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0698 - acc: 0.9832 - val_loss: 0.2791 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00660: val_acc did not improve from 0.92300\n",
            "Epoch 661/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0654 - acc: 0.9826 - val_loss: 0.2773 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00661: val_acc did not improve from 0.92300\n",
            "Epoch 662/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0614 - acc: 0.9853 - val_loss: 0.2800 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00662: val_acc did not improve from 0.92300\n",
            "Epoch 663/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0612 - acc: 0.9855 - val_loss: 0.2800 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00663: val_acc did not improve from 0.92300\n",
            "Epoch 664/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0639 - acc: 0.9831 - val_loss: 0.2793 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00664: val_acc did not improve from 0.92300\n",
            "Epoch 665/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.0620 - acc: 0.9853 - val_loss: 0.2784 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00665: val_acc did not improve from 0.92300\n",
            "Epoch 666/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0587 - acc: 0.9831 - val_loss: 0.2764 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00666: val_acc did not improve from 0.92300\n",
            "Epoch 667/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0635 - acc: 0.9852 - val_loss: 0.2841 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00667: val_acc did not improve from 0.92300\n",
            "Epoch 668/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0603 - acc: 0.9838 - val_loss: 0.2870 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00668: val_acc did not improve from 0.92300\n",
            "Epoch 669/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0596 - acc: 0.9840 - val_loss: 0.2812 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00669: val_acc did not improve from 0.92300\n",
            "Epoch 670/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.0595 - acc: 0.9851 - val_loss: 0.2775 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00670: val_acc did not improve from 0.92300\n",
            "Epoch 671/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0623 - acc: 0.9837 - val_loss: 0.2756 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00671: val_acc did not improve from 0.92300\n",
            "Epoch 672/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0620 - acc: 0.9873 - val_loss: 0.2785 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00672: val_acc did not improve from 0.92300\n",
            "Epoch 673/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0618 - acc: 0.9834 - val_loss: 0.2810 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00673: val_acc did not improve from 0.92300\n",
            "Epoch 674/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0581 - acc: 0.9853 - val_loss: 0.2824 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00674: val_acc did not improve from 0.92300\n",
            "Epoch 675/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0636 - acc: 0.9835 - val_loss: 0.2847 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00675: val_acc did not improve from 0.92300\n",
            "Epoch 676/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0560 - acc: 0.9861 - val_loss: 0.2819 - val_acc: 0.9208\n",
            "\n",
            "Epoch 00676: val_acc did not improve from 0.92300\n",
            "Epoch 677/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0622 - acc: 0.9855 - val_loss: 0.2781 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00677: val_acc did not improve from 0.92300\n",
            "Epoch 678/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.0602 - acc: 0.9841 - val_loss: 0.2790 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00678: val_acc did not improve from 0.92300\n",
            "Epoch 679/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0576 - acc: 0.9875 - val_loss: 0.2840 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00679: val_acc did not improve from 0.92300\n",
            "Epoch 680/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0633 - acc: 0.9840 - val_loss: 0.2822 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00680: val_acc did not improve from 0.92300\n",
            "Epoch 681/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0606 - acc: 0.9834 - val_loss: 0.2793 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00681: val_acc did not improve from 0.92300\n",
            "Epoch 682/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0580 - acc: 0.9862 - val_loss: 0.2872 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00682: val_acc did not improve from 0.92300\n",
            "Epoch 683/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0622 - acc: 0.9844 - val_loss: 0.2835 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00683: val_acc did not improve from 0.92300\n",
            "Epoch 684/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0607 - acc: 0.9854 - val_loss: 0.2871 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00684: val_acc did not improve from 0.92300\n",
            "Epoch 685/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.0676 - acc: 0.9838 - val_loss: 0.2836 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00685: val_acc did not improve from 0.92300\n",
            "Epoch 686/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0574 - acc: 0.9883 - val_loss: 0.2820 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00686: val_acc did not improve from 0.92300\n",
            "Epoch 687/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0599 - acc: 0.9860 - val_loss: 0.2826 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00687: val_acc did not improve from 0.92300\n",
            "Epoch 688/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0625 - acc: 0.9848 - val_loss: 0.2833 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00688: val_acc did not improve from 0.92300\n",
            "Epoch 689/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0609 - acc: 0.9873 - val_loss: 0.2861 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00689: val_acc did not improve from 0.92300\n",
            "Epoch 690/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0563 - acc: 0.9875 - val_loss: 0.2826 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00690: val_acc did not improve from 0.92300\n",
            "Epoch 691/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0607 - acc: 0.9843 - val_loss: 0.2906 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00691: val_acc did not improve from 0.92300\n",
            "Epoch 692/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0553 - acc: 0.9884 - val_loss: 0.2832 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00692: val_acc did not improve from 0.92300\n",
            "Epoch 693/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0571 - acc: 0.9864 - val_loss: 0.2907 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00693: val_acc did not improve from 0.92300\n",
            "Epoch 694/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0539 - acc: 0.9872 - val_loss: 0.2851 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00694: val_acc did not improve from 0.92300\n",
            "Epoch 695/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0627 - acc: 0.9844 - val_loss: 0.2833 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00695: val_acc did not improve from 0.92300\n",
            "Epoch 696/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0603 - acc: 0.9860 - val_loss: 0.2815 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00696: val_acc improved from 0.92300 to 0.92350, saving model to /content/saved_models/cifar10_ResNet32v1_model.696.h5\n",
            "Epoch 697/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0585 - acc: 0.9845 - val_loss: 0.2815 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00697: val_acc did not improve from 0.92350\n",
            "Epoch 698/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0575 - acc: 0.9860 - val_loss: 0.2822 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00698: val_acc did not improve from 0.92350\n",
            "Epoch 699/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0599 - acc: 0.9855 - val_loss: 0.2859 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00699: val_acc did not improve from 0.92350\n",
            "Epoch 700/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0541 - acc: 0.9878 - val_loss: 0.2846 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00700: val_acc did not improve from 0.92350\n",
            "Epoch 701/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0580 - acc: 0.9861 - val_loss: 0.2863 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00701: val_acc did not improve from 0.92350\n",
            "Epoch 702/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0566 - acc: 0.9867 - val_loss: 0.2866 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00702: val_acc did not improve from 0.92350\n",
            "Epoch 703/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0582 - acc: 0.9851 - val_loss: 0.2806 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00703: val_acc did not improve from 0.92350\n",
            "Epoch 704/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0587 - acc: 0.9860 - val_loss: 0.2831 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00704: val_acc did not improve from 0.92350\n",
            "Epoch 705/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0568 - acc: 0.9881 - val_loss: 0.2853 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00705: val_acc did not improve from 0.92350\n",
            "Epoch 706/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0588 - acc: 0.9863 - val_loss: 0.2822 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00706: val_acc did not improve from 0.92350\n",
            "Epoch 707/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0554 - acc: 0.9867 - val_loss: 0.2864 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00707: val_acc did not improve from 0.92350\n",
            "Epoch 708/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0570 - acc: 0.9862 - val_loss: 0.2869 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00708: val_acc did not improve from 0.92350\n",
            "Epoch 709/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0517 - acc: 0.9883 - val_loss: 0.2830 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00709: val_acc did not improve from 0.92350\n",
            "Epoch 710/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0534 - acc: 0.9876 - val_loss: 0.2849 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00710: val_acc did not improve from 0.92350\n",
            "Epoch 711/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0563 - acc: 0.9854 - val_loss: 0.2809 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00711: val_acc did not improve from 0.92350\n",
            "Epoch 712/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0507 - acc: 0.9889 - val_loss: 0.2878 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00712: val_acc did not improve from 0.92350\n",
            "Epoch 713/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0570 - acc: 0.9874 - val_loss: 0.2861 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00713: val_acc did not improve from 0.92350\n",
            "Epoch 714/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0587 - acc: 0.9851 - val_loss: 0.2828 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00714: val_acc did not improve from 0.92350\n",
            "Epoch 715/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0544 - acc: 0.9869 - val_loss: 0.2839 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00715: val_acc did not improve from 0.92350\n",
            "Epoch 716/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0579 - acc: 0.9862 - val_loss: 0.2961 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00716: val_acc did not improve from 0.92350\n",
            "Epoch 717/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0579 - acc: 0.9864 - val_loss: 0.2885 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00717: val_acc did not improve from 0.92350\n",
            "Epoch 718/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0517 - acc: 0.9877 - val_loss: 0.2846 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00718: val_acc did not improve from 0.92350\n",
            "Epoch 719/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0526 - acc: 0.9865 - val_loss: 0.2886 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00719: val_acc did not improve from 0.92350\n",
            "Epoch 720/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0553 - acc: 0.9871 - val_loss: 0.2890 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00720: val_acc did not improve from 0.92350\n",
            "Epoch 721/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0577 - acc: 0.9849 - val_loss: 0.2942 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00721: val_acc did not improve from 0.92350\n",
            "Epoch 722/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0568 - acc: 0.9838 - val_loss: 0.2874 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00722: val_acc did not improve from 0.92350\n",
            "Epoch 723/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0536 - acc: 0.9880 - val_loss: 0.2854 - val_acc: 0.9183\n",
            "\n",
            "Epoch 00723: val_acc did not improve from 0.92350\n",
            "Epoch 724/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0565 - acc: 0.9865 - val_loss: 0.2872 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00724: val_acc did not improve from 0.92350\n",
            "Epoch 725/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0545 - acc: 0.9862 - val_loss: 0.2959 - val_acc: 0.9184\n",
            "\n",
            "Epoch 00725: val_acc did not improve from 0.92350\n",
            "Epoch 726/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0546 - acc: 0.9860 - val_loss: 0.2919 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00726: val_acc did not improve from 0.92350\n",
            "Epoch 727/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0524 - acc: 0.9889 - val_loss: 0.2903 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00727: val_acc did not improve from 0.92350\n",
            "Epoch 728/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0560 - acc: 0.9851 - val_loss: 0.2851 - val_acc: 0.9208\n",
            "\n",
            "Epoch 00728: val_acc did not improve from 0.92350\n",
            "Epoch 729/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0555 - acc: 0.9874 - val_loss: 0.2888 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00729: val_acc did not improve from 0.92350\n",
            "Epoch 730/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0566 - acc: 0.9865 - val_loss: 0.2880 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00730: val_acc did not improve from 0.92350\n",
            "Epoch 731/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0524 - acc: 0.9890 - val_loss: 0.2905 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00731: val_acc did not improve from 0.92350\n",
            "Epoch 732/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0576 - acc: 0.9861 - val_loss: 0.2875 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00732: val_acc did not improve from 0.92350\n",
            "Epoch 733/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0465 - acc: 0.9893 - val_loss: 0.2872 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00733: val_acc did not improve from 0.92350\n",
            "Epoch 734/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0518 - acc: 0.9885 - val_loss: 0.2933 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00734: val_acc did not improve from 0.92350\n",
            "Epoch 735/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0524 - acc: 0.9858 - val_loss: 0.2879 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00735: val_acc did not improve from 0.92350\n",
            "Epoch 736/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0504 - acc: 0.9896 - val_loss: 0.2929 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00736: val_acc did not improve from 0.92350\n",
            "Epoch 737/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0515 - acc: 0.9870 - val_loss: 0.2990 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00737: val_acc did not improve from 0.92350\n",
            "Epoch 738/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0512 - acc: 0.9881 - val_loss: 0.2832 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00738: val_acc did not improve from 0.92350\n",
            "Epoch 739/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0498 - acc: 0.9875 - val_loss: 0.2896 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00739: val_acc did not improve from 0.92350\n",
            "Epoch 740/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0540 - acc: 0.9851 - val_loss: 0.2867 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00740: val_acc did not improve from 0.92350\n",
            "Epoch 741/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0494 - acc: 0.9880 - val_loss: 0.2897 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00741: val_acc did not improve from 0.92350\n",
            "Epoch 742/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0519 - acc: 0.9869 - val_loss: 0.2878 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00742: val_acc did not improve from 0.92350\n",
            "Epoch 743/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0502 - acc: 0.9892 - val_loss: 0.2891 - val_acc: 0.9187\n",
            "\n",
            "Epoch 00743: val_acc did not improve from 0.92350\n",
            "Epoch 744/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0618 - acc: 0.9837 - val_loss: 0.2926 - val_acc: 0.9188\n",
            "\n",
            "Epoch 00744: val_acc did not improve from 0.92350\n",
            "Epoch 745/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0514 - acc: 0.9878 - val_loss: 0.2958 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00745: val_acc did not improve from 0.92350\n",
            "Epoch 746/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0507 - acc: 0.9890 - val_loss: 0.2901 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00746: val_acc did not improve from 0.92350\n",
            "Epoch 747/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0500 - acc: 0.9874 - val_loss: 0.2889 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00747: val_acc did not improve from 0.92350\n",
            "Epoch 748/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0523 - acc: 0.9867 - val_loss: 0.2938 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00748: val_acc did not improve from 0.92350\n",
            "Epoch 749/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0477 - acc: 0.9905 - val_loss: 0.2977 - val_acc: 0.9188\n",
            "\n",
            "Epoch 00749: val_acc did not improve from 0.92350\n",
            "Epoch 750/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0507 - acc: 0.9878 - val_loss: 0.2918 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00750: val_acc did not improve from 0.92350\n",
            "Epoch 751/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0459 - acc: 0.9897 - val_loss: 0.2856 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00751: val_acc did not improve from 0.92350\n",
            "Epoch 752/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0527 - acc: 0.9859 - val_loss: 0.2929 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00752: val_acc did not improve from 0.92350\n",
            "Epoch 753/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0513 - acc: 0.9874 - val_loss: 0.2991 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00753: val_acc did not improve from 0.92350\n",
            "Epoch 754/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0519 - acc: 0.9876 - val_loss: 0.2898 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00754: val_acc did not improve from 0.92350\n",
            "Epoch 755/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0522 - acc: 0.9876 - val_loss: 0.2923 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00755: val_acc did not improve from 0.92350\n",
            "Epoch 756/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0533 - acc: 0.9869 - val_loss: 0.2979 - val_acc: 0.9178\n",
            "\n",
            "Epoch 00756: val_acc did not improve from 0.92350\n",
            "Epoch 757/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0465 - acc: 0.9897 - val_loss: 0.2935 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00757: val_acc did not improve from 0.92350\n",
            "Epoch 758/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0465 - acc: 0.9894 - val_loss: 0.2935 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00758: val_acc did not improve from 0.92350\n",
            "Epoch 759/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0495 - acc: 0.9865 - val_loss: 0.2958 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00759: val_acc did not improve from 0.92350\n",
            "Epoch 760/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0513 - acc: 0.9879 - val_loss: 0.3015 - val_acc: 0.9185\n",
            "\n",
            "Epoch 00760: val_acc did not improve from 0.92350\n",
            "Epoch 761/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0530 - acc: 0.9877 - val_loss: 0.2943 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00761: val_acc did not improve from 0.92350\n",
            "Epoch 762/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0511 - acc: 0.9884 - val_loss: 0.2931 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00762: val_acc did not improve from 0.92350\n",
            "Epoch 763/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0507 - acc: 0.9873 - val_loss: 0.2902 - val_acc: 0.9190\n",
            "\n",
            "Epoch 00763: val_acc did not improve from 0.92350\n",
            "Epoch 764/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0452 - acc: 0.9905 - val_loss: 0.2969 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00764: val_acc did not improve from 0.92350\n",
            "Epoch 765/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0488 - acc: 0.9892 - val_loss: 0.3045 - val_acc: 0.9175\n",
            "\n",
            "Epoch 00765: val_acc did not improve from 0.92350\n",
            "Epoch 766/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0495 - acc: 0.9875 - val_loss: 0.2919 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00766: val_acc did not improve from 0.92350\n",
            "Epoch 767/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0522 - acc: 0.9869 - val_loss: 0.2924 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00767: val_acc did not improve from 0.92350\n",
            "Epoch 768/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0560 - acc: 0.9865 - val_loss: 0.3009 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00768: val_acc did not improve from 0.92350\n",
            "Epoch 769/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0502 - acc: 0.9891 - val_loss: 0.3038 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00769: val_acc did not improve from 0.92350\n",
            "Epoch 770/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0474 - acc: 0.9892 - val_loss: 0.2950 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00770: val_acc did not improve from 0.92350\n",
            "Epoch 771/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0460 - acc: 0.9907 - val_loss: 0.3003 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00771: val_acc did not improve from 0.92350\n",
            "Epoch 772/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0477 - acc: 0.9881 - val_loss: 0.3042 - val_acc: 0.9188\n",
            "\n",
            "Epoch 00772: val_acc did not improve from 0.92350\n",
            "Epoch 773/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0519 - acc: 0.9871 - val_loss: 0.3059 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00773: val_acc did not improve from 0.92350\n",
            "Epoch 774/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0486 - acc: 0.9889 - val_loss: 0.2992 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00774: val_acc did not improve from 0.92350\n",
            "Epoch 775/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0471 - acc: 0.9891 - val_loss: 0.2972 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00775: val_acc did not improve from 0.92350\n",
            "Epoch 776/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0498 - acc: 0.9883 - val_loss: 0.2943 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00776: val_acc did not improve from 0.92350\n",
            "Epoch 777/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0473 - acc: 0.9893 - val_loss: 0.2922 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00777: val_acc did not improve from 0.92350\n",
            "Epoch 778/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0460 - acc: 0.9907 - val_loss: 0.2952 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00778: val_acc did not improve from 0.92350\n",
            "Epoch 779/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0442 - acc: 0.9915 - val_loss: 0.3029 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00779: val_acc did not improve from 0.92350\n",
            "Epoch 780/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0447 - acc: 0.9918 - val_loss: 0.2941 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00780: val_acc did not improve from 0.92350\n",
            "Epoch 781/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0455 - acc: 0.9905 - val_loss: 0.3008 - val_acc: 0.9187\n",
            "\n",
            "Epoch 00781: val_acc did not improve from 0.92350\n",
            "Epoch 782/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0499 - acc: 0.9864 - val_loss: 0.2962 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00782: val_acc did not improve from 0.92350\n",
            "Epoch 783/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0490 - acc: 0.9890 - val_loss: 0.2985 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00783: val_acc did not improve from 0.92350\n",
            "Epoch 784/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0430 - acc: 0.9895 - val_loss: 0.3021 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00784: val_acc did not improve from 0.92350\n",
            "Epoch 785/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0460 - acc: 0.9899 - val_loss: 0.3022 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00785: val_acc did not improve from 0.92350\n",
            "Epoch 786/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0527 - acc: 0.9884 - val_loss: 0.2967 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00786: val_acc did not improve from 0.92350\n",
            "Epoch 787/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0488 - acc: 0.9886 - val_loss: 0.2969 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00787: val_acc did not improve from 0.92350\n",
            "Epoch 788/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0446 - acc: 0.9903 - val_loss: 0.3041 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00788: val_acc did not improve from 0.92350\n",
            "Epoch 789/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0498 - acc: 0.9882 - val_loss: 0.2976 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00789: val_acc did not improve from 0.92350\n",
            "Epoch 790/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0535 - acc: 0.9876 - val_loss: 0.3051 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00790: val_acc did not improve from 0.92350\n",
            "Epoch 791/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0436 - acc: 0.9907 - val_loss: 0.2989 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00791: val_acc did not improve from 0.92350\n",
            "Epoch 792/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0451 - acc: 0.9894 - val_loss: 0.2973 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00792: val_acc did not improve from 0.92350\n",
            "Epoch 793/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0494 - acc: 0.9881 - val_loss: 0.2981 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00793: val_acc did not improve from 0.92350\n",
            "Epoch 794/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0445 - acc: 0.9910 - val_loss: 0.2991 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00794: val_acc did not improve from 0.92350\n",
            "Epoch 795/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0473 - acc: 0.9884 - val_loss: 0.2976 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00795: val_acc did not improve from 0.92350\n",
            "Epoch 796/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0466 - acc: 0.9893 - val_loss: 0.2961 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00796: val_acc did not improve from 0.92350\n",
            "Epoch 797/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0482 - acc: 0.9875 - val_loss: 0.2959 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00797: val_acc did not improve from 0.92350\n",
            "Epoch 798/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0449 - acc: 0.9901 - val_loss: 0.2967 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00798: val_acc did not improve from 0.92350\n",
            "Epoch 799/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0457 - acc: 0.9906 - val_loss: 0.2950 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00799: val_acc did not improve from 0.92350\n",
            "Epoch 800/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0457 - acc: 0.9899 - val_loss: 0.3040 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00800: val_acc did not improve from 0.92350\n",
            "Epoch 801/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0464 - acc: 0.9894 - val_loss: 0.3003 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00801: val_acc did not improve from 0.92350\n",
            "Epoch 802/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0492 - acc: 0.9887 - val_loss: 0.2953 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00802: val_acc did not improve from 0.92350\n",
            "Epoch 803/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0467 - acc: 0.9904 - val_loss: 0.2927 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00803: val_acc did not improve from 0.92350\n",
            "Epoch 804/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0387 - acc: 0.9930 - val_loss: 0.2915 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00804: val_acc did not improve from 0.92350\n",
            "Epoch 805/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0492 - acc: 0.9883 - val_loss: 0.2912 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00805: val_acc did not improve from 0.92350\n",
            "Epoch 806/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0495 - acc: 0.9882 - val_loss: 0.2904 - val_acc: 0.9209\n",
            "\n",
            "Epoch 00806: val_acc did not improve from 0.92350\n",
            "Epoch 807/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0497 - acc: 0.9881 - val_loss: 0.2887 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00807: val_acc did not improve from 0.92350\n",
            "Epoch 808/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0473 - acc: 0.9883 - val_loss: 0.2887 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00808: val_acc did not improve from 0.92350\n",
            "Epoch 809/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0455 - acc: 0.9896 - val_loss: 0.2882 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00809: val_acc did not improve from 0.92350\n",
            "Epoch 810/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0424 - acc: 0.9908 - val_loss: 0.2886 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00810: val_acc did not improve from 0.92350\n",
            "Epoch 811/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0445 - acc: 0.9908 - val_loss: 0.2884 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00811: val_acc did not improve from 0.92350\n",
            "Epoch 812/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0478 - acc: 0.9885 - val_loss: 0.2878 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00812: val_acc did not improve from 0.92350\n",
            "Epoch 813/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0478 - acc: 0.9899 - val_loss: 0.2873 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00813: val_acc did not improve from 0.92350\n",
            "Epoch 814/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0452 - acc: 0.9910 - val_loss: 0.2871 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00814: val_acc did not improve from 0.92350\n",
            "Epoch 815/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0448 - acc: 0.9912 - val_loss: 0.2870 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00815: val_acc did not improve from 0.92350\n",
            "Epoch 816/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0441 - acc: 0.9907 - val_loss: 0.2865 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00816: val_acc did not improve from 0.92350\n",
            "Epoch 817/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0501 - acc: 0.9905 - val_loss: 0.2854 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00817: val_acc did not improve from 0.92350\n",
            "Epoch 818/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0490 - acc: 0.9890 - val_loss: 0.2860 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00818: val_acc did not improve from 0.92350\n",
            "Epoch 819/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0436 - acc: 0.9923 - val_loss: 0.2861 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00819: val_acc did not improve from 0.92350\n",
            "Epoch 820/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0475 - acc: 0.9889 - val_loss: 0.2868 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00820: val_acc did not improve from 0.92350\n",
            "Epoch 821/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0443 - acc: 0.9910 - val_loss: 0.2867 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00821: val_acc did not improve from 0.92350\n",
            "Epoch 822/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0475 - acc: 0.9908 - val_loss: 0.2863 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00822: val_acc did not improve from 0.92350\n",
            "Epoch 823/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0473 - acc: 0.9895 - val_loss: 0.2863 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00823: val_acc did not improve from 0.92350\n",
            "Epoch 824/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0457 - acc: 0.9899 - val_loss: 0.2869 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00824: val_acc did not improve from 0.92350\n",
            "Epoch 825/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0489 - acc: 0.9884 - val_loss: 0.2876 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00825: val_acc did not improve from 0.92350\n",
            "Epoch 826/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0465 - acc: 0.9898 - val_loss: 0.2890 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00826: val_acc did not improve from 0.92350\n",
            "Epoch 827/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0428 - acc: 0.9918 - val_loss: 0.2881 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00827: val_acc did not improve from 0.92350\n",
            "Epoch 828/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0432 - acc: 0.9924 - val_loss: 0.2879 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00828: val_acc did not improve from 0.92350\n",
            "Epoch 829/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0424 - acc: 0.9920 - val_loss: 0.2879 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00829: val_acc did not improve from 0.92350\n",
            "Epoch 830/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0422 - acc: 0.9924 - val_loss: 0.2879 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00830: val_acc did not improve from 0.92350\n",
            "Epoch 831/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0452 - acc: 0.9899 - val_loss: 0.2874 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00831: val_acc did not improve from 0.92350\n",
            "Epoch 832/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0457 - acc: 0.9901 - val_loss: 0.2869 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00832: val_acc did not improve from 0.92350\n",
            "Epoch 833/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0447 - acc: 0.9910 - val_loss: 0.2876 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00833: val_acc did not improve from 0.92350\n",
            "Epoch 834/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0454 - acc: 0.9895 - val_loss: 0.2872 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00834: val_acc did not improve from 0.92350\n",
            "Epoch 835/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0461 - acc: 0.9900 - val_loss: 0.2879 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00835: val_acc did not improve from 0.92350\n",
            "Epoch 836/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0493 - acc: 0.9878 - val_loss: 0.2886 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00836: val_acc did not improve from 0.92350\n",
            "Epoch 837/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0447 - acc: 0.9903 - val_loss: 0.2883 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00837: val_acc did not improve from 0.92350\n",
            "Epoch 838/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0427 - acc: 0.9915 - val_loss: 0.2879 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00838: val_acc did not improve from 0.92350\n",
            "Epoch 839/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0476 - acc: 0.9878 - val_loss: 0.2870 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00839: val_acc did not improve from 0.92350\n",
            "Epoch 840/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0470 - acc: 0.9878 - val_loss: 0.2871 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00840: val_acc did not improve from 0.92350\n",
            "Epoch 841/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0461 - acc: 0.9891 - val_loss: 0.2867 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00841: val_acc did not improve from 0.92350\n",
            "Epoch 842/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0444 - acc: 0.9903 - val_loss: 0.2878 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00842: val_acc did not improve from 0.92350\n",
            "Epoch 843/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0433 - acc: 0.9902 - val_loss: 0.2866 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00843: val_acc did not improve from 0.92350\n",
            "Epoch 844/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0401 - acc: 0.9929 - val_loss: 0.2861 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00844: val_acc did not improve from 0.92350\n",
            "Epoch 845/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0456 - acc: 0.9907 - val_loss: 0.2867 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00845: val_acc did not improve from 0.92350\n",
            "Epoch 846/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0453 - acc: 0.9906 - val_loss: 0.2880 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00846: val_acc did not improve from 0.92350\n",
            "Epoch 847/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0419 - acc: 0.9928 - val_loss: 0.2873 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00847: val_acc did not improve from 0.92350\n",
            "Epoch 848/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0449 - acc: 0.9919 - val_loss: 0.2870 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00848: val_acc did not improve from 0.92350\n",
            "Epoch 849/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0439 - acc: 0.9905 - val_loss: 0.2866 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00849: val_acc did not improve from 0.92350\n",
            "Epoch 850/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0434 - acc: 0.9915 - val_loss: 0.2866 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00850: val_acc did not improve from 0.92350\n",
            "Epoch 851/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0421 - acc: 0.9911 - val_loss: 0.2859 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00851: val_acc did not improve from 0.92350\n",
            "Epoch 852/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0408 - acc: 0.9929 - val_loss: 0.2873 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00852: val_acc did not improve from 0.92350\n",
            "Epoch 853/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0453 - acc: 0.9905 - val_loss: 0.2876 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00853: val_acc did not improve from 0.92350\n",
            "Epoch 854/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0394 - acc: 0.9932 - val_loss: 0.2868 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00854: val_acc did not improve from 0.92350\n",
            "Epoch 855/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0448 - acc: 0.9901 - val_loss: 0.2880 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00855: val_acc did not improve from 0.92350\n",
            "Epoch 856/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0471 - acc: 0.9928 - val_loss: 0.2874 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00856: val_acc did not improve from 0.92350\n",
            "Epoch 857/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0431 - acc: 0.9922 - val_loss: 0.2868 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00857: val_acc did not improve from 0.92350\n",
            "Epoch 858/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0409 - acc: 0.9915 - val_loss: 0.2867 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00858: val_acc did not improve from 0.92350\n",
            "Epoch 859/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0417 - acc: 0.9923 - val_loss: 0.2858 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00859: val_acc did not improve from 0.92350\n",
            "Epoch 860/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0448 - acc: 0.9899 - val_loss: 0.2864 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00860: val_acc did not improve from 0.92350\n",
            "Epoch 861/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0445 - acc: 0.9909 - val_loss: 0.2863 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00861: val_acc did not improve from 0.92350\n",
            "Epoch 862/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0439 - acc: 0.9915 - val_loss: 0.2868 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00862: val_acc did not improve from 0.92350\n",
            "Epoch 863/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0496 - acc: 0.9862 - val_loss: 0.2869 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00863: val_acc did not improve from 0.92350\n",
            "Epoch 864/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0436 - acc: 0.9922 - val_loss: 0.2865 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00864: val_acc did not improve from 0.92350\n",
            "Epoch 865/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0444 - acc: 0.9901 - val_loss: 0.2863 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00865: val_acc did not improve from 0.92350\n",
            "Epoch 866/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0430 - acc: 0.9912 - val_loss: 0.2861 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00866: val_acc did not improve from 0.92350\n",
            "Epoch 867/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0468 - acc: 0.9891 - val_loss: 0.2867 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00867: val_acc did not improve from 0.92350\n",
            "Epoch 868/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0436 - acc: 0.9928 - val_loss: 0.2868 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00868: val_acc did not improve from 0.92350\n",
            "Epoch 869/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0407 - acc: 0.9931 - val_loss: 0.2871 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00869: val_acc did not improve from 0.92350\n",
            "Epoch 870/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0453 - acc: 0.9902 - val_loss: 0.2875 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00870: val_acc did not improve from 0.92350\n",
            "Epoch 871/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0435 - acc: 0.9899 - val_loss: 0.2878 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00871: val_acc did not improve from 0.92350\n",
            "Epoch 872/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0425 - acc: 0.9910 - val_loss: 0.2859 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00872: val_acc did not improve from 0.92350\n",
            "Epoch 873/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0434 - acc: 0.9908 - val_loss: 0.2866 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00873: val_acc did not improve from 0.92350\n",
            "Epoch 874/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0427 - acc: 0.9918 - val_loss: 0.2866 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00874: val_acc did not improve from 0.92350\n",
            "Epoch 875/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0458 - acc: 0.9904 - val_loss: 0.2872 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00875: val_acc did not improve from 0.92350\n",
            "Epoch 876/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0417 - acc: 0.9909 - val_loss: 0.2872 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00876: val_acc did not improve from 0.92350\n",
            "Epoch 877/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0443 - acc: 0.9908 - val_loss: 0.2875 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00877: val_acc did not improve from 0.92350\n",
            "Epoch 878/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0438 - acc: 0.9908 - val_loss: 0.2866 - val_acc: 0.9231\n",
            "\n",
            "Epoch 00878: val_acc did not improve from 0.92350\n",
            "Epoch 879/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0439 - acc: 0.9925 - val_loss: 0.2857 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00879: val_acc did not improve from 0.92350\n",
            "Epoch 880/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0440 - acc: 0.9911 - val_loss: 0.2866 - val_acc: 0.9231\n",
            "\n",
            "Epoch 00880: val_acc did not improve from 0.92350\n",
            "Epoch 881/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0446 - acc: 0.9908 - val_loss: 0.2854 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00881: val_acc did not improve from 0.92350\n",
            "Epoch 882/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0399 - acc: 0.9930 - val_loss: 0.2870 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00882: val_acc did not improve from 0.92350\n",
            "Epoch 883/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0383 - acc: 0.9936 - val_loss: 0.2868 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00883: val_acc did not improve from 0.92350\n",
            "Epoch 884/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0465 - acc: 0.9886 - val_loss: 0.2861 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00884: val_acc did not improve from 0.92350\n",
            "Epoch 885/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0412 - acc: 0.9909 - val_loss: 0.2866 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00885: val_acc did not improve from 0.92350\n",
            "Epoch 886/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0426 - acc: 0.9927 - val_loss: 0.2866 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00886: val_acc did not improve from 0.92350\n",
            "Epoch 887/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0424 - acc: 0.9925 - val_loss: 0.2865 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00887: val_acc did not improve from 0.92350\n",
            "Epoch 888/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0431 - acc: 0.9928 - val_loss: 0.2866 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00888: val_acc did not improve from 0.92350\n",
            "Epoch 889/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0411 - acc: 0.9930 - val_loss: 0.2858 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00889: val_acc did not improve from 0.92350\n",
            "Epoch 890/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0422 - acc: 0.9925 - val_loss: 0.2867 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00890: val_acc did not improve from 0.92350\n",
            "Epoch 891/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0421 - acc: 0.9913 - val_loss: 0.2858 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00891: val_acc did not improve from 0.92350\n",
            "Epoch 892/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0421 - acc: 0.9916 - val_loss: 0.2865 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00892: val_acc did not improve from 0.92350\n",
            "Epoch 893/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0447 - acc: 0.9903 - val_loss: 0.2866 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00893: val_acc did not improve from 0.92350\n",
            "Epoch 894/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0477 - acc: 0.9878 - val_loss: 0.2863 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00894: val_acc did not improve from 0.92350\n",
            "Epoch 895/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0463 - acc: 0.9901 - val_loss: 0.2857 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00895: val_acc did not improve from 0.92350\n",
            "Epoch 896/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0392 - acc: 0.9936 - val_loss: 0.2855 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00896: val_acc did not improve from 0.92350\n",
            "Epoch 897/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0419 - acc: 0.9907 - val_loss: 0.2863 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00897: val_acc did not improve from 0.92350\n",
            "Epoch 898/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0397 - acc: 0.9921 - val_loss: 0.2862 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00898: val_acc did not improve from 0.92350\n",
            "Epoch 899/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0418 - acc: 0.9918 - val_loss: 0.2860 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00899: val_acc did not improve from 0.92350\n",
            "Epoch 900/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0428 - acc: 0.9901 - val_loss: 0.2862 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00900: val_acc did not improve from 0.92350\n",
            "Epoch 901/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0454 - acc: 0.9902 - val_loss: 0.2863 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00901: val_acc did not improve from 0.92350\n",
            "Epoch 902/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0446 - acc: 0.9896 - val_loss: 0.2865 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00902: val_acc did not improve from 0.92350\n",
            "Epoch 903/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0436 - acc: 0.9909 - val_loss: 0.2858 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00903: val_acc did not improve from 0.92350\n",
            "Epoch 904/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0423 - acc: 0.9902 - val_loss: 0.2857 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00904: val_acc did not improve from 0.92350\n",
            "Epoch 905/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0466 - acc: 0.9885 - val_loss: 0.2864 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00905: val_acc did not improve from 0.92350\n",
            "Epoch 906/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0487 - acc: 0.9893 - val_loss: 0.2860 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00906: val_acc did not improve from 0.92350\n",
            "Epoch 907/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0372 - acc: 0.9930 - val_loss: 0.2862 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00907: val_acc did not improve from 0.92350\n",
            "Epoch 908/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0429 - acc: 0.9931 - val_loss: 0.2861 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00908: val_acc did not improve from 0.92350\n",
            "Epoch 909/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0404 - acc: 0.9928 - val_loss: 0.2858 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00909: val_acc did not improve from 0.92350\n",
            "Epoch 910/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0413 - acc: 0.9915 - val_loss: 0.2856 - val_acc: 0.9234\n",
            "\n",
            "Epoch 00910: val_acc did not improve from 0.92350\n",
            "Epoch 911/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0427 - acc: 0.9908 - val_loss: 0.2855 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00911: val_acc did not improve from 0.92350\n",
            "Epoch 912/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0390 - acc: 0.9934 - val_loss: 0.2862 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00912: val_acc did not improve from 0.92350\n",
            "Epoch 913/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0433 - acc: 0.9920 - val_loss: 0.2869 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00913: val_acc did not improve from 0.92350\n",
            "Epoch 914/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0395 - acc: 0.9924 - val_loss: 0.2862 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00914: val_acc did not improve from 0.92350\n",
            "Epoch 915/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0432 - acc: 0.9913 - val_loss: 0.2866 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00915: val_acc did not improve from 0.92350\n",
            "Epoch 916/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0439 - acc: 0.9918 - val_loss: 0.2854 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00916: val_acc did not improve from 0.92350\n",
            "Epoch 917/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0478 - acc: 0.9893 - val_loss: 0.2862 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00917: val_acc did not improve from 0.92350\n",
            "Epoch 918/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0432 - acc: 0.9911 - val_loss: 0.2862 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00918: val_acc did not improve from 0.92350\n",
            "Epoch 919/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0428 - acc: 0.9920 - val_loss: 0.2861 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00919: val_acc did not improve from 0.92350\n",
            "Epoch 920/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0391 - acc: 0.9934 - val_loss: 0.2859 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00920: val_acc did not improve from 0.92350\n",
            "Epoch 921/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0428 - acc: 0.9895 - val_loss: 0.2864 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00921: val_acc did not improve from 0.92350\n",
            "Epoch 922/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0388 - acc: 0.9929 - val_loss: 0.2867 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00922: val_acc did not improve from 0.92350\n",
            "Epoch 923/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0441 - acc: 0.9911 - val_loss: 0.2860 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00923: val_acc did not improve from 0.92350\n",
            "Epoch 924/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0423 - acc: 0.9915 - val_loss: 0.2867 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00924: val_acc did not improve from 0.92350\n",
            "Epoch 925/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0411 - acc: 0.9919 - val_loss: 0.2868 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00925: val_acc did not improve from 0.92350\n",
            "Epoch 926/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0457 - acc: 0.9893 - val_loss: 0.2871 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00926: val_acc did not improve from 0.92350\n",
            "Epoch 927/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0430 - acc: 0.9913 - val_loss: 0.2866 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00927: val_acc did not improve from 0.92350\n",
            "Epoch 928/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0437 - acc: 0.9902 - val_loss: 0.2863 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00928: val_acc did not improve from 0.92350\n",
            "Epoch 929/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0416 - acc: 0.9902 - val_loss: 0.2860 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00929: val_acc did not improve from 0.92350\n",
            "Epoch 930/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0458 - acc: 0.9903 - val_loss: 0.2864 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00930: val_acc did not improve from 0.92350\n",
            "Epoch 931/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0408 - acc: 0.9922 - val_loss: 0.2862 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00931: val_acc did not improve from 0.92350\n",
            "Epoch 932/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0451 - acc: 0.9892 - val_loss: 0.2862 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00932: val_acc did not improve from 0.92350\n",
            "Epoch 933/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0440 - acc: 0.9906 - val_loss: 0.2859 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00933: val_acc did not improve from 0.92350\n",
            "Epoch 934/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0438 - acc: 0.9902 - val_loss: 0.2859 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00934: val_acc did not improve from 0.92350\n",
            "Epoch 935/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0426 - acc: 0.9896 - val_loss: 0.2865 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00935: val_acc did not improve from 0.92350\n",
            "Epoch 936/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0419 - acc: 0.9934 - val_loss: 0.2870 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00936: val_acc did not improve from 0.92350\n",
            "Epoch 937/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0425 - acc: 0.9928 - val_loss: 0.2864 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00937: val_acc did not improve from 0.92350\n",
            "Epoch 938/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0408 - acc: 0.9930 - val_loss: 0.2871 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00938: val_acc did not improve from 0.92350\n",
            "Epoch 939/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0432 - acc: 0.9904 - val_loss: 0.2871 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00939: val_acc did not improve from 0.92350\n",
            "Epoch 940/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0434 - acc: 0.9901 - val_loss: 0.2865 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00940: val_acc did not improve from 0.92350\n",
            "Epoch 941/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0400 - acc: 0.9921 - val_loss: 0.2857 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00941: val_acc did not improve from 0.92350\n",
            "Epoch 942/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0470 - acc: 0.9901 - val_loss: 0.2864 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00942: val_acc did not improve from 0.92350\n",
            "Epoch 943/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0433 - acc: 0.9900 - val_loss: 0.2861 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00943: val_acc did not improve from 0.92350\n",
            "Epoch 944/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0410 - acc: 0.9922 - val_loss: 0.2863 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00944: val_acc did not improve from 0.92350\n",
            "Epoch 945/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0458 - acc: 0.9904 - val_loss: 0.2861 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00945: val_acc did not improve from 0.92350\n",
            "Epoch 946/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0429 - acc: 0.9915 - val_loss: 0.2861 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00946: val_acc did not improve from 0.92350\n",
            "Epoch 947/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0454 - acc: 0.9900 - val_loss: 0.2868 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00947: val_acc did not improve from 0.92350\n",
            "Epoch 948/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0414 - acc: 0.9918 - val_loss: 0.2863 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00948: val_acc did not improve from 0.92350\n",
            "Epoch 949/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0430 - acc: 0.9919 - val_loss: 0.2864 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00949: val_acc did not improve from 0.92350\n",
            "Epoch 950/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0424 - acc: 0.9920 - val_loss: 0.2867 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00950: val_acc did not improve from 0.92350\n",
            "Epoch 951/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0433 - acc: 0.9896 - val_loss: 0.2866 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00951: val_acc did not improve from 0.92350\n",
            "Epoch 952/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0427 - acc: 0.9909 - val_loss: 0.2858 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00952: val_acc did not improve from 0.92350\n",
            "Epoch 953/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0415 - acc: 0.9905 - val_loss: 0.2864 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00953: val_acc did not improve from 0.92350\n",
            "Epoch 954/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0422 - acc: 0.9915 - val_loss: 0.2870 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00954: val_acc did not improve from 0.92350\n",
            "Epoch 955/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0422 - acc: 0.9905 - val_loss: 0.2876 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00955: val_acc did not improve from 0.92350\n",
            "Epoch 956/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0378 - acc: 0.9926 - val_loss: 0.2875 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00956: val_acc did not improve from 0.92350\n",
            "Epoch 957/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0452 - acc: 0.9891 - val_loss: 0.2876 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00957: val_acc did not improve from 0.92350\n",
            "Epoch 958/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0418 - acc: 0.9923 - val_loss: 0.2873 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00958: val_acc did not improve from 0.92350\n",
            "Epoch 959/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0440 - acc: 0.9908 - val_loss: 0.2877 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00959: val_acc did not improve from 0.92350\n",
            "Epoch 960/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0412 - acc: 0.9922 - val_loss: 0.2871 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00960: val_acc did not improve from 0.92350\n",
            "Epoch 961/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0403 - acc: 0.9924 - val_loss: 0.2874 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00961: val_acc did not improve from 0.92350\n",
            "Epoch 962/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0425 - acc: 0.9918 - val_loss: 0.2863 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00962: val_acc did not improve from 0.92350\n",
            "Epoch 963/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0415 - acc: 0.9916 - val_loss: 0.2871 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00963: val_acc did not improve from 0.92350\n",
            "Epoch 964/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0401 - acc: 0.9935 - val_loss: 0.2869 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00964: val_acc did not improve from 0.92350\n",
            "Epoch 965/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0451 - acc: 0.9888 - val_loss: 0.2869 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00965: val_acc did not improve from 0.92350\n",
            "Epoch 966/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0479 - acc: 0.9894 - val_loss: 0.2873 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00966: val_acc did not improve from 0.92350\n",
            "Epoch 967/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0422 - acc: 0.9903 - val_loss: 0.2872 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00967: val_acc did not improve from 0.92350\n",
            "Epoch 968/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0417 - acc: 0.9904 - val_loss: 0.2873 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00968: val_acc did not improve from 0.92350\n",
            "Epoch 969/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0447 - acc: 0.9910 - val_loss: 0.2870 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00969: val_acc did not improve from 0.92350\n",
            "Epoch 970/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0449 - acc: 0.9880 - val_loss: 0.2869 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00970: val_acc did not improve from 0.92350\n",
            "Epoch 971/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0450 - acc: 0.9891 - val_loss: 0.2869 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00971: val_acc did not improve from 0.92350\n",
            "Epoch 972/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0430 - acc: 0.9911 - val_loss: 0.2864 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00972: val_acc did not improve from 0.92350\n",
            "Epoch 973/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0415 - acc: 0.9925 - val_loss: 0.2880 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00973: val_acc did not improve from 0.92350\n",
            "Epoch 974/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0419 - acc: 0.9913 - val_loss: 0.2871 - val_acc: 0.9233\n",
            "\n",
            "Epoch 00974: val_acc did not improve from 0.92350\n",
            "Epoch 975/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0420 - acc: 0.9918 - val_loss: 0.2863 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00975: val_acc did not improve from 0.92350\n",
            "Epoch 976/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0443 - acc: 0.9915 - val_loss: 0.2868 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00976: val_acc did not improve from 0.92350\n",
            "Epoch 977/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0431 - acc: 0.9915 - val_loss: 0.2877 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00977: val_acc did not improve from 0.92350\n",
            "Epoch 978/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0455 - acc: 0.9898 - val_loss: 0.2878 - val_acc: 0.9231\n",
            "\n",
            "Epoch 00978: val_acc did not improve from 0.92350\n",
            "Epoch 979/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0432 - acc: 0.9917 - val_loss: 0.2876 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00979: val_acc did not improve from 0.92350\n",
            "Epoch 980/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0395 - acc: 0.9919 - val_loss: 0.2875 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00980: val_acc did not improve from 0.92350\n",
            "Epoch 981/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0411 - acc: 0.9913 - val_loss: 0.2878 - val_acc: 0.9231\n",
            "\n",
            "Epoch 00981: val_acc did not improve from 0.92350\n",
            "Epoch 982/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0395 - acc: 0.9927 - val_loss: 0.2876 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00982: val_acc did not improve from 0.92350\n",
            "Epoch 983/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0400 - acc: 0.9928 - val_loss: 0.2869 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00983: val_acc did not improve from 0.92350\n",
            "Epoch 984/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0404 - acc: 0.9921 - val_loss: 0.2870 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00984: val_acc did not improve from 0.92350\n",
            "Epoch 985/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0411 - acc: 0.9917 - val_loss: 0.2881 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00985: val_acc did not improve from 0.92350\n",
            "Epoch 986/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0398 - acc: 0.9918 - val_loss: 0.2881 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00986: val_acc did not improve from 0.92350\n",
            "Epoch 987/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0384 - acc: 0.9935 - val_loss: 0.2876 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00987: val_acc did not improve from 0.92350\n",
            "Epoch 988/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0398 - acc: 0.9929 - val_loss: 0.2875 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00988: val_acc did not improve from 0.92350\n",
            "Epoch 989/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0398 - acc: 0.9930 - val_loss: 0.2875 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00989: val_acc did not improve from 0.92350\n",
            "Epoch 990/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0398 - acc: 0.9919 - val_loss: 0.2884 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00990: val_acc did not improve from 0.92350\n",
            "Epoch 991/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.0411 - acc: 0.9907 - val_loss: 0.2881 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00991: val_acc did not improve from 0.92350\n",
            "Epoch 992/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0403 - acc: 0.9918 - val_loss: 0.2873 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00992: val_acc did not improve from 0.92350\n",
            "Epoch 993/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0417 - acc: 0.9914 - val_loss: 0.2883 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00993: val_acc did not improve from 0.92350\n",
            "Epoch 994/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0406 - acc: 0.9903 - val_loss: 0.2878 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00994: val_acc did not improve from 0.92350\n",
            "Epoch 995/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0437 - acc: 0.9909 - val_loss: 0.2887 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00995: val_acc did not improve from 0.92350\n",
            "Epoch 996/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0424 - acc: 0.9913 - val_loss: 0.2879 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00996: val_acc did not improve from 0.92350\n",
            "Epoch 997/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0399 - acc: 0.9928 - val_loss: 0.2880 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00997: val_acc did not improve from 0.92350\n",
            "Epoch 998/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0428 - acc: 0.9903 - val_loss: 0.2878 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00998: val_acc did not improve from 0.92350\n",
            "Epoch 999/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0427 - acc: 0.9911 - val_loss: 0.2877 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00999: val_acc did not improve from 0.92350\n",
            "Epoch 1000/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0413 - acc: 0.9909 - val_loss: 0.2876 - val_acc: 0.9224\n",
            "\n",
            "Epoch 01000: val_acc did not improve from 0.92350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "KqtP1kexx3yY",
        "outputId": "018676c0-6e65-453f-f40d-c48ac6a939d8"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('simple_trainHistoryDict_clip_05', \"rb\"))\n",
        "functions.plot_loss_acc(history, 2, 0.4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3PeG4ir4ZaK",
        "outputId": "a7e64e5f-c51d-4f73-b49d-bfb67ed00c49"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9223999977111816"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKjOwC70x-LH",
        "outputId": "f8308c6c-4b99-4bee-e9ee-f3f41e7022c9"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07760000228881836"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npx7NtMb2D0_"
      },
      "source": [
        "#### Model with clipping to 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZNaQkpfVJdo",
        "outputId": "ad975116-ef05-436c-db0c-f1dc5182c53a"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NwiXcn9VhF8",
        "outputId": "1039b95c-3078-40b1-bbe5-e95e52a1bc19"
      },
      "source": [
        "callbacks = functions.standard_callbacks(model_type) + [functions.Clipping(1, \"simple\")]\n",
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'simple_trainHistoryDict_clip_1', steps_per_epoch=100, epochs=1000,\n",
        "                       batch_size=100,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Epoch 1/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 84ms/step - loss: 3.4927 - acc: 0.2104 - val_loss: 3.0568 - val_acc: 0.1511\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.15110, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 1.8758 - acc: 0.3446 - val_loss: 3.4404 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.15110\n",
            "Epoch 3/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 1.6200 - acc: 0.4300 - val_loss: 4.0561 - val_acc: 0.1126\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.15110\n",
            "Epoch 4/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.5210 - acc: 0.4705 - val_loss: 2.6097 - val_acc: 0.1881\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.15110 to 0.18810, saving model to /content/saved_models/cifar10_ResNet32v1_model.004.h5\n",
            "Epoch 5/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 1.3719 - acc: 0.5192 - val_loss: 1.7108 - val_acc: 0.4398\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.18810 to 0.43980, saving model to /content/saved_models/cifar10_ResNet32v1_model.005.h5\n",
            "Epoch 6/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 1.2721 - acc: 0.5692 - val_loss: 1.4435 - val_acc: 0.4937\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.43980 to 0.49370, saving model to /content/saved_models/cifar10_ResNet32v1_model.006.h5\n",
            "Epoch 7/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 1.2316 - acc: 0.5784 - val_loss: 2.5135 - val_acc: 0.3416\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.49370\n",
            "Epoch 8/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.1521 - acc: 0.6111 - val_loss: 2.4890 - val_acc: 0.3723\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.49370\n",
            "Epoch 9/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.1211 - acc: 0.6160 - val_loss: 1.4654 - val_acc: 0.5285\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.49370 to 0.52850, saving model to /content/saved_models/cifar10_ResNet32v1_model.009.h5\n",
            "Epoch 10/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.0841 - acc: 0.6277 - val_loss: 1.4693 - val_acc: 0.5430\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.52850 to 0.54300, saving model to /content/saved_models/cifar10_ResNet32v1_model.010.h5\n",
            "Epoch 11/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 1.0559 - acc: 0.6437 - val_loss: 1.5235 - val_acc: 0.5216\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.54300\n",
            "Epoch 12/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 1.0164 - acc: 0.6616 - val_loss: 1.5416 - val_acc: 0.5559\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.54300 to 0.55590, saving model to /content/saved_models/cifar10_ResNet32v1_model.012.h5\n",
            "Epoch 13/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.9809 - acc: 0.6761 - val_loss: 1.4763 - val_acc: 0.5366\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.55590\n",
            "Epoch 14/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.9719 - acc: 0.6792 - val_loss: 1.2907 - val_acc: 0.5951\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.55590 to 0.59510, saving model to /content/saved_models/cifar10_ResNet32v1_model.014.h5\n",
            "Epoch 15/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.9302 - acc: 0.6962 - val_loss: 1.7420 - val_acc: 0.5103\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.59510\n",
            "Epoch 16/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.9324 - acc: 0.6940 - val_loss: 1.5657 - val_acc: 0.5594\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.59510\n",
            "Epoch 17/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.8930 - acc: 0.7080 - val_loss: 1.6859 - val_acc: 0.5660\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.59510\n",
            "Epoch 18/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.8663 - acc: 0.7138 - val_loss: 1.8574 - val_acc: 0.5107\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.59510\n",
            "Epoch 19/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.8595 - acc: 0.7150 - val_loss: 1.5631 - val_acc: 0.5568\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.59510\n",
            "Epoch 20/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.8685 - acc: 0.7200 - val_loss: 1.4054 - val_acc: 0.6051\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.59510 to 0.60510, saving model to /content/saved_models/cifar10_ResNet32v1_model.020.h5\n",
            "Epoch 21/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.8246 - acc: 0.7287 - val_loss: 3.1877 - val_acc: 0.4147\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.60510\n",
            "Epoch 22/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.8215 - acc: 0.7374 - val_loss: 2.0542 - val_acc: 0.5273\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.60510\n",
            "Epoch 23/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.8271 - acc: 0.7302 - val_loss: 1.6116 - val_acc: 0.5815\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.60510\n",
            "Epoch 24/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7758 - acc: 0.7469 - val_loss: 1.1919 - val_acc: 0.6567\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.60510 to 0.65670, saving model to /content/saved_models/cifar10_ResNet32v1_model.024.h5\n",
            "Epoch 25/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7733 - acc: 0.7506 - val_loss: 1.4244 - val_acc: 0.6075\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.65670\n",
            "Epoch 26/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.7931 - acc: 0.7466 - val_loss: 1.2490 - val_acc: 0.6380\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.65670\n",
            "Epoch 27/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.7721 - acc: 0.7477 - val_loss: 0.8730 - val_acc: 0.7197\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.65670 to 0.71970, saving model to /content/saved_models/cifar10_ResNet32v1_model.027.h5\n",
            "Epoch 28/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.7391 - acc: 0.7652 - val_loss: 1.3001 - val_acc: 0.6130\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.71970\n",
            "Epoch 29/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7569 - acc: 0.7584 - val_loss: 1.1886 - val_acc: 0.6645\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.71970\n",
            "Epoch 30/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7552 - acc: 0.7549 - val_loss: 2.4495 - val_acc: 0.4685\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.71970\n",
            "Epoch 31/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7247 - acc: 0.7659 - val_loss: 1.2323 - val_acc: 0.6473\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.71970\n",
            "Epoch 32/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7212 - acc: 0.7620 - val_loss: 1.9246 - val_acc: 0.5743\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.71970\n",
            "Epoch 33/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6872 - acc: 0.7740 - val_loss: 1.6670 - val_acc: 0.5374\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.71970\n",
            "Epoch 34/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7320 - acc: 0.7630 - val_loss: 1.6776 - val_acc: 0.5623\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.71970\n",
            "Epoch 35/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7109 - acc: 0.7740 - val_loss: 1.4196 - val_acc: 0.5895\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.71970\n",
            "Epoch 36/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7007 - acc: 0.7714 - val_loss: 1.4143 - val_acc: 0.6167\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.71970\n",
            "Epoch 37/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6732 - acc: 0.7799 - val_loss: 1.7636 - val_acc: 0.5860\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.71970\n",
            "Epoch 38/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6878 - acc: 0.7750 - val_loss: 1.5026 - val_acc: 0.6189\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.71970\n",
            "Epoch 39/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6555 - acc: 0.7926 - val_loss: 1.4598 - val_acc: 0.6059\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.71970\n",
            "Epoch 40/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6701 - acc: 0.7868 - val_loss: 1.6271 - val_acc: 0.6131\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.71970\n",
            "Epoch 41/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7050 - acc: 0.7741 - val_loss: 1.0708 - val_acc: 0.6890\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.71970\n",
            "Epoch 42/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6526 - acc: 0.7900 - val_loss: 1.2763 - val_acc: 0.6702\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.71970\n",
            "Epoch 43/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6571 - acc: 0.7854 - val_loss: 1.1273 - val_acc: 0.6869\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.71970\n",
            "Epoch 44/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6184 - acc: 0.8013 - val_loss: 1.6595 - val_acc: 0.5973\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.71970\n",
            "Epoch 45/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6620 - acc: 0.7883 - val_loss: 1.1225 - val_acc: 0.7003\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.71970\n",
            "Epoch 46/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6323 - acc: 0.8009 - val_loss: 1.1074 - val_acc: 0.6824\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.71970\n",
            "Epoch 47/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.6444 - acc: 0.7969 - val_loss: 1.3818 - val_acc: 0.6387\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.71970\n",
            "Epoch 48/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6295 - acc: 0.7976 - val_loss: 1.6746 - val_acc: 0.6121\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.71970\n",
            "Epoch 49/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6731 - acc: 0.7833 - val_loss: 1.4762 - val_acc: 0.6085\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.71970\n",
            "Epoch 50/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6259 - acc: 0.8012 - val_loss: 2.0484 - val_acc: 0.5369\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.71970\n",
            "Epoch 51/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6358 - acc: 0.7940 - val_loss: 1.3493 - val_acc: 0.6614\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.71970\n",
            "Epoch 52/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.6448 - acc: 0.7868 - val_loss: 1.8909 - val_acc: 0.5794\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.71970\n",
            "Epoch 53/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6450 - acc: 0.7982 - val_loss: 1.1936 - val_acc: 0.6485\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.71970\n",
            "Epoch 54/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.5862 - acc: 0.8133 - val_loss: 1.0878 - val_acc: 0.6651\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.71970\n",
            "Epoch 55/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6332 - acc: 0.7946 - val_loss: 1.2041 - val_acc: 0.6551\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.71970\n",
            "Epoch 56/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6153 - acc: 0.8039 - val_loss: 1.8265 - val_acc: 0.5328\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.71970\n",
            "Epoch 57/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6227 - acc: 0.8092 - val_loss: 1.6186 - val_acc: 0.5791\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.71970\n",
            "Epoch 58/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6199 - acc: 0.8016 - val_loss: 2.2924 - val_acc: 0.4710\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.71970\n",
            "Epoch 59/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6174 - acc: 0.7964 - val_loss: 1.5858 - val_acc: 0.6104\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.71970\n",
            "Epoch 60/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5778 - acc: 0.8109 - val_loss: 1.5309 - val_acc: 0.5990\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.71970\n",
            "Epoch 61/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6025 - acc: 0.8085 - val_loss: 0.9114 - val_acc: 0.7263\n",
            "\n",
            "Epoch 00061: val_acc improved from 0.71970 to 0.72630, saving model to /content/saved_models/cifar10_ResNet32v1_model.061.h5\n",
            "Epoch 62/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5889 - acc: 0.8127 - val_loss: 1.5682 - val_acc: 0.6317\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.72630\n",
            "Epoch 63/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5694 - acc: 0.8174 - val_loss: 1.1556 - val_acc: 0.6806\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.72630\n",
            "Epoch 64/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5772 - acc: 0.8215 - val_loss: 3.0519 - val_acc: 0.4420\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.72630\n",
            "Epoch 65/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6067 - acc: 0.8101 - val_loss: 1.0299 - val_acc: 0.7065\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.72630\n",
            "Epoch 66/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5914 - acc: 0.8095 - val_loss: 1.7376 - val_acc: 0.5226\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.72630\n",
            "Epoch 67/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6004 - acc: 0.8073 - val_loss: 1.2355 - val_acc: 0.6413\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.72630\n",
            "Epoch 68/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5980 - acc: 0.8099 - val_loss: 1.8713 - val_acc: 0.5833\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.72630\n",
            "Epoch 69/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5780 - acc: 0.8172 - val_loss: 2.6887 - val_acc: 0.4963\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.72630\n",
            "Epoch 70/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5706 - acc: 0.8215 - val_loss: 0.9820 - val_acc: 0.7201\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.72630\n",
            "Epoch 71/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5819 - acc: 0.8131 - val_loss: 2.8270 - val_acc: 0.4576\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.72630\n",
            "Epoch 72/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5574 - acc: 0.8231 - val_loss: 0.9261 - val_acc: 0.7212\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.72630\n",
            "Epoch 73/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5698 - acc: 0.8174 - val_loss: 1.6540 - val_acc: 0.5999\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.72630\n",
            "Epoch 74/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5668 - acc: 0.8210 - val_loss: 1.1362 - val_acc: 0.6671\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.72630\n",
            "Epoch 75/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5734 - acc: 0.8203 - val_loss: 1.9984 - val_acc: 0.5287\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.72630\n",
            "Epoch 76/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5885 - acc: 0.8105 - val_loss: 0.9276 - val_acc: 0.7403\n",
            "\n",
            "Epoch 00076: val_acc improved from 0.72630 to 0.74030, saving model to /content/saved_models/cifar10_ResNet32v1_model.076.h5\n",
            "Epoch 77/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5958 - acc: 0.8109 - val_loss: 1.0806 - val_acc: 0.7116\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.74030\n",
            "Epoch 78/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5676 - acc: 0.8158 - val_loss: 1.5623 - val_acc: 0.5908\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.74030\n",
            "Epoch 79/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5596 - acc: 0.8211 - val_loss: 1.3092 - val_acc: 0.6632\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.74030\n",
            "Epoch 80/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5568 - acc: 0.8262 - val_loss: 1.2624 - val_acc: 0.6517\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.74030\n",
            "Epoch 81/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5418 - acc: 0.8207 - val_loss: 1.0830 - val_acc: 0.6769\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.74030\n",
            "Epoch 82/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5736 - acc: 0.8229 - val_loss: 1.0063 - val_acc: 0.7208\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.74030\n",
            "Epoch 83/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5448 - acc: 0.8264 - val_loss: 1.2420 - val_acc: 0.6725\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.74030\n",
            "Epoch 84/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5478 - acc: 0.8260 - val_loss: 2.9566 - val_acc: 0.4784\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.74030\n",
            "Epoch 85/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5567 - acc: 0.8209 - val_loss: 1.4362 - val_acc: 0.6246\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.74030\n",
            "Epoch 86/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5660 - acc: 0.8225 - val_loss: 1.9088 - val_acc: 0.5514\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.74030\n",
            "Epoch 87/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5562 - acc: 0.8246 - val_loss: 0.7967 - val_acc: 0.7493\n",
            "\n",
            "Epoch 00087: val_acc improved from 0.74030 to 0.74930, saving model to /content/saved_models/cifar10_ResNet32v1_model.087.h5\n",
            "Epoch 88/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5449 - acc: 0.8272 - val_loss: 1.6223 - val_acc: 0.6238\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.74930\n",
            "Epoch 89/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5395 - acc: 0.8240 - val_loss: 1.0713 - val_acc: 0.6935\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.74930\n",
            "Epoch 90/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5230 - acc: 0.8375 - val_loss: 2.2110 - val_acc: 0.5531\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.74930\n",
            "Epoch 91/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5379 - acc: 0.8346 - val_loss: 1.4868 - val_acc: 0.6611\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.74930\n",
            "Epoch 92/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5422 - acc: 0.8316 - val_loss: 1.3350 - val_acc: 0.6431\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.74930\n",
            "Epoch 93/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5162 - acc: 0.8371 - val_loss: 1.5340 - val_acc: 0.5713\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.74930\n",
            "Epoch 94/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5414 - acc: 0.8331 - val_loss: 1.0361 - val_acc: 0.6941\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.74930\n",
            "Epoch 95/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5331 - acc: 0.8350 - val_loss: 0.9382 - val_acc: 0.7254\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.74930\n",
            "Epoch 96/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5343 - acc: 0.8353 - val_loss: 1.4428 - val_acc: 0.6097\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.74930\n",
            "Epoch 97/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5562 - acc: 0.8293 - val_loss: 0.9032 - val_acc: 0.7141\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.74930\n",
            "Epoch 98/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5417 - acc: 0.8281 - val_loss: 0.8951 - val_acc: 0.7556\n",
            "\n",
            "Epoch 00098: val_acc improved from 0.74930 to 0.75560, saving model to /content/saved_models/cifar10_ResNet32v1_model.098.h5\n",
            "Epoch 99/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5134 - acc: 0.8402 - val_loss: 1.9917 - val_acc: 0.5209\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.75560\n",
            "Epoch 100/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5284 - acc: 0.8311 - val_loss: 1.6336 - val_acc: 0.6290\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.75560\n",
            "Epoch 101/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5437 - acc: 0.8332 - val_loss: 1.7284 - val_acc: 0.6006\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.75560\n",
            "Epoch 102/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5429 - acc: 0.8277 - val_loss: 1.2683 - val_acc: 0.6841\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.75560\n",
            "Epoch 103/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5220 - acc: 0.8302 - val_loss: 1.1728 - val_acc: 0.6649\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.75560\n",
            "Epoch 104/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5835 - acc: 0.8107 - val_loss: 1.0791 - val_acc: 0.7115\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.75560\n",
            "Epoch 105/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4976 - acc: 0.8449 - val_loss: 1.4686 - val_acc: 0.6220\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.75560\n",
            "Epoch 106/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5309 - acc: 0.8298 - val_loss: 0.9090 - val_acc: 0.7370\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.75560\n",
            "Epoch 107/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5108 - acc: 0.8407 - val_loss: 1.2533 - val_acc: 0.6687\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.75560\n",
            "Epoch 108/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5587 - acc: 0.8250 - val_loss: 4.9938 - val_acc: 0.2735\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.75560\n",
            "Epoch 109/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5255 - acc: 0.8355 - val_loss: 1.3709 - val_acc: 0.6401\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.75560\n",
            "Epoch 110/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5310 - acc: 0.8282 - val_loss: 1.0710 - val_acc: 0.6945\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.75560\n",
            "Epoch 111/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5304 - acc: 0.8338 - val_loss: 1.1143 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.75560\n",
            "Epoch 112/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5156 - acc: 0.8403 - val_loss: 0.7581 - val_acc: 0.7762\n",
            "\n",
            "Epoch 00112: val_acc improved from 0.75560 to 0.77620, saving model to /content/saved_models/cifar10_ResNet32v1_model.112.h5\n",
            "Epoch 113/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5157 - acc: 0.8373 - val_loss: 0.8440 - val_acc: 0.7530\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.77620\n",
            "Epoch 114/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5140 - acc: 0.8387 - val_loss: 1.0127 - val_acc: 0.7106\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.77620\n",
            "Epoch 115/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5258 - acc: 0.8317 - val_loss: 1.2680 - val_acc: 0.6524\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.77620\n",
            "Epoch 116/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5012 - acc: 0.8403 - val_loss: 0.9600 - val_acc: 0.7266\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.77620\n",
            "Epoch 117/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5143 - acc: 0.8426 - val_loss: 0.8323 - val_acc: 0.7664\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.77620\n",
            "Epoch 118/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5246 - acc: 0.8312 - val_loss: 0.8759 - val_acc: 0.7460\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.77620\n",
            "Epoch 119/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5408 - acc: 0.8284 - val_loss: 1.2843 - val_acc: 0.6678\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.77620\n",
            "Epoch 120/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5187 - acc: 0.8377 - val_loss: 2.3948 - val_acc: 0.5495\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.77620\n",
            "Epoch 121/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4964 - acc: 0.8471 - val_loss: 1.8127 - val_acc: 0.5790\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.77620\n",
            "Epoch 122/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5107 - acc: 0.8477 - val_loss: 0.8622 - val_acc: 0.7526\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.77620\n",
            "Epoch 123/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5163 - acc: 0.8399 - val_loss: 0.9296 - val_acc: 0.7338\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.77620\n",
            "Epoch 124/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5323 - acc: 0.8350 - val_loss: 2.9160 - val_acc: 0.4695\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.77620\n",
            "Epoch 125/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4995 - acc: 0.8502 - val_loss: 0.9948 - val_acc: 0.7326\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.77620\n",
            "Epoch 126/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5127 - acc: 0.8375 - val_loss: 1.1612 - val_acc: 0.6781\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.77620\n",
            "Epoch 127/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4967 - acc: 0.8438 - val_loss: 0.9416 - val_acc: 0.7064\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.77620\n",
            "Epoch 128/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5127 - acc: 0.8406 - val_loss: 1.0388 - val_acc: 0.6972\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.77620\n",
            "Epoch 129/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4968 - acc: 0.8444 - val_loss: 0.8895 - val_acc: 0.7446\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.77620\n",
            "Epoch 130/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4905 - acc: 0.8429 - val_loss: 1.4403 - val_acc: 0.6326\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.77620\n",
            "Epoch 131/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5055 - acc: 0.8497 - val_loss: 1.2550 - val_acc: 0.6494\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.77620\n",
            "Epoch 132/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4673 - acc: 0.8515 - val_loss: 0.9410 - val_acc: 0.7311\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.77620\n",
            "Epoch 133/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4999 - acc: 0.8497 - val_loss: 2.0108 - val_acc: 0.5949\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.77620\n",
            "Epoch 134/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5094 - acc: 0.8461 - val_loss: 0.9193 - val_acc: 0.7426\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.77620\n",
            "Epoch 135/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4944 - acc: 0.8443 - val_loss: 1.1573 - val_acc: 0.6653\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.77620\n",
            "Epoch 136/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4961 - acc: 0.8531 - val_loss: 1.6696 - val_acc: 0.6316\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.77620\n",
            "Epoch 137/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5035 - acc: 0.8429 - val_loss: 1.1330 - val_acc: 0.6741\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.77620\n",
            "Epoch 138/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5330 - acc: 0.8299 - val_loss: 0.7480 - val_acc: 0.7835\n",
            "\n",
            "Epoch 00138: val_acc improved from 0.77620 to 0.78350, saving model to /content/saved_models/cifar10_ResNet32v1_model.138.h5\n",
            "Epoch 139/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5162 - acc: 0.8363 - val_loss: 0.7461 - val_acc: 0.7711\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.78350\n",
            "Epoch 140/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4956 - acc: 0.8403 - val_loss: 0.7107 - val_acc: 0.7856\n",
            "\n",
            "Epoch 00140: val_acc improved from 0.78350 to 0.78560, saving model to /content/saved_models/cifar10_ResNet32v1_model.140.h5\n",
            "Epoch 141/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5255 - acc: 0.8329 - val_loss: 1.1373 - val_acc: 0.6798\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.78560\n",
            "Epoch 142/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4922 - acc: 0.8457 - val_loss: 1.3883 - val_acc: 0.6009\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.78560\n",
            "Epoch 143/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4889 - acc: 0.8488 - val_loss: 0.8979 - val_acc: 0.7516\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.78560\n",
            "Epoch 144/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4968 - acc: 0.8447 - val_loss: 3.3859 - val_acc: 0.4211\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.78560\n",
            "Epoch 145/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5007 - acc: 0.8426 - val_loss: 1.8408 - val_acc: 0.6066\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.78560\n",
            "Epoch 146/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4954 - acc: 0.8446 - val_loss: 1.0400 - val_acc: 0.7117\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.78560\n",
            "Epoch 147/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4674 - acc: 0.8543 - val_loss: 3.5054 - val_acc: 0.4147\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.78560\n",
            "Epoch 148/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5224 - acc: 0.8370 - val_loss: 1.0234 - val_acc: 0.7193\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.78560\n",
            "Epoch 149/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4975 - acc: 0.8448 - val_loss: 0.9179 - val_acc: 0.7208\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.78560\n",
            "Epoch 150/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4663 - acc: 0.8564 - val_loss: 1.2353 - val_acc: 0.6809\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.78560\n",
            "Epoch 151/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4664 - acc: 0.8492 - val_loss: 1.3795 - val_acc: 0.6517\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.78560\n",
            "Epoch 152/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4963 - acc: 0.8460 - val_loss: 1.0176 - val_acc: 0.7136\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.78560\n",
            "Epoch 153/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4907 - acc: 0.8496 - val_loss: 0.9585 - val_acc: 0.7259\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.78560\n",
            "Epoch 154/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4794 - acc: 0.8476 - val_loss: 0.8010 - val_acc: 0.7689\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.78560\n",
            "Epoch 155/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4750 - acc: 0.8533 - val_loss: 1.3888 - val_acc: 0.6359\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.78560\n",
            "Epoch 156/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4952 - acc: 0.8477 - val_loss: 1.0177 - val_acc: 0.7152\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.78560\n",
            "Epoch 157/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.4842 - acc: 0.8486 - val_loss: 1.9893 - val_acc: 0.5689\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.78560\n",
            "Epoch 158/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4907 - acc: 0.8413 - val_loss: 1.1089 - val_acc: 0.6956\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.78560\n",
            "Epoch 159/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4845 - acc: 0.8491 - val_loss: 0.6824 - val_acc: 0.7865\n",
            "\n",
            "Epoch 00159: val_acc improved from 0.78560 to 0.78650, saving model to /content/saved_models/cifar10_ResNet32v1_model.159.h5\n",
            "Epoch 160/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4982 - acc: 0.8435 - val_loss: 1.4189 - val_acc: 0.6348\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.78650\n",
            "Epoch 161/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4674 - acc: 0.8540 - val_loss: 1.1458 - val_acc: 0.6728\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.78650\n",
            "Epoch 162/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5019 - acc: 0.8453 - val_loss: 1.4148 - val_acc: 0.6454\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.78650\n",
            "Epoch 163/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5022 - acc: 0.8446 - val_loss: 0.7108 - val_acc: 0.7831\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.78650\n",
            "Epoch 164/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4857 - acc: 0.8495 - val_loss: 1.0084 - val_acc: 0.7039\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.78650\n",
            "Epoch 165/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4641 - acc: 0.8579 - val_loss: 1.0368 - val_acc: 0.7212\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.78650\n",
            "Epoch 166/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4681 - acc: 0.8561 - val_loss: 1.1399 - val_acc: 0.6746\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.78650\n",
            "Epoch 167/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4913 - acc: 0.8468 - val_loss: 1.0235 - val_acc: 0.7090\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.78650\n",
            "Epoch 168/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4931 - acc: 0.8488 - val_loss: 2.0403 - val_acc: 0.5352\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.78650\n",
            "Epoch 169/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4649 - acc: 0.8545 - val_loss: 1.1442 - val_acc: 0.6885\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.78650\n",
            "Epoch 170/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4872 - acc: 0.8506 - val_loss: 0.7954 - val_acc: 0.7644\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.78650\n",
            "Epoch 171/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4758 - acc: 0.8489 - val_loss: 0.9449 - val_acc: 0.7392\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.78650\n",
            "Epoch 172/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4665 - acc: 0.8527 - val_loss: 0.7329 - val_acc: 0.7754\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.78650\n",
            "Epoch 173/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4630 - acc: 0.8567 - val_loss: 1.0774 - val_acc: 0.7046\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.78650\n",
            "Epoch 174/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4890 - acc: 0.8456 - val_loss: 0.9698 - val_acc: 0.7255\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.78650\n",
            "Epoch 175/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4890 - acc: 0.8526 - val_loss: 0.7724 - val_acc: 0.7713\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.78650\n",
            "Epoch 176/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4636 - acc: 0.8557 - val_loss: 1.3550 - val_acc: 0.6435\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.78650\n",
            "Epoch 177/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4730 - acc: 0.8559 - val_loss: 1.4186 - val_acc: 0.6795\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.78650\n",
            "Epoch 178/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4831 - acc: 0.8523 - val_loss: 1.0302 - val_acc: 0.6967\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.78650\n",
            "Epoch 179/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4663 - acc: 0.8611 - val_loss: 2.0261 - val_acc: 0.5891\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.78650\n",
            "Epoch 180/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4634 - acc: 0.8612 - val_loss: 0.8430 - val_acc: 0.7554\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.78650\n",
            "Epoch 181/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4708 - acc: 0.8508 - val_loss: 1.1855 - val_acc: 0.6782\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.78650\n",
            "Epoch 182/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4594 - acc: 0.8581 - val_loss: 1.0836 - val_acc: 0.7102\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.78650\n",
            "Epoch 183/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4540 - acc: 0.8611 - val_loss: 0.7801 - val_acc: 0.7782\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.78650\n",
            "Epoch 184/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4680 - acc: 0.8624 - val_loss: 1.2117 - val_acc: 0.6932\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.78650\n",
            "Epoch 185/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4523 - acc: 0.8588 - val_loss: 1.1248 - val_acc: 0.6787\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.78650\n",
            "Epoch 186/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4674 - acc: 0.8605 - val_loss: 0.9997 - val_acc: 0.7331\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.78650\n",
            "Epoch 187/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4682 - acc: 0.8506 - val_loss: 1.2519 - val_acc: 0.6760\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.78650\n",
            "Epoch 188/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4905 - acc: 0.8481 - val_loss: 0.8288 - val_acc: 0.7418\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.78650\n",
            "Epoch 189/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4315 - acc: 0.8716 - val_loss: 1.7520 - val_acc: 0.6337\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.78650\n",
            "Epoch 190/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4634 - acc: 0.8615 - val_loss: 2.4953 - val_acc: 0.5063\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.78650\n",
            "Epoch 191/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4822 - acc: 0.8522 - val_loss: 1.2226 - val_acc: 0.6605\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.78650\n",
            "Epoch 192/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4648 - acc: 0.8556 - val_loss: 1.3906 - val_acc: 0.6735\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.78650\n",
            "Epoch 193/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4698 - acc: 0.8511 - val_loss: 0.9075 - val_acc: 0.7332\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.78650\n",
            "Epoch 194/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4792 - acc: 0.8443 - val_loss: 1.1028 - val_acc: 0.7055\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.78650\n",
            "Epoch 195/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4965 - acc: 0.8427 - val_loss: 1.1554 - val_acc: 0.6602\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.78650\n",
            "Epoch 196/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4840 - acc: 0.8508 - val_loss: 0.7874 - val_acc: 0.7646\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.78650\n",
            "Epoch 197/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4745 - acc: 0.8516 - val_loss: 0.8169 - val_acc: 0.7584\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.78650\n",
            "Epoch 198/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4808 - acc: 0.8534 - val_loss: 1.2003 - val_acc: 0.6760\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.78650\n",
            "Epoch 199/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4722 - acc: 0.8508 - val_loss: 0.9741 - val_acc: 0.7358\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.78650\n",
            "Epoch 200/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4654 - acc: 0.8555 - val_loss: 1.2830 - val_acc: 0.6245\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.78650\n",
            "Epoch 201/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4894 - acc: 0.8512 - val_loss: 0.7985 - val_acc: 0.7538\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.78650\n",
            "Epoch 202/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4574 - acc: 0.8641 - val_loss: 1.2284 - val_acc: 0.6923\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.78650\n",
            "Epoch 203/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4505 - acc: 0.8605 - val_loss: 0.9800 - val_acc: 0.7339\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.78650\n",
            "Epoch 204/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4679 - acc: 0.8551 - val_loss: 0.9153 - val_acc: 0.7550\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.78650\n",
            "Epoch 205/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4589 - acc: 0.8608 - val_loss: 1.0556 - val_acc: 0.7173\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.78650\n",
            "Epoch 206/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4481 - acc: 0.8611 - val_loss: 1.1211 - val_acc: 0.6854\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.78650\n",
            "Epoch 207/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4630 - acc: 0.8631 - val_loss: 1.2782 - val_acc: 0.6652\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.78650\n",
            "Epoch 208/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4638 - acc: 0.8554 - val_loss: 1.8457 - val_acc: 0.5658\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.78650\n",
            "Epoch 209/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4524 - acc: 0.8589 - val_loss: 0.9270 - val_acc: 0.7110\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.78650\n",
            "Epoch 210/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4331 - acc: 0.8717 - val_loss: 1.2317 - val_acc: 0.6831\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.78650\n",
            "Epoch 211/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4705 - acc: 0.8550 - val_loss: 1.0203 - val_acc: 0.7187\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.78650\n",
            "Epoch 212/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4514 - acc: 0.8601 - val_loss: 0.6992 - val_acc: 0.7898\n",
            "\n",
            "Epoch 00212: val_acc improved from 0.78650 to 0.78980, saving model to /content/saved_models/cifar10_ResNet32v1_model.212.h5\n",
            "Epoch 213/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4846 - acc: 0.8472 - val_loss: 0.8174 - val_acc: 0.7632\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.78980\n",
            "Epoch 214/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4568 - acc: 0.8555 - val_loss: 0.7979 - val_acc: 0.7645\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.78980\n",
            "Epoch 215/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4675 - acc: 0.8540 - val_loss: 1.3549 - val_acc: 0.6309\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.78980\n",
            "Epoch 216/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4601 - acc: 0.8554 - val_loss: 1.1142 - val_acc: 0.6919\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.78980\n",
            "Epoch 217/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4526 - acc: 0.8659 - val_loss: 0.9376 - val_acc: 0.7545\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.78980\n",
            "Epoch 218/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4457 - acc: 0.8587 - val_loss: 0.6351 - val_acc: 0.8056\n",
            "\n",
            "Epoch 00218: val_acc improved from 0.78980 to 0.80560, saving model to /content/saved_models/cifar10_ResNet32v1_model.218.h5\n",
            "Epoch 219/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4419 - acc: 0.8720 - val_loss: 0.9955 - val_acc: 0.7100\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.80560\n",
            "Epoch 220/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4626 - acc: 0.8564 - val_loss: 1.5445 - val_acc: 0.6406\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.80560\n",
            "Epoch 221/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4649 - acc: 0.8566 - val_loss: 0.8820 - val_acc: 0.7401\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.80560\n",
            "Epoch 222/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4443 - acc: 0.8644 - val_loss: 1.0887 - val_acc: 0.6962\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.80560\n",
            "Epoch 223/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4395 - acc: 0.8636 - val_loss: 0.9030 - val_acc: 0.7369\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.80560\n",
            "Epoch 224/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4653 - acc: 0.8540 - val_loss: 0.9219 - val_acc: 0.7387\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.80560\n",
            "Epoch 225/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4527 - acc: 0.8590 - val_loss: 1.9765 - val_acc: 0.5559\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.80560\n",
            "Epoch 226/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4749 - acc: 0.8568 - val_loss: 1.5506 - val_acc: 0.6117\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.80560\n",
            "Epoch 227/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4510 - acc: 0.8599 - val_loss: 1.2464 - val_acc: 0.6678\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.80560\n",
            "Epoch 228/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4525 - acc: 0.8616 - val_loss: 1.3055 - val_acc: 0.6336\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.80560\n",
            "Epoch 229/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4574 - acc: 0.8585 - val_loss: 1.9682 - val_acc: 0.5474\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.80560\n",
            "Epoch 230/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4772 - acc: 0.8565 - val_loss: 1.1374 - val_acc: 0.6724\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.80560\n",
            "Epoch 231/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4705 - acc: 0.8597 - val_loss: 0.8475 - val_acc: 0.7515\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.80560\n",
            "Epoch 232/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4357 - acc: 0.8648 - val_loss: 1.5153 - val_acc: 0.6498\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.80560\n",
            "Epoch 233/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4243 - acc: 0.8694 - val_loss: 1.1923 - val_acc: 0.6878\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.80560\n",
            "Epoch 234/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4694 - acc: 0.8508 - val_loss: 1.3803 - val_acc: 0.6852\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.80560\n",
            "Epoch 235/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4555 - acc: 0.8613 - val_loss: 0.9798 - val_acc: 0.7357\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.80560\n",
            "Epoch 236/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4829 - acc: 0.8580 - val_loss: 0.8357 - val_acc: 0.7580\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.80560\n",
            "Epoch 237/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4436 - acc: 0.8604 - val_loss: 0.8688 - val_acc: 0.7406\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.80560\n",
            "Epoch 238/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4440 - acc: 0.8650 - val_loss: 0.8652 - val_acc: 0.7645\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.80560\n",
            "Epoch 239/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4488 - acc: 0.8626 - val_loss: 1.0672 - val_acc: 0.7100\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.80560\n",
            "Epoch 240/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4318 - acc: 0.8696 - val_loss: 1.2739 - val_acc: 0.6580\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.80560\n",
            "Epoch 241/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4703 - acc: 0.8502 - val_loss: 0.7988 - val_acc: 0.7678\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.80560\n",
            "Epoch 242/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4421 - acc: 0.8660 - val_loss: 1.1033 - val_acc: 0.7132\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.80560\n",
            "Epoch 243/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4434 - acc: 0.8669 - val_loss: 2.6673 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.80560\n",
            "Epoch 244/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4537 - acc: 0.8624 - val_loss: 1.5659 - val_acc: 0.5881\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.80560\n",
            "Epoch 245/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4602 - acc: 0.8606 - val_loss: 1.1321 - val_acc: 0.7012\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.80560\n",
            "Epoch 246/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4461 - acc: 0.8603 - val_loss: 1.1912 - val_acc: 0.6669\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.80560\n",
            "Epoch 247/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4354 - acc: 0.8596 - val_loss: 1.3899 - val_acc: 0.6901\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.80560\n",
            "Epoch 248/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4548 - acc: 0.8589 - val_loss: 1.9470 - val_acc: 0.5422\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.80560\n",
            "Epoch 249/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4489 - acc: 0.8642 - val_loss: 1.1480 - val_acc: 0.6952\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.80560\n",
            "Epoch 250/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4304 - acc: 0.8706 - val_loss: 0.9474 - val_acc: 0.7427\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.80560\n",
            "Epoch 251/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4572 - acc: 0.8620 - val_loss: 0.7951 - val_acc: 0.7610\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.80560\n",
            "Epoch 252/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4355 - acc: 0.8720 - val_loss: 0.9395 - val_acc: 0.7195\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.80560\n",
            "Epoch 253/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4466 - acc: 0.8629 - val_loss: 1.1292 - val_acc: 0.6813\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.80560\n",
            "Epoch 254/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4490 - acc: 0.8667 - val_loss: 0.9680 - val_acc: 0.7244\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.80560\n",
            "Epoch 255/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4389 - acc: 0.8708 - val_loss: 1.2166 - val_acc: 0.6540\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.80560\n",
            "Epoch 256/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4426 - acc: 0.8652 - val_loss: 1.0656 - val_acc: 0.7031\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.80560\n",
            "Epoch 257/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4677 - acc: 0.8586 - val_loss: 1.3986 - val_acc: 0.6350\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.80560\n",
            "Epoch 258/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4510 - acc: 0.8623 - val_loss: 0.9321 - val_acc: 0.7227\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.80560\n",
            "Epoch 259/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4411 - acc: 0.8630 - val_loss: 0.7525 - val_acc: 0.7783\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.80560\n",
            "Epoch 260/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4552 - acc: 0.8587 - val_loss: 0.8367 - val_acc: 0.7510\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.80560\n",
            "Epoch 261/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4501 - acc: 0.8644 - val_loss: 0.9961 - val_acc: 0.7354\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.80560\n",
            "Epoch 262/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4451 - acc: 0.8625 - val_loss: 1.1925 - val_acc: 0.6718\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.80560\n",
            "Epoch 263/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4233 - acc: 0.8689 - val_loss: 1.4398 - val_acc: 0.6720\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.80560\n",
            "Epoch 264/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4539 - acc: 0.8609 - val_loss: 1.0997 - val_acc: 0.7277\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.80560\n",
            "Epoch 265/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4275 - acc: 0.8716 - val_loss: 1.6534 - val_acc: 0.5978\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.80560\n",
            "Epoch 266/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4304 - acc: 0.8675 - val_loss: 0.7441 - val_acc: 0.7691\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.80560\n",
            "Epoch 267/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4455 - acc: 0.8658 - val_loss: 1.3156 - val_acc: 0.6797\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.80560\n",
            "Epoch 268/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4370 - acc: 0.8701 - val_loss: 1.1202 - val_acc: 0.7019\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.80560\n",
            "Epoch 269/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4446 - acc: 0.8659 - val_loss: 0.9763 - val_acc: 0.7286\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.80560\n",
            "Epoch 270/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4442 - acc: 0.8626 - val_loss: 1.0098 - val_acc: 0.7156\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.80560\n",
            "Epoch 271/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4366 - acc: 0.8670 - val_loss: 2.1920 - val_acc: 0.5306\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.80560\n",
            "Epoch 272/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4381 - acc: 0.8700 - val_loss: 1.6539 - val_acc: 0.5931\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.80560\n",
            "Epoch 273/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4379 - acc: 0.8665 - val_loss: 1.3009 - val_acc: 0.6843\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.80560\n",
            "Epoch 274/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4308 - acc: 0.8638 - val_loss: 1.3837 - val_acc: 0.6526\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.80560\n",
            "Epoch 275/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4423 - acc: 0.8655 - val_loss: 1.9175 - val_acc: 0.5220\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.80560\n",
            "Epoch 276/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4220 - acc: 0.8763 - val_loss: 1.1674 - val_acc: 0.6870\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.80560\n",
            "Epoch 277/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4449 - acc: 0.8650 - val_loss: 0.9038 - val_acc: 0.7472\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.80560\n",
            "Epoch 278/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4274 - acc: 0.8737 - val_loss: 1.1657 - val_acc: 0.7004\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.80560\n",
            "Epoch 279/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4301 - acc: 0.8693 - val_loss: 1.3126 - val_acc: 0.6632\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.80560\n",
            "Epoch 280/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4337 - acc: 0.8660 - val_loss: 0.7526 - val_acc: 0.7860\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.80560\n",
            "Epoch 281/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4290 - acc: 0.8652 - val_loss: 0.7950 - val_acc: 0.7625\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.80560\n",
            "Epoch 282/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4369 - acc: 0.8646 - val_loss: 0.8883 - val_acc: 0.7520\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.80560\n",
            "Epoch 283/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4234 - acc: 0.8729 - val_loss: 1.3827 - val_acc: 0.6584\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.80560\n",
            "Epoch 284/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4468 - acc: 0.8641 - val_loss: 0.9741 - val_acc: 0.7238\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.80560\n",
            "Epoch 285/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4392 - acc: 0.8630 - val_loss: 1.1753 - val_acc: 0.6896\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.80560\n",
            "Epoch 286/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4422 - acc: 0.8620 - val_loss: 1.9851 - val_acc: 0.5790\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.80560\n",
            "Epoch 287/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4663 - acc: 0.8546 - val_loss: 0.8918 - val_acc: 0.7523\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.80560\n",
            "Epoch 288/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4133 - acc: 0.8736 - val_loss: 0.9592 - val_acc: 0.7283\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.80560\n",
            "Epoch 289/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4434 - acc: 0.8661 - val_loss: 1.2871 - val_acc: 0.6789\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.80560\n",
            "Epoch 290/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4320 - acc: 0.8692 - val_loss: 0.6702 - val_acc: 0.7973\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.80560\n",
            "Epoch 291/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4304 - acc: 0.8718 - val_loss: 0.8889 - val_acc: 0.7565\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.80560\n",
            "Epoch 292/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4253 - acc: 0.8707 - val_loss: 0.9012 - val_acc: 0.7310\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.80560\n",
            "Epoch 293/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4395 - acc: 0.8708 - val_loss: 0.9524 - val_acc: 0.7349\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.80560\n",
            "Epoch 294/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4566 - acc: 0.8576 - val_loss: 1.2981 - val_acc: 0.6541\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.80560\n",
            "Epoch 295/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4491 - acc: 0.8611 - val_loss: 1.2677 - val_acc: 0.6637\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.80560\n",
            "Epoch 296/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4521 - acc: 0.8686 - val_loss: 1.2379 - val_acc: 0.6761\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.80560\n",
            "Epoch 297/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4507 - acc: 0.8613 - val_loss: 1.0793 - val_acc: 0.7189\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.80560\n",
            "Epoch 298/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4459 - acc: 0.8620 - val_loss: 1.4759 - val_acc: 0.6374\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.80560\n",
            "Epoch 299/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4330 - acc: 0.8697 - val_loss: 1.0431 - val_acc: 0.7116\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.80560\n",
            "Epoch 300/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4429 - acc: 0.8628 - val_loss: 1.3420 - val_acc: 0.6546\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.80560\n",
            "Epoch 301/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4331 - acc: 0.8653 - val_loss: 0.9842 - val_acc: 0.7104\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.80560\n",
            "Epoch 302/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.4376 - acc: 0.8709 - val_loss: 0.7333 - val_acc: 0.7771\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.80560\n",
            "Epoch 303/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4436 - acc: 0.8656 - val_loss: 1.1645 - val_acc: 0.6815\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.80560\n",
            "Epoch 304/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4278 - acc: 0.8727 - val_loss: 1.1825 - val_acc: 0.6920\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.80560\n",
            "Epoch 305/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4537 - acc: 0.8641 - val_loss: 0.7038 - val_acc: 0.7949\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.80560\n",
            "Epoch 306/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4330 - acc: 0.8639 - val_loss: 0.9108 - val_acc: 0.7481\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.80560\n",
            "Epoch 307/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4351 - acc: 0.8658 - val_loss: 0.7427 - val_acc: 0.7682\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.80560\n",
            "Epoch 308/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4268 - acc: 0.8677 - val_loss: 1.0026 - val_acc: 0.7138\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.80560\n",
            "Epoch 309/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4377 - acc: 0.8660 - val_loss: 0.8039 - val_acc: 0.7632\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.80560\n",
            "Epoch 310/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4278 - acc: 0.8717 - val_loss: 0.8997 - val_acc: 0.7308\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.80560\n",
            "Epoch 311/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4347 - acc: 0.8725 - val_loss: 0.7335 - val_acc: 0.7748\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.80560\n",
            "Epoch 312/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4153 - acc: 0.8770 - val_loss: 0.8523 - val_acc: 0.7499\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.80560\n",
            "Epoch 313/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4147 - acc: 0.8775 - val_loss: 2.0113 - val_acc: 0.5671\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.80560\n",
            "Epoch 314/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4504 - acc: 0.8653 - val_loss: 1.0327 - val_acc: 0.7125\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.80560\n",
            "Epoch 315/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4287 - acc: 0.8736 - val_loss: 1.0378 - val_acc: 0.7137\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.80560\n",
            "Epoch 316/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4235 - acc: 0.8707 - val_loss: 1.0142 - val_acc: 0.7216\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.80560\n",
            "Epoch 317/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4263 - acc: 0.8726 - val_loss: 1.1437 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.80560\n",
            "Epoch 318/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4425 - acc: 0.8654 - val_loss: 1.3721 - val_acc: 0.6678\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.80560\n",
            "Epoch 319/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3987 - acc: 0.8850 - val_loss: 1.0385 - val_acc: 0.6902\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.80560\n",
            "Epoch 320/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4461 - acc: 0.8642 - val_loss: 0.9304 - val_acc: 0.7165\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.80560\n",
            "Epoch 321/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4339 - acc: 0.8678 - val_loss: 1.0937 - val_acc: 0.7163\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.80560\n",
            "Epoch 322/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4508 - acc: 0.8585 - val_loss: 1.3187 - val_acc: 0.6380\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.80560\n",
            "Epoch 323/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4199 - acc: 0.8752 - val_loss: 0.9055 - val_acc: 0.7470\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.80560\n",
            "Epoch 324/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4261 - acc: 0.8725 - val_loss: 2.2059 - val_acc: 0.4974\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.80560\n",
            "Epoch 325/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4157 - acc: 0.8769 - val_loss: 1.6234 - val_acc: 0.6505\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.80560\n",
            "Epoch 326/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4421 - acc: 0.8599 - val_loss: 1.4212 - val_acc: 0.6859\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.80560\n",
            "Epoch 327/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4378 - acc: 0.8637 - val_loss: 0.6179 - val_acc: 0.8249\n",
            "\n",
            "Epoch 00327: val_acc improved from 0.80560 to 0.82490, saving model to /content/saved_models/cifar10_ResNet32v1_model.327.h5\n",
            "Epoch 328/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4570 - acc: 0.8583 - val_loss: 1.1534 - val_acc: 0.6616\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.82490\n",
            "Epoch 329/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4300 - acc: 0.8621 - val_loss: 1.0686 - val_acc: 0.7207\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.82490\n",
            "Epoch 330/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4438 - acc: 0.8657 - val_loss: 1.1930 - val_acc: 0.6928\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.82490\n",
            "Epoch 331/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4445 - acc: 0.8689 - val_loss: 2.4978 - val_acc: 0.5173\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.82490\n",
            "Epoch 332/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4298 - acc: 0.8677 - val_loss: 2.0504 - val_acc: 0.5125\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.82490\n",
            "Epoch 333/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4311 - acc: 0.8663 - val_loss: 1.4010 - val_acc: 0.6457\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.82490\n",
            "Epoch 334/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4139 - acc: 0.8724 - val_loss: 0.8333 - val_acc: 0.7697\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.82490\n",
            "Epoch 335/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4323 - acc: 0.8640 - val_loss: 0.6387 - val_acc: 0.8101\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.82490\n",
            "Epoch 336/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4217 - acc: 0.8742 - val_loss: 1.3381 - val_acc: 0.6328\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.82490\n",
            "Epoch 337/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4495 - acc: 0.8633 - val_loss: 1.1482 - val_acc: 0.6834\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.82490\n",
            "Epoch 338/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.4320 - acc: 0.8718 - val_loss: 1.2635 - val_acc: 0.6669\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.82490\n",
            "Epoch 339/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4413 - acc: 0.8697 - val_loss: 0.9920 - val_acc: 0.7167\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.82490\n",
            "Epoch 340/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4112 - acc: 0.8785 - val_loss: 1.2122 - val_acc: 0.6957\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.82490\n",
            "Epoch 341/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4420 - acc: 0.8685 - val_loss: 0.6683 - val_acc: 0.7936\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.82490\n",
            "Epoch 342/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4321 - acc: 0.8701 - val_loss: 0.6893 - val_acc: 0.7937\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.82490\n",
            "Epoch 343/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.4159 - acc: 0.8733 - val_loss: 1.4930 - val_acc: 0.6440\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.82490\n",
            "Epoch 344/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4426 - acc: 0.8668 - val_loss: 2.0236 - val_acc: 0.5773\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.82490\n",
            "Epoch 345/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4295 - acc: 0.8723 - val_loss: 1.1873 - val_acc: 0.6737\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.82490\n",
            "Epoch 346/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4231 - acc: 0.8716 - val_loss: 0.8405 - val_acc: 0.7591\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.82490\n",
            "Epoch 347/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4200 - acc: 0.8718 - val_loss: 1.0004 - val_acc: 0.7215\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.82490\n",
            "Epoch 348/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4523 - acc: 0.8706 - val_loss: 0.8324 - val_acc: 0.7644\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.82490\n",
            "Epoch 349/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4284 - acc: 0.8701 - val_loss: 1.2706 - val_acc: 0.6862\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.82490\n",
            "Epoch 350/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4258 - acc: 0.8709 - val_loss: 1.7743 - val_acc: 0.6280\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.82490\n",
            "Epoch 351/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4441 - acc: 0.8602 - val_loss: 1.7968 - val_acc: 0.5659\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.82490\n",
            "Epoch 352/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4187 - acc: 0.8814 - val_loss: 0.8423 - val_acc: 0.7592\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.82490\n",
            "Epoch 353/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4097 - acc: 0.8697 - val_loss: 1.0106 - val_acc: 0.7299\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.82490\n",
            "Epoch 354/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4050 - acc: 0.8814 - val_loss: 0.7254 - val_acc: 0.7806\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.82490\n",
            "Epoch 355/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4372 - acc: 0.8709 - val_loss: 2.1858 - val_acc: 0.5305\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.82490\n",
            "Epoch 356/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4359 - acc: 0.8626 - val_loss: 1.1196 - val_acc: 0.6626\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.82490\n",
            "Epoch 357/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4092 - acc: 0.8783 - val_loss: 1.0700 - val_acc: 0.7135\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.82490\n",
            "Epoch 358/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4460 - acc: 0.8642 - val_loss: 1.1731 - val_acc: 0.7102\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.82490\n",
            "Epoch 359/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4196 - acc: 0.8696 - val_loss: 1.4195 - val_acc: 0.6109\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.82490\n",
            "Epoch 360/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4365 - acc: 0.8665 - val_loss: 2.0660 - val_acc: 0.5878\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.82490\n",
            "Epoch 361/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4524 - acc: 0.8617 - val_loss: 0.7398 - val_acc: 0.7844\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.82490\n",
            "Epoch 362/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4098 - acc: 0.8781 - val_loss: 0.8072 - val_acc: 0.7744\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.82490\n",
            "Epoch 363/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4161 - acc: 0.8738 - val_loss: 1.0344 - val_acc: 0.7188\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.82490\n",
            "Epoch 364/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4317 - acc: 0.8681 - val_loss: 0.6234 - val_acc: 0.8117\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.82490\n",
            "Epoch 365/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4163 - acc: 0.8716 - val_loss: 1.0677 - val_acc: 0.6880\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.82490\n",
            "Epoch 366/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4242 - acc: 0.8709 - val_loss: 1.1943 - val_acc: 0.6761\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.82490\n",
            "Epoch 367/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4022 - acc: 0.8804 - val_loss: 0.8122 - val_acc: 0.7774\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.82490\n",
            "Epoch 368/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4112 - acc: 0.8741 - val_loss: 1.2099 - val_acc: 0.6806\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.82490\n",
            "Epoch 369/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.4240 - acc: 0.8701 - val_loss: 1.0940 - val_acc: 0.7079\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.82490\n",
            "Epoch 370/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4440 - acc: 0.8650 - val_loss: 0.9884 - val_acc: 0.7284\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.82490\n",
            "Epoch 371/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4235 - acc: 0.8736 - val_loss: 0.9335 - val_acc: 0.7421\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.82490\n",
            "Epoch 372/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4290 - acc: 0.8691 - val_loss: 0.6799 - val_acc: 0.7848\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.82490\n",
            "Epoch 373/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4340 - acc: 0.8656 - val_loss: 2.5278 - val_acc: 0.4953\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.82490\n",
            "Epoch 374/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4552 - acc: 0.8588 - val_loss: 0.6722 - val_acc: 0.7910\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.82490\n",
            "Epoch 375/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4244 - acc: 0.8709 - val_loss: 0.7795 - val_acc: 0.7730\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.82490\n",
            "Epoch 376/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4326 - acc: 0.8695 - val_loss: 1.1923 - val_acc: 0.6663\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.82490\n",
            "Epoch 377/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4271 - acc: 0.8668 - val_loss: 0.8798 - val_acc: 0.7453\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.82490\n",
            "Epoch 378/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4065 - acc: 0.8787 - val_loss: 1.2230 - val_acc: 0.6815\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.82490\n",
            "Epoch 379/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.4267 - acc: 0.8725 - val_loss: 1.0207 - val_acc: 0.7430\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.82490\n",
            "Epoch 380/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4114 - acc: 0.8746 - val_loss: 1.5223 - val_acc: 0.6409\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.82490\n",
            "Epoch 381/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4532 - acc: 0.8628 - val_loss: 1.2862 - val_acc: 0.6786\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.82490\n",
            "Epoch 382/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4138 - acc: 0.8766 - val_loss: 0.9217 - val_acc: 0.7178\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.82490\n",
            "Epoch 383/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4166 - acc: 0.8726 - val_loss: 0.7506 - val_acc: 0.7661\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.82490\n",
            "Epoch 384/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4302 - acc: 0.8682 - val_loss: 0.9492 - val_acc: 0.7318\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.82490\n",
            "Epoch 385/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4289 - acc: 0.8664 - val_loss: 0.8556 - val_acc: 0.7443\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.82490\n",
            "Epoch 386/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4264 - acc: 0.8683 - val_loss: 0.8902 - val_acc: 0.7512\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.82490\n",
            "Epoch 387/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4274 - acc: 0.8720 - val_loss: 0.6395 - val_acc: 0.8001\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.82490\n",
            "Epoch 388/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4244 - acc: 0.8674 - val_loss: 1.1535 - val_acc: 0.6935\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.82490\n",
            "Epoch 389/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4378 - acc: 0.8657 - val_loss: 0.6996 - val_acc: 0.7947\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.82490\n",
            "Epoch 390/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4192 - acc: 0.8685 - val_loss: 1.0877 - val_acc: 0.7247\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.82490\n",
            "Epoch 391/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4119 - acc: 0.8760 - val_loss: 1.0407 - val_acc: 0.7164\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.82490\n",
            "Epoch 392/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4365 - acc: 0.8705 - val_loss: 0.9433 - val_acc: 0.7374\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.82490\n",
            "Epoch 393/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4131 - acc: 0.8740 - val_loss: 1.6400 - val_acc: 0.5864\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.82490\n",
            "Epoch 394/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4270 - acc: 0.8696 - val_loss: 1.2606 - val_acc: 0.6705\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.82490\n",
            "Epoch 395/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4267 - acc: 0.8713 - val_loss: 0.8629 - val_acc: 0.7460\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.82490\n",
            "Epoch 396/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4267 - acc: 0.8689 - val_loss: 0.9475 - val_acc: 0.7252\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.82490\n",
            "Epoch 397/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4064 - acc: 0.8778 - val_loss: 1.0721 - val_acc: 0.7170\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.82490\n",
            "Epoch 398/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3979 - acc: 0.8775 - val_loss: 2.0498 - val_acc: 0.5445\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.82490\n",
            "Epoch 399/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4355 - acc: 0.8627 - val_loss: 0.7403 - val_acc: 0.7990\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.82490\n",
            "Epoch 400/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4130 - acc: 0.8736 - val_loss: 0.8941 - val_acc: 0.7373\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.82490\n",
            "Epoch 401/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4186 - acc: 0.8710 - val_loss: 0.9654 - val_acc: 0.7238\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.82490\n",
            "Epoch 402/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3683 - acc: 0.8948 - val_loss: 0.3938 - val_acc: 0.8804\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.82490 to 0.88040, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3261 - acc: 0.9047 - val_loss: 0.3740 - val_acc: 0.8866\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.88040 to 0.88660, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2762 - acc: 0.9207 - val_loss: 0.3488 - val_acc: 0.8964\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.88660 to 0.89640, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.2858 - acc: 0.9201 - val_loss: 0.3623 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00405: val_acc did not improve from 0.89640\n",
            "Epoch 406/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2626 - acc: 0.9251 - val_loss: 0.3653 - val_acc: 0.8937\n",
            "\n",
            "Epoch 00406: val_acc did not improve from 0.89640\n",
            "Epoch 407/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2576 - acc: 0.9307 - val_loss: 0.3709 - val_acc: 0.8901\n",
            "\n",
            "Epoch 00407: val_acc did not improve from 0.89640\n",
            "Epoch 408/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2668 - acc: 0.9238 - val_loss: 0.3422 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00408: val_acc improved from 0.89640 to 0.89800, saving model to /content/saved_models/cifar10_ResNet32v1_model.408.h5\n",
            "Epoch 409/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2499 - acc: 0.9316 - val_loss: 0.3590 - val_acc: 0.8940\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.89800\n",
            "Epoch 410/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2556 - acc: 0.9294 - val_loss: 0.3318 - val_acc: 0.9012\n",
            "\n",
            "Epoch 00410: val_acc improved from 0.89800 to 0.90120, saving model to /content/saved_models/cifar10_ResNet32v1_model.410.h5\n",
            "Epoch 411/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2433 - acc: 0.9350 - val_loss: 0.3548 - val_acc: 0.8952\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.90120\n",
            "Epoch 412/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2365 - acc: 0.9315 - val_loss: 0.3432 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00412: val_acc did not improve from 0.90120\n",
            "Epoch 413/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2453 - acc: 0.9281 - val_loss: 0.3196 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00413: val_acc improved from 0.90120 to 0.90650, saving model to /content/saved_models/cifar10_ResNet32v1_model.413.h5\n",
            "Epoch 414/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2220 - acc: 0.9414 - val_loss: 0.3422 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.90650\n",
            "Epoch 415/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2328 - acc: 0.9354 - val_loss: 0.3469 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00415: val_acc did not improve from 0.90650\n",
            "Epoch 416/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2111 - acc: 0.9448 - val_loss: 0.3518 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.90650\n",
            "Epoch 417/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2245 - acc: 0.9384 - val_loss: 0.3331 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.90650\n",
            "Epoch 418/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2318 - acc: 0.9345 - val_loss: 0.3408 - val_acc: 0.9023\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.90650\n",
            "Epoch 419/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2096 - acc: 0.9429 - val_loss: 0.3193 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00419: val_acc improved from 0.90650 to 0.90670, saving model to /content/saved_models/cifar10_ResNet32v1_model.419.h5\n",
            "Epoch 420/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2225 - acc: 0.9361 - val_loss: 0.3171 - val_acc: 0.9079\n",
            "\n",
            "Epoch 00420: val_acc improved from 0.90670 to 0.90790, saving model to /content/saved_models/cifar10_ResNet32v1_model.420.h5\n",
            "Epoch 421/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2092 - acc: 0.9445 - val_loss: 0.3186 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00421: val_acc improved from 0.90790 to 0.90930, saving model to /content/saved_models/cifar10_ResNet32v1_model.421.h5\n",
            "Epoch 422/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2142 - acc: 0.9413 - val_loss: 0.3381 - val_acc: 0.9014\n",
            "\n",
            "Epoch 00422: val_acc did not improve from 0.90930\n",
            "Epoch 423/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2130 - acc: 0.9394 - val_loss: 0.3414 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.90930\n",
            "Epoch 424/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2164 - acc: 0.9407 - val_loss: 0.3185 - val_acc: 0.9081\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.90930\n",
            "Epoch 425/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2137 - acc: 0.9399 - val_loss: 0.3246 - val_acc: 0.9073\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.90930\n",
            "Epoch 426/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1931 - acc: 0.9511 - val_loss: 0.3223 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.90930\n",
            "Epoch 427/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1953 - acc: 0.9491 - val_loss: 0.3322 - val_acc: 0.9032\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.90930\n",
            "Epoch 428/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1905 - acc: 0.9483 - val_loss: 0.3303 - val_acc: 0.9060\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.90930\n",
            "Epoch 429/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2025 - acc: 0.9446 - val_loss: 0.3237 - val_acc: 0.9057\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.90930\n",
            "Epoch 430/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.2100 - acc: 0.9403 - val_loss: 0.3308 - val_acc: 0.9077\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.90930\n",
            "Epoch 431/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1908 - acc: 0.9451 - val_loss: 0.3300 - val_acc: 0.9053\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.90930\n",
            "Epoch 432/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1817 - acc: 0.9513 - val_loss: 0.3406 - val_acc: 0.9030\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.90930\n",
            "Epoch 433/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1821 - acc: 0.9519 - val_loss: 0.3516 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.90930\n",
            "Epoch 434/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1985 - acc: 0.9443 - val_loss: 0.3176 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00434: val_acc improved from 0.90930 to 0.91120, saving model to /content/saved_models/cifar10_ResNet32v1_model.434.h5\n",
            "Epoch 435/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1814 - acc: 0.9532 - val_loss: 0.3460 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.91120\n",
            "Epoch 436/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1798 - acc: 0.9521 - val_loss: 0.3287 - val_acc: 0.9041\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.91120\n",
            "Epoch 437/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1778 - acc: 0.9546 - val_loss: 0.3166 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00437: val_acc improved from 0.91120 to 0.91130, saving model to /content/saved_models/cifar10_ResNet32v1_model.437.h5\n",
            "Epoch 438/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1818 - acc: 0.9507 - val_loss: 0.3190 - val_acc: 0.9095\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.91130\n",
            "Epoch 439/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1941 - acc: 0.9493 - val_loss: 0.3273 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.91130\n",
            "Epoch 440/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1864 - acc: 0.9534 - val_loss: 0.3294 - val_acc: 0.9074\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.91130\n",
            "Epoch 441/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1922 - acc: 0.9491 - val_loss: 0.3123 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.91130\n",
            "Epoch 442/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1883 - acc: 0.9490 - val_loss: 0.3367 - val_acc: 0.9056\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.91130\n",
            "Epoch 443/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1816 - acc: 0.9548 - val_loss: 0.3299 - val_acc: 0.9071\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.91130\n",
            "Epoch 444/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1795 - acc: 0.9512 - val_loss: 0.3179 - val_acc: 0.9090\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.91130\n",
            "Epoch 445/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1820 - acc: 0.9522 - val_loss: 0.3284 - val_acc: 0.9090\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.91130\n",
            "Epoch 446/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1894 - acc: 0.9514 - val_loss: 0.3508 - val_acc: 0.9035\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.91130\n",
            "Epoch 447/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1730 - acc: 0.9529 - val_loss: 0.3235 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.91130\n",
            "Epoch 448/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1647 - acc: 0.9593 - val_loss: 0.3416 - val_acc: 0.9043\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.91130\n",
            "Epoch 449/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1778 - acc: 0.9533 - val_loss: 0.3200 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.91130\n",
            "Epoch 450/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1740 - acc: 0.9540 - val_loss: 0.3162 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.91130\n",
            "Epoch 451/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1684 - acc: 0.9575 - val_loss: 0.3314 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.91130\n",
            "Epoch 452/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1700 - acc: 0.9552 - val_loss: 0.3624 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.91130\n",
            "Epoch 453/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1651 - acc: 0.9582 - val_loss: 0.3391 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.91130\n",
            "Epoch 454/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1656 - acc: 0.9572 - val_loss: 0.3309 - val_acc: 0.9066\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.91130\n",
            "Epoch 455/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1708 - acc: 0.9567 - val_loss: 0.3316 - val_acc: 0.9094\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.91130\n",
            "Epoch 456/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1576 - acc: 0.9620 - val_loss: 0.3375 - val_acc: 0.9041\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.91130\n",
            "Epoch 457/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1501 - acc: 0.9634 - val_loss: 0.3435 - val_acc: 0.9060\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.91130\n",
            "Epoch 458/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1596 - acc: 0.9600 - val_loss: 0.3320 - val_acc: 0.9089\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.91130\n",
            "Epoch 459/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1604 - acc: 0.9568 - val_loss: 0.3484 - val_acc: 0.9032\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.91130\n",
            "Epoch 460/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1662 - acc: 0.9561 - val_loss: 0.3125 - val_acc: 0.9123\n",
            "\n",
            "Epoch 00460: val_acc improved from 0.91130 to 0.91230, saving model to /content/saved_models/cifar10_ResNet32v1_model.460.h5\n",
            "Epoch 461/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1583 - acc: 0.9582 - val_loss: 0.3225 - val_acc: 0.9106\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.91230\n",
            "Epoch 462/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1616 - acc: 0.9592 - val_loss: 0.3123 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00462: val_acc improved from 0.91230 to 0.91370, saving model to /content/saved_models/cifar10_ResNet32v1_model.462.h5\n",
            "Epoch 463/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1491 - acc: 0.9619 - val_loss: 0.3351 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.91370\n",
            "Epoch 464/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1598 - acc: 0.9594 - val_loss: 0.3286 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.91370\n",
            "Epoch 465/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1542 - acc: 0.9599 - val_loss: 0.3076 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00465: val_acc improved from 0.91370 to 0.91670, saving model to /content/saved_models/cifar10_ResNet32v1_model.465.h5\n",
            "Epoch 466/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1587 - acc: 0.9621 - val_loss: 0.3188 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.91670\n",
            "Epoch 467/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1527 - acc: 0.9610 - val_loss: 0.3071 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.91670\n",
            "Epoch 468/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1550 - acc: 0.9645 - val_loss: 0.3142 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.91670\n",
            "Epoch 469/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1457 - acc: 0.9645 - val_loss: 0.3494 - val_acc: 0.9032\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.91670\n",
            "Epoch 470/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1469 - acc: 0.9661 - val_loss: 0.3205 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.91670\n",
            "Epoch 471/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1492 - acc: 0.9630 - val_loss: 0.3419 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.91670\n",
            "Epoch 472/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1425 - acc: 0.9649 - val_loss: 0.3191 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.91670\n",
            "Epoch 473/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1421 - acc: 0.9658 - val_loss: 0.3224 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.91670\n",
            "Epoch 474/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1458 - acc: 0.9648 - val_loss: 0.3275 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.91670\n",
            "Epoch 475/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1366 - acc: 0.9660 - val_loss: 0.3272 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.91670\n",
            "Epoch 476/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1344 - acc: 0.9687 - val_loss: 0.3451 - val_acc: 0.9071\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.91670\n",
            "Epoch 477/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1423 - acc: 0.9640 - val_loss: 0.3446 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.91670\n",
            "Epoch 478/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1362 - acc: 0.9676 - val_loss: 0.3316 - val_acc: 0.9123\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.91670\n",
            "Epoch 479/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1422 - acc: 0.9658 - val_loss: 0.3131 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.91670\n",
            "Epoch 480/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1381 - acc: 0.9676 - val_loss: 0.3316 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.91670\n",
            "Epoch 481/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1425 - acc: 0.9642 - val_loss: 0.3493 - val_acc: 0.9047\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.91670\n",
            "Epoch 482/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1462 - acc: 0.9636 - val_loss: 0.2986 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00482: val_acc improved from 0.91670 to 0.91760, saving model to /content/saved_models/cifar10_ResNet32v1_model.482.h5\n",
            "Epoch 483/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1405 - acc: 0.9663 - val_loss: 0.3261 - val_acc: 0.9084\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.91760\n",
            "Epoch 484/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1461 - acc: 0.9620 - val_loss: 0.3087 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.91760\n",
            "Epoch 485/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1405 - acc: 0.9656 - val_loss: 0.3432 - val_acc: 0.9083\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.91760\n",
            "Epoch 486/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1408 - acc: 0.9669 - val_loss: 0.3402 - val_acc: 0.9068\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.91760\n",
            "Epoch 487/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1307 - acc: 0.9693 - val_loss: 0.3324 - val_acc: 0.9114\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.91760\n",
            "Epoch 488/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1385 - acc: 0.9652 - val_loss: 0.3327 - val_acc: 0.9085\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.91760\n",
            "Epoch 489/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1420 - acc: 0.9635 - val_loss: 0.3243 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.91760\n",
            "Epoch 490/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1350 - acc: 0.9680 - val_loss: 0.3062 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.91760\n",
            "Epoch 491/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1254 - acc: 0.9707 - val_loss: 0.3167 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.91760\n",
            "Epoch 492/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1374 - acc: 0.9653 - val_loss: 0.3179 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.91760\n",
            "Epoch 493/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1339 - acc: 0.9680 - val_loss: 0.3244 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.91760\n",
            "Epoch 494/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1296 - acc: 0.9686 - val_loss: 0.3805 - val_acc: 0.9020\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.91760\n",
            "Epoch 495/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1325 - acc: 0.9671 - val_loss: 0.3418 - val_acc: 0.9079\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.91760\n",
            "Epoch 496/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1279 - acc: 0.9688 - val_loss: 0.3252 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.91760\n",
            "Epoch 497/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1272 - acc: 0.9721 - val_loss: 0.3370 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.91760\n",
            "Epoch 498/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1208 - acc: 0.9728 - val_loss: 0.3393 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.91760\n",
            "Epoch 499/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1265 - acc: 0.9704 - val_loss: 0.3433 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.91760\n",
            "Epoch 500/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1205 - acc: 0.9691 - val_loss: 0.3119 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.91760\n",
            "Epoch 501/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1283 - acc: 0.9718 - val_loss: 0.3270 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.91760\n",
            "Epoch 502/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1271 - acc: 0.9713 - val_loss: 0.3461 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.91760\n",
            "Epoch 503/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1231 - acc: 0.9727 - val_loss: 0.3251 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.91760\n",
            "Epoch 504/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1159 - acc: 0.9735 - val_loss: 0.3421 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.91760\n",
            "Epoch 505/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1245 - acc: 0.9703 - val_loss: 0.3374 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.91760\n",
            "Epoch 506/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1319 - acc: 0.9658 - val_loss: 0.3619 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.91760\n",
            "Epoch 507/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1228 - acc: 0.9718 - val_loss: 0.3429 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.91760\n",
            "Epoch 508/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1251 - acc: 0.9706 - val_loss: 0.3317 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.91760\n",
            "Epoch 509/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1264 - acc: 0.9672 - val_loss: 0.3744 - val_acc: 0.9050\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.91760\n",
            "Epoch 510/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1252 - acc: 0.9717 - val_loss: 0.3531 - val_acc: 0.9066\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.91760\n",
            "Epoch 511/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1201 - acc: 0.9734 - val_loss: 0.3343 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.91760\n",
            "Epoch 512/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1246 - acc: 0.9718 - val_loss: 0.4159 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.91760\n",
            "Epoch 513/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1235 - acc: 0.9702 - val_loss: 0.3342 - val_acc: 0.9141\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.91760\n",
            "Epoch 514/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1254 - acc: 0.9689 - val_loss: 0.3373 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.91760\n",
            "Epoch 515/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1206 - acc: 0.9722 - val_loss: 0.3222 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.91760\n",
            "Epoch 516/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1178 - acc: 0.9730 - val_loss: 0.3436 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.91760\n",
            "Epoch 517/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1175 - acc: 0.9732 - val_loss: 0.3280 - val_acc: 0.9153\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.91760\n",
            "Epoch 518/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1199 - acc: 0.9700 - val_loss: 0.3184 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.91760\n",
            "Epoch 519/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1203 - acc: 0.9720 - val_loss: 0.3232 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.91760\n",
            "Epoch 520/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1169 - acc: 0.9749 - val_loss: 0.3272 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.91760\n",
            "Epoch 521/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1198 - acc: 0.9733 - val_loss: 0.4072 - val_acc: 0.8957\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.91760\n",
            "Epoch 522/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1194 - acc: 0.9716 - val_loss: 0.3239 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.91760\n",
            "Epoch 523/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1160 - acc: 0.9756 - val_loss: 0.3658 - val_acc: 0.9085\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.91760\n",
            "Epoch 524/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1226 - acc: 0.9705 - val_loss: 0.3434 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.91760\n",
            "Epoch 525/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1174 - acc: 0.9756 - val_loss: 0.3365 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.91760\n",
            "Epoch 526/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1284 - acc: 0.9711 - val_loss: 0.3296 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.91760\n",
            "Epoch 527/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1194 - acc: 0.9750 - val_loss: 0.3367 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.91760\n",
            "Epoch 528/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1137 - acc: 0.9728 - val_loss: 0.3587 - val_acc: 0.9040\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.91760\n",
            "Epoch 529/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1089 - acc: 0.9772 - val_loss: 0.3403 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.91760\n",
            "Epoch 530/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1090 - acc: 0.9766 - val_loss: 0.3425 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.91760\n",
            "Epoch 531/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1127 - acc: 0.9737 - val_loss: 0.3459 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.91760\n",
            "Epoch 532/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1055 - acc: 0.9783 - val_loss: 0.3237 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.91760\n",
            "Epoch 533/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1082 - acc: 0.9777 - val_loss: 0.3328 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.91760\n",
            "Epoch 534/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1092 - acc: 0.9759 - val_loss: 0.3448 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.91760\n",
            "Epoch 535/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1133 - acc: 0.9760 - val_loss: 0.3537 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.91760\n",
            "Epoch 536/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1203 - acc: 0.9715 - val_loss: 0.3355 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.91760\n",
            "Epoch 537/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1108 - acc: 0.9755 - val_loss: 0.3349 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.91760\n",
            "Epoch 538/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1129 - acc: 0.9737 - val_loss: 0.3533 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.91760\n",
            "Epoch 539/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1104 - acc: 0.9758 - val_loss: 0.3481 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.91760\n",
            "Epoch 540/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1125 - acc: 0.9744 - val_loss: 0.3630 - val_acc: 0.9060\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.91760\n",
            "Epoch 541/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1092 - acc: 0.9755 - val_loss: 0.3811 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.91760\n",
            "Epoch 542/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1048 - acc: 0.9801 - val_loss: 0.3745 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.91760\n",
            "Epoch 543/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1126 - acc: 0.9716 - val_loss: 0.3268 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.91760\n",
            "Epoch 544/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1066 - acc: 0.9788 - val_loss: 0.3268 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.91760\n",
            "Epoch 545/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1083 - acc: 0.9762 - val_loss: 0.3367 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.91760\n",
            "Epoch 546/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1086 - acc: 0.9740 - val_loss: 0.3770 - val_acc: 0.9049\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.91760\n",
            "Epoch 547/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1147 - acc: 0.9725 - val_loss: 0.3398 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.91760\n",
            "Epoch 548/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1093 - acc: 0.9758 - val_loss: 0.3371 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.91760\n",
            "Epoch 549/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1085 - acc: 0.9735 - val_loss: 0.3581 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.91760\n",
            "Epoch 550/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1154 - acc: 0.9704 - val_loss: 0.3344 - val_acc: 0.9146\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.91760\n",
            "Epoch 551/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1062 - acc: 0.9772 - val_loss: 0.3516 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.91760\n",
            "Epoch 552/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0995 - acc: 0.9800 - val_loss: 0.3220 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.91760\n",
            "Epoch 553/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1052 - acc: 0.9756 - val_loss: 0.3623 - val_acc: 0.9078\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.91760\n",
            "Epoch 554/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1060 - acc: 0.9761 - val_loss: 0.3647 - val_acc: 0.9043\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.91760\n",
            "Epoch 555/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1140 - acc: 0.9748 - val_loss: 0.3502 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.91760\n",
            "Epoch 556/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1030 - acc: 0.9802 - val_loss: 0.3375 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.91760\n",
            "Epoch 557/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1035 - acc: 0.9781 - val_loss: 0.3478 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.91760\n",
            "Epoch 558/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1104 - acc: 0.9770 - val_loss: 0.3508 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.91760\n",
            "Epoch 559/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1132 - acc: 0.9740 - val_loss: 0.3573 - val_acc: 0.9096\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.91760\n",
            "Epoch 560/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1031 - acc: 0.9792 - val_loss: 0.3542 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.91760\n",
            "Epoch 561/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1077 - acc: 0.9774 - val_loss: 0.3643 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.91760\n",
            "Epoch 562/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0992 - acc: 0.9816 - val_loss: 0.3601 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.91760\n",
            "Epoch 563/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1083 - acc: 0.9744 - val_loss: 0.3660 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.91760\n",
            "Epoch 564/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1071 - acc: 0.9767 - val_loss: 0.3601 - val_acc: 0.9102\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.91760\n",
            "Epoch 565/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1060 - acc: 0.9767 - val_loss: 0.3321 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.91760\n",
            "Epoch 566/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1011 - acc: 0.9801 - val_loss: 0.3617 - val_acc: 0.9068\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.91760\n",
            "Epoch 567/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1068 - acc: 0.9768 - val_loss: 0.3373 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.91760\n",
            "Epoch 568/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1005 - acc: 0.9779 - val_loss: 0.3672 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.91760\n",
            "Epoch 569/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0935 - acc: 0.9804 - val_loss: 0.3535 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.91760\n",
            "Epoch 570/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1082 - acc: 0.9741 - val_loss: 0.3573 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.91760\n",
            "Epoch 571/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0999 - acc: 0.9786 - val_loss: 0.3475 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.91760\n",
            "Epoch 572/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1064 - acc: 0.9742 - val_loss: 0.3306 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00572: val_acc improved from 0.91760 to 0.91930, saving model to /content/saved_models/cifar10_ResNet32v1_model.572.h5\n",
            "Epoch 573/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0972 - acc: 0.9800 - val_loss: 0.3631 - val_acc: 0.9091\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.91930\n",
            "Epoch 574/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1063 - acc: 0.9776 - val_loss: 0.3611 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.91930\n",
            "Epoch 575/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1017 - acc: 0.9794 - val_loss: 0.3433 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.91930\n",
            "Epoch 576/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1060 - acc: 0.9746 - val_loss: 0.3470 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.91930\n",
            "Epoch 577/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0957 - acc: 0.9789 - val_loss: 0.3808 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.91930\n",
            "Epoch 578/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0980 - acc: 0.9803 - val_loss: 0.3506 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.91930\n",
            "Epoch 579/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0942 - acc: 0.9799 - val_loss: 0.3526 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.91930\n",
            "Epoch 580/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0981 - acc: 0.9794 - val_loss: 0.3735 - val_acc: 0.9056\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.91930\n",
            "Epoch 581/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0948 - acc: 0.9795 - val_loss: 0.3555 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.91930\n",
            "Epoch 582/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0994 - acc: 0.9790 - val_loss: 0.3658 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.91930\n",
            "Epoch 583/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1014 - acc: 0.9797 - val_loss: 0.3728 - val_acc: 0.9035\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.91930\n",
            "Epoch 584/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0879 - acc: 0.9828 - val_loss: 0.3644 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.91930\n",
            "Epoch 585/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0954 - acc: 0.9790 - val_loss: 0.3419 - val_acc: 0.9134\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.91930\n",
            "Epoch 586/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1027 - acc: 0.9760 - val_loss: 0.3513 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.91930\n",
            "Epoch 587/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1017 - acc: 0.9778 - val_loss: 0.4285 - val_acc: 0.8949\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.91930\n",
            "Epoch 588/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0959 - acc: 0.9796 - val_loss: 0.4158 - val_acc: 0.9007\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.91930\n",
            "Epoch 589/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1005 - acc: 0.9791 - val_loss: 0.3492 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.91930\n",
            "Epoch 590/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0933 - acc: 0.9802 - val_loss: 0.4137 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.91930\n",
            "Epoch 591/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1004 - acc: 0.9775 - val_loss: 0.3543 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.91930\n",
            "Epoch 592/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1004 - acc: 0.9764 - val_loss: 0.3561 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.91930\n",
            "Epoch 593/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0884 - acc: 0.9832 - val_loss: 0.3604 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.91930\n",
            "Epoch 594/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0994 - acc: 0.9790 - val_loss: 0.3387 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.91930\n",
            "Epoch 595/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0990 - acc: 0.9796 - val_loss: 0.3879 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.91930\n",
            "Epoch 596/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0903 - acc: 0.9825 - val_loss: 0.3856 - val_acc: 0.9094\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.91930\n",
            "Epoch 597/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0968 - acc: 0.9801 - val_loss: 0.3403 - val_acc: 0.9181\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.91930\n",
            "Epoch 598/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.1012 - acc: 0.9784 - val_loss: 0.3690 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.91930\n",
            "Epoch 599/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0950 - acc: 0.9817 - val_loss: 0.3549 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.91930\n",
            "Epoch 600/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0955 - acc: 0.9806 - val_loss: 0.3426 - val_acc: 0.9158\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.91930\n",
            "Epoch 601/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0878 - acc: 0.9828 - val_loss: 0.3889 - val_acc: 0.9039\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.91930\n",
            "Epoch 602/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0855 - acc: 0.9831 - val_loss: 0.3311 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00602: val_acc did not improve from 0.91930\n",
            "Epoch 603/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0845 - acc: 0.9849 - val_loss: 0.3224 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00603: val_acc improved from 0.91930 to 0.92020, saving model to /content/saved_models/cifar10_ResNet32v1_model.603.h5\n",
            "Epoch 604/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0798 - acc: 0.9880 - val_loss: 0.3193 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00604: val_acc did not improve from 0.92020\n",
            "Epoch 605/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0786 - acc: 0.9874 - val_loss: 0.3207 - val_acc: 0.9244\n",
            "\n",
            "Epoch 00605: val_acc improved from 0.92020 to 0.92440, saving model to /content/saved_models/cifar10_ResNet32v1_model.605.h5\n",
            "Epoch 606/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0756 - acc: 0.9883 - val_loss: 0.3157 - val_acc: 0.9234\n",
            "\n",
            "Epoch 00606: val_acc did not improve from 0.92440\n",
            "Epoch 607/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0813 - acc: 0.9853 - val_loss: 0.3138 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00607: val_acc did not improve from 0.92440\n",
            "Epoch 608/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0826 - acc: 0.9843 - val_loss: 0.3041 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00608: val_acc improved from 0.92440 to 0.92470, saving model to /content/saved_models/cifar10_ResNet32v1_model.608.h5\n",
            "Epoch 609/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0833 - acc: 0.9855 - val_loss: 0.3073 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00609: val_acc improved from 0.92470 to 0.92540, saving model to /content/saved_models/cifar10_ResNet32v1_model.609.h5\n",
            "Epoch 610/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0798 - acc: 0.9858 - val_loss: 0.3107 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00610: val_acc did not improve from 0.92540\n",
            "Epoch 611/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0727 - acc: 0.9904 - val_loss: 0.3097 - val_acc: 0.9240\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.92540\n",
            "Epoch 612/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0804 - acc: 0.9856 - val_loss: 0.3076 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00612: val_acc did not improve from 0.92540\n",
            "Epoch 613/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0785 - acc: 0.9882 - val_loss: 0.3046 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00613: val_acc did not improve from 0.92540\n",
            "Epoch 614/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0799 - acc: 0.9865 - val_loss: 0.3067 - val_acc: 0.9234\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.92540\n",
            "Epoch 615/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0748 - acc: 0.9885 - val_loss: 0.3068 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.92540\n",
            "Epoch 616/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0789 - acc: 0.9865 - val_loss: 0.3085 - val_acc: 0.9245\n",
            "\n",
            "Epoch 00616: val_acc did not improve from 0.92540\n",
            "Epoch 617/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0756 - acc: 0.9885 - val_loss: 0.3061 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.92540\n",
            "Epoch 618/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0742 - acc: 0.9885 - val_loss: 0.3037 - val_acc: 0.9264\n",
            "\n",
            "Epoch 00618: val_acc improved from 0.92540 to 0.92640, saving model to /content/saved_models/cifar10_ResNet32v1_model.618.h5\n",
            "Epoch 619/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0762 - acc: 0.9876 - val_loss: 0.3032 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00619: val_acc did not improve from 0.92640\n",
            "Epoch 620/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0732 - acc: 0.9897 - val_loss: 0.3065 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.92640\n",
            "Epoch 621/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0722 - acc: 0.9884 - val_loss: 0.3080 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00621: val_acc did not improve from 0.92640\n",
            "Epoch 622/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0754 - acc: 0.9887 - val_loss: 0.3058 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.92640\n",
            "Epoch 623/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0710 - acc: 0.9898 - val_loss: 0.3062 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.92640\n",
            "Epoch 624/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0715 - acc: 0.9920 - val_loss: 0.3055 - val_acc: 0.9245\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.92640\n",
            "Epoch 625/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.0707 - acc: 0.9894 - val_loss: 0.3077 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.92640\n",
            "Epoch 626/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0731 - acc: 0.9894 - val_loss: 0.3086 - val_acc: 0.9242\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.92640\n",
            "Epoch 627/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0694 - acc: 0.9904 - val_loss: 0.3088 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00627: val_acc did not improve from 0.92640\n",
            "Epoch 628/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0721 - acc: 0.9895 - val_loss: 0.3108 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00628: val_acc did not improve from 0.92640\n",
            "Epoch 629/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0736 - acc: 0.9892 - val_loss: 0.3082 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.92640\n",
            "Epoch 630/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0705 - acc: 0.9919 - val_loss: 0.3111 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00630: val_acc did not improve from 0.92640\n",
            "Epoch 631/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0664 - acc: 0.9928 - val_loss: 0.3085 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00631: val_acc did not improve from 0.92640\n",
            "Epoch 632/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0687 - acc: 0.9912 - val_loss: 0.3057 - val_acc: 0.9242\n",
            "\n",
            "Epoch 00632: val_acc did not improve from 0.92640\n",
            "Epoch 633/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0677 - acc: 0.9912 - val_loss: 0.3087 - val_acc: 0.9244\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.92640\n",
            "Epoch 634/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0716 - acc: 0.9902 - val_loss: 0.3099 - val_acc: 0.9236\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.92640\n",
            "Epoch 635/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0669 - acc: 0.9919 - val_loss: 0.3094 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.92640\n",
            "Epoch 636/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0681 - acc: 0.9913 - val_loss: 0.3141 - val_acc: 0.9245\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.92640\n",
            "Epoch 637/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0706 - acc: 0.9897 - val_loss: 0.3088 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00637: val_acc did not improve from 0.92640\n",
            "Epoch 638/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0727 - acc: 0.9891 - val_loss: 0.3126 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.92640\n",
            "Epoch 639/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0734 - acc: 0.9896 - val_loss: 0.3082 - val_acc: 0.9231\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.92640\n",
            "Epoch 640/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0718 - acc: 0.9902 - val_loss: 0.3101 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.92640\n",
            "Epoch 641/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0662 - acc: 0.9919 - val_loss: 0.3144 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.92640\n",
            "Epoch 642/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0677 - acc: 0.9920 - val_loss: 0.3127 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.92640\n",
            "Epoch 643/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0713 - acc: 0.9880 - val_loss: 0.3107 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.92640\n",
            "Epoch 644/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0691 - acc: 0.9908 - val_loss: 0.3115 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.92640\n",
            "Epoch 645/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0652 - acc: 0.9910 - val_loss: 0.3102 - val_acc: 0.9234\n",
            "\n",
            "Epoch 00645: val_acc did not improve from 0.92640\n",
            "Epoch 646/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0674 - acc: 0.9912 - val_loss: 0.3091 - val_acc: 0.9241\n",
            "\n",
            "Epoch 00646: val_acc did not improve from 0.92640\n",
            "Epoch 647/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0677 - acc: 0.9905 - val_loss: 0.3136 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00647: val_acc did not improve from 0.92640\n",
            "Epoch 648/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0684 - acc: 0.9902 - val_loss: 0.3120 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.92640\n",
            "Epoch 649/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0675 - acc: 0.9913 - val_loss: 0.3106 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.92640\n",
            "Epoch 650/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0729 - acc: 0.9871 - val_loss: 0.3121 - val_acc: 0.9236\n",
            "\n",
            "Epoch 00650: val_acc did not improve from 0.92640\n",
            "Epoch 651/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0654 - acc: 0.9906 - val_loss: 0.3098 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00651: val_acc did not improve from 0.92640\n",
            "Epoch 652/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0686 - acc: 0.9914 - val_loss: 0.3088 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00652: val_acc did not improve from 0.92640\n",
            "Epoch 653/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0698 - acc: 0.9901 - val_loss: 0.3117 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00653: val_acc did not improve from 0.92640\n",
            "Epoch 654/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0668 - acc: 0.9920 - val_loss: 0.3116 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00654: val_acc did not improve from 0.92640\n",
            "Epoch 655/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0696 - acc: 0.9909 - val_loss: 0.3083 - val_acc: 0.9245\n",
            "\n",
            "Epoch 00655: val_acc did not improve from 0.92640\n",
            "Epoch 656/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0675 - acc: 0.9913 - val_loss: 0.3102 - val_acc: 0.9233\n",
            "\n",
            "Epoch 00656: val_acc did not improve from 0.92640\n",
            "Epoch 657/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0681 - acc: 0.9919 - val_loss: 0.3144 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00657: val_acc did not improve from 0.92640\n",
            "Epoch 658/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0660 - acc: 0.9923 - val_loss: 0.3125 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00658: val_acc did not improve from 0.92640\n",
            "Epoch 659/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0648 - acc: 0.9912 - val_loss: 0.3116 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00659: val_acc did not improve from 0.92640\n",
            "Epoch 660/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0634 - acc: 0.9916 - val_loss: 0.3131 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00660: val_acc did not improve from 0.92640\n",
            "Epoch 661/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0683 - acc: 0.9911 - val_loss: 0.3107 - val_acc: 0.9244\n",
            "\n",
            "Epoch 00661: val_acc did not improve from 0.92640\n",
            "Epoch 662/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0691 - acc: 0.9918 - val_loss: 0.3124 - val_acc: 0.9244\n",
            "\n",
            "Epoch 00662: val_acc did not improve from 0.92640\n",
            "Epoch 663/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0643 - acc: 0.9912 - val_loss: 0.3132 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00663: val_acc did not improve from 0.92640\n",
            "Epoch 664/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0650 - acc: 0.9923 - val_loss: 0.3128 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00664: val_acc did not improve from 0.92640\n",
            "Epoch 665/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0677 - acc: 0.9908 - val_loss: 0.3092 - val_acc: 0.9244\n",
            "\n",
            "Epoch 00665: val_acc did not improve from 0.92640\n",
            "Epoch 666/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0673 - acc: 0.9907 - val_loss: 0.3125 - val_acc: 0.9262\n",
            "\n",
            "Epoch 00666: val_acc did not improve from 0.92640\n",
            "Epoch 667/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0662 - acc: 0.9918 - val_loss: 0.3103 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00667: val_acc did not improve from 0.92640\n",
            "Epoch 668/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0661 - acc: 0.9916 - val_loss: 0.3104 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00668: val_acc did not improve from 0.92640\n",
            "Epoch 669/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0642 - acc: 0.9932 - val_loss: 0.3120 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00669: val_acc did not improve from 0.92640\n",
            "Epoch 670/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0622 - acc: 0.9938 - val_loss: 0.3092 - val_acc: 0.9264\n",
            "\n",
            "Epoch 00670: val_acc did not improve from 0.92640\n",
            "Epoch 671/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0611 - acc: 0.9936 - val_loss: 0.3105 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00671: val_acc did not improve from 0.92640\n",
            "Epoch 672/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0695 - acc: 0.9895 - val_loss: 0.3109 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00672: val_acc did not improve from 0.92640\n",
            "Epoch 673/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0655 - acc: 0.9913 - val_loss: 0.3147 - val_acc: 0.9242\n",
            "\n",
            "Epoch 00673: val_acc did not improve from 0.92640\n",
            "Epoch 674/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0652 - acc: 0.9919 - val_loss: 0.3160 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00674: val_acc did not improve from 0.92640\n",
            "Epoch 675/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0613 - acc: 0.9941 - val_loss: 0.3159 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00675: val_acc did not improve from 0.92640\n",
            "Epoch 676/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0670 - acc: 0.9912 - val_loss: 0.3171 - val_acc: 0.9242\n",
            "\n",
            "Epoch 00676: val_acc did not improve from 0.92640\n",
            "Epoch 677/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0659 - acc: 0.9911 - val_loss: 0.3103 - val_acc: 0.9243\n",
            "\n",
            "Epoch 00677: val_acc did not improve from 0.92640\n",
            "Epoch 678/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0673 - acc: 0.9901 - val_loss: 0.3109 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00678: val_acc did not improve from 0.92640\n",
            "Epoch 679/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0605 - acc: 0.9938 - val_loss: 0.3125 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00679: val_acc did not improve from 0.92640\n",
            "Epoch 680/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0653 - acc: 0.9907 - val_loss: 0.3131 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00680: val_acc did not improve from 0.92640\n",
            "Epoch 681/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0678 - acc: 0.9901 - val_loss: 0.3123 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00681: val_acc did not improve from 0.92640\n",
            "Epoch 682/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0726 - acc: 0.9903 - val_loss: 0.3118 - val_acc: 0.9246\n",
            "\n",
            "Epoch 00682: val_acc did not improve from 0.92640\n",
            "Epoch 683/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0683 - acc: 0.9903 - val_loss: 0.3135 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00683: val_acc did not improve from 0.92640\n",
            "Epoch 684/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0659 - acc: 0.9927 - val_loss: 0.3112 - val_acc: 0.9246\n",
            "\n",
            "Epoch 00684: val_acc did not improve from 0.92640\n",
            "Epoch 685/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0668 - acc: 0.9911 - val_loss: 0.3127 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00685: val_acc did not improve from 0.92640\n",
            "Epoch 686/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0667 - acc: 0.9895 - val_loss: 0.3110 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00686: val_acc did not improve from 0.92640\n",
            "Epoch 687/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0642 - acc: 0.9923 - val_loss: 0.3108 - val_acc: 0.9246\n",
            "\n",
            "Epoch 00687: val_acc did not improve from 0.92640\n",
            "Epoch 688/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0623 - acc: 0.9935 - val_loss: 0.3133 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00688: val_acc did not improve from 0.92640\n",
            "Epoch 689/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0643 - acc: 0.9930 - val_loss: 0.3134 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00689: val_acc did not improve from 0.92640\n",
            "Epoch 690/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0643 - acc: 0.9925 - val_loss: 0.3149 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00690: val_acc did not improve from 0.92640\n",
            "Epoch 691/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0647 - acc: 0.9915 - val_loss: 0.3154 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00691: val_acc did not improve from 0.92640\n",
            "Epoch 692/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0639 - acc: 0.9924 - val_loss: 0.3202 - val_acc: 0.9242\n",
            "\n",
            "Epoch 00692: val_acc did not improve from 0.92640\n",
            "Epoch 693/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0626 - acc: 0.9919 - val_loss: 0.3165 - val_acc: 0.9240\n",
            "\n",
            "Epoch 00693: val_acc did not improve from 0.92640\n",
            "Epoch 694/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0606 - acc: 0.9943 - val_loss: 0.3152 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00694: val_acc did not improve from 0.92640\n",
            "Epoch 695/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0652 - acc: 0.9908 - val_loss: 0.3181 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00695: val_acc did not improve from 0.92640\n",
            "Epoch 696/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0638 - acc: 0.9926 - val_loss: 0.3204 - val_acc: 0.9225\n",
            "\n",
            "Epoch 00696: val_acc did not improve from 0.92640\n",
            "Epoch 697/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0633 - acc: 0.9928 - val_loss: 0.3162 - val_acc: 0.9241\n",
            "\n",
            "Epoch 00697: val_acc did not improve from 0.92640\n",
            "Epoch 698/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0655 - acc: 0.9918 - val_loss: 0.3185 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00698: val_acc did not improve from 0.92640\n",
            "Epoch 699/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0613 - acc: 0.9924 - val_loss: 0.3171 - val_acc: 0.9231\n",
            "\n",
            "Epoch 00699: val_acc did not improve from 0.92640\n",
            "Epoch 700/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0633 - acc: 0.9916 - val_loss: 0.3153 - val_acc: 0.9263\n",
            "\n",
            "Epoch 00700: val_acc did not improve from 0.92640\n",
            "Epoch 701/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0590 - acc: 0.9957 - val_loss: 0.3184 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00701: val_acc did not improve from 0.92640\n",
            "Epoch 702/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0598 - acc: 0.9938 - val_loss: 0.3178 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00702: val_acc did not improve from 0.92640\n",
            "Epoch 703/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0605 - acc: 0.9930 - val_loss: 0.3187 - val_acc: 0.9241\n",
            "\n",
            "Epoch 00703: val_acc did not improve from 0.92640\n",
            "Epoch 704/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0682 - acc: 0.9881 - val_loss: 0.3166 - val_acc: 0.9241\n",
            "\n",
            "Epoch 00704: val_acc did not improve from 0.92640\n",
            "Epoch 705/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0647 - acc: 0.9928 - val_loss: 0.3170 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00705: val_acc did not improve from 0.92640\n",
            "Epoch 706/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0631 - acc: 0.9930 - val_loss: 0.3180 - val_acc: 0.9246\n",
            "\n",
            "Epoch 00706: val_acc did not improve from 0.92640\n",
            "Epoch 707/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0606 - acc: 0.9941 - val_loss: 0.3170 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00707: val_acc did not improve from 0.92640\n",
            "Epoch 708/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0598 - acc: 0.9939 - val_loss: 0.3177 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00708: val_acc did not improve from 0.92640\n",
            "Epoch 709/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0606 - acc: 0.9929 - val_loss: 0.3159 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00709: val_acc did not improve from 0.92640\n",
            "Epoch 710/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0634 - acc: 0.9913 - val_loss: 0.3184 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00710: val_acc did not improve from 0.92640\n",
            "Epoch 711/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0617 - acc: 0.9931 - val_loss: 0.3170 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00711: val_acc did not improve from 0.92640\n",
            "Epoch 712/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0605 - acc: 0.9937 - val_loss: 0.3162 - val_acc: 0.9241\n",
            "\n",
            "Epoch 00712: val_acc did not improve from 0.92640\n",
            "Epoch 713/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0570 - acc: 0.9945 - val_loss: 0.3155 - val_acc: 0.9236\n",
            "\n",
            "Epoch 00713: val_acc did not improve from 0.92640\n",
            "Epoch 714/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0631 - acc: 0.9917 - val_loss: 0.3166 - val_acc: 0.9236\n",
            "\n",
            "Epoch 00714: val_acc did not improve from 0.92640\n",
            "Epoch 715/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0603 - acc: 0.9936 - val_loss: 0.3165 - val_acc: 0.9261\n",
            "\n",
            "Epoch 00715: val_acc did not improve from 0.92640\n",
            "Epoch 716/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0601 - acc: 0.9926 - val_loss: 0.3134 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00716: val_acc did not improve from 0.92640\n",
            "Epoch 717/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0625 - acc: 0.9928 - val_loss: 0.3176 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00717: val_acc did not improve from 0.92640\n",
            "Epoch 718/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0647 - acc: 0.9912 - val_loss: 0.3124 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00718: val_acc did not improve from 0.92640\n",
            "Epoch 719/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0592 - acc: 0.9935 - val_loss: 0.3144 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00719: val_acc did not improve from 0.92640\n",
            "Epoch 720/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0620 - acc: 0.9932 - val_loss: 0.3159 - val_acc: 0.9244\n",
            "\n",
            "Epoch 00720: val_acc did not improve from 0.92640\n",
            "Epoch 721/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0581 - acc: 0.9944 - val_loss: 0.3151 - val_acc: 0.9245\n",
            "\n",
            "Epoch 00721: val_acc did not improve from 0.92640\n",
            "Epoch 722/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0602 - acc: 0.9945 - val_loss: 0.3143 - val_acc: 0.9268\n",
            "\n",
            "Epoch 00722: val_acc improved from 0.92640 to 0.92680, saving model to /content/saved_models/cifar10_ResNet32v1_model.722.h5\n",
            "Epoch 723/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0592 - acc: 0.9943 - val_loss: 0.3164 - val_acc: 0.9262\n",
            "\n",
            "Epoch 00723: val_acc did not improve from 0.92680\n",
            "Epoch 724/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0584 - acc: 0.9941 - val_loss: 0.3196 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00724: val_acc did not improve from 0.92680\n",
            "Epoch 725/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0653 - acc: 0.9917 - val_loss: 0.3175 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00725: val_acc did not improve from 0.92680\n",
            "Epoch 726/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0583 - acc: 0.9940 - val_loss: 0.3208 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00726: val_acc did not improve from 0.92680\n",
            "Epoch 727/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0584 - acc: 0.9943 - val_loss: 0.3190 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00727: val_acc did not improve from 0.92680\n",
            "Epoch 728/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0588 - acc: 0.9946 - val_loss: 0.3158 - val_acc: 0.9240\n",
            "\n",
            "Epoch 00728: val_acc did not improve from 0.92680\n",
            "Epoch 729/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0610 - acc: 0.9929 - val_loss: 0.3165 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00729: val_acc did not improve from 0.92680\n",
            "Epoch 730/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0676 - acc: 0.9904 - val_loss: 0.3188 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00730: val_acc did not improve from 0.92680\n",
            "Epoch 731/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0604 - acc: 0.9934 - val_loss: 0.3160 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00731: val_acc did not improve from 0.92680\n",
            "Epoch 732/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0606 - acc: 0.9926 - val_loss: 0.3176 - val_acc: 0.9245\n",
            "\n",
            "Epoch 00732: val_acc did not improve from 0.92680\n",
            "Epoch 733/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0629 - acc: 0.9913 - val_loss: 0.3160 - val_acc: 0.9268\n",
            "\n",
            "Epoch 00733: val_acc did not improve from 0.92680\n",
            "Epoch 734/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0618 - acc: 0.9918 - val_loss: 0.3179 - val_acc: 0.9246\n",
            "\n",
            "Epoch 00734: val_acc did not improve from 0.92680\n",
            "Epoch 735/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0602 - acc: 0.9929 - val_loss: 0.3188 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00735: val_acc did not improve from 0.92680\n",
            "Epoch 736/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0571 - acc: 0.9953 - val_loss: 0.3228 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00736: val_acc did not improve from 0.92680\n",
            "Epoch 737/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0586 - acc: 0.9931 - val_loss: 0.3238 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00737: val_acc did not improve from 0.92680\n",
            "Epoch 738/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0586 - acc: 0.9946 - val_loss: 0.3217 - val_acc: 0.9262\n",
            "\n",
            "Epoch 00738: val_acc did not improve from 0.92680\n",
            "Epoch 739/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0602 - acc: 0.9930 - val_loss: 0.3213 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00739: val_acc did not improve from 0.92680\n",
            "Epoch 740/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0597 - acc: 0.9916 - val_loss: 0.3221 - val_acc: 0.9246\n",
            "\n",
            "Epoch 00740: val_acc did not improve from 0.92680\n",
            "Epoch 741/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0588 - acc: 0.9931 - val_loss: 0.3188 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00741: val_acc did not improve from 0.92680\n",
            "Epoch 742/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0617 - acc: 0.9922 - val_loss: 0.3207 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00742: val_acc did not improve from 0.92680\n",
            "Epoch 743/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0582 - acc: 0.9938 - val_loss: 0.3209 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00743: val_acc did not improve from 0.92680\n",
            "Epoch 744/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0610 - acc: 0.9935 - val_loss: 0.3211 - val_acc: 0.9243\n",
            "\n",
            "Epoch 00744: val_acc did not improve from 0.92680\n",
            "Epoch 745/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0595 - acc: 0.9932 - val_loss: 0.3185 - val_acc: 0.9244\n",
            "\n",
            "Epoch 00745: val_acc did not improve from 0.92680\n",
            "Epoch 746/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0578 - acc: 0.9941 - val_loss: 0.3235 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00746: val_acc did not improve from 0.92680\n",
            "Epoch 747/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0577 - acc: 0.9949 - val_loss: 0.3244 - val_acc: 0.9244\n",
            "\n",
            "Epoch 00747: val_acc did not improve from 0.92680\n",
            "Epoch 748/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0605 - acc: 0.9934 - val_loss: 0.3226 - val_acc: 0.9236\n",
            "\n",
            "Epoch 00748: val_acc did not improve from 0.92680\n",
            "Epoch 749/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0595 - acc: 0.9932 - val_loss: 0.3249 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00749: val_acc did not improve from 0.92680\n",
            "Epoch 750/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0607 - acc: 0.9932 - val_loss: 0.3251 - val_acc: 0.9236\n",
            "\n",
            "Epoch 00750: val_acc did not improve from 0.92680\n",
            "Epoch 751/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0564 - acc: 0.9954 - val_loss: 0.3228 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00751: val_acc did not improve from 0.92680\n",
            "Epoch 752/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0585 - acc: 0.9941 - val_loss: 0.3222 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00752: val_acc did not improve from 0.92680\n",
            "Epoch 753/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0613 - acc: 0.9929 - val_loss: 0.3241 - val_acc: 0.9242\n",
            "\n",
            "Epoch 00753: val_acc did not improve from 0.92680\n",
            "Epoch 754/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0582 - acc: 0.9940 - val_loss: 0.3207 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00754: val_acc did not improve from 0.92680\n",
            "Epoch 755/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0585 - acc: 0.9940 - val_loss: 0.3188 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00755: val_acc did not improve from 0.92680\n",
            "Epoch 756/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0548 - acc: 0.9963 - val_loss: 0.3260 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00756: val_acc did not improve from 0.92680\n",
            "Epoch 757/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0580 - acc: 0.9927 - val_loss: 0.3178 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00757: val_acc did not improve from 0.92680\n",
            "Epoch 758/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0605 - acc: 0.9915 - val_loss: 0.3220 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00758: val_acc did not improve from 0.92680\n",
            "Epoch 759/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0591 - acc: 0.9938 - val_loss: 0.3254 - val_acc: 0.9236\n",
            "\n",
            "Epoch 00759: val_acc did not improve from 0.92680\n",
            "Epoch 760/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0616 - acc: 0.9924 - val_loss: 0.3243 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00760: val_acc did not improve from 0.92680\n",
            "Epoch 761/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0565 - acc: 0.9941 - val_loss: 0.3264 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00761: val_acc did not improve from 0.92680\n",
            "Epoch 762/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0574 - acc: 0.9945 - val_loss: 0.3280 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00762: val_acc did not improve from 0.92680\n",
            "Epoch 763/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0598 - acc: 0.9940 - val_loss: 0.3291 - val_acc: 0.9240\n",
            "\n",
            "Epoch 00763: val_acc did not improve from 0.92680\n",
            "Epoch 764/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0606 - acc: 0.9920 - val_loss: 0.3249 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00764: val_acc did not improve from 0.92680\n",
            "Epoch 765/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0577 - acc: 0.9939 - val_loss: 0.3230 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00765: val_acc did not improve from 0.92680\n",
            "Epoch 766/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0641 - acc: 0.9908 - val_loss: 0.3212 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00766: val_acc did not improve from 0.92680\n",
            "Epoch 767/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0575 - acc: 0.9928 - val_loss: 0.3237 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00767: val_acc did not improve from 0.92680\n",
            "Epoch 768/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0609 - acc: 0.9912 - val_loss: 0.3261 - val_acc: 0.9243\n",
            "\n",
            "Epoch 00768: val_acc did not improve from 0.92680\n",
            "Epoch 769/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0552 - acc: 0.9951 - val_loss: 0.3261 - val_acc: 0.9242\n",
            "\n",
            "Epoch 00769: val_acc did not improve from 0.92680\n",
            "Epoch 770/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0564 - acc: 0.9947 - val_loss: 0.3250 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00770: val_acc did not improve from 0.92680\n",
            "Epoch 771/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0555 - acc: 0.9956 - val_loss: 0.3222 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00771: val_acc did not improve from 0.92680\n",
            "Epoch 772/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0552 - acc: 0.9958 - val_loss: 0.3264 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00772: val_acc did not improve from 0.92680\n",
            "Epoch 773/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0581 - acc: 0.9937 - val_loss: 0.3241 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00773: val_acc did not improve from 0.92680\n",
            "Epoch 774/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0593 - acc: 0.9929 - val_loss: 0.3238 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00774: val_acc did not improve from 0.92680\n",
            "Epoch 775/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0586 - acc: 0.9934 - val_loss: 0.3213 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00775: val_acc did not improve from 0.92680\n",
            "Epoch 776/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0567 - acc: 0.9950 - val_loss: 0.3224 - val_acc: 0.9261\n",
            "\n",
            "Epoch 00776: val_acc did not improve from 0.92680\n",
            "Epoch 777/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0612 - acc: 0.9922 - val_loss: 0.3273 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00777: val_acc did not improve from 0.92680\n",
            "Epoch 778/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0579 - acc: 0.9946 - val_loss: 0.3278 - val_acc: 0.9241\n",
            "\n",
            "Epoch 00778: val_acc did not improve from 0.92680\n",
            "Epoch 779/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0586 - acc: 0.9938 - val_loss: 0.3291 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00779: val_acc did not improve from 0.92680\n",
            "Epoch 780/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0541 - acc: 0.9953 - val_loss: 0.3268 - val_acc: 0.9239\n",
            "\n",
            "Epoch 00780: val_acc did not improve from 0.92680\n",
            "Epoch 781/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0589 - acc: 0.9933 - val_loss: 0.3289 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00781: val_acc did not improve from 0.92680\n",
            "Epoch 782/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0564 - acc: 0.9943 - val_loss: 0.3235 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00782: val_acc did not improve from 0.92680\n",
            "Epoch 783/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0579 - acc: 0.9955 - val_loss: 0.3259 - val_acc: 0.9239\n",
            "\n",
            "Epoch 00783: val_acc did not improve from 0.92680\n",
            "Epoch 784/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0588 - acc: 0.9935 - val_loss: 0.3302 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00784: val_acc did not improve from 0.92680\n",
            "Epoch 785/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0574 - acc: 0.9940 - val_loss: 0.3253 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00785: val_acc did not improve from 0.92680\n",
            "Epoch 786/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0594 - acc: 0.9927 - val_loss: 0.3234 - val_acc: 0.9234\n",
            "\n",
            "Epoch 00786: val_acc did not improve from 0.92680\n",
            "Epoch 787/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0564 - acc: 0.9946 - val_loss: 0.3215 - val_acc: 0.9231\n",
            "\n",
            "Epoch 00787: val_acc did not improve from 0.92680\n",
            "Epoch 788/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0554 - acc: 0.9949 - val_loss: 0.3259 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00788: val_acc did not improve from 0.92680\n",
            "Epoch 789/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0572 - acc: 0.9940 - val_loss: 0.3266 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00789: val_acc did not improve from 0.92680\n",
            "Epoch 790/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0594 - acc: 0.9936 - val_loss: 0.3252 - val_acc: 0.9240\n",
            "\n",
            "Epoch 00790: val_acc did not improve from 0.92680\n",
            "Epoch 791/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0547 - acc: 0.9963 - val_loss: 0.3232 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00791: val_acc did not improve from 0.92680\n",
            "Epoch 792/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0575 - acc: 0.9945 - val_loss: 0.3226 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00792: val_acc did not improve from 0.92680\n",
            "Epoch 793/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0566 - acc: 0.9942 - val_loss: 0.3251 - val_acc: 0.9238\n",
            "\n",
            "Epoch 00793: val_acc did not improve from 0.92680\n",
            "Epoch 794/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0561 - acc: 0.9946 - val_loss: 0.3231 - val_acc: 0.9235\n",
            "\n",
            "Epoch 00794: val_acc did not improve from 0.92680\n",
            "Epoch 795/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0563 - acc: 0.9953 - val_loss: 0.3231 - val_acc: 0.9240\n",
            "\n",
            "Epoch 00795: val_acc did not improve from 0.92680\n",
            "Epoch 796/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0577 - acc: 0.9939 - val_loss: 0.3238 - val_acc: 0.9239\n",
            "\n",
            "Epoch 00796: val_acc did not improve from 0.92680\n",
            "Epoch 797/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0579 - acc: 0.9932 - val_loss: 0.3248 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00797: val_acc did not improve from 0.92680\n",
            "Epoch 798/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0566 - acc: 0.9941 - val_loss: 0.3259 - val_acc: 0.9234\n",
            "\n",
            "Epoch 00798: val_acc did not improve from 0.92680\n",
            "Epoch 799/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0552 - acc: 0.9948 - val_loss: 0.3287 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00799: val_acc did not improve from 0.92680\n",
            "Epoch 800/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0554 - acc: 0.9950 - val_loss: 0.3252 - val_acc: 0.9239\n",
            "\n",
            "Epoch 00800: val_acc did not improve from 0.92680\n",
            "Epoch 801/1000\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0584 - acc: 0.9926 - val_loss: 0.3291 - val_acc: 0.9241\n",
            "\n",
            "Epoch 00801: val_acc did not improve from 0.92680\n",
            "Epoch 802/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0553 - acc: 0.9942 - val_loss: 0.3262 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00802: val_acc did not improve from 0.92680\n",
            "Epoch 803/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0598 - acc: 0.9930 - val_loss: 0.3249 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00803: val_acc did not improve from 0.92680\n",
            "Epoch 804/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0599 - acc: 0.9920 - val_loss: 0.3246 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00804: val_acc did not improve from 0.92680\n",
            "Epoch 805/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0570 - acc: 0.9936 - val_loss: 0.3243 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00805: val_acc did not improve from 0.92680\n",
            "Epoch 806/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0569 - acc: 0.9930 - val_loss: 0.3230 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00806: val_acc did not improve from 0.92680\n",
            "Epoch 807/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0556 - acc: 0.9953 - val_loss: 0.3241 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00807: val_acc did not improve from 0.92680\n",
            "Epoch 808/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0589 - acc: 0.9937 - val_loss: 0.3233 - val_acc: 0.9245\n",
            "\n",
            "Epoch 00808: val_acc did not improve from 0.92680\n",
            "Epoch 809/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0551 - acc: 0.9951 - val_loss: 0.3229 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00809: val_acc did not improve from 0.92680\n",
            "Epoch 810/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0539 - acc: 0.9958 - val_loss: 0.3220 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00810: val_acc did not improve from 0.92680\n",
            "Epoch 811/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0568 - acc: 0.9951 - val_loss: 0.3223 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00811: val_acc did not improve from 0.92680\n",
            "Epoch 812/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0552 - acc: 0.9935 - val_loss: 0.3215 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00812: val_acc did not improve from 0.92680\n",
            "Epoch 813/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0575 - acc: 0.9938 - val_loss: 0.3216 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00813: val_acc did not improve from 0.92680\n",
            "Epoch 814/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0559 - acc: 0.9948 - val_loss: 0.3217 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00814: val_acc did not improve from 0.92680\n",
            "Epoch 815/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0574 - acc: 0.9941 - val_loss: 0.3211 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00815: val_acc did not improve from 0.92680\n",
            "Epoch 816/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0545 - acc: 0.9946 - val_loss: 0.3211 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00816: val_acc did not improve from 0.92680\n",
            "Epoch 817/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0578 - acc: 0.9947 - val_loss: 0.3206 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00817: val_acc did not improve from 0.92680\n",
            "Epoch 818/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0557 - acc: 0.9939 - val_loss: 0.3211 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00818: val_acc did not improve from 0.92680\n",
            "Epoch 819/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0552 - acc: 0.9954 - val_loss: 0.3213 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00819: val_acc did not improve from 0.92680\n",
            "Epoch 820/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0609 - acc: 0.9934 - val_loss: 0.3212 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00820: val_acc did not improve from 0.92680\n",
            "Epoch 821/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0546 - acc: 0.9955 - val_loss: 0.3218 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00821: val_acc did not improve from 0.92680\n",
            "Epoch 822/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0569 - acc: 0.9934 - val_loss: 0.3208 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00822: val_acc did not improve from 0.92680\n",
            "Epoch 823/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0551 - acc: 0.9944 - val_loss: 0.3209 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00823: val_acc did not improve from 0.92680\n",
            "Epoch 824/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0545 - acc: 0.9952 - val_loss: 0.3209 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00824: val_acc did not improve from 0.92680\n",
            "Epoch 825/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0592 - acc: 0.9931 - val_loss: 0.3216 - val_acc: 0.9261\n",
            "\n",
            "Epoch 00825: val_acc did not improve from 0.92680\n",
            "Epoch 826/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0555 - acc: 0.9952 - val_loss: 0.3222 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00826: val_acc did not improve from 0.92680\n",
            "Epoch 827/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0558 - acc: 0.9951 - val_loss: 0.3217 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00827: val_acc did not improve from 0.92680\n",
            "Epoch 828/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0560 - acc: 0.9940 - val_loss: 0.3215 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00828: val_acc did not improve from 0.92680\n",
            "Epoch 829/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0579 - acc: 0.9937 - val_loss: 0.3215 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00829: val_acc did not improve from 0.92680\n",
            "Epoch 830/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0571 - acc: 0.9941 - val_loss: 0.3222 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00830: val_acc did not improve from 0.92680\n",
            "Epoch 831/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0565 - acc: 0.9948 - val_loss: 0.3215 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00831: val_acc did not improve from 0.92680\n",
            "Epoch 832/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0558 - acc: 0.9949 - val_loss: 0.3210 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00832: val_acc did not improve from 0.92680\n",
            "Epoch 833/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0543 - acc: 0.9948 - val_loss: 0.3215 - val_acc: 0.9247\n",
            "\n",
            "Epoch 00833: val_acc did not improve from 0.92680\n",
            "Epoch 834/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0566 - acc: 0.9937 - val_loss: 0.3216 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00834: val_acc did not improve from 0.92680\n",
            "Epoch 835/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0544 - acc: 0.9964 - val_loss: 0.3218 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00835: val_acc did not improve from 0.92680\n",
            "Epoch 836/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0584 - acc: 0.9935 - val_loss: 0.3210 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00836: val_acc did not improve from 0.92680\n",
            "Epoch 837/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0541 - acc: 0.9957 - val_loss: 0.3219 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00837: val_acc did not improve from 0.92680\n",
            "Epoch 838/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0552 - acc: 0.9947 - val_loss: 0.3214 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00838: val_acc did not improve from 0.92680\n",
            "Epoch 839/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0570 - acc: 0.9933 - val_loss: 0.3220 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00839: val_acc did not improve from 0.92680\n",
            "Epoch 840/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0560 - acc: 0.9940 - val_loss: 0.3208 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00840: val_acc did not improve from 0.92680\n",
            "Epoch 841/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0520 - acc: 0.9970 - val_loss: 0.3212 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00841: val_acc did not improve from 0.92680\n",
            "Epoch 842/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0564 - acc: 0.9943 - val_loss: 0.3214 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00842: val_acc did not improve from 0.92680\n",
            "Epoch 843/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0526 - acc: 0.9960 - val_loss: 0.3213 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00843: val_acc did not improve from 0.92680\n",
            "Epoch 844/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0562 - acc: 0.9939 - val_loss: 0.3211 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00844: val_acc did not improve from 0.92680\n",
            "Epoch 845/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0549 - acc: 0.9953 - val_loss: 0.3220 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00845: val_acc did not improve from 0.92680\n",
            "Epoch 846/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0565 - acc: 0.9953 - val_loss: 0.3223 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00846: val_acc did not improve from 0.92680\n",
            "Epoch 847/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0567 - acc: 0.9945 - val_loss: 0.3221 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00847: val_acc did not improve from 0.92680\n",
            "Epoch 848/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0538 - acc: 0.9952 - val_loss: 0.3220 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00848: val_acc did not improve from 0.92680\n",
            "Epoch 849/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0538 - acc: 0.9956 - val_loss: 0.3214 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00849: val_acc did not improve from 0.92680\n",
            "Epoch 850/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0577 - acc: 0.9924 - val_loss: 0.3211 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00850: val_acc did not improve from 0.92680\n",
            "Epoch 851/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0561 - acc: 0.9947 - val_loss: 0.3208 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00851: val_acc did not improve from 0.92680\n",
            "Epoch 852/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0543 - acc: 0.9958 - val_loss: 0.3210 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00852: val_acc did not improve from 0.92680\n",
            "Epoch 853/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0562 - acc: 0.9944 - val_loss: 0.3212 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00853: val_acc did not improve from 0.92680\n",
            "Epoch 854/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0582 - acc: 0.9931 - val_loss: 0.3221 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00854: val_acc did not improve from 0.92680\n",
            "Epoch 855/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0522 - acc: 0.9962 - val_loss: 0.3215 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00855: val_acc did not improve from 0.92680\n",
            "Epoch 856/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0538 - acc: 0.9948 - val_loss: 0.3216 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00856: val_acc did not improve from 0.92680\n",
            "Epoch 857/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0566 - acc: 0.9933 - val_loss: 0.3209 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00857: val_acc did not improve from 0.92680\n",
            "Epoch 858/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0530 - acc: 0.9957 - val_loss: 0.3210 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00858: val_acc did not improve from 0.92680\n",
            "Epoch 859/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0540 - acc: 0.9955 - val_loss: 0.3208 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00859: val_acc did not improve from 0.92680\n",
            "Epoch 860/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0564 - acc: 0.9946 - val_loss: 0.3210 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00860: val_acc did not improve from 0.92680\n",
            "Epoch 861/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0554 - acc: 0.9950 - val_loss: 0.3206 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00861: val_acc did not improve from 0.92680\n",
            "Epoch 862/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0556 - acc: 0.9946 - val_loss: 0.3211 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00862: val_acc did not improve from 0.92680\n",
            "Epoch 863/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0546 - acc: 0.9948 - val_loss: 0.3210 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00863: val_acc did not improve from 0.92680\n",
            "Epoch 864/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0551 - acc: 0.9942 - val_loss: 0.3209 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00864: val_acc did not improve from 0.92680\n",
            "Epoch 865/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0554 - acc: 0.9942 - val_loss: 0.3208 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00865: val_acc did not improve from 0.92680\n",
            "Epoch 866/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0582 - acc: 0.9927 - val_loss: 0.3209 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00866: val_acc did not improve from 0.92680\n",
            "Epoch 867/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0562 - acc: 0.9948 - val_loss: 0.3224 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00867: val_acc did not improve from 0.92680\n",
            "Epoch 868/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0535 - acc: 0.9954 - val_loss: 0.3217 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00868: val_acc did not improve from 0.92680\n",
            "Epoch 869/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0552 - acc: 0.9949 - val_loss: 0.3212 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00869: val_acc did not improve from 0.92680\n",
            "Epoch 870/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0557 - acc: 0.9950 - val_loss: 0.3212 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00870: val_acc did not improve from 0.92680\n",
            "Epoch 871/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0523 - acc: 0.9955 - val_loss: 0.3219 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00871: val_acc did not improve from 0.92680\n",
            "Epoch 872/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0565 - acc: 0.9948 - val_loss: 0.3220 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00872: val_acc did not improve from 0.92680\n",
            "Epoch 873/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0587 - acc: 0.9934 - val_loss: 0.3221 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00873: val_acc did not improve from 0.92680\n",
            "Epoch 874/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0548 - acc: 0.9959 - val_loss: 0.3213 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00874: val_acc did not improve from 0.92680\n",
            "Epoch 875/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0550 - acc: 0.9949 - val_loss: 0.3210 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00875: val_acc did not improve from 0.92680\n",
            "Epoch 876/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0515 - acc: 0.9959 - val_loss: 0.3217 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00876: val_acc did not improve from 0.92680\n",
            "Epoch 877/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0522 - acc: 0.9955 - val_loss: 0.3219 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00877: val_acc did not improve from 0.92680\n",
            "Epoch 878/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0544 - acc: 0.9945 - val_loss: 0.3218 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00878: val_acc did not improve from 0.92680\n",
            "Epoch 879/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0545 - acc: 0.9941 - val_loss: 0.3209 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00879: val_acc did not improve from 0.92680\n",
            "Epoch 880/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0550 - acc: 0.9964 - val_loss: 0.3216 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00880: val_acc did not improve from 0.92680\n",
            "Epoch 881/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0542 - acc: 0.9954 - val_loss: 0.3216 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00881: val_acc did not improve from 0.92680\n",
            "Epoch 882/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0586 - acc: 0.9934 - val_loss: 0.3217 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00882: val_acc did not improve from 0.92680\n",
            "Epoch 883/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0532 - acc: 0.9951 - val_loss: 0.3228 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00883: val_acc did not improve from 0.92680\n",
            "Epoch 884/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0541 - acc: 0.9954 - val_loss: 0.3217 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00884: val_acc did not improve from 0.92680\n",
            "Epoch 885/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0553 - acc: 0.9949 - val_loss: 0.3217 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00885: val_acc did not improve from 0.92680\n",
            "Epoch 886/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0529 - acc: 0.9948 - val_loss: 0.3211 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00886: val_acc did not improve from 0.92680\n",
            "Epoch 887/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0543 - acc: 0.9962 - val_loss: 0.3210 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00887: val_acc did not improve from 0.92680\n",
            "Epoch 888/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0590 - acc: 0.9921 - val_loss: 0.3214 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00888: val_acc did not improve from 0.92680\n",
            "Epoch 889/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0536 - acc: 0.9958 - val_loss: 0.3212 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00889: val_acc did not improve from 0.92680\n",
            "Epoch 890/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0541 - acc: 0.9945 - val_loss: 0.3218 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00890: val_acc did not improve from 0.92680\n",
            "Epoch 891/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0545 - acc: 0.9949 - val_loss: 0.3216 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00891: val_acc did not improve from 0.92680\n",
            "Epoch 892/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0543 - acc: 0.9958 - val_loss: 0.3217 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00892: val_acc did not improve from 0.92680\n",
            "Epoch 893/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0552 - acc: 0.9944 - val_loss: 0.3223 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00893: val_acc did not improve from 0.92680\n",
            "Epoch 894/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0547 - acc: 0.9949 - val_loss: 0.3223 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00894: val_acc did not improve from 0.92680\n",
            "Epoch 895/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0562 - acc: 0.9938 - val_loss: 0.3222 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00895: val_acc did not improve from 0.92680\n",
            "Epoch 896/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0553 - acc: 0.9949 - val_loss: 0.3222 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00896: val_acc did not improve from 0.92680\n",
            "Epoch 897/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0577 - acc: 0.9927 - val_loss: 0.3225 - val_acc: 0.9239\n",
            "\n",
            "Epoch 00897: val_acc did not improve from 0.92680\n",
            "Epoch 898/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0563 - acc: 0.9941 - val_loss: 0.3215 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00898: val_acc did not improve from 0.92680\n",
            "Epoch 899/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0563 - acc: 0.9931 - val_loss: 0.3218 - val_acc: 0.9246\n",
            "\n",
            "Epoch 00899: val_acc did not improve from 0.92680\n",
            "Epoch 900/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0516 - acc: 0.9960 - val_loss: 0.3225 - val_acc: 0.9246\n",
            "\n",
            "Epoch 00900: val_acc did not improve from 0.92680\n",
            "Epoch 901/1000\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0547 - acc: 0.9951 - val_loss: 0.3225 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00901: val_acc did not improve from 0.92680\n",
            "Epoch 902/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0546 - acc: 0.9949 - val_loss: 0.3222 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00902: val_acc did not improve from 0.92680\n",
            "Epoch 903/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0533 - acc: 0.9955 - val_loss: 0.3219 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00903: val_acc did not improve from 0.92680\n",
            "Epoch 904/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0528 - acc: 0.9957 - val_loss: 0.3221 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00904: val_acc did not improve from 0.92680\n",
            "Epoch 905/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0546 - acc: 0.9929 - val_loss: 0.3234 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00905: val_acc did not improve from 0.92680\n",
            "Epoch 906/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0552 - acc: 0.9953 - val_loss: 0.3225 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00906: val_acc did not improve from 0.92680\n",
            "Epoch 907/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0544 - acc: 0.9947 - val_loss: 0.3223 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00907: val_acc did not improve from 0.92680\n",
            "Epoch 908/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0555 - acc: 0.9943 - val_loss: 0.3227 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00908: val_acc did not improve from 0.92680\n",
            "Epoch 909/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0566 - acc: 0.9933 - val_loss: 0.3220 - val_acc: 0.9262\n",
            "\n",
            "Epoch 00909: val_acc did not improve from 0.92680\n",
            "Epoch 910/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0547 - acc: 0.9948 - val_loss: 0.3226 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00910: val_acc did not improve from 0.92680\n",
            "Epoch 911/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0557 - acc: 0.9943 - val_loss: 0.3215 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00911: val_acc did not improve from 0.92680\n",
            "Epoch 912/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0543 - acc: 0.9949 - val_loss: 0.3222 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00912: val_acc did not improve from 0.92680\n",
            "Epoch 913/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0550 - acc: 0.9940 - val_loss: 0.3226 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00913: val_acc did not improve from 0.92680\n",
            "Epoch 914/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0534 - acc: 0.9951 - val_loss: 0.3221 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00914: val_acc did not improve from 0.92680\n",
            "Epoch 915/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0539 - acc: 0.9955 - val_loss: 0.3219 - val_acc: 0.9264\n",
            "\n",
            "Epoch 00915: val_acc did not improve from 0.92680\n",
            "Epoch 916/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0550 - acc: 0.9944 - val_loss: 0.3211 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00916: val_acc did not improve from 0.92680\n",
            "Epoch 917/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0566 - acc: 0.9936 - val_loss: 0.3218 - val_acc: 0.9262\n",
            "\n",
            "Epoch 00917: val_acc did not improve from 0.92680\n",
            "Epoch 918/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0560 - acc: 0.9943 - val_loss: 0.3221 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00918: val_acc did not improve from 0.92680\n",
            "Epoch 919/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0528 - acc: 0.9956 - val_loss: 0.3218 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00919: val_acc did not improve from 0.92680\n",
            "Epoch 920/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0548 - acc: 0.9954 - val_loss: 0.3221 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00920: val_acc did not improve from 0.92680\n",
            "Epoch 921/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0588 - acc: 0.9945 - val_loss: 0.3229 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00921: val_acc did not improve from 0.92680\n",
            "Epoch 922/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0550 - acc: 0.9949 - val_loss: 0.3217 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00922: val_acc did not improve from 0.92680\n",
            "Epoch 923/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0546 - acc: 0.9946 - val_loss: 0.3214 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00923: val_acc did not improve from 0.92680\n",
            "Epoch 924/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0518 - acc: 0.9963 - val_loss: 0.3220 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00924: val_acc did not improve from 0.92680\n",
            "Epoch 925/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0556 - acc: 0.9949 - val_loss: 0.3230 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00925: val_acc did not improve from 0.92680\n",
            "Epoch 926/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0524 - acc: 0.9963 - val_loss: 0.3222 - val_acc: 0.9261\n",
            "\n",
            "Epoch 00926: val_acc did not improve from 0.92680\n",
            "Epoch 927/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0537 - acc: 0.9961 - val_loss: 0.3211 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00927: val_acc did not improve from 0.92680\n",
            "Epoch 928/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0554 - acc: 0.9954 - val_loss: 0.3221 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00928: val_acc did not improve from 0.92680\n",
            "Epoch 929/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0533 - acc: 0.9946 - val_loss: 0.3219 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00929: val_acc did not improve from 0.92680\n",
            "Epoch 930/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0535 - acc: 0.9942 - val_loss: 0.3223 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00930: val_acc did not improve from 0.92680\n",
            "Epoch 931/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0533 - acc: 0.9961 - val_loss: 0.3233 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00931: val_acc did not improve from 0.92680\n",
            "Epoch 932/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0541 - acc: 0.9966 - val_loss: 0.3230 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00932: val_acc did not improve from 0.92680\n",
            "Epoch 933/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0589 - acc: 0.9930 - val_loss: 0.3218 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00933: val_acc did not improve from 0.92680\n",
            "Epoch 934/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0563 - acc: 0.9944 - val_loss: 0.3222 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00934: val_acc did not improve from 0.92680\n",
            "Epoch 935/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0577 - acc: 0.9941 - val_loss: 0.3223 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00935: val_acc did not improve from 0.92680\n",
            "Epoch 936/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0552 - acc: 0.9941 - val_loss: 0.3225 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00936: val_acc did not improve from 0.92680\n",
            "Epoch 937/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0567 - acc: 0.9936 - val_loss: 0.3224 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00937: val_acc did not improve from 0.92680\n",
            "Epoch 938/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0608 - acc: 0.9916 - val_loss: 0.3224 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00938: val_acc did not improve from 0.92680\n",
            "Epoch 939/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0556 - acc: 0.9942 - val_loss: 0.3223 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00939: val_acc did not improve from 0.92680\n",
            "Epoch 940/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.0543 - acc: 0.9954 - val_loss: 0.3220 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00940: val_acc did not improve from 0.92680\n",
            "Epoch 941/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0540 - acc: 0.9949 - val_loss: 0.3223 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00941: val_acc did not improve from 0.92680\n",
            "Epoch 942/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0565 - acc: 0.9928 - val_loss: 0.3224 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00942: val_acc did not improve from 0.92680\n",
            "Epoch 943/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0558 - acc: 0.9950 - val_loss: 0.3220 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00943: val_acc did not improve from 0.92680\n",
            "Epoch 944/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0539 - acc: 0.9951 - val_loss: 0.3219 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00944: val_acc did not improve from 0.92680\n",
            "Epoch 945/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0523 - acc: 0.9962 - val_loss: 0.3225 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00945: val_acc did not improve from 0.92680\n",
            "Epoch 946/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0563 - acc: 0.9936 - val_loss: 0.3231 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00946: val_acc did not improve from 0.92680\n",
            "Epoch 947/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0540 - acc: 0.9950 - val_loss: 0.3225 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00947: val_acc did not improve from 0.92680\n",
            "Epoch 948/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0523 - acc: 0.9961 - val_loss: 0.3221 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00948: val_acc did not improve from 0.92680\n",
            "Epoch 949/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0545 - acc: 0.9945 - val_loss: 0.3213 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00949: val_acc did not improve from 0.92680\n",
            "Epoch 950/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0538 - acc: 0.9956 - val_loss: 0.3210 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00950: val_acc did not improve from 0.92680\n",
            "Epoch 951/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0564 - acc: 0.9942 - val_loss: 0.3211 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00951: val_acc did not improve from 0.92680\n",
            "Epoch 952/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0596 - acc: 0.9921 - val_loss: 0.3217 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00952: val_acc did not improve from 0.92680\n",
            "Epoch 953/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0527 - acc: 0.9950 - val_loss: 0.3222 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00953: val_acc did not improve from 0.92680\n",
            "Epoch 954/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0575 - acc: 0.9947 - val_loss: 0.3217 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00954: val_acc did not improve from 0.92680\n",
            "Epoch 955/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0540 - acc: 0.9952 - val_loss: 0.3215 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00955: val_acc did not improve from 0.92680\n",
            "Epoch 956/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0552 - acc: 0.9951 - val_loss: 0.3217 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00956: val_acc did not improve from 0.92680\n",
            "Epoch 957/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0551 - acc: 0.9945 - val_loss: 0.3211 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00957: val_acc did not improve from 0.92680\n",
            "Epoch 958/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0534 - acc: 0.9952 - val_loss: 0.3213 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00958: val_acc did not improve from 0.92680\n",
            "Epoch 959/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0536 - acc: 0.9946 - val_loss: 0.3223 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00959: val_acc did not improve from 0.92680\n",
            "Epoch 960/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0549 - acc: 0.9953 - val_loss: 0.3218 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00960: val_acc did not improve from 0.92680\n",
            "Epoch 961/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0568 - acc: 0.9937 - val_loss: 0.3220 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00961: val_acc did not improve from 0.92680\n",
            "Epoch 962/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0551 - acc: 0.9953 - val_loss: 0.3220 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00962: val_acc did not improve from 0.92680\n",
            "Epoch 963/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0536 - acc: 0.9957 - val_loss: 0.3219 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00963: val_acc did not improve from 0.92680\n",
            "Epoch 964/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0542 - acc: 0.9952 - val_loss: 0.3226 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00964: val_acc did not improve from 0.92680\n",
            "Epoch 965/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0544 - acc: 0.9950 - val_loss: 0.3220 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00965: val_acc did not improve from 0.92680\n",
            "Epoch 966/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0517 - acc: 0.9963 - val_loss: 0.3227 - val_acc: 0.9262\n",
            "\n",
            "Epoch 00966: val_acc did not improve from 0.92680\n",
            "Epoch 967/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0538 - acc: 0.9955 - val_loss: 0.3221 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00967: val_acc did not improve from 0.92680\n",
            "Epoch 968/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0520 - acc: 0.9965 - val_loss: 0.3228 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00968: val_acc did not improve from 0.92680\n",
            "Epoch 969/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0537 - acc: 0.9948 - val_loss: 0.3213 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00969: val_acc did not improve from 0.92680\n",
            "Epoch 970/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0555 - acc: 0.9943 - val_loss: 0.3212 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00970: val_acc did not improve from 0.92680\n",
            "Epoch 971/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0556 - acc: 0.9949 - val_loss: 0.3217 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00971: val_acc did not improve from 0.92680\n",
            "Epoch 972/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0587 - acc: 0.9933 - val_loss: 0.3211 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00972: val_acc did not improve from 0.92680\n",
            "Epoch 973/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0524 - acc: 0.9953 - val_loss: 0.3218 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00973: val_acc did not improve from 0.92680\n",
            "Epoch 974/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0526 - acc: 0.9959 - val_loss: 0.3222 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00974: val_acc did not improve from 0.92680\n",
            "Epoch 975/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0528 - acc: 0.9962 - val_loss: 0.3222 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00975: val_acc did not improve from 0.92680\n",
            "Epoch 976/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0536 - acc: 0.9961 - val_loss: 0.3216 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00976: val_acc did not improve from 0.92680\n",
            "Epoch 977/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0593 - acc: 0.9945 - val_loss: 0.3222 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00977: val_acc did not improve from 0.92680\n",
            "Epoch 978/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0557 - acc: 0.9947 - val_loss: 0.3220 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00978: val_acc did not improve from 0.92680\n",
            "Epoch 979/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0543 - acc: 0.9955 - val_loss: 0.3223 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00979: val_acc did not improve from 0.92680\n",
            "Epoch 980/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0533 - acc: 0.9959 - val_loss: 0.3217 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00980: val_acc did not improve from 0.92680\n",
            "Epoch 981/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0523 - acc: 0.9963 - val_loss: 0.3217 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00981: val_acc did not improve from 0.92680\n",
            "Epoch 982/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0557 - acc: 0.9940 - val_loss: 0.3215 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00982: val_acc did not improve from 0.92680\n",
            "Epoch 983/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0533 - acc: 0.9944 - val_loss: 0.3223 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00983: val_acc did not improve from 0.92680\n",
            "Epoch 984/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0535 - acc: 0.9960 - val_loss: 0.3225 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00984: val_acc did not improve from 0.92680\n",
            "Epoch 985/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0557 - acc: 0.9950 - val_loss: 0.3227 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00985: val_acc did not improve from 0.92680\n",
            "Epoch 986/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0543 - acc: 0.9951 - val_loss: 0.3228 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00986: val_acc did not improve from 0.92680\n",
            "Epoch 987/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0536 - acc: 0.9957 - val_loss: 0.3220 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00987: val_acc did not improve from 0.92680\n",
            "Epoch 988/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0542 - acc: 0.9950 - val_loss: 0.3220 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00988: val_acc did not improve from 0.92680\n",
            "Epoch 989/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0508 - acc: 0.9972 - val_loss: 0.3219 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00989: val_acc did not improve from 0.92680\n",
            "Epoch 990/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0545 - acc: 0.9942 - val_loss: 0.3220 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00990: val_acc did not improve from 0.92680\n",
            "Epoch 991/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0540 - acc: 0.9953 - val_loss: 0.3228 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00991: val_acc did not improve from 0.92680\n",
            "Epoch 992/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0552 - acc: 0.9954 - val_loss: 0.3226 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00992: val_acc did not improve from 0.92680\n",
            "Epoch 993/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.0569 - acc: 0.9941 - val_loss: 0.3218 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00993: val_acc did not improve from 0.92680\n",
            "Epoch 994/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.0541 - acc: 0.9953 - val_loss: 0.3223 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00994: val_acc did not improve from 0.92680\n",
            "Epoch 995/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0568 - acc: 0.9937 - val_loss: 0.3225 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00995: val_acc did not improve from 0.92680\n",
            "Epoch 996/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0551 - acc: 0.9939 - val_loss: 0.3230 - val_acc: 0.9252\n",
            "\n",
            "Epoch 00996: val_acc did not improve from 0.92680\n",
            "Epoch 997/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0534 - acc: 0.9959 - val_loss: 0.3228 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00997: val_acc did not improve from 0.92680\n",
            "Epoch 998/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0554 - acc: 0.9941 - val_loss: 0.3228 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00998: val_acc did not improve from 0.92680\n",
            "Epoch 999/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0542 - acc: 0.9963 - val_loss: 0.3232 - val_acc: 0.9255\n",
            "\n",
            "Epoch 00999: val_acc did not improve from 0.92680\n",
            "Epoch 1000/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0550 - acc: 0.9959 - val_loss: 0.3228 - val_acc: 0.9253\n",
            "\n",
            "Epoch 01000: val_acc did not improve from 0.92680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "4pcLscHEEYsd",
        "outputId": "fbf6c2ab-f772-452d-8275-8961cca6afd6"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('simple_trainHistoryDict_clip_1', \"rb\"))\n",
        "functions.plot_loss_acc(history, 2, 0.4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uhRD_zK5NN1",
        "outputId": "071d143f-13fa-4b38-e103-c4c5415e816b"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9253000020980835"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsdFJk6P0Eex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3256d5-916f-4795-eb8a-328e1872e52f"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0746999979019165"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GGdi8wX0XLv"
      },
      "source": [
        "#### Model with modified clipping to 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urjr4ymC0jsZ",
        "outputId": "c22d20f7-5333-420b-8b16-56999d834dff"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJiCm9De0nNc",
        "outputId": "1a66f2b8-5bc8-4290-b9db-747435200ad2"
      },
      "source": [
        "callbacks = functions.standard_callbacks(model_type) + [functions.Clipping(0.5, \"trying\")]\n",
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'trying_trainHistoryDict_clip_05', steps_per_epoch=100, epochs=1000,\n",
        "                       batch_size=100,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Learning rate:  0.001\n",
            "  6/100 [>.............................] - ETA: 15s - loss: 5.5774 - acc: 0.1197WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0653s vs `on_train_batch_end` time: 0.1002s). Check your callbacks.\n",
            "100/100 [==============================] - 26s 204ms/step - loss: 2.9372 - acc: 0.2282 - val_loss: 2.2165 - val_acc: 0.2749\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.27490, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 1.9781 - acc: 0.2704 - val_loss: 3.4221 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.27490\n",
            "Epoch 3/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 1.7437 - acc: 0.3531 - val_loss: 3.8289 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.27490\n",
            "Epoch 4/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 1.5860 - acc: 0.4311 - val_loss: 3.8588 - val_acc: 0.1059\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.27490\n",
            "Epoch 5/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 1.4923 - acc: 0.4681 - val_loss: 3.9752 - val_acc: 0.1478\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.27490\n",
            "Epoch 6/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 1.4042 - acc: 0.5022 - val_loss: 1.4707 - val_acc: 0.5109\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.27490 to 0.51090, saving model to /content/saved_models/cifar10_ResNet32v1_model.006.h5\n",
            "Epoch 7/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 1.3041 - acc: 0.5345 - val_loss: 7.6177 - val_acc: 0.2125\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.51090\n",
            "Epoch 8/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 1.2485 - acc: 0.5533 - val_loss: 9.9088 - val_acc: 0.1307\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.51090\n",
            "Epoch 9/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 1.2428 - acc: 0.5644 - val_loss: 2.9409 - val_acc: 0.3998\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.51090\n",
            "Epoch 10/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 1.1544 - acc: 0.5966 - val_loss: 3.1240 - val_acc: 0.3339\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.51090\n",
            "Epoch 11/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 1.0936 - acc: 0.6265 - val_loss: 2.4536 - val_acc: 0.4446\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.51090\n",
            "Epoch 12/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 1.0699 - acc: 0.6230 - val_loss: 5.5066 - val_acc: 0.2908\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.51090\n",
            "Epoch 13/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 1.0484 - acc: 0.6367 - val_loss: 14.4787 - val_acc: 0.1090\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.51090\n",
            "Epoch 14/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 1.0477 - acc: 0.6339 - val_loss: 4.0803 - val_acc: 0.3217\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.51090\n",
            "Epoch 15/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 1.0278 - acc: 0.6471 - val_loss: 4.5117 - val_acc: 0.2905\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.51090\n",
            "Epoch 16/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 1.0105 - acc: 0.6514 - val_loss: 2.7213 - val_acc: 0.4254\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.51090\n",
            "Epoch 17/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 1.0008 - acc: 0.6548 - val_loss: 3.3375 - val_acc: 0.3527\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.51090\n",
            "Epoch 18/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.9937 - acc: 0.6630 - val_loss: 3.1670 - val_acc: 0.3632\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.51090\n",
            "Epoch 19/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.9452 - acc: 0.6774 - val_loss: 2.2181 - val_acc: 0.4769\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.51090\n",
            "Epoch 20/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.9321 - acc: 0.6828 - val_loss: 2.1110 - val_acc: 0.4859\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.51090\n",
            "Epoch 21/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.9276 - acc: 0.6914 - val_loss: 4.6547 - val_acc: 0.3124\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.51090\n",
            "Epoch 22/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.9272 - acc: 0.6797 - val_loss: 2.8200 - val_acc: 0.4379\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.51090\n",
            "Epoch 23/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.9092 - acc: 0.6934 - val_loss: 4.1888 - val_acc: 0.3731\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.51090\n",
            "Epoch 24/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.9196 - acc: 0.6897 - val_loss: 2.7292 - val_acc: 0.4393\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.51090\n",
            "Epoch 25/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.9213 - acc: 0.6824 - val_loss: 2.8319 - val_acc: 0.4558\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.51090\n",
            "Epoch 26/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.8769 - acc: 0.7004 - val_loss: 2.8244 - val_acc: 0.4336\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.51090\n",
            "Epoch 27/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.8607 - acc: 0.7074 - val_loss: 1.9696 - val_acc: 0.5402\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.51090 to 0.54020, saving model to /content/saved_models/cifar10_ResNet32v1_model.027.h5\n",
            "Epoch 28/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.8741 - acc: 0.7120 - val_loss: 6.9632 - val_acc: 0.2287\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.54020\n",
            "Epoch 29/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.8387 - acc: 0.7230 - val_loss: 2.1136 - val_acc: 0.4955\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.54020\n",
            "Epoch 30/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.8452 - acc: 0.7119 - val_loss: 3.8772 - val_acc: 0.3553\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.54020\n",
            "Epoch 31/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.8637 - acc: 0.7086 - val_loss: 2.3595 - val_acc: 0.5032\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.54020\n",
            "Epoch 32/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.8323 - acc: 0.7161 - val_loss: 4.7599 - val_acc: 0.3810\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.54020\n",
            "Epoch 33/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.8171 - acc: 0.7262 - val_loss: 2.1570 - val_acc: 0.4724\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.54020\n",
            "Epoch 34/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.8140 - acc: 0.7241 - val_loss: 3.4667 - val_acc: 0.3830\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.54020\n",
            "Epoch 35/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.8110 - acc: 0.7255 - val_loss: 1.4898 - val_acc: 0.5860\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.54020 to 0.58600, saving model to /content/saved_models/cifar10_ResNet32v1_model.035.h5\n",
            "Epoch 36/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.7852 - acc: 0.7377 - val_loss: 2.7227 - val_acc: 0.5020\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.58600\n",
            "Epoch 37/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.8414 - acc: 0.7094 - val_loss: 2.8508 - val_acc: 0.3988\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.58600\n",
            "Epoch 38/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7899 - acc: 0.7296 - val_loss: 3.1420 - val_acc: 0.4355\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.58600\n",
            "Epoch 39/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.7840 - acc: 0.7351 - val_loss: 2.1145 - val_acc: 0.5178\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.58600\n",
            "Epoch 40/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7914 - acc: 0.7280 - val_loss: 1.9544 - val_acc: 0.5454\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.58600\n",
            "Epoch 41/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.7882 - acc: 0.7308 - val_loss: 1.8390 - val_acc: 0.5928\n",
            "\n",
            "Epoch 00041: val_acc improved from 0.58600 to 0.59280, saving model to /content/saved_models/cifar10_ResNet32v1_model.041.h5\n",
            "Epoch 42/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.7814 - acc: 0.7346 - val_loss: 2.1241 - val_acc: 0.4958\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.59280\n",
            "Epoch 43/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.7928 - acc: 0.7354 - val_loss: 2.2061 - val_acc: 0.5105\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.59280\n",
            "Epoch 44/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7907 - acc: 0.7354 - val_loss: 3.7243 - val_acc: 0.3938\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.59280\n",
            "Epoch 45/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.8239 - acc: 0.7235 - val_loss: 1.9028 - val_acc: 0.5363\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.59280\n",
            "Epoch 46/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7710 - acc: 0.7382 - val_loss: 2.6302 - val_acc: 0.4380\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.59280\n",
            "Epoch 47/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7822 - acc: 0.7355 - val_loss: 3.5132 - val_acc: 0.3747\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.59280\n",
            "Epoch 48/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7748 - acc: 0.7359 - val_loss: 1.5288 - val_acc: 0.5982\n",
            "\n",
            "Epoch 00048: val_acc improved from 0.59280 to 0.59820, saving model to /content/saved_models/cifar10_ResNet32v1_model.048.h5\n",
            "Epoch 49/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7763 - acc: 0.7408 - val_loss: 2.2935 - val_acc: 0.5092\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.59820\n",
            "Epoch 50/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7606 - acc: 0.7396 - val_loss: 2.5368 - val_acc: 0.4680\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.59820\n",
            "Epoch 51/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7685 - acc: 0.7328 - val_loss: 2.8046 - val_acc: 0.4811\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.59820\n",
            "Epoch 52/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.7546 - acc: 0.7519 - val_loss: 1.2622 - val_acc: 0.6445\n",
            "\n",
            "Epoch 00052: val_acc improved from 0.59820 to 0.64450, saving model to /content/saved_models/cifar10_ResNet32v1_model.052.h5\n",
            "Epoch 53/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.7501 - acc: 0.7451 - val_loss: 2.0751 - val_acc: 0.5419\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.64450\n",
            "Epoch 54/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7523 - acc: 0.7442 - val_loss: 1.6102 - val_acc: 0.5937\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.64450\n",
            "Epoch 55/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.7616 - acc: 0.7475 - val_loss: 2.8288 - val_acc: 0.4834\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.64450\n",
            "Epoch 56/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.7544 - acc: 0.7452 - val_loss: 3.5809 - val_acc: 0.4260\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.64450\n",
            "Epoch 57/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7416 - acc: 0.7500 - val_loss: 1.1386 - val_acc: 0.6700\n",
            "\n",
            "Epoch 00057: val_acc improved from 0.64450 to 0.67000, saving model to /content/saved_models/cifar10_ResNet32v1_model.057.h5\n",
            "Epoch 58/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7375 - acc: 0.7512 - val_loss: 1.6164 - val_acc: 0.5678\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.67000\n",
            "Epoch 59/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7343 - acc: 0.7525 - val_loss: 5.0928 - val_acc: 0.3346\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.67000\n",
            "Epoch 60/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.7018 - acc: 0.7714 - val_loss: 1.9355 - val_acc: 0.5825\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.67000\n",
            "Epoch 61/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.7501 - acc: 0.7463 - val_loss: 2.0097 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.67000\n",
            "Epoch 62/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.7377 - acc: 0.7560 - val_loss: 1.3289 - val_acc: 0.6332\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.67000\n",
            "Epoch 63/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7293 - acc: 0.7581 - val_loss: 2.5037 - val_acc: 0.4823\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.67000\n",
            "Epoch 64/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7351 - acc: 0.7525 - val_loss: 1.9675 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.67000\n",
            "Epoch 65/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7311 - acc: 0.7568 - val_loss: 1.8985 - val_acc: 0.5387\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.67000\n",
            "Epoch 66/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7049 - acc: 0.7605 - val_loss: 1.9357 - val_acc: 0.5674\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.67000\n",
            "Epoch 67/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7258 - acc: 0.7533 - val_loss: 2.6729 - val_acc: 0.4404\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.67000\n",
            "Epoch 68/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.7176 - acc: 0.7618 - val_loss: 3.0955 - val_acc: 0.4301\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.67000\n",
            "Epoch 69/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7095 - acc: 0.7631 - val_loss: 4.9947 - val_acc: 0.3757\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.67000\n",
            "Epoch 70/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7195 - acc: 0.7560 - val_loss: 1.4659 - val_acc: 0.5633\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.67000\n",
            "Epoch 71/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7196 - acc: 0.7603 - val_loss: 1.4498 - val_acc: 0.6109\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.67000\n",
            "Epoch 72/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7076 - acc: 0.7607 - val_loss: 1.9308 - val_acc: 0.5905\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.67000\n",
            "Epoch 73/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.7347 - acc: 0.7524 - val_loss: 1.5357 - val_acc: 0.6208\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.67000\n",
            "Epoch 74/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7046 - acc: 0.7589 - val_loss: 2.1581 - val_acc: 0.5343\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.67000\n",
            "Epoch 75/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6997 - acc: 0.7698 - val_loss: 2.9826 - val_acc: 0.4170\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.67000\n",
            "Epoch 76/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.7083 - acc: 0.7641 - val_loss: 1.7391 - val_acc: 0.5642\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.67000\n",
            "Epoch 77/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7125 - acc: 0.7625 - val_loss: 1.7595 - val_acc: 0.5134\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.67000\n",
            "Epoch 78/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7095 - acc: 0.7654 - val_loss: 1.9441 - val_acc: 0.5299\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.67000\n",
            "Epoch 79/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6952 - acc: 0.7706 - val_loss: 2.2348 - val_acc: 0.5331\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.67000\n",
            "Epoch 80/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6764 - acc: 0.7697 - val_loss: 1.6943 - val_acc: 0.5749\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.67000\n",
            "Epoch 81/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.7146 - acc: 0.7602 - val_loss: 1.4217 - val_acc: 0.6387\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.67000\n",
            "Epoch 82/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6946 - acc: 0.7722 - val_loss: 1.7662 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.67000\n",
            "Epoch 83/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7045 - acc: 0.7656 - val_loss: 6.2597 - val_acc: 0.3219\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.67000\n",
            "Epoch 84/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6999 - acc: 0.7697 - val_loss: 3.0788 - val_acc: 0.4872\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.67000\n",
            "Epoch 85/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6859 - acc: 0.7753 - val_loss: 2.5424 - val_acc: 0.4366\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.67000\n",
            "Epoch 86/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6993 - acc: 0.7659 - val_loss: 1.4980 - val_acc: 0.6080\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.67000\n",
            "Epoch 87/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6868 - acc: 0.7642 - val_loss: 1.5427 - val_acc: 0.5951\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.67000\n",
            "Epoch 88/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7034 - acc: 0.7708 - val_loss: 1.7244 - val_acc: 0.5903\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.67000\n",
            "Epoch 89/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6781 - acc: 0.7762 - val_loss: 3.3968 - val_acc: 0.4299\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.67000\n",
            "Epoch 90/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6981 - acc: 0.7675 - val_loss: 1.5284 - val_acc: 0.5772\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.67000\n",
            "Epoch 91/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6914 - acc: 0.7725 - val_loss: 1.9030 - val_acc: 0.5293\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.67000\n",
            "Epoch 92/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6584 - acc: 0.7820 - val_loss: 4.8002 - val_acc: 0.3147\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.67000\n",
            "Epoch 93/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.6832 - acc: 0.7718 - val_loss: 4.2535 - val_acc: 0.3881\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.67000\n",
            "Epoch 94/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.6760 - acc: 0.7761 - val_loss: 5.4781 - val_acc: 0.2644\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.67000\n",
            "Epoch 95/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6901 - acc: 0.7674 - val_loss: 1.2413 - val_acc: 0.6596\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.67000\n",
            "Epoch 96/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6899 - acc: 0.7742 - val_loss: 2.1276 - val_acc: 0.5361\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.67000\n",
            "Epoch 97/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6579 - acc: 0.7809 - val_loss: 1.9061 - val_acc: 0.5732\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.67000\n",
            "Epoch 98/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6509 - acc: 0.7870 - val_loss: 1.3002 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.67000\n",
            "Epoch 99/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6908 - acc: 0.7775 - val_loss: 1.7345 - val_acc: 0.5682\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.67000\n",
            "Epoch 100/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6667 - acc: 0.7778 - val_loss: 2.8264 - val_acc: 0.4661\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.67000\n",
            "Epoch 101/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6717 - acc: 0.7759 - val_loss: 1.0885 - val_acc: 0.6620\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.67000\n",
            "Epoch 102/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6587 - acc: 0.7783 - val_loss: 2.3146 - val_acc: 0.4977\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.67000\n",
            "Epoch 103/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6599 - acc: 0.7742 - val_loss: 2.3276 - val_acc: 0.4863\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.67000\n",
            "Epoch 104/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6726 - acc: 0.7784 - val_loss: 1.8774 - val_acc: 0.5657\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.67000\n",
            "Epoch 105/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6478 - acc: 0.7825 - val_loss: 2.1792 - val_acc: 0.4492\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.67000\n",
            "Epoch 106/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6732 - acc: 0.7797 - val_loss: 1.0604 - val_acc: 0.6903\n",
            "\n",
            "Epoch 00106: val_acc improved from 0.67000 to 0.69030, saving model to /content/saved_models/cifar10_ResNet32v1_model.106.h5\n",
            "Epoch 107/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6647 - acc: 0.7805 - val_loss: 1.9138 - val_acc: 0.5515\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.69030\n",
            "Epoch 108/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6780 - acc: 0.7726 - val_loss: 1.3403 - val_acc: 0.6284\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.69030\n",
            "Epoch 109/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6717 - acc: 0.7800 - val_loss: 2.6647 - val_acc: 0.4803\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.69030\n",
            "Epoch 110/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6503 - acc: 0.7849 - val_loss: 1.3231 - val_acc: 0.6479\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.69030\n",
            "Epoch 111/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6448 - acc: 0.7877 - val_loss: 1.7870 - val_acc: 0.5678\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.69030\n",
            "Epoch 112/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6603 - acc: 0.7814 - val_loss: 1.0484 - val_acc: 0.6926\n",
            "\n",
            "Epoch 00112: val_acc improved from 0.69030 to 0.69260, saving model to /content/saved_models/cifar10_ResNet32v1_model.112.h5\n",
            "Epoch 113/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6643 - acc: 0.7788 - val_loss: 1.6201 - val_acc: 0.5927\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.69260\n",
            "Epoch 114/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.6507 - acc: 0.7819 - val_loss: 1.9112 - val_acc: 0.5319\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.69260\n",
            "Epoch 115/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6560 - acc: 0.7820 - val_loss: 1.7612 - val_acc: 0.5811\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.69260\n",
            "Epoch 116/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6693 - acc: 0.7790 - val_loss: 1.4385 - val_acc: 0.5879\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.69260\n",
            "Epoch 117/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6494 - acc: 0.7864 - val_loss: 2.1432 - val_acc: 0.5744\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.69260\n",
            "Epoch 118/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6510 - acc: 0.7865 - val_loss: 1.3145 - val_acc: 0.6499\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.69260\n",
            "Epoch 119/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6674 - acc: 0.7758 - val_loss: 4.0171 - val_acc: 0.3829\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.69260\n",
            "Epoch 120/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6421 - acc: 0.7901 - val_loss: 2.0051 - val_acc: 0.5554\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.69260\n",
            "Epoch 121/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6569 - acc: 0.7813 - val_loss: 1.9893 - val_acc: 0.5663\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.69260\n",
            "Epoch 122/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6325 - acc: 0.7943 - val_loss: 4.4331 - val_acc: 0.4108\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.69260\n",
            "Epoch 123/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6463 - acc: 0.7870 - val_loss: 3.0812 - val_acc: 0.4614\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.69260\n",
            "Epoch 124/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6354 - acc: 0.7867 - val_loss: 1.1639 - val_acc: 0.6884\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.69260\n",
            "Epoch 125/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6277 - acc: 0.7931 - val_loss: 1.3814 - val_acc: 0.6220\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.69260\n",
            "Epoch 126/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6465 - acc: 0.7861 - val_loss: 1.8447 - val_acc: 0.5891\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.69260\n",
            "Epoch 127/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6396 - acc: 0.7857 - val_loss: 1.0967 - val_acc: 0.6959\n",
            "\n",
            "Epoch 00127: val_acc improved from 0.69260 to 0.69590, saving model to /content/saved_models/cifar10_ResNet32v1_model.127.h5\n",
            "Epoch 128/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6400 - acc: 0.7885 - val_loss: 1.7585 - val_acc: 0.5768\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.69590\n",
            "Epoch 129/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6458 - acc: 0.7897 - val_loss: 2.2070 - val_acc: 0.4675\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.69590\n",
            "Epoch 130/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6520 - acc: 0.7841 - val_loss: 1.4116 - val_acc: 0.5979\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.69590\n",
            "Epoch 131/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6497 - acc: 0.7834 - val_loss: 1.2545 - val_acc: 0.6267\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.69590\n",
            "Epoch 132/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6299 - acc: 0.7929 - val_loss: 1.1111 - val_acc: 0.6966\n",
            "\n",
            "Epoch 00132: val_acc improved from 0.69590 to 0.69660, saving model to /content/saved_models/cifar10_ResNet32v1_model.132.h5\n",
            "Epoch 133/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6371 - acc: 0.7888 - val_loss: 3.3980 - val_acc: 0.4250\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.69660\n",
            "Epoch 134/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6394 - acc: 0.7854 - val_loss: 1.7072 - val_acc: 0.6084\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.69660\n",
            "Epoch 135/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6394 - acc: 0.7896 - val_loss: 2.2398 - val_acc: 0.4953\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.69660\n",
            "Epoch 136/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6197 - acc: 0.7917 - val_loss: 1.3991 - val_acc: 0.6225\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.69660\n",
            "Epoch 137/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6384 - acc: 0.7894 - val_loss: 1.7443 - val_acc: 0.6163\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.69660\n",
            "Epoch 138/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6580 - acc: 0.7846 - val_loss: 1.2004 - val_acc: 0.6610\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.69660\n",
            "Epoch 139/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6259 - acc: 0.7949 - val_loss: 1.3453 - val_acc: 0.6271\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.69660\n",
            "Epoch 140/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6276 - acc: 0.7951 - val_loss: 1.3607 - val_acc: 0.6185\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.69660\n",
            "Epoch 141/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6327 - acc: 0.7949 - val_loss: 1.7142 - val_acc: 0.5890\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.69660\n",
            "Epoch 142/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6312 - acc: 0.7910 - val_loss: 1.2309 - val_acc: 0.6370\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.69660\n",
            "Epoch 143/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6258 - acc: 0.7962 - val_loss: 2.0581 - val_acc: 0.5486\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.69660\n",
            "Epoch 144/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6425 - acc: 0.7868 - val_loss: 3.1886 - val_acc: 0.4275\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.69660\n",
            "Epoch 145/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6178 - acc: 0.7916 - val_loss: 1.6575 - val_acc: 0.5672\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.69660\n",
            "Epoch 146/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6436 - acc: 0.7911 - val_loss: 1.3805 - val_acc: 0.5849\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.69660\n",
            "Epoch 147/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6250 - acc: 0.7967 - val_loss: 2.4876 - val_acc: 0.5062\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.69660\n",
            "Epoch 148/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6350 - acc: 0.7921 - val_loss: 1.1170 - val_acc: 0.6909\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.69660\n",
            "Epoch 149/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6437 - acc: 0.7827 - val_loss: 2.5788 - val_acc: 0.4915\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.69660\n",
            "Epoch 150/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6200 - acc: 0.7909 - val_loss: 2.7172 - val_acc: 0.4227\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.69660\n",
            "Epoch 151/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6483 - acc: 0.7850 - val_loss: 2.0236 - val_acc: 0.5313\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.69660\n",
            "Epoch 152/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6387 - acc: 0.7915 - val_loss: 2.2974 - val_acc: 0.5214\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.69660\n",
            "Epoch 153/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6200 - acc: 0.7952 - val_loss: 1.5389 - val_acc: 0.5865\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.69660\n",
            "Epoch 154/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6320 - acc: 0.7947 - val_loss: 1.9595 - val_acc: 0.5727\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.69660\n",
            "Epoch 155/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6615 - acc: 0.7787 - val_loss: 2.1457 - val_acc: 0.5896\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.69660\n",
            "Epoch 156/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6339 - acc: 0.7932 - val_loss: 1.5226 - val_acc: 0.5937\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.69660\n",
            "Epoch 157/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6423 - acc: 0.7896 - val_loss: 1.2999 - val_acc: 0.6371\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.69660\n",
            "Epoch 158/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6115 - acc: 0.7987 - val_loss: 1.3725 - val_acc: 0.6417\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.69660\n",
            "Epoch 159/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6210 - acc: 0.8003 - val_loss: 1.4393 - val_acc: 0.5975\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.69660\n",
            "Epoch 160/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6317 - acc: 0.7955 - val_loss: 2.6383 - val_acc: 0.4712\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.69660\n",
            "Epoch 161/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6167 - acc: 0.7990 - val_loss: 1.2373 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.69660\n",
            "Epoch 162/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6367 - acc: 0.7845 - val_loss: 2.0137 - val_acc: 0.5576\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.69660\n",
            "Epoch 163/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6176 - acc: 0.7981 - val_loss: 1.6694 - val_acc: 0.5961\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.69660\n",
            "Epoch 164/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6089 - acc: 0.7973 - val_loss: 2.7201 - val_acc: 0.5110\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.69660\n",
            "Epoch 165/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6400 - acc: 0.7933 - val_loss: 1.2324 - val_acc: 0.6266\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.69660\n",
            "Epoch 166/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6196 - acc: 0.7956 - val_loss: 1.6416 - val_acc: 0.5942\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.69660\n",
            "Epoch 167/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6108 - acc: 0.8013 - val_loss: 1.3319 - val_acc: 0.6274\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.69660\n",
            "Epoch 168/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5991 - acc: 0.8046 - val_loss: 1.6226 - val_acc: 0.5715\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.69660\n",
            "Epoch 169/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6215 - acc: 0.7989 - val_loss: 1.3191 - val_acc: 0.6645\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.69660\n",
            "Epoch 170/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6183 - acc: 0.8001 - val_loss: 1.4570 - val_acc: 0.6424\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.69660\n",
            "Epoch 171/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6091 - acc: 0.7964 - val_loss: 2.9703 - val_acc: 0.4407\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.69660\n",
            "Epoch 172/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6139 - acc: 0.7939 - val_loss: 1.7560 - val_acc: 0.5670\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.69660\n",
            "Epoch 173/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6264 - acc: 0.7954 - val_loss: 1.7561 - val_acc: 0.5817\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.69660\n",
            "Epoch 174/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6161 - acc: 0.7935 - val_loss: 1.8988 - val_acc: 0.5585\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.69660\n",
            "Epoch 175/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6125 - acc: 0.7975 - val_loss: 1.2283 - val_acc: 0.6412\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.69660\n",
            "Epoch 176/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.6173 - acc: 0.8009 - val_loss: 1.1062 - val_acc: 0.6883\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.69660\n",
            "Epoch 177/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5987 - acc: 0.8021 - val_loss: 1.8721 - val_acc: 0.5626\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.69660\n",
            "Epoch 178/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6374 - acc: 0.7913 - val_loss: 1.3379 - val_acc: 0.6256\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.69660\n",
            "Epoch 179/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6343 - acc: 0.7924 - val_loss: 1.2325 - val_acc: 0.6714\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.69660\n",
            "Epoch 180/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6058 - acc: 0.8033 - val_loss: 1.3951 - val_acc: 0.6409\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.69660\n",
            "Epoch 181/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6246 - acc: 0.7921 - val_loss: 1.0541 - val_acc: 0.6902\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.69660\n",
            "Epoch 182/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6103 - acc: 0.8006 - val_loss: 1.9193 - val_acc: 0.5772\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.69660\n",
            "Epoch 183/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6129 - acc: 0.7965 - val_loss: 2.1792 - val_acc: 0.4830\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.69660\n",
            "Epoch 184/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6111 - acc: 0.8028 - val_loss: 2.7985 - val_acc: 0.4422\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.69660\n",
            "Epoch 185/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6036 - acc: 0.8023 - val_loss: 1.0325 - val_acc: 0.6850\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.69660\n",
            "Epoch 186/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5980 - acc: 0.8041 - val_loss: 0.8802 - val_acc: 0.7177\n",
            "\n",
            "Epoch 00186: val_acc improved from 0.69660 to 0.71770, saving model to /content/saved_models/cifar10_ResNet32v1_model.186.h5\n",
            "Epoch 187/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6139 - acc: 0.8031 - val_loss: 1.6452 - val_acc: 0.5195\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.71770\n",
            "Epoch 188/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5959 - acc: 0.8062 - val_loss: 1.2838 - val_acc: 0.6385\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.71770\n",
            "Epoch 189/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6007 - acc: 0.7970 - val_loss: 1.7303 - val_acc: 0.5909\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.71770\n",
            "Epoch 190/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6139 - acc: 0.7929 - val_loss: 1.4405 - val_acc: 0.6174\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.71770\n",
            "Epoch 191/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5970 - acc: 0.8035 - val_loss: 2.0877 - val_acc: 0.5174\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.71770\n",
            "Epoch 192/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6161 - acc: 0.7951 - val_loss: 2.3498 - val_acc: 0.5578\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.71770\n",
            "Epoch 193/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5853 - acc: 0.8056 - val_loss: 1.3587 - val_acc: 0.6093\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.71770\n",
            "Epoch 194/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6371 - acc: 0.7862 - val_loss: 2.1802 - val_acc: 0.5132\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.71770\n",
            "Epoch 195/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5861 - acc: 0.8064 - val_loss: 1.4297 - val_acc: 0.6259\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.71770\n",
            "Epoch 196/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6022 - acc: 0.8021 - val_loss: 3.3701 - val_acc: 0.3882\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.71770\n",
            "Epoch 197/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6236 - acc: 0.7946 - val_loss: 2.0199 - val_acc: 0.5771\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.71770\n",
            "Epoch 198/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6162 - acc: 0.8038 - val_loss: 2.3696 - val_acc: 0.4556\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.71770\n",
            "Epoch 199/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6201 - acc: 0.7916 - val_loss: 1.4034 - val_acc: 0.6141\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.71770\n",
            "Epoch 200/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6433 - acc: 0.7842 - val_loss: 1.7911 - val_acc: 0.5332\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.71770\n",
            "Epoch 201/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.6118 - acc: 0.8000 - val_loss: 1.4805 - val_acc: 0.6117\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.71770\n",
            "Epoch 202/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5855 - acc: 0.8093 - val_loss: 2.6247 - val_acc: 0.4980\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.71770\n",
            "Epoch 203/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5856 - acc: 0.8069 - val_loss: 1.4183 - val_acc: 0.6146\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.71770\n",
            "Epoch 204/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6019 - acc: 0.7989 - val_loss: 4.2146 - val_acc: 0.4081\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.71770\n",
            "Epoch 205/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6008 - acc: 0.7981 - val_loss: 1.2843 - val_acc: 0.6472\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.71770\n",
            "Epoch 206/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.6034 - acc: 0.7971 - val_loss: 1.9237 - val_acc: 0.5631\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.71770\n",
            "Epoch 207/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6101 - acc: 0.7959 - val_loss: 2.1655 - val_acc: 0.5813\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.71770\n",
            "Epoch 208/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5812 - acc: 0.8077 - val_loss: 1.3242 - val_acc: 0.6379\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.71770\n",
            "Epoch 209/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6199 - acc: 0.7918 - val_loss: 2.8264 - val_acc: 0.5287\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.71770\n",
            "Epoch 210/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6244 - acc: 0.7936 - val_loss: 1.4031 - val_acc: 0.6375\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.71770\n",
            "Epoch 211/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6076 - acc: 0.8007 - val_loss: 1.1096 - val_acc: 0.6635\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.71770\n",
            "Epoch 212/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6002 - acc: 0.8014 - val_loss: 1.1672 - val_acc: 0.6669\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.71770\n",
            "Epoch 213/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6183 - acc: 0.7949 - val_loss: 2.0897 - val_acc: 0.5794\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.71770\n",
            "Epoch 214/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6029 - acc: 0.8056 - val_loss: 2.3196 - val_acc: 0.4832\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.71770\n",
            "Epoch 215/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6076 - acc: 0.8100 - val_loss: 1.1124 - val_acc: 0.7051\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.71770\n",
            "Epoch 216/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5895 - acc: 0.8042 - val_loss: 1.1686 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.71770\n",
            "Epoch 217/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6133 - acc: 0.8018 - val_loss: 3.9055 - val_acc: 0.4092\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.71770\n",
            "Epoch 218/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5967 - acc: 0.8010 - val_loss: 1.5400 - val_acc: 0.6057\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.71770\n",
            "Epoch 219/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5855 - acc: 0.8048 - val_loss: 2.5897 - val_acc: 0.4435\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.71770\n",
            "Epoch 220/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.6006 - acc: 0.8042 - val_loss: 1.2341 - val_acc: 0.6397\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.71770\n",
            "Epoch 221/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.6044 - acc: 0.8033 - val_loss: 0.9709 - val_acc: 0.6889\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.71770\n",
            "Epoch 222/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5953 - acc: 0.8072 - val_loss: 4.6849 - val_acc: 0.3461\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.71770\n",
            "Epoch 223/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.5946 - acc: 0.7954 - val_loss: 0.9931 - val_acc: 0.6973\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.71770\n",
            "Epoch 224/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6034 - acc: 0.8021 - val_loss: 1.4271 - val_acc: 0.5816\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.71770\n",
            "Epoch 225/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5961 - acc: 0.8007 - val_loss: 1.4424 - val_acc: 0.6208\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.71770\n",
            "Epoch 226/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5948 - acc: 0.8096 - val_loss: 1.9430 - val_acc: 0.5669\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.71770\n",
            "Epoch 227/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5965 - acc: 0.7990 - val_loss: 2.6148 - val_acc: 0.4782\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.71770\n",
            "Epoch 228/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6003 - acc: 0.7986 - val_loss: 1.8007 - val_acc: 0.5535\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.71770\n",
            "Epoch 229/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5710 - acc: 0.8144 - val_loss: 1.0968 - val_acc: 0.6601\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.71770\n",
            "Epoch 230/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6042 - acc: 0.7982 - val_loss: 1.9183 - val_acc: 0.5847\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.71770\n",
            "Epoch 231/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5902 - acc: 0.8035 - val_loss: 1.6551 - val_acc: 0.6194\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.71770\n",
            "Epoch 232/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.6054 - acc: 0.8020 - val_loss: 1.3569 - val_acc: 0.6476\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.71770\n",
            "Epoch 233/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.5893 - acc: 0.8070 - val_loss: 1.8102 - val_acc: 0.5610\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.71770\n",
            "Epoch 234/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5898 - acc: 0.8049 - val_loss: 1.6946 - val_acc: 0.6010\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.71770\n",
            "Epoch 235/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.5760 - acc: 0.8093 - val_loss: 1.0038 - val_acc: 0.7242\n",
            "\n",
            "Epoch 00235: val_acc improved from 0.71770 to 0.72420, saving model to /content/saved_models/cifar10_ResNet32v1_model.235.h5\n",
            "Epoch 236/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6180 - acc: 0.7990 - val_loss: 0.9678 - val_acc: 0.7151\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.72420\n",
            "Epoch 237/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.5912 - acc: 0.8094 - val_loss: 2.0502 - val_acc: 0.5022\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.72420\n",
            "Epoch 238/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.5745 - acc: 0.8120 - val_loss: 3.3505 - val_acc: 0.3856\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.72420\n",
            "Epoch 239/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5851 - acc: 0.8102 - val_loss: 1.5099 - val_acc: 0.6411\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.72420\n",
            "Epoch 240/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5779 - acc: 0.8135 - val_loss: 1.3523 - val_acc: 0.6656\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.72420\n",
            "Epoch 241/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5845 - acc: 0.8037 - val_loss: 1.2901 - val_acc: 0.6255\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.72420\n",
            "Epoch 242/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5874 - acc: 0.8037 - val_loss: 1.4263 - val_acc: 0.6067\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.72420\n",
            "Epoch 243/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6126 - acc: 0.8013 - val_loss: 1.4287 - val_acc: 0.6187\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.72420\n",
            "Epoch 244/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5705 - acc: 0.8053 - val_loss: 1.4436 - val_acc: 0.6345\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.72420\n",
            "Epoch 245/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5822 - acc: 0.8099 - val_loss: 1.0337 - val_acc: 0.7048\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.72420\n",
            "Epoch 246/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5898 - acc: 0.8033 - val_loss: 1.2321 - val_acc: 0.6671\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.72420\n",
            "Epoch 247/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.6008 - acc: 0.8002 - val_loss: 1.5668 - val_acc: 0.6032\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.72420\n",
            "Epoch 248/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5928 - acc: 0.8011 - val_loss: 1.8395 - val_acc: 0.5730\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.72420\n",
            "Epoch 249/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5697 - acc: 0.8137 - val_loss: 2.1800 - val_acc: 0.4956\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.72420\n",
            "Epoch 250/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6073 - acc: 0.7982 - val_loss: 1.1679 - val_acc: 0.6545\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.72420\n",
            "Epoch 251/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5682 - acc: 0.8125 - val_loss: 0.8426 - val_acc: 0.7524\n",
            "\n",
            "Epoch 00251: val_acc improved from 0.72420 to 0.75240, saving model to /content/saved_models/cifar10_ResNet32v1_model.251.h5\n",
            "Epoch 252/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.5979 - acc: 0.8071 - val_loss: 0.8839 - val_acc: 0.7194\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.75240\n",
            "Epoch 253/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5749 - acc: 0.8142 - val_loss: 0.9655 - val_acc: 0.7120\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.75240\n",
            "Epoch 254/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5684 - acc: 0.8117 - val_loss: 1.7975 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.75240\n",
            "Epoch 255/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.5987 - acc: 0.8036 - val_loss: 2.7664 - val_acc: 0.4962\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.75240\n",
            "Epoch 256/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5690 - acc: 0.8056 - val_loss: 1.1776 - val_acc: 0.6525\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.75240\n",
            "Epoch 257/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5942 - acc: 0.8020 - val_loss: 1.8551 - val_acc: 0.5566\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.75240\n",
            "Epoch 258/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6103 - acc: 0.7990 - val_loss: 4.9049 - val_acc: 0.3036\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.75240\n",
            "Epoch 259/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5860 - acc: 0.8062 - val_loss: 1.2126 - val_acc: 0.6629\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.75240\n",
            "Epoch 260/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5574 - acc: 0.8187 - val_loss: 1.8946 - val_acc: 0.5241\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.75240\n",
            "Epoch 261/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5891 - acc: 0.8039 - val_loss: 2.9491 - val_acc: 0.4289\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.75240\n",
            "Epoch 262/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6086 - acc: 0.7994 - val_loss: 1.1461 - val_acc: 0.6666\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.75240\n",
            "Epoch 263/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6055 - acc: 0.7966 - val_loss: 1.3824 - val_acc: 0.6348\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.75240\n",
            "Epoch 264/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5832 - acc: 0.8080 - val_loss: 1.3119 - val_acc: 0.6407\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.75240\n",
            "Epoch 265/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5725 - acc: 0.8121 - val_loss: 2.2923 - val_acc: 0.5005\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.75240\n",
            "Epoch 266/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.5892 - acc: 0.8046 - val_loss: 1.1761 - val_acc: 0.6396\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.75240\n",
            "Epoch 267/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5804 - acc: 0.8073 - val_loss: 0.9618 - val_acc: 0.7321\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.75240\n",
            "Epoch 268/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5997 - acc: 0.8052 - val_loss: 1.8735 - val_acc: 0.5502\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.75240\n",
            "Epoch 269/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5753 - acc: 0.8153 - val_loss: 2.1264 - val_acc: 0.5906\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.75240\n",
            "Epoch 270/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5909 - acc: 0.8063 - val_loss: 1.8019 - val_acc: 0.5738\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.75240\n",
            "Epoch 271/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.6195 - acc: 0.7947 - val_loss: 0.9077 - val_acc: 0.7135\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.75240\n",
            "Epoch 272/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5555 - acc: 0.8200 - val_loss: 1.2774 - val_acc: 0.6486\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.75240\n",
            "Epoch 273/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5780 - acc: 0.8104 - val_loss: 1.5580 - val_acc: 0.5546\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.75240\n",
            "Epoch 274/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5894 - acc: 0.7987 - val_loss: 1.4014 - val_acc: 0.6258\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.75240\n",
            "Epoch 275/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.6122 - acc: 0.7919 - val_loss: 1.5742 - val_acc: 0.6001\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.75240\n",
            "Epoch 276/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6001 - acc: 0.8053 - val_loss: 1.2238 - val_acc: 0.6525\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.75240\n",
            "Epoch 277/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5637 - acc: 0.8151 - val_loss: 1.3162 - val_acc: 0.6656\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.75240\n",
            "Epoch 278/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5568 - acc: 0.8169 - val_loss: 1.5031 - val_acc: 0.6716\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.75240\n",
            "Epoch 279/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5853 - acc: 0.8076 - val_loss: 2.2191 - val_acc: 0.4991\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.75240\n",
            "Epoch 280/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5868 - acc: 0.8073 - val_loss: 2.3465 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.75240\n",
            "Epoch 281/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5572 - acc: 0.8146 - val_loss: 1.1658 - val_acc: 0.6757\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.75240\n",
            "Epoch 282/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5878 - acc: 0.8013 - val_loss: 0.8076 - val_acc: 0.7418\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.75240\n",
            "Epoch 283/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5690 - acc: 0.8131 - val_loss: 1.8300 - val_acc: 0.5840\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.75240\n",
            "Epoch 284/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5603 - acc: 0.8151 - val_loss: 1.2440 - val_acc: 0.6318\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.75240\n",
            "Epoch 285/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5676 - acc: 0.8118 - val_loss: 1.9251 - val_acc: 0.5513\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.75240\n",
            "Epoch 286/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5855 - acc: 0.8110 - val_loss: 1.3833 - val_acc: 0.5821\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.75240\n",
            "Epoch 287/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5661 - acc: 0.8176 - val_loss: 4.0818 - val_acc: 0.3456\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.75240\n",
            "Epoch 288/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5756 - acc: 0.8096 - val_loss: 2.9653 - val_acc: 0.4630\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.75240\n",
            "Epoch 289/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5872 - acc: 0.8120 - val_loss: 0.9773 - val_acc: 0.7115\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.75240\n",
            "Epoch 290/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5747 - acc: 0.8148 - val_loss: 1.4197 - val_acc: 0.6282\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.75240\n",
            "Epoch 291/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6011 - acc: 0.8032 - val_loss: 1.1954 - val_acc: 0.6646\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.75240\n",
            "Epoch 292/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6027 - acc: 0.7971 - val_loss: 1.1878 - val_acc: 0.6475\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.75240\n",
            "Epoch 293/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.5622 - acc: 0.8185 - val_loss: 1.8754 - val_acc: 0.5467\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.75240\n",
            "Epoch 294/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5917 - acc: 0.8071 - val_loss: 1.7789 - val_acc: 0.5797\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.75240\n",
            "Epoch 295/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5742 - acc: 0.8055 - val_loss: 1.7804 - val_acc: 0.6088\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.75240\n",
            "Epoch 296/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5752 - acc: 0.8110 - val_loss: 1.5013 - val_acc: 0.6123\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.75240\n",
            "Epoch 297/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5611 - acc: 0.8186 - val_loss: 1.2464 - val_acc: 0.6273\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.75240\n",
            "Epoch 298/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5727 - acc: 0.8133 - val_loss: 1.7953 - val_acc: 0.5918\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.75240\n",
            "Epoch 299/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5519 - acc: 0.8164 - val_loss: 1.5140 - val_acc: 0.6239\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.75240\n",
            "Epoch 300/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6009 - acc: 0.7959 - val_loss: 2.0187 - val_acc: 0.5261\n",
            "\n",
            "Epoch 00300: val_acc did not improve from 0.75240\n",
            "Epoch 301/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5523 - acc: 0.8204 - val_loss: 2.1904 - val_acc: 0.5082\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.75240\n",
            "Epoch 302/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5809 - acc: 0.8033 - val_loss: 0.8178 - val_acc: 0.7446\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.75240\n",
            "Epoch 303/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5836 - acc: 0.8103 - val_loss: 1.1261 - val_acc: 0.6781\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.75240\n",
            "Epoch 304/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5738 - acc: 0.8112 - val_loss: 0.9926 - val_acc: 0.6788\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.75240\n",
            "Epoch 305/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6186 - acc: 0.7939 - val_loss: 1.0483 - val_acc: 0.6879\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.75240\n",
            "Epoch 306/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5622 - acc: 0.8146 - val_loss: 2.0234 - val_acc: 0.5195\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.75240\n",
            "Epoch 307/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5901 - acc: 0.8079 - val_loss: 1.7761 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.75240\n",
            "Epoch 308/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5645 - acc: 0.8149 - val_loss: 10.6477 - val_acc: 0.1607\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.75240\n",
            "Epoch 309/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5675 - acc: 0.8181 - val_loss: 2.0163 - val_acc: 0.5592\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.75240\n",
            "Epoch 310/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5744 - acc: 0.8182 - val_loss: 1.8022 - val_acc: 0.5318\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.75240\n",
            "Epoch 311/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5811 - acc: 0.8096 - val_loss: 2.1302 - val_acc: 0.5183\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.75240\n",
            "Epoch 312/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5794 - acc: 0.8024 - val_loss: 2.0173 - val_acc: 0.5329\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.75240\n",
            "Epoch 313/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5703 - acc: 0.8087 - val_loss: 1.1482 - val_acc: 0.6459\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.75240\n",
            "Epoch 314/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5572 - acc: 0.8143 - val_loss: 1.7970 - val_acc: 0.5509\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.75240\n",
            "Epoch 315/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5760 - acc: 0.8104 - val_loss: 2.2882 - val_acc: 0.4773\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.75240\n",
            "Epoch 316/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5768 - acc: 0.8122 - val_loss: 1.6359 - val_acc: 0.6022\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.75240\n",
            "Epoch 317/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.5833 - acc: 0.8080 - val_loss: 5.2852 - val_acc: 0.3103\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.75240\n",
            "Epoch 318/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5862 - acc: 0.8049 - val_loss: 1.4123 - val_acc: 0.6400\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.75240\n",
            "Epoch 319/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5684 - acc: 0.8092 - val_loss: 1.6310 - val_acc: 0.5585\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.75240\n",
            "Epoch 320/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5941 - acc: 0.8059 - val_loss: 2.2517 - val_acc: 0.5409\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.75240\n",
            "Epoch 321/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5854 - acc: 0.8082 - val_loss: 1.5951 - val_acc: 0.5820\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.75240\n",
            "Epoch 322/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5564 - acc: 0.8159 - val_loss: 2.0745 - val_acc: 0.4995\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.75240\n",
            "Epoch 323/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5861 - acc: 0.8090 - val_loss: 1.1991 - val_acc: 0.6496\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.75240\n",
            "Epoch 324/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5635 - acc: 0.8168 - val_loss: 1.7687 - val_acc: 0.5966\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.75240\n",
            "Epoch 325/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.5876 - acc: 0.8043 - val_loss: 1.4887 - val_acc: 0.6484\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.75240\n",
            "Epoch 326/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5883 - acc: 0.8081 - val_loss: 1.2933 - val_acc: 0.6244\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.75240\n",
            "Epoch 327/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5752 - acc: 0.8100 - val_loss: 1.0057 - val_acc: 0.7172\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.75240\n",
            "Epoch 328/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5780 - acc: 0.8100 - val_loss: 0.9244 - val_acc: 0.7384\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.75240\n",
            "Epoch 329/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5811 - acc: 0.8053 - val_loss: 1.0973 - val_acc: 0.6885\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.75240\n",
            "Epoch 330/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5723 - acc: 0.8149 - val_loss: 1.7660 - val_acc: 0.5483\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.75240\n",
            "Epoch 331/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.5716 - acc: 0.8096 - val_loss: 1.3688 - val_acc: 0.6146\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.75240\n",
            "Epoch 332/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.5508 - acc: 0.8227 - val_loss: 1.6008 - val_acc: 0.6161\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.75240\n",
            "Epoch 333/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5468 - acc: 0.8196 - val_loss: 2.2310 - val_acc: 0.4980\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.75240\n",
            "Epoch 334/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5706 - acc: 0.8101 - val_loss: 1.9429 - val_acc: 0.5609\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.75240\n",
            "Epoch 335/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5878 - acc: 0.8112 - val_loss: 0.8001 - val_acc: 0.7516\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.75240\n",
            "Epoch 336/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5647 - acc: 0.8134 - val_loss: 1.0701 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.75240\n",
            "Epoch 337/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.5932 - acc: 0.8081 - val_loss: 1.3174 - val_acc: 0.6457\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.75240\n",
            "Epoch 338/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5755 - acc: 0.8108 - val_loss: 1.6150 - val_acc: 0.5534\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.75240\n",
            "Epoch 339/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5542 - acc: 0.8185 - val_loss: 1.4937 - val_acc: 0.6157\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.75240\n",
            "Epoch 340/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5593 - acc: 0.8233 - val_loss: 1.8093 - val_acc: 0.5771\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.75240\n",
            "Epoch 341/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.5850 - acc: 0.8082 - val_loss: 4.1443 - val_acc: 0.3410\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.75240\n",
            "Epoch 342/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5697 - acc: 0.8159 - val_loss: 2.2209 - val_acc: 0.4777\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.75240\n",
            "Epoch 343/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5819 - acc: 0.8096 - val_loss: 2.0412 - val_acc: 0.5141\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.75240\n",
            "Epoch 344/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5843 - acc: 0.8102 - val_loss: 7.3301 - val_acc: 0.2691\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.75240\n",
            "Epoch 345/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5597 - acc: 0.8196 - val_loss: 1.1892 - val_acc: 0.7020\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.75240\n",
            "Epoch 346/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5747 - acc: 0.8098 - val_loss: 2.1397 - val_acc: 0.4942\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.75240\n",
            "Epoch 347/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5732 - acc: 0.8116 - val_loss: 2.1668 - val_acc: 0.5695\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.75240\n",
            "Epoch 348/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5513 - acc: 0.8198 - val_loss: 2.2128 - val_acc: 0.5203\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.75240\n",
            "Epoch 349/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5695 - acc: 0.8113 - val_loss: 1.9134 - val_acc: 0.5225\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.75240\n",
            "Epoch 350/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5581 - acc: 0.8172 - val_loss: 1.7775 - val_acc: 0.5634\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.75240\n",
            "Epoch 351/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5680 - acc: 0.8092 - val_loss: 1.0938 - val_acc: 0.6699\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.75240\n",
            "Epoch 352/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5866 - acc: 0.8067 - val_loss: 1.8912 - val_acc: 0.5226\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.75240\n",
            "Epoch 353/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5688 - acc: 0.8104 - val_loss: 0.9961 - val_acc: 0.6974\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.75240\n",
            "Epoch 354/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5648 - acc: 0.8153 - val_loss: 1.6930 - val_acc: 0.5704\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.75240\n",
            "Epoch 355/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5596 - acc: 0.8191 - val_loss: 1.3946 - val_acc: 0.6306\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.75240\n",
            "Epoch 356/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5783 - acc: 0.8097 - val_loss: 1.9870 - val_acc: 0.5278\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.75240\n",
            "Epoch 357/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5347 - acc: 0.8218 - val_loss: 1.1132 - val_acc: 0.6616\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.75240\n",
            "Epoch 358/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5476 - acc: 0.8194 - val_loss: 1.3319 - val_acc: 0.6326\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.75240\n",
            "Epoch 359/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.5843 - acc: 0.8074 - val_loss: 1.1096 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.75240\n",
            "Epoch 360/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5547 - acc: 0.8199 - val_loss: 1.3722 - val_acc: 0.6403\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.75240\n",
            "Epoch 361/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5647 - acc: 0.8142 - val_loss: 1.2906 - val_acc: 0.6484\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.75240\n",
            "Epoch 362/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.5704 - acc: 0.8116 - val_loss: 1.3748 - val_acc: 0.6077\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.75240\n",
            "Epoch 363/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5673 - acc: 0.8148 - val_loss: 1.0981 - val_acc: 0.6743\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.75240\n",
            "Epoch 364/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.5458 - acc: 0.8209 - val_loss: 1.3029 - val_acc: 0.6334\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.75240\n",
            "Epoch 365/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5696 - acc: 0.8127 - val_loss: 1.3960 - val_acc: 0.6243\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.75240\n",
            "Epoch 366/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5703 - acc: 0.8147 - val_loss: 1.1335 - val_acc: 0.6993\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.75240\n",
            "Epoch 367/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5642 - acc: 0.8161 - val_loss: 1.2363 - val_acc: 0.6608\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.75240\n",
            "Epoch 368/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5500 - acc: 0.8206 - val_loss: 2.6156 - val_acc: 0.4454\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.75240\n",
            "Epoch 369/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5564 - acc: 0.8138 - val_loss: 1.5441 - val_acc: 0.5847\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.75240\n",
            "Epoch 370/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5757 - acc: 0.8161 - val_loss: 1.8927 - val_acc: 0.5673\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.75240\n",
            "Epoch 371/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5658 - acc: 0.8142 - val_loss: 1.5241 - val_acc: 0.6216\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.75240\n",
            "Epoch 372/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5792 - acc: 0.8077 - val_loss: 1.2193 - val_acc: 0.6857\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.75240\n",
            "Epoch 373/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5676 - acc: 0.8165 - val_loss: 2.1864 - val_acc: 0.5315\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.75240\n",
            "Epoch 374/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5778 - acc: 0.8130 - val_loss: 0.8354 - val_acc: 0.7332\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.75240\n",
            "Epoch 375/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5823 - acc: 0.8110 - val_loss: 1.1177 - val_acc: 0.6571\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.75240\n",
            "Epoch 376/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5521 - acc: 0.8226 - val_loss: 2.5099 - val_acc: 0.5063\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.75240\n",
            "Epoch 377/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5831 - acc: 0.8070 - val_loss: 1.2949 - val_acc: 0.6296\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.75240\n",
            "Epoch 378/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5532 - acc: 0.8213 - val_loss: 1.1307 - val_acc: 0.6591\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.75240\n",
            "Epoch 379/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.5490 - acc: 0.8215 - val_loss: 2.9266 - val_acc: 0.4245\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.75240\n",
            "Epoch 380/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5700 - acc: 0.8115 - val_loss: 0.9808 - val_acc: 0.7013\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.75240\n",
            "Epoch 381/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5651 - acc: 0.8218 - val_loss: 1.4265 - val_acc: 0.6144\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.75240\n",
            "Epoch 382/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5610 - acc: 0.8176 - val_loss: 2.7780 - val_acc: 0.4871\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.75240\n",
            "Epoch 383/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5698 - acc: 0.8089 - val_loss: 1.2340 - val_acc: 0.6452\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.75240\n",
            "Epoch 384/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5743 - acc: 0.8103 - val_loss: 1.9371 - val_acc: 0.5616\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.75240\n",
            "Epoch 385/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5639 - acc: 0.8200 - val_loss: 2.2958 - val_acc: 0.4534\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.75240\n",
            "Epoch 386/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5581 - acc: 0.8170 - val_loss: 0.9527 - val_acc: 0.7206\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.75240\n",
            "Epoch 387/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5759 - acc: 0.8092 - val_loss: 2.0927 - val_acc: 0.5456\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.75240\n",
            "Epoch 388/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5458 - acc: 0.8215 - val_loss: 1.1455 - val_acc: 0.6723\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.75240\n",
            "Epoch 389/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5463 - acc: 0.8183 - val_loss: 2.1327 - val_acc: 0.4857\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.75240\n",
            "Epoch 390/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.5606 - acc: 0.8119 - val_loss: 3.2737 - val_acc: 0.4147\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.75240\n",
            "Epoch 391/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5670 - acc: 0.8121 - val_loss: 1.1458 - val_acc: 0.6791\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.75240\n",
            "Epoch 392/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5570 - acc: 0.8140 - val_loss: 1.2399 - val_acc: 0.6584\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.75240\n",
            "Epoch 393/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5368 - acc: 0.8250 - val_loss: 1.4440 - val_acc: 0.6343\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.75240\n",
            "Epoch 394/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5347 - acc: 0.8220 - val_loss: 2.6572 - val_acc: 0.4449\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.75240\n",
            "Epoch 395/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5637 - acc: 0.8136 - val_loss: 0.8322 - val_acc: 0.7405\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.75240\n",
            "Epoch 396/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5691 - acc: 0.8128 - val_loss: 1.1272 - val_acc: 0.6599\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.75240\n",
            "Epoch 397/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5409 - acc: 0.8248 - val_loss: 0.9122 - val_acc: 0.7183\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.75240\n",
            "Epoch 398/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5573 - acc: 0.8164 - val_loss: 1.3856 - val_acc: 0.6096\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.75240\n",
            "Epoch 399/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5542 - acc: 0.8195 - val_loss: 2.6866 - val_acc: 0.5468\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.75240\n",
            "Epoch 400/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.5595 - acc: 0.8153 - val_loss: 2.9854 - val_acc: 0.4890\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.75240\n",
            "Epoch 401/1000\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.5467 - acc: 0.8186 - val_loss: 3.2898 - val_acc: 0.3982\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.75240\n",
            "Epoch 402/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.4651 - acc: 0.8561 - val_loss: 0.5444 - val_acc: 0.8186\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.75240 to 0.81860, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.3814 - acc: 0.8811 - val_loss: 0.4420 - val_acc: 0.8565\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.81860 to 0.85650, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.3614 - acc: 0.8877 - val_loss: 0.4302 - val_acc: 0.8597\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.85650 to 0.85970, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.3609 - acc: 0.8854 - val_loss: 0.3945 - val_acc: 0.8733\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.85970 to 0.87330, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.3388 - acc: 0.8919 - val_loss: 0.4127 - val_acc: 0.8669\n",
            "\n",
            "Epoch 00406: val_acc did not improve from 0.87330\n",
            "Epoch 407/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.3248 - acc: 0.8984 - val_loss: 0.4204 - val_acc: 0.8638\n",
            "\n",
            "Epoch 00407: val_acc did not improve from 0.87330\n",
            "Epoch 408/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.3272 - acc: 0.8920 - val_loss: 0.3931 - val_acc: 0.8751\n",
            "\n",
            "Epoch 00408: val_acc improved from 0.87330 to 0.87510, saving model to /content/saved_models/cifar10_ResNet32v1_model.408.h5\n",
            "Epoch 409/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.3299 - acc: 0.8916 - val_loss: 0.3906 - val_acc: 0.8757\n",
            "\n",
            "Epoch 00409: val_acc improved from 0.87510 to 0.87570, saving model to /content/saved_models/cifar10_ResNet32v1_model.409.h5\n",
            "Epoch 410/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.3086 - acc: 0.9076 - val_loss: 0.3758 - val_acc: 0.8781\n",
            "\n",
            "Epoch 00410: val_acc improved from 0.87570 to 0.87810, saving model to /content/saved_models/cifar10_ResNet32v1_model.410.h5\n",
            "Epoch 411/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.2983 - acc: 0.9039 - val_loss: 0.3746 - val_acc: 0.8762\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.87810\n",
            "Epoch 412/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.3078 - acc: 0.9031 - val_loss: 0.3673 - val_acc: 0.8828\n",
            "\n",
            "Epoch 00412: val_acc improved from 0.87810 to 0.88280, saving model to /content/saved_models/cifar10_ResNet32v1_model.412.h5\n",
            "Epoch 413/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.3227 - acc: 0.8921 - val_loss: 0.3818 - val_acc: 0.8785\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.88280\n",
            "Epoch 414/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.2821 - acc: 0.9093 - val_loss: 0.4221 - val_acc: 0.8675\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.88280\n",
            "Epoch 415/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.2798 - acc: 0.9085 - val_loss: 0.3705 - val_acc: 0.8805\n",
            "\n",
            "Epoch 00415: val_acc did not improve from 0.88280\n",
            "Epoch 416/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.2861 - acc: 0.9090 - val_loss: 0.3682 - val_acc: 0.8831\n",
            "\n",
            "Epoch 00416: val_acc improved from 0.88280 to 0.88310, saving model to /content/saved_models/cifar10_ResNet32v1_model.416.h5\n",
            "Epoch 417/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.2937 - acc: 0.9043 - val_loss: 0.3644 - val_acc: 0.8844\n",
            "\n",
            "Epoch 00417: val_acc improved from 0.88310 to 0.88440, saving model to /content/saved_models/cifar10_ResNet32v1_model.417.h5\n",
            "Epoch 418/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.2709 - acc: 0.9175 - val_loss: 0.3692 - val_acc: 0.8776\n",
            "\n",
            "Epoch 00418: val_acc did not improve from 0.88440\n",
            "Epoch 419/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.2755 - acc: 0.9143 - val_loss: 0.3410 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00419: val_acc improved from 0.88440 to 0.89120, saving model to /content/saved_models/cifar10_ResNet32v1_model.419.h5\n",
            "Epoch 420/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.2596 - acc: 0.9187 - val_loss: 0.3767 - val_acc: 0.8790\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.89120\n",
            "Epoch 421/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.2592 - acc: 0.9150 - val_loss: 0.3753 - val_acc: 0.8808\n",
            "\n",
            "Epoch 00421: val_acc did not improve from 0.89120\n",
            "Epoch 422/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.2639 - acc: 0.9208 - val_loss: 0.3901 - val_acc: 0.8748\n",
            "\n",
            "Epoch 00422: val_acc did not improve from 0.89120\n",
            "Epoch 423/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.2529 - acc: 0.9204 - val_loss: 0.4059 - val_acc: 0.8713\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.89120\n",
            "Epoch 424/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.2545 - acc: 0.9171 - val_loss: 0.3605 - val_acc: 0.8829\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.89120\n",
            "Epoch 425/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.2599 - acc: 0.9173 - val_loss: 0.3588 - val_acc: 0.8843\n",
            "\n",
            "Epoch 00425: val_acc did not improve from 0.89120\n",
            "Epoch 426/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.2614 - acc: 0.9160 - val_loss: 0.3895 - val_acc: 0.8740\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.89120\n",
            "Epoch 427/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.2533 - acc: 0.9177 - val_loss: 0.3654 - val_acc: 0.8810\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.89120\n",
            "Epoch 428/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.2474 - acc: 0.9211 - val_loss: 0.3584 - val_acc: 0.8858\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.89120\n",
            "Epoch 429/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.2497 - acc: 0.9212 - val_loss: 0.3783 - val_acc: 0.8812\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.89120\n",
            "Epoch 430/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.2614 - acc: 0.9153 - val_loss: 0.4057 - val_acc: 0.8724\n",
            "\n",
            "Epoch 00430: val_acc did not improve from 0.89120\n",
            "Epoch 431/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.2432 - acc: 0.9245 - val_loss: 0.3361 - val_acc: 0.8923\n",
            "\n",
            "Epoch 00431: val_acc improved from 0.89120 to 0.89230, saving model to /content/saved_models/cifar10_ResNet32v1_model.431.h5\n",
            "Epoch 432/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.2291 - acc: 0.9313 - val_loss: 0.3843 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.89230\n",
            "Epoch 433/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.2407 - acc: 0.9211 - val_loss: 0.3873 - val_acc: 0.8751\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.89230\n",
            "Epoch 434/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.2462 - acc: 0.9199 - val_loss: 0.3541 - val_acc: 0.8879\n",
            "\n",
            "Epoch 00434: val_acc did not improve from 0.89230\n",
            "Epoch 435/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.2345 - acc: 0.9260 - val_loss: 0.3645 - val_acc: 0.8852\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.89230\n",
            "Epoch 436/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.2383 - acc: 0.9218 - val_loss: 0.3529 - val_acc: 0.8864\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.89230\n",
            "Epoch 437/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.2507 - acc: 0.9220 - val_loss: 0.3465 - val_acc: 0.8877\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.89230\n",
            "Epoch 438/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.2251 - acc: 0.9283 - val_loss: 0.3831 - val_acc: 0.8817\n",
            "\n",
            "Epoch 00438: val_acc did not improve from 0.89230\n",
            "Epoch 439/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.2354 - acc: 0.9229 - val_loss: 0.3613 - val_acc: 0.8837\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.89230\n",
            "Epoch 440/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.2332 - acc: 0.9264 - val_loss: 0.3400 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00440: val_acc did not improve from 0.89230\n",
            "Epoch 441/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.2422 - acc: 0.9219 - val_loss: 0.3260 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00441: val_acc improved from 0.89230 to 0.89850, saving model to /content/saved_models/cifar10_ResNet32v1_model.441.h5\n",
            "Epoch 442/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.2097 - acc: 0.9382 - val_loss: 0.3699 - val_acc: 0.8822\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.89850\n",
            "Epoch 443/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.2254 - acc: 0.9268 - val_loss: 0.3311 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.89850\n",
            "Epoch 444/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.2052 - acc: 0.9379 - val_loss: 0.3445 - val_acc: 0.8897\n",
            "\n",
            "Epoch 00444: val_acc did not improve from 0.89850\n",
            "Epoch 445/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.2149 - acc: 0.9295 - val_loss: 0.3505 - val_acc: 0.8863\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.89850\n",
            "Epoch 446/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.2118 - acc: 0.9355 - val_loss: 0.3822 - val_acc: 0.8798\n",
            "\n",
            "Epoch 00446: val_acc did not improve from 0.89850\n",
            "Epoch 447/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.2214 - acc: 0.9287 - val_loss: 0.3633 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.89850\n",
            "Epoch 448/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.2040 - acc: 0.9379 - val_loss: 0.3579 - val_acc: 0.8860\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.89850\n",
            "Epoch 449/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.2144 - acc: 0.9279 - val_loss: 0.3843 - val_acc: 0.8797\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.89850\n",
            "Epoch 450/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1964 - acc: 0.9400 - val_loss: 0.3322 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.89850\n",
            "Epoch 451/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.2070 - acc: 0.9336 - val_loss: 0.3629 - val_acc: 0.8864\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.89850\n",
            "Epoch 452/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.2107 - acc: 0.9355 - val_loss: 0.3593 - val_acc: 0.8857\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.89850\n",
            "Epoch 453/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.1921 - acc: 0.9426 - val_loss: 0.3203 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00453: val_acc improved from 0.89850 to 0.89990, saving model to /content/saved_models/cifar10_ResNet32v1_model.453.h5\n",
            "Epoch 454/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1998 - acc: 0.9407 - val_loss: 0.3304 - val_acc: 0.8971\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.89990\n",
            "Epoch 455/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1883 - acc: 0.9436 - val_loss: 0.3430 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.89990\n",
            "Epoch 456/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.2009 - acc: 0.9320 - val_loss: 0.3850 - val_acc: 0.8806\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.89990\n",
            "Epoch 457/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1981 - acc: 0.9401 - val_loss: 0.3470 - val_acc: 0.8910\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.89990\n",
            "Epoch 458/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.2025 - acc: 0.9392 - val_loss: 0.3390 - val_acc: 0.8908\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.89990\n",
            "Epoch 459/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1871 - acc: 0.9414 - val_loss: 0.3325 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.89990\n",
            "Epoch 460/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.2108 - acc: 0.9313 - val_loss: 0.3946 - val_acc: 0.8800\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.89990\n",
            "Epoch 461/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1976 - acc: 0.9350 - val_loss: 0.3312 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00461: val_acc did not improve from 0.89990\n",
            "Epoch 462/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1940 - acc: 0.9415 - val_loss: 0.3555 - val_acc: 0.8858\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.89990\n",
            "Epoch 463/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1957 - acc: 0.9402 - val_loss: 0.3569 - val_acc: 0.8882\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.89990\n",
            "Epoch 464/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1969 - acc: 0.9378 - val_loss: 0.3369 - val_acc: 0.8940\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.89990\n",
            "Epoch 465/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1910 - acc: 0.9375 - val_loss: 0.3234 - val_acc: 0.8971\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.89990\n",
            "Epoch 466/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1844 - acc: 0.9436 - val_loss: 0.3534 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.89990\n",
            "Epoch 467/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1886 - acc: 0.9390 - val_loss: 0.3163 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00467: val_acc improved from 0.89990 to 0.90190, saving model to /content/saved_models/cifar10_ResNet32v1_model.467.h5\n",
            "Epoch 468/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1964 - acc: 0.9414 - val_loss: 0.3656 - val_acc: 0.8891\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.90190\n",
            "Epoch 469/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1848 - acc: 0.9433 - val_loss: 0.3582 - val_acc: 0.8907\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.90190\n",
            "Epoch 470/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1881 - acc: 0.9424 - val_loss: 0.3783 - val_acc: 0.8851\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.90190\n",
            "Epoch 471/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1877 - acc: 0.9391 - val_loss: 0.3639 - val_acc: 0.8873\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.90190\n",
            "Epoch 472/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1799 - acc: 0.9429 - val_loss: 0.3212 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.90190\n",
            "Epoch 473/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1753 - acc: 0.9477 - val_loss: 0.3606 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.90190\n",
            "Epoch 474/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1809 - acc: 0.9429 - val_loss: 0.3914 - val_acc: 0.8801\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.90190\n",
            "Epoch 475/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1676 - acc: 0.9475 - val_loss: 0.3713 - val_acc: 0.8841\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.90190\n",
            "Epoch 476/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1837 - acc: 0.9430 - val_loss: 0.3479 - val_acc: 0.8948\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.90190\n",
            "Epoch 477/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1856 - acc: 0.9431 - val_loss: 0.3428 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.90190\n",
            "Epoch 478/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1664 - acc: 0.9481 - val_loss: 0.3690 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.90190\n",
            "Epoch 479/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1763 - acc: 0.9444 - val_loss: 0.3161 - val_acc: 0.8987\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.90190\n",
            "Epoch 480/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1722 - acc: 0.9466 - val_loss: 0.3535 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.90190\n",
            "Epoch 481/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1660 - acc: 0.9497 - val_loss: 0.3387 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00481: val_acc did not improve from 0.90190\n",
            "Epoch 482/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1834 - acc: 0.9421 - val_loss: 0.3313 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.90190\n",
            "Epoch 483/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1744 - acc: 0.9447 - val_loss: 0.3403 - val_acc: 0.8954\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.90190\n",
            "Epoch 484/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1610 - acc: 0.9513 - val_loss: 0.3433 - val_acc: 0.8940\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.90190\n",
            "Epoch 485/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1584 - acc: 0.9509 - val_loss: 0.3929 - val_acc: 0.8829\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.90190\n",
            "Epoch 486/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1769 - acc: 0.9445 - val_loss: 0.3327 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.90190\n",
            "Epoch 487/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1794 - acc: 0.9453 - val_loss: 0.3406 - val_acc: 0.8958\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.90190\n",
            "Epoch 488/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1640 - acc: 0.9511 - val_loss: 0.3791 - val_acc: 0.8860\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.90190\n",
            "Epoch 489/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1819 - acc: 0.9452 - val_loss: 0.3595 - val_acc: 0.8907\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.90190\n",
            "Epoch 490/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1700 - acc: 0.9484 - val_loss: 0.3577 - val_acc: 0.8872\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.90190\n",
            "Epoch 491/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1581 - acc: 0.9549 - val_loss: 0.3643 - val_acc: 0.8915\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.90190\n",
            "Epoch 492/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1649 - acc: 0.9491 - val_loss: 0.3616 - val_acc: 0.8919\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.90190\n",
            "Epoch 493/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1710 - acc: 0.9489 - val_loss: 0.3567 - val_acc: 0.8877\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.90190\n",
            "Epoch 494/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1704 - acc: 0.9479 - val_loss: 0.3367 - val_acc: 0.8958\n",
            "\n",
            "Epoch 00494: val_acc did not improve from 0.90190\n",
            "Epoch 495/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1541 - acc: 0.9539 - val_loss: 0.3586 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.90190\n",
            "Epoch 496/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1621 - acc: 0.9481 - val_loss: 0.3258 - val_acc: 0.8949\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.90190\n",
            "Epoch 497/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1576 - acc: 0.9539 - val_loss: 0.3895 - val_acc: 0.8825\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.90190\n",
            "Epoch 498/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1605 - acc: 0.9469 - val_loss: 0.3873 - val_acc: 0.8863\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.90190\n",
            "Epoch 499/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1569 - acc: 0.9527 - val_loss: 0.3455 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.90190\n",
            "Epoch 500/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1637 - acc: 0.9502 - val_loss: 0.3787 - val_acc: 0.8901\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.90190\n",
            "Epoch 501/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1508 - acc: 0.9548 - val_loss: 0.3872 - val_acc: 0.8862\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.90190\n",
            "Epoch 502/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.1677 - acc: 0.9487 - val_loss: 0.3977 - val_acc: 0.8812\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.90190\n",
            "Epoch 503/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1438 - acc: 0.9555 - val_loss: 0.3415 - val_acc: 0.8923\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.90190\n",
            "Epoch 504/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1616 - acc: 0.9519 - val_loss: 0.3783 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.90190\n",
            "Epoch 505/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1499 - acc: 0.9553 - val_loss: 0.3807 - val_acc: 0.8806\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.90190\n",
            "Epoch 506/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1526 - acc: 0.9494 - val_loss: 0.3245 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.90190\n",
            "Epoch 507/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1607 - acc: 0.9517 - val_loss: 0.3609 - val_acc: 0.8891\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.90190\n",
            "Epoch 508/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1579 - acc: 0.9497 - val_loss: 0.3831 - val_acc: 0.8878\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.90190\n",
            "Epoch 509/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1638 - acc: 0.9499 - val_loss: 0.3518 - val_acc: 0.8949\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.90190\n",
            "Epoch 510/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1617 - acc: 0.9501 - val_loss: 0.3653 - val_acc: 0.8882\n",
            "\n",
            "Epoch 00510: val_acc did not improve from 0.90190\n",
            "Epoch 511/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1495 - acc: 0.9534 - val_loss: 0.3291 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.90190\n",
            "Epoch 512/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1465 - acc: 0.9575 - val_loss: 0.4036 - val_acc: 0.8820\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.90190\n",
            "Epoch 513/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1508 - acc: 0.9553 - val_loss: 0.3742 - val_acc: 0.8858\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.90190\n",
            "Epoch 514/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1448 - acc: 0.9564 - val_loss: 0.3438 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.90190\n",
            "Epoch 515/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1460 - acc: 0.9566 - val_loss: 0.3689 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.90190\n",
            "Epoch 516/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1533 - acc: 0.9510 - val_loss: 0.4080 - val_acc: 0.8831\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.90190\n",
            "Epoch 517/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1355 - acc: 0.9591 - val_loss: 0.4095 - val_acc: 0.8802\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.90190\n",
            "Epoch 518/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1465 - acc: 0.9553 - val_loss: 0.3832 - val_acc: 0.8853\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.90190\n",
            "Epoch 519/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1476 - acc: 0.9546 - val_loss: 0.3466 - val_acc: 0.8958\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.90190\n",
            "Epoch 520/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1453 - acc: 0.9573 - val_loss: 0.4038 - val_acc: 0.8822\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.90190\n",
            "Epoch 521/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1473 - acc: 0.9541 - val_loss: 0.3730 - val_acc: 0.8879\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.90190\n",
            "Epoch 522/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1553 - acc: 0.9520 - val_loss: 0.3568 - val_acc: 0.8919\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.90190\n",
            "Epoch 523/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1559 - acc: 0.9491 - val_loss: 0.3656 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.90190\n",
            "Epoch 524/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1431 - acc: 0.9529 - val_loss: 0.3374 - val_acc: 0.8933\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.90190\n",
            "Epoch 525/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1400 - acc: 0.9598 - val_loss: 0.4016 - val_acc: 0.8808\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.90190\n",
            "Epoch 526/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1437 - acc: 0.9558 - val_loss: 0.4305 - val_acc: 0.8726\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.90190\n",
            "Epoch 527/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1337 - acc: 0.9611 - val_loss: 0.3481 - val_acc: 0.8977\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.90190\n",
            "Epoch 528/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1422 - acc: 0.9548 - val_loss: 0.3367 - val_acc: 0.8998\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.90190\n",
            "Epoch 529/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1233 - acc: 0.9629 - val_loss: 0.4186 - val_acc: 0.8745\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.90190\n",
            "Epoch 530/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1337 - acc: 0.9606 - val_loss: 0.4022 - val_acc: 0.8786\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.90190\n",
            "Epoch 531/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1473 - acc: 0.9582 - val_loss: 0.3424 - val_acc: 0.8972\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.90190\n",
            "Epoch 532/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.1394 - acc: 0.9585 - val_loss: 0.3708 - val_acc: 0.8901\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.90190\n",
            "Epoch 533/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.1338 - acc: 0.9607 - val_loss: 0.3466 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.90190\n",
            "Epoch 534/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1385 - acc: 0.9552 - val_loss: 0.3377 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.90190\n",
            "Epoch 535/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.1329 - acc: 0.9607 - val_loss: 0.3462 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.90190\n",
            "Epoch 536/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1318 - acc: 0.9599 - val_loss: 0.3757 - val_acc: 0.8866\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.90190\n",
            "Epoch 537/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1332 - acc: 0.9617 - val_loss: 0.3488 - val_acc: 0.8945\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.90190\n",
            "Epoch 538/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1378 - acc: 0.9586 - val_loss: 0.3618 - val_acc: 0.8953\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.90190\n",
            "Epoch 539/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1376 - acc: 0.9596 - val_loss: 0.3482 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.90190\n",
            "Epoch 540/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1309 - acc: 0.9611 - val_loss: 0.3533 - val_acc: 0.8934\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.90190\n",
            "Epoch 541/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1308 - acc: 0.9601 - val_loss: 0.3882 - val_acc: 0.8903\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.90190\n",
            "Epoch 542/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1306 - acc: 0.9602 - val_loss: 0.3685 - val_acc: 0.8932\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.90190\n",
            "Epoch 543/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1353 - acc: 0.9582 - val_loss: 0.3481 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.90190\n",
            "Epoch 544/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1356 - acc: 0.9592 - val_loss: 0.3377 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.90190\n",
            "Epoch 545/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1428 - acc: 0.9547 - val_loss: 0.3869 - val_acc: 0.8901\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.90190\n",
            "Epoch 546/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1310 - acc: 0.9612 - val_loss: 0.3985 - val_acc: 0.8858\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.90190\n",
            "Epoch 547/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1179 - acc: 0.9666 - val_loss: 0.3377 - val_acc: 0.8979\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.90190\n",
            "Epoch 548/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1385 - acc: 0.9582 - val_loss: 0.3626 - val_acc: 0.8927\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.90190\n",
            "Epoch 549/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1362 - acc: 0.9593 - val_loss: 0.4004 - val_acc: 0.8820\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.90190\n",
            "Epoch 550/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1358 - acc: 0.9607 - val_loss: 0.4298 - val_acc: 0.8785\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.90190\n",
            "Epoch 551/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1370 - acc: 0.9597 - val_loss: 0.3743 - val_acc: 0.8901\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.90190\n",
            "Epoch 552/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1334 - acc: 0.9598 - val_loss: 0.3492 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.90190\n",
            "Epoch 553/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1444 - acc: 0.9561 - val_loss: 0.3357 - val_acc: 0.9030\n",
            "\n",
            "Epoch 00553: val_acc improved from 0.90190 to 0.90300, saving model to /content/saved_models/cifar10_ResNet32v1_model.553.h5\n",
            "Epoch 554/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1384 - acc: 0.9556 - val_loss: 0.4547 - val_acc: 0.8720\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.90300\n",
            "Epoch 555/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1318 - acc: 0.9627 - val_loss: 0.3298 - val_acc: 0.9038\n",
            "\n",
            "Epoch 00555: val_acc improved from 0.90300 to 0.90380, saving model to /content/saved_models/cifar10_ResNet32v1_model.555.h5\n",
            "Epoch 556/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1204 - acc: 0.9627 - val_loss: 0.3445 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.90380\n",
            "Epoch 557/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1419 - acc: 0.9552 - val_loss: 0.4063 - val_acc: 0.8826\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.90380\n",
            "Epoch 558/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1288 - acc: 0.9610 - val_loss: 0.3314 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.90380\n",
            "Epoch 559/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1181 - acc: 0.9673 - val_loss: 0.3555 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.90380\n",
            "Epoch 560/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1343 - acc: 0.9583 - val_loss: 0.3812 - val_acc: 0.8899\n",
            "\n",
            "Epoch 00560: val_acc did not improve from 0.90380\n",
            "Epoch 561/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1163 - acc: 0.9634 - val_loss: 0.3578 - val_acc: 0.8933\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.90380\n",
            "Epoch 562/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1401 - acc: 0.9578 - val_loss: 0.3977 - val_acc: 0.8868\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.90380\n",
            "Epoch 563/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.1276 - acc: 0.9613 - val_loss: 0.3482 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.90380\n",
            "Epoch 564/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1224 - acc: 0.9636 - val_loss: 0.3845 - val_acc: 0.8919\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.90380\n",
            "Epoch 565/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1274 - acc: 0.9613 - val_loss: 0.3474 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00565: val_acc did not improve from 0.90380\n",
            "Epoch 566/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1270 - acc: 0.9590 - val_loss: 0.3252 - val_acc: 0.9034\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.90380\n",
            "Epoch 567/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1247 - acc: 0.9616 - val_loss: 0.3345 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.90380\n",
            "Epoch 568/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1271 - acc: 0.9609 - val_loss: 0.3646 - val_acc: 0.8935\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.90380\n",
            "Epoch 569/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1269 - acc: 0.9642 - val_loss: 0.3557 - val_acc: 0.8949\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.90380\n",
            "Epoch 570/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1297 - acc: 0.9591 - val_loss: 0.3738 - val_acc: 0.8928\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.90380\n",
            "Epoch 571/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1304 - acc: 0.9599 - val_loss: 0.3443 - val_acc: 0.8971\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.90380\n",
            "Epoch 572/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1175 - acc: 0.9657 - val_loss: 0.3468 - val_acc: 0.8966\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.90380\n",
            "Epoch 573/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1265 - acc: 0.9610 - val_loss: 0.3814 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.90380\n",
            "Epoch 574/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1267 - acc: 0.9618 - val_loss: 0.4339 - val_acc: 0.8795\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.90380\n",
            "Epoch 575/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1287 - acc: 0.9622 - val_loss: 0.3546 - val_acc: 0.8948\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.90380\n",
            "Epoch 576/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1294 - acc: 0.9602 - val_loss: 0.3181 - val_acc: 0.9053\n",
            "\n",
            "Epoch 00576: val_acc improved from 0.90380 to 0.90530, saving model to /content/saved_models/cifar10_ResNet32v1_model.576.h5\n",
            "Epoch 577/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1091 - acc: 0.9707 - val_loss: 0.3837 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.90530\n",
            "Epoch 578/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1276 - acc: 0.9596 - val_loss: 0.3581 - val_acc: 0.8965\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.90530\n",
            "Epoch 579/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1249 - acc: 0.9612 - val_loss: 0.3564 - val_acc: 0.8952\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.90530\n",
            "Epoch 580/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1169 - acc: 0.9658 - val_loss: 0.3540 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.90530\n",
            "Epoch 581/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1157 - acc: 0.9643 - val_loss: 0.3857 - val_acc: 0.8877\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.90530\n",
            "Epoch 582/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1220 - acc: 0.9607 - val_loss: 0.3853 - val_acc: 0.8905\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.90530\n",
            "Epoch 583/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1129 - acc: 0.9659 - val_loss: 0.3489 - val_acc: 0.8972\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.90530\n",
            "Epoch 584/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1122 - acc: 0.9651 - val_loss: 0.3680 - val_acc: 0.8962\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.90530\n",
            "Epoch 585/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1145 - acc: 0.9670 - val_loss: 0.3508 - val_acc: 0.8952\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.90530\n",
            "Epoch 586/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1199 - acc: 0.9645 - val_loss: 0.3668 - val_acc: 0.8921\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.90530\n",
            "Epoch 587/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1203 - acc: 0.9615 - val_loss: 0.3603 - val_acc: 0.8935\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.90530\n",
            "Epoch 588/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1208 - acc: 0.9661 - val_loss: 0.3732 - val_acc: 0.8928\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.90530\n",
            "Epoch 589/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1108 - acc: 0.9688 - val_loss: 0.3916 - val_acc: 0.8913\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.90530\n",
            "Epoch 590/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1237 - acc: 0.9628 - val_loss: 0.3577 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.90530\n",
            "Epoch 591/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1223 - acc: 0.9608 - val_loss: 0.3705 - val_acc: 0.8960\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.90530\n",
            "Epoch 592/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1162 - acc: 0.9637 - val_loss: 0.3487 - val_acc: 0.8987\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.90530\n",
            "Epoch 593/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1152 - acc: 0.9643 - val_loss: 0.4281 - val_acc: 0.8844\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.90530\n",
            "Epoch 594/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1143 - acc: 0.9688 - val_loss: 0.3704 - val_acc: 0.8935\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.90530\n",
            "Epoch 595/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1211 - acc: 0.9624 - val_loss: 0.3460 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.90530\n",
            "Epoch 596/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1177 - acc: 0.9631 - val_loss: 0.3364 - val_acc: 0.9018\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.90530\n",
            "Epoch 597/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1082 - acc: 0.9682 - val_loss: 0.3869 - val_acc: 0.8947\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.90530\n",
            "Epoch 598/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1131 - acc: 0.9647 - val_loss: 0.3376 - val_acc: 0.9029\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.90530\n",
            "Epoch 599/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1049 - acc: 0.9698 - val_loss: 0.3621 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.90530\n",
            "Epoch 600/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1153 - acc: 0.9636 - val_loss: 0.3683 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.90530\n",
            "Epoch 601/1000\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1228 - acc: 0.9616 - val_loss: 0.3899 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.90530\n",
            "Epoch 602/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1090 - acc: 0.9694 - val_loss: 0.3207 - val_acc: 0.9071\n",
            "\n",
            "Epoch 00602: val_acc improved from 0.90530 to 0.90710, saving model to /content/saved_models/cifar10_ResNet32v1_model.602.h5\n",
            "Epoch 603/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1051 - acc: 0.9686 - val_loss: 0.3119 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00603: val_acc improved from 0.90710 to 0.91040, saving model to /content/saved_models/cifar10_ResNet32v1_model.603.h5\n",
            "Epoch 604/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1004 - acc: 0.9704 - val_loss: 0.3085 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00604: val_acc improved from 0.91040 to 0.91070, saving model to /content/saved_models/cifar10_ResNet32v1_model.604.h5\n",
            "Epoch 605/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1071 - acc: 0.9687 - val_loss: 0.3055 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00605: val_acc improved from 0.91070 to 0.91100, saving model to /content/saved_models/cifar10_ResNet32v1_model.605.h5\n",
            "Epoch 606/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1033 - acc: 0.9704 - val_loss: 0.3040 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00606: val_acc improved from 0.91100 to 0.91150, saving model to /content/saved_models/cifar10_ResNet32v1_model.606.h5\n",
            "Epoch 607/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1048 - acc: 0.9714 - val_loss: 0.3036 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00607: val_acc did not improve from 0.91150\n",
            "Epoch 608/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1115 - acc: 0.9661 - val_loss: 0.3023 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00608: val_acc did not improve from 0.91150\n",
            "Epoch 609/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0971 - acc: 0.9732 - val_loss: 0.3014 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00609: val_acc improved from 0.91150 to 0.91200, saving model to /content/saved_models/cifar10_ResNet32v1_model.609.h5\n",
            "Epoch 610/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1048 - acc: 0.9692 - val_loss: 0.3010 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00610: val_acc improved from 0.91200 to 0.91240, saving model to /content/saved_models/cifar10_ResNet32v1_model.610.h5\n",
            "Epoch 611/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1015 - acc: 0.9723 - val_loss: 0.3006 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00611: val_acc improved from 0.91240 to 0.91310, saving model to /content/saved_models/cifar10_ResNet32v1_model.611.h5\n",
            "Epoch 612/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1009 - acc: 0.9718 - val_loss: 0.2998 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00612: val_acc did not improve from 0.91310\n",
            "Epoch 613/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1007 - acc: 0.9719 - val_loss: 0.2997 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00613: val_acc improved from 0.91310 to 0.91320, saving model to /content/saved_models/cifar10_ResNet32v1_model.613.h5\n",
            "Epoch 614/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0969 - acc: 0.9744 - val_loss: 0.2997 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00614: val_acc improved from 0.91320 to 0.91350, saving model to /content/saved_models/cifar10_ResNet32v1_model.614.h5\n",
            "Epoch 615/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0937 - acc: 0.9738 - val_loss: 0.3003 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00615: val_acc did not improve from 0.91350\n",
            "Epoch 616/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0995 - acc: 0.9723 - val_loss: 0.2982 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00616: val_acc improved from 0.91350 to 0.91390, saving model to /content/saved_models/cifar10_ResNet32v1_model.616.h5\n",
            "Epoch 617/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0956 - acc: 0.9707 - val_loss: 0.2981 - val_acc: 0.9138\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.91390\n",
            "Epoch 618/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0993 - acc: 0.9750 - val_loss: 0.2967 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00618: val_acc improved from 0.91390 to 0.91430, saving model to /content/saved_models/cifar10_ResNet32v1_model.618.h5\n",
            "Epoch 619/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0907 - acc: 0.9759 - val_loss: 0.2972 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00619: val_acc improved from 0.91430 to 0.91450, saving model to /content/saved_models/cifar10_ResNet32v1_model.619.h5\n",
            "Epoch 620/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0998 - acc: 0.9714 - val_loss: 0.2971 - val_acc: 0.9147\n",
            "\n",
            "Epoch 00620: val_acc improved from 0.91450 to 0.91470, saving model to /content/saved_models/cifar10_ResNet32v1_model.620.h5\n",
            "Epoch 621/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1030 - acc: 0.9723 - val_loss: 0.2964 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00621: val_acc improved from 0.91470 to 0.91480, saving model to /content/saved_models/cifar10_ResNet32v1_model.621.h5\n",
            "Epoch 622/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0981 - acc: 0.9745 - val_loss: 0.2956 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00622: val_acc improved from 0.91480 to 0.91490, saving model to /content/saved_models/cifar10_ResNet32v1_model.622.h5\n",
            "Epoch 623/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0972 - acc: 0.9747 - val_loss: 0.2952 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00623: val_acc improved from 0.91490 to 0.91520, saving model to /content/saved_models/cifar10_ResNet32v1_model.623.h5\n",
            "Epoch 624/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0973 - acc: 0.9729 - val_loss: 0.2946 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.91520\n",
            "Epoch 625/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.1025 - acc: 0.9721 - val_loss: 0.2944 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.91520\n",
            "Epoch 626/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0993 - acc: 0.9716 - val_loss: 0.2939 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.91520\n",
            "Epoch 627/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1027 - acc: 0.9708 - val_loss: 0.2939 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00627: val_acc improved from 0.91520 to 0.91590, saving model to /content/saved_models/cifar10_ResNet32v1_model.627.h5\n",
            "Epoch 628/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0945 - acc: 0.9739 - val_loss: 0.2933 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00628: val_acc improved from 0.91590 to 0.91620, saving model to /content/saved_models/cifar10_ResNet32v1_model.628.h5\n",
            "Epoch 629/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0984 - acc: 0.9715 - val_loss: 0.2933 - val_acc: 0.9160\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.91620\n",
            "Epoch 630/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0911 - acc: 0.9750 - val_loss: 0.2938 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00630: val_acc improved from 0.91620 to 0.91650, saving model to /content/saved_models/cifar10_ResNet32v1_model.630.h5\n",
            "Epoch 631/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0956 - acc: 0.9730 - val_loss: 0.2933 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00631: val_acc improved from 0.91650 to 0.91670, saving model to /content/saved_models/cifar10_ResNet32v1_model.631.h5\n",
            "Epoch 632/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.1014 - acc: 0.9720 - val_loss: 0.2927 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00632: val_acc improved from 0.91670 to 0.91710, saving model to /content/saved_models/cifar10_ResNet32v1_model.632.h5\n",
            "Epoch 633/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0886 - acc: 0.9744 - val_loss: 0.2926 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.91710\n",
            "Epoch 634/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0911 - acc: 0.9735 - val_loss: 0.2921 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.91710\n",
            "Epoch 635/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0935 - acc: 0.9746 - val_loss: 0.2928 - val_acc: 0.9173\n",
            "\n",
            "Epoch 00635: val_acc improved from 0.91710 to 0.91730, saving model to /content/saved_models/cifar10_ResNet32v1_model.635.h5\n",
            "Epoch 636/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0884 - acc: 0.9752 - val_loss: 0.2926 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00636: val_acc improved from 0.91730 to 0.91740, saving model to /content/saved_models/cifar10_ResNet32v1_model.636.h5\n",
            "Epoch 637/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0995 - acc: 0.9718 - val_loss: 0.2921 - val_acc: 0.9178\n",
            "\n",
            "Epoch 00637: val_acc improved from 0.91740 to 0.91780, saving model to /content/saved_models/cifar10_ResNet32v1_model.637.h5\n",
            "Epoch 638/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0970 - acc: 0.9748 - val_loss: 0.2926 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.91780\n",
            "Epoch 639/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0967 - acc: 0.9717 - val_loss: 0.2922 - val_acc: 0.9178\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.91780\n",
            "Epoch 640/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0901 - acc: 0.9742 - val_loss: 0.2928 - val_acc: 0.9173\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.91780\n",
            "Epoch 641/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0919 - acc: 0.9763 - val_loss: 0.2923 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.91780\n",
            "Epoch 642/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0925 - acc: 0.9744 - val_loss: 0.2914 - val_acc: 0.9181\n",
            "\n",
            "Epoch 00642: val_acc improved from 0.91780 to 0.91810, saving model to /content/saved_models/cifar10_ResNet32v1_model.642.h5\n",
            "Epoch 643/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0861 - acc: 0.9785 - val_loss: 0.2921 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.91810\n",
            "Epoch 644/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0955 - acc: 0.9741 - val_loss: 0.2912 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00644: val_acc did not improve from 0.91810\n",
            "Epoch 645/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0979 - acc: 0.9727 - val_loss: 0.2913 - val_acc: 0.9177\n",
            "\n",
            "Epoch 00645: val_acc did not improve from 0.91810\n",
            "Epoch 646/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0954 - acc: 0.9734 - val_loss: 0.2907 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00646: val_acc improved from 0.91810 to 0.91820, saving model to /content/saved_models/cifar10_ResNet32v1_model.646.h5\n",
            "Epoch 647/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0942 - acc: 0.9744 - val_loss: 0.2903 - val_acc: 0.9178\n",
            "\n",
            "Epoch 00647: val_acc did not improve from 0.91820\n",
            "Epoch 648/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0909 - acc: 0.9745 - val_loss: 0.2909 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.91820\n",
            "Epoch 649/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0974 - acc: 0.9718 - val_loss: 0.2906 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.91820\n",
            "Epoch 650/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.1001 - acc: 0.9701 - val_loss: 0.2907 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00650: val_acc did not improve from 0.91820\n",
            "Epoch 651/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0929 - acc: 0.9769 - val_loss: 0.2901 - val_acc: 0.9177\n",
            "\n",
            "Epoch 00651: val_acc did not improve from 0.91820\n",
            "Epoch 652/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0929 - acc: 0.9733 - val_loss: 0.2906 - val_acc: 0.9178\n",
            "\n",
            "Epoch 00652: val_acc did not improve from 0.91820\n",
            "Epoch 653/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.0821 - acc: 0.9776 - val_loss: 0.2896 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00653: val_acc did not improve from 0.91820\n",
            "Epoch 654/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0866 - acc: 0.9774 - val_loss: 0.2891 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00654: val_acc did not improve from 0.91820\n",
            "Epoch 655/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0914 - acc: 0.9735 - val_loss: 0.2897 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00655: val_acc did not improve from 0.91820\n",
            "Epoch 656/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0879 - acc: 0.9761 - val_loss: 0.2899 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00656: val_acc did not improve from 0.91820\n",
            "Epoch 657/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0866 - acc: 0.9766 - val_loss: 0.2890 - val_acc: 0.9177\n",
            "\n",
            "Epoch 00657: val_acc did not improve from 0.91820\n",
            "Epoch 658/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0908 - acc: 0.9746 - val_loss: 0.2901 - val_acc: 0.9175\n",
            "\n",
            "Epoch 00658: val_acc did not improve from 0.91820\n",
            "Epoch 659/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0947 - acc: 0.9744 - val_loss: 0.2892 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00659: val_acc did not improve from 0.91820\n",
            "Epoch 660/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0939 - acc: 0.9748 - val_loss: 0.2891 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00660: val_acc did not improve from 0.91820\n",
            "Epoch 661/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0882 - acc: 0.9754 - val_loss: 0.2895 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00661: val_acc did not improve from 0.91820\n",
            "Epoch 662/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0884 - acc: 0.9760 - val_loss: 0.2895 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00662: val_acc did not improve from 0.91820\n",
            "Epoch 663/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0929 - acc: 0.9710 - val_loss: 0.2887 - val_acc: 0.9175\n",
            "\n",
            "Epoch 00663: val_acc did not improve from 0.91820\n",
            "Epoch 664/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0884 - acc: 0.9764 - val_loss: 0.2890 - val_acc: 0.9175\n",
            "\n",
            "Epoch 00664: val_acc did not improve from 0.91820\n",
            "Epoch 665/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0918 - acc: 0.9741 - val_loss: 0.2896 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00665: val_acc did not improve from 0.91820\n",
            "Epoch 666/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0890 - acc: 0.9751 - val_loss: 0.2898 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00666: val_acc did not improve from 0.91820\n",
            "Epoch 667/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0869 - acc: 0.9760 - val_loss: 0.2899 - val_acc: 0.9173\n",
            "\n",
            "Epoch 00667: val_acc did not improve from 0.91820\n",
            "Epoch 668/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0871 - acc: 0.9753 - val_loss: 0.2896 - val_acc: 0.9178\n",
            "\n",
            "Epoch 00668: val_acc did not improve from 0.91820\n",
            "Epoch 669/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0916 - acc: 0.9744 - val_loss: 0.2890 - val_acc: 0.9177\n",
            "\n",
            "Epoch 00669: val_acc did not improve from 0.91820\n",
            "Epoch 670/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0851 - acc: 0.9773 - val_loss: 0.2893 - val_acc: 0.9177\n",
            "\n",
            "Epoch 00670: val_acc did not improve from 0.91820\n",
            "Epoch 671/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0838 - acc: 0.9787 - val_loss: 0.2891 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00671: val_acc did not improve from 0.91820\n",
            "Epoch 672/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0968 - acc: 0.9730 - val_loss: 0.2889 - val_acc: 0.9184\n",
            "\n",
            "Epoch 00672: val_acc improved from 0.91820 to 0.91840, saving model to /content/saved_models/cifar10_ResNet32v1_model.672.h5\n",
            "Epoch 673/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0882 - acc: 0.9751 - val_loss: 0.2894 - val_acc: 0.9183\n",
            "\n",
            "Epoch 00673: val_acc did not improve from 0.91840\n",
            "Epoch 674/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0858 - acc: 0.9792 - val_loss: 0.2891 - val_acc: 0.9177\n",
            "\n",
            "Epoch 00674: val_acc did not improve from 0.91840\n",
            "Epoch 675/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0912 - acc: 0.9754 - val_loss: 0.2887 - val_acc: 0.9178\n",
            "\n",
            "Epoch 00675: val_acc did not improve from 0.91840\n",
            "Epoch 676/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0867 - acc: 0.9780 - val_loss: 0.2880 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00676: val_acc did not improve from 0.91840\n",
            "Epoch 677/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0963 - acc: 0.9717 - val_loss: 0.2884 - val_acc: 0.9185\n",
            "\n",
            "Epoch 00677: val_acc improved from 0.91840 to 0.91850, saving model to /content/saved_models/cifar10_ResNet32v1_model.677.h5\n",
            "Epoch 678/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0930 - acc: 0.9755 - val_loss: 0.2884 - val_acc: 0.9177\n",
            "\n",
            "Epoch 00678: val_acc did not improve from 0.91850\n",
            "Epoch 679/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0834 - acc: 0.9770 - val_loss: 0.2880 - val_acc: 0.9183\n",
            "\n",
            "Epoch 00679: val_acc did not improve from 0.91850\n",
            "Epoch 680/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0877 - acc: 0.9760 - val_loss: 0.2885 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00680: val_acc did not improve from 0.91850\n",
            "Epoch 681/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.0865 - acc: 0.9770 - val_loss: 0.2891 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00681: val_acc did not improve from 0.91850\n",
            "Epoch 682/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0860 - acc: 0.9776 - val_loss: 0.2888 - val_acc: 0.9184\n",
            "\n",
            "Epoch 00682: val_acc did not improve from 0.91850\n",
            "Epoch 683/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0839 - acc: 0.9778 - val_loss: 0.2884 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00683: val_acc did not improve from 0.91850\n",
            "Epoch 684/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0925 - acc: 0.9735 - val_loss: 0.2888 - val_acc: 0.9177\n",
            "\n",
            "Epoch 00684: val_acc did not improve from 0.91850\n",
            "Epoch 685/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0908 - acc: 0.9774 - val_loss: 0.2888 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00685: val_acc did not improve from 0.91850\n",
            "Epoch 686/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0864 - acc: 0.9748 - val_loss: 0.2881 - val_acc: 0.9184\n",
            "\n",
            "Epoch 00686: val_acc did not improve from 0.91850\n",
            "Epoch 687/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0871 - acc: 0.9745 - val_loss: 0.2877 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00687: val_acc did not improve from 0.91850\n",
            "Epoch 688/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0817 - acc: 0.9781 - val_loss: 0.2881 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00688: val_acc did not improve from 0.91850\n",
            "Epoch 689/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0861 - acc: 0.9765 - val_loss: 0.2874 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00689: val_acc did not improve from 0.91850\n",
            "Epoch 690/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0827 - acc: 0.9805 - val_loss: 0.2871 - val_acc: 0.9183\n",
            "\n",
            "Epoch 00690: val_acc did not improve from 0.91850\n",
            "Epoch 691/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0790 - acc: 0.9802 - val_loss: 0.2875 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00691: val_acc did not improve from 0.91850\n",
            "Epoch 692/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0896 - acc: 0.9745 - val_loss: 0.2881 - val_acc: 0.9177\n",
            "\n",
            "Epoch 00692: val_acc did not improve from 0.91850\n",
            "Epoch 693/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0851 - acc: 0.9784 - val_loss: 0.2879 - val_acc: 0.9178\n",
            "\n",
            "Epoch 00693: val_acc did not improve from 0.91850\n",
            "Epoch 694/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0823 - acc: 0.9783 - val_loss: 0.2884 - val_acc: 0.9183\n",
            "\n",
            "Epoch 00694: val_acc did not improve from 0.91850\n",
            "Epoch 695/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0805 - acc: 0.9790 - val_loss: 0.2882 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00695: val_acc did not improve from 0.91850\n",
            "Epoch 696/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0909 - acc: 0.9753 - val_loss: 0.2874 - val_acc: 0.9181\n",
            "\n",
            "Epoch 00696: val_acc did not improve from 0.91850\n",
            "Epoch 697/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0828 - acc: 0.9780 - val_loss: 0.2874 - val_acc: 0.9177\n",
            "\n",
            "Epoch 00697: val_acc did not improve from 0.91850\n",
            "Epoch 698/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0922 - acc: 0.9756 - val_loss: 0.2878 - val_acc: 0.9183\n",
            "\n",
            "Epoch 00698: val_acc did not improve from 0.91850\n",
            "Epoch 699/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0822 - acc: 0.9794 - val_loss: 0.2884 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00699: val_acc did not improve from 0.91850\n",
            "Epoch 700/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0862 - acc: 0.9773 - val_loss: 0.2873 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00700: val_acc did not improve from 0.91850\n",
            "Epoch 701/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0885 - acc: 0.9751 - val_loss: 0.2876 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00701: val_acc improved from 0.91850 to 0.91860, saving model to /content/saved_models/cifar10_ResNet32v1_model.701.h5\n",
            "Epoch 702/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0823 - acc: 0.9779 - val_loss: 0.2880 - val_acc: 0.9188\n",
            "\n",
            "Epoch 00702: val_acc improved from 0.91860 to 0.91880, saving model to /content/saved_models/cifar10_ResNet32v1_model.702.h5\n",
            "Epoch 703/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0810 - acc: 0.9792 - val_loss: 0.2882 - val_acc: 0.9181\n",
            "\n",
            "Epoch 00703: val_acc did not improve from 0.91880\n",
            "Epoch 704/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0847 - acc: 0.9779 - val_loss: 0.2876 - val_acc: 0.9187\n",
            "\n",
            "Epoch 00704: val_acc did not improve from 0.91880\n",
            "Epoch 705/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0834 - acc: 0.9788 - val_loss: 0.2878 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00705: val_acc did not improve from 0.91880\n",
            "Epoch 706/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0829 - acc: 0.9778 - val_loss: 0.2879 - val_acc: 0.9183\n",
            "\n",
            "Epoch 00706: val_acc did not improve from 0.91880\n",
            "Epoch 707/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0874 - acc: 0.9776 - val_loss: 0.2882 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00707: val_acc did not improve from 0.91880\n",
            "Epoch 708/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0866 - acc: 0.9768 - val_loss: 0.2877 - val_acc: 0.9178\n",
            "\n",
            "Epoch 00708: val_acc did not improve from 0.91880\n",
            "Epoch 709/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0815 - acc: 0.9781 - val_loss: 0.2886 - val_acc: 0.9183\n",
            "\n",
            "Epoch 00709: val_acc did not improve from 0.91880\n",
            "Epoch 710/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0802 - acc: 0.9786 - val_loss: 0.2883 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00710: val_acc did not improve from 0.91880\n",
            "Epoch 711/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0873 - acc: 0.9737 - val_loss: 0.2880 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00711: val_acc did not improve from 0.91880\n",
            "Epoch 712/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0834 - acc: 0.9759 - val_loss: 0.2875 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00712: val_acc improved from 0.91880 to 0.91890, saving model to /content/saved_models/cifar10_ResNet32v1_model.712.h5\n",
            "Epoch 713/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0855 - acc: 0.9763 - val_loss: 0.2873 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00713: val_acc did not improve from 0.91890\n",
            "Epoch 714/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0915 - acc: 0.9736 - val_loss: 0.2882 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00714: val_acc did not improve from 0.91890\n",
            "Epoch 715/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0873 - acc: 0.9753 - val_loss: 0.2885 - val_acc: 0.9177\n",
            "\n",
            "Epoch 00715: val_acc did not improve from 0.91890\n",
            "Epoch 716/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0851 - acc: 0.9755 - val_loss: 0.2877 - val_acc: 0.9178\n",
            "\n",
            "Epoch 00716: val_acc did not improve from 0.91890\n",
            "Epoch 717/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0851 - acc: 0.9769 - val_loss: 0.2871 - val_acc: 0.9178\n",
            "\n",
            "Epoch 00717: val_acc did not improve from 0.91890\n",
            "Epoch 718/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0872 - acc: 0.9743 - val_loss: 0.2872 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00718: val_acc did not improve from 0.91890\n",
            "Epoch 719/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0843 - acc: 0.9785 - val_loss: 0.2864 - val_acc: 0.9184\n",
            "\n",
            "Epoch 00719: val_acc did not improve from 0.91890\n",
            "Epoch 720/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0857 - acc: 0.9788 - val_loss: 0.2866 - val_acc: 0.9187\n",
            "\n",
            "Epoch 00720: val_acc did not improve from 0.91890\n",
            "Epoch 721/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0849 - acc: 0.9778 - val_loss: 0.2867 - val_acc: 0.9181\n",
            "\n",
            "Epoch 00721: val_acc did not improve from 0.91890\n",
            "Epoch 722/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0843 - acc: 0.9779 - val_loss: 0.2868 - val_acc: 0.9187\n",
            "\n",
            "Epoch 00722: val_acc did not improve from 0.91890\n",
            "Epoch 723/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0850 - acc: 0.9769 - val_loss: 0.2875 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00723: val_acc did not improve from 0.91890\n",
            "Epoch 724/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0841 - acc: 0.9785 - val_loss: 0.2874 - val_acc: 0.9183\n",
            "\n",
            "Epoch 00724: val_acc did not improve from 0.91890\n",
            "Epoch 725/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0888 - acc: 0.9745 - val_loss: 0.2876 - val_acc: 0.9188\n",
            "\n",
            "Epoch 00725: val_acc did not improve from 0.91890\n",
            "Epoch 726/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0762 - acc: 0.9816 - val_loss: 0.2868 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00726: val_acc did not improve from 0.91890\n",
            "Epoch 727/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0858 - acc: 0.9785 - val_loss: 0.2863 - val_acc: 0.9185\n",
            "\n",
            "Epoch 00727: val_acc did not improve from 0.91890\n",
            "Epoch 728/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0815 - acc: 0.9788 - val_loss: 0.2864 - val_acc: 0.9183\n",
            "\n",
            "Epoch 00728: val_acc did not improve from 0.91890\n",
            "Epoch 729/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0869 - acc: 0.9759 - val_loss: 0.2860 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00729: val_acc did not improve from 0.91890\n",
            "Epoch 730/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0803 - acc: 0.9797 - val_loss: 0.2866 - val_acc: 0.9183\n",
            "\n",
            "Epoch 00730: val_acc did not improve from 0.91890\n",
            "Epoch 731/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0781 - acc: 0.9801 - val_loss: 0.2865 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00731: val_acc did not improve from 0.91890\n",
            "Epoch 732/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0820 - acc: 0.9784 - val_loss: 0.2865 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00732: val_acc did not improve from 0.91890\n",
            "Epoch 733/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0741 - acc: 0.9821 - val_loss: 0.2870 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00733: val_acc did not improve from 0.91890\n",
            "Epoch 734/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0820 - acc: 0.9799 - val_loss: 0.2870 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00734: val_acc did not improve from 0.91890\n",
            "Epoch 735/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0792 - acc: 0.9779 - val_loss: 0.2876 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00735: val_acc did not improve from 0.91890\n",
            "Epoch 736/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0824 - acc: 0.9797 - val_loss: 0.2867 - val_acc: 0.9184\n",
            "\n",
            "Epoch 00736: val_acc did not improve from 0.91890\n",
            "Epoch 737/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0764 - acc: 0.9803 - val_loss: 0.2872 - val_acc: 0.9184\n",
            "\n",
            "Epoch 00737: val_acc did not improve from 0.91890\n",
            "Epoch 738/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0857 - acc: 0.9774 - val_loss: 0.2869 - val_acc: 0.9184\n",
            "\n",
            "Epoch 00738: val_acc did not improve from 0.91890\n",
            "Epoch 739/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0884 - acc: 0.9761 - val_loss: 0.2871 - val_acc: 0.9177\n",
            "\n",
            "Epoch 00739: val_acc did not improve from 0.91890\n",
            "Epoch 740/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0809 - acc: 0.9783 - val_loss: 0.2871 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00740: val_acc did not improve from 0.91890\n",
            "Epoch 741/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0840 - acc: 0.9781 - val_loss: 0.2864 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00741: val_acc improved from 0.91890 to 0.91930, saving model to /content/saved_models/cifar10_ResNet32v1_model.741.h5\n",
            "Epoch 742/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0773 - acc: 0.9811 - val_loss: 0.2872 - val_acc: 0.9188\n",
            "\n",
            "Epoch 00742: val_acc did not improve from 0.91930\n",
            "Epoch 743/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0825 - acc: 0.9782 - val_loss: 0.2875 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00743: val_acc did not improve from 0.91930\n",
            "Epoch 744/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0816 - acc: 0.9787 - val_loss: 0.2870 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00744: val_acc did not improve from 0.91930\n",
            "Epoch 745/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0831 - acc: 0.9756 - val_loss: 0.2869 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00745: val_acc did not improve from 0.91930\n",
            "Epoch 746/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0804 - acc: 0.9785 - val_loss: 0.2874 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00746: val_acc did not improve from 0.91930\n",
            "Epoch 747/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0771 - acc: 0.9789 - val_loss: 0.2867 - val_acc: 0.9190\n",
            "\n",
            "Epoch 00747: val_acc did not improve from 0.91930\n",
            "Epoch 748/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0848 - acc: 0.9780 - val_loss: 0.2866 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00748: val_acc improved from 0.91930 to 0.91940, saving model to /content/saved_models/cifar10_ResNet32v1_model.748.h5\n",
            "Epoch 749/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0793 - acc: 0.9810 - val_loss: 0.2861 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00749: val_acc improved from 0.91940 to 0.91960, saving model to /content/saved_models/cifar10_ResNet32v1_model.749.h5\n",
            "Epoch 750/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0746 - acc: 0.9822 - val_loss: 0.2867 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00750: val_acc did not improve from 0.91960\n",
            "Epoch 751/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0835 - acc: 0.9769 - val_loss: 0.2866 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00751: val_acc did not improve from 0.91960\n",
            "Epoch 752/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0767 - acc: 0.9812 - val_loss: 0.2863 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00752: val_acc improved from 0.91960 to 0.91980, saving model to /content/saved_models/cifar10_ResNet32v1_model.752.h5\n",
            "Epoch 753/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0806 - acc: 0.9781 - val_loss: 0.2864 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00753: val_acc did not improve from 0.91980\n",
            "Epoch 754/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0885 - acc: 0.9769 - val_loss: 0.2868 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00754: val_acc did not improve from 0.91980\n",
            "Epoch 755/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0845 - acc: 0.9801 - val_loss: 0.2869 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00755: val_acc did not improve from 0.91980\n",
            "Epoch 756/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0828 - acc: 0.9772 - val_loss: 0.2863 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00756: val_acc improved from 0.91980 to 0.91990, saving model to /content/saved_models/cifar10_ResNet32v1_model.756.h5\n",
            "Epoch 757/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0772 - acc: 0.9814 - val_loss: 0.2866 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00757: val_acc did not improve from 0.91990\n",
            "Epoch 758/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0829 - acc: 0.9787 - val_loss: 0.2878 - val_acc: 0.9190\n",
            "\n",
            "Epoch 00758: val_acc did not improve from 0.91990\n",
            "Epoch 759/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0816 - acc: 0.9789 - val_loss: 0.2873 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00759: val_acc did not improve from 0.91990\n",
            "Epoch 760/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0810 - acc: 0.9801 - val_loss: 0.2872 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00760: val_acc did not improve from 0.91990\n",
            "Epoch 761/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0795 - acc: 0.9791 - val_loss: 0.2870 - val_acc: 0.9184\n",
            "\n",
            "Epoch 00761: val_acc did not improve from 0.91990\n",
            "Epoch 762/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0772 - acc: 0.9812 - val_loss: 0.2879 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00762: val_acc did not improve from 0.91990\n",
            "Epoch 763/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0831 - acc: 0.9781 - val_loss: 0.2869 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00763: val_acc did not improve from 0.91990\n",
            "Epoch 764/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0782 - acc: 0.9805 - val_loss: 0.2865 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00764: val_acc did not improve from 0.91990\n",
            "Epoch 765/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0798 - acc: 0.9816 - val_loss: 0.2872 - val_acc: 0.9185\n",
            "\n",
            "Epoch 00765: val_acc did not improve from 0.91990\n",
            "Epoch 766/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0789 - acc: 0.9804 - val_loss: 0.2862 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00766: val_acc did not improve from 0.91990\n",
            "Epoch 767/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0830 - acc: 0.9785 - val_loss: 0.2863 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00767: val_acc did not improve from 0.91990\n",
            "Epoch 768/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0746 - acc: 0.9813 - val_loss: 0.2871 - val_acc: 0.9187\n",
            "\n",
            "Epoch 00768: val_acc did not improve from 0.91990\n",
            "Epoch 769/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0810 - acc: 0.9774 - val_loss: 0.2874 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00769: val_acc did not improve from 0.91990\n",
            "Epoch 770/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0827 - acc: 0.9801 - val_loss: 0.2871 - val_acc: 0.9187\n",
            "\n",
            "Epoch 00770: val_acc did not improve from 0.91990\n",
            "Epoch 771/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0823 - acc: 0.9782 - val_loss: 0.2869 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00771: val_acc did not improve from 0.91990\n",
            "Epoch 772/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0724 - acc: 0.9829 - val_loss: 0.2869 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00772: val_acc did not improve from 0.91990\n",
            "Epoch 773/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0832 - acc: 0.9786 - val_loss: 0.2868 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00773: val_acc did not improve from 0.91990\n",
            "Epoch 774/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0807 - acc: 0.9791 - val_loss: 0.2868 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00774: val_acc did not improve from 0.91990\n",
            "Epoch 775/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0792 - acc: 0.9816 - val_loss: 0.2865 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00775: val_acc did not improve from 0.91990\n",
            "Epoch 776/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0770 - acc: 0.9796 - val_loss: 0.2868 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00776: val_acc did not improve from 0.91990\n",
            "Epoch 777/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0835 - acc: 0.9754 - val_loss: 0.2867 - val_acc: 0.9190\n",
            "\n",
            "Epoch 00777: val_acc did not improve from 0.91990\n",
            "Epoch 778/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0792 - acc: 0.9784 - val_loss: 0.2871 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00778: val_acc did not improve from 0.91990\n",
            "Epoch 779/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0798 - acc: 0.9802 - val_loss: 0.2868 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00779: val_acc did not improve from 0.91990\n",
            "Epoch 780/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0729 - acc: 0.9823 - val_loss: 0.2865 - val_acc: 0.9188\n",
            "\n",
            "Epoch 00780: val_acc did not improve from 0.91990\n",
            "Epoch 781/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0770 - acc: 0.9794 - val_loss: 0.2867 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00781: val_acc did not improve from 0.91990\n",
            "Epoch 782/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0761 - acc: 0.9794 - val_loss: 0.2863 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00782: val_acc did not improve from 0.91990\n",
            "Epoch 783/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0833 - acc: 0.9778 - val_loss: 0.2867 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00783: val_acc did not improve from 0.91990\n",
            "Epoch 784/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0746 - acc: 0.9810 - val_loss: 0.2862 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00784: val_acc did not improve from 0.91990\n",
            "Epoch 785/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0751 - acc: 0.9832 - val_loss: 0.2864 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00785: val_acc did not improve from 0.91990\n",
            "Epoch 786/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0791 - acc: 0.9804 - val_loss: 0.2868 - val_acc: 0.9188\n",
            "\n",
            "Epoch 00786: val_acc did not improve from 0.91990\n",
            "Epoch 787/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0848 - acc: 0.9769 - val_loss: 0.2869 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00787: val_acc did not improve from 0.91990\n",
            "Epoch 788/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0780 - acc: 0.9798 - val_loss: 0.2871 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00788: val_acc did not improve from 0.91990\n",
            "Epoch 789/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0889 - acc: 0.9761 - val_loss: 0.2868 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00789: val_acc did not improve from 0.91990\n",
            "Epoch 790/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0737 - acc: 0.9795 - val_loss: 0.2869 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00790: val_acc did not improve from 0.91990\n",
            "Epoch 791/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0774 - acc: 0.9791 - val_loss: 0.2863 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00791: val_acc did not improve from 0.91990\n",
            "Epoch 792/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0839 - acc: 0.9746 - val_loss: 0.2863 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00792: val_acc did not improve from 0.91990\n",
            "Epoch 793/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0800 - acc: 0.9782 - val_loss: 0.2864 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00793: val_acc did not improve from 0.91990\n",
            "Epoch 794/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0818 - acc: 0.9775 - val_loss: 0.2861 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00794: val_acc did not improve from 0.91990\n",
            "Epoch 795/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0743 - acc: 0.9814 - val_loss: 0.2866 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00795: val_acc did not improve from 0.91990\n",
            "Epoch 796/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0786 - acc: 0.9821 - val_loss: 0.2865 - val_acc: 0.9190\n",
            "\n",
            "Epoch 00796: val_acc did not improve from 0.91990\n",
            "Epoch 797/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0839 - acc: 0.9776 - val_loss: 0.2855 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00797: val_acc did not improve from 0.91990\n",
            "Epoch 798/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0753 - acc: 0.9820 - val_loss: 0.2856 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00798: val_acc did not improve from 0.91990\n",
            "Epoch 799/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0726 - acc: 0.9821 - val_loss: 0.2861 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00799: val_acc improved from 0.91990 to 0.92000, saving model to /content/saved_models/cifar10_ResNet32v1_model.799.h5\n",
            "Epoch 800/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0730 - acc: 0.9828 - val_loss: 0.2860 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00800: val_acc improved from 0.92000 to 0.92030, saving model to /content/saved_models/cifar10_ResNet32v1_model.800.h5\n",
            "Epoch 801/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0804 - acc: 0.9793 - val_loss: 0.2862 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00801: val_acc did not improve from 0.92030\n",
            "Epoch 802/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0748 - acc: 0.9820 - val_loss: 0.2863 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00802: val_acc did not improve from 0.92030\n",
            "Epoch 803/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0802 - acc: 0.9786 - val_loss: 0.2857 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00803: val_acc did not improve from 0.92030\n",
            "Epoch 804/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0811 - acc: 0.9777 - val_loss: 0.2861 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00804: val_acc did not improve from 0.92030\n",
            "Epoch 805/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0755 - acc: 0.9823 - val_loss: 0.2858 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00805: val_acc did not improve from 0.92030\n",
            "Epoch 806/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0800 - acc: 0.9792 - val_loss: 0.2857 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00806: val_acc did not improve from 0.92030\n",
            "Epoch 807/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0819 - acc: 0.9785 - val_loss: 0.2855 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00807: val_acc did not improve from 0.92030\n",
            "Epoch 808/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0846 - acc: 0.9767 - val_loss: 0.2857 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00808: val_acc did not improve from 0.92030\n",
            "Epoch 809/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0821 - acc: 0.9780 - val_loss: 0.2862 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00809: val_acc did not improve from 0.92030\n",
            "Epoch 810/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0778 - acc: 0.9805 - val_loss: 0.2862 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00810: val_acc did not improve from 0.92030\n",
            "Epoch 811/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0802 - acc: 0.9769 - val_loss: 0.2865 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00811: val_acc did not improve from 0.92030\n",
            "Epoch 812/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0785 - acc: 0.9804 - val_loss: 0.2862 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00812: val_acc did not improve from 0.92030\n",
            "Epoch 813/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0756 - acc: 0.9802 - val_loss: 0.2864 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00813: val_acc did not improve from 0.92030\n",
            "Epoch 814/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0722 - acc: 0.9819 - val_loss: 0.2868 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00814: val_acc did not improve from 0.92030\n",
            "Epoch 815/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0748 - acc: 0.9820 - val_loss: 0.2861 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00815: val_acc did not improve from 0.92030\n",
            "Epoch 816/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0728 - acc: 0.9814 - val_loss: 0.2855 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00816: val_acc did not improve from 0.92030\n",
            "Epoch 817/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0786 - acc: 0.9800 - val_loss: 0.2863 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00817: val_acc did not improve from 0.92030\n",
            "Epoch 818/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0769 - acc: 0.9817 - val_loss: 0.2862 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00818: val_acc did not improve from 0.92030\n",
            "Epoch 819/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0746 - acc: 0.9816 - val_loss: 0.2871 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00819: val_acc did not improve from 0.92030\n",
            "Epoch 820/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0722 - acc: 0.9816 - val_loss: 0.2869 - val_acc: 0.9188\n",
            "\n",
            "Epoch 00820: val_acc did not improve from 0.92030\n",
            "Epoch 821/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0696 - acc: 0.9852 - val_loss: 0.2868 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00821: val_acc did not improve from 0.92030\n",
            "Epoch 822/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0713 - acc: 0.9833 - val_loss: 0.2861 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00822: val_acc did not improve from 0.92030\n",
            "Epoch 823/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0747 - acc: 0.9806 - val_loss: 0.2864 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00823: val_acc did not improve from 0.92030\n",
            "Epoch 824/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0677 - acc: 0.9840 - val_loss: 0.2857 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00824: val_acc did not improve from 0.92030\n",
            "Epoch 825/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0818 - acc: 0.9804 - val_loss: 0.2865 - val_acc: 0.9188\n",
            "\n",
            "Epoch 00825: val_acc did not improve from 0.92030\n",
            "Epoch 826/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0769 - acc: 0.9801 - val_loss: 0.2863 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00826: val_acc did not improve from 0.92030\n",
            "Epoch 827/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0808 - acc: 0.9779 - val_loss: 0.2862 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00827: val_acc did not improve from 0.92030\n",
            "Epoch 828/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0767 - acc: 0.9821 - val_loss: 0.2864 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00828: val_acc did not improve from 0.92030\n",
            "Epoch 829/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0730 - acc: 0.9815 - val_loss: 0.2869 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00829: val_acc did not improve from 0.92030\n",
            "Epoch 830/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0764 - acc: 0.9804 - val_loss: 0.2868 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00830: val_acc did not improve from 0.92030\n",
            "Epoch 831/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0787 - acc: 0.9788 - val_loss: 0.2867 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00831: val_acc did not improve from 0.92030\n",
            "Epoch 832/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0833 - acc: 0.9778 - val_loss: 0.2864 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00832: val_acc did not improve from 0.92030\n",
            "Epoch 833/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0745 - acc: 0.9800 - val_loss: 0.2864 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00833: val_acc did not improve from 0.92030\n",
            "Epoch 834/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0767 - acc: 0.9818 - val_loss: 0.2861 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00834: val_acc did not improve from 0.92030\n",
            "Epoch 835/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0769 - acc: 0.9775 - val_loss: 0.2857 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00835: val_acc did not improve from 0.92030\n",
            "Epoch 836/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0770 - acc: 0.9808 - val_loss: 0.2861 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00836: val_acc did not improve from 0.92030\n",
            "Epoch 837/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0716 - acc: 0.9824 - val_loss: 0.2865 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00837: val_acc did not improve from 0.92030\n",
            "Epoch 838/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0712 - acc: 0.9825 - val_loss: 0.2862 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00838: val_acc did not improve from 0.92030\n",
            "Epoch 839/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0806 - acc: 0.9799 - val_loss: 0.2861 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00839: val_acc did not improve from 0.92030\n",
            "Epoch 840/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0787 - acc: 0.9799 - val_loss: 0.2872 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00840: val_acc did not improve from 0.92030\n",
            "Epoch 841/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0752 - acc: 0.9821 - val_loss: 0.2863 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00841: val_acc did not improve from 0.92030\n",
            "Epoch 842/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0853 - acc: 0.9777 - val_loss: 0.2867 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00842: val_acc did not improve from 0.92030\n",
            "Epoch 843/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0772 - acc: 0.9801 - val_loss: 0.2862 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00843: val_acc did not improve from 0.92030\n",
            "Epoch 844/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0803 - acc: 0.9788 - val_loss: 0.2870 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00844: val_acc did not improve from 0.92030\n",
            "Epoch 845/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0769 - acc: 0.9785 - val_loss: 0.2872 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00845: val_acc did not improve from 0.92030\n",
            "Epoch 846/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0799 - acc: 0.9776 - val_loss: 0.2872 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00846: val_acc did not improve from 0.92030\n",
            "Epoch 847/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0744 - acc: 0.9801 - val_loss: 0.2867 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00847: val_acc did not improve from 0.92030\n",
            "Epoch 848/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0738 - acc: 0.9808 - val_loss: 0.2878 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00848: val_acc did not improve from 0.92030\n",
            "Epoch 849/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0705 - acc: 0.9859 - val_loss: 0.2875 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00849: val_acc did not improve from 0.92030\n",
            "Epoch 850/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0744 - acc: 0.9810 - val_loss: 0.2869 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00850: val_acc did not improve from 0.92030\n",
            "Epoch 851/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0757 - acc: 0.9806 - val_loss: 0.2870 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00851: val_acc did not improve from 0.92030\n",
            "Epoch 852/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0777 - acc: 0.9793 - val_loss: 0.2867 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00852: val_acc did not improve from 0.92030\n",
            "Epoch 853/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0793 - acc: 0.9790 - val_loss: 0.2871 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00853: val_acc did not improve from 0.92030\n",
            "Epoch 854/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0765 - acc: 0.9780 - val_loss: 0.2863 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00854: val_acc did not improve from 0.92030\n",
            "Epoch 855/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0733 - acc: 0.9829 - val_loss: 0.2866 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00855: val_acc did not improve from 0.92030\n",
            "Epoch 856/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0719 - acc: 0.9847 - val_loss: 0.2870 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00856: val_acc did not improve from 0.92030\n",
            "Epoch 857/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0733 - acc: 0.9814 - val_loss: 0.2868 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00857: val_acc did not improve from 0.92030\n",
            "Epoch 858/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.0680 - acc: 0.9827 - val_loss: 0.2863 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00858: val_acc did not improve from 0.92030\n",
            "Epoch 859/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0757 - acc: 0.9816 - val_loss: 0.2859 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00859: val_acc did not improve from 0.92030\n",
            "Epoch 860/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0767 - acc: 0.9793 - val_loss: 0.2862 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00860: val_acc did not improve from 0.92030\n",
            "Epoch 861/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0758 - acc: 0.9801 - val_loss: 0.2863 - val_acc: 0.9188\n",
            "\n",
            "Epoch 00861: val_acc did not improve from 0.92030\n",
            "Epoch 862/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0681 - acc: 0.9826 - val_loss: 0.2865 - val_acc: 0.9190\n",
            "\n",
            "Epoch 00862: val_acc did not improve from 0.92030\n",
            "Epoch 863/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0797 - acc: 0.9787 - val_loss: 0.2866 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00863: val_acc did not improve from 0.92030\n",
            "Epoch 864/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0736 - acc: 0.9833 - val_loss: 0.2855 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00864: val_acc did not improve from 0.92030\n",
            "Epoch 865/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0759 - acc: 0.9824 - val_loss: 0.2858 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00865: val_acc did not improve from 0.92030\n",
            "Epoch 866/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0742 - acc: 0.9821 - val_loss: 0.2861 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00866: val_acc did not improve from 0.92030\n",
            "Epoch 867/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0757 - acc: 0.9789 - val_loss: 0.2867 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00867: val_acc did not improve from 0.92030\n",
            "Epoch 868/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0820 - acc: 0.9785 - val_loss: 0.2864 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00868: val_acc did not improve from 0.92030\n",
            "Epoch 869/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0710 - acc: 0.9824 - val_loss: 0.2864 - val_acc: 0.9188\n",
            "\n",
            "Epoch 00869: val_acc did not improve from 0.92030\n",
            "Epoch 870/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0777 - acc: 0.9797 - val_loss: 0.2868 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00870: val_acc did not improve from 0.92030\n",
            "Epoch 871/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0752 - acc: 0.9809 - val_loss: 0.2861 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00871: val_acc did not improve from 0.92030\n",
            "Epoch 872/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0736 - acc: 0.9815 - val_loss: 0.2870 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00872: val_acc did not improve from 0.92030\n",
            "Epoch 873/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0717 - acc: 0.9842 - val_loss: 0.2865 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00873: val_acc did not improve from 0.92030\n",
            "Epoch 874/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0747 - acc: 0.9824 - val_loss: 0.2875 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00874: val_acc did not improve from 0.92030\n",
            "Epoch 875/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0695 - acc: 0.9828 - val_loss: 0.2873 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00875: val_acc did not improve from 0.92030\n",
            "Epoch 876/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0742 - acc: 0.9819 - val_loss: 0.2871 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00876: val_acc did not improve from 0.92030\n",
            "Epoch 877/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0689 - acc: 0.9839 - val_loss: 0.2862 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00877: val_acc did not improve from 0.92030\n",
            "Epoch 878/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0722 - acc: 0.9819 - val_loss: 0.2866 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00878: val_acc did not improve from 0.92030\n",
            "Epoch 879/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0700 - acc: 0.9853 - val_loss: 0.2864 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00879: val_acc did not improve from 0.92030\n",
            "Epoch 880/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0748 - acc: 0.9808 - val_loss: 0.2862 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00880: val_acc did not improve from 0.92030\n",
            "Epoch 881/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0776 - acc: 0.9781 - val_loss: 0.2865 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00881: val_acc did not improve from 0.92030\n",
            "Epoch 882/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0751 - acc: 0.9812 - val_loss: 0.2855 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00882: val_acc did not improve from 0.92030\n",
            "Epoch 883/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0779 - acc: 0.9810 - val_loss: 0.2862 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00883: val_acc did not improve from 0.92030\n",
            "Epoch 884/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0745 - acc: 0.9828 - val_loss: 0.2871 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00884: val_acc did not improve from 0.92030\n",
            "Epoch 885/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0780 - acc: 0.9793 - val_loss: 0.2867 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00885: val_acc did not improve from 0.92030\n",
            "Epoch 886/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0681 - acc: 0.9847 - val_loss: 0.2864 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00886: val_acc did not improve from 0.92030\n",
            "Epoch 887/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0703 - acc: 0.9812 - val_loss: 0.2867 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00887: val_acc did not improve from 0.92030\n",
            "Epoch 888/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0778 - acc: 0.9793 - val_loss: 0.2866 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00888: val_acc did not improve from 0.92030\n",
            "Epoch 889/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0731 - acc: 0.9802 - val_loss: 0.2867 - val_acc: 0.9187\n",
            "\n",
            "Epoch 00889: val_acc did not improve from 0.92030\n",
            "Epoch 890/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0794 - acc: 0.9794 - val_loss: 0.2867 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00890: val_acc did not improve from 0.92030\n",
            "Epoch 891/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0707 - acc: 0.9819 - val_loss: 0.2859 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00891: val_acc did not improve from 0.92030\n",
            "Epoch 892/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0712 - acc: 0.9834 - val_loss: 0.2864 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00892: val_acc did not improve from 0.92030\n",
            "Epoch 893/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0689 - acc: 0.9817 - val_loss: 0.2869 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00893: val_acc did not improve from 0.92030\n",
            "Epoch 894/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0697 - acc: 0.9831 - val_loss: 0.2855 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00894: val_acc did not improve from 0.92030\n",
            "Epoch 895/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0722 - acc: 0.9831 - val_loss: 0.2856 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00895: val_acc did not improve from 0.92030\n",
            "Epoch 896/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0770 - acc: 0.9809 - val_loss: 0.2855 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00896: val_acc did not improve from 0.92030\n",
            "Epoch 897/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0715 - acc: 0.9829 - val_loss: 0.2852 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00897: val_acc did not improve from 0.92030\n",
            "Epoch 898/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0753 - acc: 0.9799 - val_loss: 0.2855 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00898: val_acc did not improve from 0.92030\n",
            "Epoch 899/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0694 - acc: 0.9838 - val_loss: 0.2862 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00899: val_acc did not improve from 0.92030\n",
            "Epoch 900/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0690 - acc: 0.9827 - val_loss: 0.2867 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00900: val_acc did not improve from 0.92030\n",
            "Epoch 901/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0720 - acc: 0.9830 - val_loss: 0.2868 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00901: val_acc did not improve from 0.92030\n",
            "Epoch 902/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0714 - acc: 0.9806 - val_loss: 0.2867 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00902: val_acc did not improve from 0.92030\n",
            "Epoch 903/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0723 - acc: 0.9812 - val_loss: 0.2866 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00903: val_acc did not improve from 0.92030\n",
            "Epoch 904/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0776 - acc: 0.9817 - val_loss: 0.2864 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00904: val_acc did not improve from 0.92030\n",
            "Epoch 905/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0762 - acc: 0.9787 - val_loss: 0.2862 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00905: val_acc did not improve from 0.92030\n",
            "Epoch 906/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0734 - acc: 0.9805 - val_loss: 0.2866 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00906: val_acc did not improve from 0.92030\n",
            "Epoch 907/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0736 - acc: 0.9809 - val_loss: 0.2863 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00907: val_acc did not improve from 0.92030\n",
            "Epoch 908/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0754 - acc: 0.9800 - val_loss: 0.2859 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00908: val_acc did not improve from 0.92030\n",
            "Epoch 909/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0717 - acc: 0.9821 - val_loss: 0.2863 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00909: val_acc improved from 0.92030 to 0.92040, saving model to /content/saved_models/cifar10_ResNet32v1_model.909.h5\n",
            "Epoch 910/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0742 - acc: 0.9818 - val_loss: 0.2861 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00910: val_acc did not improve from 0.92040\n",
            "Epoch 911/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0700 - acc: 0.9828 - val_loss: 0.2856 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00911: val_acc did not improve from 0.92040\n",
            "Epoch 912/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0655 - acc: 0.9842 - val_loss: 0.2856 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00912: val_acc did not improve from 0.92040\n",
            "Epoch 913/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0714 - acc: 0.9835 - val_loss: 0.2861 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00913: val_acc did not improve from 0.92040\n",
            "Epoch 914/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0753 - acc: 0.9812 - val_loss: 0.2857 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00914: val_acc did not improve from 0.92040\n",
            "Epoch 915/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0729 - acc: 0.9805 - val_loss: 0.2862 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00915: val_acc did not improve from 0.92040\n",
            "Epoch 916/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0726 - acc: 0.9817 - val_loss: 0.2858 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00916: val_acc did not improve from 0.92040\n",
            "Epoch 917/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0747 - acc: 0.9808 - val_loss: 0.2854 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00917: val_acc did not improve from 0.92040\n",
            "Epoch 918/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0675 - acc: 0.9825 - val_loss: 0.2849 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00918: val_acc did not improve from 0.92040\n",
            "Epoch 919/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0773 - acc: 0.9809 - val_loss: 0.2855 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00919: val_acc did not improve from 0.92040\n",
            "Epoch 920/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0760 - acc: 0.9823 - val_loss: 0.2861 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00920: val_acc did not improve from 0.92040\n",
            "Epoch 921/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0719 - acc: 0.9816 - val_loss: 0.2864 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00921: val_acc did not improve from 0.92040\n",
            "Epoch 922/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0734 - acc: 0.9819 - val_loss: 0.2860 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00922: val_acc did not improve from 0.92040\n",
            "Epoch 923/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0751 - acc: 0.9802 - val_loss: 0.2863 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00923: val_acc did not improve from 0.92040\n",
            "Epoch 924/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0816 - acc: 0.9783 - val_loss: 0.2861 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00924: val_acc did not improve from 0.92040\n",
            "Epoch 925/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0736 - acc: 0.9814 - val_loss: 0.2862 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00925: val_acc did not improve from 0.92040\n",
            "Epoch 926/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0722 - acc: 0.9807 - val_loss: 0.2863 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00926: val_acc did not improve from 0.92040\n",
            "Epoch 927/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0741 - acc: 0.9814 - val_loss: 0.2857 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00927: val_acc did not improve from 0.92040\n",
            "Epoch 928/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0673 - acc: 0.9841 - val_loss: 0.2855 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00928: val_acc did not improve from 0.92040\n",
            "Epoch 929/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0712 - acc: 0.9835 - val_loss: 0.2850 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00929: val_acc did not improve from 0.92040\n",
            "Epoch 930/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0705 - acc: 0.9830 - val_loss: 0.2850 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00930: val_acc did not improve from 0.92040\n",
            "Epoch 931/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0685 - acc: 0.9846 - val_loss: 0.2854 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00931: val_acc improved from 0.92040 to 0.92060, saving model to /content/saved_models/cifar10_ResNet32v1_model.931.h5\n",
            "Epoch 932/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0728 - acc: 0.9812 - val_loss: 0.2858 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00932: val_acc improved from 0.92060 to 0.92070, saving model to /content/saved_models/cifar10_ResNet32v1_model.932.h5\n",
            "Epoch 933/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0689 - acc: 0.9832 - val_loss: 0.2859 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00933: val_acc did not improve from 0.92070\n",
            "Epoch 934/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0700 - acc: 0.9841 - val_loss: 0.2863 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00934: val_acc did not improve from 0.92070\n",
            "Epoch 935/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0729 - acc: 0.9829 - val_loss: 0.2867 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00935: val_acc did not improve from 0.92070\n",
            "Epoch 936/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0780 - acc: 0.9778 - val_loss: 0.2872 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00936: val_acc did not improve from 0.92070\n",
            "Epoch 937/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0679 - acc: 0.9845 - val_loss: 0.2863 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00937: val_acc did not improve from 0.92070\n",
            "Epoch 938/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0757 - acc: 0.9809 - val_loss: 0.2860 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00938: val_acc did not improve from 0.92070\n",
            "Epoch 939/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0698 - acc: 0.9827 - val_loss: 0.2859 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00939: val_acc did not improve from 0.92070\n",
            "Epoch 940/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0736 - acc: 0.9817 - val_loss: 0.2862 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00940: val_acc did not improve from 0.92070\n",
            "Epoch 941/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0708 - acc: 0.9826 - val_loss: 0.2861 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00941: val_acc did not improve from 0.92070\n",
            "Epoch 942/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0744 - acc: 0.9828 - val_loss: 0.2859 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00942: val_acc did not improve from 0.92070\n",
            "Epoch 943/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0692 - acc: 0.9817 - val_loss: 0.2861 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00943: val_acc did not improve from 0.92070\n",
            "Epoch 944/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0795 - acc: 0.9784 - val_loss: 0.2861 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00944: val_acc did not improve from 0.92070\n",
            "Epoch 945/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0751 - acc: 0.9812 - val_loss: 0.2861 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00945: val_acc did not improve from 0.92070\n",
            "Epoch 946/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0753 - acc: 0.9826 - val_loss: 0.2865 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00946: val_acc did not improve from 0.92070\n",
            "Epoch 947/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0709 - acc: 0.9848 - val_loss: 0.2873 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00947: val_acc did not improve from 0.92070\n",
            "Epoch 948/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0686 - acc: 0.9835 - val_loss: 0.2871 - val_acc: 0.9192\n",
            "\n",
            "Epoch 00948: val_acc did not improve from 0.92070\n",
            "Epoch 949/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0707 - acc: 0.9826 - val_loss: 0.2864 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00949: val_acc did not improve from 0.92070\n",
            "Epoch 950/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0691 - acc: 0.9838 - val_loss: 0.2866 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00950: val_acc did not improve from 0.92070\n",
            "Epoch 951/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0693 - acc: 0.9812 - val_loss: 0.2870 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00951: val_acc did not improve from 0.92070\n",
            "Epoch 952/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0619 - acc: 0.9871 - val_loss: 0.2862 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00952: val_acc did not improve from 0.92070\n",
            "Epoch 953/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0695 - acc: 0.9851 - val_loss: 0.2868 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00953: val_acc did not improve from 0.92070\n",
            "Epoch 954/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0794 - acc: 0.9786 - val_loss: 0.2864 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00954: val_acc did not improve from 0.92070\n",
            "Epoch 955/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0745 - acc: 0.9789 - val_loss: 0.2864 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00955: val_acc did not improve from 0.92070\n",
            "Epoch 956/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0790 - acc: 0.9788 - val_loss: 0.2864 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00956: val_acc did not improve from 0.92070\n",
            "Epoch 957/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0709 - acc: 0.9818 - val_loss: 0.2856 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00957: val_acc did not improve from 0.92070\n",
            "Epoch 958/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0706 - acc: 0.9830 - val_loss: 0.2858 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00958: val_acc did not improve from 0.92070\n",
            "Epoch 959/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0724 - acc: 0.9824 - val_loss: 0.2856 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00959: val_acc did not improve from 0.92070\n",
            "Epoch 960/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0740 - acc: 0.9805 - val_loss: 0.2859 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00960: val_acc did not improve from 0.92070\n",
            "Epoch 961/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0704 - acc: 0.9823 - val_loss: 0.2852 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00961: val_acc did not improve from 0.92070\n",
            "Epoch 962/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0769 - acc: 0.9817 - val_loss: 0.2861 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00962: val_acc did not improve from 0.92070\n",
            "Epoch 963/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0708 - acc: 0.9812 - val_loss: 0.2858 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00963: val_acc did not improve from 0.92070\n",
            "Epoch 964/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0716 - acc: 0.9831 - val_loss: 0.2866 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00964: val_acc did not improve from 0.92070\n",
            "Epoch 965/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0640 - acc: 0.9857 - val_loss: 0.2862 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00965: val_acc did not improve from 0.92070\n",
            "Epoch 966/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0679 - acc: 0.9832 - val_loss: 0.2860 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00966: val_acc did not improve from 0.92070\n",
            "Epoch 967/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0672 - acc: 0.9832 - val_loss: 0.2861 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00967: val_acc did not improve from 0.92070\n",
            "Epoch 968/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0712 - acc: 0.9825 - val_loss: 0.2864 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00968: val_acc did not improve from 0.92070\n",
            "Epoch 969/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0701 - acc: 0.9837 - val_loss: 0.2863 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00969: val_acc did not improve from 0.92070\n",
            "Epoch 970/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0640 - acc: 0.9833 - val_loss: 0.2860 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00970: val_acc did not improve from 0.92070\n",
            "Epoch 971/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0685 - acc: 0.9828 - val_loss: 0.2861 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00971: val_acc did not improve from 0.92070\n",
            "Epoch 972/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0702 - acc: 0.9816 - val_loss: 0.2865 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00972: val_acc did not improve from 0.92070\n",
            "Epoch 973/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0708 - acc: 0.9832 - val_loss: 0.2858 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00973: val_acc did not improve from 0.92070\n",
            "Epoch 974/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0706 - acc: 0.9831 - val_loss: 0.2859 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00974: val_acc did not improve from 0.92070\n",
            "Epoch 975/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0699 - acc: 0.9806 - val_loss: 0.2863 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00975: val_acc did not improve from 0.92070\n",
            "Epoch 976/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0738 - acc: 0.9811 - val_loss: 0.2861 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00976: val_acc did not improve from 0.92070\n",
            "Epoch 977/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0667 - acc: 0.9851 - val_loss: 0.2857 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00977: val_acc did not improve from 0.92070\n",
            "Epoch 978/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0653 - acc: 0.9854 - val_loss: 0.2865 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00978: val_acc did not improve from 0.92070\n",
            "Epoch 979/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0740 - acc: 0.9817 - val_loss: 0.2867 - val_acc: 0.9195\n",
            "\n",
            "Epoch 00979: val_acc did not improve from 0.92070\n",
            "Epoch 980/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0708 - acc: 0.9827 - val_loss: 0.2864 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00980: val_acc did not improve from 0.92070\n",
            "Epoch 981/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0712 - acc: 0.9829 - val_loss: 0.2862 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00981: val_acc did not improve from 0.92070\n",
            "Epoch 982/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0667 - acc: 0.9815 - val_loss: 0.2865 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00982: val_acc did not improve from 0.92070\n",
            "Epoch 983/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0713 - acc: 0.9814 - val_loss: 0.2863 - val_acc: 0.9205\n",
            "\n",
            "Epoch 00983: val_acc did not improve from 0.92070\n",
            "Epoch 984/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0713 - acc: 0.9829 - val_loss: 0.2863 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00984: val_acc did not improve from 0.92070\n",
            "Epoch 985/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.0691 - acc: 0.9823 - val_loss: 0.2866 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00985: val_acc did not improve from 0.92070\n",
            "Epoch 986/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0650 - acc: 0.9861 - val_loss: 0.2863 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00986: val_acc did not improve from 0.92070\n",
            "Epoch 987/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0712 - acc: 0.9829 - val_loss: 0.2853 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00987: val_acc did not improve from 0.92070\n",
            "Epoch 988/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0735 - acc: 0.9822 - val_loss: 0.2861 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00988: val_acc did not improve from 0.92070\n",
            "Epoch 989/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0625 - acc: 0.9845 - val_loss: 0.2864 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00989: val_acc did not improve from 0.92070\n",
            "Epoch 990/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.0698 - acc: 0.9834 - val_loss: 0.2868 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00990: val_acc did not improve from 0.92070\n",
            "Epoch 991/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0704 - acc: 0.9810 - val_loss: 0.2869 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00991: val_acc did not improve from 0.92070\n",
            "Epoch 992/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0737 - acc: 0.9814 - val_loss: 0.2870 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00992: val_acc did not improve from 0.92070\n",
            "Epoch 993/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0727 - acc: 0.9827 - val_loss: 0.2872 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00993: val_acc did not improve from 0.92070\n",
            "Epoch 994/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0688 - acc: 0.9844 - val_loss: 0.2876 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00994: val_acc did not improve from 0.92070\n",
            "Epoch 995/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.0704 - acc: 0.9807 - val_loss: 0.2870 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00995: val_acc did not improve from 0.92070\n",
            "Epoch 996/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 195ms/step - loss: 0.0688 - acc: 0.9825 - val_loss: 0.2862 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00996: val_acc did not improve from 0.92070\n",
            "Epoch 997/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0716 - acc: 0.9841 - val_loss: 0.2861 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00997: val_acc did not improve from 0.92070\n",
            "Epoch 998/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0729 - acc: 0.9814 - val_loss: 0.2862 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00998: val_acc did not improve from 0.92070\n",
            "Epoch 999/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.0722 - acc: 0.9831 - val_loss: 0.2857 - val_acc: 0.9198\n",
            "\n",
            "Epoch 00999: val_acc did not improve from 0.92070\n",
            "Epoch 1000/1000\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0657 - acc: 0.9824 - val_loss: 0.2858 - val_acc: 0.9200\n",
            "\n",
            "Epoch 01000: val_acc did not improve from 0.92070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "UhtnpiKqumiK",
        "outputId": "6139698f-9b77-4c7a-f21a-067181c8fe1d"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('trying_trainHistoryDict_clip_05', \"rb\"))\n",
        "functions.plot_loss_acc(history, 2, 0.4)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhqKiZyuu1ly",
        "outputId": "64902b22-378d-40c3-fa1f-e6007a37ef2a"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9200000166893005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ja4Ybheu2gf",
        "outputId": "db4b252a-6ddd-43a9-fba8-6a59453aba24"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07999998331069946"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXKrbbvBu5j9"
      },
      "source": [
        "#### Model with modified clipping to 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTJn4jZDu_Ti",
        "outputId": "a60b0b4d-05d9-453d-e32f-38851430cc3e"
      },
      "source": [
        "model, model_type = functions.define_and_compile_ResNet_model(input_shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZh0MlaPvEn8",
        "outputId": "09ba0180-0001-4180-e2d0-a1bcc696b07a"
      },
      "source": [
        "callbacks = functions.standard_callbacks(model_type) + [functions.Clipping(1, \"trying\")]\n",
        "history = functions.run_training(model, model_type, x_train, y_train, x_test, y_test,\n",
        "                       'trying_trainHistoryDict_clip_1', steps_per_epoch=100, epochs=650,\n",
        "                       batch_size=100,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 45s 115ms/step - loss: 2.6999 - acc: 0.2526 - val_loss: 2.5398 - val_acc: 0.2269\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.22690, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.8676 - acc: 0.3379 - val_loss: 4.3840 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.22690\n",
            "Epoch 3/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.5738 - acc: 0.4640 - val_loss: 4.6673 - val_acc: 0.1122\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.22690\n",
            "Epoch 4/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.4469 - acc: 0.5055 - val_loss: 1.9222 - val_acc: 0.3649\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.22690 to 0.36490, saving model to /content/saved_models/cifar10_ResNet32v1_model.004.h5\n",
            "Epoch 5/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.3389 - acc: 0.5458 - val_loss: 1.7710 - val_acc: 0.4303\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.36490 to 0.43030, saving model to /content/saved_models/cifar10_ResNet32v1_model.005.h5\n",
            "Epoch 6/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.2829 - acc: 0.5665 - val_loss: 3.5188 - val_acc: 0.3282\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.43030\n",
            "Epoch 7/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.1899 - acc: 0.6057 - val_loss: 1.9054 - val_acc: 0.4680\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.43030 to 0.46800, saving model to /content/saved_models/cifar10_ResNet32v1_model.007.h5\n",
            "Epoch 8/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.1334 - acc: 0.6246 - val_loss: 4.6022 - val_acc: 0.2908\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.46800\n",
            "Epoch 9/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.0795 - acc: 0.6493 - val_loss: 1.6948 - val_acc: 0.4991\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.46800 to 0.49910, saving model to /content/saved_models/cifar10_ResNet32v1_model.009.h5\n",
            "Epoch 10/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.0548 - acc: 0.6526 - val_loss: 1.6966 - val_acc: 0.5169\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.49910 to 0.51690, saving model to /content/saved_models/cifar10_ResNet32v1_model.010.h5\n",
            "Epoch 11/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.0186 - acc: 0.6610 - val_loss: 1.7661 - val_acc: 0.5240\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.51690 to 0.52400, saving model to /content/saved_models/cifar10_ResNet32v1_model.011.h5\n",
            "Epoch 12/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.9867 - acc: 0.6682 - val_loss: 2.1419 - val_acc: 0.4343\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.52400\n",
            "Epoch 13/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.9421 - acc: 0.6923 - val_loss: 2.0982 - val_acc: 0.4914\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.52400\n",
            "Epoch 14/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.9118 - acc: 0.7048 - val_loss: 1.3548 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.52400 to 0.57640, saving model to /content/saved_models/cifar10_ResNet32v1_model.014.h5\n",
            "Epoch 15/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.8890 - acc: 0.7072 - val_loss: 1.4306 - val_acc: 0.5739\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.57640\n",
            "Epoch 16/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.9147 - acc: 0.7034 - val_loss: 1.5115 - val_acc: 0.5635\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.57640\n",
            "Epoch 17/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.9067 - acc: 0.7146 - val_loss: 1.6024 - val_acc: 0.5501\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.57640\n",
            "Epoch 18/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.8485 - acc: 0.7265 - val_loss: 1.6225 - val_acc: 0.5457\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.57640\n",
            "Epoch 19/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.8477 - acc: 0.7256 - val_loss: 1.4991 - val_acc: 0.5847\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.57640 to 0.58470, saving model to /content/saved_models/cifar10_ResNet32v1_model.019.h5\n",
            "Epoch 20/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.8444 - acc: 0.7227 - val_loss: 2.8183 - val_acc: 0.3925\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.58470\n",
            "Epoch 21/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.8138 - acc: 0.7374 - val_loss: 1.5213 - val_acc: 0.5878\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.58470 to 0.58780, saving model to /content/saved_models/cifar10_ResNet32v1_model.021.h5\n",
            "Epoch 22/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.8153 - acc: 0.7402 - val_loss: 1.1901 - val_acc: 0.6589\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.58780 to 0.65890, saving model to /content/saved_models/cifar10_ResNet32v1_model.022.h5\n",
            "Epoch 23/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.8031 - acc: 0.7393 - val_loss: 2.8202 - val_acc: 0.4611\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.65890\n",
            "Epoch 24/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.8054 - acc: 0.7423 - val_loss: 1.3457 - val_acc: 0.6027\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.65890\n",
            "Epoch 25/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.7692 - acc: 0.7532 - val_loss: 1.1580 - val_acc: 0.6634\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.65890 to 0.66340, saving model to /content/saved_models/cifar10_ResNet32v1_model.025.h5\n",
            "Epoch 26/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.7464 - acc: 0.7638 - val_loss: 1.3941 - val_acc: 0.6258\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.66340\n",
            "Epoch 27/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.7571 - acc: 0.7582 - val_loss: 1.7667 - val_acc: 0.5198\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.66340\n",
            "Epoch 28/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.7515 - acc: 0.7601 - val_loss: 1.3635 - val_acc: 0.6157\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.66340\n",
            "Epoch 29/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.7341 - acc: 0.7660 - val_loss: 1.4125 - val_acc: 0.5800\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.66340\n",
            "Epoch 30/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.7135 - acc: 0.7791 - val_loss: 1.2157 - val_acc: 0.6531\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.66340\n",
            "Epoch 31/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.6920 - acc: 0.7828 - val_loss: 1.2008 - val_acc: 0.6369\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.66340\n",
            "Epoch 32/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.7314 - acc: 0.7700 - val_loss: 1.2401 - val_acc: 0.6536\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.66340\n",
            "Epoch 33/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.6990 - acc: 0.7783 - val_loss: 0.9749 - val_acc: 0.7028\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.66340 to 0.70280, saving model to /content/saved_models/cifar10_ResNet32v1_model.033.h5\n",
            "Epoch 34/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.7091 - acc: 0.7731 - val_loss: 1.5950 - val_acc: 0.5760\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.70280\n",
            "Epoch 35/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.6932 - acc: 0.7820 - val_loss: 1.1176 - val_acc: 0.6719\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.70280\n",
            "Epoch 36/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.6951 - acc: 0.7789 - val_loss: 1.3272 - val_acc: 0.6277\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.70280\n",
            "Epoch 37/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.6902 - acc: 0.7785 - val_loss: 1.1269 - val_acc: 0.6612\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.70280\n",
            "Epoch 38/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.6638 - acc: 0.7868 - val_loss: 1.7612 - val_acc: 0.5628\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.70280\n",
            "Epoch 39/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.6698 - acc: 0.7928 - val_loss: 1.8422 - val_acc: 0.5867\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.70280\n",
            "Epoch 40/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.6813 - acc: 0.7860 - val_loss: 1.3176 - val_acc: 0.6262\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.70280\n",
            "Epoch 41/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.6717 - acc: 0.7905 - val_loss: 1.3732 - val_acc: 0.6307\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.70280\n",
            "Epoch 42/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.6819 - acc: 0.7852 - val_loss: 2.3932 - val_acc: 0.5046\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.70280\n",
            "Epoch 43/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.6622 - acc: 0.7927 - val_loss: 2.2956 - val_acc: 0.5394\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.70280\n",
            "Epoch 44/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.6517 - acc: 0.7992 - val_loss: 0.9769 - val_acc: 0.7099\n",
            "\n",
            "Epoch 00044: val_acc improved from 0.70280 to 0.70990, saving model to /content/saved_models/cifar10_ResNet32v1_model.044.h5\n",
            "Epoch 45/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.6485 - acc: 0.8002 - val_loss: 1.3625 - val_acc: 0.6538\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.70990\n",
            "Epoch 46/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.6383 - acc: 0.8011 - val_loss: 1.6367 - val_acc: 0.6147\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.70990\n",
            "Epoch 47/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.6466 - acc: 0.7951 - val_loss: 1.4552 - val_acc: 0.6467\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.70990\n",
            "Epoch 48/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.6363 - acc: 0.8004 - val_loss: 1.1976 - val_acc: 0.6593\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.70990\n",
            "Epoch 49/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.6432 - acc: 0.8010 - val_loss: 0.8274 - val_acc: 0.7422\n",
            "\n",
            "Epoch 00049: val_acc improved from 0.70990 to 0.74220, saving model to /content/saved_models/cifar10_ResNet32v1_model.049.h5\n",
            "Epoch 50/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.6192 - acc: 0.8045 - val_loss: 1.6446 - val_acc: 0.6171\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.74220\n",
            "Epoch 51/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.6272 - acc: 0.8034 - val_loss: 0.9306 - val_acc: 0.7282\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.74220\n",
            "Epoch 52/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.6149 - acc: 0.8119 - val_loss: 1.3329 - val_acc: 0.6297\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.74220\n",
            "Epoch 53/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.6136 - acc: 0.8048 - val_loss: 1.3499 - val_acc: 0.6490\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.74220\n",
            "Epoch 54/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.6084 - acc: 0.8146 - val_loss: 1.3461 - val_acc: 0.6518\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.74220\n",
            "Epoch 55/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.6303 - acc: 0.8010 - val_loss: 2.1502 - val_acc: 0.5660\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.74220\n",
            "Epoch 56/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.5977 - acc: 0.8164 - val_loss: 1.6796 - val_acc: 0.5874\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.74220\n",
            "Epoch 57/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.6068 - acc: 0.8189 - val_loss: 2.2357 - val_acc: 0.5482\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.74220\n",
            "Epoch 58/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.6097 - acc: 0.8115 - val_loss: 0.9385 - val_acc: 0.7113\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.74220\n",
            "Epoch 59/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.5835 - acc: 0.8237 - val_loss: 1.2533 - val_acc: 0.6546\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.74220\n",
            "Epoch 60/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.5949 - acc: 0.8144 - val_loss: 1.0895 - val_acc: 0.6880\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.74220\n",
            "Epoch 61/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.5882 - acc: 0.8184 - val_loss: 1.0390 - val_acc: 0.7229\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.74220\n",
            "Epoch 62/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.5874 - acc: 0.8136 - val_loss: 1.0695 - val_acc: 0.7142\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.74220\n",
            "Epoch 63/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.5828 - acc: 0.8170 - val_loss: 1.4214 - val_acc: 0.6524\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.74220\n",
            "Epoch 64/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.5822 - acc: 0.8221 - val_loss: 1.0145 - val_acc: 0.7152\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.74220\n",
            "Epoch 65/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.5796 - acc: 0.8164 - val_loss: 1.2188 - val_acc: 0.6617\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.74220\n",
            "Epoch 66/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5635 - acc: 0.8221 - val_loss: 1.7942 - val_acc: 0.5408\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.74220\n",
            "Epoch 67/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5681 - acc: 0.8295 - val_loss: 1.5185 - val_acc: 0.6156\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.74220\n",
            "Epoch 68/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.5906 - acc: 0.8163 - val_loss: 1.1809 - val_acc: 0.6694\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.74220\n",
            "Epoch 69/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5753 - acc: 0.8228 - val_loss: 1.3720 - val_acc: 0.6512\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.74220\n",
            "Epoch 70/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5828 - acc: 0.8215 - val_loss: 1.0358 - val_acc: 0.6852\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.74220\n",
            "Epoch 71/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.5754 - acc: 0.8170 - val_loss: 0.9777 - val_acc: 0.7247\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.74220\n",
            "Epoch 72/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5714 - acc: 0.8222 - val_loss: 2.7844 - val_acc: 0.4819\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.74220\n",
            "Epoch 73/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5782 - acc: 0.8186 - val_loss: 1.3707 - val_acc: 0.6323\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.74220\n",
            "Epoch 74/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.5577 - acc: 0.8248 - val_loss: 0.8817 - val_acc: 0.7429\n",
            "\n",
            "Epoch 00074: val_acc improved from 0.74220 to 0.74290, saving model to /content/saved_models/cifar10_ResNet32v1_model.074.h5\n",
            "Epoch 75/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5241 - acc: 0.8377 - val_loss: 1.3080 - val_acc: 0.6254\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.74290\n",
            "Epoch 76/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5565 - acc: 0.8245 - val_loss: 1.4719 - val_acc: 0.6330\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.74290\n",
            "Epoch 77/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5548 - acc: 0.8343 - val_loss: 0.9967 - val_acc: 0.7212\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.74290\n",
            "Epoch 78/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5614 - acc: 0.8242 - val_loss: 0.9044 - val_acc: 0.7309\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.74290\n",
            "Epoch 79/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.5707 - acc: 0.8243 - val_loss: 0.8765 - val_acc: 0.7406\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.74290\n",
            "Epoch 80/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.5498 - acc: 0.8388 - val_loss: 0.9952 - val_acc: 0.7047\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.74290\n",
            "Epoch 81/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5425 - acc: 0.8327 - val_loss: 1.6346 - val_acc: 0.5981\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.74290\n",
            "Epoch 82/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5484 - acc: 0.8384 - val_loss: 1.5726 - val_acc: 0.6143\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.74290\n",
            "Epoch 83/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5485 - acc: 0.8298 - val_loss: 1.1608 - val_acc: 0.6810\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.74290\n",
            "Epoch 84/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.5389 - acc: 0.8344 - val_loss: 1.0715 - val_acc: 0.7118\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.74290\n",
            "Epoch 85/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.5108 - acc: 0.8433 - val_loss: 1.4884 - val_acc: 0.6322\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.74290\n",
            "Epoch 86/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5488 - acc: 0.8336 - val_loss: 1.1711 - val_acc: 0.6740\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.74290\n",
            "Epoch 87/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.5419 - acc: 0.8307 - val_loss: 1.4231 - val_acc: 0.6361\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.74290\n",
            "Epoch 88/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.5407 - acc: 0.8403 - val_loss: 0.9219 - val_acc: 0.7473\n",
            "\n",
            "Epoch 00088: val_acc improved from 0.74290 to 0.74730, saving model to /content/saved_models/cifar10_ResNet32v1_model.088.h5\n",
            "Epoch 89/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.5559 - acc: 0.8334 - val_loss: 1.1873 - val_acc: 0.6487\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.74730\n",
            "Epoch 90/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5118 - acc: 0.8466 - val_loss: 1.1295 - val_acc: 0.6957\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.74730\n",
            "Epoch 91/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5290 - acc: 0.8404 - val_loss: 0.9105 - val_acc: 0.7345\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.74730\n",
            "Epoch 92/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5465 - acc: 0.8359 - val_loss: 1.9177 - val_acc: 0.5805\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.74730\n",
            "Epoch 93/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5094 - acc: 0.8497 - val_loss: 1.2678 - val_acc: 0.6664\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.74730\n",
            "Epoch 94/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5386 - acc: 0.8353 - val_loss: 0.7533 - val_acc: 0.7707\n",
            "\n",
            "Epoch 00094: val_acc improved from 0.74730 to 0.77070, saving model to /content/saved_models/cifar10_ResNet32v1_model.094.h5\n",
            "Epoch 95/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.5136 - acc: 0.8441 - val_loss: 2.0359 - val_acc: 0.5785\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.77070\n",
            "Epoch 96/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.5098 - acc: 0.8466 - val_loss: 0.9226 - val_acc: 0.7296\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.77070\n",
            "Epoch 97/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.5200 - acc: 0.8422 - val_loss: 1.4207 - val_acc: 0.6518\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.77070\n",
            "Epoch 98/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.5214 - acc: 0.8468 - val_loss: 1.4432 - val_acc: 0.6331\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.77070\n",
            "Epoch 99/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.5001 - acc: 0.8505 - val_loss: 1.2537 - val_acc: 0.6634\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.77070\n",
            "Epoch 100/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.5080 - acc: 0.8477 - val_loss: 0.8632 - val_acc: 0.7479\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.77070\n",
            "Epoch 101/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.5061 - acc: 0.8458 - val_loss: 1.2007 - val_acc: 0.6805\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.77070\n",
            "Epoch 102/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.5225 - acc: 0.8480 - val_loss: 1.4787 - val_acc: 0.6312\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.77070\n",
            "Epoch 103/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.5367 - acc: 0.8337 - val_loss: 1.0707 - val_acc: 0.7111\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.77070\n",
            "Epoch 104/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.5027 - acc: 0.8436 - val_loss: 0.9191 - val_acc: 0.7558\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.77070\n",
            "Epoch 105/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.5004 - acc: 0.8506 - val_loss: 1.5431 - val_acc: 0.6383\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.77070\n",
            "Epoch 106/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.5159 - acc: 0.8370 - val_loss: 1.0701 - val_acc: 0.6969\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.77070\n",
            "Epoch 107/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.4987 - acc: 0.8476 - val_loss: 1.0740 - val_acc: 0.6989\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.77070\n",
            "Epoch 108/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.5030 - acc: 0.8488 - val_loss: 0.7370 - val_acc: 0.7771\n",
            "\n",
            "Epoch 00108: val_acc improved from 0.77070 to 0.77710, saving model to /content/saved_models/cifar10_ResNet32v1_model.108.h5\n",
            "Epoch 109/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.5125 - acc: 0.8421 - val_loss: 1.0727 - val_acc: 0.7077\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.77710\n",
            "Epoch 110/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.5054 - acc: 0.8492 - val_loss: 1.9542 - val_acc: 0.5766\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.77710\n",
            "Epoch 111/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4918 - acc: 0.8536 - val_loss: 0.9114 - val_acc: 0.7450\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.77710\n",
            "Epoch 112/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.5092 - acc: 0.8474 - val_loss: 0.7630 - val_acc: 0.7632\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.77710\n",
            "Epoch 113/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4851 - acc: 0.8527 - val_loss: 1.1924 - val_acc: 0.6766\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.77710\n",
            "Epoch 114/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.5165 - acc: 0.8405 - val_loss: 1.0059 - val_acc: 0.7011\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.77710\n",
            "Epoch 115/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.5123 - acc: 0.8465 - val_loss: 1.3509 - val_acc: 0.6692\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.77710\n",
            "Epoch 116/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.5099 - acc: 0.8452 - val_loss: 0.7173 - val_acc: 0.7845\n",
            "\n",
            "Epoch 00116: val_acc improved from 0.77710 to 0.78450, saving model to /content/saved_models/cifar10_ResNet32v1_model.116.h5\n",
            "Epoch 117/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4977 - acc: 0.8462 - val_loss: 0.9010 - val_acc: 0.7481\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.78450\n",
            "Epoch 118/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.5217 - acc: 0.8437 - val_loss: 1.2532 - val_acc: 0.6580\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.78450\n",
            "Epoch 119/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4857 - acc: 0.8526 - val_loss: 1.0150 - val_acc: 0.7079\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.78450\n",
            "Epoch 120/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.5050 - acc: 0.8485 - val_loss: 1.0977 - val_acc: 0.6831\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.78450\n",
            "Epoch 121/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4993 - acc: 0.8490 - val_loss: 1.4272 - val_acc: 0.6746\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.78450\n",
            "Epoch 122/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4715 - acc: 0.8613 - val_loss: 0.8418 - val_acc: 0.7573\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.78450\n",
            "Epoch 123/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4770 - acc: 0.8594 - val_loss: 1.3047 - val_acc: 0.6895\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.78450\n",
            "Epoch 124/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4968 - acc: 0.8523 - val_loss: 1.0878 - val_acc: 0.7014\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.78450\n",
            "Epoch 125/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.5001 - acc: 0.8459 - val_loss: 0.7219 - val_acc: 0.7917\n",
            "\n",
            "Epoch 00125: val_acc improved from 0.78450 to 0.79170, saving model to /content/saved_models/cifar10_ResNet32v1_model.125.h5\n",
            "Epoch 126/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.5163 - acc: 0.8434 - val_loss: 0.8479 - val_acc: 0.7438\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.79170\n",
            "Epoch 127/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4934 - acc: 0.8524 - val_loss: 0.9021 - val_acc: 0.7436\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.79170\n",
            "Epoch 128/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4957 - acc: 0.8497 - val_loss: 1.3103 - val_acc: 0.6558\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.79170\n",
            "Epoch 129/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4949 - acc: 0.8460 - val_loss: 0.9244 - val_acc: 0.7500\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.79170\n",
            "Epoch 130/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4539 - acc: 0.8642 - val_loss: 1.0446 - val_acc: 0.7249\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.79170\n",
            "Epoch 131/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.5004 - acc: 0.8484 - val_loss: 1.5405 - val_acc: 0.6140\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.79170\n",
            "Epoch 132/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4698 - acc: 0.8556 - val_loss: 1.1140 - val_acc: 0.6993\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.79170\n",
            "Epoch 133/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.5067 - acc: 0.8452 - val_loss: 0.6441 - val_acc: 0.8079\n",
            "\n",
            "Epoch 00133: val_acc improved from 0.79170 to 0.80790, saving model to /content/saved_models/cifar10_ResNet32v1_model.133.h5\n",
            "Epoch 134/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4833 - acc: 0.8584 - val_loss: 0.9349 - val_acc: 0.7222\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.80790\n",
            "Epoch 135/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4853 - acc: 0.8526 - val_loss: 2.4385 - val_acc: 0.5194\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.80790\n",
            "Epoch 136/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4858 - acc: 0.8546 - val_loss: 1.7832 - val_acc: 0.5726\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.80790\n",
            "Epoch 137/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.5043 - acc: 0.8468 - val_loss: 0.9668 - val_acc: 0.7398\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.80790\n",
            "Epoch 138/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4823 - acc: 0.8567 - val_loss: 1.2420 - val_acc: 0.6662\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.80790\n",
            "Epoch 139/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.4894 - acc: 0.8518 - val_loss: 0.7466 - val_acc: 0.7850\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.80790\n",
            "Epoch 140/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4984 - acc: 0.8517 - val_loss: 0.8814 - val_acc: 0.7464\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.80790\n",
            "Epoch 141/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4649 - acc: 0.8603 - val_loss: 0.9337 - val_acc: 0.7361\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.80790\n",
            "Epoch 142/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.4657 - acc: 0.8596 - val_loss: 2.1537 - val_acc: 0.5635\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.80790\n",
            "Epoch 143/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4987 - acc: 0.8539 - val_loss: 0.8494 - val_acc: 0.7493\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.80790\n",
            "Epoch 144/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.4693 - acc: 0.8575 - val_loss: 1.1613 - val_acc: 0.6853\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.80790\n",
            "Epoch 145/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.4776 - acc: 0.8571 - val_loss: 1.2099 - val_acc: 0.6929\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.80790\n",
            "Epoch 146/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4858 - acc: 0.8475 - val_loss: 1.6973 - val_acc: 0.6014\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.80790\n",
            "Epoch 147/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.4927 - acc: 0.8594 - val_loss: 1.2685 - val_acc: 0.6870\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.80790\n",
            "Epoch 148/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.4748 - acc: 0.8593 - val_loss: 1.3401 - val_acc: 0.6673\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.80790\n",
            "Epoch 149/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4979 - acc: 0.8487 - val_loss: 0.9654 - val_acc: 0.7404\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.80790\n",
            "Epoch 150/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.4806 - acc: 0.8578 - val_loss: 1.2369 - val_acc: 0.6684\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.80790\n",
            "Epoch 151/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4514 - acc: 0.8666 - val_loss: 1.9152 - val_acc: 0.5944\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.80790\n",
            "Epoch 152/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.4567 - acc: 0.8625 - val_loss: 1.1681 - val_acc: 0.7032\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.80790\n",
            "Epoch 153/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4833 - acc: 0.8527 - val_loss: 0.6730 - val_acc: 0.7991\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.80790\n",
            "Epoch 154/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4549 - acc: 0.8637 - val_loss: 0.6591 - val_acc: 0.7977\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.80790\n",
            "Epoch 155/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4774 - acc: 0.8575 - val_loss: 0.8688 - val_acc: 0.7504\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.80790\n",
            "Epoch 156/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4604 - acc: 0.8613 - val_loss: 0.8758 - val_acc: 0.7521\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.80790\n",
            "Epoch 157/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.4918 - acc: 0.8503 - val_loss: 0.9051 - val_acc: 0.7515\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.80790\n",
            "Epoch 158/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.4806 - acc: 0.8586 - val_loss: 1.3624 - val_acc: 0.6599\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.80790\n",
            "Epoch 159/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4833 - acc: 0.8600 - val_loss: 1.4626 - val_acc: 0.6449\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.80790\n",
            "Epoch 160/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4588 - acc: 0.8625 - val_loss: 1.3801 - val_acc: 0.6626\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.80790\n",
            "Epoch 161/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4690 - acc: 0.8621 - val_loss: 1.0250 - val_acc: 0.7334\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.80790\n",
            "Epoch 162/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4669 - acc: 0.8604 - val_loss: 0.9335 - val_acc: 0.7368\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.80790\n",
            "Epoch 163/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4700 - acc: 0.8583 - val_loss: 0.8252 - val_acc: 0.7682\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.80790\n",
            "Epoch 164/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4508 - acc: 0.8658 - val_loss: 0.8708 - val_acc: 0.7298\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.80790\n",
            "Epoch 165/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4694 - acc: 0.8592 - val_loss: 0.8347 - val_acc: 0.7503\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.80790\n",
            "Epoch 166/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4529 - acc: 0.8641 - val_loss: 1.1342 - val_acc: 0.6968\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.80790\n",
            "Epoch 167/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4573 - acc: 0.8614 - val_loss: 1.0765 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.80790\n",
            "Epoch 168/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4612 - acc: 0.8642 - val_loss: 1.1276 - val_acc: 0.6834\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.80790\n",
            "Epoch 169/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4602 - acc: 0.8652 - val_loss: 0.9414 - val_acc: 0.7433\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.80790\n",
            "Epoch 170/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4828 - acc: 0.8568 - val_loss: 0.9192 - val_acc: 0.7469\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.80790\n",
            "Epoch 171/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4710 - acc: 0.8550 - val_loss: 0.8043 - val_acc: 0.7589\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.80790\n",
            "Epoch 172/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4710 - acc: 0.8593 - val_loss: 1.7511 - val_acc: 0.5843\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.80790\n",
            "Epoch 173/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4577 - acc: 0.8637 - val_loss: 1.1577 - val_acc: 0.6920\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.80790\n",
            "Epoch 174/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4678 - acc: 0.8595 - val_loss: 0.7724 - val_acc: 0.7795\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.80790\n",
            "Epoch 175/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4376 - acc: 0.8709 - val_loss: 1.2898 - val_acc: 0.6804\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.80790\n",
            "Epoch 176/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4533 - acc: 0.8629 - val_loss: 0.7315 - val_acc: 0.7846\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.80790\n",
            "Epoch 177/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4547 - acc: 0.8664 - val_loss: 1.0767 - val_acc: 0.7140\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.80790\n",
            "Epoch 178/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4927 - acc: 0.8495 - val_loss: 1.0469 - val_acc: 0.7225\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.80790\n",
            "Epoch 179/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4731 - acc: 0.8541 - val_loss: 1.9454 - val_acc: 0.5667\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.80790\n",
            "Epoch 180/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4587 - acc: 0.8622 - val_loss: 0.8067 - val_acc: 0.7720\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.80790\n",
            "Epoch 181/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4219 - acc: 0.8792 - val_loss: 0.7955 - val_acc: 0.7792\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.80790\n",
            "Epoch 182/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4703 - acc: 0.8529 - val_loss: 1.0815 - val_acc: 0.6974\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.80790\n",
            "Epoch 183/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4514 - acc: 0.8678 - val_loss: 1.1252 - val_acc: 0.7101\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.80790\n",
            "Epoch 184/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4580 - acc: 0.8639 - val_loss: 0.8792 - val_acc: 0.7483\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.80790\n",
            "Epoch 185/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4639 - acc: 0.8668 - val_loss: 0.9780 - val_acc: 0.7245\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.80790\n",
            "Epoch 186/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4453 - acc: 0.8676 - val_loss: 0.8031 - val_acc: 0.7578\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.80790\n",
            "Epoch 187/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4554 - acc: 0.8619 - val_loss: 0.9647 - val_acc: 0.7368\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.80790\n",
            "Epoch 188/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4521 - acc: 0.8637 - val_loss: 0.6755 - val_acc: 0.8010\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.80790\n",
            "Epoch 189/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4413 - acc: 0.8675 - val_loss: 0.9291 - val_acc: 0.7114\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.80790\n",
            "Epoch 190/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4680 - acc: 0.8593 - val_loss: 0.8482 - val_acc: 0.7506\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.80790\n",
            "Epoch 191/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4589 - acc: 0.8636 - val_loss: 1.2742 - val_acc: 0.6805\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.80790\n",
            "Epoch 192/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4515 - acc: 0.8709 - val_loss: 1.0751 - val_acc: 0.7163\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.80790\n",
            "Epoch 193/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4610 - acc: 0.8651 - val_loss: 1.2602 - val_acc: 0.6944\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.80790\n",
            "Epoch 194/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4656 - acc: 0.8554 - val_loss: 1.0980 - val_acc: 0.7118\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.80790\n",
            "Epoch 195/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4584 - acc: 0.8624 - val_loss: 0.9312 - val_acc: 0.7357\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.80790\n",
            "Epoch 196/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4521 - acc: 0.8680 - val_loss: 1.4575 - val_acc: 0.6212\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.80790\n",
            "Epoch 197/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4658 - acc: 0.8620 - val_loss: 0.8371 - val_acc: 0.7621\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.80790\n",
            "Epoch 198/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4620 - acc: 0.8596 - val_loss: 0.8970 - val_acc: 0.7361\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.80790\n",
            "Epoch 199/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4508 - acc: 0.8689 - val_loss: 0.8342 - val_acc: 0.7546\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.80790\n",
            "Epoch 200/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4419 - acc: 0.8722 - val_loss: 0.8662 - val_acc: 0.7556\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.80790\n",
            "Epoch 201/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4495 - acc: 0.8610 - val_loss: 0.8360 - val_acc: 0.7525\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.80790\n",
            "Epoch 202/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4586 - acc: 0.8603 - val_loss: 1.1087 - val_acc: 0.7047\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.80790\n",
            "Epoch 203/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4403 - acc: 0.8721 - val_loss: 0.8443 - val_acc: 0.7693\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.80790\n",
            "Epoch 204/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.4425 - acc: 0.8693 - val_loss: 0.7020 - val_acc: 0.7978\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.80790\n",
            "Epoch 205/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4444 - acc: 0.8722 - val_loss: 0.7812 - val_acc: 0.7648\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.80790\n",
            "Epoch 206/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4753 - acc: 0.8571 - val_loss: 0.9103 - val_acc: 0.7483\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.80790\n",
            "Epoch 207/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4444 - acc: 0.8713 - val_loss: 0.8054 - val_acc: 0.7630\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.80790\n",
            "Epoch 208/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.4611 - acc: 0.8625 - val_loss: 1.2531 - val_acc: 0.6781\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.80790\n",
            "Epoch 209/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4456 - acc: 0.8694 - val_loss: 1.8468 - val_acc: 0.5955\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.80790\n",
            "Epoch 210/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4662 - acc: 0.8611 - val_loss: 1.0350 - val_acc: 0.7339\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.80790\n",
            "Epoch 211/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4531 - acc: 0.8629 - val_loss: 1.3192 - val_acc: 0.6638\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.80790\n",
            "Epoch 212/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4283 - acc: 0.8706 - val_loss: 1.2203 - val_acc: 0.6847\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.80790\n",
            "Epoch 213/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4562 - acc: 0.8648 - val_loss: 1.0908 - val_acc: 0.7108\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.80790\n",
            "Epoch 214/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4485 - acc: 0.8669 - val_loss: 0.8386 - val_acc: 0.7604\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.80790\n",
            "Epoch 215/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4451 - acc: 0.8676 - val_loss: 0.9145 - val_acc: 0.7573\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.80790\n",
            "Epoch 216/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4512 - acc: 0.8632 - val_loss: 0.8008 - val_acc: 0.7699\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.80790\n",
            "Epoch 217/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4393 - acc: 0.8732 - val_loss: 1.4323 - val_acc: 0.6289\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.80790\n",
            "Epoch 218/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4438 - acc: 0.8671 - val_loss: 1.0727 - val_acc: 0.7041\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.80790\n",
            "Epoch 219/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4581 - acc: 0.8600 - val_loss: 2.6628 - val_acc: 0.5266\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.80790\n",
            "Epoch 220/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4303 - acc: 0.8771 - val_loss: 1.0232 - val_acc: 0.7314\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.80790\n",
            "Epoch 221/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4492 - acc: 0.8590 - val_loss: 0.9256 - val_acc: 0.7443\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.80790\n",
            "Epoch 222/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4548 - acc: 0.8643 - val_loss: 2.2899 - val_acc: 0.5463\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.80790\n",
            "Epoch 223/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4338 - acc: 0.8729 - val_loss: 1.1419 - val_acc: 0.6968\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.80790\n",
            "Epoch 224/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4467 - acc: 0.8676 - val_loss: 0.9848 - val_acc: 0.7290\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.80790\n",
            "Epoch 225/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4438 - acc: 0.8704 - val_loss: 1.6376 - val_acc: 0.6243\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.80790\n",
            "Epoch 226/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4416 - acc: 0.8667 - val_loss: 1.0714 - val_acc: 0.7054\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.80790\n",
            "Epoch 227/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4579 - acc: 0.8668 - val_loss: 1.1533 - val_acc: 0.6901\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.80790\n",
            "Epoch 228/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4333 - acc: 0.8729 - val_loss: 0.7687 - val_acc: 0.7625\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.80790\n",
            "Epoch 229/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4378 - acc: 0.8703 - val_loss: 1.0980 - val_acc: 0.7044\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.80790\n",
            "Epoch 230/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.4315 - acc: 0.8724 - val_loss: 1.5844 - val_acc: 0.6628\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.80790\n",
            "Epoch 231/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4355 - acc: 0.8737 - val_loss: 0.8678 - val_acc: 0.7513\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.80790\n",
            "Epoch 232/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4157 - acc: 0.8778 - val_loss: 0.8128 - val_acc: 0.7721\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.80790\n",
            "Epoch 233/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4328 - acc: 0.8730 - val_loss: 1.2407 - val_acc: 0.6873\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.80790\n",
            "Epoch 234/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4288 - acc: 0.8694 - val_loss: 1.1063 - val_acc: 0.7196\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.80790\n",
            "Epoch 235/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4299 - acc: 0.8737 - val_loss: 1.1166 - val_acc: 0.7017\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.80790\n",
            "Epoch 236/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4406 - acc: 0.8701 - val_loss: 0.8842 - val_acc: 0.7571\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.80790\n",
            "Epoch 237/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4366 - acc: 0.8709 - val_loss: 0.8122 - val_acc: 0.7746\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.80790\n",
            "Epoch 238/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4540 - acc: 0.8618 - val_loss: 0.8296 - val_acc: 0.7654\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.80790\n",
            "Epoch 239/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4609 - acc: 0.8615 - val_loss: 1.6654 - val_acc: 0.6041\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.80790\n",
            "Epoch 240/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4317 - acc: 0.8741 - val_loss: 0.6703 - val_acc: 0.8045\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.80790\n",
            "Epoch 241/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4287 - acc: 0.8759 - val_loss: 1.0832 - val_acc: 0.7223\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.80790\n",
            "Epoch 242/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4369 - acc: 0.8738 - val_loss: 0.8878 - val_acc: 0.7533\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.80790\n",
            "Epoch 243/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4360 - acc: 0.8714 - val_loss: 0.5858 - val_acc: 0.8318\n",
            "\n",
            "Epoch 00243: val_acc improved from 0.80790 to 0.83180, saving model to /content/saved_models/cifar10_ResNet32v1_model.243.h5\n",
            "Epoch 244/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4103 - acc: 0.8770 - val_loss: 1.4748 - val_acc: 0.6233\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.83180\n",
            "Epoch 245/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4265 - acc: 0.8722 - val_loss: 0.6013 - val_acc: 0.8202\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.83180\n",
            "Epoch 246/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4358 - acc: 0.8672 - val_loss: 0.7319 - val_acc: 0.7922\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.83180\n",
            "Epoch 247/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4391 - acc: 0.8709 - val_loss: 0.8659 - val_acc: 0.7479\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.83180\n",
            "Epoch 248/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4252 - acc: 0.8758 - val_loss: 1.2883 - val_acc: 0.6796\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.83180\n",
            "Epoch 249/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4204 - acc: 0.8749 - val_loss: 0.8827 - val_acc: 0.7371\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.83180\n",
            "Epoch 250/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4366 - acc: 0.8728 - val_loss: 1.0648 - val_acc: 0.7319\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.83180\n",
            "Epoch 251/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4516 - acc: 0.8706 - val_loss: 1.5727 - val_acc: 0.5862\n",
            "\n",
            "Epoch 00251: val_acc did not improve from 0.83180\n",
            "Epoch 252/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4301 - acc: 0.8719 - val_loss: 1.5130 - val_acc: 0.6591\n",
            "\n",
            "Epoch 00252: val_acc did not improve from 0.83180\n",
            "Epoch 253/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4324 - acc: 0.8707 - val_loss: 1.2246 - val_acc: 0.7087\n",
            "\n",
            "Epoch 00253: val_acc did not improve from 0.83180\n",
            "Epoch 254/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4180 - acc: 0.8768 - val_loss: 0.7786 - val_acc: 0.7677\n",
            "\n",
            "Epoch 00254: val_acc did not improve from 0.83180\n",
            "Epoch 255/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4505 - acc: 0.8588 - val_loss: 0.8229 - val_acc: 0.7682\n",
            "\n",
            "Epoch 00255: val_acc did not improve from 0.83180\n",
            "Epoch 256/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4554 - acc: 0.8678 - val_loss: 1.0795 - val_acc: 0.6991\n",
            "\n",
            "Epoch 00256: val_acc did not improve from 0.83180\n",
            "Epoch 257/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4460 - acc: 0.8698 - val_loss: 0.7266 - val_acc: 0.7842\n",
            "\n",
            "Epoch 00257: val_acc did not improve from 0.83180\n",
            "Epoch 258/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4311 - acc: 0.8721 - val_loss: 1.1419 - val_acc: 0.6975\n",
            "\n",
            "Epoch 00258: val_acc did not improve from 0.83180\n",
            "Epoch 259/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4451 - acc: 0.8666 - val_loss: 0.8821 - val_acc: 0.7510\n",
            "\n",
            "Epoch 00259: val_acc did not improve from 0.83180\n",
            "Epoch 260/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4252 - acc: 0.8740 - val_loss: 0.8724 - val_acc: 0.7540\n",
            "\n",
            "Epoch 00260: val_acc did not improve from 0.83180\n",
            "Epoch 261/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4124 - acc: 0.8763 - val_loss: 0.9418 - val_acc: 0.7334\n",
            "\n",
            "Epoch 00261: val_acc did not improve from 0.83180\n",
            "Epoch 262/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4383 - acc: 0.8725 - val_loss: 0.8272 - val_acc: 0.7679\n",
            "\n",
            "Epoch 00262: val_acc did not improve from 0.83180\n",
            "Epoch 263/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4302 - acc: 0.8750 - val_loss: 0.6894 - val_acc: 0.7986\n",
            "\n",
            "Epoch 00263: val_acc did not improve from 0.83180\n",
            "Epoch 264/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4321 - acc: 0.8716 - val_loss: 0.7050 - val_acc: 0.7947\n",
            "\n",
            "Epoch 00264: val_acc did not improve from 0.83180\n",
            "Epoch 265/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4254 - acc: 0.8760 - val_loss: 0.9663 - val_acc: 0.7358\n",
            "\n",
            "Epoch 00265: val_acc did not improve from 0.83180\n",
            "Epoch 266/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4492 - acc: 0.8628 - val_loss: 0.8254 - val_acc: 0.7675\n",
            "\n",
            "Epoch 00266: val_acc did not improve from 0.83180\n",
            "Epoch 267/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4469 - acc: 0.8634 - val_loss: 0.8467 - val_acc: 0.7679\n",
            "\n",
            "Epoch 00267: val_acc did not improve from 0.83180\n",
            "Epoch 268/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4339 - acc: 0.8738 - val_loss: 0.8091 - val_acc: 0.7534\n",
            "\n",
            "Epoch 00268: val_acc did not improve from 0.83180\n",
            "Epoch 269/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4290 - acc: 0.8762 - val_loss: 0.8739 - val_acc: 0.7602\n",
            "\n",
            "Epoch 00269: val_acc did not improve from 0.83180\n",
            "Epoch 270/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4426 - acc: 0.8635 - val_loss: 0.9563 - val_acc: 0.7520\n",
            "\n",
            "Epoch 00270: val_acc did not improve from 0.83180\n",
            "Epoch 271/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4378 - acc: 0.8689 - val_loss: 1.5162 - val_acc: 0.6476\n",
            "\n",
            "Epoch 00271: val_acc did not improve from 0.83180\n",
            "Epoch 272/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4386 - acc: 0.8691 - val_loss: 1.1769 - val_acc: 0.6735\n",
            "\n",
            "Epoch 00272: val_acc did not improve from 0.83180\n",
            "Epoch 273/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4430 - acc: 0.8693 - val_loss: 0.8988 - val_acc: 0.7653\n",
            "\n",
            "Epoch 00273: val_acc did not improve from 0.83180\n",
            "Epoch 274/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4148 - acc: 0.8768 - val_loss: 1.3043 - val_acc: 0.6879\n",
            "\n",
            "Epoch 00274: val_acc did not improve from 0.83180\n",
            "Epoch 275/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4296 - acc: 0.8740 - val_loss: 0.9850 - val_acc: 0.7300\n",
            "\n",
            "Epoch 00275: val_acc did not improve from 0.83180\n",
            "Epoch 276/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4204 - acc: 0.8778 - val_loss: 0.6679 - val_acc: 0.8017\n",
            "\n",
            "Epoch 00276: val_acc did not improve from 0.83180\n",
            "Epoch 277/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4273 - acc: 0.8787 - val_loss: 0.7020 - val_acc: 0.8028\n",
            "\n",
            "Epoch 00277: val_acc did not improve from 0.83180\n",
            "Epoch 278/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.4203 - acc: 0.8752 - val_loss: 1.0662 - val_acc: 0.7028\n",
            "\n",
            "Epoch 00278: val_acc did not improve from 0.83180\n",
            "Epoch 279/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4081 - acc: 0.8773 - val_loss: 0.5964 - val_acc: 0.8190\n",
            "\n",
            "Epoch 00279: val_acc did not improve from 0.83180\n",
            "Epoch 280/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4153 - acc: 0.8768 - val_loss: 0.9538 - val_acc: 0.7490\n",
            "\n",
            "Epoch 00280: val_acc did not improve from 0.83180\n",
            "Epoch 281/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4126 - acc: 0.8778 - val_loss: 0.7852 - val_acc: 0.7542\n",
            "\n",
            "Epoch 00281: val_acc did not improve from 0.83180\n",
            "Epoch 282/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4085 - acc: 0.8816 - val_loss: 0.8385 - val_acc: 0.7667\n",
            "\n",
            "Epoch 00282: val_acc did not improve from 0.83180\n",
            "Epoch 283/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4174 - acc: 0.8820 - val_loss: 1.1416 - val_acc: 0.7112\n",
            "\n",
            "Epoch 00283: val_acc did not improve from 0.83180\n",
            "Epoch 284/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4293 - acc: 0.8746 - val_loss: 1.1682 - val_acc: 0.6898\n",
            "\n",
            "Epoch 00284: val_acc did not improve from 0.83180\n",
            "Epoch 285/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4273 - acc: 0.8720 - val_loss: 0.7424 - val_acc: 0.7841\n",
            "\n",
            "Epoch 00285: val_acc did not improve from 0.83180\n",
            "Epoch 286/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4375 - acc: 0.8707 - val_loss: 0.6885 - val_acc: 0.7947\n",
            "\n",
            "Epoch 00286: val_acc did not improve from 0.83180\n",
            "Epoch 287/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4344 - acc: 0.8725 - val_loss: 0.9241 - val_acc: 0.7347\n",
            "\n",
            "Epoch 00287: val_acc did not improve from 0.83180\n",
            "Epoch 288/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4359 - acc: 0.8721 - val_loss: 0.9221 - val_acc: 0.7424\n",
            "\n",
            "Epoch 00288: val_acc did not improve from 0.83180\n",
            "Epoch 289/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4187 - acc: 0.8779 - val_loss: 1.0717 - val_acc: 0.7178\n",
            "\n",
            "Epoch 00289: val_acc did not improve from 0.83180\n",
            "Epoch 290/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.3953 - acc: 0.8817 - val_loss: 0.9652 - val_acc: 0.7344\n",
            "\n",
            "Epoch 00290: val_acc did not improve from 0.83180\n",
            "Epoch 291/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4331 - acc: 0.8748 - val_loss: 1.2096 - val_acc: 0.7021\n",
            "\n",
            "Epoch 00291: val_acc did not improve from 0.83180\n",
            "Epoch 292/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4145 - acc: 0.8772 - val_loss: 1.2646 - val_acc: 0.6938\n",
            "\n",
            "Epoch 00292: val_acc did not improve from 0.83180\n",
            "Epoch 293/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4196 - acc: 0.8789 - val_loss: 0.6831 - val_acc: 0.8027\n",
            "\n",
            "Epoch 00293: val_acc did not improve from 0.83180\n",
            "Epoch 294/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4327 - acc: 0.8715 - val_loss: 1.1894 - val_acc: 0.7071\n",
            "\n",
            "Epoch 00294: val_acc did not improve from 0.83180\n",
            "Epoch 295/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4387 - acc: 0.8701 - val_loss: 1.9335 - val_acc: 0.5897\n",
            "\n",
            "Epoch 00295: val_acc did not improve from 0.83180\n",
            "Epoch 296/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4256 - acc: 0.8714 - val_loss: 1.0099 - val_acc: 0.7207\n",
            "\n",
            "Epoch 00296: val_acc did not improve from 0.83180\n",
            "Epoch 297/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4184 - acc: 0.8814 - val_loss: 1.1094 - val_acc: 0.7037\n",
            "\n",
            "Epoch 00297: val_acc did not improve from 0.83180\n",
            "Epoch 298/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4266 - acc: 0.8766 - val_loss: 1.5309 - val_acc: 0.6677\n",
            "\n",
            "Epoch 00298: val_acc did not improve from 0.83180\n",
            "Epoch 299/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4278 - acc: 0.8765 - val_loss: 1.9644 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00299: val_acc did not improve from 0.83180\n",
            "Epoch 300/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4296 - acc: 0.8790 - val_loss: 0.5499 - val_acc: 0.8381\n",
            "\n",
            "Epoch 00300: val_acc improved from 0.83180 to 0.83810, saving model to /content/saved_models/cifar10_ResNet32v1_model.300.h5\n",
            "Epoch 301/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4285 - acc: 0.8734 - val_loss: 1.0598 - val_acc: 0.7216\n",
            "\n",
            "Epoch 00301: val_acc did not improve from 0.83810\n",
            "Epoch 302/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4174 - acc: 0.8790 - val_loss: 0.6724 - val_acc: 0.8099\n",
            "\n",
            "Epoch 00302: val_acc did not improve from 0.83810\n",
            "Epoch 303/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4373 - acc: 0.8700 - val_loss: 1.0912 - val_acc: 0.7134\n",
            "\n",
            "Epoch 00303: val_acc did not improve from 0.83810\n",
            "Epoch 304/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4141 - acc: 0.8807 - val_loss: 0.9564 - val_acc: 0.7354\n",
            "\n",
            "Epoch 00304: val_acc did not improve from 0.83810\n",
            "Epoch 305/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4436 - acc: 0.8680 - val_loss: 1.1218 - val_acc: 0.6935\n",
            "\n",
            "Epoch 00305: val_acc did not improve from 0.83810\n",
            "Epoch 306/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4225 - acc: 0.8792 - val_loss: 1.1703 - val_acc: 0.7035\n",
            "\n",
            "Epoch 00306: val_acc did not improve from 0.83810\n",
            "Epoch 307/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4138 - acc: 0.8753 - val_loss: 0.9968 - val_acc: 0.7480\n",
            "\n",
            "Epoch 00307: val_acc did not improve from 0.83810\n",
            "Epoch 308/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4305 - acc: 0.8729 - val_loss: 1.8509 - val_acc: 0.5656\n",
            "\n",
            "Epoch 00308: val_acc did not improve from 0.83810\n",
            "Epoch 309/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4306 - acc: 0.8765 - val_loss: 0.9595 - val_acc: 0.7305\n",
            "\n",
            "Epoch 00309: val_acc did not improve from 0.83810\n",
            "Epoch 310/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4320 - acc: 0.8758 - val_loss: 1.0801 - val_acc: 0.7121\n",
            "\n",
            "Epoch 00310: val_acc did not improve from 0.83810\n",
            "Epoch 311/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4326 - acc: 0.8693 - val_loss: 0.7885 - val_acc: 0.7769\n",
            "\n",
            "Epoch 00311: val_acc did not improve from 0.83810\n",
            "Epoch 312/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4030 - acc: 0.8809 - val_loss: 1.5247 - val_acc: 0.6398\n",
            "\n",
            "Epoch 00312: val_acc did not improve from 0.83810\n",
            "Epoch 313/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4224 - acc: 0.8753 - val_loss: 1.2218 - val_acc: 0.6861\n",
            "\n",
            "Epoch 00313: val_acc did not improve from 0.83810\n",
            "Epoch 314/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4121 - acc: 0.8792 - val_loss: 0.9345 - val_acc: 0.7300\n",
            "\n",
            "Epoch 00314: val_acc did not improve from 0.83810\n",
            "Epoch 315/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4235 - acc: 0.8727 - val_loss: 0.9150 - val_acc: 0.7596\n",
            "\n",
            "Epoch 00315: val_acc did not improve from 0.83810\n",
            "Epoch 316/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4220 - acc: 0.8718 - val_loss: 0.9020 - val_acc: 0.7590\n",
            "\n",
            "Epoch 00316: val_acc did not improve from 0.83810\n",
            "Epoch 317/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4104 - acc: 0.8819 - val_loss: 0.9994 - val_acc: 0.7449\n",
            "\n",
            "Epoch 00317: val_acc did not improve from 0.83810\n",
            "Epoch 318/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4052 - acc: 0.8859 - val_loss: 0.9581 - val_acc: 0.7369\n",
            "\n",
            "Epoch 00318: val_acc did not improve from 0.83810\n",
            "Epoch 319/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4178 - acc: 0.8767 - val_loss: 0.9488 - val_acc: 0.7526\n",
            "\n",
            "Epoch 00319: val_acc did not improve from 0.83810\n",
            "Epoch 320/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4289 - acc: 0.8744 - val_loss: 0.6261 - val_acc: 0.8165\n",
            "\n",
            "Epoch 00320: val_acc did not improve from 0.83810\n",
            "Epoch 321/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.3996 - acc: 0.8848 - val_loss: 1.3834 - val_acc: 0.6638\n",
            "\n",
            "Epoch 00321: val_acc did not improve from 0.83810\n",
            "Epoch 322/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4003 - acc: 0.8828 - val_loss: 1.0550 - val_acc: 0.7256\n",
            "\n",
            "Epoch 00322: val_acc did not improve from 0.83810\n",
            "Epoch 323/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4090 - acc: 0.8790 - val_loss: 0.8662 - val_acc: 0.7608\n",
            "\n",
            "Epoch 00323: val_acc did not improve from 0.83810\n",
            "Epoch 324/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4169 - acc: 0.8766 - val_loss: 0.7011 - val_acc: 0.7993\n",
            "\n",
            "Epoch 00324: val_acc did not improve from 0.83810\n",
            "Epoch 325/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4221 - acc: 0.8799 - val_loss: 1.3934 - val_acc: 0.6624\n",
            "\n",
            "Epoch 00325: val_acc did not improve from 0.83810\n",
            "Epoch 326/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4120 - acc: 0.8805 - val_loss: 0.9386 - val_acc: 0.7285\n",
            "\n",
            "Epoch 00326: val_acc did not improve from 0.83810\n",
            "Epoch 327/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4312 - acc: 0.8717 - val_loss: 1.2782 - val_acc: 0.6782\n",
            "\n",
            "Epoch 00327: val_acc did not improve from 0.83810\n",
            "Epoch 328/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4144 - acc: 0.8779 - val_loss: 0.6956 - val_acc: 0.7947\n",
            "\n",
            "Epoch 00328: val_acc did not improve from 0.83810\n",
            "Epoch 329/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4319 - acc: 0.8684 - val_loss: 0.8619 - val_acc: 0.7605\n",
            "\n",
            "Epoch 00329: val_acc did not improve from 0.83810\n",
            "Epoch 330/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4233 - acc: 0.8737 - val_loss: 0.6304 - val_acc: 0.8129\n",
            "\n",
            "Epoch 00330: val_acc did not improve from 0.83810\n",
            "Epoch 331/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4215 - acc: 0.8781 - val_loss: 0.9298 - val_acc: 0.7438\n",
            "\n",
            "Epoch 00331: val_acc did not improve from 0.83810\n",
            "Epoch 332/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4059 - acc: 0.8812 - val_loss: 0.8662 - val_acc: 0.7630\n",
            "\n",
            "Epoch 00332: val_acc did not improve from 0.83810\n",
            "Epoch 333/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4323 - acc: 0.8722 - val_loss: 1.1718 - val_acc: 0.6719\n",
            "\n",
            "Epoch 00333: val_acc did not improve from 0.83810\n",
            "Epoch 334/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4216 - acc: 0.8759 - val_loss: 1.1661 - val_acc: 0.6926\n",
            "\n",
            "Epoch 00334: val_acc did not improve from 0.83810\n",
            "Epoch 335/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4059 - acc: 0.8798 - val_loss: 0.9073 - val_acc: 0.7571\n",
            "\n",
            "Epoch 00335: val_acc did not improve from 0.83810\n",
            "Epoch 336/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4169 - acc: 0.8757 - val_loss: 0.6995 - val_acc: 0.7937\n",
            "\n",
            "Epoch 00336: val_acc did not improve from 0.83810\n",
            "Epoch 337/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4299 - acc: 0.8708 - val_loss: 1.0805 - val_acc: 0.7017\n",
            "\n",
            "Epoch 00337: val_acc did not improve from 0.83810\n",
            "Epoch 338/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4125 - acc: 0.8817 - val_loss: 1.1793 - val_acc: 0.6973\n",
            "\n",
            "Epoch 00338: val_acc did not improve from 0.83810\n",
            "Epoch 339/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4213 - acc: 0.8744 - val_loss: 1.7351 - val_acc: 0.6008\n",
            "\n",
            "Epoch 00339: val_acc did not improve from 0.83810\n",
            "Epoch 340/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.4170 - acc: 0.8744 - val_loss: 0.7329 - val_acc: 0.7871\n",
            "\n",
            "Epoch 00340: val_acc did not improve from 0.83810\n",
            "Epoch 341/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.3950 - acc: 0.8869 - val_loss: 0.6292 - val_acc: 0.8036\n",
            "\n",
            "Epoch 00341: val_acc did not improve from 0.83810\n",
            "Epoch 342/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.4283 - acc: 0.8707 - val_loss: 1.2383 - val_acc: 0.6803\n",
            "\n",
            "Epoch 00342: val_acc did not improve from 0.83810\n",
            "Epoch 343/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4213 - acc: 0.8751 - val_loss: 0.6174 - val_acc: 0.8174\n",
            "\n",
            "Epoch 00343: val_acc did not improve from 0.83810\n",
            "Epoch 344/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4114 - acc: 0.8745 - val_loss: 0.9374 - val_acc: 0.7460\n",
            "\n",
            "Epoch 00344: val_acc did not improve from 0.83810\n",
            "Epoch 345/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4075 - acc: 0.8780 - val_loss: 1.3458 - val_acc: 0.6134\n",
            "\n",
            "Epoch 00345: val_acc did not improve from 0.83810\n",
            "Epoch 346/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4192 - acc: 0.8798 - val_loss: 0.9950 - val_acc: 0.7348\n",
            "\n",
            "Epoch 00346: val_acc did not improve from 0.83810\n",
            "Epoch 347/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4458 - acc: 0.8696 - val_loss: 0.9253 - val_acc: 0.7526\n",
            "\n",
            "Epoch 00347: val_acc did not improve from 0.83810\n",
            "Epoch 348/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4134 - acc: 0.8798 - val_loss: 1.1254 - val_acc: 0.7214\n",
            "\n",
            "Epoch 00348: val_acc did not improve from 0.83810\n",
            "Epoch 349/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4196 - acc: 0.8799 - val_loss: 0.7689 - val_acc: 0.7807\n",
            "\n",
            "Epoch 00349: val_acc did not improve from 0.83810\n",
            "Epoch 350/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4318 - acc: 0.8731 - val_loss: 0.8210 - val_acc: 0.7562\n",
            "\n",
            "Epoch 00350: val_acc did not improve from 0.83810\n",
            "Epoch 351/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4254 - acc: 0.8721 - val_loss: 1.3187 - val_acc: 0.6933\n",
            "\n",
            "Epoch 00351: val_acc did not improve from 0.83810\n",
            "Epoch 352/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4063 - acc: 0.8806 - val_loss: 1.0113 - val_acc: 0.7490\n",
            "\n",
            "Epoch 00352: val_acc did not improve from 0.83810\n",
            "Epoch 353/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.3966 - acc: 0.8824 - val_loss: 1.1928 - val_acc: 0.7075\n",
            "\n",
            "Epoch 00353: val_acc did not improve from 0.83810\n",
            "Epoch 354/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4183 - acc: 0.8708 - val_loss: 1.1805 - val_acc: 0.7130\n",
            "\n",
            "Epoch 00354: val_acc did not improve from 0.83810\n",
            "Epoch 355/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4355 - acc: 0.8738 - val_loss: 1.2146 - val_acc: 0.6832\n",
            "\n",
            "Epoch 00355: val_acc did not improve from 0.83810\n",
            "Epoch 356/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.4049 - acc: 0.8804 - val_loss: 1.2129 - val_acc: 0.6827\n",
            "\n",
            "Epoch 00356: val_acc did not improve from 0.83810\n",
            "Epoch 357/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4423 - acc: 0.8656 - val_loss: 1.3490 - val_acc: 0.6611\n",
            "\n",
            "Epoch 00357: val_acc did not improve from 0.83810\n",
            "Epoch 358/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4116 - acc: 0.8759 - val_loss: 0.7311 - val_acc: 0.7861\n",
            "\n",
            "Epoch 00358: val_acc did not improve from 0.83810\n",
            "Epoch 359/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4078 - acc: 0.8844 - val_loss: 0.9168 - val_acc: 0.7329\n",
            "\n",
            "Epoch 00359: val_acc did not improve from 0.83810\n",
            "Epoch 360/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4308 - acc: 0.8728 - val_loss: 0.6795 - val_acc: 0.7951\n",
            "\n",
            "Epoch 00360: val_acc did not improve from 0.83810\n",
            "Epoch 361/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4312 - acc: 0.8725 - val_loss: 0.8996 - val_acc: 0.7346\n",
            "\n",
            "Epoch 00361: val_acc did not improve from 0.83810\n",
            "Epoch 362/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4066 - acc: 0.8836 - val_loss: 1.0304 - val_acc: 0.7361\n",
            "\n",
            "Epoch 00362: val_acc did not improve from 0.83810\n",
            "Epoch 363/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4335 - acc: 0.8719 - val_loss: 0.9608 - val_acc: 0.7425\n",
            "\n",
            "Epoch 00363: val_acc did not improve from 0.83810\n",
            "Epoch 364/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4284 - acc: 0.8766 - val_loss: 2.2205 - val_acc: 0.5533\n",
            "\n",
            "Epoch 00364: val_acc did not improve from 0.83810\n",
            "Epoch 365/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4075 - acc: 0.8800 - val_loss: 1.0737 - val_acc: 0.7064\n",
            "\n",
            "Epoch 00365: val_acc did not improve from 0.83810\n",
            "Epoch 366/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4168 - acc: 0.8759 - val_loss: 1.4901 - val_acc: 0.6500\n",
            "\n",
            "Epoch 00366: val_acc did not improve from 0.83810\n",
            "Epoch 367/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4197 - acc: 0.8787 - val_loss: 1.1664 - val_acc: 0.6927\n",
            "\n",
            "Epoch 00367: val_acc did not improve from 0.83810\n",
            "Epoch 368/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4134 - acc: 0.8763 - val_loss: 0.9160 - val_acc: 0.7565\n",
            "\n",
            "Epoch 00368: val_acc did not improve from 0.83810\n",
            "Epoch 369/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4122 - acc: 0.8753 - val_loss: 0.9007 - val_acc: 0.7397\n",
            "\n",
            "Epoch 00369: val_acc did not improve from 0.83810\n",
            "Epoch 370/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4124 - acc: 0.8784 - val_loss: 0.7299 - val_acc: 0.7826\n",
            "\n",
            "Epoch 00370: val_acc did not improve from 0.83810\n",
            "Epoch 371/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4200 - acc: 0.8714 - val_loss: 1.2848 - val_acc: 0.6536\n",
            "\n",
            "Epoch 00371: val_acc did not improve from 0.83810\n",
            "Epoch 372/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4180 - acc: 0.8834 - val_loss: 0.7694 - val_acc: 0.7872\n",
            "\n",
            "Epoch 00372: val_acc did not improve from 0.83810\n",
            "Epoch 373/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.3991 - acc: 0.8894 - val_loss: 0.7069 - val_acc: 0.8015\n",
            "\n",
            "Epoch 00373: val_acc did not improve from 0.83810\n",
            "Epoch 374/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4074 - acc: 0.8782 - val_loss: 0.8872 - val_acc: 0.7417\n",
            "\n",
            "Epoch 00374: val_acc did not improve from 0.83810\n",
            "Epoch 375/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4007 - acc: 0.8835 - val_loss: 1.2343 - val_acc: 0.6946\n",
            "\n",
            "Epoch 00375: val_acc did not improve from 0.83810\n",
            "Epoch 376/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4090 - acc: 0.8761 - val_loss: 1.0347 - val_acc: 0.7219\n",
            "\n",
            "Epoch 00376: val_acc did not improve from 0.83810\n",
            "Epoch 377/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4087 - acc: 0.8858 - val_loss: 1.0025 - val_acc: 0.7178\n",
            "\n",
            "Epoch 00377: val_acc did not improve from 0.83810\n",
            "Epoch 378/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4153 - acc: 0.8794 - val_loss: 1.3187 - val_acc: 0.6627\n",
            "\n",
            "Epoch 00378: val_acc did not improve from 0.83810\n",
            "Epoch 379/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.3971 - acc: 0.8813 - val_loss: 0.7538 - val_acc: 0.7730\n",
            "\n",
            "Epoch 00379: val_acc did not improve from 0.83810\n",
            "Epoch 380/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4160 - acc: 0.8791 - val_loss: 0.7218 - val_acc: 0.7806\n",
            "\n",
            "Epoch 00380: val_acc did not improve from 0.83810\n",
            "Epoch 381/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4043 - acc: 0.8801 - val_loss: 0.6934 - val_acc: 0.7938\n",
            "\n",
            "Epoch 00381: val_acc did not improve from 0.83810\n",
            "Epoch 382/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4002 - acc: 0.8857 - val_loss: 0.9581 - val_acc: 0.7371\n",
            "\n",
            "Epoch 00382: val_acc did not improve from 0.83810\n",
            "Epoch 383/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4127 - acc: 0.8842 - val_loss: 0.7588 - val_acc: 0.7766\n",
            "\n",
            "Epoch 00383: val_acc did not improve from 0.83810\n",
            "Epoch 384/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.3965 - acc: 0.8849 - val_loss: 0.8527 - val_acc: 0.7616\n",
            "\n",
            "Epoch 00384: val_acc did not improve from 0.83810\n",
            "Epoch 385/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4147 - acc: 0.8819 - val_loss: 0.7934 - val_acc: 0.7839\n",
            "\n",
            "Epoch 00385: val_acc did not improve from 0.83810\n",
            "Epoch 386/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.3993 - acc: 0.8788 - val_loss: 0.7564 - val_acc: 0.7865\n",
            "\n",
            "Epoch 00386: val_acc did not improve from 0.83810\n",
            "Epoch 387/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4101 - acc: 0.8833 - val_loss: 0.7609 - val_acc: 0.7793\n",
            "\n",
            "Epoch 00387: val_acc did not improve from 0.83810\n",
            "Epoch 388/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.4062 - acc: 0.8795 - val_loss: 0.8232 - val_acc: 0.7755\n",
            "\n",
            "Epoch 00388: val_acc did not improve from 0.83810\n",
            "Epoch 389/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.4047 - acc: 0.8822 - val_loss: 1.2019 - val_acc: 0.6898\n",
            "\n",
            "Epoch 00389: val_acc did not improve from 0.83810\n",
            "Epoch 390/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.4116 - acc: 0.8806 - val_loss: 1.0562 - val_acc: 0.7227\n",
            "\n",
            "Epoch 00390: val_acc did not improve from 0.83810\n",
            "Epoch 391/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.4016 - acc: 0.8861 - val_loss: 1.2346 - val_acc: 0.7087\n",
            "\n",
            "Epoch 00391: val_acc did not improve from 0.83810\n",
            "Epoch 392/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4348 - acc: 0.8710 - val_loss: 1.3601 - val_acc: 0.6753\n",
            "\n",
            "Epoch 00392: val_acc did not improve from 0.83810\n",
            "Epoch 393/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4005 - acc: 0.8858 - val_loss: 0.7231 - val_acc: 0.7894\n",
            "\n",
            "Epoch 00393: val_acc did not improve from 0.83810\n",
            "Epoch 394/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.3991 - acc: 0.8883 - val_loss: 0.7657 - val_acc: 0.7874\n",
            "\n",
            "Epoch 00394: val_acc did not improve from 0.83810\n",
            "Epoch 395/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4093 - acc: 0.8828 - val_loss: 0.7082 - val_acc: 0.7875\n",
            "\n",
            "Epoch 00395: val_acc did not improve from 0.83810\n",
            "Epoch 396/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.3968 - acc: 0.8870 - val_loss: 0.7883 - val_acc: 0.7819\n",
            "\n",
            "Epoch 00396: val_acc did not improve from 0.83810\n",
            "Epoch 397/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4010 - acc: 0.8799 - val_loss: 1.1887 - val_acc: 0.6567\n",
            "\n",
            "Epoch 00397: val_acc did not improve from 0.83810\n",
            "Epoch 398/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4102 - acc: 0.8809 - val_loss: 0.8720 - val_acc: 0.7463\n",
            "\n",
            "Epoch 00398: val_acc did not improve from 0.83810\n",
            "Epoch 399/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.3968 - acc: 0.8810 - val_loss: 0.7150 - val_acc: 0.7937\n",
            "\n",
            "Epoch 00399: val_acc did not improve from 0.83810\n",
            "Epoch 400/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4034 - acc: 0.8828 - val_loss: 1.1160 - val_acc: 0.6947\n",
            "\n",
            "Epoch 00400: val_acc did not improve from 0.83810\n",
            "Epoch 401/650\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4083 - acc: 0.8788 - val_loss: 1.0408 - val_acc: 0.7217\n",
            "\n",
            "Epoch 00401: val_acc did not improve from 0.83810\n",
            "Epoch 402/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.3802 - acc: 0.8947 - val_loss: 0.3948 - val_acc: 0.8869\n",
            "\n",
            "Epoch 00402: val_acc improved from 0.83810 to 0.88690, saving model to /content/saved_models/cifar10_ResNet32v1_model.402.h5\n",
            "Epoch 403/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.3020 - acc: 0.9228 - val_loss: 0.3829 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00403: val_acc improved from 0.88690 to 0.89120, saving model to /content/saved_models/cifar10_ResNet32v1_model.403.h5\n",
            "Epoch 404/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.2918 - acc: 0.9220 - val_loss: 0.3794 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00404: val_acc improved from 0.89120 to 0.89250, saving model to /content/saved_models/cifar10_ResNet32v1_model.404.h5\n",
            "Epoch 405/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.2803 - acc: 0.9248 - val_loss: 0.3649 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00405: val_acc improved from 0.89250 to 0.89940, saving model to /content/saved_models/cifar10_ResNet32v1_model.405.h5\n",
            "Epoch 406/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2722 - acc: 0.9291 - val_loss: 0.3588 - val_acc: 0.8979\n",
            "\n",
            "Epoch 00406: val_acc did not improve from 0.89940\n",
            "Epoch 407/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.2747 - acc: 0.9280 - val_loss: 0.3696 - val_acc: 0.8957\n",
            "\n",
            "Epoch 00407: val_acc did not improve from 0.89940\n",
            "Epoch 408/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.2676 - acc: 0.9313 - val_loss: 0.3487 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00408: val_acc improved from 0.89940 to 0.90210, saving model to /content/saved_models/cifar10_ResNet32v1_model.408.h5\n",
            "Epoch 409/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.2582 - acc: 0.9319 - val_loss: 0.3754 - val_acc: 0.8936\n",
            "\n",
            "Epoch 00409: val_acc did not improve from 0.90210\n",
            "Epoch 410/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.2541 - acc: 0.9325 - val_loss: 0.3567 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00410: val_acc did not improve from 0.90210\n",
            "Epoch 411/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.2548 - acc: 0.9321 - val_loss: 0.3643 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00411: val_acc did not improve from 0.90210\n",
            "Epoch 412/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2422 - acc: 0.9378 - val_loss: 0.3402 - val_acc: 0.9048\n",
            "\n",
            "Epoch 00412: val_acc improved from 0.90210 to 0.90480, saving model to /content/saved_models/cifar10_ResNet32v1_model.412.h5\n",
            "Epoch 413/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2353 - acc: 0.9395 - val_loss: 0.3559 - val_acc: 0.9006\n",
            "\n",
            "Epoch 00413: val_acc did not improve from 0.90480\n",
            "Epoch 414/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.2203 - acc: 0.9448 - val_loss: 0.3453 - val_acc: 0.9040\n",
            "\n",
            "Epoch 00414: val_acc did not improve from 0.90480\n",
            "Epoch 415/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.2379 - acc: 0.9370 - val_loss: 0.3660 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00415: val_acc did not improve from 0.90480\n",
            "Epoch 416/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2401 - acc: 0.9355 - val_loss: 0.3454 - val_acc: 0.9035\n",
            "\n",
            "Epoch 00416: val_acc did not improve from 0.90480\n",
            "Epoch 417/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2367 - acc: 0.9376 - val_loss: 0.3512 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00417: val_acc did not improve from 0.90480\n",
            "Epoch 418/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2339 - acc: 0.9425 - val_loss: 0.3420 - val_acc: 0.9049\n",
            "\n",
            "Epoch 00418: val_acc improved from 0.90480 to 0.90490, saving model to /content/saved_models/cifar10_ResNet32v1_model.418.h5\n",
            "Epoch 419/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.2316 - acc: 0.9405 - val_loss: 0.3553 - val_acc: 0.9023\n",
            "\n",
            "Epoch 00419: val_acc did not improve from 0.90490\n",
            "Epoch 420/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2217 - acc: 0.9429 - val_loss: 0.3591 - val_acc: 0.9002\n",
            "\n",
            "Epoch 00420: val_acc did not improve from 0.90490\n",
            "Epoch 421/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.2183 - acc: 0.9460 - val_loss: 0.3459 - val_acc: 0.9041\n",
            "\n",
            "Epoch 00421: val_acc did not improve from 0.90490\n",
            "Epoch 422/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2232 - acc: 0.9445 - val_loss: 0.3401 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00422: val_acc improved from 0.90490 to 0.90670, saving model to /content/saved_models/cifar10_ResNet32v1_model.422.h5\n",
            "Epoch 423/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2111 - acc: 0.9486 - val_loss: 0.3440 - val_acc: 0.9040\n",
            "\n",
            "Epoch 00423: val_acc did not improve from 0.90670\n",
            "Epoch 424/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2120 - acc: 0.9500 - val_loss: 0.3364 - val_acc: 0.9066\n",
            "\n",
            "Epoch 00424: val_acc did not improve from 0.90670\n",
            "Epoch 425/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2131 - acc: 0.9512 - val_loss: 0.3367 - val_acc: 0.9075\n",
            "\n",
            "Epoch 00425: val_acc improved from 0.90670 to 0.90750, saving model to /content/saved_models/cifar10_ResNet32v1_model.425.h5\n",
            "Epoch 426/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.2092 - acc: 0.9487 - val_loss: 0.3549 - val_acc: 0.9011\n",
            "\n",
            "Epoch 00426: val_acc did not improve from 0.90750\n",
            "Epoch 427/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2154 - acc: 0.9470 - val_loss: 0.3367 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00427: val_acc did not improve from 0.90750\n",
            "Epoch 428/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2018 - acc: 0.9517 - val_loss: 0.3477 - val_acc: 0.9057\n",
            "\n",
            "Epoch 00428: val_acc did not improve from 0.90750\n",
            "Epoch 429/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2131 - acc: 0.9472 - val_loss: 0.3570 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00429: val_acc did not improve from 0.90750\n",
            "Epoch 430/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2000 - acc: 0.9502 - val_loss: 0.3316 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00430: val_acc improved from 0.90750 to 0.90860, saving model to /content/saved_models/cifar10_ResNet32v1_model.430.h5\n",
            "Epoch 431/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1985 - acc: 0.9512 - val_loss: 0.3545 - val_acc: 0.9007\n",
            "\n",
            "Epoch 00431: val_acc did not improve from 0.90860\n",
            "Epoch 432/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1957 - acc: 0.9551 - val_loss: 0.3513 - val_acc: 0.9029\n",
            "\n",
            "Epoch 00432: val_acc did not improve from 0.90860\n",
            "Epoch 433/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.2044 - acc: 0.9433 - val_loss: 0.3403 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00433: val_acc did not improve from 0.90860\n",
            "Epoch 434/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1949 - acc: 0.9544 - val_loss: 0.3320 - val_acc: 0.9066\n",
            "\n",
            "Epoch 00434: val_acc did not improve from 0.90860\n",
            "Epoch 435/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1952 - acc: 0.9479 - val_loss: 0.3427 - val_acc: 0.9058\n",
            "\n",
            "Epoch 00435: val_acc did not improve from 0.90860\n",
            "Epoch 436/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1855 - acc: 0.9571 - val_loss: 0.3373 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00436: val_acc did not improve from 0.90860\n",
            "Epoch 437/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1881 - acc: 0.9556 - val_loss: 0.3434 - val_acc: 0.9048\n",
            "\n",
            "Epoch 00437: val_acc did not improve from 0.90860\n",
            "Epoch 438/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1947 - acc: 0.9503 - val_loss: 0.3403 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00438: val_acc improved from 0.90860 to 0.90980, saving model to /content/saved_models/cifar10_ResNet32v1_model.438.h5\n",
            "Epoch 439/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1888 - acc: 0.9543 - val_loss: 0.3445 - val_acc: 0.9054\n",
            "\n",
            "Epoch 00439: val_acc did not improve from 0.90980\n",
            "Epoch 440/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1955 - acc: 0.9506 - val_loss: 0.3403 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00440: val_acc improved from 0.90980 to 0.91010, saving model to /content/saved_models/cifar10_ResNet32v1_model.440.h5\n",
            "Epoch 441/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1824 - acc: 0.9578 - val_loss: 0.3478 - val_acc: 0.9037\n",
            "\n",
            "Epoch 00441: val_acc did not improve from 0.91010\n",
            "Epoch 442/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1876 - acc: 0.9581 - val_loss: 0.3654 - val_acc: 0.9018\n",
            "\n",
            "Epoch 00442: val_acc did not improve from 0.91010\n",
            "Epoch 443/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1806 - acc: 0.9568 - val_loss: 0.3573 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00443: val_acc did not improve from 0.91010\n",
            "Epoch 444/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1831 - acc: 0.9535 - val_loss: 0.3237 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00444: val_acc improved from 0.91010 to 0.91180, saving model to /content/saved_models/cifar10_ResNet32v1_model.444.h5\n",
            "Epoch 445/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1700 - acc: 0.9599 - val_loss: 0.3366 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00445: val_acc did not improve from 0.91180\n",
            "Epoch 446/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1788 - acc: 0.9572 - val_loss: 0.3269 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00446: val_acc improved from 0.91180 to 0.91190, saving model to /content/saved_models/cifar10_ResNet32v1_model.446.h5\n",
            "Epoch 447/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1835 - acc: 0.9574 - val_loss: 0.3437 - val_acc: 0.9072\n",
            "\n",
            "Epoch 00447: val_acc did not improve from 0.91190\n",
            "Epoch 448/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1722 - acc: 0.9589 - val_loss: 0.3260 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00448: val_acc did not improve from 0.91190\n",
            "Epoch 449/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1710 - acc: 0.9613 - val_loss: 0.3378 - val_acc: 0.9068\n",
            "\n",
            "Epoch 00449: val_acc did not improve from 0.91190\n",
            "Epoch 450/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1797 - acc: 0.9554 - val_loss: 0.3432 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00450: val_acc did not improve from 0.91190\n",
            "Epoch 451/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1809 - acc: 0.9574 - val_loss: 0.3336 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00451: val_acc did not improve from 0.91190\n",
            "Epoch 452/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1739 - acc: 0.9594 - val_loss: 0.3593 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00452: val_acc did not improve from 0.91190\n",
            "Epoch 453/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1693 - acc: 0.9611 - val_loss: 0.3367 - val_acc: 0.9090\n",
            "\n",
            "Epoch 00453: val_acc did not improve from 0.91190\n",
            "Epoch 454/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1732 - acc: 0.9550 - val_loss: 0.3410 - val_acc: 0.9057\n",
            "\n",
            "Epoch 00454: val_acc did not improve from 0.91190\n",
            "Epoch 455/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1590 - acc: 0.9640 - val_loss: 0.3506 - val_acc: 0.9052\n",
            "\n",
            "Epoch 00455: val_acc did not improve from 0.91190\n",
            "Epoch 456/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1702 - acc: 0.9591 - val_loss: 0.3562 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00456: val_acc did not improve from 0.91190\n",
            "Epoch 457/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1646 - acc: 0.9607 - val_loss: 0.3587 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00457: val_acc did not improve from 0.91190\n",
            "Epoch 458/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1712 - acc: 0.9598 - val_loss: 0.3392 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00458: val_acc did not improve from 0.91190\n",
            "Epoch 459/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1640 - acc: 0.9613 - val_loss: 0.3428 - val_acc: 0.9066\n",
            "\n",
            "Epoch 00459: val_acc did not improve from 0.91190\n",
            "Epoch 460/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1688 - acc: 0.9613 - val_loss: 0.3413 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00460: val_acc did not improve from 0.91190\n",
            "Epoch 461/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1638 - acc: 0.9642 - val_loss: 0.3242 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00461: val_acc improved from 0.91190 to 0.91450, saving model to /content/saved_models/cifar10_ResNet32v1_model.461.h5\n",
            "Epoch 462/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1627 - acc: 0.9629 - val_loss: 0.3372 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00462: val_acc did not improve from 0.91450\n",
            "Epoch 463/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1575 - acc: 0.9636 - val_loss: 0.3384 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00463: val_acc did not improve from 0.91450\n",
            "Epoch 464/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1587 - acc: 0.9634 - val_loss: 0.3322 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00464: val_acc did not improve from 0.91450\n",
            "Epoch 465/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1583 - acc: 0.9618 - val_loss: 0.3481 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00465: val_acc did not improve from 0.91450\n",
            "Epoch 466/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1574 - acc: 0.9630 - val_loss: 0.3594 - val_acc: 0.9057\n",
            "\n",
            "Epoch 00466: val_acc did not improve from 0.91450\n",
            "Epoch 467/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1535 - acc: 0.9671 - val_loss: 0.3382 - val_acc: 0.9112\n",
            "\n",
            "Epoch 00467: val_acc did not improve from 0.91450\n",
            "Epoch 468/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1556 - acc: 0.9629 - val_loss: 0.3468 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00468: val_acc did not improve from 0.91450\n",
            "Epoch 469/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1511 - acc: 0.9662 - val_loss: 0.3359 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00469: val_acc did not improve from 0.91450\n",
            "Epoch 470/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1595 - acc: 0.9644 - val_loss: 0.3589 - val_acc: 0.9044\n",
            "\n",
            "Epoch 00470: val_acc did not improve from 0.91450\n",
            "Epoch 471/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1575 - acc: 0.9641 - val_loss: 0.3454 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00471: val_acc did not improve from 0.91450\n",
            "Epoch 472/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1547 - acc: 0.9637 - val_loss: 0.3339 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00472: val_acc did not improve from 0.91450\n",
            "Epoch 473/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1415 - acc: 0.9695 - val_loss: 0.3886 - val_acc: 0.9005\n",
            "\n",
            "Epoch 00473: val_acc did not improve from 0.91450\n",
            "Epoch 474/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1477 - acc: 0.9643 - val_loss: 0.3606 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00474: val_acc did not improve from 0.91450\n",
            "Epoch 475/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1462 - acc: 0.9692 - val_loss: 0.3503 - val_acc: 0.9056\n",
            "\n",
            "Epoch 00475: val_acc did not improve from 0.91450\n",
            "Epoch 476/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1429 - acc: 0.9686 - val_loss: 0.3483 - val_acc: 0.9085\n",
            "\n",
            "Epoch 00476: val_acc did not improve from 0.91450\n",
            "Epoch 477/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1518 - acc: 0.9678 - val_loss: 0.3280 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00477: val_acc did not improve from 0.91450\n",
            "Epoch 478/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1442 - acc: 0.9685 - val_loss: 0.3721 - val_acc: 0.9037\n",
            "\n",
            "Epoch 00478: val_acc did not improve from 0.91450\n",
            "Epoch 479/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1497 - acc: 0.9680 - val_loss: 0.3440 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00479: val_acc did not improve from 0.91450\n",
            "Epoch 480/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1567 - acc: 0.9616 - val_loss: 0.3474 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00480: val_acc did not improve from 0.91450\n",
            "Epoch 481/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1460 - acc: 0.9688 - val_loss: 0.3293 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00481: val_acc improved from 0.91450 to 0.91540, saving model to /content/saved_models/cifar10_ResNet32v1_model.481.h5\n",
            "Epoch 482/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1510 - acc: 0.9647 - val_loss: 0.3723 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00482: val_acc did not improve from 0.91540\n",
            "Epoch 483/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1496 - acc: 0.9668 - val_loss: 0.3610 - val_acc: 0.9034\n",
            "\n",
            "Epoch 00483: val_acc did not improve from 0.91540\n",
            "Epoch 484/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1448 - acc: 0.9722 - val_loss: 0.3591 - val_acc: 0.9039\n",
            "\n",
            "Epoch 00484: val_acc did not improve from 0.91540\n",
            "Epoch 485/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1390 - acc: 0.9713 - val_loss: 0.3281 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00485: val_acc did not improve from 0.91540\n",
            "Epoch 486/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1357 - acc: 0.9725 - val_loss: 0.3539 - val_acc: 0.9079\n",
            "\n",
            "Epoch 00486: val_acc did not improve from 0.91540\n",
            "Epoch 487/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1379 - acc: 0.9736 - val_loss: 0.3511 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00487: val_acc did not improve from 0.91540\n",
            "Epoch 488/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1335 - acc: 0.9705 - val_loss: 0.3385 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00488: val_acc did not improve from 0.91540\n",
            "Epoch 489/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1437 - acc: 0.9658 - val_loss: 0.3395 - val_acc: 0.9106\n",
            "\n",
            "Epoch 00489: val_acc did not improve from 0.91540\n",
            "Epoch 490/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1392 - acc: 0.9714 - val_loss: 0.3452 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00490: val_acc did not improve from 0.91540\n",
            "Epoch 491/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1556 - acc: 0.9621 - val_loss: 0.3231 - val_acc: 0.9128\n",
            "\n",
            "Epoch 00491: val_acc did not improve from 0.91540\n",
            "Epoch 492/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1412 - acc: 0.9697 - val_loss: 0.3360 - val_acc: 0.9089\n",
            "\n",
            "Epoch 00492: val_acc did not improve from 0.91540\n",
            "Epoch 493/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1395 - acc: 0.9700 - val_loss: 0.3311 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00493: val_acc did not improve from 0.91540\n",
            "Epoch 494/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1366 - acc: 0.9711 - val_loss: 0.3226 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00494: val_acc improved from 0.91540 to 0.91620, saving model to /content/saved_models/cifar10_ResNet32v1_model.494.h5\n",
            "Epoch 495/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1317 - acc: 0.9707 - val_loss: 0.3358 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00495: val_acc did not improve from 0.91620\n",
            "Epoch 496/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1299 - acc: 0.9741 - val_loss: 0.3476 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00496: val_acc did not improve from 0.91620\n",
            "Epoch 497/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.1460 - acc: 0.9677 - val_loss: 0.3338 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00497: val_acc did not improve from 0.91620\n",
            "Epoch 498/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1412 - acc: 0.9688 - val_loss: 0.3343 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00498: val_acc did not improve from 0.91620\n",
            "Epoch 499/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1340 - acc: 0.9713 - val_loss: 0.3735 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00499: val_acc did not improve from 0.91620\n",
            "Epoch 500/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1357 - acc: 0.9689 - val_loss: 0.3615 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00500: val_acc did not improve from 0.91620\n",
            "Epoch 501/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1339 - acc: 0.9721 - val_loss: 0.3616 - val_acc: 0.9081\n",
            "\n",
            "Epoch 00501: val_acc did not improve from 0.91620\n",
            "Epoch 502/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1401 - acc: 0.9687 - val_loss: 0.3461 - val_acc: 0.9091\n",
            "\n",
            "Epoch 00502: val_acc did not improve from 0.91620\n",
            "Epoch 503/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1281 - acc: 0.9701 - val_loss: 0.3455 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00503: val_acc did not improve from 0.91620\n",
            "Epoch 504/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1386 - acc: 0.9696 - val_loss: 0.3533 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00504: val_acc did not improve from 0.91620\n",
            "Epoch 505/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1284 - acc: 0.9745 - val_loss: 0.3530 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00505: val_acc did not improve from 0.91620\n",
            "Epoch 506/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1349 - acc: 0.9699 - val_loss: 0.3344 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00506: val_acc did not improve from 0.91620\n",
            "Epoch 507/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1283 - acc: 0.9757 - val_loss: 0.3338 - val_acc: 0.9146\n",
            "\n",
            "Epoch 00507: val_acc did not improve from 0.91620\n",
            "Epoch 508/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1238 - acc: 0.9748 - val_loss: 0.3878 - val_acc: 0.9020\n",
            "\n",
            "Epoch 00508: val_acc did not improve from 0.91620\n",
            "Epoch 509/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1331 - acc: 0.9710 - val_loss: 0.3820 - val_acc: 0.9010\n",
            "\n",
            "Epoch 00509: val_acc did not improve from 0.91620\n",
            "Epoch 510/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1355 - acc: 0.9710 - val_loss: 0.3255 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00510: val_acc improved from 0.91620 to 0.91680, saving model to /content/saved_models/cifar10_ResNet32v1_model.510.h5\n",
            "Epoch 511/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1246 - acc: 0.9746 - val_loss: 0.3691 - val_acc: 0.9065\n",
            "\n",
            "Epoch 00511: val_acc did not improve from 0.91680\n",
            "Epoch 512/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1295 - acc: 0.9761 - val_loss: 0.3456 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00512: val_acc did not improve from 0.91680\n",
            "Epoch 513/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1287 - acc: 0.9733 - val_loss: 0.3583 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00513: val_acc did not improve from 0.91680\n",
            "Epoch 514/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1287 - acc: 0.9727 - val_loss: 0.3438 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00514: val_acc did not improve from 0.91680\n",
            "Epoch 515/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1323 - acc: 0.9702 - val_loss: 0.3415 - val_acc: 0.9102\n",
            "\n",
            "Epoch 00515: val_acc did not improve from 0.91680\n",
            "Epoch 516/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1305 - acc: 0.9746 - val_loss: 0.3680 - val_acc: 0.9057\n",
            "\n",
            "Epoch 00516: val_acc did not improve from 0.91680\n",
            "Epoch 517/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1234 - acc: 0.9751 - val_loss: 0.3450 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00517: val_acc did not improve from 0.91680\n",
            "Epoch 518/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1247 - acc: 0.9761 - val_loss: 0.3767 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00518: val_acc did not improve from 0.91680\n",
            "Epoch 519/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1267 - acc: 0.9746 - val_loss: 0.3955 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00519: val_acc did not improve from 0.91680\n",
            "Epoch 520/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1281 - acc: 0.9702 - val_loss: 0.3593 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00520: val_acc did not improve from 0.91680\n",
            "Epoch 521/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1266 - acc: 0.9738 - val_loss: 0.4012 - val_acc: 0.9010\n",
            "\n",
            "Epoch 00521: val_acc did not improve from 0.91680\n",
            "Epoch 522/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1249 - acc: 0.9741 - val_loss: 0.3469 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00522: val_acc did not improve from 0.91680\n",
            "Epoch 523/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1245 - acc: 0.9767 - val_loss: 0.3619 - val_acc: 0.9074\n",
            "\n",
            "Epoch 00523: val_acc did not improve from 0.91680\n",
            "Epoch 524/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1237 - acc: 0.9750 - val_loss: 0.3537 - val_acc: 0.9114\n",
            "\n",
            "Epoch 00524: val_acc did not improve from 0.91680\n",
            "Epoch 525/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1262 - acc: 0.9765 - val_loss: 0.3571 - val_acc: 0.9074\n",
            "\n",
            "Epoch 00525: val_acc did not improve from 0.91680\n",
            "Epoch 526/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1163 - acc: 0.9764 - val_loss: 0.3451 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00526: val_acc did not improve from 0.91680\n",
            "Epoch 527/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1212 - acc: 0.9750 - val_loss: 0.3615 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00527: val_acc did not improve from 0.91680\n",
            "Epoch 528/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1217 - acc: 0.9724 - val_loss: 0.4150 - val_acc: 0.8939\n",
            "\n",
            "Epoch 00528: val_acc did not improve from 0.91680\n",
            "Epoch 529/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1308 - acc: 0.9705 - val_loss: 0.3331 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00529: val_acc did not improve from 0.91680\n",
            "Epoch 530/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1143 - acc: 0.9776 - val_loss: 0.3406 - val_acc: 0.9126\n",
            "\n",
            "Epoch 00530: val_acc did not improve from 0.91680\n",
            "Epoch 531/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1254 - acc: 0.9717 - val_loss: 0.3572 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00531: val_acc did not improve from 0.91680\n",
            "Epoch 532/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1172 - acc: 0.9764 - val_loss: 0.3600 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00532: val_acc did not improve from 0.91680\n",
            "Epoch 533/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1216 - acc: 0.9744 - val_loss: 0.3588 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00533: val_acc did not improve from 0.91680\n",
            "Epoch 534/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1208 - acc: 0.9763 - val_loss: 0.3664 - val_acc: 0.9095\n",
            "\n",
            "Epoch 00534: val_acc did not improve from 0.91680\n",
            "Epoch 535/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1187 - acc: 0.9761 - val_loss: 0.3651 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00535: val_acc did not improve from 0.91680\n",
            "Epoch 536/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1137 - acc: 0.9782 - val_loss: 0.3615 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00536: val_acc did not improve from 0.91680\n",
            "Epoch 537/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1111 - acc: 0.9782 - val_loss: 0.3554 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00537: val_acc did not improve from 0.91680\n",
            "Epoch 538/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.1204 - acc: 0.9781 - val_loss: 0.3539 - val_acc: 0.9102\n",
            "\n",
            "Epoch 00538: val_acc did not improve from 0.91680\n",
            "Epoch 539/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1155 - acc: 0.9753 - val_loss: 0.3658 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00539: val_acc did not improve from 0.91680\n",
            "Epoch 540/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1157 - acc: 0.9751 - val_loss: 0.3586 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00540: val_acc did not improve from 0.91680\n",
            "Epoch 541/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1215 - acc: 0.9761 - val_loss: 0.3609 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00541: val_acc did not improve from 0.91680\n",
            "Epoch 542/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1200 - acc: 0.9758 - val_loss: 0.3739 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00542: val_acc did not improve from 0.91680\n",
            "Epoch 543/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1115 - acc: 0.9786 - val_loss: 0.3716 - val_acc: 0.9079\n",
            "\n",
            "Epoch 00543: val_acc did not improve from 0.91680\n",
            "Epoch 544/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1140 - acc: 0.9784 - val_loss: 0.3719 - val_acc: 0.9055\n",
            "\n",
            "Epoch 00544: val_acc did not improve from 0.91680\n",
            "Epoch 545/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1156 - acc: 0.9782 - val_loss: 0.4110 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00545: val_acc did not improve from 0.91680\n",
            "Epoch 546/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1147 - acc: 0.9746 - val_loss: 0.3507 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00546: val_acc did not improve from 0.91680\n",
            "Epoch 547/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1124 - acc: 0.9772 - val_loss: 0.3783 - val_acc: 0.9077\n",
            "\n",
            "Epoch 00547: val_acc did not improve from 0.91680\n",
            "Epoch 548/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.1135 - acc: 0.9805 - val_loss: 0.3544 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00548: val_acc did not improve from 0.91680\n",
            "Epoch 549/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1125 - acc: 0.9769 - val_loss: 0.3583 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00549: val_acc did not improve from 0.91680\n",
            "Epoch 550/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1126 - acc: 0.9787 - val_loss: 0.3357 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00550: val_acc did not improve from 0.91680\n",
            "Epoch 551/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.1049 - acc: 0.9795 - val_loss: 0.3761 - val_acc: 0.9094\n",
            "\n",
            "Epoch 00551: val_acc did not improve from 0.91680\n",
            "Epoch 552/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.1111 - acc: 0.9765 - val_loss: 0.3627 - val_acc: 0.9123\n",
            "\n",
            "Epoch 00552: val_acc did not improve from 0.91680\n",
            "Epoch 553/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1222 - acc: 0.9756 - val_loss: 0.3663 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00553: val_acc did not improve from 0.91680\n",
            "Epoch 554/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1087 - acc: 0.9792 - val_loss: 0.3524 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00554: val_acc did not improve from 0.91680\n",
            "Epoch 555/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1109 - acc: 0.9794 - val_loss: 0.3478 - val_acc: 0.9152\n",
            "\n",
            "Epoch 00555: val_acc did not improve from 0.91680\n",
            "Epoch 556/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1048 - acc: 0.9816 - val_loss: 0.3599 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00556: val_acc did not improve from 0.91680\n",
            "Epoch 557/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1110 - acc: 0.9788 - val_loss: 0.4042 - val_acc: 0.9042\n",
            "\n",
            "Epoch 00557: val_acc did not improve from 0.91680\n",
            "Epoch 558/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1094 - acc: 0.9788 - val_loss: 0.4170 - val_acc: 0.9035\n",
            "\n",
            "Epoch 00558: val_acc did not improve from 0.91680\n",
            "Epoch 559/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1120 - acc: 0.9816 - val_loss: 0.3915 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00559: val_acc did not improve from 0.91680\n",
            "Epoch 560/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1116 - acc: 0.9815 - val_loss: 0.3365 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00560: val_acc improved from 0.91680 to 0.91820, saving model to /content/saved_models/cifar10_ResNet32v1_model.560.h5\n",
            "Epoch 561/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1121 - acc: 0.9782 - val_loss: 0.3565 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00561: val_acc did not improve from 0.91820\n",
            "Epoch 562/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1027 - acc: 0.9807 - val_loss: 0.4060 - val_acc: 0.9009\n",
            "\n",
            "Epoch 00562: val_acc did not improve from 0.91820\n",
            "Epoch 563/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1068 - acc: 0.9807 - val_loss: 0.3784 - val_acc: 0.9077\n",
            "\n",
            "Epoch 00563: val_acc did not improve from 0.91820\n",
            "Epoch 564/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1149 - acc: 0.9768 - val_loss: 0.3676 - val_acc: 0.9102\n",
            "\n",
            "Epoch 00564: val_acc did not improve from 0.91820\n",
            "Epoch 565/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.1078 - acc: 0.9794 - val_loss: 0.3456 - val_acc: 0.9183\n",
            "\n",
            "Epoch 00565: val_acc improved from 0.91820 to 0.91830, saving model to /content/saved_models/cifar10_ResNet32v1_model.565.h5\n",
            "Epoch 566/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1041 - acc: 0.9788 - val_loss: 0.3979 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00566: val_acc did not improve from 0.91830\n",
            "Epoch 567/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1080 - acc: 0.9802 - val_loss: 0.3416 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00567: val_acc did not improve from 0.91830\n",
            "Epoch 568/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1100 - acc: 0.9779 - val_loss: 0.3621 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00568: val_acc did not improve from 0.91830\n",
            "Epoch 569/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1094 - acc: 0.9793 - val_loss: 0.3547 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00569: val_acc did not improve from 0.91830\n",
            "Epoch 570/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1044 - acc: 0.9807 - val_loss: 0.3715 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00570: val_acc did not improve from 0.91830\n",
            "Epoch 571/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1061 - acc: 0.9796 - val_loss: 0.3656 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00571: val_acc did not improve from 0.91830\n",
            "Epoch 572/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.1147 - acc: 0.9766 - val_loss: 0.3455 - val_acc: 0.9150\n",
            "\n",
            "Epoch 00572: val_acc did not improve from 0.91830\n",
            "Epoch 573/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.1087 - acc: 0.9786 - val_loss: 0.3730 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00573: val_acc did not improve from 0.91830\n",
            "Epoch 574/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.1087 - acc: 0.9785 - val_loss: 0.3732 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00574: val_acc did not improve from 0.91830\n",
            "Epoch 575/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.1048 - acc: 0.9810 - val_loss: 0.3599 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00575: val_acc did not improve from 0.91830\n",
            "Epoch 576/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0976 - acc: 0.9837 - val_loss: 0.3882 - val_acc: 0.9066\n",
            "\n",
            "Epoch 00576: val_acc did not improve from 0.91830\n",
            "Epoch 577/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1047 - acc: 0.9807 - val_loss: 0.3558 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00577: val_acc did not improve from 0.91830\n",
            "Epoch 578/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0999 - acc: 0.9824 - val_loss: 0.3973 - val_acc: 0.9091\n",
            "\n",
            "Epoch 00578: val_acc did not improve from 0.91830\n",
            "Epoch 579/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.1020 - acc: 0.9809 - val_loss: 0.3709 - val_acc: 0.9123\n",
            "\n",
            "Epoch 00579: val_acc did not improve from 0.91830\n",
            "Epoch 580/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.1055 - acc: 0.9799 - val_loss: 0.3632 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00580: val_acc did not improve from 0.91830\n",
            "Epoch 581/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1041 - acc: 0.9821 - val_loss: 0.3734 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00581: val_acc did not improve from 0.91830\n",
            "Epoch 582/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1054 - acc: 0.9800 - val_loss: 0.3786 - val_acc: 0.9146\n",
            "\n",
            "Epoch 00582: val_acc did not improve from 0.91830\n",
            "Epoch 583/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1056 - acc: 0.9808 - val_loss: 0.3628 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00583: val_acc did not improve from 0.91830\n",
            "Epoch 584/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.1016 - acc: 0.9814 - val_loss: 0.3822 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00584: val_acc did not improve from 0.91830\n",
            "Epoch 585/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0968 - acc: 0.9853 - val_loss: 0.3685 - val_acc: 0.9148\n",
            "\n",
            "Epoch 00585: val_acc did not improve from 0.91830\n",
            "Epoch 586/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.1048 - acc: 0.9823 - val_loss: 0.3600 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00586: val_acc did not improve from 0.91830\n",
            "Epoch 587/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1024 - acc: 0.9814 - val_loss: 0.3486 - val_acc: 0.9151\n",
            "\n",
            "Epoch 00587: val_acc did not improve from 0.91830\n",
            "Epoch 588/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1006 - acc: 0.9817 - val_loss: 0.4010 - val_acc: 0.9073\n",
            "\n",
            "Epoch 00588: val_acc did not improve from 0.91830\n",
            "Epoch 589/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1049 - acc: 0.9801 - val_loss: 0.3599 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00589: val_acc did not improve from 0.91830\n",
            "Epoch 590/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1039 - acc: 0.9828 - val_loss: 0.3628 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00590: val_acc did not improve from 0.91830\n",
            "Epoch 591/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.1031 - acc: 0.9814 - val_loss: 0.4038 - val_acc: 0.9034\n",
            "\n",
            "Epoch 00591: val_acc did not improve from 0.91830\n",
            "Epoch 592/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.0954 - acc: 0.9855 - val_loss: 0.3835 - val_acc: 0.9089\n",
            "\n",
            "Epoch 00592: val_acc did not improve from 0.91830\n",
            "Epoch 593/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1026 - acc: 0.9819 - val_loss: 0.3711 - val_acc: 0.9089\n",
            "\n",
            "Epoch 00593: val_acc did not improve from 0.91830\n",
            "Epoch 594/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.1022 - acc: 0.9797 - val_loss: 0.3643 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00594: val_acc did not improve from 0.91830\n",
            "Epoch 595/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0961 - acc: 0.9836 - val_loss: 0.3720 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00595: val_acc did not improve from 0.91830\n",
            "Epoch 596/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0948 - acc: 0.9841 - val_loss: 0.3909 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00596: val_acc did not improve from 0.91830\n",
            "Epoch 597/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0991 - acc: 0.9836 - val_loss: 0.3556 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00597: val_acc did not improve from 0.91830\n",
            "Epoch 598/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0988 - acc: 0.9821 - val_loss: 0.3800 - val_acc: 0.9138\n",
            "\n",
            "Epoch 00598: val_acc did not improve from 0.91830\n",
            "Epoch 599/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0950 - acc: 0.9847 - val_loss: 0.3712 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00599: val_acc did not improve from 0.91830\n",
            "Epoch 600/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.1000 - acc: 0.9807 - val_loss: 0.3649 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00600: val_acc did not improve from 0.91830\n",
            "Epoch 601/650\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1006 - acc: 0.9802 - val_loss: 0.3873 - val_acc: 0.9094\n",
            "\n",
            "Epoch 00601: val_acc did not improve from 0.91830\n",
            "Epoch 602/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1004 - acc: 0.9805 - val_loss: 0.3527 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00602: val_acc did not improve from 0.91830\n",
            "Epoch 603/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0996 - acc: 0.9825 - val_loss: 0.3475 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00603: val_acc improved from 0.91830 to 0.91970, saving model to /content/saved_models/cifar10_ResNet32v1_model.603.h5\n",
            "Epoch 604/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0941 - acc: 0.9839 - val_loss: 0.3459 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00604: val_acc did not improve from 0.91970\n",
            "Epoch 605/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0943 - acc: 0.9852 - val_loss: 0.3449 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00605: val_acc improved from 0.91970 to 0.92040, saving model to /content/saved_models/cifar10_ResNet32v1_model.605.h5\n",
            "Epoch 606/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1001 - acc: 0.9828 - val_loss: 0.3446 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00606: val_acc improved from 0.92040 to 0.92060, saving model to /content/saved_models/cifar10_ResNet32v1_model.606.h5\n",
            "Epoch 607/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0987 - acc: 0.9840 - val_loss: 0.3427 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00607: val_acc did not improve from 0.92060\n",
            "Epoch 608/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0990 - acc: 0.9832 - val_loss: 0.3430 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00608: val_acc did not improve from 0.92060\n",
            "Epoch 609/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0943 - acc: 0.9849 - val_loss: 0.3429 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00609: val_acc did not improve from 0.92060\n",
            "Epoch 610/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0999 - acc: 0.9809 - val_loss: 0.3424 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00610: val_acc did not improve from 0.92060\n",
            "Epoch 611/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0999 - acc: 0.9836 - val_loss: 0.3412 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00611: val_acc did not improve from 0.92060\n",
            "Epoch 612/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0955 - acc: 0.9854 - val_loss: 0.3402 - val_acc: 0.9202\n",
            "\n",
            "Epoch 00612: val_acc did not improve from 0.92060\n",
            "Epoch 613/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0900 - acc: 0.9865 - val_loss: 0.3406 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00613: val_acc improved from 0.92060 to 0.92070, saving model to /content/saved_models/cifar10_ResNet32v1_model.613.h5\n",
            "Epoch 614/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0965 - acc: 0.9843 - val_loss: 0.3396 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00614: val_acc did not improve from 0.92070\n",
            "Epoch 615/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0960 - acc: 0.9836 - val_loss: 0.3390 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00615: val_acc improved from 0.92070 to 0.92120, saving model to /content/saved_models/cifar10_ResNet32v1_model.615.h5\n",
            "Epoch 616/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0990 - acc: 0.9817 - val_loss: 0.3386 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00616: val_acc improved from 0.92120 to 0.92150, saving model to /content/saved_models/cifar10_ResNet32v1_model.616.h5\n",
            "Epoch 617/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0970 - acc: 0.9842 - val_loss: 0.3393 - val_acc: 0.9207\n",
            "\n",
            "Epoch 00617: val_acc did not improve from 0.92150\n",
            "Epoch 618/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0907 - acc: 0.9853 - val_loss: 0.3392 - val_acc: 0.9208\n",
            "\n",
            "Epoch 00618: val_acc did not improve from 0.92150\n",
            "Epoch 619/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0978 - acc: 0.9817 - val_loss: 0.3385 - val_acc: 0.9208\n",
            "\n",
            "Epoch 00619: val_acc did not improve from 0.92150\n",
            "Epoch 620/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0894 - acc: 0.9865 - val_loss: 0.3382 - val_acc: 0.9208\n",
            "\n",
            "Epoch 00620: val_acc did not improve from 0.92150\n",
            "Epoch 621/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0905 - acc: 0.9867 - val_loss: 0.3375 - val_acc: 0.9206\n",
            "\n",
            "Epoch 00621: val_acc did not improve from 0.92150\n",
            "Epoch 622/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0905 - acc: 0.9861 - val_loss: 0.3372 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00622: val_acc did not improve from 0.92150\n",
            "Epoch 623/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0908 - acc: 0.9872 - val_loss: 0.3376 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00623: val_acc did not improve from 0.92150\n",
            "Epoch 624/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0955 - acc: 0.9848 - val_loss: 0.3389 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00624: val_acc did not improve from 0.92150\n",
            "Epoch 625/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0917 - acc: 0.9845 - val_loss: 0.3376 - val_acc: 0.9211\n",
            "\n",
            "Epoch 00625: val_acc did not improve from 0.92150\n",
            "Epoch 626/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.0943 - acc: 0.9838 - val_loss: 0.3370 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00626: val_acc did not improve from 0.92150\n",
            "Epoch 627/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0917 - acc: 0.9869 - val_loss: 0.3368 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00627: val_acc did not improve from 0.92150\n",
            "Epoch 628/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0871 - acc: 0.9875 - val_loss: 0.3374 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00628: val_acc improved from 0.92150 to 0.92180, saving model to /content/saved_models/cifar10_ResNet32v1_model.628.h5\n",
            "Epoch 629/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0970 - acc: 0.9833 - val_loss: 0.3369 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00629: val_acc did not improve from 0.92180\n",
            "Epoch 630/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0869 - acc: 0.9866 - val_loss: 0.3370 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00630: val_acc did not improve from 0.92180\n",
            "Epoch 631/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0927 - acc: 0.9868 - val_loss: 0.3372 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00631: val_acc did not improve from 0.92180\n",
            "Epoch 632/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0950 - acc: 0.9855 - val_loss: 0.3368 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00632: val_acc improved from 0.92180 to 0.92200, saving model to /content/saved_models/cifar10_ResNet32v1_model.632.h5\n",
            "Epoch 633/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0909 - acc: 0.9867 - val_loss: 0.3373 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00633: val_acc did not improve from 0.92200\n",
            "Epoch 634/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0928 - acc: 0.9840 - val_loss: 0.3371 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00634: val_acc did not improve from 0.92200\n",
            "Epoch 635/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0958 - acc: 0.9845 - val_loss: 0.3364 - val_acc: 0.9215\n",
            "\n",
            "Epoch 00635: val_acc did not improve from 0.92200\n",
            "Epoch 636/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0944 - acc: 0.9824 - val_loss: 0.3360 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00636: val_acc did not improve from 0.92200\n",
            "Epoch 637/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0893 - acc: 0.9869 - val_loss: 0.3367 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00637: val_acc did not improve from 0.92200\n",
            "Epoch 638/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.0956 - acc: 0.9841 - val_loss: 0.3355 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00638: val_acc did not improve from 0.92200\n",
            "Epoch 639/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0971 - acc: 0.9827 - val_loss: 0.3363 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00639: val_acc did not improve from 0.92200\n",
            "Epoch 640/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0887 - acc: 0.9865 - val_loss: 0.3353 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00640: val_acc did not improve from 0.92200\n",
            "Epoch 641/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0881 - acc: 0.9866 - val_loss: 0.3350 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00641: val_acc did not improve from 0.92200\n",
            "Epoch 642/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0884 - acc: 0.9868 - val_loss: 0.3359 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00642: val_acc did not improve from 0.92200\n",
            "Epoch 643/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0882 - acc: 0.9867 - val_loss: 0.3353 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00643: val_acc did not improve from 0.92200\n",
            "Epoch 644/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0918 - acc: 0.9864 - val_loss: 0.3345 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00644: val_acc improved from 0.92200 to 0.92210, saving model to /content/saved_models/cifar10_ResNet32v1_model.644.h5\n",
            "Epoch 645/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0907 - acc: 0.9852 - val_loss: 0.3347 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00645: val_acc improved from 0.92210 to 0.92230, saving model to /content/saved_models/cifar10_ResNet32v1_model.645.h5\n",
            "Epoch 646/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0917 - acc: 0.9855 - val_loss: 0.3352 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00646: val_acc did not improve from 0.92230\n",
            "Epoch 647/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0838 - acc: 0.9902 - val_loss: 0.3357 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00647: val_acc did not improve from 0.92230\n",
            "Epoch 648/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0854 - acc: 0.9875 - val_loss: 0.3348 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00648: val_acc did not improve from 0.92230\n",
            "Epoch 649/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0926 - acc: 0.9856 - val_loss: 0.3339 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00649: val_acc did not improve from 0.92230\n",
            "Epoch 650/650\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0872 - acc: 0.9891 - val_loss: 0.3345 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00650: val_acc did not improve from 0.92230\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "pM8_lBNeLh1R",
        "outputId": "087e30c4-caeb-45a8-c848-885c4bdc69c2"
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = pickle.load(open('trying_trainHistoryDict_clip_1', \"rb\"))\n",
        "functions.plot_loss_acc(history, 2, 0.4)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eikjJjqZLnaQ",
        "outputId": "626c18ac-c1f8-46f3-94ae-9f5ecbf91e98"
      },
      "source": [
        "history['val_acc'][-1]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9218999743461609"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL29hAiKLoWX",
        "outputId": "1dd03d24-acef-4bb1-fda9-cf22974e62c1"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07810002565383911"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYsweyOS3wPM"
      },
      "source": [
        "#### Plotting final graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "MOF7V2LgY8_K",
        "outputId": "e217c298-b40c-4bb5-8325-b08589ca85bc"
      },
      "source": [
        "history_no_clipping = pickle.load(open('simple_trainHistoryDict', \"rb\"))\n",
        "history_05 = pickle.load(open('simple_trainHistoryDict_clip_05', \"rb\"))\n",
        "history_1 = pickle.load(open('simple_trainHistoryDict_clip_1', \"rb\"))\n",
        "history_05_trying = pickle.load(open('trying_trainHistoryDict_clip_05', \"rb\"))\n",
        "history_1_trying = pickle.load(open('trying_trainHistoryDict_clip_1', \"rb\"))\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
        "axs[0].grid(True)\n",
        "axs[1].grid(True)\n",
        "max_len = len(history_no_clipping['val_loss'])\n",
        "axs[0].plot(history_no_clipping['val_loss'][4:max_len:5], label='no clipping')\n",
        "axs[0].plot(history_05['val_loss'][4:max_len:5], label='0.5')\n",
        "axs[0].plot(history_1['val_loss'][4:max_len:5], label='1')\n",
        "axs[0].plot(history_05_trying['val_loss'][4:max_len:5], label='0.5 try')\n",
        "axs[0].plot(history_1_trying['val_loss'][4:max_len:5] + [history_1_trying['val_loss'][-1]] * 70 , label='1 try')\n",
        "axs[0].set_title('Loss')\n",
        "axs[0].set_xlabel('Epochs')\n",
        "axs[0].set_ylim(0, 0.6)\n",
        "axs[1].plot(1 - np.array(history_no_clipping['val_acc'][4:max_len:5]), label='no clipping')\n",
        "axs[1].plot(1 - np.array(history_05['val_acc'][4:max_len:5]), label='0.5')\n",
        "axs[1].plot(1 - np.array(history_1['val_acc'][4:max_len:5]), label='1')\n",
        "axs[1].plot(1 - np.array(history_05_trying['val_acc'][4:max_len:5]), label='0.5 try')\n",
        "axs[1].plot(1 - np.array(history_1_trying['val_acc'][4:max_len:5] + [history_1_trying['val_acc'][-1]] * 70), label='1 try')\n",
        "axs[1].set_title('Error')\n",
        "axs[1].set_xlabel('Epochs')\n",
        "axs[1].set_ylim(0, 0.15)\n",
        "axs[0].legend(loc='best')\n",
        "axs[1].legend(loc='best')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f31933c5090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
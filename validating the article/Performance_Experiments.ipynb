{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "navigate_num": "#000000",
        "navigate_text": "#333333",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700",
        "sidebar_border": "#EEEEEE",
        "wrapper_background": "#FFFFFF"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "264px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 4,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false,
      "widenNotebook": false
    },
    "colab": {
      "name": "Performance Experiments",
      "provenance": [],
      "collapsed_sections": [
        "oV3pIElqkHvI",
        "QkOcJ7cvkeeM",
        "MNdHB-BBk6tR",
        "2zM40r0II99z",
        "joxUfpa9b2bk"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WhiteTeaDragon/SingularValues/blob/main/Performance_Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJQ1vryM8J-6"
      },
      "source": [
        "Code for ResNet copied from https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/blob/master/chapter2-deep-networks/resnet-cifar10-2.2.1.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UIiFViKj7fS"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrkJLYDzAArN"
      },
      "source": [
        "from __future__ import absolute_import\r\n",
        "from __future__ import division\r\n",
        "from __future__ import print_function\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.keras.layers import Dense, Conv2D\r\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\r\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input\r\n",
        "from tensorflow.keras.layers import Flatten, add\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\r\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.regularizers import l2, Regularizer\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.datasets import cifar10\r\n",
        "from tensorflow.keras.utils import plot_model\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import math"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51xUbivJ9BCi"
      },
      "source": [
        "import time\r\n",
        "\r\n",
        "def tensorflow_method128(kernel, n1, n2):\r\n",
        "    start = time.time()\r\n",
        "    print(kernel.shape)\r\n",
        "    conv_tr = tf.cast(tf.transpose(kernel, perm=[2, 3, 0, 1]), tf.complex64)\r\n",
        "    print(\"after cast\", time.time() - start)\r\n",
        "    transforms = tf.transpose(\r\n",
        "        tf.signal.fft2d(\r\n",
        "            tf.pad(\r\n",
        "                conv_tr, ((0, 0), (0, 0), (0, n1 - kernel.shape[0]),\r\n",
        "                                (0, n2 - kernel.shape[0]))\r\n",
        "            )\r\n",
        "        ), \r\n",
        "        perm=[2, 3, 0, 1]\r\n",
        "    )\r\n",
        "    print(\"before svd\", time.time() - start)\r\n",
        "    return tf.linalg.svd(transforms, compute_uv=False)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpfoDiTJ80oQ"
      },
      "source": [
        "# better not to use it, works really long\r\n",
        "class MyRegularizer(Regularizer):\r\n",
        "    def __init__(self, n1, n2):\r\n",
        "        self.n1 = n1\r\n",
        "        self.n2 = n2\r\n",
        "        self.cnt = 0\r\n",
        "\r\n",
        "    def __call__(self, x):\r\n",
        "        self.cnt += 1\r\n",
        "        print(self.cnt)\r\n",
        "        if self.cnt == 1:\r\n",
        "          self.cnt = 0\r\n",
        "          return tf.reduce_sum(tf.square(tensorflow_method128(x, self.n1, self.n2)))\r\n",
        "    \r\n",
        "    def get_config(self):\r\n",
        "        return {'n1': self.n1, 'n2': self.n2, 'cnt': self.cnt}"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipXgVAL4S6Pp"
      },
      "source": [
        "def lr_schedule(epoch):\r\n",
        "    \"\"\"Learning Rate Schedule\r\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\r\n",
        "    Called automatically every epoch as part of callbacks during training.\r\n",
        "    # Arguments\r\n",
        "        epoch (int): The number of epochs\r\n",
        "    # Returns\r\n",
        "        lr (float32): learning rate\r\n",
        "    \"\"\"\r\n",
        "    lr = 1e-3\r\n",
        "    if epoch > 180:\r\n",
        "        lr *= 0.5e-3\r\n",
        "    elif epoch > 160:\r\n",
        "        lr *= 1e-3\r\n",
        "    elif epoch > 120:\r\n",
        "        lr *= 1e-2\r\n",
        "    elif epoch > 80:\r\n",
        "        lr *= 1e-1\r\n",
        "    print('Learning rate: ', lr)\r\n",
        "    return lr"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnYttaDTTEdp"
      },
      "source": [
        "def resnet_layer(inputs,\r\n",
        "                 num_filters=16,\r\n",
        "                 kernel_size=3,\r\n",
        "                 strides=1,\r\n",
        "                 activation='relu',\r\n",
        "                 batch_normalization=True,\r\n",
        "                 conv_first=True,\r\n",
        "                 singular_reg=False):\r\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\r\n",
        "    Arguments:\r\n",
        "        inputs (tensor): input tensor from input image or previous layer\r\n",
        "        num_filters (int): Conv2D number of filters\r\n",
        "        kernel_size (int): Conv2D square kernel dimensions\r\n",
        "        strides (int): Conv2D square stride dimensions\r\n",
        "        activation (string): activation name\r\n",
        "        batch_normalization (bool): whether to include batch normalization\r\n",
        "        conv_first (bool): conv-bn-activation (True) or\r\n",
        "            bn-activation-conv (False)\r\n",
        "    Returns:\r\n",
        "        x (tensor): tensor as input to the next layer\r\n",
        "    \"\"\"\r\n",
        "    if not singular_reg:\r\n",
        "        conv = Conv2D(num_filters,\r\n",
        "                    kernel_size=kernel_size,\r\n",
        "                    strides=strides,\r\n",
        "                    padding='same',\r\n",
        "                    kernel_initializer='he_normal',\r\n",
        "                    kernel_regularizer=l2(1e-4))\r\n",
        "    else:\r\n",
        "        conv = Conv2D(num_filters,\r\n",
        "                    kernel_size=kernel_size,\r\n",
        "                    strides=strides,\r\n",
        "                    padding='same',\r\n",
        "                    kernel_initializer='he_normal',\r\n",
        "                    kernel_regularizer=MyRegularizer(inputs.shape[1], inputs.shape[2]))\r\n",
        "\r\n",
        "    x = inputs\r\n",
        "    if conv_first:\r\n",
        "        x = conv(x)\r\n",
        "        if batch_normalization:\r\n",
        "            x = BatchNormalization()(x)\r\n",
        "        if activation is not None:\r\n",
        "            x = Activation(activation)(x)\r\n",
        "    else:\r\n",
        "        if batch_normalization:\r\n",
        "            x = BatchNormalization()(x)\r\n",
        "        if activation is not None:\r\n",
        "            x = Activation(activation)(x)\r\n",
        "        x = conv(x)\r\n",
        "    return x"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4Q1C_POTJCI"
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10, singular_reg=False):\r\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\r\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\r\n",
        "    Last ReLU is after the shortcut connection.\r\n",
        "    At the beginning of each stage, the feature map size is halved\r\n",
        "    (downsampled) by a convolutional layer with strides=2, while \r\n",
        "    the number of filters is doubled. Within each stage, \r\n",
        "    the layers have the same number filters and the\r\n",
        "    same number of filters.\r\n",
        "    Features maps sizes:\r\n",
        "    stage 0: 32x32, 16\r\n",
        "    stage 1: 16x16, 32\r\n",
        "    stage 2:  8x8,  64\r\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\r\n",
        "    ResNet20 0.27M\r\n",
        "    ResNet32 0.46M\r\n",
        "    ResNet44 0.66M\r\n",
        "    ResNet56 0.85M\r\n",
        "    ResNet110 1.7M\r\n",
        "    Arguments:\r\n",
        "        input_shape (tensor): shape of input image tensor\r\n",
        "        depth (int): number of core convolutional layers\r\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\r\n",
        "    Returns:\r\n",
        "        model (Model): Keras model instance\r\n",
        "    \"\"\"\r\n",
        "    if (depth - 2) % 6 != 0:\r\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, in [a])')\r\n",
        "    # start model definition.\r\n",
        "    num_filters = 16\r\n",
        "    num_res_blocks = int((depth - 2) / 6)\r\n",
        "\r\n",
        "    inputs = Input(shape=input_shape)\r\n",
        "    x = resnet_layer(inputs=inputs, singular_reg=singular_reg)\r\n",
        "    # instantiate the stack of residual units\r\n",
        "    for stack in range(3):\r\n",
        "        for res_block in range(num_res_blocks):\r\n",
        "            strides = 1\r\n",
        "            # first layer but not first stack\r\n",
        "            if stack > 0 and res_block == 0:  \r\n",
        "                strides = 2  # downsample\r\n",
        "            y = resnet_layer(inputs=x,\r\n",
        "                             num_filters=num_filters,\r\n",
        "                             strides=strides, singular_reg=singular_reg)\r\n",
        "            y = resnet_layer(inputs=y,\r\n",
        "                             num_filters=num_filters,\r\n",
        "                             activation=None, singular_reg=singular_reg)\r\n",
        "            # first layer but not first stack\r\n",
        "            if stack > 0 and res_block == 0:\r\n",
        "                # linear projection residual shortcut\r\n",
        "                # connection to match changed dims\r\n",
        "                x = resnet_layer(inputs=x,\r\n",
        "                                 num_filters=num_filters,\r\n",
        "                                 kernel_size=1,\r\n",
        "                                 strides=strides,\r\n",
        "                                 activation=None,\r\n",
        "                                 batch_normalization=False,\r\n",
        "                                 singular_reg=singular_reg)\r\n",
        "            x = add([x, y])\r\n",
        "            x = Activation('relu')(x)\r\n",
        "        num_filters *= 2\r\n",
        "\r\n",
        "    # add classifier on top.\r\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\r\n",
        "    x = AveragePooling2D(pool_size=8)(x)\r\n",
        "    y = Flatten()(x)\r\n",
        "    outputs = Dense(num_classes,\r\n",
        "                    activation='softmax',\r\n",
        "                    kernel_initializer='he_normal')(y)\r\n",
        "\r\n",
        "    # instantiate model.\r\n",
        "    model = Model(inputs=inputs, outputs=outputs)\r\n",
        "    return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0gn6pDETQ9f"
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=10, singular_reg=False):\r\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\r\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or \r\n",
        "    also known as bottleneck layer.\r\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\r\n",
        "    Second and onwards shortcut connection is identity.\r\n",
        "    At the beginning of each stage, \r\n",
        "    the feature map size is halved (downsampled)\r\n",
        "    by a convolutional layer with strides=2, \r\n",
        "    while the number of filter maps is\r\n",
        "    doubled. Within each stage, the layers have \r\n",
        "    the same number filters and the same filter map sizes.\r\n",
        "    Features maps sizes:\r\n",
        "    conv1  : 32x32,  16\r\n",
        "    stage 0: 32x32,  64\r\n",
        "    stage 1: 16x16, 128\r\n",
        "    stage 2:  8x8,  256\r\n",
        "    Arguments:\r\n",
        "        input_shape (tensor): shape of input image tensor\r\n",
        "        depth (int): number of core convolutional layers\r\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\r\n",
        "    Returns:\r\n",
        "        model (Model): Keras model instance\r\n",
        "    \"\"\"\r\n",
        "    if (depth - 2) % 9 != 0:\r\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\r\n",
        "    # start model definition.\r\n",
        "    num_filters_in = 16\r\n",
        "    num_res_blocks = int((depth - 2) / 9)\r\n",
        "\r\n",
        "    inputs = Input(shape=input_shape)\r\n",
        "    # v2 performs Conv2D with BN-ReLU\r\n",
        "    # on input before splitting into 2 paths\r\n",
        "    x = resnet_layer(inputs=inputs,\r\n",
        "                     num_filters=num_filters_in,\r\n",
        "                     conv_first=True, singular_reg=singular_reg)\r\n",
        "\r\n",
        "    # instantiate the stack of residual units\r\n",
        "    for stage in range(3):\r\n",
        "        for res_block in range(num_res_blocks):\r\n",
        "            activation = 'relu'\r\n",
        "            batch_normalization = True\r\n",
        "            strides = 1\r\n",
        "            if stage == 0:\r\n",
        "                num_filters_out = num_filters_in * 4\r\n",
        "                # first layer and first stage\r\n",
        "                if res_block == 0:  \r\n",
        "                    activation = None\r\n",
        "                    batch_normalization = False\r\n",
        "            else:\r\n",
        "                num_filters_out = num_filters_in * 2\r\n",
        "                # first layer but not first stage\r\n",
        "                if res_block == 0:\r\n",
        "                    # downsample\r\n",
        "                    strides = 2 \r\n",
        "\r\n",
        "            # bottleneck residual unit\r\n",
        "            y = resnet_layer(inputs=x,\r\n",
        "                             num_filters=num_filters_in,\r\n",
        "                             kernel_size=1,\r\n",
        "                             strides=strides,\r\n",
        "                             activation=activation,\r\n",
        "                             batch_normalization=batch_normalization,\r\n",
        "                             conv_first=False,\r\n",
        "                             singular_reg=singular_reg)\r\n",
        "            y = resnet_layer(inputs=y,\r\n",
        "                             num_filters=num_filters_in,\r\n",
        "                             conv_first=False,\r\n",
        "                             singular_reg=singular_reg)\r\n",
        "            y = resnet_layer(inputs=y,\r\n",
        "                             num_filters=num_filters_out,\r\n",
        "                             kernel_size=1,\r\n",
        "                             conv_first=False,\r\n",
        "                             singular_reg=singular_reg)\r\n",
        "            if res_block == 0:\r\n",
        "                # linear projection residual shortcut connection\r\n",
        "                # to match changed dims\r\n",
        "                x = resnet_layer(inputs=x,\r\n",
        "                                 num_filters=num_filters_out,\r\n",
        "                                 kernel_size=1,\r\n",
        "                                 strides=strides,\r\n",
        "                                 activation=None,\r\n",
        "                                 batch_normalization=False,\r\n",
        "                                 singular_reg=singular_reg)\r\n",
        "            x = add([x, y])\r\n",
        "\r\n",
        "        num_filters_in = num_filters_out\r\n",
        "\r\n",
        "    # add classifier on top.\r\n",
        "    # v2 has BN-ReLU before Pooling\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = AveragePooling2D(pool_size=8)(x)\r\n",
        "    y = Flatten()(x)\r\n",
        "    outputs = Dense(num_classes,\r\n",
        "                    activation='softmax',\r\n",
        "                    kernel_initializer='he_normal')(y)\r\n",
        "\r\n",
        "    # instantiate model.\r\n",
        "    model = Model(inputs=inputs, outputs=outputs)\r\n",
        "    return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3slMuCc5T87E"
      },
      "source": [
        "def define_and_compile_ResNet_model(version=1, depth=32, singular_reg=False):\r\n",
        "    # model name, depth and version\r\n",
        "    model_type = 'ResNet%dv%d' % (depth, version)\r\n",
        "    if version == 2:\r\n",
        "        model = resnet_v2(input_shape=input_shape, depth=depth,\r\n",
        "                          singular_reg=singular_reg)\r\n",
        "    else:\r\n",
        "        model = resnet_v1(input_shape=input_shape, depth=depth,\r\n",
        "                          singular_reg=singular_reg)\r\n",
        "\r\n",
        "    model.compile(loss='categorical_crossentropy',\r\n",
        "                optimizer=Adam(lr=lr_schedule(0)),\r\n",
        "                metrics=['acc'])\r\n",
        "    return model, model_type"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_9Xd-OCf_uh"
      },
      "source": [
        "# prepare model saving directory.\r\n",
        "def prepare_model_saving_directory(model_type):\r\n",
        "    save_dir = os.path.join(os.getcwd(), 'saved_models')\r\n",
        "    model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\r\n",
        "    if not os.path.isdir(save_dir):\r\n",
        "        os.makedirs(save_dir)\r\n",
        "    filepath = os.path.join(save_dir, model_name)\r\n",
        "    return filepath"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kxm3zqFVZP6"
      },
      "source": [
        "# prepare callbacks for model saving and for learning rate adjustment.\r\n",
        "def standard_callbacks(model_type):\r\n",
        "    checkpoint = ModelCheckpoint(filepath=prepare_model_saving_directory(model_type),\r\n",
        "                                monitor='val_acc',\r\n",
        "                                verbose=1,\r\n",
        "                                save_best_only=True)\r\n",
        "\r\n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\r\n",
        "\r\n",
        "    lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\r\n",
        "                                cooldown=0,\r\n",
        "                                patience=5,\r\n",
        "                                min_lr=0.5e-6)\r\n",
        "\r\n",
        "    return [checkpoint, lr_reducer, lr_scheduler]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t713X5kTi-PS"
      },
      "source": [
        "import pickle\r\n",
        "\r\n",
        "# run training, with or without data augmentation.\r\n",
        "def run_training(model, model_type, x_train, y_train, x_test, y_test,\r\n",
        "                 history_file_dump_name,\r\n",
        "                 steps_per_epoch=None,\r\n",
        "                 batch_size=128, epochs=250, data_augmentation=True,\r\n",
        "                 callbacks=None):\r\n",
        "    if steps_per_epoch is None:\r\n",
        "        steps_per_epoch =  math.ceil(len(x_train) / batch_size)\r\n",
        "    if callbacks is None:\r\n",
        "        callbacks = standard_callbacks(model_type)\r\n",
        "    if not data_augmentation:\r\n",
        "        print('Not using data augmentation.')\r\n",
        "        history = model.fit(x_train, y_train,\r\n",
        "                batch_size=batch_size,\r\n",
        "                epochs=epochs,\r\n",
        "                validation_data=(x_test, y_test),\r\n",
        "                shuffle=True,\r\n",
        "                steps_per_epoch=steps_per_epoch,\r\n",
        "                callbacks=standard_callbacks(model_type))\r\n",
        "    else:\r\n",
        "        print('Using real-time data augmentation.')\r\n",
        "        # this will do preprocessing and realtime data augmentation:\r\n",
        "        datagen = ImageDataGenerator(\r\n",
        "            # set input mean to 0 over the dataset\r\n",
        "            featurewise_center=False,\r\n",
        "            # set each sample mean to 0\r\n",
        "            samplewise_center=False,\r\n",
        "            # divide inputs by std of dataset\r\n",
        "            featurewise_std_normalization=False,\r\n",
        "            # divide each input by its std\r\n",
        "            samplewise_std_normalization=False,\r\n",
        "            # apply ZCA whitening\r\n",
        "            zca_whitening=False,\r\n",
        "            # randomly rotate images in the range (deg 0 to 180)\r\n",
        "            rotation_range=0,\r\n",
        "            # randomly shift images horizontally\r\n",
        "            width_shift_range=0.1,\r\n",
        "            # randomly shift images vertically\r\n",
        "            height_shift_range=0.1,\r\n",
        "            # randomly flip images\r\n",
        "            horizontal_flip=True,\r\n",
        "            # randomly flip images\r\n",
        "            vertical_flip=False)\r\n",
        "\r\n",
        "        # compute quantities required for featurewise normalization\r\n",
        "        # (std, mean, and principal components if ZCA whitening is applied).\r\n",
        "        datagen.fit(x_train)\r\n",
        "        \r\n",
        "        # fit the model on the batches generated by datagen.flow().\r\n",
        "        history = model.fit(x=datagen.flow(x_train, y_train,\r\n",
        "                                           batch_size=batch_size),\r\n",
        "                verbose=1,\r\n",
        "                epochs=epochs,\r\n",
        "                validation_data=(x_test, y_test),\r\n",
        "                steps_per_epoch=steps_per_epoch,\r\n",
        "                callbacks=callbacks)\r\n",
        "    file_pi = open(history_file_dump_name, 'wb')\r\n",
        "    pickle.dump(history.history, file_pi)\r\n",
        "    file_pi.close()\r\n",
        "    return history"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi6Y2-FtGjZv"
      },
      "source": [
        "def Clip_OperatorNorm(conv, inp_shape, clip_to):\r\n",
        "  conv_tr = tf.cast(tf.transpose(conv, perm=[2, 3, 0, 1]), tf.complex128)\r\n",
        "  conv_shape = conv.get_shape().as_list()\r\n",
        "  padding = tf.constant([[0, 0], [0, 0],\r\n",
        "                         [0, inp_shape[0] - conv_shape[0]],\r\n",
        "                         [0, inp_shape[1] - conv_shape[1]]])\r\n",
        "  transform_coeff = tf.signal.fft2d(tf.pad(conv_tr, padding))\r\n",
        "  D, U, V = tf.linalg.svd(tf.transpose(transform_coeff, perm = [2, 3, 0, 1]))\r\n",
        "  norm = tf.reduce_max(D)\r\n",
        "  D_clipped = tf.cast(tf.minimum(D, clip_to), tf.complex128)\r\n",
        "  clipped_coeff = tf.matmul(U, tf.matmul(tf.linalg.diag(D_clipped),\r\n",
        "                                         V, adjoint_b=True))\r\n",
        "  clipped_conv_padded = tf.math.real(tf.signal.ifft2d(\r\n",
        "      tf.transpose(clipped_coeff, perm=[2, 3, 0, 1])))\r\n",
        "  return tf.slice(tf.transpose(clipped_conv_padded, perm=[2, 3, 0, 1]),\r\n",
        "                  [0] * len(conv_shape), conv_shape), norm"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXZWmjlLjzn5"
      },
      "source": [
        "import keras.backend as K\r\n",
        "from keras.callbacks import LambdaCallback\r\n",
        "import copy\r\n",
        "\r\n",
        "def afterEpochClipTo05(epochs, logs):\r\n",
        "    for layer in model.layers:\r\n",
        "        if layer.name[:6] == \"conv2d\":\r\n",
        "            K.set_value(layer.kernel, Clip_OperatorNorm(layer.kernel,\r\n",
        "                                                        layer.input_shape[1:3],\r\n",
        "                                                        0.5)[0])\r\n",
        "            \r\n",
        "def afterEpochClipTo1(epochs, logs):\r\n",
        "    for layer in model.layers:\r\n",
        "        if layer.name[:6] == \"conv2d\":\r\n",
        "            K.set_value(layer.kernel, Clip_OperatorNorm(layer.kernel,\r\n",
        "                                                        layer.input_shape[1:3],\r\n",
        "                                                        1.0)[0])"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j272slYi8ybb"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def plot_loss_acc(history):\r\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\r\n",
        "    axs[0].grid(True)\r\n",
        "    axs[1].grid(True)\r\n",
        "    axs[0].plot(history['loss'], label='train')\r\n",
        "    axs[0].plot(history['val_loss'], label='val')\r\n",
        "    axs[0].set_title('Loss')\r\n",
        "    axs[0].set_xlabel('Epochs')\r\n",
        "    axs[0].set_ylim(0, 2)\r\n",
        "    axs[1].plot(1 - np.array(history['acc']), label='train')\r\n",
        "    axs[1].plot(1 - np.array(history['val_acc']), label='val')\r\n",
        "    axs[1].set_title('Error')\r\n",
        "    axs[1].set_xlabel('Epochs')\r\n",
        "    axs[1].set_ylim(0, 0.4)\r\n",
        "    axs[0].legend(loc='best')\r\n",
        "    axs[1].legend(loc='best')"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV3pIElqkHvI"
      },
      "source": [
        "### Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTPb9VLtNzm1",
        "outputId": "29b89e0f-344d-44ba-d36b-ff19b6ee4ad9"
      },
      "source": [
        "num_classes = 10\r\n",
        "\r\n",
        "# Model parameter\r\n",
        "# ----------------------------------------------------------------------------\r\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\r\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\r\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\r\n",
        "# ----------------------------------------------------------------------------\r\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\r\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\r\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\r\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\r\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\r\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\r\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\r\n",
        "# ---------------------------------------------------------------------------\r\n",
        "\r\n",
        "\r\n",
        "# load the CIFAR10 data.\r\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\r\n",
        "\r\n",
        "# input image dimensions.\r\n",
        "input_shape = x_train.shape[1:]\r\n",
        "\r\n",
        "# normalize data.\r\n",
        "x_train = x_train.astype('float32') / 255\r\n",
        "x_test = x_test.astype('float32') / 255\r\n",
        "\r\n",
        "# if subtract pixel mean is enabled\r\n",
        "x_train_mean = np.mean(x_train, axis=0)\r\n",
        "x_train -= x_train_mean\r\n",
        "x_test -= x_train_mean\r\n",
        "\r\n",
        "print('x_train shape:', x_train.shape)\r\n",
        "print(x_train.shape[0], 'train samples')\r\n",
        "print(x_test.shape[0], 'test samples')\r\n",
        "print('y_train shape:', y_train.shape)\r\n",
        "\r\n",
        "# convert class vectors to binary class matrices.\r\n",
        "y_train = to_categorical(y_train, num_classes)\r\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkOcJ7cvkeeM"
      },
      "source": [
        "### Model without clipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccm054_-TaQk",
        "outputId": "20e98180-3549-4eff-fd12-79ce9bd587e7"
      },
      "source": [
        "model, model_type = define_and_compile_ResNet_model()\r\n",
        "\r\n",
        "# enable this if pydot can be installed\r\n",
        "# plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\r\n",
        "# print(model_type)\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_12 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_363 (Conv2D)             (None, 32, 32, 16)   448         input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_341 (BatchN (None, 32, 32, 16)   64          conv2d_363[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_341 (Activation)     (None, 32, 32, 16)   0           batch_normalization_341[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_364 (Conv2D)             (None, 32, 32, 16)   2320        activation_341[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_342 (BatchN (None, 32, 32, 16)   64          conv2d_364[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_342 (Activation)     (None, 32, 32, 16)   0           batch_normalization_342[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_365 (Conv2D)             (None, 32, 32, 16)   2320        activation_342[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_343 (BatchN (None, 32, 32, 16)   64          conv2d_365[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_165 (Add)                   (None, 32, 32, 16)   0           activation_341[0][0]             \n",
            "                                                                 batch_normalization_343[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_343 (Activation)     (None, 32, 32, 16)   0           add_165[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_366 (Conv2D)             (None, 32, 32, 16)   2320        activation_343[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_344 (BatchN (None, 32, 32, 16)   64          conv2d_366[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_344 (Activation)     (None, 32, 32, 16)   0           batch_normalization_344[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_367 (Conv2D)             (None, 32, 32, 16)   2320        activation_344[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_345 (BatchN (None, 32, 32, 16)   64          conv2d_367[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_166 (Add)                   (None, 32, 32, 16)   0           activation_343[0][0]             \n",
            "                                                                 batch_normalization_345[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_345 (Activation)     (None, 32, 32, 16)   0           add_166[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_368 (Conv2D)             (None, 32, 32, 16)   2320        activation_345[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_346 (BatchN (None, 32, 32, 16)   64          conv2d_368[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_346 (Activation)     (None, 32, 32, 16)   0           batch_normalization_346[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_369 (Conv2D)             (None, 32, 32, 16)   2320        activation_346[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_347 (BatchN (None, 32, 32, 16)   64          conv2d_369[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_167 (Add)                   (None, 32, 32, 16)   0           activation_345[0][0]             \n",
            "                                                                 batch_normalization_347[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_347 (Activation)     (None, 32, 32, 16)   0           add_167[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_370 (Conv2D)             (None, 32, 32, 16)   2320        activation_347[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_348 (BatchN (None, 32, 32, 16)   64          conv2d_370[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_348 (Activation)     (None, 32, 32, 16)   0           batch_normalization_348[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_371 (Conv2D)             (None, 32, 32, 16)   2320        activation_348[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_349 (BatchN (None, 32, 32, 16)   64          conv2d_371[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_168 (Add)                   (None, 32, 32, 16)   0           activation_347[0][0]             \n",
            "                                                                 batch_normalization_349[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_349 (Activation)     (None, 32, 32, 16)   0           add_168[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_372 (Conv2D)             (None, 32, 32, 16)   2320        activation_349[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_350 (BatchN (None, 32, 32, 16)   64          conv2d_372[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_350 (Activation)     (None, 32, 32, 16)   0           batch_normalization_350[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_373 (Conv2D)             (None, 32, 32, 16)   2320        activation_350[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_351 (BatchN (None, 32, 32, 16)   64          conv2d_373[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_169 (Add)                   (None, 32, 32, 16)   0           activation_349[0][0]             \n",
            "                                                                 batch_normalization_351[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_351 (Activation)     (None, 32, 32, 16)   0           add_169[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_374 (Conv2D)             (None, 16, 16, 32)   4640        activation_351[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_352 (BatchN (None, 16, 16, 32)   128         conv2d_374[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_352 (Activation)     (None, 16, 16, 32)   0           batch_normalization_352[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_375 (Conv2D)             (None, 16, 16, 32)   9248        activation_352[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_376 (Conv2D)             (None, 16, 16, 32)   544         activation_351[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_353 (BatchN (None, 16, 16, 32)   128         conv2d_375[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_170 (Add)                   (None, 16, 16, 32)   0           conv2d_376[0][0]                 \n",
            "                                                                 batch_normalization_353[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_353 (Activation)     (None, 16, 16, 32)   0           add_170[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_377 (Conv2D)             (None, 16, 16, 32)   9248        activation_353[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_354 (BatchN (None, 16, 16, 32)   128         conv2d_377[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_354 (Activation)     (None, 16, 16, 32)   0           batch_normalization_354[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_378 (Conv2D)             (None, 16, 16, 32)   9248        activation_354[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_355 (BatchN (None, 16, 16, 32)   128         conv2d_378[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_171 (Add)                   (None, 16, 16, 32)   0           activation_353[0][0]             \n",
            "                                                                 batch_normalization_355[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_355 (Activation)     (None, 16, 16, 32)   0           add_171[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_379 (Conv2D)             (None, 16, 16, 32)   9248        activation_355[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_356 (BatchN (None, 16, 16, 32)   128         conv2d_379[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_356 (Activation)     (None, 16, 16, 32)   0           batch_normalization_356[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_380 (Conv2D)             (None, 16, 16, 32)   9248        activation_356[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_357 (BatchN (None, 16, 16, 32)   128         conv2d_380[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_172 (Add)                   (None, 16, 16, 32)   0           activation_355[0][0]             \n",
            "                                                                 batch_normalization_357[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_357 (Activation)     (None, 16, 16, 32)   0           add_172[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_381 (Conv2D)             (None, 16, 16, 32)   9248        activation_357[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_358 (BatchN (None, 16, 16, 32)   128         conv2d_381[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_358 (Activation)     (None, 16, 16, 32)   0           batch_normalization_358[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_382 (Conv2D)             (None, 16, 16, 32)   9248        activation_358[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_359 (BatchN (None, 16, 16, 32)   128         conv2d_382[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_173 (Add)                   (None, 16, 16, 32)   0           activation_357[0][0]             \n",
            "                                                                 batch_normalization_359[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_359 (Activation)     (None, 16, 16, 32)   0           add_173[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_383 (Conv2D)             (None, 16, 16, 32)   9248        activation_359[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_360 (BatchN (None, 16, 16, 32)   128         conv2d_383[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_360 (Activation)     (None, 16, 16, 32)   0           batch_normalization_360[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_384 (Conv2D)             (None, 16, 16, 32)   9248        activation_360[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_361 (BatchN (None, 16, 16, 32)   128         conv2d_384[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_174 (Add)                   (None, 16, 16, 32)   0           activation_359[0][0]             \n",
            "                                                                 batch_normalization_361[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_361 (Activation)     (None, 16, 16, 32)   0           add_174[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_385 (Conv2D)             (None, 8, 8, 64)     18496       activation_361[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_362 (BatchN (None, 8, 8, 64)     256         conv2d_385[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_362 (Activation)     (None, 8, 8, 64)     0           batch_normalization_362[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_386 (Conv2D)             (None, 8, 8, 64)     36928       activation_362[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_387 (Conv2D)             (None, 8, 8, 64)     2112        activation_361[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_363 (BatchN (None, 8, 8, 64)     256         conv2d_386[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_175 (Add)                   (None, 8, 8, 64)     0           conv2d_387[0][0]                 \n",
            "                                                                 batch_normalization_363[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_363 (Activation)     (None, 8, 8, 64)     0           add_175[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_388 (Conv2D)             (None, 8, 8, 64)     36928       activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_364 (BatchN (None, 8, 8, 64)     256         conv2d_388[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_364 (Activation)     (None, 8, 8, 64)     0           batch_normalization_364[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_389 (Conv2D)             (None, 8, 8, 64)     36928       activation_364[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_365 (BatchN (None, 8, 8, 64)     256         conv2d_389[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_176 (Add)                   (None, 8, 8, 64)     0           activation_363[0][0]             \n",
            "                                                                 batch_normalization_365[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_365 (Activation)     (None, 8, 8, 64)     0           add_176[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_390 (Conv2D)             (None, 8, 8, 64)     36928       activation_365[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_366 (BatchN (None, 8, 8, 64)     256         conv2d_390[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_366 (Activation)     (None, 8, 8, 64)     0           batch_normalization_366[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_391 (Conv2D)             (None, 8, 8, 64)     36928       activation_366[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_367 (BatchN (None, 8, 8, 64)     256         conv2d_391[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_177 (Add)                   (None, 8, 8, 64)     0           activation_365[0][0]             \n",
            "                                                                 batch_normalization_367[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_367 (Activation)     (None, 8, 8, 64)     0           add_177[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_392 (Conv2D)             (None, 8, 8, 64)     36928       activation_367[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_368 (BatchN (None, 8, 8, 64)     256         conv2d_392[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_368 (Activation)     (None, 8, 8, 64)     0           batch_normalization_368[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_393 (Conv2D)             (None, 8, 8, 64)     36928       activation_368[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_369 (BatchN (None, 8, 8, 64)     256         conv2d_393[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_178 (Add)                   (None, 8, 8, 64)     0           activation_367[0][0]             \n",
            "                                                                 batch_normalization_369[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_369 (Activation)     (None, 8, 8, 64)     0           add_178[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_394 (Conv2D)             (None, 8, 8, 64)     36928       activation_369[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_370 (BatchN (None, 8, 8, 64)     256         conv2d_394[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_370 (Activation)     (None, 8, 8, 64)     0           batch_normalization_370[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_395 (Conv2D)             (None, 8, 8, 64)     36928       activation_370[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_371 (BatchN (None, 8, 8, 64)     256         conv2d_395[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_179 (Add)                   (None, 8, 8, 64)     0           activation_369[0][0]             \n",
            "                                                                 batch_normalization_371[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_371 (Activation)     (None, 8, 8, 64)     0           add_179[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 1, 1, 64)     0           activation_371[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_11 (Flatten)            (None, 64)           0           average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 10)           650         flatten_11[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 470,218\n",
            "Trainable params: 467,946\n",
            "Non-trainable params: 2,272\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AMyYVSCTgqw",
        "outputId": "825abd80-3a1b-49f4-de7a-3775bd92507c"
      },
      "source": [
        "history = run_training(model, model_type, x_train, y_train, x_test, y_test,\r\n",
        "                       'trainHistoryDict', steps_per_epoch=100, epochs=250)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 92ms/step - loss: 2.8730 - acc: 0.2339 - val_loss: 2.6847 - val_acc: 0.1900\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.19000, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.7984 - acc: 0.4292 - val_loss: 2.6166 - val_acc: 0.1782\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.19000\n",
            "Epoch 3/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6379 - acc: 0.4905 - val_loss: 1.7994 - val_acc: 0.4398\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.19000 to 0.43980, saving model to /content/saved_models/cifar10_ResNet32v1_model.003.h5\n",
            "Epoch 4/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.5362 - acc: 0.5300 - val_loss: 2.0058 - val_acc: 0.4026\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.43980\n",
            "Epoch 5/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.4690 - acc: 0.5618 - val_loss: 1.6813 - val_acc: 0.4966\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.43980 to 0.49660, saving model to /content/saved_models/cifar10_ResNet32v1_model.005.h5\n",
            "Epoch 6/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.3902 - acc: 0.5808 - val_loss: 1.9608 - val_acc: 0.5056\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.49660 to 0.50560, saving model to /content/saved_models/cifar10_ResNet32v1_model.006.h5\n",
            "Epoch 7/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.3008 - acc: 0.6172 - val_loss: 1.6834 - val_acc: 0.5253\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.50560 to 0.52530, saving model to /content/saved_models/cifar10_ResNet32v1_model.007.h5\n",
            "Epoch 8/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.2292 - acc: 0.6443 - val_loss: 2.1359 - val_acc: 0.4488\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.52530\n",
            "Epoch 9/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.1695 - acc: 0.6648 - val_loss: 1.4525 - val_acc: 0.6021\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.52530 to 0.60210, saving model to /content/saved_models/cifar10_ResNet32v1_model.009.h5\n",
            "Epoch 10/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.1641 - acc: 0.6691 - val_loss: 2.1130 - val_acc: 0.4973\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.60210\n",
            "Epoch 11/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.0810 - acc: 0.7030 - val_loss: 1.6418 - val_acc: 0.5729\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.60210\n",
            "Epoch 12/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.0750 - acc: 0.7042 - val_loss: 1.5339 - val_acc: 0.5800\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.60210\n",
            "Epoch 13/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.0438 - acc: 0.7155 - val_loss: 1.3854 - val_acc: 0.6190\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.60210 to 0.61900, saving model to /content/saved_models/cifar10_ResNet32v1_model.013.h5\n",
            "Epoch 14/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.9992 - acc: 0.7293 - val_loss: 1.3072 - val_acc: 0.6324\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.61900 to 0.63240, saving model to /content/saved_models/cifar10_ResNet32v1_model.014.h5\n",
            "Epoch 15/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.0282 - acc: 0.7236 - val_loss: 1.0924 - val_acc: 0.6947\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.63240 to 0.69470, saving model to /content/saved_models/cifar10_ResNet32v1_model.015.h5\n",
            "Epoch 16/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.9563 - acc: 0.7342 - val_loss: 1.5952 - val_acc: 0.5972\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.69470\n",
            "Epoch 17/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.9534 - acc: 0.7433 - val_loss: 1.1213 - val_acc: 0.6969\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.69470 to 0.69690, saving model to /content/saved_models/cifar10_ResNet32v1_model.017.h5\n",
            "Epoch 18/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.9449 - acc: 0.7484 - val_loss: 1.1325 - val_acc: 0.6912\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.69690\n",
            "Epoch 19/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.9102 - acc: 0.7528 - val_loss: 1.3944 - val_acc: 0.6202\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.69690\n",
            "Epoch 20/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8891 - acc: 0.7589 - val_loss: 1.1840 - val_acc: 0.6674\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.69690\n",
            "Epoch 21/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8736 - acc: 0.7697 - val_loss: 1.0056 - val_acc: 0.7252\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.69690 to 0.72520, saving model to /content/saved_models/cifar10_ResNet32v1_model.021.h5\n",
            "Epoch 22/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8503 - acc: 0.7725 - val_loss: 1.0499 - val_acc: 0.7179\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.72520\n",
            "Epoch 23/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.8591 - acc: 0.7746 - val_loss: 1.2928 - val_acc: 0.6588\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.72520\n",
            "Epoch 24/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8481 - acc: 0.7790 - val_loss: 1.0748 - val_acc: 0.7083\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.72520\n",
            "Epoch 25/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.8215 - acc: 0.7856 - val_loss: 1.3550 - val_acc: 0.6407\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.72520\n",
            "Epoch 26/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8144 - acc: 0.7856 - val_loss: 0.9609 - val_acc: 0.7510\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.72520 to 0.75100, saving model to /content/saved_models/cifar10_ResNet32v1_model.026.h5\n",
            "Epoch 27/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7867 - acc: 0.7970 - val_loss: 1.0918 - val_acc: 0.7144\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.75100\n",
            "Epoch 28/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8038 - acc: 0.7993 - val_loss: 1.4271 - val_acc: 0.6258\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.75100\n",
            "Epoch 29/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7632 - acc: 0.8072 - val_loss: 1.5322 - val_acc: 0.6097\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.75100\n",
            "Epoch 30/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7754 - acc: 0.8006 - val_loss: 1.0870 - val_acc: 0.7115\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.75100\n",
            "Epoch 31/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7407 - acc: 0.8161 - val_loss: 0.9982 - val_acc: 0.7295\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.75100\n",
            "Epoch 32/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7393 - acc: 0.8136 - val_loss: 1.2434 - val_acc: 0.6830\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.75100\n",
            "Epoch 33/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.7443 - acc: 0.8118 - val_loss: 0.8928 - val_acc: 0.7721\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.75100 to 0.77210, saving model to /content/saved_models/cifar10_ResNet32v1_model.033.h5\n",
            "Epoch 34/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7539 - acc: 0.8098 - val_loss: 0.9156 - val_acc: 0.7557\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.77210\n",
            "Epoch 35/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7249 - acc: 0.8202 - val_loss: 0.9805 - val_acc: 0.7505\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.77210\n",
            "Epoch 36/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7152 - acc: 0.8272 - val_loss: 0.8478 - val_acc: 0.7836\n",
            "\n",
            "Epoch 00036: val_acc improved from 0.77210 to 0.78360, saving model to /content/saved_models/cifar10_ResNet32v1_model.036.h5\n",
            "Epoch 37/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7094 - acc: 0.8261 - val_loss: 1.1342 - val_acc: 0.7027\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.78360\n",
            "Epoch 38/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6867 - acc: 0.8363 - val_loss: 0.9967 - val_acc: 0.7408\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.78360\n",
            "Epoch 39/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7017 - acc: 0.8328 - val_loss: 0.8662 - val_acc: 0.7819\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.78360\n",
            "Epoch 40/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6970 - acc: 0.8247 - val_loss: 0.9175 - val_acc: 0.7625\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.78360\n",
            "Epoch 41/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6893 - acc: 0.8282 - val_loss: 1.1844 - val_acc: 0.7093\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.78360\n",
            "Epoch 42/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6929 - acc: 0.8306 - val_loss: 0.9455 - val_acc: 0.7563\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.78360\n",
            "Epoch 43/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6929 - acc: 0.8309 - val_loss: 0.8888 - val_acc: 0.7724\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.78360\n",
            "Epoch 44/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6619 - acc: 0.8380 - val_loss: 0.8754 - val_acc: 0.7789\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.78360\n",
            "Epoch 45/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6532 - acc: 0.8404 - val_loss: 1.1669 - val_acc: 0.7081\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.78360\n",
            "Epoch 46/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6669 - acc: 0.8367 - val_loss: 0.8792 - val_acc: 0.7740\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.78360\n",
            "Epoch 47/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6411 - acc: 0.8469 - val_loss: 0.8732 - val_acc: 0.7779\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.78360\n",
            "Epoch 48/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6322 - acc: 0.8460 - val_loss: 0.9292 - val_acc: 0.7654\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.78360\n",
            "Epoch 49/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6348 - acc: 0.8488 - val_loss: 0.9932 - val_acc: 0.7474\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.78360\n",
            "Epoch 50/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6331 - acc: 0.8469 - val_loss: 1.0196 - val_acc: 0.7423\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.78360\n",
            "Epoch 51/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6258 - acc: 0.8518 - val_loss: 0.9233 - val_acc: 0.7624\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.78360\n",
            "Epoch 52/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6259 - acc: 0.8509 - val_loss: 0.9631 - val_acc: 0.7583\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.78360\n",
            "Epoch 53/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6161 - acc: 0.8534 - val_loss: 1.0844 - val_acc: 0.7314\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.78360\n",
            "Epoch 54/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6143 - acc: 0.8537 - val_loss: 0.9194 - val_acc: 0.7826\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.78360\n",
            "Epoch 55/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6123 - acc: 0.8549 - val_loss: 0.9664 - val_acc: 0.7563\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.78360\n",
            "Epoch 56/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6194 - acc: 0.8547 - val_loss: 0.8516 - val_acc: 0.7820\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.78360\n",
            "Epoch 57/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.6144 - acc: 0.8526 - val_loss: 0.7516 - val_acc: 0.8131\n",
            "\n",
            "Epoch 00057: val_acc improved from 0.78360 to 0.81310, saving model to /content/saved_models/cifar10_ResNet32v1_model.057.h5\n",
            "Epoch 58/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6056 - acc: 0.8605 - val_loss: 0.9568 - val_acc: 0.7663\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.81310\n",
            "Epoch 59/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5981 - acc: 0.8609 - val_loss: 0.9071 - val_acc: 0.7711\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.81310\n",
            "Epoch 60/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6006 - acc: 0.8567 - val_loss: 1.1408 - val_acc: 0.7230\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.81310\n",
            "Epoch 61/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5841 - acc: 0.8644 - val_loss: 0.9170 - val_acc: 0.7669\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.81310\n",
            "Epoch 62/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5837 - acc: 0.8659 - val_loss: 0.9296 - val_acc: 0.7700\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.81310\n",
            "Epoch 63/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5643 - acc: 0.8718 - val_loss: 1.3575 - val_acc: 0.7018\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.81310\n",
            "Epoch 64/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5683 - acc: 0.8703 - val_loss: 1.0273 - val_acc: 0.7434\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.81310\n",
            "Epoch 65/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5835 - acc: 0.8623 - val_loss: 0.8497 - val_acc: 0.7856\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.81310\n",
            "Epoch 66/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5694 - acc: 0.8707 - val_loss: 0.9124 - val_acc: 0.7766\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.81310\n",
            "Epoch 67/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5831 - acc: 0.8645 - val_loss: 1.0327 - val_acc: 0.7382\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.81310\n",
            "Epoch 68/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5729 - acc: 0.8738 - val_loss: 0.8913 - val_acc: 0.7743\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.81310\n",
            "Epoch 69/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5680 - acc: 0.8677 - val_loss: 0.8449 - val_acc: 0.7982\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.81310\n",
            "Epoch 70/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5591 - acc: 0.8737 - val_loss: 1.0931 - val_acc: 0.7397\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.81310\n",
            "Epoch 71/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5568 - acc: 0.8780 - val_loss: 0.9686 - val_acc: 0.7481\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.81310\n",
            "Epoch 72/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5667 - acc: 0.8714 - val_loss: 1.2771 - val_acc: 0.7118\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.81310\n",
            "Epoch 73/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5541 - acc: 0.8777 - val_loss: 0.8773 - val_acc: 0.7818\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.81310\n",
            "Epoch 74/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5601 - acc: 0.8730 - val_loss: 0.9342 - val_acc: 0.7687\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.81310\n",
            "Epoch 75/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5576 - acc: 0.8760 - val_loss: 1.0247 - val_acc: 0.7498\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.81310\n",
            "Epoch 76/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5616 - acc: 0.8725 - val_loss: 0.8178 - val_acc: 0.7991\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.81310\n",
            "Epoch 77/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5400 - acc: 0.8842 - val_loss: 0.9558 - val_acc: 0.7638\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.81310\n",
            "Epoch 78/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5399 - acc: 0.8804 - val_loss: 0.9327 - val_acc: 0.7769\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.81310\n",
            "Epoch 79/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5198 - acc: 0.8822 - val_loss: 0.7339 - val_acc: 0.8246\n",
            "\n",
            "Epoch 00079: val_acc improved from 0.81310 to 0.82460, saving model to /content/saved_models/cifar10_ResNet32v1_model.079.h5\n",
            "Epoch 80/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5437 - acc: 0.8798 - val_loss: 0.9973 - val_acc: 0.7661\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.82460\n",
            "Epoch 81/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5351 - acc: 0.8846 - val_loss: 0.9709 - val_acc: 0.7639\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.82460\n",
            "Epoch 82/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5107 - acc: 0.8896 - val_loss: 0.5933 - val_acc: 0.8681\n",
            "\n",
            "Epoch 00082: val_acc improved from 0.82460 to 0.86810, saving model to /content/saved_models/cifar10_ResNet32v1_model.082.h5\n",
            "Epoch 83/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4629 - acc: 0.9064 - val_loss: 0.5725 - val_acc: 0.8745\n",
            "\n",
            "Epoch 00083: val_acc improved from 0.86810 to 0.87450, saving model to /content/saved_models/cifar10_ResNet32v1_model.083.h5\n",
            "Epoch 84/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4384 - acc: 0.9139 - val_loss: 0.5747 - val_acc: 0.8728\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.87450\n",
            "Epoch 85/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4309 - acc: 0.9171 - val_loss: 0.5701 - val_acc: 0.8751\n",
            "\n",
            "Epoch 00085: val_acc improved from 0.87450 to 0.87510, saving model to /content/saved_models/cifar10_ResNet32v1_model.085.h5\n",
            "Epoch 86/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4144 - acc: 0.9208 - val_loss: 0.5684 - val_acc: 0.8752\n",
            "\n",
            "Epoch 00086: val_acc improved from 0.87510 to 0.87520, saving model to /content/saved_models/cifar10_ResNet32v1_model.086.h5\n",
            "Epoch 87/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4394 - acc: 0.9116 - val_loss: 0.5644 - val_acc: 0.8759\n",
            "\n",
            "Epoch 00087: val_acc improved from 0.87520 to 0.87590, saving model to /content/saved_models/cifar10_ResNet32v1_model.087.h5\n",
            "Epoch 88/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4219 - acc: 0.9213 - val_loss: 0.5720 - val_acc: 0.8744\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.87590\n",
            "Epoch 89/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4318 - acc: 0.9166 - val_loss: 0.5640 - val_acc: 0.8756\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.87590\n",
            "Epoch 90/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4270 - acc: 0.9213 - val_loss: 0.5780 - val_acc: 0.8709\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.87590\n",
            "Epoch 91/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4117 - acc: 0.9248 - val_loss: 0.5790 - val_acc: 0.8733\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.87590\n",
            "Epoch 92/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4114 - acc: 0.9249 - val_loss: 0.5704 - val_acc: 0.8758\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.87590\n",
            "Epoch 93/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4062 - acc: 0.9289 - val_loss: 0.5778 - val_acc: 0.8739\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.87590\n",
            "Epoch 94/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4070 - acc: 0.9239 - val_loss: 0.5714 - val_acc: 0.8747\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.87590\n",
            "Epoch 95/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3968 - acc: 0.9288 - val_loss: 0.5573 - val_acc: 0.8805\n",
            "\n",
            "Epoch 00095: val_acc improved from 0.87590 to 0.88050, saving model to /content/saved_models/cifar10_ResNet32v1_model.095.h5\n",
            "Epoch 96/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4009 - acc: 0.9275 - val_loss: 0.5534 - val_acc: 0.8810\n",
            "\n",
            "Epoch 00096: val_acc improved from 0.88050 to 0.88100, saving model to /content/saved_models/cifar10_ResNet32v1_model.096.h5\n",
            "Epoch 97/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4048 - acc: 0.9239 - val_loss: 0.5613 - val_acc: 0.8805\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.88100\n",
            "Epoch 98/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4031 - acc: 0.9255 - val_loss: 0.5509 - val_acc: 0.8822\n",
            "\n",
            "Epoch 00098: val_acc improved from 0.88100 to 0.88220, saving model to /content/saved_models/cifar10_ResNet32v1_model.098.h5\n",
            "Epoch 99/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4000 - acc: 0.9238 - val_loss: 0.5747 - val_acc: 0.8756\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.88220\n",
            "Epoch 100/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3858 - acc: 0.9278 - val_loss: 0.5614 - val_acc: 0.8782\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.88220\n",
            "Epoch 101/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3846 - acc: 0.9285 - val_loss: 0.5528 - val_acc: 0.8795\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.88220\n",
            "Epoch 102/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3866 - acc: 0.9313 - val_loss: 0.5605 - val_acc: 0.8804\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.88220\n",
            "Epoch 103/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3756 - acc: 0.9342 - val_loss: 0.5556 - val_acc: 0.8821\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.88220\n",
            "Epoch 104/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3928 - acc: 0.9263 - val_loss: 0.5457 - val_acc: 0.8827\n",
            "\n",
            "Epoch 00104: val_acc improved from 0.88220 to 0.88270, saving model to /content/saved_models/cifar10_ResNet32v1_model.104.h5\n",
            "Epoch 105/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3862 - acc: 0.9304 - val_loss: 0.5590 - val_acc: 0.8803\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.88270\n",
            "Epoch 106/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.3842 - acc: 0.9307 - val_loss: 0.5530 - val_acc: 0.8822\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.88270\n",
            "Epoch 107/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3772 - acc: 0.9342 - val_loss: 0.5665 - val_acc: 0.8788\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.88270\n",
            "Epoch 108/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3694 - acc: 0.9359 - val_loss: 0.5641 - val_acc: 0.8771\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.88270\n",
            "Epoch 109/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3696 - acc: 0.9333 - val_loss: 0.5731 - val_acc: 0.8751\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.88270\n",
            "Epoch 110/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3692 - acc: 0.9343 - val_loss: 0.5651 - val_acc: 0.8787\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.88270\n",
            "Epoch 111/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3678 - acc: 0.9345 - val_loss: 0.5492 - val_acc: 0.8809\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.88270\n",
            "Epoch 112/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3702 - acc: 0.9344 - val_loss: 0.5631 - val_acc: 0.8779\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.88270\n",
            "Epoch 113/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3744 - acc: 0.9325 - val_loss: 0.5607 - val_acc: 0.8800\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.88270\n",
            "Epoch 114/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3709 - acc: 0.9344 - val_loss: 0.5639 - val_acc: 0.8776\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.88270\n",
            "Epoch 115/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3767 - acc: 0.9326 - val_loss: 0.5712 - val_acc: 0.8736\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.88270\n",
            "Epoch 116/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3583 - acc: 0.9388 - val_loss: 0.5486 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00116: val_acc improved from 0.88270 to 0.88390, saving model to /content/saved_models/cifar10_ResNet32v1_model.116.h5\n",
            "Epoch 117/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3506 - acc: 0.9433 - val_loss: 0.5485 - val_acc: 0.8812\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.88390\n",
            "Epoch 118/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3681 - acc: 0.9334 - val_loss: 0.5608 - val_acc: 0.8788\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.88390\n",
            "Epoch 119/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3529 - acc: 0.9380 - val_loss: 0.5455 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.88390\n",
            "Epoch 120/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3626 - acc: 0.9341 - val_loss: 0.5654 - val_acc: 0.8798\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.88390\n",
            "Epoch 121/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3577 - acc: 0.9362 - val_loss: 0.5488 - val_acc: 0.8831\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.88390\n",
            "Epoch 122/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3515 - acc: 0.9366 - val_loss: 0.5415 - val_acc: 0.8860\n",
            "\n",
            "Epoch 00122: val_acc improved from 0.88390 to 0.88600, saving model to /content/saved_models/cifar10_ResNet32v1_model.122.h5\n",
            "Epoch 123/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3456 - acc: 0.9419 - val_loss: 0.5446 - val_acc: 0.8849\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.88600\n",
            "Epoch 124/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3515 - acc: 0.9391 - val_loss: 0.5418 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.88600\n",
            "Epoch 125/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3597 - acc: 0.9373 - val_loss: 0.5398 - val_acc: 0.8861\n",
            "\n",
            "Epoch 00125: val_acc improved from 0.88600 to 0.88610, saving model to /content/saved_models/cifar10_ResNet32v1_model.125.h5\n",
            "Epoch 126/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3473 - acc: 0.9428 - val_loss: 0.5410 - val_acc: 0.8862\n",
            "\n",
            "Epoch 00126: val_acc improved from 0.88610 to 0.88620, saving model to /content/saved_models/cifar10_ResNet32v1_model.126.h5\n",
            "Epoch 127/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3320 - acc: 0.9450 - val_loss: 0.5469 - val_acc: 0.8844\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.88620\n",
            "Epoch 128/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3568 - acc: 0.9373 - val_loss: 0.5415 - val_acc: 0.8857\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.88620\n",
            "Epoch 129/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3405 - acc: 0.9446 - val_loss: 0.5399 - val_acc: 0.8876\n",
            "\n",
            "Epoch 00129: val_acc improved from 0.88620 to 0.88760, saving model to /content/saved_models/cifar10_ResNet32v1_model.129.h5\n",
            "Epoch 130/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3558 - acc: 0.9382 - val_loss: 0.5407 - val_acc: 0.8876\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.88760\n",
            "Epoch 131/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3361 - acc: 0.9448 - val_loss: 0.5378 - val_acc: 0.8869\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.88760\n",
            "Epoch 132/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3471 - acc: 0.9429 - val_loss: 0.5391 - val_acc: 0.8868\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.88760\n",
            "Epoch 133/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3516 - acc: 0.9412 - val_loss: 0.5388 - val_acc: 0.8873\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.88760\n",
            "Epoch 134/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3404 - acc: 0.9413 - val_loss: 0.5410 - val_acc: 0.8862\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.88760\n",
            "Epoch 135/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3446 - acc: 0.9411 - val_loss: 0.5432 - val_acc: 0.8859\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.88760\n",
            "Epoch 136/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3353 - acc: 0.9477 - val_loss: 0.5373 - val_acc: 0.8876\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.88760\n",
            "Epoch 137/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3376 - acc: 0.9453 - val_loss: 0.5362 - val_acc: 0.8884\n",
            "\n",
            "Epoch 00137: val_acc improved from 0.88760 to 0.88840, saving model to /content/saved_models/cifar10_ResNet32v1_model.137.h5\n",
            "Epoch 138/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3361 - acc: 0.9437 - val_loss: 0.5383 - val_acc: 0.8872\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.88840\n",
            "Epoch 139/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3474 - acc: 0.9384 - val_loss: 0.5416 - val_acc: 0.8859\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.88840\n",
            "Epoch 140/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.3440 - acc: 0.9415 - val_loss: 0.5369 - val_acc: 0.8881\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.88840\n",
            "Epoch 141/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3407 - acc: 0.9437 - val_loss: 0.5372 - val_acc: 0.8874\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.88840\n",
            "Epoch 142/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3432 - acc: 0.9443 - val_loss: 0.5380 - val_acc: 0.8875\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.88840\n",
            "Epoch 143/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3340 - acc: 0.9467 - val_loss: 0.5363 - val_acc: 0.8882\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.88840\n",
            "Epoch 144/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.3393 - acc: 0.9438 - val_loss: 0.5393 - val_acc: 0.8874\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.88840\n",
            "Epoch 145/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3449 - acc: 0.9410 - val_loss: 0.5367 - val_acc: 0.8874\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.88840\n",
            "Epoch 146/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3464 - acc: 0.9425 - val_loss: 0.5403 - val_acc: 0.8866\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.88840\n",
            "Epoch 147/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3316 - acc: 0.9449 - val_loss: 0.5374 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00147: val_acc improved from 0.88840 to 0.88900, saving model to /content/saved_models/cifar10_ResNet32v1_model.147.h5\n",
            "Epoch 148/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3442 - acc: 0.9392 - val_loss: 0.5365 - val_acc: 0.8883\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.88900\n",
            "Epoch 149/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3432 - acc: 0.9418 - val_loss: 0.5344 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.88900\n",
            "Epoch 150/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3300 - acc: 0.9482 - val_loss: 0.5350 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00150: val_acc improved from 0.88900 to 0.88920, saving model to /content/saved_models/cifar10_ResNet32v1_model.150.h5\n",
            "Epoch 151/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3339 - acc: 0.9476 - val_loss: 0.5356 - val_acc: 0.8893\n",
            "\n",
            "Epoch 00151: val_acc improved from 0.88920 to 0.88930, saving model to /content/saved_models/cifar10_ResNet32v1_model.151.h5\n",
            "Epoch 152/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3450 - acc: 0.9397 - val_loss: 0.5383 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.88930\n",
            "Epoch 153/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3390 - acc: 0.9445 - val_loss: 0.5384 - val_acc: 0.8884\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.88930\n",
            "Epoch 154/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3420 - acc: 0.9395 - val_loss: 0.5370 - val_acc: 0.8887\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.88930\n",
            "Epoch 155/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3397 - acc: 0.9404 - val_loss: 0.5347 - val_acc: 0.8901\n",
            "\n",
            "Epoch 00155: val_acc improved from 0.88930 to 0.89010, saving model to /content/saved_models/cifar10_ResNet32v1_model.155.h5\n",
            "Epoch 156/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3387 - acc: 0.9456 - val_loss: 0.5376 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.89010\n",
            "Epoch 157/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3432 - acc: 0.9448 - val_loss: 0.5396 - val_acc: 0.8878\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.89010\n",
            "Epoch 158/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3320 - acc: 0.9451 - val_loss: 0.5363 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.89010\n",
            "Epoch 159/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3386 - acc: 0.9417 - val_loss: 0.5356 - val_acc: 0.8893\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.89010\n",
            "Epoch 160/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3296 - acc: 0.9459 - val_loss: 0.5378 - val_acc: 0.8877\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.89010\n",
            "Epoch 161/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3355 - acc: 0.9433 - val_loss: 0.5356 - val_acc: 0.8884\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.89010\n",
            "Epoch 162/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3388 - acc: 0.9426 - val_loss: 0.5369 - val_acc: 0.8884\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.89010\n",
            "Epoch 163/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3424 - acc: 0.9447 - val_loss: 0.5366 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.89010\n",
            "Epoch 164/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3332 - acc: 0.9466 - val_loss: 0.5364 - val_acc: 0.8887\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.89010\n",
            "Epoch 165/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3300 - acc: 0.9468 - val_loss: 0.5362 - val_acc: 0.8891\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.89010\n",
            "Epoch 166/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3385 - acc: 0.9431 - val_loss: 0.5363 - val_acc: 0.8884\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.89010\n",
            "Epoch 167/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3397 - acc: 0.9427 - val_loss: 0.5371 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.89010\n",
            "Epoch 168/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3355 - acc: 0.9478 - val_loss: 0.5375 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.89010\n",
            "Epoch 169/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.3407 - acc: 0.9422 - val_loss: 0.5374 - val_acc: 0.8887\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.89010\n",
            "Epoch 170/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3310 - acc: 0.9461 - val_loss: 0.5367 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.89010\n",
            "Epoch 171/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3451 - acc: 0.9430 - val_loss: 0.5380 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.89010\n",
            "Epoch 172/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3452 - acc: 0.9438 - val_loss: 0.5374 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.89010\n",
            "Epoch 173/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3376 - acc: 0.9469 - val_loss: 0.5370 - val_acc: 0.8882\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.89010\n",
            "Epoch 174/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3385 - acc: 0.9414 - val_loss: 0.5371 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.89010\n",
            "Epoch 175/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3330 - acc: 0.9483 - val_loss: 0.5369 - val_acc: 0.8884\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.89010\n",
            "Epoch 176/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3347 - acc: 0.9454 - val_loss: 0.5355 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.89010\n",
            "Epoch 177/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3391 - acc: 0.9455 - val_loss: 0.5356 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.89010\n",
            "Epoch 178/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3273 - acc: 0.9493 - val_loss: 0.5367 - val_acc: 0.8891\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.89010\n",
            "Epoch 179/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3394 - acc: 0.9456 - val_loss: 0.5364 - val_acc: 0.8883\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.89010\n",
            "Epoch 180/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3381 - acc: 0.9453 - val_loss: 0.5361 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.89010\n",
            "Epoch 181/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.3337 - acc: 0.9446 - val_loss: 0.5365 - val_acc: 0.8881\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.89010\n",
            "Epoch 182/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3430 - acc: 0.9389 - val_loss: 0.5357 - val_acc: 0.8891\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.89010\n",
            "Epoch 183/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3278 - acc: 0.9501 - val_loss: 0.5363 - val_acc: 0.8891\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.89010\n",
            "Epoch 184/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3354 - acc: 0.9465 - val_loss: 0.5365 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.89010\n",
            "Epoch 185/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3398 - acc: 0.9423 - val_loss: 0.5368 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.89010\n",
            "Epoch 186/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3249 - acc: 0.9480 - val_loss: 0.5364 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.89010\n",
            "Epoch 187/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3323 - acc: 0.9468 - val_loss: 0.5363 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.89010\n",
            "Epoch 188/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3454 - acc: 0.9406 - val_loss: 0.5358 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.89010\n",
            "Epoch 189/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.3362 - acc: 0.9459 - val_loss: 0.5354 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.89010\n",
            "Epoch 190/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3294 - acc: 0.9499 - val_loss: 0.5360 - val_acc: 0.8891\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.89010\n",
            "Epoch 191/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3311 - acc: 0.9474 - val_loss: 0.5360 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.89010\n",
            "Epoch 192/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3381 - acc: 0.9442 - val_loss: 0.5362 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.89010\n",
            "Epoch 193/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3378 - acc: 0.9457 - val_loss: 0.5357 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.89010\n",
            "Epoch 194/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3337 - acc: 0.9449 - val_loss: 0.5352 - val_acc: 0.8896\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.89010\n",
            "Epoch 195/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3374 - acc: 0.9422 - val_loss: 0.5355 - val_acc: 0.8899\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.89010\n",
            "Epoch 196/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3377 - acc: 0.9447 - val_loss: 0.5352 - val_acc: 0.8898\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.89010\n",
            "Epoch 197/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3365 - acc: 0.9473 - val_loss: 0.5358 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.89010\n",
            "Epoch 198/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3357 - acc: 0.9430 - val_loss: 0.5363 - val_acc: 0.8891\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.89010\n",
            "Epoch 199/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3303 - acc: 0.9473 - val_loss: 0.5366 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.89010\n",
            "Epoch 200/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3438 - acc: 0.9403 - val_loss: 0.5351 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.89010\n",
            "Epoch 201/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3367 - acc: 0.9430 - val_loss: 0.5361 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.89010\n",
            "Epoch 202/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3384 - acc: 0.9444 - val_loss: 0.5362 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.89010\n",
            "Epoch 203/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3359 - acc: 0.9447 - val_loss: 0.5372 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.89010\n",
            "Epoch 204/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3353 - acc: 0.9433 - val_loss: 0.5366 - val_acc: 0.8895\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.89010\n",
            "Epoch 205/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.3369 - acc: 0.9429 - val_loss: 0.5370 - val_acc: 0.8895\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.89010\n",
            "Epoch 206/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3398 - acc: 0.9397 - val_loss: 0.5361 - val_acc: 0.8897\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.89010\n",
            "Epoch 207/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3364 - acc: 0.9418 - val_loss: 0.5364 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.89010\n",
            "Epoch 208/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3289 - acc: 0.9488 - val_loss: 0.5361 - val_acc: 0.8897\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.89010\n",
            "Epoch 209/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3452 - acc: 0.9398 - val_loss: 0.5362 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.89010\n",
            "Epoch 210/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3366 - acc: 0.9459 - val_loss: 0.5356 - val_acc: 0.8896\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.89010\n",
            "Epoch 211/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3407 - acc: 0.9428 - val_loss: 0.5346 - val_acc: 0.8896\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.89010\n",
            "Epoch 212/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3456 - acc: 0.9384 - val_loss: 0.5341 - val_acc: 0.8891\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.89010\n",
            "Epoch 213/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3463 - acc: 0.9403 - val_loss: 0.5347 - val_acc: 0.8893\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.89010\n",
            "Epoch 214/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3282 - acc: 0.9445 - val_loss: 0.5347 - val_acc: 0.8893\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.89010\n",
            "Epoch 215/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3339 - acc: 0.9452 - val_loss: 0.5353 - val_acc: 0.8897\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.89010\n",
            "Epoch 216/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3410 - acc: 0.9410 - val_loss: 0.5345 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.89010\n",
            "Epoch 217/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.3525 - acc: 0.9387 - val_loss: 0.5367 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.89010\n",
            "Epoch 218/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.3365 - acc: 0.9442 - val_loss: 0.5364 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.89010\n",
            "Epoch 219/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3447 - acc: 0.9387 - val_loss: 0.5354 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.89010\n",
            "Epoch 220/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3367 - acc: 0.9446 - val_loss: 0.5356 - val_acc: 0.8895\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.89010\n",
            "Epoch 221/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3340 - acc: 0.9434 - val_loss: 0.5352 - val_acc: 0.8899\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.89010\n",
            "Epoch 222/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3350 - acc: 0.9432 - val_loss: 0.5350 - val_acc: 0.8899\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.89010\n",
            "Epoch 223/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3333 - acc: 0.9421 - val_loss: 0.5357 - val_acc: 0.8895\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.89010\n",
            "Epoch 224/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3421 - acc: 0.9430 - val_loss: 0.5364 - val_acc: 0.8895\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.89010\n",
            "Epoch 225/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3397 - acc: 0.9418 - val_loss: 0.5360 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.89010\n",
            "Epoch 226/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3327 - acc: 0.9444 - val_loss: 0.5363 - val_acc: 0.8896\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.89010\n",
            "Epoch 227/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.3362 - acc: 0.9437 - val_loss: 0.5359 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.89010\n",
            "Epoch 228/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3382 - acc: 0.9457 - val_loss: 0.5364 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.89010\n",
            "Epoch 229/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3392 - acc: 0.9444 - val_loss: 0.5363 - val_acc: 0.8897\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.89010\n",
            "Epoch 230/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3272 - acc: 0.9481 - val_loss: 0.5366 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.89010\n",
            "Epoch 231/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3278 - acc: 0.9464 - val_loss: 0.5354 - val_acc: 0.8893\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.89010\n",
            "Epoch 232/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3405 - acc: 0.9406 - val_loss: 0.5349 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.89010\n",
            "Epoch 233/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3368 - acc: 0.9451 - val_loss: 0.5346 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.89010\n",
            "Epoch 234/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3294 - acc: 0.9471 - val_loss: 0.5355 - val_acc: 0.8897\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.89010\n",
            "Epoch 235/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3299 - acc: 0.9458 - val_loss: 0.5347 - val_acc: 0.8903\n",
            "\n",
            "Epoch 00235: val_acc improved from 0.89010 to 0.89030, saving model to /content/saved_models/cifar10_ResNet32v1_model.235.h5\n",
            "Epoch 236/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.3485 - acc: 0.9412 - val_loss: 0.5349 - val_acc: 0.8897\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.89030\n",
            "Epoch 237/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.3412 - acc: 0.9422 - val_loss: 0.5359 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.89030\n",
            "Epoch 238/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3464 - acc: 0.9423 - val_loss: 0.5362 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.89030\n",
            "Epoch 239/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3352 - acc: 0.9448 - val_loss: 0.5359 - val_acc: 0.8895\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.89030\n",
            "Epoch 240/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3348 - acc: 0.9439 - val_loss: 0.5353 - val_acc: 0.8892\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.89030\n",
            "Epoch 241/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3414 - acc: 0.9409 - val_loss: 0.5349 - val_acc: 0.8895\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.89030\n",
            "Epoch 242/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.3364 - acc: 0.9442 - val_loss: 0.5359 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.89030\n",
            "Epoch 243/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3366 - acc: 0.9436 - val_loss: 0.5362 - val_acc: 0.8896\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.89030\n",
            "Epoch 244/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3216 - acc: 0.9480 - val_loss: 0.5349 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.89030\n",
            "Epoch 245/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.3386 - acc: 0.9436 - val_loss: 0.5355 - val_acc: 0.8902\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.89030\n",
            "Epoch 246/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.3370 - acc: 0.9439 - val_loss: 0.5353 - val_acc: 0.8904\n",
            "\n",
            "Epoch 00246: val_acc improved from 0.89030 to 0.89040, saving model to /content/saved_models/cifar10_ResNet32v1_model.246.h5\n",
            "Epoch 247/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3283 - acc: 0.9486 - val_loss: 0.5355 - val_acc: 0.8899\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.89040\n",
            "Epoch 248/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3426 - acc: 0.9400 - val_loss: 0.5352 - val_acc: 0.8898\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.89040\n",
            "Epoch 249/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.3352 - acc: 0.9407 - val_loss: 0.5355 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.89040\n",
            "Epoch 250/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.3369 - acc: 0.9444 - val_loss: 0.5342 - val_acc: 0.8902\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.89040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "yqJwFv3RxH1_",
        "outputId": "d88d8cb1-668f-4adc-ad53-2fd068c75b1c"
      },
      "source": [
        "import pickle\r\n",
        "\r\n",
        "history = pickle.load(open('trainHistoryDict', \"rb\"))\r\n",
        "plot_loss_acc(history)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwDRMeXAFWQ1",
        "outputId": "a5b6c73f-2508-4eae-a06c-ecd406beda3d"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10979998111724854"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNdHB-BBk6tR"
      },
      "source": [
        "### Model with clipping to 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UULpxYtilHlR",
        "outputId": "5f9c9bf9-56d9-49ef-e55c-a71bf3a0e8dc"
      },
      "source": [
        "model, model_type = define_and_compile_ResNet_model()\r\n",
        "\r\n",
        "# enable this if pydot can be installed\r\n",
        "# plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\r\n",
        "# print(model_type)\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_330 (Conv2D)             (None, 32, 32, 16)   448         input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_310 (BatchN (None, 32, 32, 16)   64          conv2d_330[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, 32, 32, 16)   0           batch_normalization_310[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_331 (Conv2D)             (None, 32, 32, 16)   2320        activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_311 (BatchN (None, 32, 32, 16)   64          conv2d_331[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, 32, 32, 16)   0           batch_normalization_311[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_332 (Conv2D)             (None, 32, 32, 16)   2320        activation_311[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_312 (BatchN (None, 32, 32, 16)   64          conv2d_332[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_150 (Add)                   (None, 32, 32, 16)   0           activation_310[0][0]             \n",
            "                                                                 batch_normalization_312[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 32, 32, 16)   0           add_150[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_333 (Conv2D)             (None, 32, 32, 16)   2320        activation_312[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_313 (BatchN (None, 32, 32, 16)   64          conv2d_333[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, 32, 32, 16)   0           batch_normalization_313[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_334 (Conv2D)             (None, 32, 32, 16)   2320        activation_313[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_314 (BatchN (None, 32, 32, 16)   64          conv2d_334[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_151 (Add)                   (None, 32, 32, 16)   0           activation_312[0][0]             \n",
            "                                                                 batch_normalization_314[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 32, 32, 16)   0           add_151[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_335 (Conv2D)             (None, 32, 32, 16)   2320        activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_315 (BatchN (None, 32, 32, 16)   64          conv2d_335[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 32, 32, 16)   0           batch_normalization_315[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_336 (Conv2D)             (None, 32, 32, 16)   2320        activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_316 (BatchN (None, 32, 32, 16)   64          conv2d_336[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_152 (Add)                   (None, 32, 32, 16)   0           activation_314[0][0]             \n",
            "                                                                 batch_normalization_316[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 32, 32, 16)   0           add_152[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_337 (Conv2D)             (None, 32, 32, 16)   2320        activation_316[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_317 (BatchN (None, 32, 32, 16)   64          conv2d_337[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 32, 32, 16)   0           batch_normalization_317[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_338 (Conv2D)             (None, 32, 32, 16)   2320        activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_318 (BatchN (None, 32, 32, 16)   64          conv2d_338[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_153 (Add)                   (None, 32, 32, 16)   0           activation_316[0][0]             \n",
            "                                                                 batch_normalization_318[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 32, 32, 16)   0           add_153[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_339 (Conv2D)             (None, 32, 32, 16)   2320        activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_319 (BatchN (None, 32, 32, 16)   64          conv2d_339[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 32, 32, 16)   0           batch_normalization_319[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_340 (Conv2D)             (None, 32, 32, 16)   2320        activation_319[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_320 (BatchN (None, 32, 32, 16)   64          conv2d_340[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_154 (Add)                   (None, 32, 32, 16)   0           activation_318[0][0]             \n",
            "                                                                 batch_normalization_320[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 32, 32, 16)   0           add_154[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_341 (Conv2D)             (None, 16, 16, 32)   4640        activation_320[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_321 (BatchN (None, 16, 16, 32)   128         conv2d_341[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, 16, 16, 32)   0           batch_normalization_321[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_342 (Conv2D)             (None, 16, 16, 32)   9248        activation_321[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_343 (Conv2D)             (None, 16, 16, 32)   544         activation_320[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_322 (BatchN (None, 16, 16, 32)   128         conv2d_342[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_155 (Add)                   (None, 16, 16, 32)   0           conv2d_343[0][0]                 \n",
            "                                                                 batch_normalization_322[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, 16, 16, 32)   0           add_155[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_344 (Conv2D)             (None, 16, 16, 32)   9248        activation_322[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_323 (BatchN (None, 16, 16, 32)   128         conv2d_344[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, 16, 16, 32)   0           batch_normalization_323[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_345 (Conv2D)             (None, 16, 16, 32)   9248        activation_323[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_324 (BatchN (None, 16, 16, 32)   128         conv2d_345[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_156 (Add)                   (None, 16, 16, 32)   0           activation_322[0][0]             \n",
            "                                                                 batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, 16, 16, 32)   0           add_156[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_346 (Conv2D)             (None, 16, 16, 32)   9248        activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_325 (BatchN (None, 16, 16, 32)   128         conv2d_346[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_325 (Activation)     (None, 16, 16, 32)   0           batch_normalization_325[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_347 (Conv2D)             (None, 16, 16, 32)   9248        activation_325[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_326 (BatchN (None, 16, 16, 32)   128         conv2d_347[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_157 (Add)                   (None, 16, 16, 32)   0           activation_324[0][0]             \n",
            "                                                                 batch_normalization_326[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_326 (Activation)     (None, 16, 16, 32)   0           add_157[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_348 (Conv2D)             (None, 16, 16, 32)   9248        activation_326[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_327 (BatchN (None, 16, 16, 32)   128         conv2d_348[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_327 (Activation)     (None, 16, 16, 32)   0           batch_normalization_327[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_349 (Conv2D)             (None, 16, 16, 32)   9248        activation_327[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_328 (BatchN (None, 16, 16, 32)   128         conv2d_349[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_158 (Add)                   (None, 16, 16, 32)   0           activation_326[0][0]             \n",
            "                                                                 batch_normalization_328[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_328 (Activation)     (None, 16, 16, 32)   0           add_158[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_350 (Conv2D)             (None, 16, 16, 32)   9248        activation_328[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_329 (BatchN (None, 16, 16, 32)   128         conv2d_350[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_329 (Activation)     (None, 16, 16, 32)   0           batch_normalization_329[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_351 (Conv2D)             (None, 16, 16, 32)   9248        activation_329[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_330 (BatchN (None, 16, 16, 32)   128         conv2d_351[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_159 (Add)                   (None, 16, 16, 32)   0           activation_328[0][0]             \n",
            "                                                                 batch_normalization_330[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_330 (Activation)     (None, 16, 16, 32)   0           add_159[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_352 (Conv2D)             (None, 8, 8, 64)     18496       activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_331 (BatchN (None, 8, 8, 64)     256         conv2d_352[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_331 (Activation)     (None, 8, 8, 64)     0           batch_normalization_331[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_353 (Conv2D)             (None, 8, 8, 64)     36928       activation_331[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_354 (Conv2D)             (None, 8, 8, 64)     2112        activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_332 (BatchN (None, 8, 8, 64)     256         conv2d_353[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_160 (Add)                   (None, 8, 8, 64)     0           conv2d_354[0][0]                 \n",
            "                                                                 batch_normalization_332[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_332 (Activation)     (None, 8, 8, 64)     0           add_160[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_355 (Conv2D)             (None, 8, 8, 64)     36928       activation_332[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_333 (BatchN (None, 8, 8, 64)     256         conv2d_355[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_333 (Activation)     (None, 8, 8, 64)     0           batch_normalization_333[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_356 (Conv2D)             (None, 8, 8, 64)     36928       activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_334 (BatchN (None, 8, 8, 64)     256         conv2d_356[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_161 (Add)                   (None, 8, 8, 64)     0           activation_332[0][0]             \n",
            "                                                                 batch_normalization_334[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_334 (Activation)     (None, 8, 8, 64)     0           add_161[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_357 (Conv2D)             (None, 8, 8, 64)     36928       activation_334[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_335 (BatchN (None, 8, 8, 64)     256         conv2d_357[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_335 (Activation)     (None, 8, 8, 64)     0           batch_normalization_335[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_358 (Conv2D)             (None, 8, 8, 64)     36928       activation_335[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_336 (BatchN (None, 8, 8, 64)     256         conv2d_358[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_162 (Add)                   (None, 8, 8, 64)     0           activation_334[0][0]             \n",
            "                                                                 batch_normalization_336[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_336 (Activation)     (None, 8, 8, 64)     0           add_162[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_359 (Conv2D)             (None, 8, 8, 64)     36928       activation_336[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_337 (BatchN (None, 8, 8, 64)     256         conv2d_359[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_337 (Activation)     (None, 8, 8, 64)     0           batch_normalization_337[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_360 (Conv2D)             (None, 8, 8, 64)     36928       activation_337[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_338 (BatchN (None, 8, 8, 64)     256         conv2d_360[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_163 (Add)                   (None, 8, 8, 64)     0           activation_336[0][0]             \n",
            "                                                                 batch_normalization_338[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_338 (Activation)     (None, 8, 8, 64)     0           add_163[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_361 (Conv2D)             (None, 8, 8, 64)     36928       activation_338[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_339 (BatchN (None, 8, 8, 64)     256         conv2d_361[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_339 (Activation)     (None, 8, 8, 64)     0           batch_normalization_339[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_362 (Conv2D)             (None, 8, 8, 64)     36928       activation_339[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_340 (BatchN (None, 8, 8, 64)     256         conv2d_362[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_164 (Add)                   (None, 8, 8, 64)     0           activation_338[0][0]             \n",
            "                                                                 batch_normalization_340[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_340 (Activation)     (None, 8, 8, 64)     0           add_164[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 1, 1, 64)     0           activation_340[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_10 (Flatten)            (None, 64)           0           average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 10)           650         flatten_10[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 470,218\n",
            "Trainable params: 467,946\n",
            "Non-trainable params: 2,272\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXrPF2J6WWiL"
      },
      "source": [
        "singular_values_clipping = LambdaCallback(on_epoch_end = afterEpochClipTo05)\r\n",
        "callbacks = standard_callbacks(model_type) + [singular_values_clipping]"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THwkiS3tlRHw",
        "outputId": "201cdfb0-6c85-4cd7-9560-39fc107a4e63"
      },
      "source": [
        "history = run_training(model, model_type, x_train, y_train, x_test, y_test,\r\n",
        "                       'trainHistoryDict_clip_05', steps_per_epoch=100, epochs=250,\r\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 91ms/step - loss: 2.6063 - acc: 0.2643 - val_loss: 2.3301 - val_acc: 0.2673\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.26730, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.9281 - acc: 0.2893 - val_loss: 2.9392 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.26730\n",
            "Epoch 3/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.6299 - acc: 0.4081 - val_loss: 3.6542 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.26730\n",
            "Epoch 4/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 1.4266 - acc: 0.4920 - val_loss: 3.9285 - val_acc: 0.1553\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.26730\n",
            "Epoch 5/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.3233 - acc: 0.5302 - val_loss: 3.2044 - val_acc: 0.1964\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.26730\n",
            "Epoch 6/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 1.2454 - acc: 0.5556 - val_loss: 3.3517 - val_acc: 0.3039\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.26730 to 0.30390, saving model to /content/saved_models/cifar10_ResNet32v1_model.006.h5\n",
            "Epoch 7/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.1579 - acc: 0.5945 - val_loss: 2.6228 - val_acc: 0.3943\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.30390 to 0.39430, saving model to /content/saved_models/cifar10_ResNet32v1_model.007.h5\n",
            "Epoch 8/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.1183 - acc: 0.6043 - val_loss: 4.3403 - val_acc: 0.3125\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.39430\n",
            "Epoch 9/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.0763 - acc: 0.6274 - val_loss: 2.2795 - val_acc: 0.4480\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.39430 to 0.44800, saving model to /content/saved_models/cifar10_ResNet32v1_model.009.h5\n",
            "Epoch 10/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.0468 - acc: 0.6336 - val_loss: 4.8069 - val_acc: 0.2942\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.44800\n",
            "Epoch 11/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.0078 - acc: 0.6483 - val_loss: 2.3515 - val_acc: 0.4222\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.44800\n",
            "Epoch 12/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.0153 - acc: 0.6467 - val_loss: 3.5922 - val_acc: 0.3437\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.44800\n",
            "Epoch 13/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.9892 - acc: 0.6630 - val_loss: 3.5598 - val_acc: 0.4033\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.44800\n",
            "Epoch 14/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.9659 - acc: 0.6668 - val_loss: 5.9507 - val_acc: 0.2941\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.44800\n",
            "Epoch 15/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.9117 - acc: 0.6829 - val_loss: 1.4674 - val_acc: 0.5671\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.44800 to 0.56710, saving model to /content/saved_models/cifar10_ResNet32v1_model.015.h5\n",
            "Epoch 16/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.9150 - acc: 0.6866 - val_loss: 3.2662 - val_acc: 0.4132\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.56710\n",
            "Epoch 17/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.8710 - acc: 0.7030 - val_loss: 1.8799 - val_acc: 0.5515\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.56710\n",
            "Epoch 18/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.9041 - acc: 0.6859 - val_loss: 2.7854 - val_acc: 0.4344\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.56710\n",
            "Epoch 19/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.8381 - acc: 0.7199 - val_loss: 3.1375 - val_acc: 0.3561\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.56710\n",
            "Epoch 20/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8796 - acc: 0.7011 - val_loss: 3.3311 - val_acc: 0.3873\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.56710\n",
            "Epoch 21/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.8278 - acc: 0.7196 - val_loss: 2.7932 - val_acc: 0.4855\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.56710\n",
            "Epoch 22/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.8410 - acc: 0.7189 - val_loss: 1.8825 - val_acc: 0.5479\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.56710\n",
            "Epoch 23/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8037 - acc: 0.7286 - val_loss: 2.1477 - val_acc: 0.4702\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.56710\n",
            "Epoch 24/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.8231 - acc: 0.7230 - val_loss: 2.2638 - val_acc: 0.5183\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.56710\n",
            "Epoch 25/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.8505 - acc: 0.7118 - val_loss: 1.2146 - val_acc: 0.6418\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.56710 to 0.64180, saving model to /content/saved_models/cifar10_ResNet32v1_model.025.h5\n",
            "Epoch 26/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7966 - acc: 0.7282 - val_loss: 1.7461 - val_acc: 0.5611\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.64180\n",
            "Epoch 27/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7853 - acc: 0.7365 - val_loss: 1.2387 - val_acc: 0.6567\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.64180 to 0.65670, saving model to /content/saved_models/cifar10_ResNet32v1_model.027.h5\n",
            "Epoch 28/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7914 - acc: 0.7296 - val_loss: 2.5496 - val_acc: 0.5030\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.65670\n",
            "Epoch 29/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7923 - acc: 0.7307 - val_loss: 1.8803 - val_acc: 0.5509\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.65670\n",
            "Epoch 30/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.7693 - acc: 0.7320 - val_loss: 3.8976 - val_acc: 0.4132\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.65670\n",
            "Epoch 31/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7755 - acc: 0.7375 - val_loss: 5.8177 - val_acc: 0.3039\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.65670\n",
            "Epoch 32/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7653 - acc: 0.7374 - val_loss: 8.6054 - val_acc: 0.2358\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.65670\n",
            "Epoch 33/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7642 - acc: 0.7356 - val_loss: 5.5096 - val_acc: 0.3402\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.65670\n",
            "Epoch 34/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7654 - acc: 0.7409 - val_loss: 10.8354 - val_acc: 0.2154\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.65670\n",
            "Epoch 35/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7536 - acc: 0.7450 - val_loss: 2.4501 - val_acc: 0.5198\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.65670\n",
            "Epoch 36/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.7688 - acc: 0.7444 - val_loss: 2.4166 - val_acc: 0.5020\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.65670\n",
            "Epoch 37/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7131 - acc: 0.7556 - val_loss: 6.2322 - val_acc: 0.3197\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.65670\n",
            "Epoch 38/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.7627 - acc: 0.7380 - val_loss: 1.8315 - val_acc: 0.5949\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.65670\n",
            "Epoch 39/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7552 - acc: 0.7406 - val_loss: 3.5161 - val_acc: 0.4381\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.65670\n",
            "Epoch 40/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.7394 - acc: 0.7520 - val_loss: 6.0429 - val_acc: 0.2836\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.65670\n",
            "Epoch 41/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7033 - acc: 0.7675 - val_loss: 5.1141 - val_acc: 0.3225\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.65670\n",
            "Epoch 42/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7357 - acc: 0.7462 - val_loss: 5.1427 - val_acc: 0.3382\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.65670\n",
            "Epoch 43/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7063 - acc: 0.7574 - val_loss: 2.3221 - val_acc: 0.5001\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.65670\n",
            "Epoch 44/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7250 - acc: 0.7540 - val_loss: 2.1644 - val_acc: 0.5808\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.65670\n",
            "Epoch 45/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6997 - acc: 0.7672 - val_loss: 3.0573 - val_acc: 0.4522\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.65670\n",
            "Epoch 46/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7383 - acc: 0.7471 - val_loss: 1.9482 - val_acc: 0.5687\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.65670\n",
            "Epoch 47/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7069 - acc: 0.7588 - val_loss: 0.9333 - val_acc: 0.7268\n",
            "\n",
            "Epoch 00047: val_acc improved from 0.65670 to 0.72680, saving model to /content/saved_models/cifar10_ResNet32v1_model.047.h5\n",
            "Epoch 48/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6995 - acc: 0.7663 - val_loss: 4.0629 - val_acc: 0.4234\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.72680\n",
            "Epoch 49/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7104 - acc: 0.7638 - val_loss: 1.3387 - val_acc: 0.6399\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.72680\n",
            "Epoch 50/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7092 - acc: 0.7625 - val_loss: 1.8919 - val_acc: 0.5488\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.72680\n",
            "Epoch 51/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6895 - acc: 0.7700 - val_loss: 1.1448 - val_acc: 0.6864\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.72680\n",
            "Epoch 52/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7196 - acc: 0.7601 - val_loss: 1.8396 - val_acc: 0.5904\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.72680\n",
            "Epoch 53/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6690 - acc: 0.7740 - val_loss: 2.3306 - val_acc: 0.5094\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.72680\n",
            "Epoch 54/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6998 - acc: 0.7628 - val_loss: 2.5728 - val_acc: 0.4571\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.72680\n",
            "Epoch 55/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6935 - acc: 0.7621 - val_loss: 1.1968 - val_acc: 0.6392\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.72680\n",
            "Epoch 56/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6745 - acc: 0.7736 - val_loss: 2.3318 - val_acc: 0.5674\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.72680\n",
            "Epoch 57/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6763 - acc: 0.7717 - val_loss: 1.8203 - val_acc: 0.5781\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.72680\n",
            "Epoch 58/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6851 - acc: 0.7702 - val_loss: 4.0332 - val_acc: 0.4249\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.72680\n",
            "Epoch 59/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6774 - acc: 0.7707 - val_loss: 2.1410 - val_acc: 0.5053\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.72680\n",
            "Epoch 60/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6790 - acc: 0.7698 - val_loss: 1.4079 - val_acc: 0.6137\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.72680\n",
            "Epoch 61/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6881 - acc: 0.7680 - val_loss: 2.6911 - val_acc: 0.4800\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.72680\n",
            "Epoch 62/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6727 - acc: 0.7753 - val_loss: 2.1186 - val_acc: 0.5352\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.72680\n",
            "Epoch 63/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6963 - acc: 0.7653 - val_loss: 2.1989 - val_acc: 0.5467\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.72680\n",
            "Epoch 64/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6681 - acc: 0.7737 - val_loss: 4.9457 - val_acc: 0.3253\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.72680\n",
            "Epoch 65/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6405 - acc: 0.7792 - val_loss: 1.4930 - val_acc: 0.6176\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.72680\n",
            "Epoch 66/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6862 - acc: 0.7664 - val_loss: 2.5743 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.72680\n",
            "Epoch 67/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6545 - acc: 0.7768 - val_loss: 3.2030 - val_acc: 0.3856\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.72680\n",
            "Epoch 68/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6754 - acc: 0.7756 - val_loss: 1.9252 - val_acc: 0.6020\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.72680\n",
            "Epoch 69/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6587 - acc: 0.7774 - val_loss: 1.0133 - val_acc: 0.7017\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.72680\n",
            "Epoch 70/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6344 - acc: 0.7885 - val_loss: 2.3031 - val_acc: 0.5511\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.72680\n",
            "Epoch 71/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6362 - acc: 0.7858 - val_loss: 4.4640 - val_acc: 0.3344\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.72680\n",
            "Epoch 72/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6472 - acc: 0.7837 - val_loss: 1.9445 - val_acc: 0.5804\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.72680\n",
            "Epoch 73/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6404 - acc: 0.7858 - val_loss: 3.7805 - val_acc: 0.4184\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.72680\n",
            "Epoch 74/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6392 - acc: 0.7844 - val_loss: 2.9719 - val_acc: 0.4803\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.72680\n",
            "Epoch 75/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6762 - acc: 0.7737 - val_loss: 1.5625 - val_acc: 0.6241\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.72680\n",
            "Epoch 76/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6474 - acc: 0.7836 - val_loss: 2.6714 - val_acc: 0.5442\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.72680\n",
            "Epoch 77/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6668 - acc: 0.7770 - val_loss: 4.0697 - val_acc: 0.3940\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.72680\n",
            "Epoch 78/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6733 - acc: 0.7724 - val_loss: 4.3857 - val_acc: 0.3577\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.72680\n",
            "Epoch 79/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6222 - acc: 0.7931 - val_loss: 1.8043 - val_acc: 0.5983\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.72680\n",
            "Epoch 80/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6358 - acc: 0.7872 - val_loss: 1.7755 - val_acc: 0.5868\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.72680\n",
            "Epoch 81/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6356 - acc: 0.7802 - val_loss: 7.2913 - val_acc: 0.2920\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.72680\n",
            "Epoch 82/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4820 - acc: 0.8364 - val_loss: 0.7154 - val_acc: 0.7710\n",
            "\n",
            "Epoch 00082: val_acc improved from 0.72680 to 0.77100, saving model to /content/saved_models/cifar10_ResNet32v1_model.082.h5\n",
            "Epoch 83/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4324 - acc: 0.8598 - val_loss: 0.6122 - val_acc: 0.7967\n",
            "\n",
            "Epoch 00083: val_acc improved from 0.77100 to 0.79670, saving model to /content/saved_models/cifar10_ResNet32v1_model.083.h5\n",
            "Epoch 84/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3941 - acc: 0.8694 - val_loss: 0.5073 - val_acc: 0.8332\n",
            "\n",
            "Epoch 00084: val_acc improved from 0.79670 to 0.83320, saving model to /content/saved_models/cifar10_ResNet32v1_model.084.h5\n",
            "Epoch 85/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3995 - acc: 0.8677 - val_loss: 0.4832 - val_acc: 0.8434\n",
            "\n",
            "Epoch 00085: val_acc improved from 0.83320 to 0.84340, saving model to /content/saved_models/cifar10_ResNet32v1_model.085.h5\n",
            "Epoch 86/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3796 - acc: 0.8748 - val_loss: 0.4330 - val_acc: 0.8547\n",
            "\n",
            "Epoch 00086: val_acc improved from 0.84340 to 0.85470, saving model to /content/saved_models/cifar10_ResNet32v1_model.086.h5\n",
            "Epoch 87/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3589 - acc: 0.8822 - val_loss: 0.4845 - val_acc: 0.8413\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.85470\n",
            "Epoch 88/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3683 - acc: 0.8789 - val_loss: 0.4342 - val_acc: 0.8584\n",
            "\n",
            "Epoch 00088: val_acc improved from 0.85470 to 0.85840, saving model to /content/saved_models/cifar10_ResNet32v1_model.088.h5\n",
            "Epoch 89/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3588 - acc: 0.8835 - val_loss: 0.5095 - val_acc: 0.8412\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.85840\n",
            "Epoch 90/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3610 - acc: 0.8821 - val_loss: 0.5933 - val_acc: 0.8108\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.85840\n",
            "Epoch 91/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3369 - acc: 0.8902 - val_loss: 0.4401 - val_acc: 0.8540\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.85840\n",
            "Epoch 92/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3405 - acc: 0.8885 - val_loss: 0.4530 - val_acc: 0.8498\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.85840\n",
            "Epoch 93/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3429 - acc: 0.8889 - val_loss: 0.4654 - val_acc: 0.8530\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.85840\n",
            "Epoch 94/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3047 - acc: 0.8984 - val_loss: 0.4231 - val_acc: 0.8602\n",
            "\n",
            "Epoch 00094: val_acc improved from 0.85840 to 0.86020, saving model to /content/saved_models/cifar10_ResNet32v1_model.094.h5\n",
            "Epoch 95/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3279 - acc: 0.8920 - val_loss: 0.4468 - val_acc: 0.8547\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.86020\n",
            "Epoch 96/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3305 - acc: 0.8887 - val_loss: 0.4313 - val_acc: 0.8559\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.86020\n",
            "Epoch 97/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3050 - acc: 0.8996 - val_loss: 0.5165 - val_acc: 0.8327\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.86020\n",
            "Epoch 98/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3182 - acc: 0.8946 - val_loss: 0.4400 - val_acc: 0.8574\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.86020\n",
            "Epoch 99/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3060 - acc: 0.9017 - val_loss: 0.4969 - val_acc: 0.8431\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.86020\n",
            "Epoch 100/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2917 - acc: 0.9055 - val_loss: 0.4505 - val_acc: 0.8564\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.86020\n",
            "Epoch 101/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2981 - acc: 0.9023 - val_loss: 0.4831 - val_acc: 0.8424\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.86020\n",
            "Epoch 102/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2708 - acc: 0.9147 - val_loss: 0.4184 - val_acc: 0.8625\n",
            "\n",
            "Epoch 00102: val_acc improved from 0.86020 to 0.86250, saving model to /content/saved_models/cifar10_ResNet32v1_model.102.h5\n",
            "Epoch 103/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2844 - acc: 0.9058 - val_loss: 0.4531 - val_acc: 0.8571\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.86250\n",
            "Epoch 104/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2868 - acc: 0.9047 - val_loss: 0.5623 - val_acc: 0.8215\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.86250\n",
            "Epoch 105/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2855 - acc: 0.9050 - val_loss: 0.4801 - val_acc: 0.8467\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.86250\n",
            "Epoch 106/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2910 - acc: 0.9033 - val_loss: 0.4429 - val_acc: 0.8563\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.86250\n",
            "Epoch 107/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2850 - acc: 0.9072 - val_loss: 0.4465 - val_acc: 0.8592\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.86250\n",
            "Epoch 108/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2795 - acc: 0.9088 - val_loss: 0.3936 - val_acc: 0.8652\n",
            "\n",
            "Epoch 00108: val_acc improved from 0.86250 to 0.86520, saving model to /content/saved_models/cifar10_ResNet32v1_model.108.h5\n",
            "Epoch 109/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2783 - acc: 0.9099 - val_loss: 0.4967 - val_acc: 0.8391\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.86520\n",
            "Epoch 110/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2694 - acc: 0.9120 - val_loss: 0.4324 - val_acc: 0.8626\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.86520\n",
            "Epoch 111/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2686 - acc: 0.9126 - val_loss: 0.5282 - val_acc: 0.8304\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.86520\n",
            "Epoch 112/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2680 - acc: 0.9114 - val_loss: 0.4820 - val_acc: 0.8449\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.86520\n",
            "Epoch 113/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2646 - acc: 0.9085 - val_loss: 0.4355 - val_acc: 0.8623\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.86520\n",
            "Epoch 114/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2597 - acc: 0.9152 - val_loss: 0.4487 - val_acc: 0.8548\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.86520\n",
            "Epoch 115/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2533 - acc: 0.9191 - val_loss: 0.4056 - val_acc: 0.8701\n",
            "\n",
            "Epoch 00115: val_acc improved from 0.86520 to 0.87010, saving model to /content/saved_models/cifar10_ResNet32v1_model.115.h5\n",
            "Epoch 116/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2587 - acc: 0.9149 - val_loss: 0.4057 - val_acc: 0.8657\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.87010\n",
            "Epoch 117/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2474 - acc: 0.9184 - val_loss: 0.4871 - val_acc: 0.8441\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.87010\n",
            "Epoch 118/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2711 - acc: 0.9106 - val_loss: 0.4989 - val_acc: 0.8411\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.87010\n",
            "Epoch 119/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2567 - acc: 0.9143 - val_loss: 0.4413 - val_acc: 0.8608\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.87010\n",
            "Epoch 120/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2525 - acc: 0.9177 - val_loss: 0.4962 - val_acc: 0.8456\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.87010\n",
            "Epoch 121/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2485 - acc: 0.9186 - val_loss: 0.5018 - val_acc: 0.8452\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.87010\n",
            "Epoch 122/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2341 - acc: 0.9242 - val_loss: 0.3453 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00122: val_acc improved from 0.87010 to 0.88800, saving model to /content/saved_models/cifar10_ResNet32v1_model.122.h5\n",
            "Epoch 123/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2221 - acc: 0.9283 - val_loss: 0.3421 - val_acc: 0.8895\n",
            "\n",
            "Epoch 00123: val_acc improved from 0.88800 to 0.88950, saving model to /content/saved_models/cifar10_ResNet32v1_model.123.h5\n",
            "Epoch 124/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2182 - acc: 0.9308 - val_loss: 0.3258 - val_acc: 0.8944\n",
            "\n",
            "Epoch 00124: val_acc improved from 0.88950 to 0.89440, saving model to /content/saved_models/cifar10_ResNet32v1_model.124.h5\n",
            "Epoch 125/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2092 - acc: 0.9323 - val_loss: 0.3297 - val_acc: 0.8945\n",
            "\n",
            "Epoch 00125: val_acc improved from 0.89440 to 0.89450, saving model to /content/saved_models/cifar10_ResNet32v1_model.125.h5\n",
            "Epoch 126/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2101 - acc: 0.9315 - val_loss: 0.3276 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00126: val_acc improved from 0.89450 to 0.89560, saving model to /content/saved_models/cifar10_ResNet32v1_model.126.h5\n",
            "Epoch 127/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2047 - acc: 0.9335 - val_loss: 0.3268 - val_acc: 0.8942\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.89560\n",
            "Epoch 128/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2111 - acc: 0.9334 - val_loss: 0.3385 - val_acc: 0.8908\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.89560\n",
            "Epoch 129/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2101 - acc: 0.9291 - val_loss: 0.3249 - val_acc: 0.8964\n",
            "\n",
            "Epoch 00129: val_acc improved from 0.89560 to 0.89640, saving model to /content/saved_models/cifar10_ResNet32v1_model.129.h5\n",
            "Epoch 130/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2082 - acc: 0.9383 - val_loss: 0.3187 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00130: val_acc improved from 0.89640 to 0.89680, saving model to /content/saved_models/cifar10_ResNet32v1_model.130.h5\n",
            "Epoch 131/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2004 - acc: 0.9375 - val_loss: 0.3255 - val_acc: 0.8954\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.89680\n",
            "Epoch 132/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2056 - acc: 0.9333 - val_loss: 0.3239 - val_acc: 0.8958\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.89680\n",
            "Epoch 133/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2042 - acc: 0.9324 - val_loss: 0.3215 - val_acc: 0.8962\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.89680\n",
            "Epoch 134/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2009 - acc: 0.9381 - val_loss: 0.3299 - val_acc: 0.8944\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.89680\n",
            "Epoch 135/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2004 - acc: 0.9380 - val_loss: 0.3259 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.89680\n",
            "Epoch 136/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2009 - acc: 0.9367 - val_loss: 0.3274 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.89680\n",
            "Epoch 137/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1967 - acc: 0.9394 - val_loss: 0.3180 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00137: val_acc improved from 0.89680 to 0.89920, saving model to /content/saved_models/cifar10_ResNet32v1_model.137.h5\n",
            "Epoch 138/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1985 - acc: 0.9362 - val_loss: 0.3147 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00138: val_acc improved from 0.89920 to 0.89970, saving model to /content/saved_models/cifar10_ResNet32v1_model.138.h5\n",
            "Epoch 139/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1868 - acc: 0.9409 - val_loss: 0.3279 - val_acc: 0.8958\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.89970\n",
            "Epoch 140/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2063 - acc: 0.9341 - val_loss: 0.3225 - val_acc: 0.8970\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.89970\n",
            "Epoch 141/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1863 - acc: 0.9404 - val_loss: 0.3192 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.89970\n",
            "Epoch 142/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1912 - acc: 0.9378 - val_loss: 0.3194 - val_acc: 0.8965\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.89970\n",
            "Epoch 143/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1870 - acc: 0.9399 - val_loss: 0.3195 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.89970\n",
            "Epoch 144/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1944 - acc: 0.9371 - val_loss: 0.3121 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.89970\n",
            "Epoch 145/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1907 - acc: 0.9404 - val_loss: 0.3278 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.89970\n",
            "Epoch 146/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1933 - acc: 0.9434 - val_loss: 0.3246 - val_acc: 0.8960\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.89970\n",
            "Epoch 147/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1860 - acc: 0.9424 - val_loss: 0.3212 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.89970\n",
            "Epoch 148/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1858 - acc: 0.9415 - val_loss: 0.3176 - val_acc: 0.8972\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.89970\n",
            "Epoch 149/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1876 - acc: 0.9435 - val_loss: 0.3183 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.89970\n",
            "Epoch 150/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1851 - acc: 0.9426 - val_loss: 0.3183 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.89970\n",
            "Epoch 151/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1848 - acc: 0.9419 - val_loss: 0.3193 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.89970\n",
            "Epoch 152/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1865 - acc: 0.9405 - val_loss: 0.3199 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.89970\n",
            "Epoch 153/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1873 - acc: 0.9396 - val_loss: 0.3289 - val_acc: 0.8965\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.89970\n",
            "Epoch 154/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1845 - acc: 0.9427 - val_loss: 0.3203 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.89970\n",
            "Epoch 155/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1786 - acc: 0.9411 - val_loss: 0.3243 - val_acc: 0.8972\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.89970\n",
            "Epoch 156/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1849 - acc: 0.9384 - val_loss: 0.3267 - val_acc: 0.8944\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.89970\n",
            "Epoch 157/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1857 - acc: 0.9421 - val_loss: 0.3254 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.89970\n",
            "Epoch 158/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1749 - acc: 0.9446 - val_loss: 0.3275 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.89970\n",
            "Epoch 159/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1703 - acc: 0.9463 - val_loss: 0.3213 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.89970\n",
            "Epoch 160/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1723 - acc: 0.9462 - val_loss: 0.3177 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.89970\n",
            "Epoch 161/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1853 - acc: 0.9389 - val_loss: 0.3162 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.89970\n",
            "Epoch 162/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1670 - acc: 0.9496 - val_loss: 0.3150 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.89970\n",
            "Epoch 163/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1777 - acc: 0.9431 - val_loss: 0.3161 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.89970\n",
            "Epoch 164/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1885 - acc: 0.9385 - val_loss: 0.3160 - val_acc: 0.8972\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.89970\n",
            "Epoch 165/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1813 - acc: 0.9435 - val_loss: 0.3157 - val_acc: 0.8982\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.89970\n",
            "Epoch 166/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1730 - acc: 0.9451 - val_loss: 0.3154 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.89970\n",
            "Epoch 167/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1817 - acc: 0.9442 - val_loss: 0.3150 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.89970\n",
            "Epoch 168/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1764 - acc: 0.9471 - val_loss: 0.3137 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.89970\n",
            "Epoch 169/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1853 - acc: 0.9393 - val_loss: 0.3146 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.89970\n",
            "Epoch 170/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1776 - acc: 0.9414 - val_loss: 0.3155 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.89970\n",
            "Epoch 171/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1809 - acc: 0.9425 - val_loss: 0.3146 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.89970\n",
            "Epoch 172/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1882 - acc: 0.9410 - val_loss: 0.3137 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.89970\n",
            "Epoch 173/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1697 - acc: 0.9493 - val_loss: 0.3139 - val_acc: 0.8977\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.89970\n",
            "Epoch 174/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1701 - acc: 0.9482 - val_loss: 0.3141 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.89970\n",
            "Epoch 175/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1768 - acc: 0.9445 - val_loss: 0.3131 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.89970\n",
            "Epoch 176/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1690 - acc: 0.9498 - val_loss: 0.3131 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.89970\n",
            "Epoch 177/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1713 - acc: 0.9451 - val_loss: 0.3134 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.89970\n",
            "Epoch 178/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1763 - acc: 0.9437 - val_loss: 0.3133 - val_acc: 0.8982\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.89970\n",
            "Epoch 179/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1776 - acc: 0.9480 - val_loss: 0.3144 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.89970\n",
            "Epoch 180/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1822 - acc: 0.9440 - val_loss: 0.3139 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.89970\n",
            "Epoch 181/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1822 - acc: 0.9428 - val_loss: 0.3127 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.89970\n",
            "Epoch 182/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1724 - acc: 0.9473 - val_loss: 0.3129 - val_acc: 0.8998\n",
            "\n",
            "Epoch 00182: val_acc improved from 0.89970 to 0.89980, saving model to /content/saved_models/cifar10_ResNet32v1_model.182.h5\n",
            "Epoch 183/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1660 - acc: 0.9502 - val_loss: 0.3134 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.89980\n",
            "Epoch 184/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1696 - acc: 0.9497 - val_loss: 0.3143 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.89980\n",
            "Epoch 185/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1807 - acc: 0.9466 - val_loss: 0.3142 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.89980\n",
            "Epoch 186/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1677 - acc: 0.9483 - val_loss: 0.3124 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.89980\n",
            "Epoch 187/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1773 - acc: 0.9454 - val_loss: 0.3121 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.89980\n",
            "Epoch 188/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1784 - acc: 0.9433 - val_loss: 0.3126 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.89980\n",
            "Epoch 189/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1726 - acc: 0.9456 - val_loss: 0.3139 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.89980\n",
            "Epoch 190/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1798 - acc: 0.9453 - val_loss: 0.3143 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.89980\n",
            "Epoch 191/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1713 - acc: 0.9493 - val_loss: 0.3135 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.89980\n",
            "Epoch 192/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1796 - acc: 0.9443 - val_loss: 0.3133 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.89980\n",
            "Epoch 193/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1883 - acc: 0.9414 - val_loss: 0.3134 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.89980\n",
            "Epoch 194/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1730 - acc: 0.9477 - val_loss: 0.3124 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.89980\n",
            "Epoch 195/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1793 - acc: 0.9427 - val_loss: 0.3133 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.89980\n",
            "Epoch 196/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1881 - acc: 0.9423 - val_loss: 0.3131 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.89980\n",
            "Epoch 197/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1715 - acc: 0.9463 - val_loss: 0.3134 - val_acc: 0.8982\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.89980\n",
            "Epoch 198/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1834 - acc: 0.9436 - val_loss: 0.3124 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.89980\n",
            "Epoch 199/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1829 - acc: 0.9428 - val_loss: 0.3123 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.89980\n",
            "Epoch 200/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1749 - acc: 0.9452 - val_loss: 0.3127 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.89980\n",
            "Epoch 201/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1787 - acc: 0.9448 - val_loss: 0.3128 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.89980\n",
            "Epoch 202/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1721 - acc: 0.9423 - val_loss: 0.3129 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.89980\n",
            "Epoch 203/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1801 - acc: 0.9467 - val_loss: 0.3131 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.89980\n",
            "Epoch 204/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1719 - acc: 0.9472 - val_loss: 0.3131 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.89980\n",
            "Epoch 205/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1850 - acc: 0.9393 - val_loss: 0.3133 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.89980\n",
            "Epoch 206/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1787 - acc: 0.9437 - val_loss: 0.3135 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.89980\n",
            "Epoch 207/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1728 - acc: 0.9459 - val_loss: 0.3130 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.89980\n",
            "Epoch 208/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1861 - acc: 0.9413 - val_loss: 0.3136 - val_acc: 0.8987\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.89980\n",
            "Epoch 209/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1723 - acc: 0.9477 - val_loss: 0.3130 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.89980\n",
            "Epoch 210/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1811 - acc: 0.9394 - val_loss: 0.3130 - val_acc: 0.8983\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.89980\n",
            "Epoch 211/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1815 - acc: 0.9431 - val_loss: 0.3133 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.89980\n",
            "Epoch 212/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1791 - acc: 0.9432 - val_loss: 0.3123 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.89980\n",
            "Epoch 213/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1760 - acc: 0.9455 - val_loss: 0.3134 - val_acc: 0.8979\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.89980\n",
            "Epoch 214/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1749 - acc: 0.9459 - val_loss: 0.3127 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.89980\n",
            "Epoch 215/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1758 - acc: 0.9440 - val_loss: 0.3126 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.89980\n",
            "Epoch 216/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1843 - acc: 0.9450 - val_loss: 0.3119 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.89980\n",
            "Epoch 217/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1638 - acc: 0.9499 - val_loss: 0.3125 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.89980\n",
            "Epoch 218/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1701 - acc: 0.9450 - val_loss: 0.3121 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.89980\n",
            "Epoch 219/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1737 - acc: 0.9446 - val_loss: 0.3112 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00219: val_acc improved from 0.89980 to 0.89990, saving model to /content/saved_models/cifar10_ResNet32v1_model.219.h5\n",
            "Epoch 220/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1837 - acc: 0.9452 - val_loss: 0.3124 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.89990\n",
            "Epoch 221/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1772 - acc: 0.9450 - val_loss: 0.3125 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.89990\n",
            "Epoch 222/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1678 - acc: 0.9512 - val_loss: 0.3130 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.89990\n",
            "Epoch 223/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1655 - acc: 0.9483 - val_loss: 0.3131 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.89990\n",
            "Epoch 224/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1824 - acc: 0.9403 - val_loss: 0.3128 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.89990\n",
            "Epoch 225/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1708 - acc: 0.9468 - val_loss: 0.3130 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.89990\n",
            "Epoch 226/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1805 - acc: 0.9398 - val_loss: 0.3111 - val_acc: 0.9004\n",
            "\n",
            "Epoch 00226: val_acc improved from 0.89990 to 0.90040, saving model to /content/saved_models/cifar10_ResNet32v1_model.226.h5\n",
            "Epoch 227/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1723 - acc: 0.9479 - val_loss: 0.3120 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.90040\n",
            "Epoch 228/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1671 - acc: 0.9489 - val_loss: 0.3129 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.90040\n",
            "Epoch 229/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1845 - acc: 0.9431 - val_loss: 0.3130 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.90040\n",
            "Epoch 230/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1659 - acc: 0.9478 - val_loss: 0.3129 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.90040\n",
            "Epoch 231/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1666 - acc: 0.9465 - val_loss: 0.3132 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.90040\n",
            "Epoch 232/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1698 - acc: 0.9498 - val_loss: 0.3128 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.90040\n",
            "Epoch 233/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1689 - acc: 0.9461 - val_loss: 0.3124 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.90040\n",
            "Epoch 234/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1713 - acc: 0.9470 - val_loss: 0.3124 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.90040\n",
            "Epoch 235/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1732 - acc: 0.9435 - val_loss: 0.3130 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.90040\n",
            "Epoch 236/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1818 - acc: 0.9455 - val_loss: 0.3121 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.90040\n",
            "Epoch 237/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1734 - acc: 0.9480 - val_loss: 0.3121 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.90040\n",
            "Epoch 238/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1786 - acc: 0.9431 - val_loss: 0.3124 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.90040\n",
            "Epoch 239/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1640 - acc: 0.9475 - val_loss: 0.3136 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.90040\n",
            "Epoch 240/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1744 - acc: 0.9439 - val_loss: 0.3129 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.90040\n",
            "Epoch 241/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1761 - acc: 0.9448 - val_loss: 0.3124 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.90040\n",
            "Epoch 242/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1736 - acc: 0.9468 - val_loss: 0.3114 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.90040\n",
            "Epoch 243/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1788 - acc: 0.9433 - val_loss: 0.3119 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.90040\n",
            "Epoch 244/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1712 - acc: 0.9465 - val_loss: 0.3115 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.90040\n",
            "Epoch 245/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1737 - acc: 0.9472 - val_loss: 0.3125 - val_acc: 0.8987\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.90040\n",
            "Epoch 246/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1731 - acc: 0.9439 - val_loss: 0.3121 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.90040\n",
            "Epoch 247/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1726 - acc: 0.9474 - val_loss: 0.3123 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.90040\n",
            "Epoch 248/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1749 - acc: 0.9451 - val_loss: 0.3121 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.90040\n",
            "Epoch 249/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1695 - acc: 0.9470 - val_loss: 0.3130 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.90040\n",
            "Epoch 250/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1776 - acc: 0.9448 - val_loss: 0.3127 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.90040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "NYkcxUan9hpX",
        "outputId": "d60d3b7e-09e5-4a28-89ef-defab579414f"
      },
      "source": [
        "import pickle\r\n",
        "\r\n",
        "history = pickle.load(open('trainHistoryDict_clip_05', \"rb\"))\r\n",
        "plot_loss_acc(history)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAGDCAYAAADZHo16AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxc5XX4/8+Z0WiXbFmy5X0BGxsbYxsbMIEEQSEsCZAFAjQk+bZpaH6FZmu+KWlTQmiSpkmbZoMAbWi+SRooCQmQBsJWBMHgEIMNXvCOjeVNsrxoX+f5/XHvSKPRnf3eWa7P+/XyS6M7M/c+V8aPDmfOcx4xxqCUUkoppZQaFcj3AJRSSimllCo0GiQrpZRSSikVQ4NkpZRSSimlYmiQrJRSSimlVAwNkpVSSimllIqhQbJSSimllFIxNEhWSimllFIqhgbJquiJyB4RuSTf41BKKRWfPVf3ikhX1J8f5HtcSsVTku8BKKWUUuqkcZUx5plELxCREmPMUMyxoDFmONWLpPt6pZxoJln5koiUich3ROSA/ec7IlJmP9cgIv8jIsdF5KiI/F5EAvZzfysi+0WkU0S2icif5PdOlFLK30Tk/4jIGhH5NxFpB+4QkR+LyA9F5HER6QYuEpHTRaTZnrs3i8jVUecY9/q83ZDyDc0kK7/6e2A1sBwwwKPAl4B/AP4GaAEm269dDRgRWQjcCpxtjDkgInOBYG6HrZRSJ6VzgQeBRiAE/BD4U+BK4L1AFbAeuB94N3AB8KiIrDLGbLPPEf360pyOXvmSZpKVX30YuNMY02qMaQO+AnzEfm4QmAbMMcYMGmN+b4wxwDBQBiwWkZAxZo8xZldeRq+UUv70iJ0Jjvz5hH38gDHm+8aYIWNMr33sUWPMGmNMGCvhUQ18wxgzYIz5X+B/gBujzj3yemNMX+5uSfmVBsnKr6YDe6O+32sfA/gWsBN4SkR2i8htAMaYncBngDuAVhF5UESmo5RSyi3vM8ZMjPrz7/bxfQ6vjT42HdhnB8wRe4EZcV6vVNY0SFZ+dQCYE/X9bPsYxphOY8zfGGNOAa4GPhepPTbG/NwYc4H9XgP8c26HrZRSJyWT5NgBYFZk/YhtNrA/yTmUypgGycovQiJSHvkDPAB8SUQmi0gDcDvwMwARea+IzBcRAU5glVmERWShiFxsL/DrA3qBsPPllFJK5dAfgB7gCyISEpEm4CqsOmalPKFBsvKLx7GC2sifcmAd8AawEXgN+Kr92gXAM0AX8DJwtzHmOax65G8AR4BDwBTgi7m7BaWU8r3fxPRJ/nUqbzLGDGAFxVdgzdF3Ax81xmz1cKzqJCfWeiWllFJKKaVUhGaSlVJKKaWUipE0SBaRWSLynIhssZt3f9rhNSIi3xORnSLyhoicFfXcx0Rkh/3nY27fgFJKqbFE5HJ7M5ydke4tcV73QRExIrIq6tgX7fdtE5HLcjNipZQqPEnLLURkGjDNGPOaiNQAr2K1cNkS9Zorgb/GauJ9LvBdY8y5IjIJqy50Fdaq01eBlcaYY57cjVJKneREJAhsBy7F2jTnj8CN0XO2/boa4LdYmy7caoxZJyKLsRa9noPVcusZ4DTd3lcpdTJKmkk2xhw0xrxmP+4E3mRsX0KAa4CfGMtaYKIdXF8GPG2MOWoHxk8Dl7t6B0oppaKdA+w0xuy2Fzs9iDVHx/pHrBaH0ZsuXAM8aIzpN8a8hdVP/ByvB6yUUoUorZpke5veFVitWKLNYGwT7xb7WLzjSimlvJF03rVL4mYZY36b7nuVUupkUZLqC0WkGngY+IwxpsPtgYjIzcDNABUVFStnzZqV1vvf7gxTVSLUV0ja167p3Dnm+67qeRgJAhAID1LVbW3cNlA6idKBo3TWzAegqmcfgeF+APrLJzMQmhD3GqHBDsr7WhkM1dJXPiXOazop7zsMCEYCiBmmp3Imw8FygoOdVPYdprtqFlXdLUT3TO8vqyc43E/JUBfAyHuir2skSFf1PGq6djMQqiU02MlgqIbQUBcSHqK7ei4lg12U9R/BBEJ0VVn7cFT27Cc43AsIA6UTKR08QWf1Ken9gFMQDocJBPy5jtTP9wb+vr9M7m379u1HjDGTPRpS1uzNGL4N/J8sz5PVnA3OP99jfYaOAcOcWnf+m4qepwGGSqrorZjmyrkBqrr3EggPAkL0vDwcKCMYHqCz5lRKhrqo6D0EMPL7A0Z/93RVn4Kx98gQE6a6a/fIayt6DxEID4AIYSkZM/bY18YqHThKWf9Rx+eypf/ui5ef78/tOTulIFlEQlgB8n8ZY37l8JL9QPQMOdM+th9oijne7HQNY8x9wH0Aq1atMuvWrUtlaCPOuuNx/mTJDL513bK03gfAHTHB7RdegcpJ1uOju+F7K6zHTZ+H5q/D7W9CIAA/PB8Ob7Keu+IrcO5fxr/Gqz+G33waVnwYrvmB82s2PACPfBIkCBV10HME/uxBmHMemx/6Gku2fBP+6gm4550QHhx9X9PfQNubsNluN/nnD8Hsc63Hr/0UHrsVqhvh89vg6zPgrI/B+p/C8g/Dm49Bx3747PPW+5/6EkycDZ/ZaL3/P98De18ECcDqv4R1/wl/vy3lH22qmpubaWpqcv28hcDP9wb+vr9M7k1E9iZ/lafizccRNcAZQLO1nw5TgcdE5OoU3jsi2zkbnH++33lmO995Zgdbvn4lwUD6SY9x7r0QDm4Y/X7Re+GG/8r+vBHfXQbH9kCwDKKC8a6quVT3H4YvbYPNj8Av7HXrd0TNn5HfPbe9CuW11uP+LvinGaOv/eWfw4ENUFoJE2bBjQ+Mvn+gG74+ffx5I5r/2f6dtQUCQXfuN3Jq/XdftPx8f27P2al0txDgR8Cbxphvx3nZY8BH7S4Xq4ETxpiDwJPAu0WkTkTqgHfbx1wXFBgKu9TzWaIm5ugdMCPHI1vHRy96NCluzCYJJv3ItUx43Osksm5GguPPYYZjxun01ypRzxlr7ONeJzFfk4xXKVWI/ggsEJF5IlIK3IA1RwNgjDlhjGkwxsw1xswF1gJXG2PW2a+7QUTKRGQe1sY7r+Ry8FWlVu6me2DInRPGBoeO82MWIucbN2cPQaAktWtGjzF2zg2UWHO805yd7Lwjv7N0PwSlMpFKJvl84CPARhGJ/O/432HtmY4x5h6s3c6uxFrk0QP8mf3cURH5R6xJG+BOY8xR94Y/KigwOOzSDsLxAs6RycuecKID42STUCqT1Jjzj72WRK4VCI6fGE3YCp7HnSfqsUQFwCY8GohHjyulgFgnW6UKmTFmSERuxUpIBIH7jTGbReROYJ0x5rEE790sIg8BW4Ah4JZcd7aYXFMGQFtnP7XloexPKDkKkhk7fwbCg6PBb9JgNnqMMv658LD1J3aOjr238SdO8rxSKpGkQbIx5kWS/EszVh+5W+I8dz9wf0ajS0MwAEPDbmWS4wXJUZle68Hoc0kzyZHXppBJhnEZgJFMciA4/hzhmEyy4zWigmVjGB/sSpKJXDSrrFSRMMY8jpW8iD52e5zXNsV8/zXga54NLonpEysAOHC8l1MnV2d/wthMsstlB/EyyYHwEJSkGiQn+CQwYAfJscmQVM47QpMbSmUi5YV7hS4owlDY40xyJND0rNwi+rnY10UyySUplFs4nCc6o2zCScotUhyvUg4GBwdpaWmhr68v+YsL3IQJE3jzzTcdnysvL2fmzJmEQi5kO9WI6ROtRccHjve6c0LPM8mR8zuVW5Snds2E5RZBCA/ZQXK65Rb2Vy23UAnonB2ff4LkAAzmLJPsUG6R7P/UU5qknGqBYzLJ4pBJNmFrIeG49zqce6QmOVL37FBukTBYVyqxlpYWampqmDt3LlLk/5PV2dlJTU3NuOPGGNrb22lpaWHevHl5GJl/NdaWExDYf9ylX9ixK909q0kee95AOI2a5ESfBI7UJMd+Ysj4ext/YvurBskqPp2z4/NNDxBr4Z7XNcm5LLcYG5CP1iSXjJ8ow7EZhhRqksfUPUeed1i4F3sezUioJPr6+qivry/6yTYREaG+vt4XmZdCEwoGaKwtdzGTnKsgOTaTnE5NcoLF0hKVSU63VMTH/waVe3TOjs9XQbL3meQcdbewvhn7VHRN8rhyi9iFe4m6W9g1yZFyiymnW8eDZc5j06yyyoCfJ9uIk+Ee82X6xAoPyy3crkl2Ti4EwoOj10rrvxWHTHI47FxukSpNbqgkTob5LJN79E2QXBKAIc+7W0QeO3W3SHLttLpbRD926G4xrtwinZrkmHKL634MH30UquoTl2koVSSOHz/O3Xffnfb7rrzySo4fP+7BiFS6XA2Sx7WAc3lOG8kkxxzGpF5u4XS+iEDAziQ7rSNJejL7qwbJqnAV8pztmyDZWrjnRSbZoWeyY7lFqtfOtrtFyfhTpNLdIl65RfkEOKUp+dg0WFZFIt6EOzSUuO/u448/zsSJE70alkrD9InlHDjRR9iNOd3rhXsB54V71nNJguRg6fhj8fokj5vnU6BlcqoIFPKc7auFe71DbmWS45UYxEw4JpMgOdF1E5Vb2PcmcfokB6NWazoG+VGZ5HjdLZwW7o3Luuhkqwrbbbfdxq5du1i+fDmhUIjy8nLq6urYunUr27dv533vex/79u2jr6+PT3/609x8880AzJ07l3Xr1tHV1cUVV1zBBRdcwIsvvsisWbN49NFHqaioyPOdnTxmTKxgYChMe/fASN/kjOVpMxHr2kmC5L9aC4feiDlfgprkjDPJShWuQp6z/RMki4s77kVL2N0ijZrkyGtTrUmOW25RQnrlFjHHJGCf0jhMxglqmZONXSkHX/nNZrYc6HD1nIun1/Llq5bEff4b3/gGmzZtYsOGDTQ3N/Oe97yHTZs2jaxovv/++5k0aRK9vb2cffbZfPCDH6S+vn7MOXbs2MEDDzzAt7/9bT7+8Y/z8MMPc9NNN7l6Hyq+qbVW67RDJ/qyD5Kd+g67KU53C+taCZ4DqD/V+pNIoMRObGSQSR6hyQ2VGp2zx/JNuYWrNcnREi3cGzPxuFBu4ZS1jnyXdOFekt7OYzLJwzHPJRibY1s4pYrHOeecM6blz/e+9z2WLVvG6tWr2bdvHzt27Bj3nnnz5rF8+XIAVq5cyZ49e3I1XAXUV1tlCO3d/dmfLFfdLTIpt0hFJKgfHsi8u4WWW6giUkhzto8yyeJed4tornW3SGXhXvyaZLAD4TGt2iJPJWgBF3s+Eau2LfZ60a/Rj+iUSxJlD3Klqqpq5HFzczPPPPMML7/8MpWVlTQ1NTm2BCorG81eBoNBentdWkSmUjKpyvr5H+0eyP5kBVFukeac+s7Pw8Ir7XNEguRBXbinPKdz9lj+CZIDLvZJjuZ2d4u0d9yLWrgXLyuRqNxiXE2yjGaSx40lhe4WmpFQBa6mpobOzk7H506cOEFdXR2VlZVs3bqVtWvX5nh0KhWTqqxMsitBsuct4NLIJKd67T/5h6jzZxMkK1X4CnnO9k+QLDDkeSbZ6+4WDsHt22th0ilWkByv52Zsk3mniTS6Jjkcp9wi0ftwyGArVYDq6+s5//zzOeOMM6ioqKCxsXHkucsvv5x77rmH008/nYULF7J69eo8jlTFU1teQigotLuZSY4sWvasBZzTJ3gB56/piATa0X2XUx6blluowlfIc7avguRBr2uSR7pb5KDcInKt5/8ZutushXuRydJpW+q4k290f2TG1iSPW7inQbDyh5///OeOx8vKynjiiSccn4vUsDU0NLBp06aR45///OddH59KTESoqyzlaJeLmeRgGQz15qkm2X4uk0WDYxIg6c7RWm6hikOhztm++ezGKrfwMJNcOyMqk5xBucXI+VLtbhH1eKjfLreIk42I7Z+ZaFOQ6ExyvHIL3WVPKZVn9dVlLmWS7bmxxK5ZzGcLuExKPQJRuaxM+yQrpTLinyBZJPtyiwv/FiomjT0WCMAHfwQff8q53GL+JRCqghUfSXzulD7uitNuzYTHZpLHlVsME3db6tjuFGOC5HgL9xyOiWYklFK5U19V6lJ3C3tuDNk9U3PaAi4mSM7k2nE7F9lKq+GMaxOfQ8stlMqIf8otAjCY7cK9i/7O+hNrqT0BOXW3mDgbbno4hZNHJqkUM8k4BMkSZ2enVLpbjMkkDzm/LtHHhqBZCaVUzkyqKmXfsZ7sTxSZ1yK72+V0x72oeuhMrx2dSXYKsv9uf4I3a3JDqWz4JpNcIlbMOuxFyUWEU3cLNz/+ipcxMOGY7hZONclJNv0Ys5lIFt0tlFIqByZVuVSTHAksS6wNSnJbbhETJGddk6zbUiuVS74JkoP2nXiyeC8itiYZQ8pBZCqTVLy64vCwXW6RRXeL6HrjTMotYrfkVkopD9VXldLZP0T/0HDyFycyUm7hcZDsZgs4p3OMuVaqNMmhVDb8EyTbwZynQbJTd4uUSxBSKbeIs2BuJJMc52O9cduVOmSVR2LdBC3gko1DJ1ylVI5MsnfdO9Y9mN2JAlHdLSCzQDWR2Dl2zLXdqEkOOj9WSnnON0FyiT1BedIrOSL2oytjPCy3iDpuwkCChXvhBAv3Yk8Y6RXqdB6tOVYnoerq6nwPQTmor3Jpa+rIfDjS3cKjPsmOO526UZOs5RZKRcvlnO2bIHmk3MKLXfciHDcTcbPcIkkmOd7CvUQ77iXskxxbbuEw2Y/rbqGUUt6rr7aC2vZs65IDMd0tXC+3iAmEox+PW7infZKVKib+6W6R00xyNuUWCS8w/lr29cbWJMduSx2b0U5SWxyvu0VKAb9Otqqw3XbbbcyaNYtbbrkFgDvuuIOSkhKee+45jh07xuDgIF/96le55ppr8jxSlUiDHSS3dbqUSfaqu4XTwj0J2mtFYn7FBjLJJCfpbpFwbJrcUIWvkOds/wTJ9tzjbZCcRXeLM6+H134K53wihfPD+EyycZ6MI+OI95Fc7MI7CcDwgPN5kk2oOuGqdD1xGxza6O45py6FK74R9+nrr7+ez3zmMyMT7kMPPcSTTz7Jpz71KWprazly5AirV6/m6quvRvS/6YI1pcYKkluzDpJjult41Sd5TJIjkkm2f8WOlLhlW5OcYYCv5RYqVTpnj+GfIDmycC/n5RYpqpkKf70utfPHPg4PA2HnyTjy2rRawIVHH4990fj3xwbZShW4FStW0NrayoEDB2hra6Ouro6pU6fy2c9+lhdeeIFAIMD+/fs5fPgwU6dOzfdwVRxVZSVUlQZp7ezL7kSBHHW3iJ43A0EYjrp2ZLF0bGY5FVl1t4jQIFkVrkKes/0TJOcik5xVd4tUTp+k3CJ2Mp55Nsx5B5zzl7DjqfHjHPPYaTOR2OsnWPCnVCYSZA+8dN111/HLX/6SQ4cOcf311/Nf//VftLW18eqrrxIKhZg7dy59fVkGX8pzU2rL3cskBz3eljpRJjky52bUJzk6eZJhuYVmklWqdM4ewz9Bsj0X5LRPciabiaRyfuub0YfxapIlCJfeOf69yTLJ4TibiaQS8Otkq4rA9ddfzyc+8QmOHDnC888/z0MPPcSUKVMIhUI899xz7N27N99DVCmYXFNGW0eWQXIkyBzZTMTlcouAQyY5co3InD2yWDrXfZKVKg6FOmf7LkgeysWOe5l0t0jn/BCTSR62rhXb3SJeeUaicgmR+N0tnO4lGIo6j2aVVXFYsmQJnZ2dzJgxg2nTpvHhD3+Yq666iqVLl7Jq1SoWLVqU7yGqFEypKWPT/hPZnWTcZiI5aAEXuUYkwC2fYH2dcVYG58+mJlm7W6jiUKhztm+C5JKc7Ljn1CfZqyA5eltq41xuEVsDN/pmh3M7lVvEyyRHHZ+6FDY9DANdKd6EUoVh48bRxScNDQ28/PLLjq/r6tL/tgvVlJpyWjtbszvJuM1EvKpJDlgLtIOlsO1x+5h97bq58InnoHFJ+ucf091C+yQr/yrEOds3QXJOdtzLprtFahdwfjyymUiqmWSnso3oIDneZiIO9zL7vJRGrpRSbptSW0bPwDDd/UNUlWX46ypSZlFaaX31cuHeB+6zHn9rvvU1OsDNJIsM2W0mop/+KZUV3wTJo5nkHPZJzlW5RXg4JpPsMFGmU5OcTrnF9BUxBzQjoZTKjeg2cPMyDZKXXgsTZkLPUev7nLSAi6lJzkZWQXKEzttKZcI3qwBC9p0MDHmYSc5ld4uEfZIjL0khkywxWefohXvxyi2ixxHZynXc+JRSyltTaqwscGtHFqvaK+pg4RXxN2PK1siOewm6W7hx/ujzpvxeLbdQKhs+CpKtyaB/aDjJK7MQ292C2J3usj1//BZwjn2SnSbl6OfHnnz0delkkgHO/zRMnJ1w6EpFMyfBL+WT4R7zbUqtSxuKwGjAmosWcAE3M8nR3S3SPZ8u3FOpORnms0zuMelsISL3i0iriGyK8/z/FZEN9p9NIjIsIpPs5/aIyEb7uSQ7aWQnZM8d/YM52kxk5Iedi4V7w3FawEW9ZsxHcg4Z6egscbot4C69Ez7j8g48yrfKy8tpb2/39aRrjKG9vZ3y8vJ8D8WRiFwuIttEZKeI3Obw/Cej5uYXRWSxfXyuiPRGzen35H70o2bWVVASELYc7Mj+ZJ5lkmM+4YPx3S2ykU25hX76p1Kgc3Z8qfwL/jHwA+AncS78LeBbACJyFfBZY8zRqJdcZIw5ktaoMhApt+j3stwiuiY58h+TV90tosXbTCSlhXsO10hWbpGIj/8RKXfMnDmTlpYW2tra8j2UrPX19cWdVMvLy5k5c2aOR5SciASBu4BLgRbgjyLymDFmS9TLfm6Mucd+/dXAt4HL7ed2GWOW53LM8VSWlrBi9kTW7HThV8hIWYTbNclO83Ekk+xGkOxCn2Sdt1UCOmfHl/RfsDHmBRGZm+L5bgQeSGsELomUWwzkotwCk2Br56wuEPUwttzCoU+y0w5P8c6T1sK9eMGyZiVUcqFQiHnz5uV7GK5obm5mxYrYxasF7xxgpzFmN4CIPAhcA4wEycaY6NRsFQX8efz58xv47rM7ONEzyITKUOYnGim3yEGfZDfLLeJ9Ypjam+2vBfvXqwqAztnxudbdQkQqsTIRt0YdNsBTImKAe40x9yV4/83AzQCNjY00Nzendf3+3m5A2LJ9B82D6e3M0mR/TXbNCcc3swLY/cKDGPkFpwJvvbWHvSa9scZT1neESMO1Y8eOU2c/7urswIQNR9qPsqm5mbM6O6kF2o8eY6M95vojW1hqv/75F17A2L8Q6o9sYql9vtebm1lypJ36oQECwJatb9J6bHTsE4+9wXKgq7ubdQ4/i7l79zAHeD7Nv5tUdHV1pf13Xiz8fG/g7/sr0nubAeyL+r4FODf2RSJyC/A5oBS4OOqpeSKyHugAvmSM+b3TRbKdsyG1n29l5zDGwL8/9jyrpmb+K2tS+xbOBDa/uZW29sTXTMe8lv3MATq6unjNvpeze/uoArZt38nBruyuVdbXNvJ7YfObb6Y19qkHt7EIWPvyy/RV7M5qHLGK9N9GSvx8b+Dv+3P73txsAXcVsCam1OICY8x+EZkCPC0iW40xLzi92Q6g7wNYtWqVaWpqSuviz/7vc0APM2fPo6lpQXojb7a+JL3m3jLYAKd0vQpHrQln3inzmPeu9MYaV8dBWGs9rJs0CY5bj6srK+nq6aFhyhRrjDsnQifUNzSMjnn7ANhV4xc2XTSacdjaA5us8zU1NUHr/dBuZRUWn76ExWdGjf2tALwO1dXVzj+L8BrYa5L/nDLQ3NzsyXkLgZ/vDfx9f36+N2PMXcBdIvKnwJeAjwEHgdnGmHYRWQk8IiJLYjLPkfdnNWdDaj/f84fDfH/D0xwOTqapaVna1xixcwg2wpIlZ8CSxNdMy/AL8DbU1tSO3svmGuiBhacvYeGKLK/VcWDk90LaY1+/H7bB6tWroW5OduOI4ed/G36+N/D3/bl9b27WCtxATKmFMWa//bUV+DXWx4CeCAaEkoDkprvF8MDornWudreIUzJhwogZduhukWwDEcYfG1NuEfu6JB9D6iIQpYrBfmBW1Pcz7WPxPAi8D8AY02+MabcfvwrsAk7zaJwpCQUDXLqkkSc3H8pufo+UW3jVJ9mrFnBZdbeI0HILpTLhSoQnIhOAC4FHo45ViUhN5DHwbkZynd4oKwnkprtFeChqQxGP+iSP624RVZPstH109HalTq3knDpipNrdQilVTP4ILBCReSJSipXAeCz6BSIS/XHbe4Ad9vHJ9sI/ROQUYAHg7uf0Gbhq2XQ6+ob4/fYsFvDltAVcJEh2oyZZ+yQrlS9J/zdXRB7AKtttEJEW4MtACCCyOhp4P/CUMaY76q2NwK/F+kdagrWa+nfuDX28slAwN90thofGH3Pl/HEC2HT7JCfbcW/0YOyL4hxXShULY8yQiNwKPAkEgfuNMZtF5E5gnTHmMeBWEbkEGASOYZVaALwLuFNEBoEw8MmYErq8uGB+A7XlJTy79TCXLG7M7CTidQs4p0xyvnfc04V7SmUjle4WN6bwmh9jtYqLPrYbyKKALH1lJQGPyy0iQfJA1LFclVs49Ul22AY1WeCbqFWc2788lFJ5YYx5HHg85tjtUY8/Hed9DwMPezu69IWCAeY1VNFyrDfzkwTtzhiut4BzCL5dbQEXdH6slPKcr6IiK0jOUbnF6EGPrhV13nDsttQJAt54mW3H96RbbqEZZqVUfjTWltPakcXOe9OWQdMXYe757g0KnMvfPKtJ1nILpXLJZ0Fy0Nua5MgkGM5BuQWx5RbDDtlih0k57iSaRrmFxsJKqQLTWFvOoY6+zE8QDEHTbVBa5d6gwDlBEXAxkzymJjndyVknc6Wy4a8gOeR1uUVUd4vYY26eP/axiWSSHTYGiQjEKbcY2fQk2QYkuBvwK6WUixpryzjRO0jfoIdzfCacFu4lTVqkIZvuFjqnK5UVfwXJnpdbOGSSPetuEZ1JHo6pSU6wcG/cpBz5mM3pPRku3NOP7pRSOdZYa201m1XJhRcSrRFxpdwiwTqSVOmcrVRGfBYke93dwv5xmahr5KzcwozPWKRSkxyZHFPpbpFsAtashFIqTyJBclYlF15w+hQvMle6ESRHn0e7WyiVUzx26o8AACAASURBVD4LknNUbpHsmBvnj2kBJybMuD7JjuUZsYGsGft8wu4WmQxaKaW8N3WCFSQfLrQg2euaZHDuoJHS+3ThnlLZ8FeQHPJ4M5FEO9m5cvo4QXJ4GMc+yanUwMVOjgn7KTuUZCilVAForCmiIHmk3MKllm1e7RaolErIV0FyaTBHLeDGHHMzoBTnx8bE6ZPssHBv3HjSKLdIlWYllFI5VltRQnkoULhBsmMLOLeC5Gw3QtE5W6lM+CpItmqSc11ukZsd95z7JDt1qohTk5zKZiLJB5jm65VSyh0iYreBK7SFew7zsdvlFpkGyVpuoVRW/BUkh3LU3WLsQRfPH2/hXpxyi3S6WzjWMWc3XKWUyqXGmvICzCQ7LdxzcTOR6Gvowj2lcspfQXKJxzXJTkGyq5nkeC3gIgv3YgNhhxq4cdUW4bGvTSmTrNGzUqrwNE4op7XggmSnmuTIMZdrkjPNJCulMuKzINkqtzBefbTkeXeLOBt9RILkcX2SncozkrWAi1P3bL04xYFqVkIplXuNNWUc6ujzbo7PRDHUJBfSz0upIuKzIDlA2MBQ2KsJweNyC3CecMPDOPdJdqiBS2db6nhZhnSPK6VUDkydUE7fYJiOvqHkL86VRAup3a5JTjvo1nILpbLhryA5ZN2OZ3XJnne3AMcA2AwjGFLqk5x0M5EE21IrpVQBm1JbgG3gEpVb5LsmWRfuKZUVX0VJZSXWRNI/6FGHC6/LLcacz6n+OVFNcqrbUidoAZdytYVOuEqp3JtaiEGy4457HvVJ1sSGUjnlq39xZSVeZ5JzWG7hdK1A7A550Zlkh4kaojLJTjvuxRt7useVUsp7jbVlABwupDZwucgkj5TTabmFUrnkryDZD+UWKWWSE7WAS2MzEc1KKKWKSGMhZpKdFk1nXEMcx0gmOc3fN1puoVRWfBUlRcotBnIaJLtdbuFUFhF5LiZb7FiTHG9bahd33FNKqTwoDwWZUBEqsCDZKZNsP3atJjleOV3SN7pzfaVOUj4LkiOZZK923ctzuUXsROm0mnpcuUV47PkSlltoCzilVGFrrC3j0IlCDJIdyt/c7pOccWZa52ylMuGzINleuOfXcovYPsk4ZC7iBr4plFvEdsIYNzbnw0oplSuNteXsauuiu79A2sA5BcK6LbVSvuCvIDlSk+zVrnuJsrvuXSSFaznVJMeZRNPaTEQppQrbZUumsqutm2vvebkwNhXJycK9TLtb6MI9pbLhryDZ63KLXGymETcjDOP7JDv1PE4nk6xBslKquNy0eg53XrOENw92sOVgR76HE6clZxCDjO9IlPE1sswkK6Uy4rMg2eflFrF1xY4L92LeM5JJjj0/Ccae5J4KIXujlDppXX7GVACat7XleSTEzSQbNz9lzLgFnE3nbKUy4rMg2etMci67WySoSR6NeMc/F28zEcfV0eku3NOshFIq/6bUlLNkei3N21rzPZSobPHY+di4tWjPPp91CS23UCqX/BUk2zXJvQMeZZJz2d0ipT7JTovw4mwm4hRYjwvEE7SfU0qpAtK0cDKvvX2cnoE8L+BzSkCc0sShqRe7d42s+yS7NxSlTiYurSooDJUh63b6crotdS5bwMX2SU5jW+pUNhOZcRacczOcd0u6o1ZKqZw6dXI1w2HD4Y5+5jXk8VeZ05y94FJ27A8xw7VrZLo5iX76p1Q2fJUyLC+1M8k5DZLdLrdIJZOcqCY5SSY5UblFIAhXfgvq5iYZpKYllFL5NbnG2qK6rTPPW1QnmrPdknG5RYTO2UplwldBcmkwQECgdyCX3S3cnhhTqEmO2ydZGD8eF7el1pXSSqkCUXBBspfzo/ZJViovfBUkiwiVpSU5ziR7VW6RKGsdp3Y4EBx/LFEmWYNepVSRmlwdCZLzvPtebBmcF0ZqkjMtt9AgWalM+CpIBigPBenxLJNcKOUWcbLNEohfbqGbiSilfKSuspRgQDjSNZDfgeQik5xpn2SlVFZ89y+uojTg3cK9nHS3iHxNs7vFyPdZbEudKv3oTimVZ4GAUF9VWjjlFjnJJKdbbmF/1TlbqYz4LkiuDJXktiY5l+UWsX2Sx2WSE5RbOC72S3fsmnlWShWOyTVltHUVSJDsZZY30os54+4WGiQrlYmk/6pF5H4RaRWRTXGebxKREyKywf5ze9Rzl4vINhHZKSK3uTnweMpLgx7WJDssjMtnuYXTWMYFvgkW7mnQq5QvJZt7ReSTIrLRnrNfFJHFUc990X7fNhG5LLcjT8/kmjJ2tXXx+V+8Tnu+guVEG0C5Jds+yUqpjKQS4f0YuDzJa35vjFlu/7kTQESCwF3AFcBi4MboidgrFaGAd5lkcJh0ctjdIrYubdzCPYdyi4QL97SdkFJ+k+Lc+3NjzFJjzHLgm8C37fcuBm4AlmDN+3fb5ytIk6vL2Nvewy9fbeHX6/fnZxDjdkL1gNOnhOnQcgulMpL0X50x5gXgaAbnPgfYaYzZbYwZAB4ErsngPGnxtLsFONQBe3x+x+fSWLiXsAWcZiWU8qGkc68xpiPq2ypG/8/3GuBBY0y/MeYtYKd9voIUaQMHUBLI0/w0krTw8BqBkgw6W4CWWyiVHbe2KTpPRF4HDgCfN8ZsBmYA+6Je0wKcG+8EInIzcDNAY2Mjzc3NaQ2gq6uL5uZmOo/30d4ZTuv9TfbXVN7zLjP2/yxef2MTx1rc2+3p7N5eqoC3W1qYHfPcG5s2c/RgOQsOHGAGsGv3W+wbGh3zO4aG6e/q5tWo+5i5byfzgX0tLexqbqbx0DZOt5/7wx9eobcy+q8osVlv7+ZU4IUXXiAcLEv6+nRE/v78yM/3Bv6+vyK9t5TmXhG5BfgcUApE9lCeAayNea/jxnHZztmQ/c/30P7Rzhavbt7B3MG9GZ8rU1VdezgbOHjwENui7sXN/3ZOPXCAGQZeSPN8E4+9wXJg/fr1nHjL3S4gRfpvIyV+vjfw9/25fW9uRHevAXOMMV0iciXwCLAg3ZMYY+4D7gNYtWqVaWpqSuv9zc3NNDU18ZvW1zmwu5203t9sfUnpPb8PwvDQyLfLli2DU9O4VjKba6AHZs+aPfbXHHDmsmUwvwm6/wcOwKmnzufU86Ou/cdySmtrx97HoXrYdT+zLvkks+aeD68fgq3WU+euXg2T5qU+thfXw25417veBaGKDG/QWeTvz4/8fG/g7/vz870ZY+4C7hKRPwW+BHwszfdnNWdD9j/fg5Vv86sdGwGoqp9KU9OZGZ8rY61vwjqYNn0606Luxd3/dv4Ax9amf77dAq/DiuXLYe75Lo3F4ud/G36+N/D3/bl9b1kHydEf2xljHheRu0WkAdgPzIp66Uz7mKcqSgM5Lrdwu7tFFjXJTi3gpi6FO07EvCbmWunS+jalClm6c++DwA8zfG9efWjVLE6fVssXf7WRI3lbuJeD7hbn/RUsvTaLE+icrVQmsv5XLSJTRaxoS0TOsc/ZDvwRWCAi80SkFGsxyGPZXi+ZylIPW8BBnMDUg/Mn2rgknc1E4p3D+ibdwaX5eqVUHiSde0Uk+tO+9wA77MePATeISJmIzMP6VPCVHIw5I8GAsHzWRBqqS2nL16Yiudhxr6wG6k9N/326LbVSWUmaSRaRB7DKdhtEpAX4MhACMMbcA1wL/H8iMgT0AjcYYwwwJCK3Ak8CQeB+u1bZU+UhqwVcOGwIeLGQw+vuFvHau4FDn+QUtqWOe36H9yulip4xxnHuFZE7gXXGmMeAW0XkEmAQOIZdamG/7iFgCzAE3GKM8TDr4I7J1WXsbuvOz8Vz0QIuY7pwT6lsJA2SjTE3Jnn+B8AP4jz3OPB4ZkPLTEXICiT7h8JUlHrQucjrcouELeCS9Ul26OMc7xzxrqGUKnpOc68x5vaox59O8N6vAV/zbnTua6gp40hXP/c+v4t3nTaZ06fV5u7iudhxL1M6xyuVFd+lEivtwDituuQvvAW3vZ3aa51KHNyUcDORZDXJQY/LLSI0K6GUKhwN1aX0D4X5pye28v9e2pPbi49LXhQgLbdQKiPu9S4rEJFMclpBcuWkNK7gdblFCjXJI9871SQnK7fIYjORQv4loJQ6aTVUj7ak3Lj/RIJXeqCQM8labqFUVnyXSS6PZJIHhpK8MkP57G4RSGHhnpZbKKVOMtGbimw71Emflx2OYkXWihTifKoL95TKiu+C5MpIJnkg7M0FctXdwrHcInbHPaeFe7kot1BKqcIRySTXVYYYChu2HurM3cVz0QJOKZUXvvtXXZFJTXI6PO9ukaC+LbYmedzCPY/LLSI0K6GUKiAz6yqYVFXKZy45DYCNLcdzd3Ett1DKt3xXk1xuZ5J7irbcIoVMssTJJKcU9Ea3gNM+yUqp4ldTHuLVL10CwHef3ZHbuuRCXrin5RZKZcV3QXKku4VnNWn5bAE3rk9ylpuJ6MeDSimfsPe0YumMCbzRkocguSCTCIU4JqWKh++ipIy6W6QlR+UWCTPJCbalTmczEaWU8pmlMyawo7XL251XoxVyJnmEZpKVyoT/guTSSLlFkWaSE3W3kNhV1DGvCQTHHxt3Dje6W+iEq5QqTEtnTmA4bNhysCM3FyzkT+RGyi3yOwylilUB/+vOzMjCvZwFyW53t0gUJMcEx7HXnvMOmL06yfm1T7JSyr/OnDkBgE25qksu6O4WunBPqWz4riZ5pNzCsyA56YEsz5+g3CK2H2ds0Prur6Zx/jjXUEqpIja1tpyG6jJetztcbGw5wc/W7uXrH1hKMODBnFfI5RaFOCalikgh/q9vVkLBAGUlAbr6ve5ukSDj68b5HTPJSWqS0zl/vGukQldKK6UKlIhw/vx6ntp8mBO9g3zrqW3897p97Gj1qHdyQS/cs+mcrVRGfBckA9RWhOjo8yhIjkyEwVL7W7d/hHFKKWC0Jpk4NckpnT6b7hYF/EtAKaVsf/muU+nqH+LLj27ihe1tAGza71GNciHvuKflFkplxZdBck15CR19g96cPBJYlkS2Qc1nn+Qsg2QNepVSPrR4ei1XnDGVRzYcoDQYoDwU8K5GuZAzySMxsgbJSmXCdzXJALXlITq9yiRHJsSRTHIOyy2S9UlO5/yZvl8ppYrAd29YwcfePkZ5KMjXfrvF+yC5IOfTQhyTUsXDl0FyTXkJHb1eZZLtSSeSSXa9u0UWO+6ldf4M3w/oR3dKqUJXWhJg9Sn1ACyZPoGH1u1jOGzcX7wXryVnQdE5W6lM+LLcwqpJ9rjcIhiKHHD5/IlawLkRJEefN82xF2SmRCmlEjtjxgR6BobZ3dblzQVW3wILLvXm3NnQbamVyoovM8m5KbeIZJK9KrdwWrgXm2XOpNxCnB8rpZRPLZ81EYD1bx9nQWON+xe4/Ovun9MVunBPqWz4M5PsZblFZNIp8ai7RaKP7sb1Sc5XuYVSShWPUxqqmFgZ4tW9x/I9FKVUEfFllFRbEaJ/KEz/kAcbisQu3HP/AvaXRNtSZ7FQxI3uFvrRnVKqiAQCwlmz63j17WMYY/jxmrfY6VXf5EKi5RZKZcWXQXJNuVVF4knJRWTS8brcIhLAzrsw/nM530xEyzOUUsVp5Zw6drZ2cc/zu7njN1v47rM78z2kHNByC6Wy4csgubbcWlTnScmFeF1uEZUl/vwOuPb+0efGNa3XFnBKKZWKs+dOAuCff7eVgMBzW1u9+bSxkOgcr1RW/Llwr8K6LU923YtduOdVdwuA6inQH/WRoKuZZJ08lVInj7Pn1vEfH13F9tZOGqrK+MLDb/DSrnYuWjgl30PznpZbKJURX2aSa+xMcqcXbeBGdtzzeDMRp+9jO19kU5OcVQZcJ1ylVHERES5Z3MhfNc3n6uXTqS4r4RuPb2XbIT/XJmu5hVLZ8GWQPFpu4UUbuNiaZA/LLaK+N8j4HspZBclZto9TSqkiVR4K8v0bV3Ckq58vPPwGD7/awp//+I/5Hpb7dOGeUlnxZ5A8Um7hYSZ5pLuF15lkqw7ZOHalyCbQ1YBXKXXyumjRFD563lzeaDnO3c07+d+trXT1e9RfP290nlcqG74MknNSbhHZcc/17GpMEOtUQ5xNyYQr5RZKKVX8LlhQjzGwq60bgH1He/I8Iq9oJlmpTPgyUqoqDRIQj8otRlrA5aC7RdT3xqkrRa7LLSL0ozullA8smzmRmrLR9eu+C5K13EKprPgySBYRaspD3pVbSBACkYnVw+4WAIHIX1GibarTukDM10zeq5RSxa8kGOBdp02modpaY7LvWC8Am/afwPgisNSFe0plw5dBMkBdZYhjPR4FyYGgQ89it87vEMRKIE4mWcstlFIqG1//wFJ++6kLqCoNsu9oDy9sb+O933+Rx14/wNrd7RztHsj3EDOni62Vyoov+yQDNFSXcaSz35uTB0qigmSPyi1ijhlxqEnOZjMRnTyVUooJFSEmVISYNamSlmM9/Pe6fQD829Pb2Xu0hxvOns0/fWBpnkeZJV9kxZXKPd+mExuqyzjS5UGQHCm3sLtOeNbdYkxQHGTsX1WeNhPRwFop5VMz6yrZtL+DpzcfZkJFiD3tPRgDT20+xNBwON/Dy5DO2UplI2mUJSL3i0iriGyK8/yHReQNEdkoIi+JyLKo5/bYxzeIyDo3B55MfXUp7V58TCYBq07Yq3ILp0ktbrlFvjYTUUoVMhG5XES2ichOEbnN4fnPicgWe+5+VkTmRD03bM/ZG0TksdyOPH+mTijjUEcfA8NhvnP9cqpKg1xy+hTauwd4Zc/RfA8vM7pwT6mspBIp/Ri4PMHzbwEXGmOWAv8I3Bfz/EXGmOXGmFWZDTEzDdVlHOsZcD8DIDJ24Z5nO+5FnTcQdO6TnFVNciaDU0oVOhEJAncBVwCLgRtFZHHMy9YDq4wxZwK/BL4Z9VyvPWcvN8ZcnZNBF4AzZ0wE4F+vW8ZFi6aw/vZ38/0bz6IiFOQLv3yD375xkP9c8xYX/2uzTxb1KaWSSRplGWNeAOL+b7Qx5iVjzDH727XATJfGlpWG6lKMgaM9LmeTJWAFyF6XW4w75lZNsgubiegvCKUK2TnATmPMbmPMAPAgcE30C4wxzxljIv3OCmbezqfrVs1kw+2X8sGV1o+itCRARWmQuz68guGw4b7f7+b1fcfZ3dZNm73exRjDA6+8zbGCXdyn3S2UyobbC/c+DjwR9b0BnhIRA9xrjInNMo8QkZuBmwEaGxtpbm5O68JdXV1j3nPokNUj+XfPrWF2bTDOu9K39OgxqgeH2L9nL6cAv1+zhuGSKtfOP3//AWYCW7dv51BnMwDnDw8TDoRG7m/qwW0sAl5dv57OXd1pnb9ksIsLgMGhYdak+TOe0bKTBcCaNWsYLK1N673JxP79+Ymf7w38fX9Fem8zgH1R37cA5yZ4fey8XW6Xxw0B3zDGPOL0pmznbCiOn28AmF89xMbWE/R1dQDwy6fXsLg+SGtPmC++0MuGzdu4Yl5ozPsK4d4qeg5wLvDmli0cPuruWArh/rzi53sDf9+f2/fmWpAsIhdhTbYXRB2+wBizX0SmAE+LyFY7Mz2OHUDfB7Bq1SrT1NSU1vWbm5uJfk/VnqPcteFl5i46k3edNjmtcyW0/24YOswpCxbBW/DOd14IZdXunb/vSdgPixYuYtFZTdaxP5QxHA6O3t/6/bANVq5cCTNWpnn+DlgDodJS0v0Z84ftsBPOP/98qKpP771JxP79+Ymf7w38fX9+vjcAEbkJWAVcGHV4jj1vnwL8r4hsNMbsin1vtnM2FM/Pd/3gdl783x1UlJcBfVRNO5ULz5vD2t1H4YW1BCZMpalpbAeMgri39l3wCpx++umcvszdsRTE/XnEz/cG/r4/t+/NldVbInIm8B/ANcaY9shxY8x++2sr8GusjwFzor7K2hGvvdvlDheRPslLr4MP/Lu7AXLk/A7HXO+TrEXJSvnVfmBW1Pcz7WNjiMglwN8DVxtjRibKqHl7N9AMrPBysMVgxsQKjIGDJ/oAeOCVt1l6x1Os32dVGu5tT+8TvdzTcgulMpF1kCwis4FfAR8xxmyPOl4lIjWRx8C7AccOGV5oqLF2UDrS6UVNchBqGuHMD7l7bnDuXOFJn+Rs/up1wlWqgP0RWCAi80SkFLgBGNOlQkRWAPdiBcitUcfrRKTMftwAnA9sydnIC9T0iRVjvt96qJOu/iGe3nIYgD1HCjRI1u4WSmUlabmFiDwANAENItICfBkIARhj7gFuB+qBu8X6Bzlkd7JoBH5tHysBfm6M+Z0H9+CopqyE0mCAI65nkiVq0Z4XHALfQBDCbnW3yKZ9nGaflSp0xpghEbkVeBIIAvcbYzaLyJ3AOmPMY8C3gGrgF/Yc/bbdyeJ04F4RCWMlUb5hjDnpg+RpE8tHHk+sDHHc3s31jZYTABw40Uff4DDlIS9/N2RCF+4plY2kQbIx5sYkz/8F8BcOx3cDy8a/IzdEhIbqUvczycFSCJUnf12mnLLE4zLJ2idZKRWfMeZx4PGYY7dHPb4kzvteAop8ezn3TZ8wmkm+eOEUHtmwn1AwQP/QaIvRve09LJxaw/ef3cG2w51cOz0fI42hiQ2lsuLrSKmhxoNd9y76O7jqu+6eM1rcmuToDIXWJCulVK5UlAapq7S6V3z20tN44tPv4owZEwCrJz/AW3bJxVNbDvPU5sMMhQsoe6vlFkplxNdBcn1VqfsL9xoWpN9RIh1xapLHZpbd2ExE+yQrpVSqpk+soCQgzJhYwcKpNcxrsFp/nneq1eln26FOhsOG7Yc7GRgOc6jbmieHw4afrd1L3+BwHkat5RZKZcPXQXJDdZn75RZeS6W7RandUSNUMf61qZ5fyy2UUiplM+sqmDaxnEDACjwjQfLCxmpWnzKJ+9e8xfq3j42UYLzdaX39w1vtfOmRTTyyflyDEe/pwj2lsuLrSKmhpoz27v7i2kI0Tk3ymO8XXAp/9juom5vB+V3YcU8ppU4y//eyhXz7Q8tHvj/FDpKnTqjgq+87g56BIT794IaR5/fZQfKeI9bGhmt2tZN7Os8rlQ1fB8n1VaUMDhs6eofyPZTUOWV4A8GxmeRAEOacl901dO5USqmUzZ9Sw9lzJ418f9acOuZPqeas2ROZP6WG68+exf7jvYjAKZOreOKtQa6/92W2H+4E4KWdRwjnrU65iBJFShUQXwfJk+1eyW1uL97zVLw+yS7+VUlA+yQrpVQWGmvLeeZzF3LKZKv87S8uOIWAwNz6Kubbx/7w1lGe2HQQgPbuAbYe6sztILXcQqms+DpIrq+yguT2YgqS45ZbuBwkZ7QRiaaflVLKydyGKv7ywlO5duVM/u9lC3nPPKsbxuGOfpbOmEBJQPj7RzZywu6xnBu6cE+pbPg6SG6osbamPtJVRIv3nAJRCY7tk5z1NQIa8CqllMv+9vJF3HLRfBY01nDdwlKm1lo99c+ZN4m7PnwWr+87zo9e3J3SuW7+yTrufX6Xl8NVSiXh7yDZ7l/peq9kLzm2gJPCKrfQj+6UUiqpZbOsXspz6yu5bMlU5tZXsaO1C4COvkHaOp1/N3X1D/H0m4d5YtOh7Aag5RZKZcXXQXJdZSkBKdZyiyiBIO7+VQmZrdzT7LNSSqXqzJkTAZhTb3XCmNtQxZ72Hl556ygX/0sz197z0kj3JWMML+44wnDYsOVAB8bAmwc7GBoOxz1/clpuoVQ2fB0kBwPCpKpS2oqq3CLettRuZ5I14FVKKS9dtmQqZ8+tY5kdLM+tr2Jvezf/8MgmOnqH2Nvew8b9JwB4aVc7N/3oD/zoxd0jx/qHwuxq6858ADrPK5UVXwfJYC3eK6pMslO2dtF7aa8/28VLZNvdQimlVDLzp1Tzi0++gwn2ltZzGyrpGRhm2+FOblo9h2BA+MW6Fja2nOC5ra0A3N28i5d2HiEUtH4XRALmjAStdTkMFVGiSKkC4vtIqaGmtMhqkh22jX7n59g/870uXiPTcosI/ehOKaXSNdcuuwC45PQpnDN3Ej9du5erfvAiD7/WwuxJlZzoHeTZra2cO6+eilCQTdkEyZHdWQdy3HpOKZ/wfZA8bUIF+4715nsYqctFhjfTcgv96E4ppTIWCZIDAstmTeTWi+dz7cqZTKkp41jPIB8+dzb33LSSilCQy8+YytKZE3hx55GEu8b+9OU9rNl5xPnJklIIlkG/BslKZcL3QfKCKdW0dfbnuDdlFnIRiGq5hVJK5dz0ieWEgsLp02qpKivh/PkN/Mt1y/jilYsIBoQ/Ob2Ry5ZMZcudl/Hhc2dz/apZ7Gzt4oUdzkHwiZ5BvvKbLdyTqFVcWTX0d3l0R0r5m+8jpQWN1sdNO9uK5P+kncotPLmGZoWVUiqXSoIB/mRRI1ctmz7m+PtXzOS1f7iU+VOs31cigohw1bLpTKkp44fNOx2zyc9ta2UobNh8oGPk+cHYbhhlNZpJVipD/g+Sp9QAsONwkfyfdM7KLbJ4v/bcVEqpjNzzkZV88sJTxx2fUBEad6y0JMBfXzyftbuPcu8Lu8cFyk9vOQzA0e4B9rT3cO0PX+Lif20mHI56XakGyUplyvdB8oyJFZSHAiMN3AveSAbZ40xyRsG4Zp+VUiqXblo9h0sXN/KNJ7ZyzV1r2N3WxbKvPMUrbx2leVsrp0+rBeCj9/+BdXuPse9oL/uO9YyeoKwGBork959SBcb3QXIgIMyfUl08QXIuAlEtt1BKqaIgIvzgT1dw60XzeaPlBP+9bh8negf54q/eoHtgmE9dPJ+AwL6jvVwwvwGAzQc6Rk9QVgP9HXHOrpRKxPdBMlglFzsOF8nHTbmqSdaFe0opVRTKSoJcvdyqY/7tGwcB2NXWTVVpkItPn8L8KdXUVYb4zg3LCQaELQc66OizF6vrwj2lMnZSREqLptZw8EQfR7uLoKF6TmqSyTII15pkpZTKpbn1VYSCQktUS9OmRVMoKwnyES0j3wAAIABJREFUTx9Yyn987GwaqstYMKWan67dy/KvPMWvXmvRhXtKZeGkCJKXzpgAZLlzUa7kqiY5k/Nrn2SllMqL0pIA8xqsPsvnz69nwZRqbjh7FgAr50xi5Zw6ABZPq+VEr5VF/tuH3+D4cJnWJCuVoZMiSF5iB8lZ7VyUKznrbnFS/NUrpZRvnNZodWtaOWcST3/uQt65YPK416yYU0cwIHzt/UsZHDa0D5bBYA8MD+V6uEoVvZJ8DyAXJlSEmFtfyRstx/M9lORyVpOsWWGllComCxtr+B8OssDup+zkxrNncdHCyXT3DwPQH6y0nhjohIq6XAxTKd84adKJS2dOZNP+YljhW8DlFhHaJ1kppXJu5dw6SgLCspkT476mJBhgZl0loaA1x/cHrBINXbynVPpOniB5Ri37j/fS3tWf76EkVtDlFpp9VkqpfHnHqQ2sv/1SZtdXJn1tKGjN8SOZZF28p1TaTqIg2fo/74JfvKflFkoppeKoKR+/M5+TSJDcF4iUW2gmWal0nTRB8pIZ1q5EG1sKPUguhs1EtNxCKaUKWaTcolcqrAO6oYhSaTtpguTa8hCnNFQVQSY5FzXJklkwrtlnpZQqCqES69d7j0TKLTSTrFS6TpogGeCMGROKIEjOVU2yBrxKKeVXoYD1u6Q3oDXJSmXqpAqSl86YwMETfbR29uV7KPHlqiZZF+EppZRvRcoteoxdbqE1yUqlLaUgWUTuF5FWEdkU53kRke+JyE4ReUNEzop67mMissP+8zG3Bp6Jd8yvB+DJzYfzOYwkchG8SnYZa20Bp1RBE5HLRWSbPSff5vD850Rkiz1fPysic6KeK5g5W2UuGBBEoAc7SO7TmmSl0pVqpPRj4PIEz18BLLD/3Az8EEBEJgFfBs4FzgG+LCJ562a+eFotpzVW88j6/fkaQnIjwauHwXLFRCifkMEbNfusVKETkSBwF9a8vBi4UUQWx7xsPbDKGHMm8Evgm/Z7C2rOVpkTEUKBAP0EIVgKg935HpJSRSelINkY8wJwNMFLrgF+YixrgYkiMg24DHjaGHPUGHMMeJrEwbanRIT3r5jJq3uPsedIgU4YuSi3eP+98J5ve3d+pVQ+nQPsNMbsNsYMAA9izdEjjDHPGWN67G/XAjPtxwU1Z6vshILC4FAYQhUwWMBlhkoVKLdqkmcA+6K+b7GPxTueN+9fMYNgQHjglbfzOYz4crGgrnoKVNV7fx2lVD6kO+9+HHgiw/eqAhYqCTA4HIZQJQz2JH+DUmqMknwPIEJEbsYq1aCxsZHm5ua03t/V1ZXye1ZMDvCzl3ezsuwQpcHCKiGY1L6ZM4GNGzfRfrBi5Hg69+eVqQe3sQh4ee3L9JfvcvXchXB/XvHzvYG/78/P9wYgIjcBq4ALM3hvVnM2+PvnWwj3Fh4aYm/LfnoHDR379/Kmi+MphPvzip/vDfx9f27fm1tB8n5gVtT3M+1j+4GmmOPNTicwxtwH3AewatUq09TU5PSyuJqbm0n1PeWz27nhvrUcnzCfD62alfwNubRjEDbC0qVLYWHTyOF07s8z61tgG5y3ejVMnO3qqQvi/jzi53sDf99fkd5bvPl4DBG5BPh74EJjTH/Ue5ti3tvsdJFs52wo2p9vSgrh3qpffpbJUxqokHoqJtXS6OJ4CuH+vOLnewN/35/b9+ZWucVjwEftLhergRPGmIPAk8C7RaTOXvzxbvtYXp07bxKnNVbz/17agym0Tg2RcgvtY6yUyswfgQUiMk9ESoEbsOboESKyArgXuNoY0xr1VEHO2Sozo+UW5TDYm+/hKFV0Um0B9wDwMrBQRFpE5OMi8kkR+aT9kseB3cBO4N+BvwIwxhwF/hFr0v4jcKd9LK9EhI+eN5fNBzp47e3j+R5ODA2OlVKZM8YMAbdiBbdvAg8ZYzaLyJ0icrX9sm8B1cAvRGSDiDxmv7cg52yVmZKAMBg2dk2yBslKpSulcgtjzI1JnjfALXGeux+4P/2heev9K2Zw5/9s4cnNh1g5p4A6HOWiBVy2Ci37rpQawxjzOFbyIvrY7VGPL0nw3oKcs1X6QsHAaHeL7rZ8D0eponNS7bgXraqshEVTa9h8oMC2qc7FttQZK+DAXSml1BilkXKLEi23UCoThRyReW7xtFq2HOgorLpkrUlWSinlgpKAMDRSbqEt4JRK10kdJC+ZXsuxnkEOniigJuvFUG6hlFKq4IWCAQaGIgv3Evye6ziQu0EpVURO6iB58fRaALYcKKA97Qu63CKigDLvSimlHJWO2UwkTrlF+y749mLY90puB6dUESiGiMwzi6bWIgKbCylIjmSQCzGRrCUgSilVNELBgFVuUVIOQ3GC5I4DgIHOgzkdm1LF4KQOkqvKSlg6YwK/eeMA4XCBZEfLaqyvpdX5HYdSSqmiVhIQu9yiEsJDMDw4/kUD3dbXof7xzyl1kjupg2SAj18wj52tXTy7tTX5i3Nh6hnw8Wdg1rn5Hkl8hbTQUSmllKPRzUQqrANOJReDkSC5gNbmKFUgTvog+T1LpzGzroJvPbmVvsHhfA/HMuvsAi1tKMQxKaWUclIaKbcIlVsHnIJkzSQrFddJHySXBAP84/vOYPvhLv71qW35Ho5SSinlipKA2JuJVFoHnOqSB+zWcJpJVmqckz5IBrho4RSuXDqVRzZoGxyllFL+ECoJMDBsL9yDOJnkLuurBslKjaNBsm3FrDraOvs52j2Q76EUAa1JVkqpQlcajGoBB3FqkiOZZC23UCqWBsm206ZaXSW2H+7M80gKWEHWSSullHJSEhCGhsMp1iRnmElu2wZ71mT2XqUKnAbJtoWNGiQrpZTyD6u7hUmcSc524d7z34THbs3svUoVuJJ8D6BQNNaWUVtewtNbDiPATavnIJo5VUopVaRCwQADw2FMSbnVm8hx4V6WmeSBLug7kekQlSpoGiTbRIRpEyr4/Y4j/H7HEd65YDJzG6ryPazCpH2SlVKq4IUCVqJnOFhu/bJPVJM8mGGQPNgD/foJrPInLbeIsmRG7cjjV/cey+NICpVm1pVSqliESqxf8YMBD2uSB3theEAX/ilf0iA5ypffu4THP/VOaspLePVtDZKVUkoVr1AwEiSXWQe8qEmOZKA1m6x8SIPkKBMqQyyeXstZs+t4cccRvvm7rZzocdjrXimllCpwoaD16d+g2EGyFzXJkXKN/o7M3q9UAdMg2cHKOXW8fbSHu5t38aM1b+V7OEoppVTaRjLJkiCTnG2f5Mg542WSu49Af1dm51YqzzRIdvC+5TO4fMlUzpo9kZ//YS/9Q8P5HlJh0G4fSilVNEaC5LCBkgpvdtwbySTHCYR/+j545o7Mzq1UnmmQ7GB2fSX3fGQln7t0IUe6BnjwlX35HpJSSimVlpFyi+EwhOIFyUkyyYO90LIu/kWSZZI7DkL7zhRHrFRh0SA5gfPn13PB/Aa++but7Dvak+/hKKWUUikbySRHNhQZjPk9NjwEw3ZwHC+TvOHn8KN3Q+/x8c+Fw6PvjxckD/ZAV2sGo1cq/zRITkBE+MYHlyIi3Prz1+gbHOaZLYd56I8neWZZ+yQrpVTBGw2Sw1A9BToOjH3BYPfo43iZ5O42MMPQ69DxKXohoNPCvXDYDpIPpzlypQqDbiaSxMy6Sr79oWXc/NNX+ZuHXuf3O9oYDhuuWTGdspJgvoeXY1qTrJRSxWJMucWkebD/tbEviHS2CITiZ5L77ODXKVMcXb7h9HwkiO5ph+FBCIbSGL1S+aeZ5BS8e8lUPnPJAn678SAdfUN0Dwyzbo/2UVZKKVW4xpRb1M2FE/usEouISD1y5aT4meR+e8tpxyA5qnzD6fnI+TFWlwuliowGySn61MUL+Oh5c/jkhadSGgzQvO1krrHScgullCp0Y8ot6uZCeAg6WkZfEOlsUVlvZX2dSukSZpKjss+xzw90jy3n0JILVYQ0SE5RICDcec0Z3HbFIs6eV8ezb7YyHD7JgkVtAaeUUkVjTLlF3Vzr4LE9oy+IZIIrJoEJW0F0rEitsVPNcXQmeSCqBVxfB/zLabDxF6PHdPGeKkIaJGfg+rNns/tIN3c/p21tlFJKFaax5RbzrIPH9lidKg5vHq1JrqyzvjrVJfclCpLjLNzrbrOC5kMbR485ZZKNgfU/g+721G5IqRzTIDkDV505jauXTec7z+5gZ2sXj27Yz8BQON/DUkoppUaMKbeonW4t0Dv6Fqz5Dtx/xWhgWzXZ+upUl9zvUG6xu5nQwPGoTLKMfT7yuPPQ6DGnIHnzr+HRW2DNv6V/c0rlgAbJGRAR/v49pxMU4fp7X+bTD27gsdcPJH+jX2gLOKWUKnhjyi0CQZg428okH9trLcg7/rb1wtoZ1tdEmeRje+FHl0H7LvjZtcxs+c1oJrmqYWyQHCm96Dw4esyp3OKVf7e+Bssyu0GlPKZBcoYaa8u5btVM2rsHAHhq8yGe2nyII11xVggrpZRSOTSm3AKgbg4c3zua4W3bbn2tmWZ9dcok99ndLfa8CPvWwpZHITxIaLBjNKiubkycSZbA+Exy+y54+yXrcSSo7j02djGgUnmmfZKz8LlLT2NmXSW727p4+LUWntpymPeeOY1/uW4ZAOWhk62PslJKqUIRCZJHygEnzLLqhEurrO+PbIPyCVBWbX0fm0ke6h/dUe/YW9bXgxsAKBnqGi23qJ4CrW+Ovq/fDnqHB+zrzhyfST4R1WWj9xg89tfw2k9g8TXwoZ9kcrtK/f/s3Xd4VFX6wPHvmT6T3nsPNfTeREBQ7LoW7KuuddW1rLtrWbu7P3fd1VXXhrp2UbEgKIogBKV3CBBKCCEhvfcy5f7+OJNKIgFCCpzP88wzM7fNuRO488477zmny3UqkyyEmC2E2CuESBNCPNTO+heFENvct31CiLIW65wt1i3sysb3tABPM3dOS+CSkRG4NNDrBD/szGPmCyu546PNAGiaRqk726woitIdOnHNniqE2CKEcAghLm+z7pS9Zp9uvK0yD1Zea5cLfKNkp7rybPm8aL8c/s1gkc/bBsl1LTrjNY58kSODZKO9qrncwjOk9bYNbYaD84mG2pI2x3ZnqIVediTc7f6n1lgCoii9wFEzyUIIPfAqMAs4DGwUQizUNG134zaapt3fYvt7gJEtDlGradqIrmty7zMhPoAHz+7PiCg/rntnPYdLazlcWktWSQ2fb8rinVUHWfPQDHxtpp5uahdRNcmK0lt15poNZAI3Ag+2c4hT/pp9urCZDHiaDRRWurPBPtHy3uUOmusrIGggGNw1wW3LLdob0aLsENAmk+yfIMdErimRE5O0HTPZN0pmrVtqDJL9YmUpRp07t6apTvBK79GZTPI4IE3TtHRN0xqAT4GLf2X7q4F5XdG4vkKvE9w9ox9T+gXy6HmDeOaSIQgBzy/Zy5sr06lpcPLz/lNgtiE1TrKi9AVHvWZrmpahadoOQEUkp7ggLzOFjX1lfKOO3KBlJnn/j1BV2LyuMZDlyGu/DJLdmeeQwfK+xF2SUd9izGSE7BhYUwKuFv/cWgbJxS2GU1U1yUov0pma5Aggq8Xzw8D49jYUQsQAccDyFostQohNgAN4TtO0BR3sextwG0BISAjJycmdaFqzqqqqY97nZOgHUAdJ/noWbs/BwwgGAZ8k72D91l3sL3MyOcLA8KBjKwfvDecXVLCbJGDDhg3UeOQedftj0RvO72Q5lc8NTu3z66Pn1ulrdge65ZoNffb97ZTecm5GZy37MmtJTk7GXFfAxDbrcysayN6+kzEAq16kYO9Gdif9CQDf0u2MAOpNfpgbWpdLGOyVZKbvJUJnYvOBYsYBu1d/S0FIJQnpqTSG406dmfTcMvppTlb9tBiHUdY/xx7cTgyC3BoD4e6Oew69BXtVGet7+H3rLX+7k+VUPr+uPreu7rh3FfCFpmnOFstiNE3LFkLEA8uFECmaph1ou6OmaXOBuQBjxozRpk2bdkwvnJyczLHuczINH9vA3vxKEoM9eXrRbhZuz2FdrhNvi4ENefW8cvVgfG1GzAY94+L8j3q8XnF+O4thN4wbNw6CBnTpoXvF+Z0kp/K5wal9fqfyuf2Kbrlmw6n9/vaWc5ufvYXUvArZFqcD1t8BmhOZHdYISxhC2PDJILvREFy8juBR/eW4yrsrYDuYg+Ihu3WQbHTWEh3iB0WejDv7Stj4BwaHmBk8bRqUz5dfzQC91Yt+w8ZD2ttMGTUIAhLkiprFkO9DeEIS5C4BwBAQj6GmpMfft97ytztZTuXz6+pz60y5RTbQ8jeaSPey9lxFm1ILTdOy3ffpQDKt65VPWX4eJibEBxDoaWb2kFAA/nr+IDY8OpNIPyvfbMvhT/N38Pg3OwHZwa+81s57qw/2/umu1TjJitKbHcs1+win6zX7VBXkZW6uSdYbZPALzdNU2wKaa5IBXE7Y/L583FiT7OMeR1lnbH3wyjww2sBokSNYlKS792tRbmG0yjplgOoWZYd15XJkDatf8zKfqPbHalaUHtKZIHkj0E8IESeEMCED4SN6PAshBgJ+wNoWy/yEEGb340BgMrC77b6nuvOGhrH+kbO45Yx4LEY9kxMCWbmvgLyKOvbkVfLMt7uZ9q9kXly6jycX7WZVWm+tX1Y1yYrSB3Tqmt0edc0+9QR5mamsc1Bnd//A6xMFZp/m+mRbgAx0AUKHQcQoOLRajjJxwF056R0p7xtrj/XuTugVOTIIBvCPaxEkt+i4Z/SQrwFyGLn8XfJxXdmRQbJvVPtjNStKDzlqkKxpmgO4G1gCpAKfa5q2SwjxtBDiohabXgV8qmmt0oyDgE1CiO3ACmR922l5wQ3xtjQ9npDg3zy4O/DOqoMcKq7hvTUZAPy8r7njxF2fbOGjdYe6rZ2KovRtnblmCyHGCiEOA1cAbwoh3JGLumafaoK8ZJa4KZscNVYGwo2Bqy0QvELh0rnw24UyUM7bAd/eDzu/lNs0Zp/D3IOeBPST95W5LYLkeDlBCDRPDgJgsjW/1pJH5Kx9mtYik+wr1xk9wOovM8nq10qll+hUTbKmaYuBxW2WPd7m+ZPt7LcGGHoC7TsljY+TF4xofxv5FXXUO1xNP4mFeJtZua+Qx4BdOeV8tyOXw6W13DtYw+nSyC6t5duUHO48MwGhRptQFKUdR7tma5q2EVmG0XY/dc0+xTQFyVX1RPnbYNbTcsV37tH/GgPY4XPkfdgw2PwuHFghnwf0a872RoyCLe/LjHLBLjl0W2PZRkCiHAu5LFOWW+jNciISY4sguaZY3teVySDZP7752J5B7rIPDZx2MJwqQ6YqfZmaca8HhPtaGRfrz5R+gaxLL2ZXTgXzb5/IqrQi6uxOnv0ulXdXH2RXjqwH25Vdzht2HW/sW8ewCB/eXnWQCfEBjIr2O8ordbHGn9hUzZiiKEqfEOTZJpPcqCmT3KbjeKicMRbNCVe8B4MuhoMr5bKYKXDVPDl5SMr81scZfDEsexLWvibLLbzDoDRDzu5ntMlh5ho/O6qLZJBs9W0Okj2CW0xqUquCZKVXUEFyD/n8DjkQzwXDwqiocxAb6EFsoAdZJTW8+XM6Ty2Sv3AGe5kpqKxnQ54TKKHIPd7lt9tzuz9IbvxZrGnsTEVRFKU3C3ZnkgvaBsmhQ2R5g1dYmx0GgdDJST1iJoNOB/HT4O5NEJgoby2nmI6eIO99o2HoFTLTbK+R+5ZmyHIMIWQwXeHuP1pV4C63aBEkewZ3PKmJovQQFST3sPggz1bPo/xtbHjkLA4UVvF9Sh5T+wdx6WuraRzwIr2wGoDvUnI4d2goY2L8uq/swuIj7+vKfn07RVEUpVfw9zCh1wkOuj87mgy6UN7aMtkgsL8Mkj2D5TIhILBf8zYW3+bHsWc0Px59E2x3D3Dl7R4Rw+gh723+zUFyZa6sW7b4NB/LI6i5vln9Wqn0Ep0Z3ULpZkIIEoO9uOesfgyP8mVYpC9xPjqsRj0AF48IJ7+iniveWMuKvQVHOVoXaryY1aogWVEUpS8w6HXMHBTM11sPU9vgPPoOAOc9Dxe8+CsHbVEKETa8+XF4i9nMGzv7mdwjZzSWZUDzDHsWHxkYBw+W9c5N5RYqk6z0DipI7gPeumEMD4y2MCZW/iz11/MHs+yBqXiaDSzdnc+LS/fxyfrM5iF+2qiqd3D562vYfKik3fWd1lRuoYJkRVGUvuLmyXGU1thZsK2Tw2XHTYXYKZ3bVqdvfmwwyw58IMs4hB7MXvK5b7TsBCh0ULRPLrP4yCz179fCqBtalFuoTLLSO6hyiz4gyMuMl0nw24mxxAV6EORlJsjLzJTEQL7cnE2D0wXIEoxbpsTT4HRRZ3fy0k/7eeHKERRV1rPpUCkfr89kdMzRZ/frkMlTXvRUTbKiKEqfMS7On7hAD5btzufqcdFdcszNo/7F6DPOPnJF8CCZKTaYYc5HcrQMgLOfBXstvDEFivbLZS3LNkBlkpVeRwXJfcjMwSHMHBzS9HzGwGB+2JVHlL+V286I57FvdrE6rRidAE+zgYo6B1fPXceUfoEA/JRagN3pwqhv/weE8ho7c+au5fELBzMpIfDIDYSQ2WRVbqEoitJnCCEYGuHD5kOlXXbMSu9+4Bdz5IqI0ZC6SCZTxtzUvNziI28ewc3jKTf2c2mkMslKL6PKLfqw6QOD8TIbePDsAVw/MZY/zx7APTMSifSzUVHn4I3rRuNwuVi6Ox+bSU95rZ3L31jb4eQk36Xksiev8tcnL7H4qHILRVGUPmZgmBfZZbWU19pP7guNvxPOeBDG3Nz+es8gsLs7EXqFtl7XmEm2qyBZ6R1UJrkPC/Iys+2Js9Hr5OgWv58ma8EuHx3JvvwqZg0O4eIREXyx+TA3Torl041ZpOZW8PS3u5mSGEhsoAd1dic7DpczKtqXhdtlvdryPQUUVtbz6oo0YgNs3Dg5rvlFLSqTrCiK0tcMCvMGYE9uBePjA46y9QkwWuCsxzpe7xEk7wMS5VTWLTWVW6ggWekdVJDcxzUGyC3FBHgQEyCH3bnjzAQ2HCzh0pER3DOjH2W1DZz9ws/c/uFm/nvNSBZuz+GV5WkEeJgoqWlgcmIAq9OKmfb8CqobnFiNei4dFYmP1SgPbvVVNcmKoih9zKBQd5CcV3lyg+SjaSypGHBeO+tUkKz0LipIPsUlBnvy85+nNz23mqy8eu0o7v9sG9e9sx6DTsfgMG8GhnlRXmPnmUuG8My3u9HpBONi/Xli4S6ueWsdfjYT7988Dr3FV047qiiKovQZId5m/GxGUnMrerYhDe5Si8SzjlynJhNRehkVJJ+GpvYP4vXrRnPlm2sBuH9Wfy4fHdm0/vXrRjc9XrQ9h03uzh4r9xUwQ3XcUxRF6XOEEAyJ8GFbVg9fv2c9DSFDIHbqketUJlnpZVTHvdPUuDh/pg8IwmLUcU5SSIfbvXbdKH647wyCvcx8sPZQc8c9TevG1iqKoignamJCAHvyKilsO0V1d/KNhqkPyumu21KZZKWXUUHyaezFOSP46s7JeFmMHW4T7GVhYKg3l4+OZOW+QhqM3uBygL2mG1uqKIqinKgpiXJoz9VpRT3ckg6oTLLSy6gg+TTmazMxONy7U9uG+1rRNKjTu2dPUiUXiqIofUpSuA++NiO/7O+tQbIaJ1npXVSQrHSK1SinHq03uoNqNVayoihKn6LXCSYnBrJibwH1DmdPN+dIQshssgqSlV5CBclKp1hNMkiu1XvKBSqTrCiK0udcNTaKkuoGFqfk9nRT2mcwq5pkpddQQbLSKY2Z5Bqdu9xCjZWsKIrS50xOCCQ+yIP/Lk9jw8GSnm7OkVQmWelFVJCsdIrFHSRX69yZZFVuoSiK0ufodIKHzx1EUVUDV7+1jtzy2p5uUmsqk6z0IipIVjqlsdyiKUjuqNyiKA2WPaWGiFMURemlZg0OYd6tE3C6NNakFfd0c1pTmWSlF1FBstIpjeUWlZoHIDrOJO/6Gla9ADW97MKrKIqiNBkY6oWfzcjXW7O5/p31ZJX0kmE9DRaVSVZ6DRUkK53SGCTXOjQwe3dck9wYHDdOPaooiqL0OjqdYEJ8AKvSivhlfxGLduT0dJMkgwXsvawERDltqSBZ6ZSm0S3sTrD6dFxuUeMef1NNNqIoitKrTUoIAEAnetEEI6omWelFDD3dAKVvaAyS6xqcYPHtuNyi2n2hbVBBsqIoSm/2m1GRaEBaQRWfbsziN6+t5reTYrl4RETPNcpgUeV6Sq+hMslKp1gM8p+KzCT7Hj2T3FB1fC+05UPIXHd8+yqKoiid5mE2cMPEWKYPCKbB4WJLZhkLtzWXXZTX2NmV083DfapMstKLqCBZ6RSDXodJr5NBssWn45rkancG4HjLLZY9CRvmHt++iqIoyjEbH+/PuFh/BoZ6sTGjBJdLjk700k/7ufz1tTicru5rjC0AStIhZ1v3vaaidEAFyUqnWYw6an+t3ELTWmSSj6PjnqbJ4Lu6l9TGKYqinAZsJgOf3zGR26bGU1HnYG9+JQAp2WXU2p1klXZjR7ppD4FHIHx6Dbh64dTZymlFBclKp1lNehkkd1RuUV8Jzgb5+HiCZHstuOyqHk1RFKUHjI31B2DDwRI0TWNPrgyWU3Mr+G5HLlp3jH/vHQ4zn4SKbMjZ2rzc0QBvTJEleYrSTVSQrHSa1ah3l1v4gqP2yLqxmhYZ4OMpt2gs4VCZZEVRlG4X6Wcl2t/GB2sz2JtfSWW9A4B/LdnLXZ9s6b5prBNmAALSfmpetudbyEuBXV91TxsUBRUkK8fA0hgkW33lgrZ1yTUtLqDH03Gv8Xg1RR3P2Ofqxto4RVGU04gQgud+M5SDRdVc9N/VTcvTi+Qvg5sOlXZPQ2z+EDEK0pY1fxZsflfeZ64Hp+PIfU72Z4OmqZlkT0MqSFY6zWrSU9eYSYYjSy5aZoCPZwi4xiCQhwezAAAgAElEQVTZ5Wi/5rmuHP4RA/uWHPuxFUVRlKOalBjIH88eQINDBp3DIn2a1m3K6KZMMkDiTDi8Af4RC4v/BAd/hrARYK+GvO3y86f4gAxcU76Af8bCjvmw+mWozD/x12/5+eZywptnwKI/nPhxlT5FjZOsdJrVqG/uuAdHBrKdKbew18m6Y7PXketaZqari8Hq13p9eTbUV0DmWuh/zrGfgKIoinJUd5yZwAdrMzDodAyN8GHH4XL8PUxsPlSKy6Wh04mT34jxd8jPid3fyBGP4qfBhS/BS8Nh2zxIXwHFaeAbA9WF4KiDr26R+1blwzl/gx8fg8pcuOA/oDNAzhaInigD6w1zIeMXiJkEY28Fg6nppQML18I/LpZtOPtZ2Ya8FHmz+MpfTSPHwKgbQKc/+e+F0mM6lUkWQswWQuwVQqQJIR5qZ/2NQohCIcQ29+2WFut+K4TY7779tisbr3Qva9tyi44yyWafjsstfngIPrq8/XUtg+SaduqSa90/9RUf6HyjFeU01Ilr9lQhxBYhhEMIcXmbdeqafZrT6wQr/zSdxfeewfBIX8wGHbeeIUe+SCs8zjHwj5XNHybdAzcuhiveh6vmgV+sDHI3vgUVOTDjMQgeBAEJcPvPMO42CB8JuxfKz4v1b0DKfPjoN/DdA/DuufDx5bD+dfjhL7Jj4JJH4PlE+bm0+T3QNGIOzQeTl9z/+79A8nMQ2B88Q2DNy7DvB/j2PvjwkuYyw7py+Op22PCW/GysKpQZaE2Dw5vl8roKuSxtGaQugoLUzpWJuFzy19meGu3DXgsVuT3z2j3sqJlkIYQeeBWYBRwGNgohFmqatrvNpp9pmnZ3m339gSeAMYAGbHbv202FTUpXsphadNyD9jPJejN4BnVcblGcBkV721/X8njVhUeuV0GyohxVJ6/ZmcCNwINt9lXXbAWQfVAsRj2XjY5k2sAgahuc/OOHPaxJK6J/SDu/BJ4sBhMkXdL8/PoFkLEKvEIhdEjrbc97HrZ+BN/cBcuflaMtTb4PVv8HstZDzBS5b9oyiBgDv1sKB5Nh55ey1nnRvXB4E15VB2TWOnc7bHoH9Ca4eh54R8jPtohR8nW+ewDenApBA+TYziXpsONTWOz+b2X1A69wKNgln695WQa6FdnNbQ7oB+Nvh+wtsqQkfISciyAkCQZfAt//GfYvBWc9GKwQPR4CB0DaUtBcMngPGy6/LOz6WgazXqFQVQBVeTLAPu+f4BstXy93B8H5abCnGg4sh9wdMvFl8pTBsFeIHEmkYJfcxytcftFoqJLvb+hQ8AyVn/e+0Uf+4gvyfdi/FHyioN/ZoDllx0uXS2bgfaLk53ltiTyuZ4iMK7LWQ8gQ2QaA0kNQuBfMnvJXhcZfoPd+L887dor8kuJy16iXHuzyuvHOlFuMA9I0TUsHEEJ8ClwMtA2S23MOsFTTtBL3vkuB2cC842uu0pOsRr2clto7DHRG+dPTsCubN6gqBM9gMHl0XG5RUyz/czjtoDe2Xteq3OJXMskl6fI/m67NDyEuF+TtkBeZynyZKRhzM8RNPfaTVZS+66jXbE3TMtzr2qax1DVbaUWvEwR7WQCID/Rgxd5Cbpwc13MNMlqg38yO1w84T34+bXwb/OPlcHI6vczcXj1PZm+XPQnn/kN+hiTMkDdHA7w7G7Z+SJnPYHyHzYGhV8oyjcGXQOzk1q8z6np5/BV/l59NHsEw+zkZtFUXgNEmSwPLs+H8f8vAcOU/5efnOX+XWfG8FFj1ogyqDRbZjoJUOYTqto9luYjmgrG3gE8EVObB/h9lMJ04UwaNBXvkKCCaU2a/Q4fKZJRniMy65++SY063MBggFfmaEaNleUr9ATBaZR243iyz8xmrZOCcOFN+Ji+698j3O2q8zJw3VMlzLj3YHLSCDJILUqE8q3N/X48g+cUhfxfUH/tsj6aJ7x3zPr+mM0FyBNDy7A4D49vZ7jIhxFRgH3C/pmlZHezb7qTwQojbgNsAQkJCSE5O7kTTmlVVVR3zPn1Jbzi/ksJ6KmocJK/ZyHDvQRi3f8Mm01lN64dl7cHgsuCqsaPVHmZ7O+2dWJaLGdjz+VNEHl7E5tH/QtMZqaqqIjN/J5FCj05zkr5rI5lV8kLsUXWIQan/pjhgDDEAjlrW/vgl9ZagVsfuv/dVwnN/ZNPoF0ja9RzWugIOlzlI69ezI2L0hr/dyXQqn18fPbfOXrM7u+9JuWZDn31/O+VUPLd+HvX8lFbNkp9WYK+t7rXn5zPsKcJzfqAocByFK1eCfioknQHrtsgN4v8Ce0tgb3Kr/Qyx9+MRdIhsfQyeq9fLhbbzIcMOGa23bRL3p+bHOQBh8mYHAvtBIFDtvvV7TG5XCBSWAVGIIc9jaijBYfDAabDJ3QGPqoMkHHiPwqDJ5HqcDQ7ACgydjc5Vj0svv7gQCDpnPR7VmdRZQrCbvFs1T+9dS6jXMuxGHzShp8YWQU1NDZ4WAzW2KJwGa4fvo4i2A6DpjAiXHR//VPTOWsz1JdiN3thqsggqXIfDYKPekoDeWUdNxFDsRi8KgyYSXLCK+P0fUWsJZf/QJ6g3++FTvgejvRyHwQu70Qun3oKpoQxTQym11jCishagK8qiNHAKtdYwKr0S0bkaMDhqMDhq0LnqKfdJwqtyv/t980ITekCj1hpKWb3Wpf8uu6rj3iJgnqZp9UKI24H3gRnHcgBN0+YCcwHGjBmjTZs27ZgakJyczLHu05f0hvNbU5PKmtwM2Q7jFbD0MaaN7Ce/4QKkOiEoQf6cVFN8ZHs1DX6Wg9MPdOyC6gzOTIqAkMEkJycT7fKGkgCw1xIf7E184/5bPoRNh/D0C2k61MT+QbIjR6OKHEj+EYAx3sVQVwBAZEQ4kT38vvWGv93JdCqf36l8bifqRK/ZcGq/v6fiuRkiiljyznpE6CA8C/f04vObBtxFyNE260B5r/jbTQNuwh8YcMLHOrfVs+TkZEYf1/nN6vSWCQBcDVm/xRo8iGHtddZv1+MAeBxr09zKuvhv15mOe9lAVIvnke5lTTRNK9Y0rXFmibeB0Z3dV+k7rEY9dXYXLpcmf34BWdu1+M/y56vqAne5ha39cou68uafYbLd3+hztsCCuzA2VMj1Fh/wCGhdk9xYhlGQCsLdk7htXfLOL5sfH2oe3/O4Zv5TlL7tRK676pqtdGhcnD8h3mbm/px+xOx7q/YX8fBXO1i4Pad7ZuZT+oaoce2PZtVHdCaTvBHoJ4SIQ14srwJaFbgIIcI0TWvs+ngRstoFYAnwdyFEY2X32cDDJ9xqpUdYTTJArXe4sAYPArO3rKna94OsRaouknVZTkf7wWnL6aYbO+mtfwPyUvAdHNYcJAudrL1qu21DpaxVKj98ZJBclS/rqNAga4NcZguUY2oqyunlqNfsX6Gu2UqHTAYdd8/ox2MLdrIj0MxUl8YnGzJZtD2HjRklGPU65m3IwmLQcXZSaE83V1FO2FEzyZqmOYC7kRfPVOBzTdN2CSGeFkJc5N7sD0KIXUKI7cAfkL2mcXf+eAZ50d4IPN3YIUTpe6xGGSTX2p0ghOx4ULRPBq1F+2THgcaOe0cLkhvlpQBgri9uDpKDBkDB7uZeqi2HmrMFyA4FxWmtj1NdLAv+fSJlFtvkKctAjmdSE0XpwzpzzRZCjBVCHAauAN4UQuxy76uu2cqvmjMmivggD95JqeeKN9bw2IKdVNU5uH1qApv/OpMIXyvvrDrY081UlC7RqZpkTdMWA4vbLHu8xeOH6SDboGna/4D/nUAblV6iVZAM4B/nnv2uxU9rHkFyeJuGatnj98tbYMZf5diV7Y1Y4WauL5FBsl+s7J279UM5CLx3eOuh4ax+MhAvaDO4Sk2RLNOw+MrRL3yjwfgro2woyimsE9fsjchSivb2VddspUMmg46514/mgpd+5mBRNS/OGc4lIyIQQk4w8ttJMfx98R5251QwONz7KEdTlN5NTUutdJrFXW5RXe+uK/aLk7McteQZLLO4znr4+V+yZrlxGunGTLLOPfRbi161poYWmeQQ99iXeTvlfatMsj8EJEJphhxGrlF1oTuT7C6n9I2WtdGqJllRFKVLJQZ78bcpVpIfnM6lIyObAmSAK0ZHodcJvt2R04MtVJSuoYJkpdPiA2V/0335coQK/GKP3MgjWNYng6w3BjkYODTPoheQKO9jJjXt1lxu4d08QHy+LMU4IpMckCg7ABanNc9AVF0sa5B93Mkxn6hfH69ZURRFOW4BVh0+NuMRy/08TEyMD+CHnXlNHfi+2ZbNf5btI7+i7ojtFaU3U0Gy0mn9Q7ww6XWkZLtHm/B3DyivN8nOdtA8ugXIZaFDZZC85FFY+5ocvLwxuB56hQyooyfiVZkGLjv4xshssmcI/PQ0LHuqdSbZ6tscZL82Ab66VT6uLgSPFkFyY7mFyiQriqJ0q3OGhJJeVM25L/3Ch+sO8devd/KfZfu5au46NE2j3uHkux25ahQMpddTQbLSaSaDjgGhXuxsDJL93EGyXyx4R8pg2eIjyy0Axt4qxzIu2gdr/yuHiDN7yWmrAYb8Bh7Jgcgx6F0Ncln4CHnfmGVe9YLcr3HoN6uf7LjXKGujDIQdtTJI9lXlFoqiKD3pnKQQPEx6MoqreWzBTirrHcwZE8XBomq2ZJbx+cYs7vpkC2sPFDN/UxYl1Q093WRFaZcKkpVjMiTCh53ZFTID4BMpp+z0iwX/WFlqIYScpnLIZTD1QTnHvKtN7fDgS2DCXWAwy+29wuU6nQGCk+Tj8/4FZzwoH9eVN2ePrX5yhItG5ZlQ5p4gzBYIMZNh5lNyKkxjB+M1K4qiKCdNsJeFzY/N4os7ZLIjIciDRy8YhMmgY9H2HH7YJYf4fH3lAf70xQ7++cOenmyuonRIBcnKMRka4UN5rZ2sklrQ6WXA2+9smTWedI/cyC8GLv+f7GQXNFAu83TPfRQ6FBLPgtl/bz6ot3sezqBBYHRPtekRKLdrFDtFBsfBSTKwvvozmPpnuS5zbfM+eiNMuU9mkU0esmNhY92yoiiK0i0sRj1DInx45uIknrpoCN4WI9MHBPHNtmzWpctRBX/ZL/upfLnlMHnlql5Z6X1UkKwck9Exco6Bn/bkywWXvwPjboXBF8GEO47cIai/vE+cBQ9lwk3fH7lNYyY5bHjr5b4xzY9Dh8Kf0yHYHXQPmA1Jl8rHh9bIe4+g1vs3diBU2WRFUZQecf3EWKb0CwTgvpn9EULgdGlMjJe/CA4M9cLp0njpp3092UxFaVenxklWlEYDQr0YEeXLh+sOceOk2FZD/7TL4gOXvAHRE+Tj9vjFoKFDRI1tvdwrTNY5Oxtkh722AhJk58DGILllGQY0dyBsqOnT02IqiqKcCgaFefPlnZNYn15MmK+VtenF3DAxloziaub+nE5SuA+XjozAw6xCE6V3UJlk5ZjdMDGG9MJqVqe1M4Nee0Zc3TwSRnu8Qtk8+t8w4rrWy3W65nGPLe0EyQazrIeuOCyfH5FJlkPW0VDVuXYqiqIoJ1VcoAdXjYvmjMRAXrl6JJePjuSBWf0ZHObNXxfs5N5Pt/Z0ExWliQqSlWN23tAwAjxMfLA2o8uOWeUVD/p2sgd+7pKLjrLQQYPkvclT1iC31PhclVsoiqL0Kjqd4MLh4ZgMOixGPQvvnszspFBScyt7ummK0kQFycoxsxj1zBkbxbLUfLLLak/uizXWJbdXbgFwzrNwwYtw7ReyQ19LLcstFEVRlF7LoNcxMMyLnPJa6uyqs7XSO6ggWTku106QwevH6w6d3BcK7CfHSG5bb9zIPx7G3AwxE49c11huYVdjJSuKovR2cYEeaBocLlWJDaV3UEGyclwifK2cNSiEzzZmUe84id/6R98Ev/ux43KLX6MyyYqiKH1GTIBMbBwsUtdspXdQQbJy3H47MZbi6ga+25F78l7EZIPIMce3r1HVJCuKovQVsQEysXGoWP36p/QOKkhWjtvkxAAGhnrx3Pd7KKqq7+nmHKkpk6xGt1AURentfG0mfKxGMlSQrPQSKkhWjpsQghfnjKCs1s6Z/1zBU4t29XSTWjOqcgtFUZS+JDbQg7SCKjRN6+mmKIoKkpUTMyjMm/duGsuYWH/eXZ3Bou05PP7NTpyuXnCBU0PAKYqi9CkjIn1Yl17ClW+u7R2fI8ppTQXJygmblBDIPy4bhk7APfO28sHaQ2zLKuvpZoHeKGfsa1A/3SmKovQFD583iPtm9mNjRimr0op6ujnKaU4FyUqXCPWxMGNgMCCHK16cksvbv6RTXmvv2YYZbSqTrCiK0kdYjHrunJaAv4eJzzZmAqjSC6XHqCBZ6TJPXJjE/24cw6hoP95ZdZBnv0vlxaX7erZRtgDY8iFseOvIdSrDrCiK0uuYDXp+MzKCH3fl8+8f9zLqmaU8v2QPdqerp5umnGZUkKx0mSh/GzMGhjCtfxAAvjYjH607xMEiGYxW1zuobejmmZSunQ8Ro2DZU1DfYrrTtJ/gH3GwZ3H3tkdRFEU5qt9PTyQx2JNXlqdhMep5dcUBXk8+wIPztzNvQ2ZPN085TaggWelyV46N4sZJsXz9+8lYjHoe+nIHLpfG9e+s5555WyitbmBndnn3NCYgAWY9DQ2V8PUd8rblQ/j+L+Csh+XPgsudnWj8SS/1W1jwe8hYDQeWNy9PT4byw0e+hqMBUhf9ema6JB3W/BecDnm8/N1QkQsHf4HK/C49ZUVRlL7O38PEvFsn8MwlQ1j+x2nMHBTMyz/t54vNh/li82F251Tw7Y4cVYqhnFSGnm6AcuoJ8bbw5EVJADx2wSD+8mUKjy5IYUtmGSaDjr8u2MnS1Hw2PjITH5vx5DcoYjSEj4Q934LZB7bPk8uHXy0fr3gW9i2B2jKInwYp82UAve1jud15/4Ko8fDBxWD1g/P/DQMvBGcDGMyw7jVY9gTYAmHyH2DsLc0jawAGexV8MgeK9kHmWshLgbIW03nbAuGaz45/0hRFUZRTkJ+HiesnxABw94x+LEstAGB3TgVPLNzJxoxS3oxIJybAxgtXjsBk0LEvv5KEIE/0OgFAZZ2dWruTYC9Lj52H0nepIFk5qa4cE8XilDzmbcgCoMHh4rsUOUPftyk5XDs+5uQ3Qgi4/F2oyIboSTKr66iF4MGyBOOXf8vgOXYK7F4A3mFw1Two2gtbP4Ilj0JgPzk1tnckfHFz87G9I0BzQdgIsPnD0sdh9UvgGSI7DNaVM6W2FBAQP10G6mHD4Yw/yvW2APjpGXh7JiSeBRFjwCcSKnLAYJKzBppsMuj2iZKjdZRlyqy1bxR4hcrMtNMu2220gcsp21RTBNVFMrC3BYDZC+y1UFcGdeXgFQZWX3kejgYoz5ITr5i9wOILOoN8rGngssvnQiffz7ZcLrmN0y7vhV62pb5CttlgkV8qjNbm9hlMJ/9v36ihWrbdaO2+11QUpcuMiPLl5atHcrCwmheX7WNjRilDIrxxuDS+3ZHLRcPDqbU7uffTbfxxVn+uGheNzaTn0a93simjhJ//PB2D/vh/PK+ss2My6DAb9F14Vkpvp4Jk5aQSQvDcZUM558WfGRcXwM/7C2lwuLAa9Xy1Jbt7gmQA/zh5AwhMbF5+xfuw8S2IPQNCh8hgUXOB0QIhg+Xy+TdCxi9w1uMw+T5ZWlG0H/QGWPMK1BS7s8vnQ9YGWPuqDBZNHmD2Ir24gfgzr5bZ6OxNEDkWdC0utP1mweqXZQCd9hNwsn4+FK2PLXQyINc0qMyTwW1bRltz4NtIZwCdUZ6Dy8GZjgZI7mSHGpMXOOrk8Ywe8ouFwSK/MFj9weYHZVkyuHY5ZHmKy30zWuWXkYYqqCqA6gL5t2psj94gH2uaDIo9g+U5O+uhyl3SYvUDr3AZ/Dtq5X7lWXIfnUEG7rWlYK+D4IEw4OnjfbMVReliFw0PZ39+JS8ukx3C/3TOQCYnBDDh/37ileVp7C+Q/U4+Xp/Je2symBAfwKq0Ispr7azcV8hZg0IoqKzjnV8OctvUeAI8zQCkF1ZhNuqJ8G3/S3SDw8X5L69iaKQPr14zqntOVukVVJCsnHRhPlZ+vP9MPC0G7vxoM6m5Fdw8JY5//rCXtQeKmZgQ0HON0xtgwp3Nz9tmNz0C4cZvofgA+MWBTgdJlzSvT5wJe3+A/rPl86hx8tZCZnIy8bGT5ZPoCUe2weoHM5+Qt/oqGdD5RMnA0F4jg8KGaig5KINL3xgwecrgrjLPHSTqZabcUS+DX51eZr49Q2XmuKZYlpOYPGT22OwNhXtlVloImZEOHABmT5ldry2Tr1+ZJ8ebtnjLDLDL4Q6aHfK5Tk/m4Rxi4vvJdjSOTe1yyJkOLT4yg2yvle91ZZ4Mds1eUFPqDkir5fnUlMjsd9hwmfnWG93n5r7VlkDuDvk3CUkCjyC5TVN73G0DmX2vdo+xqjOAb7R8XypyoDJXnqPFW75f/WbJYNlll88tPk1fcFCd6RWlV4kP8sRm0mN3uhgb64dBr+PC4eG8uzqDaH8bv5sSxxML5eyvjb9aAny6MYvhUb5cNXcd6YXVuDSNR88fzAtL9/Hf5fuJDfBg4T1TyCuvPeI1F2zLJrOkhsySGu47q5J+IV7ddr5Kz1JBstItQn1kPdhzlw2jss5OjL8H8zZk8uiCFL6+c3IPt64TAhLaXx46VN66itlT3gAwyWDPI1A+DUlqvW1Q/6573RNwMDmZmGnTeroZJ0dyck+3QFGUFvQ6wbg4fwBsJhnC3Dw5jvyKOv4yeyBhPlbmbchkQKgX32zLAeCqsVF8timLrLdryC6tZUSUL59uzOKGibG8uiKN+CBP0gqqmPXCSgor63l0vJlpwIHCKl5bcYAVewtICPIgp6yO15MP8MKcEYDMMC/fk8/Zg0PRuWugq+odGPWi3bIMl0vjw3WHOHdIKMHevaNGWtM07E4Nk6F1KcqrK9KIDfDg/GFhPdSy3kGNbqF0qwhfKwNDvbGa9PzfpcPILK7hvJd/IbPCiaZpHC6tod7hpLLOTkFlXU83V1EURellXrt2FK9fO7rpeZS/jdeuHU1MgAcmg44f7pvKf+aMIC7Qg6Rwb564MIlBod7syavkoXMH8tgFg6msc3Dbh5txujRevHIEEb5WcsvrsBr1vLmjnvfXZDD7Pz+zZFceSeHe/PvKEVwzPppvtueQVSInqPp2Rw53fLSFL7Yc5o2VB1iXXszMf6/k0a93NrVN0zSKquoBWHewmCcW7uKd1Qe7/D2prndQVe845v0Wbs9h1DNLyW2RQa9tcPLSsv0890PqcY0eklZQxQWv/EJhZT0VdfY+PQKJyiQrPWZKv0C+uHMSd360mb+vr+PFbUsprbETG2Cj3uGitKaBv8weyLXjY474lqsoiqKcnhozyL9GCMFbN4xBCLCa9Lx301hW7ivkslGR6HSC84aGsjglj/ggD4ZEePOvK4ZzsKiauEAPbvrfOp5YuIuxsX68ft1oAt21y6HeFj5ce4g3Vh7gb5cOZUtmKQCPfJWCw9UcCH63I5enL07CZjLw3poMnv52N/+4bBjr0osBWJ5awMPnDuqy90PTNC55dTUHCqv43ZQ4Hj1/cIfbulxaq6D1x135VNU7eG91Bg+fJ9u0NbOUBqeLrJJavth8mEFh3gyJ8Ol0e5bvyWdndgXLUvN55tvdPHlREleOiepwe4fTxSvL07hsVCTRAbam5avTivguJZe/XTIE0V6H8W6ggmSlR42I8uWLOydx77sriY8KoV+wF2/9ko5Rr2NMjD9PLdrNe2sy+PiW8UT62Y5+QEVRFEUBEoM9mx4He1u4okWg9vTFQ9hyqIyrxkYhhGBiQkBT/5hnp1gpssVw/YQYPMzNYVKoj4U5Y6P4eP0hfjMqkq2ZZXiZDVTWO7h0ZASlNQ1E+Fr5eH0m32zL4cLh4Xy0Tg73+ecvdqAT4G0xsL+giqySGqL8O/5Mq3c4OxxJY29eJR+vP8Sd0xII87FyoLCa/QVVeJhkh/hbzohna2YZs4eEArA9q4z7P9/GgBAvNh8qJcBoZ8S4BnysRtYckH033l+bwaLtOUxICMCk16ETcubDP32xA4tRx9L7zyTK30ZxVX1Th8eOpGRXAPDF5sPUNDj5YWceV46J4qEvd+B0aTx/xXBABvcp2eVszSzjpZ/2U1rTwNMXD2k6zrurD7IstYDR0X7sK6gk1NvCNeOjMRv0aJrWKnAur7GzMaMEfRdnrVWQrPS4CF8rd4+0MG2a/I9z3YQYhACzQUfy3kLu/XQrl7y6hhBvM09dlERhZT02s4HJCQEnNKSPoiiKcnoK9DSz+qEZTeMpt1pn1XH5me33Q/nz7AEs31PA/Z9tI7usljvPTGD6wCCGRfpi1OtwujR+3J3Pw1+l8PSi3dTanTx9cRKVdQ4Wp+Tyh7P6cfuHm/m/71MJ97EyNNKHIE8zLy/fj4/VyN8uHcr7azJ4c2U6V42L4skLk9DphMwAA2sOFHH7h5upaXCyZFce82+fRPJeOX70zVPieGV5Grd/uJltWWU8dVESEb5W7pm3FW+rgVX7i4gN9CA1p545c9fy5IVJlNbYuW1qPKvTiojwtbI4JZc6u4vhkT6cPyyMAwXVLNqRwx8/305coAefbcpiUkIAQyJ8uGZcNLGBHmSV1KBpNGWBGycL23xIZtrXHCiiqt7Bwu05OF0az1wyBItRz9Ld+dz24eam93bJrjyevDCJZan5OF0aaw/IzPsf529HCDkIUXFVA3dMS+Dat9YxIsqXu2YkUlptZ8G2bN5YeYD/m9K1w3yqIFnpdaym5m/P0wcG8+5NY3lx6X7SCqq4+q112J3ym+LspFBev25Uq2+TLpfW1IFCURRFUTrSXoB8NF4WIy/OGcGcuWvRNBgZ7cvoGP9Wx/zn5cPYlV3O4pQ8DpfWcOnICLwsRu6aLocfvWlyLMKLhhMAABgYSURBVB+vy6TB6SLAw0T/EC9ScyupbXAy/flkKusdDI/y5YO1h3BpGs9cPIS7521hzYFi6u0uYgJsPHLeIO76eAsPf70Du1NjQIgXFwwL55XlaWzLKsOoF02jfAyN8OGdG8c0Tajy2pc/8Z8tNdz47kZAdnx8xF1qsT69mBv+t4HpA4O5bar8ojA6xo+/LtjJhowSzh8axs6ccjZllPL5pizevG40D3y+neLqel66aiQTEwI4WNQ8+6wQUGd3MffndGoanAAs2JpNtL+NdeklmAw6xsT4MSzSlzdWHuDFZft4dUUajdUrw6N82Z5Vxn+vHsWSXXm8vSqdLZmlbD9czvbD5SzemUdZTQM6Ibh4eDihHl07m2+ngmQhxGzgJUAPvK1p2nNt1j8A3AI4gELgZk3TDrnXOYEU96aZmqZd1EVtV04To2P8+eiW8ezLr+SmdzcyZ2wULk3jP8v28/6aDMJ9razcV0iQl5n31mTw/k3jGB7l29PNVpQe04lrthn4ABgNFANzNE3LEELEAqnAXvem6zRNu6O72q0ofcG4OH9+Py2Bt385yMhovyPWTx8QzPQBwdx+ZgIVtXa8LK1nln3iwiQemNWfZan53P/ZdtamF3PntARi/G08/s0unr1kCNeOj+a5H/bw5sp0tmeVk5JdzrBIWRf89m9lwPvn2QN47BsZCN8/sz/9gj2byj/+M2cktXYnZTUNXD0uulXZyOAAPe/eNJYFW7OJ9LM1jT4FMD4+gPWPnNWqzVeOjeKcIaEUV9UTHyRLWA4VV3PD/zZwzdvrcbo0YgNs/P7jLVwzLhpoDm6n9Q9iXXoJc38+gBBg0ut46KsUhIBIPysjIn355NYJlNfa+d+qg7yyPI0BIV5kltTQ4HTxwU3jKKyqJzHYk2GRPixLzWfzoVL+dM4A3l2dQXW9g5gADzKKqrlvZn8ydm7sor+ydNQgWQihB14FZgGHgY1CiIWapu1usdlWYIymaTVCiDuBfwJz3OtqNU0b0aWtVk5L/UO8WP3QDEBmjHdml/Pkot0YdKKp04ReJ7jrky342UzcNjWeC4eH92STFaXbdfKa/TugVNO0RCHEVcA/aL5mH1DXbEX5dQ+ePYBbpsTj59HxzKFGva7D+l0vi5HZSWE8YtxJrd3JuUNCGRbpy6WjIppqkR+aPRCjTsfinblcOjKCF64c3uqX02vHx9Dg1Ijys3LWoBB0OsHIGD82ZZRw1qBgLMaOZwecnBjI5MTAdtf52o48Jx+rER9rc+AcE+DB/24cy6WvrpZZ4OtHc8M76/lw3SEsRh1XjI5ke1YZY2L9mTYgmCcW7mJIhDchXhZ+3l+I3amRVVLLeUPDmo7/2e0TKKu1Mz7On+9T8sgorsbHZsTHJl83yt/GxkdnYjHq0esEZw8OwaVBhJ+VvPJaYgM9yOjwjI9PZzLJ44A0TdPSAYQQnwIXA00XXE3TVrTYfh1wXVc2UlHa0ukE/71mFA/O305+RR2Pnj+Y1NwKwnws3PL+JursLu79dCteFgPTBgT3dHMVpTsd9Zrtfv6k+/EXwH9FT3UfV5Q+SAjxqwFyZ1hNes4bGsbWrFKGukePaNlZTwjBg+cM4MFzBrS7v04n+N2UuFbLHj1vEAWVdb8aIHeVhCBPVjw4DZvJgNWkZ95tE9ibV0mkn416h5OXfzJzZv8gksK9ySmvJSnchzExfhRXNfDXb3ayPauM0S0y8S2z8peNjmz3NVtmxFtO6pIYfHImeBFHG79OCHE5MFvTtFvcz68HxmuadncH2/8XyNM07Vn3cwewDVmK8ZymaQs62O824DaAkJCQ0Z9++ukxnUhVVRWenp5H37CPUufXeQ1ODU2Dh1fVEuWl4/7RPTtou/rb9V3Hc27Tp0/frGnamJPUpKPqzDVbCLHTvc1h9/MDwHjAE9gF7AMqgL9qmvZLB69zQtdsUP92+rJT+fy689wanBpODayG7vuO2hv+dslZdj5JbeBf02x4m7ru3Lv6mt2lHfeEENcBY4AzWyyO0TQtWwgRDywXQqRomnag7b6aps0F5gKMGTNGm3aMM3glJydzrPv0Jer8jt3aml3M25DJuElTOjWu5smi/nZ916l8bh3IBaI1TSsWQowGFgghkjRNq2i74Yles+HUfn9P5XODU/v8TuVzg95xfmdqGvfXOppKKbpKV59bZ8bPygZajgId6V7WihBiJvAocJGmafWNyzVNy3bfpwPJwMgTaK+idNqswSHUO1z8sr+op5uiKN2pM9fspm2EEAbAByjWNK1e07RiAE3TNgMHgN4x/7miKKcMIUSXB8gnQ2eC5I1APyFEnBDCBFwFLGy5gRBiJPAmMkAuaLHcz92LGiFEIDCZ1nVxinLSjIvzx8dq5F9L9rYakkZRTnFHvWa7n//W/fhyYLmmaZoQIsjd8Q/3r3/9gPRuareiKEqvctQgWdM0B3A3sAQ5NNDnmqbtEkI8LYRoHM7teWQt23whxDYhROMFeRCwSQixHViBrElWQbLSLYx6Ha9cPZLCqnp+89pqUg537fiJitIbdfKa/Q4QIIRIAx4AHnIvnwrsEEJsQ3bou0PTtJLuPQNFUZTeoVOFmpqmLQYWt1n2eIvHMzvYbw0w9EQaqCgnYmr/IBb8fjLXvr2ea95axxMXJWHQCQaEejEozLunm6coJ0Unrtl1wBXt7Pcl8OVJb6CiKEofoGbcU055sYEezL9jIte9s54H529vWj4y2hcBXDQ8nMtGR+JpNrQag9LudLEvv5LBYd6tliuKoiiKcupTQbJyWgj3tfLNXZNJza3E12bk532FfL4pC50QPLloN08u2k1SuDeDw7wJ87VywbAwHpy/nR2Hy/nr+YO4bkIMFqOe91YfJD7Ik6n9g3r6lBRFURRFOYlUkKycNrwsRsbF+QNy9r5bzohH0zRW7C0gNbeSr7YcZmlqPmU1dl7+aT++Nrn9s9+l8vfFqVwyMoKvtmTjaTbww31nUO9wsWBrNjohuHNaQrcM3q4oiqIoSvdQQbJyWhNCMGNgCDMGhnDX9EQA5m/KYm16MQ/NHoiXxcgnGzJZua+Qr7ZkE+RlpqbewZVvrKW81k6dw4XTpbE1q4zpA4J4+5eDNDhdDI3wwWLU4WczEeJwIPYV8t2OHPYXVHHF6Cg+3ZhJuI+VB87uT/+Q9mcK0jSNNQeKGR3j1yoA1zQNIQTr04v585c7+PDm8UQH2Lr8vWmcaEiVmiiKoiinIxUkK0obV4yJ4ooxzcPM/m5KHFePi+Lhr1K4dGQEFqOel3/aj8mg47nfDOOnPfk8/s0uft5XyPBIH/qHeLHpUCmappFfUU+t3QmbN+BpNuBpNvDI1ymEeJvJLKnhqrnr+OTW8QwM9aagso41acUEeZmxmfTszC7nsW92ccPEGJ6+eAjltXbumbeVspoGPrttIs98t5tDxTW8snw/z18xvMPzqayzYzLoWk13+mucLo0Xlu7l/TWHuHNaAlMSA8mrqGNKYmDTlKAul4YQUO9wtdo3NbeClOxyBoV6Y3e5iPC1YjXpeWbRbs4dGsqMgSGttne5NEpqGgj0NDct255VRrS/rWnK14LKOjKKapp+BWiUVlBFpJ+13S8Q7TlcWoPLRae+UDhdGg1tzk1RFEU5vaggWVE6wWYy8NJVzfPgTIgPaHp87fgYLhweTmZxDYPCvNHrmoO06noHH3y7koFJQ5mYEEBtg5MP1x1iztgoahqczHlzLZe8upq7piUyf/NhMktqWr2u2aBj3oZMVqUVkV5YjUEncLg0LvzvKtIKqugX7MlXW7OZlBhAemE1Zw0KweF0sS+/CqtJx5ebs1mVVoROwMhoP+48M4ER0b7c/N5G4gM9CPGxsCmjlEg/KwEeZmYNDuH7nbl8sPYQ4T4WXlm+n1dXpFHT4CTC18ofzkrk4/WZpGSX03iW58UZ+XfKKixGHTuzK+SXghZiAmwcKq5h/ubDRPlbifS1MTDMi/4hXny/M49V+wv53ZQ4Hpg1gMOlNVz62mrigzz52yVDCPe1cvuHm9mTV8EP903lQEEVwd4WnC6Nq+au5eIREbw4ZwQAzy/Zw6cbsjg7KYQdh8s5s38QYT4WKusdTO0XxK0fbKKoqp6JCYEcKKjC7nTx+IWDsTtdBHqa8bEaCfW2EOhp5pGvUthfUMmdA7Uu/pekKIqi9BUqSFaULuBtMTIkwueI5R5mA4MC9EwbGAyAxajnD2f1a1q/6J4p/OXLHfx76T6sRj3/u3EMNpOBkuoGdhwu58LhYVzxxlpcLo0HZvVnSr9AluzK45P1mdw8OY47zoznmrfXc/9nctSOd1YdpM7uxOWO7XxtRv4wIxGnprE4JY9bPtiEQSfQCcEO97jRwyJ92JJZSkFFPf9bfRCAmybHcvPkOM7690q8bQb+efkwHv4yhb98mUK/YE/uODMBvRDszq3g2z0FmAyVeJkNRPlb+b/fDKWwsgGzQcfKfYV8uO4QT1+cREWtnbSCKjKKa/h0Qxa1dicmvY4ZA0N465eD/Lg7Hz+bCatRT1ZJDXPmrmt6n/Q6wWWvraGy3tG0TAj4Zls20wcGU1JVz2vJB/Czmfh0YxZJ4d68vvIA7ooRnl+yF02DmYOCySqpZVSMH3tyK7j7k61H/M18rEaZtZ+RiFGXewL/KhRFUZS+TAXJitKDQrwtvHfTOA4UVqFpkBjs2bTuvKFhACT/aRo+VmNTucSoaD8ePndQ03bf33sGP+8rJMDTzIPztxMb4MHD5w1E0zSi/T0wGeScQffN7M/CbTlszSrlwmHhlNXaEcDZSaGALMvYcLAEq1HPhPgAdDrBvNsmEORpJjrARoy/B+sPFnP9xJimttQ7nPx+7jKumzGSSYkyu96yrGP6wGAeOnfgEZ0anS6N3PJaTAYdwV4W1hwo4ulFu9mWVcYfZ/XnguHhZBRXsy2zDA+zngMF1Xy2KYt7z+pHYrAny1LzuWREBHd8tJk/zJOBbrS/jW//MAWjTofVpKeyzk6d3UVFnZ1bP9jExPgA/nZp87DtlXV2kvcWkhDkSUWdnco6B4dLa9iWVUZSuDe3nhHPypUqSFYURTldqSBZUXqBhCDPDtcFe1l+dV+jXsdZg2St79L7p3ZYk2vU67hsdCSXjY5sd72Xxdh0nEajY/yaHg+N9GFoZOtsudmg5/rB5qZMeXvaG/VDrxNE+jXXBk9KCOT7e88gvaiauAAPdDpBXKAH0wfI45bX2pn2/+3de6hlZRnH8e+vcdQhJ/OWWlqjJsFYqYOIhBgUlBphUaERJCVIol2IwgkhJPIPhS5YFigZdiGLSvMPM02lgspLMY43vGRCyuSl0hpIU3v6Y6/B7ersOXtm9sw+653vBzZ77Xevvc777Pesh+esy3nfsB8nvvEAkvDuI18NwBUfPZaNzzzPYa/agwNesTsrdn3xZ63cfTkrd4f9Vu7GjZ9+64LxbtqOJEl9FslSQ4b8nyiSTPxjYc8VyzmpO7I+bvza8MW2LUnSlnjZvDsgSZIkLTUWyZIkSVKPRbIkSZLUY5EsSZIk9VgkS5IkST0WyZIkSVKPRbIkSZLUY5EsSZIk9VgkS5IkST0WyZIkSVKPRbIkSZLUY5EsSZIk9VgkS5IkST0WyZIkSVKPRbIkSZLUY5EsSZIk9VgkS5IkST0WyZIkSVKPRbIkSZLUY5EsSZIk9VgkS5IkST1TFclJTkxyX5IHk6xd4P3dkvywe/+WJKvG3vtc135fknfOruuSpIWYsyVp2y1aJCdZBlwCnASsBj6YZHVvtTOAf1TV64GvABd2n10NnAYcAZwIfKPbniRpOzBnS9JsTHMk+Vjgwap6qKr+A1wJnNJb5xTgim75x8Dbk6Rrv7Kqnq2qPwMPdtuTJG0f5mxJmoFpiuTXAH8Ze/1I17bgOlX1PPA0sM+Un5UkzY45W5JmYJd5d2CTJGcCZ3YvNya5bws3sS/w5Gx7taQY33C1HBu0Hd/WxPa67dGRpWYGORv83RmyluNrOTZoO76Z5uxpiuRHgYPHXh/UtS20ziNJdgH2BP425WcBqKpLgUun6M+CktxeVcds7eeXOuMbrpZjg7bjG2hsg8jZMNjvdyotxwZtx9dybNB2fLOObZrLLW4DDk9ySJJdGd3UcU1vnWuA07vl9wM3VVV17ad1d1IfAhwO3DqbrkuSFmDOlqQZWPRIclU9n+Qc4BfAMuDyqro7yReA26vqGuBbwHeTPAj8nVFSplvvR8A9wPPA2VX1wnaKRZJ2euZsSZqNqa5JrqprgWt7bZ8fW34G+MCEz14AXLANfZzWNp32GwDjG66WY4O24xtkbAPJ2TDQ73dKLccGbcfXcmzQdnwzjS2jM2ySJEmSNnFaakmSJKmniSJ5sSlYhybJw0nuTLIuye1d295JbkjyQPe817z7Oa0klyd5PMldY20LxpORi7uxXJ9kzfx6Pp0J8Z2f5NFuDNclOXnsvcFM+5vk4CQ3J7knyd1JPtm1D378NhNbE2O3lLWWs6GtvG3OHu5+33LOhjnk7aoa9IPRjSl/Ag4FdgXuAFbPu1/bGNPDwL69touAtd3yWuDCefdzC+I5AVgD3LVYPMDJwM+BAMcBt8y7/1sZ3/nAZxZYd3X3O7obcEj3u7ts3jFsJrYDgTXd8krg/i6GwY/fZmJrYuyW6qPFnN3F1UzeNme/ZN1B7fct5+xF4tsu49fCkeRppmBtwfg0slcA75ljX7ZIVf2a0R304ybFcwrwnRr5PfDKJAfumJ5unQnxTTKoaX+rakNV/bFb/hdwL6MZ2AY/fpuJbZJBjd0StrPkbBho3jZnv8Sg9vuWczbs+LzdQpHc4jSqBVyf5A8ZzWoFsH9VbeiW/wrsP5+uzcykeFoaz3O601eXj51mHWx8SVYBRwO30Nj49WKDxsZuiWn1e2w9bze1z0/Q1H7fcs6GHZO3WyiSW3R8Va0BTgLOTnLC+Js1OofQzL8laS2ezjeBw4CjgA3Al+bbnW2TZA/gJ8Cnquqf4+8NffwWiK2psdMOs9Pk7ZZiGdPUft9yzoYdl7dbKJKnnkZ1KKrq0e75ceAqRqcGHtt0CqR7fnx+PZyJSfE0MZ5V9VhVvVBV/wUu48XTO4OLL8lyRsno+1X10665ifFbKLaWxm6JavJ73AnydhP7/CQt7fct52zYsXm7hSJ5milYByPJy5Os3LQMvAO4i5dOI3s68LP59HBmJsVzDfDh7o7b44Cnx04RDUbvmq73MhpDGNi0v0nCaHa2e6vqy2NvDX78JsXWytgtYU3lbNhp8vbg9/nNaWW/bzlnwxzy9tbcXbjUHozuzryf0V2L5827P9sYy6GM7sS8A7h7UzzAPsCNwAPAL4G9593XLYjpB4xOfzzH6HqgMybFw+gO20u6sbwTOGbe/d/K+L7b9X99t5MeOLb+eV189wEnzbv/i8R2PKPTcuuBdd3j5BbGbzOxNTF2S/nRUs7u4mkqb5uzh7vft5yzF4lvu4yfM+5JkiRJPS1cbiFJkiTNlEWyJEmS1GORLEmSJPVYJEuSJEk9FsmSJElSj0WyBiXJC0nWjT3WznDbq5LctfiakqRpmLM1ZLvMuwPSFvp3VR01705IkqZiztZgeSRZTUjycJKLktyZ5NYkr+/aVyW5Kcn6JDcmeW3Xvn+Sq5Lc0T3e0m1qWZLLktyd5PokK7r1P5Hknm47V84pTElqgjlbQ2CRrKFZ0Tt1d+rYe09X1ZuArwNf7dq+BlxRVW8Gvg9c3LVfDPyqqo4E1jCaJQtGU1ZeUlVHAE8B7+va1wJHd9v52PYKTpIaY87WYDnjngYlycaq2mOB9oeBt1XVQ0mWA3+tqn2SPMloesrnuvYNVbVvkieAg6rq2bFtrAJuqKrDu9fnAsur6otJrgM2AlcDV1fVxu0cqiQNnjlbQ+aRZLWkJixviWfHll/gxev238Vofvs1wG1JvJ5fkraNOVtLmkWyWnLq2PPvuuXfAqd1yx8CftMt3wicBZBkWZI9J200ycuAg6vqZuBcYE/g/46MSJK2iDlbS5p/WWloViRZN/b6uqra9C+F9kqyntGRhQ92bR8Hvp3ks8ATwEe69k8ClyY5g9HRh7OADRN+5jLge11SDnBxVT01s4gkqV3mbA2W1ySrCd31bcdU1ZPz7oskafPM2RoCL7eQJEmSejySLEmSJPV4JFmSJEnqsUiWJEmSeiySJUmSpB6LZEmSJKnHIlmSJEnqsUiWJEmSev4HRb1wdukeEAwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk7aPrzw-t9b",
        "outputId": "16814828-0715-4a58-c424-e638f9186603"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10089999437332153"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zM40r0II99z"
      },
      "source": [
        "### Model with clipping to 1.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjtXAeU9JB2-",
        "outputId": "33212f4d-e3a0-4f61-d900-eda800869871"
      },
      "source": [
        "model, model_type = define_and_compile_ResNet_model()\r\n",
        "\r\n",
        "# enable this if pydot can be installed\r\n",
        "# plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\r\n",
        "# print(model_type)\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_396 (Conv2D)             (None, 32, 32, 16)   448         input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_372 (BatchN (None, 32, 32, 16)   64          conv2d_396[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_372 (Activation)     (None, 32, 32, 16)   0           batch_normalization_372[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_397 (Conv2D)             (None, 32, 32, 16)   2320        activation_372[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_373 (BatchN (None, 32, 32, 16)   64          conv2d_397[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_373 (Activation)     (None, 32, 32, 16)   0           batch_normalization_373[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_398 (Conv2D)             (None, 32, 32, 16)   2320        activation_373[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_374 (BatchN (None, 32, 32, 16)   64          conv2d_398[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_180 (Add)                   (None, 32, 32, 16)   0           activation_372[0][0]             \n",
            "                                                                 batch_normalization_374[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_374 (Activation)     (None, 32, 32, 16)   0           add_180[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_399 (Conv2D)             (None, 32, 32, 16)   2320        activation_374[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_375 (BatchN (None, 32, 32, 16)   64          conv2d_399[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_375 (Activation)     (None, 32, 32, 16)   0           batch_normalization_375[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_400 (Conv2D)             (None, 32, 32, 16)   2320        activation_375[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_376 (BatchN (None, 32, 32, 16)   64          conv2d_400[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_181 (Add)                   (None, 32, 32, 16)   0           activation_374[0][0]             \n",
            "                                                                 batch_normalization_376[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_376 (Activation)     (None, 32, 32, 16)   0           add_181[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_401 (Conv2D)             (None, 32, 32, 16)   2320        activation_376[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_377 (BatchN (None, 32, 32, 16)   64          conv2d_401[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_377 (Activation)     (None, 32, 32, 16)   0           batch_normalization_377[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_402 (Conv2D)             (None, 32, 32, 16)   2320        activation_377[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_378 (BatchN (None, 32, 32, 16)   64          conv2d_402[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_182 (Add)                   (None, 32, 32, 16)   0           activation_376[0][0]             \n",
            "                                                                 batch_normalization_378[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_378 (Activation)     (None, 32, 32, 16)   0           add_182[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_403 (Conv2D)             (None, 32, 32, 16)   2320        activation_378[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_379 (BatchN (None, 32, 32, 16)   64          conv2d_403[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_379 (Activation)     (None, 32, 32, 16)   0           batch_normalization_379[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_404 (Conv2D)             (None, 32, 32, 16)   2320        activation_379[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_380 (BatchN (None, 32, 32, 16)   64          conv2d_404[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_183 (Add)                   (None, 32, 32, 16)   0           activation_378[0][0]             \n",
            "                                                                 batch_normalization_380[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_380 (Activation)     (None, 32, 32, 16)   0           add_183[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_405 (Conv2D)             (None, 32, 32, 16)   2320        activation_380[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_381 (BatchN (None, 32, 32, 16)   64          conv2d_405[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_381 (Activation)     (None, 32, 32, 16)   0           batch_normalization_381[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_406 (Conv2D)             (None, 32, 32, 16)   2320        activation_381[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_382 (BatchN (None, 32, 32, 16)   64          conv2d_406[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_184 (Add)                   (None, 32, 32, 16)   0           activation_380[0][0]             \n",
            "                                                                 batch_normalization_382[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_382 (Activation)     (None, 32, 32, 16)   0           add_184[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_407 (Conv2D)             (None, 16, 16, 32)   4640        activation_382[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_383 (BatchN (None, 16, 16, 32)   128         conv2d_407[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_383 (Activation)     (None, 16, 16, 32)   0           batch_normalization_383[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_408 (Conv2D)             (None, 16, 16, 32)   9248        activation_383[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_409 (Conv2D)             (None, 16, 16, 32)   544         activation_382[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_384 (BatchN (None, 16, 16, 32)   128         conv2d_408[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_185 (Add)                   (None, 16, 16, 32)   0           conv2d_409[0][0]                 \n",
            "                                                                 batch_normalization_384[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_384 (Activation)     (None, 16, 16, 32)   0           add_185[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_410 (Conv2D)             (None, 16, 16, 32)   9248        activation_384[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_385 (BatchN (None, 16, 16, 32)   128         conv2d_410[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_385 (Activation)     (None, 16, 16, 32)   0           batch_normalization_385[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_411 (Conv2D)             (None, 16, 16, 32)   9248        activation_385[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_386 (BatchN (None, 16, 16, 32)   128         conv2d_411[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_186 (Add)                   (None, 16, 16, 32)   0           activation_384[0][0]             \n",
            "                                                                 batch_normalization_386[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_386 (Activation)     (None, 16, 16, 32)   0           add_186[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_412 (Conv2D)             (None, 16, 16, 32)   9248        activation_386[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_387 (BatchN (None, 16, 16, 32)   128         conv2d_412[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_387 (Activation)     (None, 16, 16, 32)   0           batch_normalization_387[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_413 (Conv2D)             (None, 16, 16, 32)   9248        activation_387[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_388 (BatchN (None, 16, 16, 32)   128         conv2d_413[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_187 (Add)                   (None, 16, 16, 32)   0           activation_386[0][0]             \n",
            "                                                                 batch_normalization_388[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_388 (Activation)     (None, 16, 16, 32)   0           add_187[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_414 (Conv2D)             (None, 16, 16, 32)   9248        activation_388[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_389 (BatchN (None, 16, 16, 32)   128         conv2d_414[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_389 (Activation)     (None, 16, 16, 32)   0           batch_normalization_389[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_415 (Conv2D)             (None, 16, 16, 32)   9248        activation_389[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_390 (BatchN (None, 16, 16, 32)   128         conv2d_415[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_188 (Add)                   (None, 16, 16, 32)   0           activation_388[0][0]             \n",
            "                                                                 batch_normalization_390[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_390 (Activation)     (None, 16, 16, 32)   0           add_188[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_416 (Conv2D)             (None, 16, 16, 32)   9248        activation_390[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_391 (BatchN (None, 16, 16, 32)   128         conv2d_416[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_391 (Activation)     (None, 16, 16, 32)   0           batch_normalization_391[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_417 (Conv2D)             (None, 16, 16, 32)   9248        activation_391[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_392 (BatchN (None, 16, 16, 32)   128         conv2d_417[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_189 (Add)                   (None, 16, 16, 32)   0           activation_390[0][0]             \n",
            "                                                                 batch_normalization_392[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_392 (Activation)     (None, 16, 16, 32)   0           add_189[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_418 (Conv2D)             (None, 8, 8, 64)     18496       activation_392[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_393 (BatchN (None, 8, 8, 64)     256         conv2d_418[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_393 (Activation)     (None, 8, 8, 64)     0           batch_normalization_393[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_419 (Conv2D)             (None, 8, 8, 64)     36928       activation_393[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_420 (Conv2D)             (None, 8, 8, 64)     2112        activation_392[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_394 (BatchN (None, 8, 8, 64)     256         conv2d_419[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_190 (Add)                   (None, 8, 8, 64)     0           conv2d_420[0][0]                 \n",
            "                                                                 batch_normalization_394[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_394 (Activation)     (None, 8, 8, 64)     0           add_190[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_421 (Conv2D)             (None, 8, 8, 64)     36928       activation_394[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_395 (BatchN (None, 8, 8, 64)     256         conv2d_421[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_395 (Activation)     (None, 8, 8, 64)     0           batch_normalization_395[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_422 (Conv2D)             (None, 8, 8, 64)     36928       activation_395[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_396 (BatchN (None, 8, 8, 64)     256         conv2d_422[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_191 (Add)                   (None, 8, 8, 64)     0           activation_394[0][0]             \n",
            "                                                                 batch_normalization_396[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_396 (Activation)     (None, 8, 8, 64)     0           add_191[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_423 (Conv2D)             (None, 8, 8, 64)     36928       activation_396[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_397 (BatchN (None, 8, 8, 64)     256         conv2d_423[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_397 (Activation)     (None, 8, 8, 64)     0           batch_normalization_397[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_424 (Conv2D)             (None, 8, 8, 64)     36928       activation_397[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_398 (BatchN (None, 8, 8, 64)     256         conv2d_424[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_192 (Add)                   (None, 8, 8, 64)     0           activation_396[0][0]             \n",
            "                                                                 batch_normalization_398[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_398 (Activation)     (None, 8, 8, 64)     0           add_192[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_425 (Conv2D)             (None, 8, 8, 64)     36928       activation_398[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_399 (BatchN (None, 8, 8, 64)     256         conv2d_425[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_399 (Activation)     (None, 8, 8, 64)     0           batch_normalization_399[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_426 (Conv2D)             (None, 8, 8, 64)     36928       activation_399[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_400 (BatchN (None, 8, 8, 64)     256         conv2d_426[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_193 (Add)                   (None, 8, 8, 64)     0           activation_398[0][0]             \n",
            "                                                                 batch_normalization_400[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_400 (Activation)     (None, 8, 8, 64)     0           add_193[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_427 (Conv2D)             (None, 8, 8, 64)     36928       activation_400[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_401 (BatchN (None, 8, 8, 64)     256         conv2d_427[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_401 (Activation)     (None, 8, 8, 64)     0           batch_normalization_401[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_428 (Conv2D)             (None, 8, 8, 64)     36928       activation_401[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_402 (BatchN (None, 8, 8, 64)     256         conv2d_428[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_194 (Add)                   (None, 8, 8, 64)     0           activation_400[0][0]             \n",
            "                                                                 batch_normalization_402[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_402 (Activation)     (None, 8, 8, 64)     0           add_194[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 1, 1, 64)     0           activation_402[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_12 (Flatten)            (None, 64)           0           average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 10)           650         flatten_12[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 470,218\n",
            "Trainable params: 467,946\n",
            "Non-trainable params: 2,272\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9m2oluAJD6f"
      },
      "source": [
        "singular_values_clipping = LambdaCallback(on_epoch_end = afterEpochClipTo1)\r\n",
        "callbacks = standard_callbacks(model_type) + [singular_values_clipping]"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHLX6E6ZJVpw",
        "outputId": "103e707f-884f-4ce4-af47-4f29715df662"
      },
      "source": [
        "history = run_training(model, model_type, x_train, y_train, x_test, y_test,\r\n",
        "                       'trainHistoryDict_clip_1', steps_per_epoch=100, epochs=250,\r\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 12s 91ms/step - loss: 3.2535 - acc: 0.2539 - val_loss: 2.6328 - val_acc: 0.2073\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.20730, saving model to /content/saved_models/cifar10_ResNet32v1_model.001.h5\n",
            "Epoch 2/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.7636 - acc: 0.3840 - val_loss: 3.7335 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.20730\n",
            "Epoch 3/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 1.4934 - acc: 0.4833 - val_loss: 4.6673 - val_acc: 0.1110\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.20730\n",
            "Epoch 4/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.3222 - acc: 0.5528 - val_loss: 2.6482 - val_acc: 0.2707\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.20730 to 0.27070, saving model to /content/saved_models/cifar10_ResNet32v1_model.004.h5\n",
            "Epoch 5/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.2194 - acc: 0.5885 - val_loss: 2.2573 - val_acc: 0.3819\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.27070 to 0.38190, saving model to /content/saved_models/cifar10_ResNet32v1_model.005.h5\n",
            "Epoch 6/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.1504 - acc: 0.6119 - val_loss: 1.3997 - val_acc: 0.5593\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.38190 to 0.55930, saving model to /content/saved_models/cifar10_ResNet32v1_model.006.h5\n",
            "Epoch 7/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.1043 - acc: 0.6297 - val_loss: 1.2628 - val_acc: 0.6014\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.55930 to 0.60140, saving model to /content/saved_models/cifar10_ResNet32v1_model.007.h5\n",
            "Epoch 8/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.0317 - acc: 0.6480 - val_loss: 1.4558 - val_acc: 0.5494\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.60140\n",
            "Epoch 9/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.9608 - acc: 0.6822 - val_loss: 3.6441 - val_acc: 0.3443\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.60140\n",
            "Epoch 10/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.9612 - acc: 0.6825 - val_loss: 1.5780 - val_acc: 0.5506\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.60140\n",
            "Epoch 11/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.9179 - acc: 0.6975 - val_loss: 1.2917 - val_acc: 0.5927\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.60140\n",
            "Epoch 12/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.8941 - acc: 0.7061 - val_loss: 1.4259 - val_acc: 0.6134\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.60140 to 0.61340, saving model to /content/saved_models/cifar10_ResNet32v1_model.012.h5\n",
            "Epoch 13/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.8653 - acc: 0.7151 - val_loss: 1.5479 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.61340\n",
            "Epoch 14/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.8600 - acc: 0.7132 - val_loss: 2.1037 - val_acc: 0.4695\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.61340\n",
            "Epoch 15/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.8264 - acc: 0.7268 - val_loss: 1.0168 - val_acc: 0.6847\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.61340 to 0.68470, saving model to /content/saved_models/cifar10_ResNet32v1_model.015.h5\n",
            "Epoch 16/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.8114 - acc: 0.7384 - val_loss: 3.9366 - val_acc: 0.3606\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.68470\n",
            "Epoch 17/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.7991 - acc: 0.7445 - val_loss: 0.9482 - val_acc: 0.6997\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.68470 to 0.69970, saving model to /content/saved_models/cifar10_ResNet32v1_model.017.h5\n",
            "Epoch 18/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7910 - acc: 0.7421 - val_loss: 1.8348 - val_acc: 0.5185\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.69970\n",
            "Epoch 19/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7562 - acc: 0.7499 - val_loss: 2.2560 - val_acc: 0.4759\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.69970\n",
            "Epoch 20/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.7393 - acc: 0.7643 - val_loss: 1.7903 - val_acc: 0.5562\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.69970\n",
            "Epoch 21/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7506 - acc: 0.7589 - val_loss: 1.8165 - val_acc: 0.5326\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.69970\n",
            "Epoch 22/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7336 - acc: 0.7596 - val_loss: 1.6379 - val_acc: 0.5611\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.69970\n",
            "Epoch 23/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.7108 - acc: 0.7726 - val_loss: 1.4344 - val_acc: 0.6303\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.69970\n",
            "Epoch 24/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7091 - acc: 0.7731 - val_loss: 2.3021 - val_acc: 0.4711\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.69970\n",
            "Epoch 25/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6794 - acc: 0.7818 - val_loss: 1.4584 - val_acc: 0.6106\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.69970\n",
            "Epoch 26/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6884 - acc: 0.7744 - val_loss: 1.2966 - val_acc: 0.6456\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.69970\n",
            "Epoch 27/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7143 - acc: 0.7712 - val_loss: 0.9970 - val_acc: 0.7110\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.69970 to 0.71100, saving model to /content/saved_models/cifar10_ResNet32v1_model.027.h5\n",
            "Epoch 28/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6845 - acc: 0.7842 - val_loss: 1.3445 - val_acc: 0.6389\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.71100\n",
            "Epoch 29/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6472 - acc: 0.7950 - val_loss: 1.4332 - val_acc: 0.5861\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.71100\n",
            "Epoch 30/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6486 - acc: 0.7901 - val_loss: 1.2648 - val_acc: 0.6579\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.71100\n",
            "Epoch 31/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6551 - acc: 0.7848 - val_loss: 3.0551 - val_acc: 0.4578\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.71100\n",
            "Epoch 32/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6554 - acc: 0.7908 - val_loss: 0.8916 - val_acc: 0.7266\n",
            "\n",
            "Epoch 00032: val_acc improved from 0.71100 to 0.72660, saving model to /content/saved_models/cifar10_ResNet32v1_model.032.h5\n",
            "Epoch 33/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6131 - acc: 0.8055 - val_loss: 1.2121 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.72660\n",
            "Epoch 34/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6228 - acc: 0.8036 - val_loss: 1.2823 - val_acc: 0.6526\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.72660\n",
            "Epoch 35/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6312 - acc: 0.8003 - val_loss: 3.3187 - val_acc: 0.4113\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.72660\n",
            "Epoch 36/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6008 - acc: 0.8099 - val_loss: 1.0416 - val_acc: 0.7007\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.72660\n",
            "Epoch 37/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6345 - acc: 0.7957 - val_loss: 1.3877 - val_acc: 0.6163\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.72660\n",
            "Epoch 38/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5981 - acc: 0.8073 - val_loss: 1.8630 - val_acc: 0.5390\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.72660\n",
            "Epoch 39/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5967 - acc: 0.8106 - val_loss: 1.9402 - val_acc: 0.5388\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.72660\n",
            "Epoch 40/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5997 - acc: 0.8064 - val_loss: 1.5304 - val_acc: 0.6234\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.72660\n",
            "Epoch 41/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6026 - acc: 0.8068 - val_loss: 0.9947 - val_acc: 0.7028\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.72660\n",
            "Epoch 42/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6038 - acc: 0.8097 - val_loss: 1.3821 - val_acc: 0.6346\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.72660\n",
            "Epoch 43/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5667 - acc: 0.8220 - val_loss: 1.0198 - val_acc: 0.7126\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.72660\n",
            "Epoch 44/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6161 - acc: 0.8038 - val_loss: 1.0390 - val_acc: 0.6956\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.72660\n",
            "Epoch 45/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5844 - acc: 0.8121 - val_loss: 1.7012 - val_acc: 0.5971\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.72660\n",
            "Epoch 46/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5806 - acc: 0.8147 - val_loss: 1.0389 - val_acc: 0.7174\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.72660\n",
            "Epoch 47/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5742 - acc: 0.8217 - val_loss: 0.8880 - val_acc: 0.7397\n",
            "\n",
            "Epoch 00047: val_acc improved from 0.72660 to 0.73970, saving model to /content/saved_models/cifar10_ResNet32v1_model.047.h5\n",
            "Epoch 48/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5884 - acc: 0.8114 - val_loss: 1.5177 - val_acc: 0.5598\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.73970\n",
            "Epoch 49/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5683 - acc: 0.8176 - val_loss: 1.7339 - val_acc: 0.6070\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.73970\n",
            "Epoch 50/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5553 - acc: 0.8246 - val_loss: 1.0777 - val_acc: 0.6812\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.73970\n",
            "Epoch 51/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5424 - acc: 0.8332 - val_loss: 1.8777 - val_acc: 0.5891\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.73970\n",
            "Epoch 52/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5648 - acc: 0.8199 - val_loss: 1.1341 - val_acc: 0.6810\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.73970\n",
            "Epoch 53/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5440 - acc: 0.8294 - val_loss: 2.1426 - val_acc: 0.5095\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.73970\n",
            "Epoch 54/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5545 - acc: 0.8177 - val_loss: 1.1522 - val_acc: 0.6624\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.73970\n",
            "Epoch 55/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5515 - acc: 0.8284 - val_loss: 2.8151 - val_acc: 0.5108\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.73970\n",
            "Epoch 56/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5352 - acc: 0.8316 - val_loss: 0.9719 - val_acc: 0.7170\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.73970\n",
            "Epoch 57/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5589 - acc: 0.8278 - val_loss: 1.0305 - val_acc: 0.7189\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.73970\n",
            "Epoch 58/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5442 - acc: 0.8344 - val_loss: 1.7767 - val_acc: 0.5651\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.73970\n",
            "Epoch 59/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5401 - acc: 0.8297 - val_loss: 1.3055 - val_acc: 0.6608\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.73970\n",
            "Epoch 60/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5332 - acc: 0.8324 - val_loss: 1.3757 - val_acc: 0.6300\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.73970\n",
            "Epoch 61/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5449 - acc: 0.8313 - val_loss: 1.0205 - val_acc: 0.7274\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.73970\n",
            "Epoch 62/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5229 - acc: 0.8350 - val_loss: 1.6959 - val_acc: 0.6242\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.73970\n",
            "Epoch 63/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5545 - acc: 0.8259 - val_loss: 1.0910 - val_acc: 0.6881\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.73970\n",
            "Epoch 64/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5246 - acc: 0.8345 - val_loss: 1.3198 - val_acc: 0.6327\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.73970\n",
            "Epoch 65/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5241 - acc: 0.8354 - val_loss: 1.0656 - val_acc: 0.6799\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.73970\n",
            "Epoch 66/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5293 - acc: 0.8337 - val_loss: 1.3807 - val_acc: 0.6163\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.73970\n",
            "Epoch 67/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5282 - acc: 0.8369 - val_loss: 0.8094 - val_acc: 0.7628\n",
            "\n",
            "Epoch 00067: val_acc improved from 0.73970 to 0.76280, saving model to /content/saved_models/cifar10_ResNet32v1_model.067.h5\n",
            "Epoch 68/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5233 - acc: 0.8359 - val_loss: 1.1459 - val_acc: 0.6769\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.76280\n",
            "Epoch 69/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5313 - acc: 0.8281 - val_loss: 0.9170 - val_acc: 0.7265\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.76280\n",
            "Epoch 70/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5118 - acc: 0.8409 - val_loss: 1.1025 - val_acc: 0.7062\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.76280\n",
            "Epoch 71/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5432 - acc: 0.8294 - val_loss: 0.9300 - val_acc: 0.7229\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.76280\n",
            "Epoch 72/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4863 - acc: 0.8540 - val_loss: 1.3479 - val_acc: 0.6653\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.76280\n",
            "Epoch 73/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5399 - acc: 0.8266 - val_loss: 2.0814 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.76280\n",
            "Epoch 74/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4864 - acc: 0.8493 - val_loss: 1.0816 - val_acc: 0.7041\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.76280\n",
            "Epoch 75/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5127 - acc: 0.8393 - val_loss: 1.6470 - val_acc: 0.6215\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.76280\n",
            "Epoch 76/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5132 - acc: 0.8389 - val_loss: 1.0459 - val_acc: 0.6907\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.76280\n",
            "Epoch 77/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5024 - acc: 0.8437 - val_loss: 1.0350 - val_acc: 0.7075\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.76280\n",
            "Epoch 78/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4919 - acc: 0.8450 - val_loss: 2.3961 - val_acc: 0.4970\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.76280\n",
            "Epoch 79/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5171 - acc: 0.8384 - val_loss: 0.9111 - val_acc: 0.7515\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.76280\n",
            "Epoch 80/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5100 - acc: 0.8353 - val_loss: 0.9693 - val_acc: 0.7184\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.76280\n",
            "Epoch 81/250\n",
            "Learning rate:  0.001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4820 - acc: 0.8523 - val_loss: 1.6277 - val_acc: 0.5994\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.76280\n",
            "Epoch 82/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4369 - acc: 0.8672 - val_loss: 0.4357 - val_acc: 0.8671\n",
            "\n",
            "Epoch 00082: val_acc improved from 0.76280 to 0.86710, saving model to /content/saved_models/cifar10_ResNet32v1_model.082.h5\n",
            "Epoch 83/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3501 - acc: 0.8969 - val_loss: 0.4331 - val_acc: 0.8682\n",
            "\n",
            "Epoch 00083: val_acc improved from 0.86710 to 0.86820, saving model to /content/saved_models/cifar10_ResNet32v1_model.083.h5\n",
            "Epoch 84/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3266 - acc: 0.9060 - val_loss: 0.3982 - val_acc: 0.8786\n",
            "\n",
            "Epoch 00084: val_acc improved from 0.86820 to 0.87860, saving model to /content/saved_models/cifar10_ResNet32v1_model.084.h5\n",
            "Epoch 85/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3317 - acc: 0.9012 - val_loss: 0.4351 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.87860\n",
            "Epoch 86/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.3096 - acc: 0.9110 - val_loss: 0.4314 - val_acc: 0.8672\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.87860\n",
            "Epoch 87/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3076 - acc: 0.9115 - val_loss: 0.4363 - val_acc: 0.8682\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.87860\n",
            "Epoch 88/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3015 - acc: 0.9087 - val_loss: 0.4284 - val_acc: 0.8711\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.87860\n",
            "Epoch 89/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2921 - acc: 0.9135 - val_loss: 0.4040 - val_acc: 0.8786\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.87860\n",
            "Epoch 90/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2953 - acc: 0.9142 - val_loss: 0.4239 - val_acc: 0.8718\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.87860\n",
            "Epoch 91/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2987 - acc: 0.9122 - val_loss: 0.3996 - val_acc: 0.8791\n",
            "\n",
            "Epoch 00091: val_acc improved from 0.87860 to 0.87910, saving model to /content/saved_models/cifar10_ResNet32v1_model.091.h5\n",
            "Epoch 92/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2867 - acc: 0.9178 - val_loss: 0.3909 - val_acc: 0.8830\n",
            "\n",
            "Epoch 00092: val_acc improved from 0.87910 to 0.88300, saving model to /content/saved_models/cifar10_ResNet32v1_model.092.h5\n",
            "Epoch 93/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2822 - acc: 0.9207 - val_loss: 0.4389 - val_acc: 0.8686\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.88300\n",
            "Epoch 94/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2864 - acc: 0.9151 - val_loss: 0.4164 - val_acc: 0.8760\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.88300\n",
            "Epoch 95/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2833 - acc: 0.9193 - val_loss: 0.4187 - val_acc: 0.8762\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.88300\n",
            "Epoch 96/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2754 - acc: 0.9238 - val_loss: 0.4067 - val_acc: 0.8772\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.88300\n",
            "Epoch 97/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2843 - acc: 0.9182 - val_loss: 0.4053 - val_acc: 0.8783\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.88300\n",
            "Epoch 98/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2780 - acc: 0.9224 - val_loss: 0.4116 - val_acc: 0.8768\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.88300\n",
            "Epoch 99/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2648 - acc: 0.9209 - val_loss: 0.3973 - val_acc: 0.8772\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.88300\n",
            "Epoch 100/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2672 - acc: 0.9231 - val_loss: 0.3951 - val_acc: 0.8824\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.88300\n",
            "Epoch 101/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2627 - acc: 0.9282 - val_loss: 0.3890 - val_acc: 0.8829\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.88300\n",
            "Epoch 102/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2599 - acc: 0.9273 - val_loss: 0.4813 - val_acc: 0.8555\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.88300\n",
            "Epoch 103/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2620 - acc: 0.9288 - val_loss: 0.4080 - val_acc: 0.8788\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.88300\n",
            "Epoch 104/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2727 - acc: 0.9206 - val_loss: 0.3705 - val_acc: 0.8876\n",
            "\n",
            "Epoch 00104: val_acc improved from 0.88300 to 0.88760, saving model to /content/saved_models/cifar10_ResNet32v1_model.104.h5\n",
            "Epoch 105/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2511 - acc: 0.9259 - val_loss: 0.3912 - val_acc: 0.8804\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.88760\n",
            "Epoch 106/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2500 - acc: 0.9295 - val_loss: 0.4125 - val_acc: 0.8814\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.88760\n",
            "Epoch 107/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2347 - acc: 0.9348 - val_loss: 0.3814 - val_acc: 0.8863\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.88760\n",
            "Epoch 108/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2405 - acc: 0.9297 - val_loss: 0.3960 - val_acc: 0.8788\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.88760\n",
            "Epoch 109/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2383 - acc: 0.9317 - val_loss: 0.4152 - val_acc: 0.8761\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.88760\n",
            "Epoch 110/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2319 - acc: 0.9332 - val_loss: 0.4442 - val_acc: 0.8694\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.88760\n",
            "Epoch 111/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2430 - acc: 0.9317 - val_loss: 0.4169 - val_acc: 0.8770\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.88760\n",
            "Epoch 112/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2451 - acc: 0.9282 - val_loss: 0.3938 - val_acc: 0.8822\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.88760\n",
            "Epoch 113/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2415 - acc: 0.9293 - val_loss: 0.4252 - val_acc: 0.8767\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.88760\n",
            "Epoch 114/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.2304 - acc: 0.9366 - val_loss: 0.3763 - val_acc: 0.8898\n",
            "\n",
            "Epoch 00114: val_acc improved from 0.88760 to 0.88980, saving model to /content/saved_models/cifar10_ResNet32v1_model.114.h5\n",
            "Epoch 115/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2262 - acc: 0.9380 - val_loss: 0.4591 - val_acc: 0.8677\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.88980\n",
            "Epoch 116/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2180 - acc: 0.9407 - val_loss: 0.4364 - val_acc: 0.8703\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.88980\n",
            "Epoch 117/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2237 - acc: 0.9439 - val_loss: 0.4105 - val_acc: 0.8801\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.88980\n",
            "Epoch 118/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2393 - acc: 0.9315 - val_loss: 0.4024 - val_acc: 0.8838\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.88980\n",
            "Epoch 119/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2264 - acc: 0.9338 - val_loss: 0.3742 - val_acc: 0.8906\n",
            "\n",
            "Epoch 00119: val_acc improved from 0.88980 to 0.89060, saving model to /content/saved_models/cifar10_ResNet32v1_model.119.h5\n",
            "Epoch 120/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2299 - acc: 0.9328 - val_loss: 0.4159 - val_acc: 0.8798\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.89060\n",
            "Epoch 121/250\n",
            "Learning rate:  0.0001\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2410 - acc: 0.9303 - val_loss: 0.3733 - val_acc: 0.8908\n",
            "\n",
            "Epoch 00121: val_acc improved from 0.89060 to 0.89080, saving model to /content/saved_models/cifar10_ResNet32v1_model.121.h5\n",
            "Epoch 122/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2201 - acc: 0.9382 - val_loss: 0.3428 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00122: val_acc improved from 0.89080 to 0.90000, saving model to /content/saved_models/cifar10_ResNet32v1_model.122.h5\n",
            "Epoch 123/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1991 - acc: 0.9464 - val_loss: 0.3418 - val_acc: 0.9009\n",
            "\n",
            "Epoch 00123: val_acc improved from 0.90000 to 0.90090, saving model to /content/saved_models/cifar10_ResNet32v1_model.123.h5\n",
            "Epoch 124/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2087 - acc: 0.9429 - val_loss: 0.3366 - val_acc: 0.9016\n",
            "\n",
            "Epoch 00124: val_acc improved from 0.90090 to 0.90160, saving model to /content/saved_models/cifar10_ResNet32v1_model.124.h5\n",
            "Epoch 125/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2033 - acc: 0.9437 - val_loss: 0.3409 - val_acc: 0.9007\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.90160\n",
            "Epoch 126/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2204 - acc: 0.9357 - val_loss: 0.3411 - val_acc: 0.9008\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.90160\n",
            "Epoch 127/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2128 - acc: 0.9416 - val_loss: 0.3345 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.90160\n",
            "Epoch 128/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1966 - acc: 0.9468 - val_loss: 0.3398 - val_acc: 0.9008\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.90160\n",
            "Epoch 129/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2053 - acc: 0.9429 - val_loss: 0.3358 - val_acc: 0.9023\n",
            "\n",
            "Epoch 00129: val_acc improved from 0.90160 to 0.90230, saving model to /content/saved_models/cifar10_ResNet32v1_model.129.h5\n",
            "Epoch 130/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2053 - acc: 0.9465 - val_loss: 0.3367 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00130: val_acc improved from 0.90230 to 0.90260, saving model to /content/saved_models/cifar10_ResNet32v1_model.130.h5\n",
            "Epoch 131/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2071 - acc: 0.9445 - val_loss: 0.3329 - val_acc: 0.9020\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.90260\n",
            "Epoch 132/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2081 - acc: 0.9454 - val_loss: 0.3348 - val_acc: 0.9029\n",
            "\n",
            "Epoch 00132: val_acc improved from 0.90260 to 0.90290, saving model to /content/saved_models/cifar10_ResNet32v1_model.132.h5\n",
            "Epoch 133/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2081 - acc: 0.9406 - val_loss: 0.3332 - val_acc: 0.9022\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.90290\n",
            "Epoch 134/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1977 - acc: 0.9466 - val_loss: 0.3386 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.90290\n",
            "Epoch 135/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1969 - acc: 0.9448 - val_loss: 0.3362 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.90290\n",
            "Epoch 136/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1976 - acc: 0.9456 - val_loss: 0.3440 - val_acc: 0.9006\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.90290\n",
            "Epoch 137/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1994 - acc: 0.9489 - val_loss: 0.3384 - val_acc: 0.9005\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.90290\n",
            "Epoch 138/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1968 - acc: 0.9490 - val_loss: 0.3325 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.90290\n",
            "Epoch 139/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1984 - acc: 0.9476 - val_loss: 0.3325 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.90290\n",
            "Epoch 140/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1934 - acc: 0.9489 - val_loss: 0.3370 - val_acc: 0.9009\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.90290\n",
            "Epoch 141/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1955 - acc: 0.9472 - val_loss: 0.3381 - val_acc: 0.9011\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.90290\n",
            "Epoch 142/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1927 - acc: 0.9469 - val_loss: 0.3356 - val_acc: 0.9009\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.90290\n",
            "Epoch 143/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2054 - acc: 0.9427 - val_loss: 0.3367 - val_acc: 0.9022\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.90290\n",
            "Epoch 144/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1967 - acc: 0.9486 - val_loss: 0.3356 - val_acc: 0.9007\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.90290\n",
            "Epoch 145/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1805 - acc: 0.9566 - val_loss: 0.3354 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.90290\n",
            "Epoch 146/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1865 - acc: 0.9509 - val_loss: 0.3336 - val_acc: 0.9009\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.90290\n",
            "Epoch 147/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1860 - acc: 0.9501 - val_loss: 0.3330 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.90290\n",
            "Epoch 148/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1878 - acc: 0.9484 - val_loss: 0.3373 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00148: val_acc improved from 0.90290 to 0.90310, saving model to /content/saved_models/cifar10_ResNet32v1_model.148.h5\n",
            "Epoch 149/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1964 - acc: 0.9486 - val_loss: 0.3404 - val_acc: 0.9012\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.90310\n",
            "Epoch 150/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1899 - acc: 0.9484 - val_loss: 0.3374 - val_acc: 0.9012\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.90310\n",
            "Epoch 151/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1879 - acc: 0.9510 - val_loss: 0.3357 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.90310\n",
            "Epoch 152/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2022 - acc: 0.9450 - val_loss: 0.3375 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.90310\n",
            "Epoch 153/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1950 - acc: 0.9481 - val_loss: 0.3322 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.90310\n",
            "Epoch 154/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1907 - acc: 0.9461 - val_loss: 0.3362 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.90310\n",
            "Epoch 155/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1945 - acc: 0.9471 - val_loss: 0.3341 - val_acc: 0.9016\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.90310\n",
            "Epoch 156/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1939 - acc: 0.9465 - val_loss: 0.3349 - val_acc: 0.9012\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.90310\n",
            "Epoch 157/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1909 - acc: 0.9470 - val_loss: 0.3354 - val_acc: 0.9020\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.90310\n",
            "Epoch 158/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1914 - acc: 0.9469 - val_loss: 0.3411 - val_acc: 0.9008\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.90310\n",
            "Epoch 159/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1897 - acc: 0.9479 - val_loss: 0.3389 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.90310\n",
            "Epoch 160/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1850 - acc: 0.9505 - val_loss: 0.3346 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.90310\n",
            "Epoch 161/250\n",
            "Learning rate:  1e-05\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1865 - acc: 0.9489 - val_loss: 0.3396 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.90310\n",
            "Epoch 162/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1795 - acc: 0.9525 - val_loss: 0.3373 - val_acc: 0.9034\n",
            "\n",
            "Epoch 00162: val_acc improved from 0.90310 to 0.90340, saving model to /content/saved_models/cifar10_ResNet32v1_model.162.h5\n",
            "Epoch 163/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1775 - acc: 0.9550 - val_loss: 0.3360 - val_acc: 0.9033\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.90340\n",
            "Epoch 164/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1894 - acc: 0.9520 - val_loss: 0.3352 - val_acc: 0.9036\n",
            "\n",
            "Epoch 00164: val_acc improved from 0.90340 to 0.90360, saving model to /content/saved_models/cifar10_ResNet32v1_model.164.h5\n",
            "Epoch 165/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1823 - acc: 0.9502 - val_loss: 0.3333 - val_acc: 0.9038\n",
            "\n",
            "Epoch 00165: val_acc improved from 0.90360 to 0.90380, saving model to /content/saved_models/cifar10_ResNet32v1_model.165.h5\n",
            "Epoch 166/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1896 - acc: 0.9481 - val_loss: 0.3328 - val_acc: 0.9042\n",
            "\n",
            "Epoch 00166: val_acc improved from 0.90380 to 0.90420, saving model to /content/saved_models/cifar10_ResNet32v1_model.166.h5\n",
            "Epoch 167/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1847 - acc: 0.9511 - val_loss: 0.3327 - val_acc: 0.9041\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.90420\n",
            "Epoch 168/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1805 - acc: 0.9518 - val_loss: 0.3326 - val_acc: 0.9034\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.90420\n",
            "Epoch 169/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1878 - acc: 0.9520 - val_loss: 0.3326 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.90420\n",
            "Epoch 170/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1888 - acc: 0.9496 - val_loss: 0.3337 - val_acc: 0.9034\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.90420\n",
            "Epoch 171/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1983 - acc: 0.9483 - val_loss: 0.3331 - val_acc: 0.9032\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.90420\n",
            "Epoch 172/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1841 - acc: 0.9507 - val_loss: 0.3326 - val_acc: 0.9033\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.90420\n",
            "Epoch 173/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1947 - acc: 0.9467 - val_loss: 0.3326 - val_acc: 0.9035\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.90420\n",
            "Epoch 174/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1810 - acc: 0.9541 - val_loss: 0.3332 - val_acc: 0.9034\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.90420\n",
            "Epoch 175/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1818 - acc: 0.9503 - val_loss: 0.3327 - val_acc: 0.9032\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.90420\n",
            "Epoch 176/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1795 - acc: 0.9525 - val_loss: 0.3328 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.90420\n",
            "Epoch 177/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1838 - acc: 0.9535 - val_loss: 0.3323 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.90420\n",
            "Epoch 178/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1902 - acc: 0.9489 - val_loss: 0.3320 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.90420\n",
            "Epoch 179/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1813 - acc: 0.9503 - val_loss: 0.3316 - val_acc: 0.9032\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.90420\n",
            "Epoch 180/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1942 - acc: 0.9490 - val_loss: 0.3320 - val_acc: 0.9029\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.90420\n",
            "Epoch 181/250\n",
            "Learning rate:  1e-06\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1858 - acc: 0.9508 - val_loss: 0.3328 - val_acc: 0.9037\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.90420\n",
            "Epoch 182/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1889 - acc: 0.9498 - val_loss: 0.3321 - val_acc: 0.9035\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.90420\n",
            "Epoch 183/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1950 - acc: 0.9480 - val_loss: 0.3326 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.90420\n",
            "Epoch 184/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1861 - acc: 0.9485 - val_loss: 0.3342 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.90420\n",
            "Epoch 185/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1828 - acc: 0.9554 - val_loss: 0.3333 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.90420\n",
            "Epoch 186/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1884 - acc: 0.9494 - val_loss: 0.3326 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.90420\n",
            "Epoch 187/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1951 - acc: 0.9454 - val_loss: 0.3326 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.90420\n",
            "Epoch 188/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1818 - acc: 0.9534 - val_loss: 0.3323 - val_acc: 0.9030\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.90420\n",
            "Epoch 189/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1760 - acc: 0.9548 - val_loss: 0.3327 - val_acc: 0.9035\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.90420\n",
            "Epoch 190/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1810 - acc: 0.9513 - val_loss: 0.3324 - val_acc: 0.9030\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.90420\n",
            "Epoch 191/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1974 - acc: 0.9474 - val_loss: 0.3331 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.90420\n",
            "Epoch 192/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1862 - acc: 0.9500 - val_loss: 0.3324 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.90420\n",
            "Epoch 193/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1935 - acc: 0.9499 - val_loss: 0.3331 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.90420\n",
            "Epoch 194/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1881 - acc: 0.9490 - val_loss: 0.3335 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.90420\n",
            "Epoch 195/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1889 - acc: 0.9510 - val_loss: 0.3332 - val_acc: 0.9030\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.90420\n",
            "Epoch 196/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1859 - acc: 0.9512 - val_loss: 0.3328 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.90420\n",
            "Epoch 197/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1808 - acc: 0.9531 - val_loss: 0.3323 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.90420\n",
            "Epoch 198/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1957 - acc: 0.9477 - val_loss: 0.3331 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.90420\n",
            "Epoch 199/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1923 - acc: 0.9505 - val_loss: 0.3323 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.90420\n",
            "Epoch 200/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1911 - acc: 0.9507 - val_loss: 0.3328 - val_acc: 0.9022\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.90420\n",
            "Epoch 201/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1850 - acc: 0.9520 - val_loss: 0.3330 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.90420\n",
            "Epoch 202/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1882 - acc: 0.9489 - val_loss: 0.3326 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.90420\n",
            "Epoch 203/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1872 - acc: 0.9476 - val_loss: 0.3327 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.90420\n",
            "Epoch 204/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1882 - acc: 0.9489 - val_loss: 0.3330 - val_acc: 0.9022\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.90420\n",
            "Epoch 205/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1860 - acc: 0.9527 - val_loss: 0.3327 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.90420\n",
            "Epoch 206/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1929 - acc: 0.9490 - val_loss: 0.3326 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.90420\n",
            "Epoch 207/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1827 - acc: 0.9518 - val_loss: 0.3326 - val_acc: 0.9023\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.90420\n",
            "Epoch 208/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1782 - acc: 0.9553 - val_loss: 0.3325 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.90420\n",
            "Epoch 209/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1827 - acc: 0.9511 - val_loss: 0.3332 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.90420\n",
            "Epoch 210/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1772 - acc: 0.9549 - val_loss: 0.3331 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.90420\n",
            "Epoch 211/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1894 - acc: 0.9503 - val_loss: 0.3327 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.90420\n",
            "Epoch 212/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1827 - acc: 0.9544 - val_loss: 0.3325 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.90420\n",
            "Epoch 213/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1871 - acc: 0.9495 - val_loss: 0.3324 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.90420\n",
            "Epoch 214/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1917 - acc: 0.9480 - val_loss: 0.3326 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00214: val_acc did not improve from 0.90420\n",
            "Epoch 215/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1961 - acc: 0.9448 - val_loss: 0.3323 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00215: val_acc did not improve from 0.90420\n",
            "Epoch 216/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1843 - acc: 0.9499 - val_loss: 0.3322 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00216: val_acc did not improve from 0.90420\n",
            "Epoch 217/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1910 - acc: 0.9497 - val_loss: 0.3329 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00217: val_acc did not improve from 0.90420\n",
            "Epoch 218/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1836 - acc: 0.9519 - val_loss: 0.3324 - val_acc: 0.9029\n",
            "\n",
            "Epoch 00218: val_acc did not improve from 0.90420\n",
            "Epoch 219/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1878 - acc: 0.9493 - val_loss: 0.3320 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00219: val_acc did not improve from 0.90420\n",
            "Epoch 220/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1688 - acc: 0.9587 - val_loss: 0.3322 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00220: val_acc did not improve from 0.90420\n",
            "Epoch 221/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1729 - acc: 0.9551 - val_loss: 0.3322 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00221: val_acc did not improve from 0.90420\n",
            "Epoch 222/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1842 - acc: 0.9540 - val_loss: 0.3320 - val_acc: 0.9023\n",
            "\n",
            "Epoch 00222: val_acc did not improve from 0.90420\n",
            "Epoch 223/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1864 - acc: 0.9498 - val_loss: 0.3323 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00223: val_acc did not improve from 0.90420\n",
            "Epoch 224/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2001 - acc: 0.9453 - val_loss: 0.3319 - val_acc: 0.9029\n",
            "\n",
            "Epoch 00224: val_acc did not improve from 0.90420\n",
            "Epoch 225/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1829 - acc: 0.9540 - val_loss: 0.3321 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00225: val_acc did not improve from 0.90420\n",
            "Epoch 226/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1827 - acc: 0.9514 - val_loss: 0.3327 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00226: val_acc did not improve from 0.90420\n",
            "Epoch 227/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1915 - acc: 0.9482 - val_loss: 0.3327 - val_acc: 0.9031\n",
            "\n",
            "Epoch 00227: val_acc did not improve from 0.90420\n",
            "Epoch 228/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1958 - acc: 0.9478 - val_loss: 0.3326 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00228: val_acc did not improve from 0.90420\n",
            "Epoch 229/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1817 - acc: 0.9516 - val_loss: 0.3318 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00229: val_acc did not improve from 0.90420\n",
            "Epoch 230/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1956 - acc: 0.9477 - val_loss: 0.3329 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00230: val_acc did not improve from 0.90420\n",
            "Epoch 231/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1838 - acc: 0.9501 - val_loss: 0.3332 - val_acc: 0.9030\n",
            "\n",
            "Epoch 00231: val_acc did not improve from 0.90420\n",
            "Epoch 232/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1769 - acc: 0.9542 - val_loss: 0.3322 - val_acc: 0.9029\n",
            "\n",
            "Epoch 00232: val_acc did not improve from 0.90420\n",
            "Epoch 233/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1812 - acc: 0.9537 - val_loss: 0.3323 - val_acc: 0.9018\n",
            "\n",
            "Epoch 00233: val_acc did not improve from 0.90420\n",
            "Epoch 234/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1767 - acc: 0.9541 - val_loss: 0.3328 - val_acc: 0.9029\n",
            "\n",
            "Epoch 00234: val_acc did not improve from 0.90420\n",
            "Epoch 235/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1767 - acc: 0.9525 - val_loss: 0.3325 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00235: val_acc did not improve from 0.90420\n",
            "Epoch 236/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1885 - acc: 0.9498 - val_loss: 0.3325 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00236: val_acc did not improve from 0.90420\n",
            "Epoch 237/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1807 - acc: 0.9540 - val_loss: 0.3322 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00237: val_acc did not improve from 0.90420\n",
            "Epoch 238/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1804 - acc: 0.9525 - val_loss: 0.3324 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00238: val_acc did not improve from 0.90420\n",
            "Epoch 239/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1959 - acc: 0.9430 - val_loss: 0.3328 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00239: val_acc did not improve from 0.90420\n",
            "Epoch 240/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1799 - acc: 0.9522 - val_loss: 0.3330 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00240: val_acc did not improve from 0.90420\n",
            "Epoch 241/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1902 - acc: 0.9487 - val_loss: 0.3321 - val_acc: 0.9023\n",
            "\n",
            "Epoch 00241: val_acc did not improve from 0.90420\n",
            "Epoch 242/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1974 - acc: 0.9457 - val_loss: 0.3319 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00242: val_acc did not improve from 0.90420\n",
            "Epoch 243/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1819 - acc: 0.9519 - val_loss: 0.3325 - val_acc: 0.9022\n",
            "\n",
            "Epoch 00243: val_acc did not improve from 0.90420\n",
            "Epoch 244/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1800 - acc: 0.9510 - val_loss: 0.3330 - val_acc: 0.9022\n",
            "\n",
            "Epoch 00244: val_acc did not improve from 0.90420\n",
            "Epoch 245/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1854 - acc: 0.9518 - val_loss: 0.3326 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00245: val_acc did not improve from 0.90420\n",
            "Epoch 246/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1928 - acc: 0.9496 - val_loss: 0.3326 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00246: val_acc did not improve from 0.90420\n",
            "Epoch 247/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1956 - acc: 0.9457 - val_loss: 0.3327 - val_acc: 0.9020\n",
            "\n",
            "Epoch 00247: val_acc did not improve from 0.90420\n",
            "Epoch 248/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1868 - acc: 0.9497 - val_loss: 0.3330 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00248: val_acc did not improve from 0.90420\n",
            "Epoch 249/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1798 - acc: 0.9536 - val_loss: 0.3322 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00249: val_acc did not improve from 0.90420\n",
            "Epoch 250/250\n",
            "Learning rate:  5e-07\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1852 - acc: 0.9509 - val_loss: 0.3322 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00250: val_acc did not improve from 0.90420\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "7MFzQn16UW_0",
        "outputId": "94186601-2050-4ed1-f328-2bbb6a81dfe6"
      },
      "source": [
        "import pickle\r\n",
        "\r\n",
        "history = pickle.load(open('trainHistoryDict_clip_1', \"rb\"))\r\n",
        "plot_loss_acc(history)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mROdGw5xUeTn",
        "outputId": "51ce7696-ecd7-4790-d6fa-a97d8b91984f"
      },
      "source": [
        "1 - history['val_acc'][-1]"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0974000096321106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joxUfpa9b2bk"
      },
      "source": [
        "### Plotting final graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvn_WyzCb8lS"
      },
      "source": [
        "history_no_clipping = pickle.load(open('trainHistoryDict', \"rb\"))\r\n",
        "history_05 = pickle.load(open('trainHistoryDict_clip_05', \"rb\"))\r\n",
        "history_1 = pickle.load(open('trainHistoryDict_clip_1', \"rb\"))"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "3fEb8EdkcnqV",
        "outputId": "55b40be2-96a4-4e6c-edd3-c59fdc330c7c"
      },
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\r\n",
        "axs[0].grid(True)\r\n",
        "axs[1].grid(True)\r\n",
        "axs[0].plot(history_no_clipping['val_loss'], label='no clipping')\r\n",
        "axs[0].plot(history_05['val_loss'], label='0.5')\r\n",
        "axs[0].plot(history_1['val_loss'], label='1')\r\n",
        "axs[0].set_title('Loss')\r\n",
        "axs[0].set_xlabel('Epochs')\r\n",
        "axs[0].set_ylim(0, 2)\r\n",
        "axs[1].plot(1 - np.array(history_no_clipping['val_acc']), label='no clipping')\r\n",
        "axs[1].plot(1 - np.array(history_05['val_acc']), label='0.5')\r\n",
        "axs[1].plot(1 - np.array(history_1['val_acc']), label='1')\r\n",
        "axs[1].set_title('Error')\r\n",
        "axs[1].set_xlabel('Epochs')\r\n",
        "axs[1].set_ylim(0, 0.4)\r\n",
        "axs[0].legend(loc='best')\r\n",
        "axs[1].legend(loc='best')"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f532c20d160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAGDCAYAAADZHo16AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9ebwkdXnv/36quk+fMwuzMTPAzLAJKvsgAwyiMmhwQYQY0YgaUa9Rc+HG/BL1ehND1HuNMbnXGETNdSEkMYpJiAhXXHAZkQgiyiLbOCzDzLDMvpyZs3R31fP7o+pb9f1WVfdZ5szWfD++htNdXesZ56lPf+rzfB5RVTw8PDw8PDw8PDw8cgT7+wQ8PDw8PDw8PDw8DjR4kuzh4eHh4eHh4eFRgCfJHh4eHh4eHh4eHgV4kuzh4eHh4eHh4eFRgCfJHh4eHh4eHh4eHgV4kuzh4eHh4eHh4eFRgCfJHh4eHh4eHh4eHgV4kuxx0ENE1ojIb+3v8/Dw8PDw6Iy0Vg+LyC7rzzX7+7w8PDqhtr9PwMPDw8PDw+M5g9ep6g+6rSAiNVVtF5aFqhqN9yATXd/DowpeSfboSYhIQ0Q+IyJPp38+IyKN9LNDReT/ich2EdkqIj8VkSD97L+LyFMiMigiq0TkFfv3Sjw8PDx6GyLyDhH5TxH5WxHZAnxURK4TkS+IyC0ishs4X0ROEJGVae1+UEQutvZRWn+/XZBHz8AryR69ij8DlgNLAQW+BXwE+HPgT4D1wPx03eWAisgLgCuBM1X1aRE5Ggj37Wl7eHh4PCdxNnA9sBCoA18A3gJcCFwETAfuAa4FXgm8BPiWiCxT1VXpPuz1+/bp2Xv0JLyS7NGreCvwcVXdqKqbgI8Bv5d+1gIOB45S1Zaq/lRVFYiABnCiiNRVdY2qPrZfzt7Dw8OjN3FjqgSbP7+fLn9aVT+rqm1VHU6XfUtV/1NVYxLBYwbwV6raVNUfAf8PuMzad7a+qo7su0vy6FV4kuzRqzgCeNJ6/2S6DOBvgEeB74vI4yLyYQBVfRT4I+CjwEYRuV5EjsDDw8PDY6rw26o62/rzpXT5uop17WVHAOtSwmzwJLCow/oeHnsMT5I9ehVPA0dZ749Ml6Gqg6r6J6p6LHAx8MfGe6yqX1PVl6TbKvCpfXvaHh4eHs9J6BjLngaWmP6RFEcCT42xDw+PScOTZI9eQV1E+s0f4OvAR0RkvogcClwFfBVARC4SkeNERIAdJDaLWEReICIvTxv8RoBhIK4+nIeHh4fHPsTPgSHgQyJSF5EVwOtIfMweHnsFniR79ApuISG15k8/cDdwP/Br4FfA/0rXPR74AbALuAP4vKr+mMSP/FfAZuBZYAHwP/bdJXh4eHj0PG4u5CR/czwbqWqThBS/hqRGfx54u6o+shfP1eM5Dkn6lTw8PDw8PDw8PDw8DLyS7OHh4eHh4eHh4VHAmCRZRJaIyI9F5KE0vPv9FeuIiFwtIo+KyP0i8iLrs8tFZHX65/KpvgAPDw8PDxci8up0GM6jJr2lw3pvEBEVkWXWsv+RbrdKRF61b87Yw8PD48DDmHYLETkcOFxVfyUiM4FfkkS4PGStcyHw30hCvM8G/k5VzxaRuSS+0GUkXae/BM5Q1W175Wo8PDw8nuMQkRD4DXABydCcXwCX2TU7XW8m8G2SoQtXqurdInIiSdPrWSSRWz8Anu/H+3p4eDwXMaaSrKrPqOqv0teDwMO4uYQAlwD/pAnuBGan5PpVwK2qujUlxrcCr57SK/Dw8PDwsHEW8KiqPp42O11PUqOL+J8kEYf20IVLgOtVdVRVnyDJEz9rb5+wh4eHx4GICXmS0zG9p5NEsdhYhBvivT5d1mm5h4eHh8fewZh1N7XELVHVb090Ww8PD4/nCmrjXVFEZgA3AH+kqjun+kRE5D3AewAGBgbOWLJkyYS2j+OYoUjYPJzYR/obO2jLbhb3LWbt7iGobybQPmLazJZFHNInRBrxVOspZz9zo5itYfLdoSENDg/nMn33k4yI8FhfHYBF9SMIpcb0oXUE0SgATzams4sWAEv6ljASj7CpvQmAmcFMFmhI/8hGWvVDGOlfUHkN9dYg/SMbAEElQDRiaNpiorCfsDXIpmgruwJBSLwrs6KYxe02o415hNEotfYugGybZJ876R/ZiErIrhnHMHPX4zTrh1BvDdKqz6Te3sUWUTbUQhYxjdmj29Ggzo5pi7PfzYmjTQSh2TebvtYOBmccO6G/m/EgjmOCoDf7SHv52qC3r28y1/ab3/xms6rO30untMdIhzF8GnjHHu5nj2o2VP9+N7Q2MKqjzOIIto0EzOwTwvoOdkY7Ia6zsH44G6K1ycoagkQ0pMHC+sJsH21t83TraQDmxsK2QDlxtAnA9vo0ngrazjEPrR1KTWo823qWUEJQEBEa0mBubS7rmuuYHc7mkPCQbJsRHWFjayOL28pA3GZ1en+YE8VEAjsr/n9TVzissYR1zeR7yHHNFg1Vds04Fk1nZIjGzNj1OACDM49jYPhZgrgJIsRSY3jgcIbjYTa1NzErmMni4S3Jdc08hqeaSc2eW5tLXepsaG3gyFYbpvuaPRH08rVBb1/fVNfscZFkEamTEOR/UdX/qFjlKcCukIvTZU8BKwrLV1YdQ1W/CHwRYNmyZXr33XeP59QyrFy5kk0znscH//1+AJadfjtr2z/krrfexWl/8xniBV9hWvw8dutT/OFx1/Oelz2P9YPrec1/vMbZzxt27uKGQ2YAcOK8E/nGiz8JV5/OI3113rjocAC+89vfZvGsI+EL58KGBwD441PP59bBxwD4+Vt+zt0b7uaKH14BwJue/yb+vG8J3Px+OP2tcMk11Rdx79fhxveBhDAwB4Y2wzuvh6PO4cF//QR/t/UfuGNgIFv9lbt28382bYEVfwKbHoYH07jJd/0rHHl28vpX/ww3XQkzFsIHVsFfLoIXXQ73/DMsfSs8fBNfkkGunjub/3vEhbz4P/8eZh/Js79/Kxf8+wUA/GzNWhoEsPy9cPc/wJ+tmtDfzXiwcuVKVqxYMeX7PRDQy9cGvX19k7k2EXly7LX2KjrVY4OZwMnAymSeDocBN4nIxePYNsOe1myo/v1uHdnKz57+GUc3XspFn72df3rXWTw8/B9cc+81RKPz+fIr/pX33n4+AHFzNkHfdk6bfxpfvfCr2T6e3f1sVr/e2e7nH2oj/OKJtQjw3eNfwgfba51j/u/z/jeLZizism9fxsJpC2nFLfrDfpYdtoy/OOcvOOOrZ/D+F72fd5/y7mybnz39M95763v5m93CiVuf4rVLkgn2Fw/uYnsYctu0AYpY0G7z7cvv4cx/OROAG9c/zfNabfjwL6E/JeCju+CTqXj/0VXw7++Cp++Fvmkwawlc9nV+vPbH/OGP/5B3vvCt/PF3PgnApg/dwcv/7eUA/OnZf8oL5ryAy797OVdv2MT5H3gIgnDCfz/d4P/dH7zo5eub6po9nnQLAb4CPKyqn+6w2k3A29OUi+XADlV9Bvge8EoRmSMic4BXpsv2CoKk4AOgKpimxDhOfpr/ttP3sZaHqUVivY4jSL/d22tmPSx202OXBki1J2Va51iCmbapcWk90YgYd5madTQ/T2c/7h6szzQ533Q9c81qrWs3dCpdztnDw+NAwy+A40XkGBHpA95MUqMBUNUdqnqoqh6tqkcDdwIXq+rd6XpvFpGGiBxDMnjnrn158nP753LRsRdx8qJZPPHJC3nZ8+dzSCMhkBI0GW3Z1TipYUGh5tWCXP+ppZ+ZitaqKGeKZjXP7KutbWpBLVGWgXbsqs9RnNwHYhHn/tASoVOXY4w49522qa02gS3eI4JaUuPtmp3egyKratv7VdVsHU0WdDgjDw+PbhiPknwu8HvAr0Xk3nTZn5LMTEdV/55k2tmFJE0eQ8A708+2isj/JCnaAB9X1a1Td/oubIU91rxoRLESAmhSfKIoKRhRRcN22ypQkUU+baKYFSO7KKHOa5dk6viKVHZsJSO16X5F485D6TVO1OfSfqzX2TJJ1jdEXPMzj63N3OtxDjb2dXh4eOw3qGpbRK4kESRC4FpVfVBEPg7crao3ddn2QRH5V+AhoA1csT+TLVKlm0P6cpI80rJPR9L/usSyHtSz12H6WURCqVtVB1KIU6obSICq0o7bhBLmpLlAkrP7i4hTO5sizn3E2UZcMpttZ9fvoighIcRR8ifdrzmXuHifsV6b4/iK7eExeYxJklX1dkr/akvrKHBFh8+uBa6d1NlNELaSHFtFL9aYkERdRpTIKMxVSrL1uh23K5XkWE2xtIqSuq+1VJrM+3EoyZCTWjUkOeq4R+KCklx5DIssqzrnbhTqyi8C2ZrSXQX38PA4YKCqt5CIF/ayqzqsu6Lw/hPAJ/bayU0ChiQTNBlpW1U6FT4moiQ3K+pYrHFWw0MJM5JZC2qICLWgVhJV2ul9ICZwavNoFyU5WT+vrZHzhI/ya0hU5jhyxBBz7AhXPbZfO0qyp8oeHpPCuBv3DgaIbbeIhTiO+e4DzxCpUiflhkGiLMPYSnKscU6SbZU1LtstiqS4WLCsk+x2AfabwocxRUqf7bVkt6jYj60oazyG3aJ8PR4HD1qtFuvXr2dkZGTslacAs2bN4uGHH94nx9rX6HZt/f39LF68mHq9Xvm5x9Qhs1tIxEjL/gI/NkkOMXUuEQhaFbVNyYWNQAJijRNxJSWlNall9goDIyQkdou85rYKyrKzDe79oG3W62q3CCFupyTZVbVtJdm+Q5SUZG+3OKDha/bUYaprdk+R5MD2E6sQq/LVO9dmRckU1G6eZPtRnGu3yFFtt8B6XVGQxlWkKmwSmd0iMqJJ+Zgau16TSiJe9CQb37Nlt7C3t063/FvyOJCxfv16Zs6cydFHH+18cdxbGBwcZObMmXv9OPsDna5NVdmyZQvr16/nmGOO2Q9n9txCpiRDtd2i8P/zmlhKclBQkiv2X/QkK4ndwpDtMAgz9dbAkOao4EluY3mNC4gp2C2qlOTitpknOb8fZcfuoCQbkp9ftyfJBzJ8zZ46THXN7qkMEKdxLwZEGW7lhS2pIZo18nVTkutBvWC3sBTmeAy7Ba7dInk9UbuFaeLLPcmlxr38hDoX2U6eZMv3bB75xdY5ljzJBfuHx4GLkZER5s2bt0+K7XMVIsK8efP2mfLzXIdLki1KauwWhVtZaCmzYnmSgWolWXPlNZAANLE0GCU5lLDcuKd5454tYLRFnAZw5ziIc9/J1qvqI8neW0py4DYRFpv1nPOzGgs9Dmz4mr33Mdma3bMkOU6r1nCrDZJ+l1ZXSS4+PoP88VcjbDhK8lh2iyJh7mRXuK+9k2ZUpWXQVU3o6kkuNe51S7dIPcnGbrHgBCfVwsApvlL+3OPAhi+2ex/+d7zvMJaSXLRb2KgZH2/69zVc8UW/aLdQlCiOMiW5FpTtFnnCREFJFstrXDyOFOwWlWtVKMmxabbOkzfAvYfFBVXZeVLqxY0DHr6e7H1M5nfcYyQ5f53yYIabtpKc2AuibhFwaYHqC/scT7Jjt6DCblEsQk46XEJKV9frvG3nL7j6V1dXX0ClmjCedIuJeJILdos3Xkd8UjKxNpZOndIeHvsfM2Yk+eVPP/00l1566aT38+53v5uHHnpoqk7LYx+gHuYeQqdxr4PdwkZ/SpJHDUmOy3Xfrt+hhEQaoWimSNek3LhnK7WZN1qVCMm9xgWU7BZV511q3AtSJTnvIxlLSY6JfeOex35HL9TsHvMk25YIIMCxWxji3E6LZLHoiaqjJO9u7c7IpZNukX1779K4V/HZ2nry635y8MnqCxgj3aLYDJLlJI8n3aKT3aJ/FvEhi+CpQha0cz1SvU8Pj/2AI444gn//93+f9PZf/vKXp/BsPPYp2rMKOcljK8mGJA8HAhGMxPazM8lUZNtu0YqS7hTjbQ6D7nYLc0b19B5StMYZJMa7/PhRUAcKj3875SRbdT5TsXVsJTlOFlSej4fHvsDBXLN7S0l2cpItu4X5Lp0pyWYdV1EQciU5s1tQJslVw0QcUlywW5hv+DvSE5zVN6v6ArraLbqlW8SF7ugqVdlSkgvpFqU8TSkOE6k8qodHJdasWcMJJ5zA7//+73PSSSfxyle+kuHhYQDuvfdeli9fzqmnnsrrX/96tm3bVtp+w4YNvP71r+e0007jtNNO42c/+1lp/yeffDIA1113HZdccgkrVqzg+OOP52Mf+1i2zgtf+ELe+ta3csIJJ3DppZcyNDQEwIoVKzDT4WbMmMGf/dmfcdppp7F8+XI2bNgAwGOPPcby5ctZvnw5H/nIRzJFxGP/4Tu/8x0aGz7o2i06eJJt9KdEdySzW+SV1HiO7ZodSJDZGTIlOah1bNyLrTSLPk2a9jp7kl1i277wr+GN17krdfMkj1NJVooRcB4eneFrdmf0lJJsP3IzRHik1U7i9Ek5rUDUSUkmie+B5PGePXFPHZXa2C26NO6V7BfKjjAlyY1xkORKu0WHxr2udovCsrQpBTRXyTOSbDU+Oo/uuuzX44DGx25+kIee3jml+zzxiEP4i9ed1HWd1atX8/Wvf50vfelLvOlNb+KGG27gbW97G29/+9v57Gc/y3nnncdVV13Fxz72MT7zmc842/7hH/4h5513Ht/85jeJoohdu3Z1PdZdd93FAw88wLRp0zjzzDN57Wtfy6GHHsqqVav4yle+wrnnnsu73vUuPv/5z/OBD3zA2Xb37t0sX76cT3ziE3zoQx/iS1/6Eh/5yEd4//vfz/vf/34uuugi/uVf/mVyvyiPKcXimYsZqP1mXOkWNgZSImxI8mgcZ/KQadIrKskGmZIsYVdPsqmWdTS7h1ShOHEvnrEAjvqtynU/O3sWz1/zPV4V1FJhoyLdwrqHFWNHfbrFwQlfsw+smt1bSnLRbgGMtiNMgcjtFun7uKwkZ3aLoNC4Z60Xa5XdAut1tfViezAGSXZI8EQb9zqF0VcpyZGzzHksV3ENTrqFh8c4cMwxx7B06VIAzjjjDNasWcOOHTvYvn075513HgCXX345t912W2nbH/3oR/zBH/wBAGEYMmtWp38vCS644ALmzZvHwMAAv/M7v8Ptt98OwJIlSzj33HMBeNvb3pYtt9HX18dFF13knCfAHXfcwRvf+EYA3vKWt0z08j32EvprYSHdIql1xYl7zjYp0R1O6+KIrSQHuZJsSp5Nkm0lueRJduwWqbiiSiR0VpKLjXta3boHcOPM6dy2/rb8KWHUzF634sQO4sbJuTnJ2fkK3m7hMSZ8za5GTynJbuOeIYX2t+vEbtEpAk7I8y37wr7OJNl40yaUbqHsSAtcR/9cF08yxGVPcn5C4/ckiyTeNut42WTCbhFwHgclxlIP9hYajUb2OgzD7NHd3kBRRTTvOy23Ua/Xs+VhGNJudyYtHvsf/fUwadzLyt04PMlpQsVIYCnJKe8MrBpoj6U2sJVkQ0wNsrHUYNktlGEJCjP4chTtFlUJSwC89AO0N3w3OUZGkltdPcnFnGTzPiHwvoofLPA1u/N6sO9rds8qya3IFIUy2Wt3IsmaK8n9tf4kkL20l/GlW5Q8yarsDF0/WQmVE/esxr1Oakk3u0XJkyy5klyyW1i7dKYEOh9Un4OHxxiYNWsWc+bM4ac//SkA//zP/5wpFDZe8YpX8IUvfAGAKIrYsWNH1/3eeuutbN26leHhYW688cZMiVi7di133HEHAF/72td4yUteMu5zXb58OTfccAMA119//bi389i7mNlfY+dwTlbVsltc86PVbNxZzkDtD5JkjMxuYdUwQ4hVc4tcaMVpdouAy3zBktst+tLGPXtyq026ixP3qhKWAHjFn9OSVA2WMkmu9CQXmsW9J9ljT+Frdg+T5GbbJsnp60IEXFlJ1jwCLuhL1jFWDWdQSfd0C0UrK9O2wFUBSqgit2vvhG1rEI1KlodxNe4V9ydBriRTJMnWNZa+XPiEC489xz/+4z/ywQ9+kFNPPZV7772Xq666qrTO3/3d3/HjH/+YU045hTPOOGPM6J+zzjqLN7zhDZx66qm84Q1vYNmyZQC84AUv4HOf+xwnnHAC27Ztyx4Hjgef+cxn+PSnP80555zDo48+OubjQ499g4WH9LNxcDRfkD4xbLaV//393/C9hzaUthlISfJoWn+bFY17kNc8W70ydoswCEt1O1OSnXSLxKNsr2kfIxbXk9xRMEk/U9Uk3QIgbmWE2VaSfzRtgEf66oVc5IL44cUNj0niuV6ze9Zu0Won3wBE1OJ2punBeJQ7e5L7woQkmzUqPclOo4R7LlUT97aGaYHr9IityjLxk0/B7k2VE/fyAxTtFs5O3X3bnuSCkuwMTHEaET059hg/jj76aB544IHsvd14sXTpUu68886u2y9cuJBvfetbpeWmGaS4/8WLF3PjjTeW1q/Vanz1q18tLV+5cmVpnwCXXnppluW5aNEi7rzzTnbt2sW3v/1tVq1a1fWcPfYNFhzSYOPOURqHmSVJbdKMLJeV2X5JSPJwmrVsk+SxlGTzuiYVSnLqJzaBmpBHwIVWzawFNceq4dgtOgkmJL7jSKOCAJLsN1OS45hPzZ3DspER3uJzkj0mCV+zO6O3SLLFkpuR0g84SjKCSDclOX9M1ggb6TppiZk2N1svT7fo8KhLtZR2AbDF2C06NWt0aL4bbQ3T0hZxgQdnk/CKOcmVTXYVSnLRbmHOWcRpAunwQNDDo2fxy1/+kiuvvJIoipg7dy7XXnvt/j4lD2DhzH6aUUzunnTtZKPtMunsD1NPsiHJVq02JDgmdiLgDIzdIgy6eZKtxj2TbqHlYxg42cZmH3HErzb+ijMPOxNIanFJSYZKu0VLklSm4j2oykbn4dGr2Fs1u7dIsuOddT299stO6RaEfbTTEHmjJLclhjd8hThswS/+MtmNnW5x3G/Bk3fAzMNgy6Z0acGfrEorbrMjVZI7P2Kr8hLDh4YeJgijTC0pXE7qSR4jJ7nKblHISXYaA4uVVSp+nx4e+xnveMc7eMc73lFaXlQuJoqXvvSl3HfffQwODjJz5sw9OEOPqcTCQ/rdBaYmdlGSG6mSPFJLfraoVpJNHaz0JEuNpjad/eY5yflpJJ5kN2ujFtQqt4P8XvCzp3/Gf/3hf+Xm376Zo2cdnavUHZKLzHaRRkQS0J612E260Dg7jvp0C48DCAdbze4pT7LbCVlOtzDLOinJQa1Bu286kJPkKI7glEuJp83J1nPsFrOPhD97Gq0POPsq2i22RXmn6ITsFsDGeJQttCvyMtJ1xpNu4SjJbWeZUZDVUmUq0y18DJyHh8d+xMJDGoUlaQ2jM0kOgpD+OGYktS1EUlZ5zdQ9KHiSxfIkd8pJLniSAScruZuSbF7vbu12fjqNeTbJDlxPcqwxrYFZtI44rWQfzKM9fbqFh8dk0VMkOagiyQW7BeRjqcueZMmKU263SL+NV3UkW9/yu03cA9jStkhyx8a9artF4nmLneZBBxp3SLSgvKzCk5x71wqJHOa158YeHh4HAEpKMq6SPFpBkglC+lUZriDJ4063kIqcZKPU4qZbFBEG47BbpMuMpSPLQaa6KdtRkuOo9HTSyUlOLrB0Xh4eHmOjx0hy/lqr7BaZktyFJGuBJMdRaV3NXitFNTZZmhdcQUBhKM4f1XWOgKv2FSeku6wFTCjdwo6AK9gtDDl2mhOdYHpre19sPTw89hPmz6xWkumiJCMJSTZKciyKxrlCDK6S7AwTMY17heY7sCfukXmSq0hyPU3XyLarsFuY+4s5hk2CqzzJtpIcaUKSi3YL70n28Nhz9BhJrrJbWL3H6irJpQY6yYtVUUl2C5BltxDzuK+6FAUSYI88TY4/kZzkZMhHTOyMxgabJBca96q8zdm9pBwBl38RyBv3XNJfsV8PDw+PfYz+esjsaRbp1HGQ5CCkP1ZGTASnKMRJfc/sFtphLLXVuNd54l7ez1GvUpILdgv7vvPw1of5xiPfyO4J5mcr7Y1R1UK/iTtxz1aSi5nJPifZw2PP0fskGbV8ycZeUN24Z7dbOJ5kXBKcp1torsY6cXCuv01R2pYyOz67Rf4yIcnllInsiHGXxr3iDiXIUzlMukW65062Ch8B5zEZfPe73+UFL3gBxx13HH/1V39V+vy6665j/vz5LF26lKVLl/LlL395P5ylx8GGwyzLhWZP8srpFi9a8KLkhQQMqGbDRCKJUU3qe2A9TeumJIdS4UmOcyU5j4Arn2/JbmHt53trvsf/+vn/KivJduNeF7tFrDFtbSdJGIUm9dyTjH8C6DEu+JpdRm+lW9jcUM2bcnEwdotS455VHDOSXKEkV9ktbJTsFtYxk9fjGCZSUJI1JcruccyLbhFw3XKSXYJvK8auKlHcp4dHd0RRxBVXXMGtt97K4sWLOfPMM7n44os58cQTnfV+93d/l2uuuWY/naXHwYgFh/TzVPaukJMc5XXrH1/zj8mLH3yUfo0ZTv14id2iQJI1HwBVpSTXglrpCWB2byBv3Kv0JHdp3Csua8dtblt/G/MH5if7LpFk9+lfM2pm2xX7ZjIlWcDryR5jwdfsavS+kiy2bSC1W0SdholYSnLgkmS3AE3QbqHqeHw75iR3iICL1RDlgt0iE8uVMdMt7PHUhXSL/IuAte+qdIuKdx4eVbjrrrs47rjjOPbYY+nr6+PNb35zZdi8h8dEMXvAtluYupcqya0qT3KQeJLTt4ndIqnvdrpFVQSc7Uku1u083SJ/ytdXUR+7eZKL+9owtIErfngFNz9+M9A53cKcS0aStV3oI9HS/c3Doxt8za5GbynJDjeU9L9Wy5u6qm5pmIhFTLOc5EJjhfPaTrcoNu6RK8mK0j7qJfDM9519ltCB6Jq9dUyZ6Na4Z5Nj81laWDOCb5Rk+wtFlSfZq8kHH77zYXj211O7z8NOgdeUH8XZeOqpp1iyZEn2fvHixfz85z8vrXfDDTdw22238fznP5+//du/dbbx8KhCLSyLIaZc2UpyvkriSd6aklm1lOTKCLjCtDyzXhRH/PDJH/L9J7/Pp172KcfOYPpFqjzJQcH+ViWSmHvCYHMQgJIaxpIAACAASURBVB2jO5J9a1xppcuU5HhsJTlGvN3iYIKv2QcUekpJdhTUbukWprh1+aZtiuOW4S1Jp7A9gc4eJpK9qp64Z4h31D8z2+/EI+A08yXbUHvdCUXAxflr7Il7+brO9Qj4pj2PqcbrXvc61qxZw/33388FF1zA5Zdfvr9PyeMgQF9o1UktepI7R8CNoLSy20JqtwjyGpgpyZbgYF6HkjTu3b3hbn7w5A8AK4ECutotiiS5Skk2XuSh1pDzs6QkFzzJpsGvSJIh750pmuk8PCaL52LN7iklOYrLhDixWxQa9zqOpc6JoHlE9t4fvJerzrlqQnYL+7UULA2NsDE+T7Jtt8DYLVxo30w49zI4672w+vvOlZRfVw0TMddTnrhXnW7hcdBhDPVgb2HRokWsW7cue79+/XoWLVrkrDNv3rzs9bvf/W4+9KEP7bPz8zh40U1JriTJaQTcMDHNdP1Ak3SLoEIncjzJ4nqS23G71KdiN1VXNe5JQbSoEkmMbWKonZBjM1QkyUm2xZOC3SJVkltxq2y3wCLJXkk+eOBr9gGFnlKSW86jts5Kcjtdr0hW7WJm+8hWbV3lNrLFZbuFcxjNibLxJJtj9QV9nT3JHewWhiCXlGQBLvg4zFrUpXGvsMwZS+2mW9j77+hJ9sXWYxw488wzWb16NU888QTNZpPrr7+eiy++2FnnmWeeyV7fdNNNnHDCCfv6ND0OQtTDcp3ULmOpCYIkAk7jbBJeQBoBF5Qj4CqHiaRPAFtxi0ijpKZbnmR7LHXp8OltVtLPqux2GUlOFeTd7ZQkx92V5NFoNHtftFv4nGSPicDX7Gr0lJLs+NEsu4UUlsVmeEbBbmGrCjZJPmLGEdWeZHuYSLG9zbJb2JmVfWHfhIeJGJJcHiZiK88dSHLJkyyldIss5k6r1XBF0v14y4XH+FCr1bjmmmt41ateRRRFvOtd7+Kkk07iqquuYtmyZVx88cVcffXV3HTTTdRqNebOnct11123v0/b4yBAvcpuYRr32hVP6cwwEY0ykhzSICInxLHmz+rsJ4q23cIoyZAouXk8aD5MpMqTLBkxT6wZVUqysVsMp5NZM7sF3T3Jdr5y0fLn0y08JgJfs6vRUyR58ZwBAF7xwgWsXP9QslBiJ+ECoN3BbmFzQNuXNtoezYaLgN24Z9ktOjTuFZXk/lp/F7tFB0+yQtQxPyOFk8U5lpLspluYPeeNgRXDRJq7uh3dw6OECy+8kAsvvNBZ9vGPfzx7/clPfpJPfvKT+/q0PA5y1CvtFp2V5LXbRxnQmCYxzbQO1qSPiEJOsnbJSU6HiZingLbtwvYk1xctg9HHneMb0i1BDdLhH0V0sluoaiHdIlWSC08jW3GrNEzEifb0TwA9xgFfs8voKbvFgpn9PPaXF/L2Fx9NN7tFt7HUBqZIAYxEI4UCVGG3sNDNk1wP6p0b9yq9xHm6RcfGPehIsKs9yYVhIlpht/CeZA8PjwMQE7VbrNsZ05/Ws11pBFIoqSd5jGEitt0i1jgjs1GcE2b7iH1n/pfS8Y3gIlJNcCH3FmeNeylZTsZSdx4mYlC0W9hKcuyfAHp4TBo9RZIBwkCoB1IYJlKMgOvQuGcei0nASxe/lD960R9RD+qMtF2SHGdKQLXdwpm4l0bAGfWgETYmYbcwjRguOpPksdItXLtFnm7RyW7R8ageHh4e+xQ2Sc4n7iXvqxr3Hj70VdzQejkAu1IltibuWGo0r3+OJ9k07qU/jQc40ihLj3CU5EImMuRCSVCwStgw5NvYLbLGvTEm7hm047Fykn3d9vCYDHqOJAPUawFuuoVBqpyOoSQHBNSDOv/llP/CnMYcRqKRUlME0DXdopMnuRE2ujTudVKSk0JcEgTS91+8/4usGt5kLa8gzPbEvaxId1CSKyPgiufn4eHhse/h2C3U5NR3VpJ3BzN5JHoeAIMpSa4HLkmOyWM+AytNIvMkpz9H2wlJNg18ybZ5MpAZQmXDFl+ggyc5cj3JTj5/lSe5sI+2dpm4B95u4eExSfQkSa4FeZOZVKVbdBomYraxyGB/rZ/h9rD7Ld1u3KsYJmIjkAAUp3FvohFwxo9cVpKT8dGfveez3Lrj4dJ1Fnae/uiiJFtrO/aSpW+B2UdWn7OHh4fHPkQtKNstTPpn1TCRdhxDnCi8RknuS0myKYt2tr3dwJ15ktOfw1FCYqM4sjzJ+TTUelhWkosxc5URcAW7hUE5JzmNgKuI8Szu163rniR7eEwGY5JkEblWRDaKyAMdPv+giNyb/nlARCIRmZt+tkZEfp1+dvdUn3wn1MOgMEykkJOs3SPgbE9af62/bLfQ2J68UTq+oyRnPmgrJ3nCw0Q62y2q/MSVirRYP4sRcNk+qgupnv0++KMpngDk4eGx1yAirxaRVSLyqIh8uOLz91m1+XYROTFdfrSIDFs1/e/3/dl3R/Kk0IXGuZWuXSDKrUhBE6I5bCbjBXlOciBBx8Y925MMMNJOhlvb6RZ2TrKZ1GrD7E8ykab8JDEbJtJ2SbKilXaLbpYNs12mdPsHgB4ek8Z40i2uA64B/qnqQ1X9G+BvAETkdcD/p6pbrVXOV9XNe3ieE0LiWTOqsO0V7u5JNiiS5NFotDxMxLyvsFvYOcmTjoCzoChR8Rik9N9kb9qfddhP9lnRbpGFzru+avv41ged9+3h4bHfISIh8DngAmA98AsRuUlVH7JW+5qq/n26/sXAp4FXp589pqpL9+U5TwR9FekWNi1uRjE1y7fcjmKUhGiOpPW6L8wb9yRN8zF1zk42ykhy0ZMcR5m4EFkCRqUneRx2i6In2SCKo+qc5C6jraEiJ9nXbQ+PSWFMJVlVbwO2jrVeisuAr+/RGU0BkolMadRPiOVLzh/NxXGxscGyW1jqcH9YVpIVpTjauROpNCqF40nuRJKd3ONi4171A7N8+lPZVuLsp1vjXlxUo6VE+kv79fDogne9610sWLCAk08+eX+fynMRZwGPqurjqtoErgcusVdQ1Z3W2+kcRM/jHbtFetaxVcpHW25db8eaeZeH03SLRtAPJATWNFebGp8N/0AyYmuIc6Ykx20n3SIbJlLhSc6UZHGfKtrIUjMKBFotS1+ys2q7hb0PcIejmD15eHSDr9nVmLKcZBGZRqJEXGktVuD7ksi5/1dVv9hl+/cA7wFYuHAhK1eunNDxd+3alW2zcSjOqlZATLkkKT9auZL129Y7S0dGkgIYR3G2r907drMz2snjVvblpsd+xWOP/388D3jiiTU8qSsZ3DWYfX7XXXexenQ1AM2RJpu3bObRwUcB2LJxC8Ojw5XX1xjZzDnp623btjMnfW0e58V5mAYArSjiJ7f9BIANm3Ox/ie33Yam6sO8zQ9wSrq/+1au5KTNW5jXbhIADz3yMBu3rWTX7iQDecPGjcnvcvdu7v/1/dn+7v7l3WxqbOLoJ9dwFPCTCf7djAf231+vYV9f26xZsxgcHBx7xSlCFEWl473pTW/ine98J+9973v36blMNaquzcbIyMiB+P/bRcA66/164OziSiJyBfDHQB/wcuujY0TkHmAn8BFV/WnVQfa0ZsPk/m2sfsYmiElB3L5jR7Zk5U9vZ05/TizXrBsFdZXkoZ27YSZs3rQZFJ588km2h9sBeHLNk0BCls25Pborqd+7RpJaeeddd7JzZ/I9Y7g5msWs3XfPfaXz3bZlGwBROujkiSefKK2zeXv1w9ah4SHuuOvu7L7w4MMPs2nLykqS/NBv8gcFzzz7DCNxej9DuPOOOxgZeLy0zZ7A1+ypg6/ZU4eprtlTOUzkdcB/FqwWL1HVp0RkAXCriDySKtMlpAT6iwDLli3TFStWTOjgK1euxGzzzI5h+EXSyNboC4nzeIb8xF76Mn5y14/g0fQTVQYGBmAQ6vV6tq+bV97M0PYhjjr6KEjr39zRdTxvw88AOObYYzjmZSu4+qarIamFnHnmmeizCnfBwMAAc2fN5ch5RyL3C0cuOpJH1jxC5fXtfAbuTF7OmTsXkpqddU9rQcgNw5CXvPQl8DWYPW8uJLyc81acn/vYHhmCB5L9rVixAjZeC1sSVeHEE07ixFNX8H+++X9gJ8xfMB9WwYwZMzjp5JPgx8kuTn/R6Zw6/1SI/xOe1Opz30PYf3+9hn19bQ8//DAzZ87cZ8cbHBwsHe/Vr341a9asIQiCfXouU42qa7PR39/P6aefvg/PaOqgqp8DPicibwE+AlwOPAMcqapbROQM4EYROamgPJvt96hmw+T+bQz/+hn+5VfushkzD8leLztrOUvmTsve37L5PticFPqRVJU97NCFPD4SsHDBQh5c+yCLj1zMgoEF8At43rHPg3ugr9aXndvgY4NwO0SSEN2lZyzl327/N9gOtb6+7Cnci896MXzLPbf5h86HddCoNxgaHWLR4kXwkLtO//R+aFJCvVHnnBefm90XTjrpZOITX4b+kxJK6CjPRx17FPwyeb1w4UIGm4OwPlGqli9fDnOO6v6LnSB8zZ46+Jo9dZjqmj2VJPnNFKwWqvpU+nOjiHyT5DFgJUmeStSCIOs2DgMIzJMmwzJFibrYLUqe5PZoOSfZfJPvYLco+ocjjQglpBbUukTAuV3bn5s9i5cPDaVKckFGBlTE6rCOnW0rdp4fQ93GvdyyYe/cfun6rz0OHnzqrk/xyNZHpnSfL5z7Qv77Wf99SvfpMaV4ClhivV+cLuuE64EvAKjqKDCavv6liDwGPB/YZ43XY8EdJpIgtopXcTR1O1LUKMnGblGvw3CQ2C1EQGHzcKLmmuY7Jy/ZNO5FiTpre5KNHS45t9yT3IhjRoOgbLfoMpa6iNLEvXQ8tjlP28PcqXHPp1scXPA1+8DClETAicgs4Dys79AiMl1EZprXwCuByoSMqUaflW5RCyHv85Dsv+1YnWJl0z87smegNlCauBdpnHuSO6RbZPsynuQ4IgxCQqvIlWCR0BbC38+ZxdsPX5jnJJeOk5PzjukWVTnJhc+q0i3cyDtfYD08DiL8AjheRI4RkT4SAeMmewUROd56+1rS51AiMj9t/ENEjgWOB6b2Of0eoirdwv6CXxwo0oo1s1sMmca9oA80zBr3htvD/Mfq/+C8xecxvT4dcBv4bMIMabpFlpOslTnJfZm24Pa6jOUnthFpVMpJtkly1T4CCdzGPcE37nl4TBJjKski8nVgBXCoiKwH/gKoA5juaOD1wPdVdbe16ULgm2mBqJF0U3936k69M5zGvQAkNt+j81i4KNasYc18khUzi2Q2wgbD7eFC8oNFWU26hWrWAOJkblo5yUZJ7pyTnBf/ppCmZCQEuF0h4toRcG2bJo81cc+56vJQFdJub4+DH149eO5BVdsiciXwPSAErlXVB0Xk48DdqnoTcKWI/BbQIjGKXZ5u/jLg4yLSIik97ytY6PY76kG5vsWWF604UKQdxSVPcqNeS5ZpoiR/+/FvM9ga5PKTLmftzrVAtZKc7TNuZ2Q1SbcwqRk5ca3jRsqNZ5hIEYmSXCDJ6ZPIhsl6ts7JHMduRPRK8sEFX7MPLIxJklX1snGscx1JVJy97HHgtMme2J7AJslhKASRUWKtAR2xlmwPnewWI+2RlOQGRBonEXDZRqndAiWQwHrEVRhLnZLkoo/MPYH8uKPp9jVgVCDqUOMyu0XH3OaCH7sii7kqa7k4QdDDw+PggareAtxSWHaV9fr9Hba7Abhh757dnqFaSbbtFuWcZE2fDmZ2i7COEmTpFoOtQabVprFs4TLWDSY9jzYxriLJlXYLKwKuURhO0s1uYYaJFBFp5JLkIMxEluLgErOPUELQ6iFRHh4eE0NPTtyrB67dIksMsqpF0ZPczW6hKKPt0XyEqZb9v4pmRdAmlWZZO24TBqmSrNGYSm0zPaEwXS+qUIdtu0U0lm+4Skm2VHBw7RbVmcnek+wxPlx22WWcc845rFq1isWLF/OVr3xlf5+SR4+gVqUkWyXZKMnNdsxIK0om7qVK8sb+wwHoryV2C0mJMiSk05BmyLORoWy3iDSyholYdgtLSW7EeVY+5OJLld3C5C8XUfYk53aLRugqyY7dAj+W2mNi8DW7GlPZuHfAIAiEIDD5lpDX1Jwtt+PyGE8DZyx1mORpDreHCXFJZbpytszOV7ZHnJrMSqMkQ+Jpq0uuBAy1hvjNlocwCf6mZHb7FqPYSrKb21xxVRWfu8pGdl3iXmPZjuHh0R1f//p+j0v36FFUN+4lpVg1V5L/8paHefiZncmTxZQkb6vPgfZ26kGN0Q0X8YbXvpaV634E5KTY1P+qoSIG7bjtPMUzFTKUMHt6WLRbCJ2V5E6NezFxwZOcN2sXPclmH6GETk6yenHDYxzwNbsaPakkA9TSwlQLbF5oDeiIO5M/227RqCXf1ofaQ0mTh2ql3cLezp7eZE/cM55kKAfK3/TYTbzzx1dmjSWjmZLc+RorlWSE9YPruW19GiKSkedyDJ5tFQE3Yq7jxD0PDw+P/Yi+Do170/uS2mqU5Gd2DPPU9uF0LLURJxL5oR7WaA+ewvFzXpiVRFObDZm11eOSkhxHTuOeWlY9Q64b6pLkzJNc0ZPSqZk71riUbmHIcLfGvXK6hYeHx2TQsyS5nhaqMIDQEEQrAq6oJNuNe44nOVWSh1oJSQ7obLcICqQTcpJs2y2grCYMtYdoa0QrPcWmGZHapcQlTX3paFRLSb7+kev58E8/bK2Vn2dV8kXmrbNsFV2JsX905+HhsZ9QabdQZXojqfnNKKmtrUhptuNkLHVKklsZSU6e4sVx/gQwI8nivi++BjfdIrKqpYhkvuQ+zftS7J9mu985/nccS0cVEpLs9pFk6RbBOJVkn27h4TFp9CxJDtPCUgvtTIscxXQLG7ZtYqA2ACQkNvGrFZTVCruFSbiw91WyWxSUg+KjMWO3cPWLMsw1ZI17IrTiVt4tbS1PfnaxW1BtsdDiPjw8PDz2EzrZLYySbMZSt6KYZhSnY6mTShoZkpyNd9YSKS6SZqiIgIvbuSc5tVuYPH5DfA1JPn5OkrZ38qEnZ9sC/OnZf8o3XveNrtea1WFzLhJkx+3mSbaVZN++5+ExefQsSZ7eSL7NL5rdz2Gz+tOlVgRcYba9aOd0C0iVZAICLWYSu+kW6ZuMcGYRcCYnOehOko2+PCrp9mPYLTIlOTurxLOWK9WG4FblJLuDUOIOhdTbLQ4++Ai/vQ//O94/qCLJkcK0TEnOG/ea7biD3SJXkk2jdlHV7RYBF2lk1WxFJb+ZmhpvcpKXH76cm3/7Zi457pJsW0j6VcalJEPuS7Yi4ErpFlGebuF6kvFK8kEAX0/2PibzO+5ZkvyXrz8VgFefspBLlh6RLs2V0HY0zgg4q3EvECGw/Gf2PouNe/Y+leRYjie5YLfIvvVP1G6hZbuFndNcKo4V6RZ5416+vJOq7HHgo7+/ny1btviiuxehqmzZsoX+/v6xV/aYUtTz6VAExjIWw7SCJ7kVxZndwtzqYpInbPWUnFYpyab+O8NEgrKSbO4fJsvePGgz+7E9yUfPOrrkSRYR515ThZKSbEXAFe0WJgIuCNx0C48DH75m731Mtmb3ZLoFwLGHJrO77SY6uzOtHAFXjm0DS0luDyVxQeRENl052XUhAs5Wkk2wexiEmXJQbN7I1dyC3aLbvxmpIsmdlOTOdovKCLhujXuq3npxAGPx4sWsX7+eTZs27ZPjjYyM9CxZ7HZt/f39LF68eB+fkYedkxxmfRVknuTRjCQr7VjT90JASEwEGhCGhrDmta1kt7BU3qLia+ckm2EiQcGm0WeRZHu/hlyHEpbIdxHGuidBriQb77G5NxnYnmQ0t+LFqUnQ48CFr9lTh6mu2T1LksVqSrPaKtKfWjmWOmvco0JJbg3TH9SSxj33QNlLJ92i4EmO4sgpikUV2/WPTUJJtuwWhqSrKlLMOO4yTEStLw2OepydgifGBwPq9TrHHHPMPjveypUrOf300/fZ8fYlevnaDlbUrUa2IEjkjShWBvqKJDn5OdRMamsY1IjjCAiz5r8ozm1y3Rr3imS2FbeshudEXjBnZQi1UZKLDeG2klz0OkP+9NHACCzJhzlJLnqSTR+Kz0k++OBr9tRhqq+tZ+0WQYEAFhFrl8a9TkqyJJ5kt9zkaqydbuFEwGlutxircS9KD20m7o3pSa6wW5ginBTJLkqyuMfudCjvSfbw8DhQYNstwiBXkuthQF8YZOQ4J8mpcms0IQ2z7SKtSLeoiIArepKN/xdSJVlyCcGsWy9M3LPvSZmlo4IkT69Pd947WcldSHJHT7KAV5I9PCaHnifJdtKEM0wkKivJ2esKkhxpRJB+x4/ttW27hZVuYe/LsVt0yEkup1sYJbkzXJKcDwKxFY4sJ7mbkox5LKfcMGM6OyySX7weDw8Pj/2J0IqACwxJjqEWBNRDoWXZLSBXkoOUaApBTq7HGQFXJLP2hLws3cLaT0hulSv6jttxOyPOVXaLEkm2s5KtCLhOdgufk+zhMXXoXbuFFb1W8iSLljzJNopjqbPlaU5y5DDqnIzb5Lo4cc/YLTJPslaT5CzdwijJY5S4PCfZbCnuslIEXLnp0Bz72ZEtfHT+PKTVcj3JpUd1vux6eHjsH9h1NvckK/VQqNfKSnK+bpIGIYTZdu1YOw8T6TJxz1ZtI0ciMSRZMqtcaSy1tiemJGsMlt3CHLukJMdWBJxPt/DwmBL0vJLciQgPt6ISUa0aJmIXIhEhoIvdgvLEPbswjsuTnPrtMiV5DLuFIbBty26RNWxUDD0pplvY67RShaJNTr6T4/icZA8PjwMPxp4cxVALhXoY0EwV5CJJzpXkMFOgbU9y3ZBooyR3adwzSnI9qBNrTJ6fkTbkIdQKSnKl3aJCSZ5Rn+G8d0hykE/cM/0yBo7doqQke5Ls4TEZ9CxJzpIm7Dg0yyYxONIqN+6ZyUgWGawFtaxABlKVk1xOt6iCsVt08iQX0y1M417chZcqFrm20i3GrSRL4JDkdjZBipKSPNQa4p6RjZ1PxsPDw2Mfw9iTY03sFrYn2UTBGQQYpdht3OvoSe4SAZeR5LCeeZJdu0WuJBvxJEu3iNvZvWLcSnKFJ9nYLcyEP8duYd33vJLs4TF59CxJDiy/bVW6xc7h1rjsFgCNWiNbHqBogWimu6z0QWf+MGO36OBJzkacilGSk3Nrd0iUCFQdJdlu3MvTKpTyWGo3As5Vkk1Ws1tQFeXmx27mnc9+nyERX3A9PDwOCGQNeHHS0FcPxbJbuHUqEEOCa7mS3KVxr5sn2ai2hqBGULZbZPqEK76043a2v/HbLXJPskmxME85DVk2y0MJ3XQL/wTQw2PS6F2STIXdwspJ3jHcdoiqrSQXGy1MMTJjqV1qnSvJTgScnZOsYw8TyTuRk30YJbndob4Z24fZrm17krVKSa6auCcFJTlRt+MCeVZVhtpDRGjH8/Hw8PDY1zB2izhWamFAvSLdIlvXslvU7MY9cZXjKpW36Em27RYAbXFzkkOxlGRjt7DuSRNRkp/e9TSra0bkCEtKsrFdZEpykEx5dVOLvLDh4TEZ9G7jXoXdwiRHTKsH7BzprCQXbROGJJvGvU52CxtZBBxuusXYEXCpkmy8xh2UZEmPUWW3cJd1i4Bz7RZGjY4r0i1yf5tnyR4eHgcGjN0iUqgHqSe5rcRxkoVvI8BKt7Aa94rDQ6qU5E6Ney5JJttPzVKSi57kSKPunuS+Gdl+2trm6nuu5tn+Jt8EEClFwNWDetJAmNbokpIM/umfh8ck0btKstUkUbRbzOivsXO4wpNc0bgHBZJczEm21GPbblF0OZhHbFnjXgeSHIsbAdfq8KgsMMQ/s1tE2flkhDu2lORx2C06epIp+Ns8PDw8DgBkc0VUEiU5TbdoVWTgG09yQOhGwBUi36pU3kACK78iV5L7wmQ0tP1csBbUCOx0i6z2Jj9accvJTi6ScqMkm33vau5iN/kTwWLjnh0tavZpp1tUS0EeHh7jQc+TZHuwh7FbzGiEmZJsCqGo1bhHtZKcPFDTjMiSLjXHqbRbkGdWjsduYfbdNJ7ksewWZj0rD7kyJ7lSSRYnxaJtPMm4yriqpVinV+vh4eGxvxHYTdah0BcKzXZMOyrXKDFKstQyktyumrhXoSSDq/qauDVDZKvsFqV0C/KJe7YQY+5BhvROq00jlDD3GsctmuYygzD3JKe9MvZ9xRzPPL0Eb7fw8NgT9CxJzsZBa1Qaq5woyW0ijZzismbLbqCbkixdx1Lbw0TsiXvGHxYGVk5yh8a9PALO5CZ3s1uQxb3lSnLBk9ytcS9VHAyMJ7lKSR5rKp+Hh4fHvkY+V0SoB7knuehHTtbNleSqxj1jnejkF7Zj4EbbBU8y+c20HtSpE9Cf7tusUxUBBzn5NveZvrCPv37ZX/PG578RSElydpmJkiwIfUFC0GtBLbuPGWXaZPNn8HYLD49JoWc9yd1ykqc3QnbsbBEfEjuFsBUp1CpIcm1idgvn49STnNktpDonOR8m4kbAjVdJzj3JQUFJ7j5MxFa029pZSXZHnHp4eHjsfwQBmdfB5CTvHm3TrCLJqZIciBUBF2mmOo+lJNeCWnasqsY9Q65/78TfY/OWZzlr1yqOfPO/ZR5jg7a2s0zm5HyS+4Yd6fbKo1/J7lYi2jSjJi2zckqS60E9adCjEFOazYXVwtNJT5I9PCaDnifJtvUhU5IbNdYOt4hjV0nO+aTLBM0jNZGgIt0iR6Ykp82CgmQCrrFbjOVJNnE9oya1ooMnWXSc6RZdleSCJzk2MXReSfbw8DjwkXmSkSzdohlpKf4tXSPZhlpm04hU2TqU6LTdPMlQsFuYxr3QkORcST51/qnQfziqcM6iF+fnKtV2C0Nw7UY8e/1ESXY9yfWw7sTIZfcxSc7ftsj5mu3hMXn0rN2isnEvlUGnN4KscS9XFiVx/AAAIABJREFUD/JSUsxJNl6xJN2i4EnuMEzEfq+qxHHsPBbrOJa6lJPc4fqSlGS3SS+5EDfdImP+5ny7TNzrpCTbqgQ+J9nDw2P/oqYzAdtukaRb9NWSnORWuyxlSNYsF1IL88Y9E4Ixpic5JaU1qeWNe6nloU3uSU52EmRxngZ2uoVNwIt2C0O8bZIcS3ovkMSTXA/qTkJGZrdIlWT7vufTLTw8Jo/eJ8nEliqaFKNpDWFwtE2scaWS3C3dovTgymoQFIswGyU5s1tom0CCjp7k/NFY8n4sJbmYkxxb6RbZ9D4nAq4iJ3mc6RblzE0PDw+P/YcT9C8YWvOeLMoNcHKSqzzJYqdbWBFwptYVI+CK8WzmXtFf66+IgLPnuQJBiBaU6KxPJo6c5nBzv8k8ySnxzkhy2qjXFHHsFjZpt9XnQALHzucb9zw8Jo+eJcmO9QEFBNWkyA30JYQ40ihv1sAyJnTISRakPJbaOo5RoG0V1pDkkt2igyc5zoaJjGG3SM/XFPi2RlngUKWSnEvJ1k7EJcPmXArXEGvsH915eHgcMJgeziMaPtaJgKuHkoylbseVnmSTbhFKPnEvVs0EBtuyAG6jnv2+ETYYjd0IuJKSfOwKnj3s5e7xDTFPBZPSfmud7RZgSLLknuQKJVkkYeu2CKPZfzw8PCaKnvUkJ9PxXKUUTYrkQF8+yjmLgIOskHTNSabzMJGiD1rImzmM3aLTMJGM2GbDRLqnW5rJ0bZtIwZCS0l2PMkdhokUbR8A8fGv7Gi38I17Hh4e+xv10GTaJ+8VqAVJTnJnT3K5ca8dKYpLkouRcAZG4Oiv9bN1ZGtyHhUT9wA4/gJWP1VnkbW9fV9xXqdMf8HAAgAOnXaos45RrZsiSQRcwZNck5pjFZFCQ7bnxx4ek0fPkmRIikwVSW70GTtCoXHPbEc1SRYJk8Y9x5McZBvbdovks/QjtewWQbXdIrNIZMNEupPkAKUNTs5xQpLHUJILdotKJbkxwx1LTTGY3pddDw+P/Yd6aPzFZomkOcmd7RakTxJDcRv3NK1qRU9yqXEvfT9QG8jTLVL/cKtot6hAlcXC3u8xs47hB5f+gIXTFzrrmEzmpgAS0I7bZSVZcoIfpOtkl23918PDY2LoWbsFpF2+1tQjNSS5ppgsH9tukYuuBbtFrZEtD7KSmh2FZFN1iqDtSYaEFNuPxYoKbpT5gdMIuLGUZFy7BUBbAjqmW3QaS11Bxovn5julPTw8DiTUUvXVrtW1ILFcdG7cs9IgQlOXc5Kc3wvG8CSH/VmNNdtEiDPYpAr2uTp2C0vBNgQZymJN5kmOyp7kLIEp/Z9DksU3W3t4TBY9TZIDAqvLVzIlua+uECRKgJ1hmSnJHewWscaEpZzkst0CzUmznVlZk852CzvTUhmPkuySV4AoCDvnJHeIgKu0W2hcUpi15G328PDw2D/oqwlhIIjkdemwWf15415cQQrT+h+mE/EgJclpvcysd2ZMddGTHLjeYXAb98a6mdr3lSrCXFSui/ehlkiSbpHaLWwl+ZC+Q7L9VtstPEn28JgMepskp/7cjOClj9vqYYykJHlmPYkSEkBVsu1sGJKcTDrKEygAdo5GXPbFO4m1kG5h0i7EtVuMlZMcE+TB8d2uzVySRWYjCRziG8XRmMNEquwWkUaO3cJu3OtO3T08PDz2PuphQCjifGV/4WGHpCRZaVYoyViNe6HVuKdSbbfoFAFnIkGT87CGiYwhINifOxFwJu846E6SmxTSLYJcGZ/TPyfbRkTKjXseHh6TQk+TZLFygG27RRjGSJiS5L6Z2fq2NcNGTpLbqd0i//wnqzZzx+NbaEWRm26h+X6MpcEZS90hJzkWGB3jsV1yjm4EHEAUJHaLygi4SiW5Q+OenS1NxTAR/+jOw8NjP6IvDBLLRKokz5/RIAyEvlpS34aa5YR50ZxUhlbjHkVPshkmUmG3CCXM1GOwc5JxG/cq4CjJFYS5SIpLJLkQAWc3GBqSnNktrPSkGHzN9vCYJHqaJAep5zYfJpIWozCqtFswhpLcjJulnORhS7GomvJn+8NqUqt8HAZ2uoWMiyQH6REckiyhQ3xj7GEiFTnJHSLgojhySbKqQ+I9PDw89id+98wlfPySk7MGvaPnJXXcpF4MNZMaGDj1qjoCLku3KOYkVzTu1YKaQ56zCDgZhye5U+NekHuLbZRJMkm6RdGTHNSY00hI8u7Wbt+45+ExhRiTJIvItSKyUUQe6PD5ChHZISL3pn+usj57tYisEpFHReTDU3ni40FA4OQkG7sFRAThCAAz6klxFauGFBv3+mvJ47Vm1CzlJI+0zYZlD29GiGNTsHMPWVxozLM9ya1xkORQXYUXUiXZalaMY3uYSHW6RfE8snPRimUeHh4HBcaqvSLyPhH5dVqzbxeRE63P/ke63SoRedW+PfPx4fiFM7n0jMXZ+5OOmAXkqRe7RxOSOL1hEU/NSWUWARfnSnIgrpJctFuYiak2eTYKbntMs0Xnxr1MSQ6CjuuD8SQLzbjppltYdotm3EzsFhVPCD08PCaO8SjJ1wGvHmOdn6rq0vTPxwFEJAQ+B7wGOBG4zC7E+wKZ3UJNekVSjFpxi/6+xPlr2y0Mit/gjVrQiltJTrJVu0ZaFUqyPUxELCU5MBFEYceJexFCNA61NrNbULZbmH1HanmSO9gtqshvpJGzXzMMBdKx1F6V8PA4YDHO2vs1VT1FVZcCfw18Ot32RODNwEkkdf/z6f4OSBw1bxoAS5fMBnKSbJTkGSlJrgWCampPsCLgmu04U0hM/e7mSa4HdWf5vP55gJm4N367RRVJ7hQ5Z9AM8uEidk5yGOQk2cDxJPt0Cw+PSWNMkqyqtwFbJ7Hvs4BHVfVxVW0C1wOXTGI/k4bJSc4n7uUkua+ekGRjtxDrv8XoHdOo0YpaaVpFjqGMJKtT+Ox0C+MPs71nJU+ySSAWyTzPtS6FLXDU4gSmcS9TknUMJdnybNsFuZhuYTc/+lLr4XHAY8zaq6o7rbfTyf9pXwJcr6qjqvoE8Gi6vwMSfWnjnCGufUZJbrpKcqMWEMd5uoVRkoeaESKmb6XgSZayJ9n8AZhWm5Y9ZUyGiXTHWHaLsdItmunnxm5hK8lz++c629l2C59t7+ExeUzVMJFzROQ+4GngA6r6ILAIWGetsx44u9MOROQ9wHsAFi5cyMqVKyd0Art27Spt0261Wf/UehpBI/kinZLkVY+uwhSNdauTU7Sp74YNG5x9rR5ZDcBwcxgpNO5t2p7ca2KN2b59OwD3338/60bWEUcxmzZvYnhkGIDHHn2MlRtXopGydt1aVu7Oj7F9R7LtUKuZKcl11a5jqSONWbV6VbZsOIoZ3LWboRnJNvf9+j4WbXmC44B169fz2MqVLHx2FSek6//853fxUGo7EWuU3rMbn0W35b+PR1Y9wrMjzybXCdx2223EYR6DNBWo+vvrFfTytUFvX99Bem3jqr0icgXwx0AfYGYoLwLuLGy7iArsac2GPf/9vjh6MYMzB6mvqbPyyZU8+nRCDlc/sRaAeHQIgEAjduwchpmwY9t2fnrbT9L1nky+IgAP/vohgici1o0mv7pVD64ieDwnqtu3bidqRmzasAmAAQb49X2/BpLGvVaz5VxL8dp2Rbuy1zt37Mw+25neQ37zyG/40bofZyr3oyOPOtc6KsLKlSvZNbyLzRs2c/tPbwdgw9MbWLUrvw9s2rjJadxT4J577mHHE81x/EbHj4P038a40MvXBr19fVN9bVNBkn8FHKWqu0TkQuBG4PiJ7kRVvwh8EWDZsmW6YsWKCW2/cuVKits0vtHg8CMOZ1ptGsFgnpO85OglDDyzlhZw1tKz+Icf/ENyDul2Rxx+BCvOzfc1b9M8rr7lamKJCQtKcthIK6wI8+bMg2fg5FNOZvczu6k9WmPB/AWseXYNjMIJLziBFS9YQeP6BocvOpwVZ+fH+PzNn4etUO/rz4wOtS5f/oN0wt/zjnse3JWeS73BzBmHUO8LYRhOPOlEjmucD49dy5Lfeh9Ljj4X7nsWHknWP3v5cvra2+E7UK/VabeTwnrooYdy5KwjIan/HP/849n89GZYCwi87GUvg/rAGH8jE0PV31+voJevDXr7+nr52lT1c8DnROQtwEeAyye4/R7VbJia3+9reW32etf9T8P99zD70IWw9ikOnz+Hx3dsYca0fgYGkqeGCw89jPPPP5/g+99m7vzDIOHRnHrKUs476mxijTnksUM4LHwxS5fMpVFL7hvf+vG32LZ1G4uPWAy/gcNnHc6LTn8RfC95AtjfaDjXUry27SPb4RvJ6zmz52Sffe37X2P1M6s5/Ojjed/XR7jxinM58YhDmLVxFnwnv85W3zRWrFhB8I2AIxcdyflnnw//DEctOYrXLH0NH/3aR5PrW7AQ1uTbKXD60qVw9Ll79Hsuopf/bfTytUFvX99UX9sep1uo6k5V3ZW+vgWoi8ihwFPAEmvVxemyfYai3QICAkm6g2u1UQJt5AHy1n+7eZKLOcmZJ9nKSTYwj9fMoy/be1YaS20sEpbdot7lEVlARQScmbiHNXHvsFPgozvyAtnBbmF3VkfqpltgHcfHCXl4HPCYaO29HvjtSW57QCHzJI8m9XV6Xzolrx4SxXnjHkAYCEOtvA4bu0UgAS89/DW8+Yt38f/ueyb7fN7APOZPm59tP6d/juszHisn2bo/2NYK07A3OBzRjGLWbt2dnk+hce+c/5r8rBgmMlDLRYvifcgb5Tw8Jo89Jskicpik/ypF5Kx0n1uAXwDHi8gxItJH0gxy054eb4Lnlg/2SJfVgxrtuI2Eo4g2SoQYysXJ+M4UJUCcdAvjSc6Gh1COgCumW1R5krMBICIZCe/mSRbK6RbttPvZmbhX2rA63cKONaryJDs5yR4eHgcyxqy9ImI/7XstsDp9fRPwZhFpiMgxJE8F79oH5zwlMJ7koVaECAz0JXWtUQuIojxXGCAQYbhpk+S8Bu4ebaMK24fz0U5/suxP+NwrPpcR3Dn9cxyyO5HGPWecdipQxHHy+Wi73CcC0OxPpuq14zb1oI6IMKsxi9mN2c7+SiQ5mZTV9dw8PDyqMabdQkS+DqwADhWR9cBfAHUAVf174FLgD0SkDQwDb9aEYbVF5ErgeyQBldemXuV9hkxJVqMkQy2o04ybBOEotPsrC1unnGQwCm6+zZCdbmEPEyE7ZOYPy4tzOVXCNOApYMp2vZvdAkXVJcJxNpY6KeyVMUB2AbXOw+7YLirJdrqFL7UeHgc2VLWy9orIx4G7VfUm4EoR+S2gBWwjtVqk6/0r8BCJ1fYK1YMnT8yOgKuHQUaaG7WAkdhNragFkgwdycp7XvejdKz1iKU0G7XWDBOZ0ygoyWOkEnVs3MvIsDjHLN6HNg5t5JbHb8ka9wD+7aJ/KyVbFO9pXkn28Jg8xiTJqnrZGJ9fA1zT4bNbgFsmd2p7joCcBJrCUQ/qtKIWKiNo1Mi+ddtlpRtJFoTIKjgjlpJsR8CppukWVgRcFv4utY7pFpGQ2y26pVukH7l2CwFrUEnVoJBJpVugefrGmGmgHh4e+xtVtVdVr7Jev7/Ltp8APrH3zm7vwQwT2T3api8M6KsFhIEQBkK7ndS+emByiYXhVpyRZNG8NrZTkjzaKn8/aMWJCDG7f/aUKMnmKZ4WlOTifeiG1Tfw1Ye/ml5DQpIPn3F41+OAr9keHnuCnp64JxUT5fqCPlpxQpLjOLdbbNC52cS9TmOpIVELbE9yK3tjeZI1t1846kHQ2W6Re34tu0XFt3/bQ22sJAbtNAIuy1yuVJKr7RbdlORYY0fp9qqEh4fHgYh6NpY6oh4mY6prKUlupbFBtSw2Thh2xlfnhNcoyaPtsmVtZzNJo6jpTP7gq7/Klk/Wk2xex+n9Z7RVTZKH28P5dYZ1ijh/yfksGFhQWq7g7RYeHpPEVEXAHZAwY6ljja0pSnVacYtYRojaMzISG3d4FAYuSe5TnIl4dumx7RaZkmzt13jPwiB08o0hD39PGvfS9SvqmiHYpnHPbgCMRBwLxZieZGvdbkqyvS8/ltrDw+NAReZJbiZ2i0uWLuLwWf388OGNtCOjJFuNe01bSMhroBl3bdstvrDyMVZvGKQ9fzD5bLTB+m2DTE/dDmOSZPseg23TSO8bqZJtjln0FtswSrKNq19+NQB//p9/7iz3woaHx+TR00qy8f6ORqNMrw/wJxc8n0YtIcltHSFu9xFXORIKxcluautXGHZIcj6BTpzlWlKkuw0TydItSKbuQbXdwii+kq1fkW4xXiVZqhv3orjgSVbbbuHh4eFxYCL3JEfUw4ClS2bznpc9L7FbRLnlDsqNe8RlJdmeqHrvum3c/eQ2BpsJSW6E00GrLRRV6Ni4l9b0TEnu0LjnXGcFSc72Xbjv+EQiD4/Jo6dJspDYLUaiEabV+/lvrzg+8yS3dRiNG9mjrcTAUG23sDEADDuT9XKSXBxLLSKO2dmerDSedIuqCLh8dGquWGf7CFy7xf/P3ptHWXKeZZ6/L5a75VKZlVWVVapFpdJmSZYsW2XZIC8p5B2w1LSN8QDdpulxN2s32znM0AcYbJaGPkD3HJjB3fjQDQ2mYcaNp9tgvChtSzJ4lW1ZRktprVLtW253i4hv/vjii/gibtzcVGVlpt7fOXJm3lhuRJbru0898bzvW3arzYFDuluUnGTXhdbozLGWpVYQhI2KzSS3+zG1wJ1qp+i3dxAvHWBf61C6r8dCN49buN0tbCa5E+XrdD/WdKM4F8lqBAru8POMWyRWJK/sJP/+vU/x9NnFFd/HQ6Hl6Z8grJstLZIzJznqZm3cwjRu0dNL6KRBN0plny4eN4ymhrZTxhyrmPqu/wnk4tod4+wK7kKf5CGZZM3KcQswhXuaoltcjlus7CR7mUPsZpLLMY1iCzglroQgCBsSVxhbwQxGJPd6TZae/lF2NHcDMN4MS5ljRyRXxC16UUIvSnjtvtcCMBbuzCISQDYpbxjuZ0FByGZxC9vdIs0kL/PxfOJin0dOzK/4PrkYlzVbENbDlhfJGuMk21xx6IUs9heJdQRJnW5/uFvr8muv+TU+9J0fookiUgrbPbPdPEVt6v7CcW5UoaqKubIFnBW2SmVxi6o+yTbXbK+w4CSn77VsJtl1O5brblHq1mHFtGSSBUHYqNhMMuTRCwBfqcwd9lOTY7JVjCyoyhZw+RraixO6UcKP3/rjfOZdn6HhjeOup2vpbuF+bw2KOOtuEafXPDxugQ6y+ylT7MHsSeGeIDwPtnThnkpFYDfu5iLZDznXPgeATur0rJM85F/5lu+++rsB+FL6r/22pwgTTeR3B47LB5hUZ5KXc5ITcOIWg1ihbc9ccJLTR2tWpK/KSR7S3SLRSaHPdLG7hSAIwsYjHCKSPefpnx0zPTlSKxyrk8G4RTcadJJ9z2eyMUkUHy9kkp9v4Z5Nx1l3e9mMs/aHi+SSk5yscF2CIAxnazvJVMctznfPA0YkdwqP21R23DAa6VebS45dkewsRlUt4DKR7A2Opc67R7hxi+Eut2cL90p9kmPn2qv7JJcazaf7VHW3cLt1yDARQRA2OqETt6iVnGRLIzSvl51ktCuSbdwiX1/7cUKU6Mxl7if5kCpYRdzCjVh4g8NEbJ9kG/FYzknW2s8iIWWKg0rsJ4Ws3IKwHra2SFZeVrjnxi0udi+aHQYK9/LjhtG0ubF0wYv9zuBxmsoWcG7hXjkKYUVoQh6bqBLJWYeMdJMdVAKmcM9tHL+a7hZ2n6o+yYXhKIWlVhZcQRA2Hm4OOQyKmWRLI0yd5FbRSY6dZS2KByfu9VJDxX6N4qQgrFfDS6deCsCZ9pn82tI1PS51t1jRSY5XXoczoS1LtiCsiy0tkpVSJJi4RcPPneTMFY0bBacg626xzOLUSn9ltnjPdZIHulukE/csy7WAc/sQ2yuqjFuoYtyi4CRPXUO8/5UD5yywyj7J4MRHtC6IeEEQhI1I6Di0+yZa2ffeakSyE1+oGibSS51bG8GIYo1OGtn2leIWAL/6GjPI0I64htw8SWwmecgwkQLap1/Vvah0XM0L0vieqGRBWA9bOpPsKxNr6EQd6kGeSbbocuFe9q3iwWcvcOv+iYFz2qXN9kpOHCe50N0CTXnNdOMW3ahb2JYV7sGycQvr+NplsJBJvukekoNvgT/984Ft+UUOaQHnDbaAyx4DOq3mZMSpIAgbFVcM33jFePa9YzDTrNlMctGGcDO+/WTQSe6XnOR+koAO8QhIiFaMWwAcmjjEX939V2yrb3OuzYpk87NtO1cu7nOfGqK9oU6y+/Sy6ddFHgvC82BLO8nNoEk7ahcL99wm7EndcZLznsZPn2lzz+/dz7PnlgbPiS3cG8wkF+IJVVGJZeIW7lhqG7eoGiaSt4AbLM6zBXflcxYYMkxk2biF4ySbBs2y7AqCsLEpiGTHYW4ENpNcdpKTge+rnWQbtzDrYM0zjvVK3S0shyYOMdWccq4tjVvYPskVTrJ1nrPpr14/mwpYxn162bIiWdZsQVgXW1okt8IWi/3FgbiFRSfluIV9xGa+Xmz3KdOwItk3C2wSOE5yyUkYyCSX4hYnFk9waumUOY/b3SLdv6pPctZGLv25ELdI4gHRbImSyAj3UtzCRkMqC/fcFnDO9QmCIGx0XrJ7LPveqeHLneSSSHad5OUyyVYkW5EaYkTyapzkMp997DSfeeQsMDhMxF2TrUi+bvI684KKV9XdYiRoFgZeCYKwNra0SB4JR1jsLxbjFo5IbnhN5jtuJCHtGJG14hmMKzTTX9lSYM5TGbewLeCUqhw/ap3kf3Pfv+HX//7XzXkqMslBxcKWCe305ziJs97JJxZPcLZ9NtvXnnOht8BrPvQaHnjugYG4hRXS7oJc5STnw0QEQRA2PmONfK0vFO4FK2eSIyduYZ8KWic5K9xL9wlVKpLXEUX71D+c4mtH59PzFYeJFBzhwLzH++54Hzc13kW88JKh3S3c4xp+TZxkQXgebGmR3ApaXOheQKNzJznNJCsUU6OjXFhycl4lkVx0mQ1WJHd8I0wLItkpdKvqbuGK5EhHzPXmshGn2VhqFMkq4hZun2R7T3/40B9y91/dne1rz3m+e57F/iLHFo4NxC3sB0Bh4l4y3EmWpVYQhM2GdXlrgZfllgcyyfGgSE60GUcN+de8cC+NqqkRYIVuFEPoRQlxnBaBp56MdardVqTWSd4zsocD/ncDXnY9ZexnTt2v42XNQgVBWA9bunBvJBxhob8AMJBJboUtdow0ubC0ZH4LWoGyC2PxsZdLlkn2Q7oKtJdHMtxFrWqYiHV8fc8nSRIiL6Kf9Av5ZY0p3gMIK1a3bOKek0l2Ba6LHQBiCz4SnaxqmEhCOnFvaJ9kWXYFQdiY/Pl7X830eKPwmnWSm2H+xGy0HhA4DnOhu4Xj0naiGN9T2fayk+yn5dzrcZK7UYJO19nyxD03kzxaGyX0QppBMzNvohW6WzSDJp5SsmYLwvNgS4vkVpi3AHKHiYAR0DtGazw914fx4nF2rexWOcnKtoDzueAVe2S6E/fsz1VxC5tJTpKESEfFHPFKcYuKTHKhGNHh7KJxufuJEfKxjkvDRKrjFlkm2Ra76OKwE0EQhI3Kqw5NDbxmnWQ7SATM+jw5UkOd/lec654hesmgkwwmcuEOJikX7vk2k7ztwJqvtRcl6LhFzaujk6Bwflckv/sl7+b7X/L9KKVo9/MWdFVYc6YRNEwbVCm2FoR1s6XjFiPBSPZ92UkeDUeZGqlzftEtzkvd2ayAYlAkzy/FBFobkewXf32FiXtaD7zmiuREJ8RJTJREheI7jcrGUlcV7g3ELZJ4qEj+7w8epd2LS06yI3KduIXbAi7LJKf/90hIJG4hCMKmJahwksFM3RtT1xDN30ysq0Vyt58Uu1y4LeAAXxsnWY3tXvN19aKE6OKtfPANf45O6tlrSaILxsWV41dy15V3AXkx4dC4RbrGN4Om8/kjK7cgrIctLZJdJ7ncJ3kkHGHHWI2LaSbZhCPKmeTBuMVSL6aZaNq+x/nMaU3HWTuFblVYMRuogFibThRlkRyjSShmkj2tUaXx0W6f5KFxC53Q7seZk1wVt6h0ktNMspuxFpEsCMJmxcYtGiWR/O1X7+DwlduBYsTCjV50ozgTxpAX8FknV6UiubIv/QqYc/lsr+8pxCd6cVJ8CqnyNd5+Lg2LW2ROst9wPtUEQVgPW1okj4S5k2wL92peLds2NVKnwizGrpVVTnKMoqkTOsrjYiqSA22GjpTHOA9kkktxi37SJ05KvY3JM8k2buGR/0HlY6ltfjopCNwCKiGKk8xJNnGL6mEirhttnWSzhxos3JNHd4IgbCK8ISL5l99+E7/wXTcA1S3gwBRwuz2Jy4V7njZmzGJ/ceB9Hz05zxt++9OcX+xVXpc9VzeKC85wt58U4hbuk772WpxkpYzpImu2IKyLF41IroxbjNYojMVTNm5hfqwq3EvwaGpNWyl66WLkU6xuthP3hraASwv34iQeyCQnCqe7RXpZOCK5lIOOdbzM+FJNP9HLOMl5JtkVyYlOshZwKo1kyFhqQRA2K35FJtlioxjFFnBO4V6/5CRncYt0f20MmCqR/NCxizx+aoGj59uV12XP1eknhZZunai4rrtGSFa4N6wFHMW4hRTuCcL62dIi2faWBKdwz3e6W4zWyUVy3nB9uRZwWmPiFp4iShfeIKtudrpblFrAecrLp+Upj0hH5r9S3CJBZUI0fPOvmf21zpzjctwi0clwkawS+pHjJCfxgEi228oT9xKdFK5f4haCIGxWhjnJkEcxooo+yVDlJJdEamzW/yqRvNg162svro5iuANKyk4y5E8n3fW53bNxi5Wd5OEGiiAIq2FL/w0qZJIrnOSiSM5ZzkmOUTSTg6xpAAAgAElEQVS0pq0gSg/1VSqSy3ELlYtMN1Nmh4nEiYlcDGaSDUHTZOXcuEUmtO3+yzjJioTznQv04yonWWXHQ6kFnE5A5905CnEL6W4hCMImwzrJ9aDKSbYt2JwWcKVMclXhXhbJSIY7yQtdG6eodn27mUiOKyMddm13nWS7behYasdJBuluIQjPhy0tkqsyyW4LuKnRWlZ0Zyh1t6hwkmNtMsltIKLoJBcKN3Sxs4V1sMEseLZob9BJNm3g3Gt1RbIVs2kyhDgZLpL9kSP80Ke+k+cWn8uvz+6rvOz4QAWFWIjNJFsnOdHl7hay4AqCsHmwjYhCf3CttK2SXWfWFaDDnGQbt9Cpk2x78rtYJ3lYfth1ksvuNeRPJwuZ5N7yLeDs54FtASdrtiCsnxeNSC6PpR4JR5hs1Uptg4uZ5E6Fk6xJ4xboLG5hx5J2467ZJ80kQ/7oy3VqbQs4m0cui+Ssu4UVydr8B27cIi/cGyaSvfAisY45uXgy2zcXyfYRY4Tv+YWoCBihbJ3wwWEigiAImwc/dYtrFSJZKUXgKWInhxyX+iS7meRy3CKOl3OS07jFSk5ymkm2gj1/ipnWvaTrvtY675O8QneLul/Ph4mIkywI62JLi2Q3k5zFLfw8buF7iommed04yqXCvaFOshXJ5rUwjVtkIrlCSpbjFrZHcpSUC/dU5iRnrjE686Sr4hblLhpllqKlbN/8XwWpSNYRgRcMCO04MedVSoHO29pJ4Z4gCJuN5Zxks10NzySXO09Exe4SOjafIQu94U7yMJFs28nZ7haj9eJAEauVAy8gTjSn5rvZsKth7rT9OGgEtgWcROQEYb1saZHsNlO3cQsrPG1euVjIUe5uMUQkJwltkixuEXolJ7kqk+w4yb7nZx0noiQq9FVOdC6xs5Zx5M6xdRTcYSK+8nn/He/n1p23Vv4erMNRdJK9wvGqlDW24lucZEEQNjt24l6tIpMMpsNF7IjOKE6ywSOdflIovMvHUlsn2bQVvX3P7QPnXeytvnAvShLGGmH6nna9zZ3k37v3cV71a5/Mr3GIk2xrUOp+XbpbCMLzZEuPpVZK0QpbLPYXB+IWo+EoAPXAZz47ohS3cIaJ/O4nHuXmvdvYrqGhNR3iQSc5cuIWutgnuSCS00wyMOAkx5jiQBgcQV14zWaStZm4d/c1d/PExSd48PSDA7+Hpb7rJBfjFnYYSdmNjnSUFe4VJgIq6bkpCMLmwi5Zw0RylZM8Ug9o9+N0mEi+zQpbG8mIYvjoP/ooU82p9L3yfRfTwr3hcYu8sC+KNSN1P/vZnEyBMuv+546cLRw7zEnuxB0gLdxTKn1IKmu2IKyHLe0kgxlN7Ss/E8eHth3ilh23cMOUaSBfD6x4zUWifcTlOsl//Lmn+euHThCjCLQi0pq+UqAVNc+41NZJBvLCN5tbdvoQu9EGO3kvO06ZXsk+KssJr5RJrso9uyxGjpNMKW6RRPjKr45bpE544foq30EQBGHjYmMNy8Utyt0trGA1TnJF4V5sv2r2j+/Pnk7+kw9+ntf+5r2A2wJuhcK9fkw/SRjJ4hZ2zc27W1w51SocO6xPsjVr6n4dL/ukkJVbENbDlnaSwcQq3KrjqeYU//U7/2v2cz1w4hbLDBPpRQndKCHWCl9DP41bePiEyrjU9l/wQDbWuTJuUZqQ14vzaUwxmphSX2XyJc6+lsUtdJydb5hIbvfb6X0NdreIktjI8bJI1nkm2fZSBskkC4Kw+bBidLiT7A1M3As8RT3w6DqFe54abAHnilWtNZ997Ez608iyhXtRnGT54m6U0I/yTLLtbqG1MWI85bFrrF48fkifZPs5VPfr6cQ9QRDWy5Z3klthKxskUkXuJIOVonbxc4eJdOOEbj8m0eBrs/D0lEIpnyAddW3Frtaa893zjNfGK13e8tS8XpKL5ASTQ/NR2X4K8DEC2Ypu34lbVLnVLtWZZHPMk2fmODnXL7goYBxm+36F1naCIAibDOv61vzqIrbAUySliXuB59EIfTr9vIfxaD3IC/fS/fvOcY+ezA0ZrXWeSa4QyWV3OkqSvHDPZpJ1Pm/VFcWBp4bHLaI8bpHF6CRuIQjrYsuL5JFwJOtsUUU9K9xz4halwj2tNb0ood2PibXKog9tzzjJNc+c3y3cO9M+w87WzsphImXX1hZaQN4n2XWhPexoai8TxG7hXjaVSVU7ycXuFsVhIkv9HjrxKHe7y7pboIwD7VyfIAjCZqK/irhFVIpbBL6iEXombpF+Fow1QsdJLsYuAO57/Ez2fS9ZPpNcbCtnuluMlLpbaK3Q2ht4n7FGMDxuEedxi7xPsiAI62FFkayU+qBS6pRS6qEh279fKfU1pdTXlVIPKKVe5mx7Kn39QaXUFy/lha+WkXBkeSfZWTTtchKnPdisY2D/xb/QjUjwsoxKWxmRPBrsAuDmHTcDRiSfXjrNzubO7NyrjVsk6cQ9H1UYQe1hCjjyCEZ6rc7EvbJDbakUyU53C4030CYo0pH9pQxkpgVB2Ngopd6ilHpEKfW4UurnK7b/tFLq4XTt/qRS6kpnW5yu2Q8qpT7yrb3yy4N1XYeJ5MAv9kmOEhu38NMWcK6TXI5b5DL0c0dykbzU13ncoqK7hVvzYvsku3EL854KtEeS6IJz7Cm1ctwisHELKbYWhPWyGif5j4C3LLP9SeD1WuubgfcBHyhtv1NrfavW+vD6LvH58Z6b3sNPvvwnh24vxC3STLJdfGyfZPsv/oWOWfD8VClakTwZXkH8zM/xY7f+GGC6SSxFS+xo7shOvZxIdgv+bHcLT3l4Xp5JNv95A32SE51kBX7ueyidv4ftblGMW5gvkY5Be+ljvRxbuOcpr5RJFpUsCBsZpZQP/B7wVuBG4N1KqRtLu30FOKy1vgX4S+A3nW3tdM2+VWv99m/JRV9muitmktVAJtn3jJPc7SfZ8aONIPs86CeDTvLR8+3s+4tdne9bEY0oDyjpJ5p66BH6im4Um+5KWoE2Qt2NZ+zf3ho6ltoW7jX8tE+yLNmCsG5WFMla688A55bZ/oDW+nz6498B+y7RtV0Sbpu+jTdc+Yah2xtO4V42njTrblF8VGad5Ewkex6e8k3RR3dn5uSeaRs3YWdr5+oyyY6TrKnoboHR724muWosdUEkk7+H7clcNUwk1hFof6D4OUoiE++oyiSLKyEIG5nbgce11k9orXvAh4C73R201vdqrZfSHzfcun2pyTPJy/RJTjRRnPDZx04XM8krOMmuWD2/1GPfpGkJeq4z2DbOxXWSe5FxkkPPox74dNN4n3lm6NHuxfSjhCu2NfjG//Fmrpsezd7/X33oK/zR/U/m57Vxi6DuTFKVNVsQ1sOl7m7xw8BfOz9r4G+VUhr4A6112WXOUEq9F3gvwPT0NLOzs2t644WFhTUfA3D29BKMghGNZiGx/2Jf7PSYnZ3lXMf8fGGxQ6IUnuMkJzEce/YZojjhgfsfAOBzj5lkynOPPsfR9lEA5s7PZdd3ZP5I4RoefMj0Nvbx6fR6ZjR1HPPlL30ZMIJYAUmScOzoMSD/10272+b8+fPMzs5yZCE/r9Y+ZdP3+Inj3Hf/A7wG6Ecx98/OstReBDyeePIpAAICIiLmF+eJvIgoijh56mR+XuD++++nXxtf/S95Faz3z28zsJXvDbb2/W3Se9sLPOv8fBR41TL7l9ftRhqPi4Df0Fr/96qDnu+aDd+63+/CWSMcjz35CLOLRwa2t5fanDjV5kc+8HE+/nREzYOrJzxiDSeW4PH+BXwFCxfPcX4xYXZ2loUl4xonGj51770o4Ox8l+u3exwFnrvYwS7CTz1zlNnZ04X3fGYuNx+eee44iYajzz6N0hFPPP0sn/7sCWzcYvaz93P0uR5RP+ELn7uPUye7LHUiZmdn+cQ3Fjl58iQH+08DcG7OeFpf+9LXOHX+FAnwzYcf5uS52Uv5K92sfzdWxVa+N9ja93ep7+2SiWSl1J2YxfY1zsuv0VofU0rtAj6ulPqH1JkeIBXQHwA4fPiwnpmZWdP7z87OstZjAD4z/xBfOgdoRTqBmTixLqvHzMwMT59dhNlZOjHoQJl8MKZwrxbWObTvIMkTj3HHt98B/w3OJsaguevVdzH/+Dw8DLt27squ79Qjp4x3k3L19VfDGagFNXwCEqWoBSGveuWr4CPptCgNgR9wYP8BeDjPJAdhwM6pnczMzDB/ZB7uM+f0VEA5Bbdj5w5e8+rXwf0Q1mrMzMwQHvsD6HpceeVV8A1zDVEUUWvU2NbYxvzCPJNTk5B6Tglwxx13wMjUmn/Xy7HeP7/NwFa+N9ja97eV7w1AKfUDwGHg9c7LV6br9iHgU0qpr2utB5Tl812z4Vv3+331HTEfefA53nl438B0UYCJr9/H5FidLzxjHor2EtgxtR2A+U7Enr2T1I8+wxW7pzl37CIzMzP4938COkZ83/Ha1xHFmuhjH+Pl1+7jG2efYSEJMf/OgKldu5mZeVnhPb/yzHl4wBgrrfHtcOI01159iM+ffpqpXTu49bZDcNSUbL/sttv51LlHOR3PMzPzeu69+BBfOfMcr33d61n62EeZnNrJzMxtAKhnFb/8uV/me+76Hp747IPoJ+CGG27ghpfNXNLf6Vb+u7GV7w229v1d6nu7JN0tlFK3AP8JuFtrnY0F0lofS7+eAj6MeQy4oWiETuGezTCgCH1FL06IkzxXprXJ5HqpiD7KBJ4KCdKcRtbzMk2f7Gzm3S3c9mzDCvcCLyDR1X2SvdJrdpmPdJS9VmgBpweL+AqZ5CxuEaOdTHLoh9nrypnKl5124KyCIGwwjgH7nZ/3pa8VUEq9AfgF4O1a66wwwlm3nwBmgZdfzov9VtAIfb73lfsrBTKYTHI/TriwlHcaygr30j7Joe9lfZOh2B85ijXnFs06fnBqBIAzbSduUZEfdiMYtsAv8BSN0MQtOv0kLahOryFOssLDwPeI4oS5dh+ti+d6/f7Xc+/33muGiSgZSy0Iz4fnLZKVUgeA/xf4Qa31o87rI0qpMfs98CagskPGC0mxT3KKVow1jFi0Q0SyTSi8tCXPoufjqwDft2LS7NPRFwi9kG31bXkmebkWcGlmOPTCQneLTCRr8ul96Rpvl3qt9ZBM8uAfbVV3i0THgJ+L5FRoF1rADXS3kAVXEDYwXwCuVUpdpZSqAd8HFLpUKKVeDvwBRiCfcl6fVMpMR1JK7QDuAB7+ll35C0TgKb55fK74mu/RCD16kZm4Vws8aoGXCd4o1lmJhyuw929v4aliJrm/TJ9k31PZZL7AN+/R6cd0IltU7WW9mm2f58BX9BPNhbZ5z27F+YG0BZx0txCE9bKaFnB/BnwOuF4pdVQp9cNKqX+plPqX6S6/CEwBv19q9TYN3KeU+irweeB/aq3/5jLcw/OiEeaOq+skjzXy8aBlkezb4jnVxVdB5iTbgRyaPjuaO4ZP3POqu1sEXmDyyMoI4qwFnFK5k+yMqoZiC7jCxD09KP6Nk2xVtnW/7UJsXrYiOdJR1t3C7ZNcbhUnCMLGQmsdAT8OfAz4JvDftNbfUEr9ilLKdqv4LUw1xl+UWr3dAHwxXbfvxWSSt7xI9j3FmYVe4TXr6honWVPLnORUJCeaZvr50Y8155bM8VMjNcabIWc7tu2c6Vbx23/7CM9dyLtf5L2Xg8xJrvmKeuYkx9hMcjsVydZJDj3jJJ9P37OqMBBwuluISBaE9bBiJllr/e4Vtv9z4J9XvP4E8LLBIzYW9cBGDVzxl4tkt5E8QI+AxApQr2+c5LRVWy/KFyK3/RsUBWzZSbYiOfTCbCy1XxocYv5TA3GLYd0tqv79M9RJ1iFJ2UnW1U6yDBMRhI2P1vqjwEdLr/2i831lyx+t9QPAzZf36jYeQcUkPtsCruM4ySO1gMVeRJJooiRhvBGy1IuJkoQLqWCdaNXY1gx5+qxxeSdbNZ46u8S9j5xm+0iN99xxFZC7v+ONkPlOP70Oj0Ya6TATX83Kb7pbaCduoUg0nE8jHt0h7eCQYSKC8LzY8hP3VsJM3FMUompa5eNBS/0pfyd6Bx/sfxdgnGff8zMnudPPxeR4Pe3+kJ7XFbDlyXh24l7mJGPcY3eYiBXIVjjbwr1hfZKHO8nFTHJCOkyk7CQnURbvKDrJgiAIWwsva9WZfxCEvkcjzST3o4TQV0yN1ow4XerRj3X2JLIf6Uywbh+pMdHM60O2j9SyvPJiL19LXSfZTuYLPOMkd6yTrL3MSe7FCWHa59mK5TML3cK5Bu7LflJI3EIQ1oWI5MAOfVag7EKjGE8zyd2o6CQ/oa/g8eRA9rNxkq1IzvezYrMqblF2krPCPRWYTLJS+IXBIaoglKEYt7DCuVAQWFG4V3SSy3GLUuGek0nOpu+BLLiCIGw5rDi2PY7BOMn10MuK5mqBx9RoHYBT80acNmupSE4Szi31UQq2NUPGU5F8aMcIO8fqXEyzw/OdfC11RbI1YtziwCxugYl4FDLJ6fWenrcieXCiH9hMMoi9IQjr40Uvkhuhb9q/4QYu8sK9Tj/Ohork5AI08PJMcrs3XCQv290iKXa3SCDLA0Pe3cLNOGeFe+jsfO576JW6W9i4BTFoP+vMYV1um0lWSpE441plepMgCFsNG5nbva2RDZUKPEUjMGvjYjci9D2mRmoAnJwzo59tJjmKNReWeow3Qvx0MAnA227ekxoxhoVu3j3DRiTsZw2YGEUj9OlFCZ3IxC10RSY5yJzkNJM8JG6RiWQxNgRhXbzoRbJdwMy6mC4k2i3cSwYfZTkCNHCc5CUnblHMB6/OSTbdLUgzyargJCttJvBlcYvb/0V2fNVUv0onORmcuKd1OtXJxi0qnGTJJAuCsJWxRsfUaD0Tvn5auAfGAa75HlOj1SK5HyecW+yxPRXRj55cAIxIdkdh21gFkLWSG3dFsmec5E4/Ntu1W7jnZJKtk7xC3EJlwTxBENaDiOTAZJKNeLTLicd4VrgXDyxArksbeE7cwsmbZU7yKsZSF7tbmLiFp7zMITYP3FJ32Xa3mDqUHV9VuKf14B9totP7UF5mRWsS0F5WuFfzaunrOnOzi3ELsZIFQdha2DaeUyM1mjWzjoZpCzgwGeRmzWdqxMQtTlwsxS3SFnATLbPu/7t33sLr9wXcsGesMAq7ELeI87iFJfSViVukmeSkP4HuTxR6NUNeaJjHLRK+8dxFZh/JuvnRjxOeOrtIUvhsEwRhLVzqsdSbjnropXELhc7SWyrLlHX6yeCjrIJIDjORXBW30KlFWxDJywwTybpbpFEHMEUlWpWHiaiB8xUKAofFLSAVyV56r8VhIoHv9lq2re3KhXuy4AqCsIVIl7TtIzWaNbM2+mkRHZgM8quu2s5kKoJPzpfiFokZJrJ7WwOAmet3wfE6SqmSkzyYSR4viGSvMEykd/xdBH4et6gFNr43WLj3+7NHePCZC9z/898BwC98+Ovc9/Q59BQStxCEdSJOclq4p9xQss4L96qcZFeAhl5AkC5YnYq4hY0quHnhYXGLOPHQ2kh1D8/pbqFQ7kCR0jmq3OpkWOEepALZBkwSwMsyye51Vg4TGTirIAjC5mYubcE2NVKjFZp11EzcM+tsnGgmWjUC32OyFXLyYiqSHSf5/FKPyVZt4Ny1QibZiOQvP3OeLzx1LutmYQlSJ7nTj2n3YxphjWZYo9OLiRI94CSfSZ3kbpSw1I04OdchSTTHLrT5b188ilu9IgjC2hEnOY1bGNc0HyYy3jS/mnY/HpxmNMRJXqqIW0RJOklJLeMkp4V7X3pqjtFRTayUGSDiZJKhWLjniuTKFnDJSnELK5Krh4nY91BKZfcAUrgnCMLWw3afmBqt00iFry2is2xLny5OjdY5MVcUyd1+wqn5Lru31QfOXfPzc1gn+Xt+/wEARmp+5kaD7W7hEyWapV5EI/Sp+R6dfpK2oSsW7s2l8Q2zvxHSZxd7fPXZC9k5RR4LwvoRJzlwfwWOSC50tyhnkp3HY253i2gwbpGJ5FUU7sWJR5x5u16hu4XNB2evuSK5IpOcJCs4yU7cAu1jEyWuSEaZfz5k4pq0cE8e3QmCsIWwInn7SI1WVrjnFUSyzRtvH6lxci7NJKfbj1/sECea3dualHGd5HknbgGmb/Jrrs0HTwXpABN7Tc3Qp1nzsz7J1kEOvUG3wt7DybkO/XRB1yhZswXhefCiF8mmBZztGuE6yWZBbPdWiFv4QVb00e4Nj1ssNw3PimS0j9aaWJlMcla4pxSeZm0iOS3cU8615mLXzZYYSa5LE/fMXibe4WaSBUEQthqZkzxSy9xh0wIuX2etSN4xWsuywFYkP3t+CYA9442Bc9ecaX7WSXY17nXTY9n3SuURj4vtPvXQdLvIMsklJ9m9rrn0Hk5c7OSfWVqhpXBPENbNi14k1wMPnYUY8hZw29zCvWUzyeGyfZKrRHKSFF0A290C7ROTZ5ILw0TSqMVdB+7ip277KUbCkex4u1+hT3Ji88y5sxHrmP/w5f/AJ5r1vBWcStDayST7g5lkt7tFIt0tBEHYYlxYyuMWzSFxi4mmyRvbDheQxy2eOWdEsi3cc3Gd5KVeTJxo9k4WHecP/OBt1AKP/ZPNLKN8YalPIzBO8lIvItEMZJIBDmxvAXn04uR8h36cF6FDXkAuCMLaEJEcDnaLADNpqebbcaBlJ9XLwrmhH1R2t7CiuCpuUW7PZjPJaNPTMqaUSR6dph9OopRi39g+/tlL/1nheu1+v/7RRwfeQ+l80Y6TmA8//mHubdac8dRpC7j00t3stM0kS+GeIAgvBiaaYeYOB+nEPcs2J25hsSL6aCqS96wgkgEWe1FmvPzAq8301jfdtJtH3/9Wk4l24haN0IzGnmubzxErkm13C4D9k0Yk26LAkxfzuEWSfsTrqLeWX4MgCCkvepFsHl+ZPsmaPI5Q930adiRplFCOgKl06l7NC7PuFu1e7riWM8n/5yefyCqoyx3lbNxCaz/tk5wLVIVCTV1Nr3VFoeDPdrSAXCR/7ehcftLU7S6IZB0TJRG9tJWHmcBnfOvyWGpzj2l3CyduYUxwkcqCIGwd/p8f+XZ+9k3X4XmKVs3JJAeuk2zWxism8jU1j1u0qfleQUBb3D7JAAsdI5J/8NVX8v57bh7Yv56+pxHJxkm2nx2hHUvtOMn7UyfZcsLJJPdIW5H25hAEYe286LtbBL6HKvnIO0YajDYCUzDRM4V7Y42Qi+0+oa/SR1kBEK3oJFsX9ukzHZ4+s8TN+7YRl+IW/diOKk17bqLwnS4WvvK5c+xODt54MDvGvWIrmHv9/DVbXKiSZjZFO9FJLpLdrhXaz4aJVBXuuU6yIAjCVuO2Kye57cpJIBe+YTlukbZ3u3nvRPaa7YJ0brHHge2tgnlhqQX5BL840Sx0I7pRUioaz7Gvz3dMd4tG6GV5Y+tKhxVxC8vJuS4Hd5g4nm0FqrvzK/8SBEEY4EXvJBtMgZrNbf3IzDX4nqIZ+nQi4yTbqUh2AbUFcTXfySRHFYV7mQvrZY/DEtueTRuB3k262c8AkaJQoOcpj0ONQ3zHge9wrzj73jrMvYKWTd8jyfNzsY7pJ326SoHyMnGutUechpJrfs05gzdQuCdjqQVB2Mo0a7mobThxCzv047rp0ey1XWMNbrpiHKjOI0MubHeNmbV4oWuc5HIMw+IK80boMVILssLCfCx1fuzOsWLbuZNzHfpRXoQOoLsLw25XEIRlEJGMmW+vAM8zC8vM9bsAs1jZ7haj9VQkpwuoHU1d990+yY6TrIqZZLSXVTZnhXvaJ/ACp7tFekyaSQYjgIs+d3bRzrfWSdag0/1tQ+MkX7hzJ9kc1YlsPCTPJBe6W6RT/4pjqQVBELYubibZCtaxRpB1lHA7SwS+4u5brwAY7KefYl3f6bTzxVy7T5ToLFZRxnWYG6HPWCN0CqsHC/fKYtuNW+QiWZxkQVgPIpKxDdEGndlGmPentE3d64Fv8snaPpILswXLHSai0nNYgam1z2KvKJI1XkEk22K7vsrjFsop4BuG3W7GZ/vpz2nBRlIs3It1nMYtoGdjHtrLrqlq4p7bJ1mjpOemIAhbFjeTbPPEts2a5eBUHnH4rluMSLaZ5TJW9O5ORfK5RbPeD3OSXfG8b7KVPcWEXHCHjlB3M89jjYCFTiQiWRAuESKSAZVOoLNi0ObKmqGfDROpB6ZfZegrAt9znOQAXw2KZI/hcYtsenXqJGeZ3/ScfSdu4Su/MudWJeq7fTM9z1NeFt1I4vxRnO2i0VOKT/kRf/YPf5q9b1Um2Z3wZxF5LAjCVqbhZJI9T1ELvKz9m+X7bjddKVo1nysmmvzJD7+K33rnLZXns2J4etysxSuJZDficfXOkYJIzvoke9VO8kQrJEo03VKxedKXuIUgrIcXfeEeuEOpjQS0ArVZ8zk13yfwPMYaAfXQI/Q9Ak+RJGYYdC2oVRbuKYqFe4W4hba9K71CyzUrkiOlslHTtnCv6pqz723hXpzQ0D6e0lgHwYrkht+gG5nscxf4sN/jc4/8cXoGjyR1h6uGibgkg3pdEARhy9CqmTXZruuNwBtwkv/F6w7x5pt2c1VaIOdOzStjx1LbaXxnU5E8vHAvX+8P7Ril08/Nl6wFXPp1shUWzrOtGfIsbRa6pugv0uIkC8LzQZxkwFMK3ymEsALVtIBLHCfZpxYYkew6yXkLOCduYTtVOJnkha7ZHscqe833BkVy38kku1P2XMot4JJE0481Wvt4+Fl0I4nMI756UM+iHz2lmIsSunHHvK32sK2gCy3gxEkWBOFFRrNWdGsboZ8Nl7IopTKBvBIDTvLCCnELx0m+aucIY438vcP0GBunuHJqpHAee50LnYhm6GfDRJDCPUFYF+IkAztGG+xstvjaWfOzFaC2cE+Hmloat6j5HoHvEaVFdq2w5gU4oFQAACAASURBVGSSI+yyWRbJGj9zkrO4mC66xJq8u4XvdLewQvWzj53mvsfP8L+99YaBYSK99KQ6HbEdzd1CrV5jsT9CCNQ9J3ahoOPKXSdu4Q49qSoY1M7/CoIgbDWaoVkDrfnxozNXc/Wu0eUOWRbbO3nfZIta4HFuaXkn2e3NPFoPsqJxyDPJV+0Y4efefD3vvG1fIeZnRfJizzjJtjuy7olIFoT1IE4ypo9lIyxOmoM8k9yLE2q+Ry0wcQvfdZKDWvYoLnG0o7KdKvRgd4vIOsn4+IW4hfm+78QtfOVn1/M3D53gj+5/ypy/5CR3+6ny1j4KDx1NMN6/izi215mL5C7QLehfj4Bt+Mpnz8ie/B4qigZ1hXAWBEHYKuzf3qQWeOzbbuIR77njKl577c51n++aXaN84qdfxysPTtKq+VxMR2APjVuExderMslKKX7szmvYNd4oTgW0TnI3Ss+fxu56i+u+fkF4MSNOMnkXB4srktv9mMBX1AOfnWN1xpsh4VmVFcYFXkAzNDGMXuRmko04zQr3dF64Z3fT2iuJZOskq6wY8B3XvYMbtt8AT5A1oU+SopPr4dFN8xJae6hUYNcDjySxsZCik9xVrpPsUdc7eeDdDxQGh5R/LyAesiAIW5t9ky0eed9bKgum18s1u8YAaIU+5zMnuboFXHlCX7G7xaCwdvcft05yN6IWeHjpgCkdLUEcgS8f+YKwFsRJhgG31ArDZs3PxlLXAo/ffdet/Oo9L8X3Veb6Bl6AUortrVrpHKVMshu3iPI+yZ6NW2jTiK58TT96649y54E7ATOBCaDdjwdEfe4ke6ZbB2mVtq4QyZSc5HSYSCtsDYy+lsI9QRBebFxKgezSrPlcKE3PK+N5ip/4jmv48I9+O0Axk1wlkisyyYvdmND3sieSGqAnxXuCsFZEJJOKYmdN9ByRmWjj4NYCj6nROhOtGqHnZeLTZngnR2qls6ZOsrYOr89iWrjXzwxnD8/OjEZlxXZmy+AivZCK5KVePBC36GVBZz8bJNIIPeLuFbzxwJu5ZWfenihW0HGcZI1HPyl29rC/l0onWfokC4IgrJmResCFFTLJAD/zput5+QEzJrsQtwiqxl47LeDSVnUL3YjQz00OjZLiPUFYByKSGXQNXJEM0I91YSFyM8m2hdtkqUUQSVV3i9RJdvokZ04yeX7MvQaXuY5xIDolJ1kpVcgk2/M0Qx+SBr/4ql9jqjFVONeie3rtEacj91wn2VMeZa0u8lgQBGF9NEOffmxW0WFOctUxth3dSnGLbU7cIvS9rEuSBpA2cIKwZkQkM9jqzB0mYnErjgN/ZSdZl5xktJdN3MuHiXjZ0BF0nnOGvLuFixXZS72iSPaVX+xuwaDI971i/q0Qm9A+UTzoJEOxw4WHEpEsCIKwTuw0P1i9SFZKZR0uqkSyUioTylYkR4kxduz6beIW4iQLwloRkYwJPRTFoB0mkv969qeVzpD2z7RjqdPhG+VMcllEw2B3CyNoV+8kW5Hc7scD8ZBuP5/aZztQWJEcJckKo609Iidusau5K70+XTjOVx5JOnZFEARBWBt2UAkML9yrYjmRDEZwewpG6vk5Q9/DS9vYJQDducpjBUEYjohkBgVpFrdwJx/tzPtkFuIW3pC4Rbr99+/6ffbo70ZH45nI7cU6zR/7uUhO6gUnuZxJ1lpnhXtLvWjA+c4yydrPzpM5yZGunNqX3Y/yM5GslOJnDv8MAA+dfajwPgGD8QtBEARhdTTX4SRDnksud75wz9UM/YLwDn2Vf44oJJMsCOtARHKKm0vOhonUXJGcT1cKfbVy3CLdfnDbQXZGbwcUnX5CFCdmWlIar+glZlR0vHATOsnPURbuvQTiVMi2S4V7vvLzTDIeWhfjIv0kyYr5qqgHQZZJBnjrVW/lPTe9h596xU8V9vOVIikfLAiCIKyKEeczZbnCvTLjaYeLsKJwD4x4btb8gvAOfc8p3EMyyYKwDkQkM9xJdjPJ441qp9iK5O0DIjk/Zz/K4wmLvTjtp+yB9nhy4SGzz8VbwRHJNpN8ZqFLuxfT7ufnKLeAm6xPOplkp3AvjYv0oiTPQVdQ90P6sWa+0+fw+z/BA0fO8jOHf4Y7D9xZEuOeBC0EQRDWSbPmdqpY/cfvaGPluEUj9AvCu+Z72eeIRkkmWRDWwar+liqlPqiUOqWUemjIdqWU+g9KqceVUl9TSr3C2fZPlVKPpf/900t14ZcSd/QzOH2Sw+qIQjdK0E6fZICJUibZDvEAnPZspurYOMkeWvvsbb4EgP7SAbR2nWSF1prD7/8E/+t/+SLtKD93uXBvz+geulHaaq4/Sai3AzBaN8K+04+XF8lhSJxojp5vc2ahy5HT+WJaLBD0pAWcIGwClFJvUUo9kq7JP1+x/aeVUg+n6/UnlVJXOts2/Jq9WWmt00m2cYvAG+IkZ3GLkpOc/pgAdCSTLAhrZbV/S/8IeMsy298KXJv+917g/wJQSm0Hfgl4FXA78EtKqcn1Xuzl4nuv/17uufae7OcsbpGK5IlS3thEG4ot4AYL9xwnuSSSjZOsAI937X8fH//Hs4BCJ/nADw+Px04ZsXrf42dox7kw7fSLcYs9I3uyaX/dk9/JtfpfA7n70O7H9ByRXabhh0Rxkk2CyqMbxRhKgDjJgrDRUUr5wO9h1uUbgXcrpW4s7fYV4LDW+hbgL4HfTI/dFGv2ZqXQ3WKIK1zFWCOg5sQnytR84yQX4haByorQ8UPoy2hqQVgrq/pbqrX+DHBumV3uBv6LNvwdMKGU2gO8Gfi41vqc1vo88HGWF9svCPdccw9vOZhfll1Y7D/ab9k3Udi/E8WFsdQAkyNFIV1wkqOERmj2X+hG9OLEtGnTPjquMxKMpwcVM8kPPH4GgH2TTdIhTYBxkl3Ga+N0ozyTvNQ1UnYsrYju9GP6y4jkehASJZoLS3kf5vLvAiBQXtY5QxCEDcvtwONa6ye01j3gQ5g1OkNrfa/Wein98e+Afen3m2LN3qzYwr3lBG8VL9s3wcsPTAzdXl245/RJDhrQ76zzqgXhxculGuS+F3jW+flo+tqw1zc0NpN8za5R3nfPS3n7LVcUtrd7MdSKcYvJkpPsmMf044TJVo3jFzssdk0mWWG6UPTiJGsur0uZ5AeOnAVM+5921Mu2lUWyUipzks32KDsOoNNP6MXDPeBmELLY07mT7Jyr3GpOxlILwoanat191TL7/zDw18scu+HX7M3CSPq5sZaoBcA7D+/nnYf3D93+g6++ksBXBSe55ojkJGxCf2nY4YIgDOFSieTnjVLqvZioBtPT08zOzq7p+IWFhTUfM4xPf/rT2ff7ga98/snC9sVOlzjZyx7/Kr74wBfxlY/WmjcfDHgg3ecb3/wHdi4cAWB+sU0rNIvV33/5QY6fjGCsjk6aPPLYET7dftoc5IjkUydOct+jJwE4cX6BC2M2ogGPHnmK8fgZwDi9s7OzfPNILqJPnzfZs8e+aSLkX/naQzylnxt6v53FBS4u+HzpoUcAePzJp5idPQ7AhfMXANBa0e/10cDn/u5zdBtHVvw9roVL+ee30djK9wZb+/628r0BKKV+ADgMvH4dxz6vNRu29u+36t6OnLQTWKNLet92nupnP/MYnoJEw3NHn6XfM08H25Hm5LGn+eYlfM8X25/dVmIr39+lvrdLJZKPYfSkZV/62jFgpvT6bNUJtNYfAD4AcPjwYT0zM1O121BmZ2dZ6zED/GfzZaXzRJ/4a+LFa/n3d/0zbtgznr1+551w83/+WQCuvuZaZr7tIADe/Z9g/65Rnp0/y8FrXsJDS8+xd+kneeRMxN4br+TwK/fD7L1A/qhsauduliLzGK0dQ+LXgR6Bp9ixew8vf/kU/I0p2puZmeHL/UfhsccAUGEDaPPaVx/m337hPq68+joW5o7B8er72bNzF4uRx+T0NDz2JDt372Vm5qUA/Onf/ml6nIfyAjTwba9+NUwcWNOvdiUuyZ/fBmUr3xts7fvbpPc2bD0uoJR6A/ALwOu11l3n2JnSsbNVb/J812zYtL/fVVF1b/5jp+Ern2es2bhs913/5N/Q7sdcfeggX3/8qywB9dFJpifHmb6E7/li+7PbSmzl+7vU93apWsB9BPgnaZeLVwMXtdbHgY8Bb1JKTabFH29KX9vU2DiCjTNU0Y81H3/4JL/w4a9ncQuAxV5EP9a0vGlq3ijdKC4U9qm0n7EtnnvJ7jG6UcJcz8QlpkZrtHsJ/cQ4BNOtacDknkNfZe/hXl+nH9PtD89JNMKAKHHjFnmcI8vNaUU/TqRwTxA2Pl8ArlVKXaWUqgHfh1mjM5RSLwf+AHi71vqUs2lLrtkbBVu4t5b2b2ulnta/hL6X1ZTooA799mV7T0HYqqzKSVZK/RnGXdihlDqKqX4OAbTW/zfwUeBtwOPAEvBD6bZzSqn3YRZtgF/RWi9XALipWE4kR0nCXz90nP/x1eOEvso6ZCyk3S1qvkc98NMexrn09AmI6NNJRfL102N87ehFTi8lNEOfsUZIux9xasl8rk2PGJHcjWIagY+nEpa6RuRm3S2y3sxFdNxA+R1qXo0oXnIK96q6WyiiWMswEUHY4GitI6XUj2PErQ98UGv9DaXUrwBf1Fp/BPgtYBT4i/Tv+DNa67dv9TX7haYZ2kzy6kdSrxXbNcPNJOuwISJZENbBqkSy1vrdK2zXwI8N2fZB4INrv7SNz8gKTvLJuQ69OCFKYKwR4inTAq4bJ0zUQmqBLdwz0lMp8LQPqk8ndY6v3z0GwJm2ZrQR0gx9zsz3eOwZU+n8zuveCRgnuRaYsdF2fHUj9Ak8RSeK6fTKVwg+IyR0CHwzlvrcYoWTbCv3tEcUa7RS0idZEDY4WuuPYswL97VfdL5/wzLHbtk1+4VmpH75nWR77tBXeJ51khuwdPGyvacgbFU2TOHeZmS5hS6KNScumpY7iTb7jtQDFrsx/Sgh9D1qvke3n2TDRlqhb0Qy0OlpPAXXThuRfLqdsGM8oFnz+fyT5/j8U/DX/+p+bthtMtHdKKEemLZC8xiRHHiKRujT7iV0+oPCdldrOye6Zwm9gChJuJDGLQpOciqSdTyKoitxC0EQhHViW8CttbvFWrDnDgMPL12/E78mTrIgrAMRyevg9/6XV/A33zix7D5RknByrpv9XA88xupB1ie5HnjUQ49unNBPoxCteoCXTvJb6sXsGK2zY9Rkmed68IqpVuE95tp9tNa89Jc+xmIv5uBUC6Wc6IYVyf18rLXWCl95xIliojnKiS6EXkAca86ncYtuFPOr//NhbtgznsUtkv42CE6JSBYEQVgnrbQF3OV1ko0QD30P3zb7DxrSAk4Q1oGI5HXwnbfs4Ttv2bPsPheW+ix08wkeoa9SJ9mMpQ59Rc33CpnkkZpPJx1C0u5pdm9rFMZdXz89xjPn8oVurmME92LaN7ke+Hhe7gL7StGseXT6MZ1eAjVAe/heSKyh4TfSa/PpRrmj3ekn/MfPmrZ33/XG1EnuT0BwWjLJgiAI66QZfuviFmZgSRq3COvLDxOZew7Grxi+XRBepFy+v6mbkJ+//ee5cao8vXV9HLtQfLQV+iZukRXuBV4ahci7W7RqASp1ktvdmOnxBhPNfJLfddNj2eM6gPlOvxCNqAVeVrThKfA8RTN9j3YWt/DxCNFJSDNo4imPwPczgQzFYSJLaZ/NpD+B0qROsvjJgiAIa8X3lHmK+K2IW/gefmHi3pC4xdkj8Ns3wrOfv2zXJAibFRHJDt9/w/fz59/155fkXEfPFx9thb7HaMFJ9pger2fFfWCKOlTqJC/2EvZsa9Cq+Vlrt+umxwpV0fOdqFBkZyIcZnuQiuVm6KeFe6mw1T6KEHSNZtAgUAGhl7eHU2lxoeXpiyZWoqMJkJHUgiAIz4uRepBFIi4H9YrCvcSvQTREJM89B2iYH9JIXxBexIhIvkwcPV9ckGq+x0jdZ7Eb002d5L0TLY5daGft2Vq1gDidujffD5geb6CUYluzhsKMyZ5r97Nzznf6WT9li10gg1T4Wrd6qWf209oH7aOTgFbYxPd8fC//v8HO0XrW5QLgXNe0mkv6pptGokQoC4IgrJcD21vsm2xetvPbp4lu4Z4OGpBEEPcHD+gtmq9Rd3CbILzIkUzyZWKpFxd+DgOVxS36semTvHOszlIv5vS8WZxG6wHzS2P4wJN6D3u2mczwRCvET3o0az4n5/Jc2VzJST4132X/drP4XjFhvjZCnwtLPdpdTQ1Ae2gdgPa5bfp2PL9P4AwauWrHCH//ZN4WNWIBgCDZjtLKBC2kBZwgCMK6+NB7X52ZGJcDO0yk5nvGSU6AoG429tvgh8UD+lYkL5NZFoQXKeIkX0Z8ZyHM4ha9PJNs3YSnz5pFqlXzSZL83y17U6H77VdPcdu0ed1zzlnOJJ+42OH+x88C8JN3XQuYuMWFdp9sN+2TxAE6CXnjgTfyq6/51cKCfWjnSOW9NLztAFK4JwiC8DxohH4Wh7scZE6yk0lOrDCuyiWLkywIQxGRfBm5akcuOG3h3sV2n0SbXNreCdPS7cmzJr88UjfiFUB5ffamIvpX7n4p33u9iWH8zrtu5Ze++0YO7RgZcJJ7ccJP3nUtV+8c4btuNt03mjXfONU6/aPWPnT3k3T2Z1XQVsybyYB5Nw23AnskaOWDRQRBEIQNSWGYiHKGiUB1LrmX1s+IkywIA4hIvoy8/rqdhXY8o/UgSyoc2N7iigmzcD11JneS0UYke17E7vHGwDn3TjT5oTuuYqwRMN+JCk4ywE+/8To++TMzmePcCP00+pFm07TP0vF76J56W3Zt1kneNdag4RSUTI3UaCzNQOdKWul0wUR0siAIwoalVtXdwk/Nj0on2UTqRCQLwiCSSb6M3PWSXXz4K8c4F/WMk+y0bzuwvcX2kRqN0Mt6H7tO8lhTL/tIbqwRmsK91En+oTsO8o9evndgP9uX0zrJCp9OP8H3VOYg2/eZHq9neTaA7SM1zl24h7jdp7XLp4OSFnCCIAgbGNsBqRZ4zlhqJ5Ncxg4ZkbiFIAwgTvJl5PDB7YymDqwdJmI5MNVCKZXljsE6yWafsRWKn8ebAXPtPJP8rlfu55Z9EwP7NTLRa/snpwuoI8Ctkzw93ij075wardPpx/SixIhtDVoiF4IgCBuWopNsRfJqMsnrdJJPPwJP3b++YwVhgyMi+TKww7+Jf/TyvdQCLxPGYeBlgnmiFTLeMIvW3sl81LQbtxgdTFoUGKuHhT7J9SF9NzMnORW3vhoci2onA06PN2iExbhFux8TJZpWzUchHrIgCMJGJi/cU3hZ3CL9QLkchXuf/k34yI+v71hB2OBI3OIS8+Uf+DKe8vA9IzZH67lzawXzge25ML7z+p185tHTZp/Ao3fu21C1M3zb9f942fcpZ5IbYfW/d+yEvslWgx5QTx0FVySfuGgchLKTvH2klp2/VQugo6S7hSAIwgbGbQFnI3U6SDPJlYV7z9NJ7i1A5+L6jhWEDY44yZeY0A8zgQxkwth1lfc7Ivndtx/Ivt852gBdp3v8HRzavnPZ9xlrhLT7cTYdrzHESbbO8K7Umm6FZrF04xZWSF+9cyTb31MURmK30n2kT7IgCMLGxT49rAc+ysYtvGUK92wmub9Okdxfgu78+o4VhA2OOMmXmSxu4edxC9dJboQ+f/CDt/G5I2e545op3vu6Q3zgM09w3e6xZc871jDnOr1gHpHVhznJ6YK5Y7TFUWC0Zgo4Ov28ddyP3XkN1+wa5Y03TvOpfzAT9kZqQSaewYhkpVXWSU4QBEHYeNx9614mWzW2tUKCLJO8XHeL5+kk99sQ90xcwxYICsIWQUTyZWa0lhfujTVq+J7iuunRwj5vvmk3b75pNwD/+9tu4Me/45osszyM8dTltdP6hmWSrTM8Pd6EORitm0XsrDN6uhH63H3r3sJ5WnWfupNPbqb3IR6yIAjCxmX7SI170k5HA3GLy5FJtg50d15EsrDlEJF8mRlNHd+a77FjtM7H/vVruWrH6LLHrCSQIXeSzyz0CH1VmO7n0qyl7d3GjEgeayy/iNls80g9oOHkk03hnpLuFoIgCJsEG7fIJu5djkyyjWt052Bkx/rOIQgbFHl4fplx4xYA1+waGypo10IWt5jvDs0jQ+4k7x43PeXG68u3zbBO8mg9KHS6sJlkKdwTBEHYHATeGjLJ63aS03MOyyUvnoHuwvrOLQgvMCKSLzPT43XqgVfI914KrNt8er4zNI8McPXOUa7aMcIt+7YDeXeLYVgnuVXzC50uWrUAxEUWBEHYNGQt4NAQNC/PxL3MSR4ihP/4HvjEL6/v3ILwAiNxi8vMO27bx7dfvaPgyl4KJlpG7J5d7HHFtuGTR6bHG9z7szNc7JoWPaEX8r67b8oyxmWWdZK1jKUWBEHYLPipkxwlMYTDRPIKTnK/DSe/AfsOD98Ow53kueNw9vE1XLUgbBzESb7M1AOfq3aMXPLzbksL97Qe3tnCxU8n7QVewA9+20Hecdu+yv3qbia5ULhnM8mCIAjCZsBO3Iu1hrCVu76WOII4FcfDnOQH/xT+8E3QvjC4LUny44eJ5P4SLJxax9ULwguPiORNymg9yLLNy2WSLV66WAbe8g8P7LlataAwoCTPJCvpkywIgrAJ8NLPiCTRMLoL5p4r7tBfzL8f5iQvngYdQ/v84Da3ELA7N7g9SVKRfHKNVy4IGwMRyZsUpVTmJq/KSU4HnARqeZFszzVa9ysK9yRrIQiCsFmwTnI/iWH7VXD+qeIOtrOFFw53kjup+K1yit34RtV2K6KXzkLcX/2FC8IGQUTyJsZOxLuUTnI98JgaqbFvslUo3GuEPkpLdwtBEITNgs0kJ4mGyYNw8VkTsbDYPHJr+3AnOa1nqRbJTnyjars9P9p0uRCETYYU7m1ixtfiJCuTKa75tWX3U0px78/N0Ar9wsCReuChlM0kS9xCEARho+On3S1inYrkJIK5o+Z7yDtbtKbSWIUGVXpiuKyT7LjP5e29xWKcY+EkjO9Z970IwguBOMmbGNvhYrVO8m+89je455p7Vtx3vBES+F7hvKHvoVDS3UIQBGGT4LndLawwdiMX1glubgedGBFdxmaNqzLHrpPcc1rAdebg310HX/+L/DUp3hM2ISKSNzFrySQDvO3Q27hi9IpVn989by3wBgwGQRAEYeMSuIV7k1eZF88/ZTpVnPxGnkluTZqvVbnkznIieUjh3uJpI5pPfD1/rap4T2v4yp/A4tnV3ZAgfIsRkbyJWUsmeT24meSa7+GhTHcLQRAEYcOTt4BLYPwKU6B37km4/3fhg2/Nhe3ITvO1KpfcrYhbPDFL2LvgOMmquN1+P38if61KJH/jw/BXPwb3/87ab04QvgWISN7ErNVJXitKqUwoh4GX90mWFnCCIAgbHlu4FycaPB8mDhgn+fzTpiDvwjNmx/G95utyTvL5p+EP3wxnj8CfvIN9R/+/3Eke2VEUyTZ6MX88f60qbvH5/5heaH19NygIlxkp3NvEbGuZIrxLPc3PpRH6dKOEmu8W7gmCIAgbHVu4FyVpX6LJK+HC02ZENcDpR83XsbSgrspJ7qTdLZ66D84+Bg//FSR9wv5cLqpHp5d3kpU36CSfPQLPPGC+t6K6fd5cW9hYx90KwqVHnORNTOYkB5fvj9EOFKmlhXta0haCIAibAi/tj5/oVCRv2w8Xj8J8OlTkzCPQ2Ab1UfNz2UmOuvlEvfNPmq/HHwQgiBbyuMXorpJITkVvnHZI2rZv0Em+eDT/vn0ePvIT8G8Pwoffu447FYTLw6rUlVLqLUqpR5RSjyulfr5i++8opR5M/3tUKXXB2RY72z5yKS/+xU6WSb7MTnLgKTxP4clYakHYFKxizX6dUurLSqlIKfWO0jZZs7cItnAvTtKVe2K/Kaq7eMz8fOYx0/4tSJ3bskjuOMV4tvPFc0Ykh/2FPG4xOl3ct1dqB7ftALTPlc6dOtTKN4WED6f/V7MREEHYAKwYt1BK+cDvAW8EjgJfUEp9RGv9sN1Ha/1Tzv4/AbzcOUVba33rpbtkwbKtdfmd5HrgUUvPrxTEgPRJFoSNy2rWbOAZ4D3Az1acQtbsLYIdIhUnZuVm2wHzNUmn33XnYOdLIEgzweW4RVVHiwtPAyUnefvVpify0jkzmKTcM3liv3GtXaxInjxoohid1FvTMrJK2DisRl3dDjyutX5Ca90DPgTcvcz+7wb+7FJcnLA8E1nh3uV1kkM/Fcl4aOluIQgbnRXXbK31U1rrryFDNLc0gZ24px0nuYzrJD/2t7BwOt9mhWzFum9Ecuo8T99ovp5LIxldp2cyyhQGLp2DxPm/myuSzz6ev94fMh5bEF4AVlO4txd41vn5KPCqqh2VUlcCVwGfcl5uKKW+CETAb2it//uQY98LvBdgenqa2dnZVVxazsLCwpqP2UxU3V830uwbVXSPP87s7JOX5X07i21INLOzs+g4Rgfw+c9/nqWR4ysfvAa28p/fVr432Nr3t0nvbdVr9hC+JWs2bNrf76rYCPf2xEnzf4PHjhxhdm6WeucU31ba5/hcj2NffYjDAPf9Dqce+QIP3/RzAEyc/yq3At3aJPVeMS4R9Od55olH2OvV+NKRs9wOPHz//+DU9DxXP/FNrByPvTpPHL/AtTrmvk9+lCg0+eeDT36VK1EcXwq4Ii3ci/wG/YUL/P0L/HvbCH92l5OtfH+X+t4udXeL7wP+UmsdO69dqbU+ppQ6BHxKKfV1rfWR8oFa6w8AHwA4fPiwnpmZWdMbz87OstZjNhPD7u/Nb7i87/uHR/6exdOLzMzM8LuP/DY9BbfffjvsvP6Svs9W/vPbyvcGW/v+tvK9LcO3ZM2Grf373Qj3duLBL8BX4cqDB5l55QzEEfz9vwQdY9xhvqlrDwAAIABJREFUzZ6rX8qel90BXzLH7Dr7d+x6xXWmr/LDc/BVqO88BMeKIjmM2xyYnoQzo9z+pu+FL/wkN07XuXFmBi7+hfmnGeA3x7j2llfB4/+J17ziBpi62mxY+iic3MYVV98Exz8GQDB1iGDp3Av+e9sIf3aXk618f5f63lYTtzgGuM9o9qWvVfF9lKIWWutj6dcngFmKeWVhg9MI/SyT7Cllns1Kn2RB2MisZc0eQNbsrUOgTBQvtjlfPzDiF/Ix1a2pPJMMkMTwpf9svreZ5G1pH2UvLL7B/AkIW6Zl27Z9cO6J9DgnbhE2TU4ZYPFM/nrnoums0ZzMX9u2v7pXsyC8QKxGJH8BuFYpdZVSqoYRwgMVz0qplwCTwOec1yaVUvX0+x3AHcDD5WOFjctdL9nF227eDZAPExEEYSOzqjW7ClmztxZ+ubsFGCFa35bnk1tTRugC7L4F9r4Cnr7fdJk4kiYnx/eZrzZ77Jse/cw9Z0QwwParHJHsFO6FI+Y94P9n777j5CrrxY9/nnOm153tvSS76SGVhCSUAAlVmoKgXNuVq3jlKmK7NlTUa0Ev4hVUQJAfXUQ6AgFZSgjpIWFTN21btvfpM+f8/nhmZ3ezm2QDATbxeec1r5k5bc6ZnZz5zvd8n+eR3ci11MjHke6RQXJGyeh9NSvKh+SIQbJpmgngOuAFYBvwV9M0a4QQNwkhLh6y6FXAw6Y5LM04FVgnhHgbeAVZ36ZOuMeRqxaU8s1zpwAyk6yCZEUZ38ZyzhZCnCyEaACuAP4khEhFLuqcfSLR0w33hjSYKzlZBsIDgasrG7z5cNkd8JmnZKDcvBme+Rq885hcZiD7XJDq9CSrijv9Pl6OtgwJkifIAUJgcHAQAJtr8LVe+K4ctc80h2SSM+Q8qxucmTKTrK5WKuPEmGqSTdN8DnjuoGk3HvT8R6Os9yYw8z3snzKOyEyy6t1CUca7I52zTdNciyzDOHg9dc4+gQxmkocEyctvkvfPpnr/GwhgZ10p7wtOgvX3wO5X5POsqsFsb9Fc2HAv5E3jwe5u5kYinD0QJGdVyr6Qu+tkuYVulwORWIcEyaEOeR/plkFy5oTBbXtyUmUfJiTjYLEd2zdDUd4FNeKeMmZC6DKTrGrGFEVRxj1LasS9YeUWA9KZ5Mzh0/NnyXszCVf8Bb68ZjCTXHYqXPUQLPwSQU3Qr2mD25l2CWgWWHW7LLfwpYa6trlloGwZMtR0sF0Gyc6MwSDZnTtkUJPweztwRTlGVJCsjFlSs8lhqdN9ZyqKoijj1UAm2RhtgI78GbK8wVswfHruVEgNQkLZEtA0mLAUrlsH2ZUw5QIMfxFhTZNBcukpctmMUph5hcw099TJvpFBlmMIMRhMgxyiOtIDjiFBsif30IOaKMqHRAXJypgZmk1mkiPdR1pUURRF+ZANDCaSMEYJkqdeBN/eK2uGh7K5IHuSvHly5TQhILsqvUg4Fcz2axqUnza47rzPDY7Clw6S3fJ+aMa674CsW3b4ZaAM4M4ZrG9WVyuVceJY95OsnMAMzSYHTAqrIFlRFGW8S4+4d7RNri+4eTCbPIqgKYe17tcEFMwanFE4ZDTzgRKNgSB8aCZ5YIQ9h18GxrnTZL1zutxCZZKV8UEFycqYGZpDZZIVRVGOE+lyi9Fqkg+n4vTDzg7GgwD0aRqk6p4BWS6RVSmDYG8BCB3sXjkvo1Q2AuzcDe075TSHX2ap/zPVc+y2p+W9yiQr44QKkpUxMzUrBkLVJCuKohwH9FQAO2pN8nsQSsiSirCmkTASWLQhoUTuVBkkW+xw5f2ytwyAc34K8TD88VRo3yWnDZRaDFCZZGWcUTXJypjpmoYphCq3UBRFOQ5YUiUTydFqkt+D0EDdMYNZ5bSiefI+0gNTLpAj8YHMGnvzZS8WA/0pO/wH7fBAwz2VSVbGB5VJVsZMIzUstSq3UBRFGfd0faB3C1lu8fL+l9nZvZOLJ15MkafoXW93aGDcF+vDbx8S7C78kuwnef6/j76yJwdaU2PXePOHzxvIJMdVkKyMDyqTrIyZrmmy3EJlkhVFUcY9j9WNaVhY2/kMLcEWbtlwC7dvup1Ln7iUJ2ufHHUd0zSPWJ4xNJPcH+8fPtPqgLN/AA7fqOu+43DyldxsQlkT5VDWQ6XLLVSQrIwPKkhWxkyIgUyyqklWFEUZ73I9fsINn6I9Ws8D2x+gK9LF6cWnMzNnJje+eSP1ffUj1vnM85/htxt+e9jtBhPDM8mHsvrAatrD7cOmPZHs5BW3iz8XVoxcQQXJyjijgmRlzHShYQKmKrdQFEUZ97wOK2XOudjIYWfnTnpjvczJncMvTvsFutC5t+ZeABq75Qh3pmmyvXM7qw+sPux2h2WSY/2HXOaLK77In7f8efg+pXraeChcPzLAVoOJKOOMCpKVMdM1DVOVWyiKohw3ZpVkEAtnsLF1IwD57nxyXblcPPFiHt/1OKv2NnDGH27m4TV7CCVChBNhartqSRiJQ25zaE3yiHKLlK0dW0maSXZ27Rw2va94rrxPhtnasXX4SiqTrIwzKkhWxkwTWmpY6m4wj7LfTUVRFOUDN7skg0g4I91tW4FbDkN9ZsmZxIwYt224B2fho/zqjb9R19MMQMyIsb93/yG3OTSTfKhyi5oO2ThvZ9dOzCHfF73CTHcZN6LcQ2WSlXFGBcnKmOlCYALCSAwOPaooiqKMW7NKMjDig0NCO4Uc+a7IPQGAd3pfAqDfrOMvb21OL7e59aAs7xDBRBCnJoeQPlQmeSBI7o520xZuS0/f29GOEc3Hqlmp66sbvpLKJCvjjAqSlTHThIY5MLypKrlQFEUZ96YWeHGY2QCYpuC6+3Zz45Pv8O1H6jCTDpJaJwD5OR38ffP29Hp/WvXGsO2Ypkn1jlYSSYNgPIhbc2PX7aPWJPdG4ryydwN+mwzOh5Zc1HV3Eos6yHEUUN97qEyyCpKV8UEFycqYDQxxCqi+khVFUY4DdovOHz9xDgBeayY5HhcPr6lnQ103Pr0svZxhbcRikwGvQ2TRYD7Pf7z4H7QEWwgnwvx+zd/43P0vcOfrewnHwziEA4/VQ198ZLnF955aSYQWvPGFgAyS93Tv4eW9q+iP92EaTvzWgpHlFkLIbLIKkpVxQg0mooyZJjQYiJNVJllRFOW4MCtfllZMyCjigasX0dQdpqU3wvMHNvPg9h3ku/NpDjZz/twk/2yw8NnKG/ndW4+x0bKWjz/zccp95Wxo3YB7osYfVl3H7Fn92DU7uk0fkUl+clMjLzY8gi1TsGfvDEqmb2Rl/SZe3PM69X11oEUwkw7sZg47+jZjmiZCDEnAWOyqJlkZN1QmWRkzXZMfFxNUX8mKoijHCY/NQ4Y9g3y3HOGuMMPJnNIAkzMnA3Bp5aUAbGxfTbYzi49OX0S09QKuLPw1GfYMNrRuoFy7HIEgan+b7a1tWIV9RCZ5d1s/3378TeyZqzmt4FyikSy8TGbNgTW80/E2vfF2dEsYm+bCiGcRToS59qFqapqGfJ+oTLIyjqhMsjJmeurXvgHoqtxCURTluHHT4pso8BQMm3Ze+Xn0x/q5pPIS7tpyF+3hdqZnTafA76Qow8nW/Q5+du5dbGzewZ9WxPDnb8FV1EhjT5BdIT9zvH6a+5tY17CP53etIdw9GRz7MEWcL8y5mt76KG/V5uAsDKYvQpoY+O0+QsEAaPDSrq3ku3N4tfvrVPmncafKJCvjiAqSlTHTNR1IZZIPVW7RXgubHoCzb5T1ZYqiKMqH7szSM0dMc1ldfHr6pwE4tehUquuryXTIxnbLp+Xxlzf38cqOwZ4pzp4yl7XdD2N3Wkn0VLBxtwWRUcd/PvdTwvbVJPumMal0EvsSgkmBSfz4EoPzf79nxOtmOf00NWVBvkD37ODJtytJlKyn40AXhm5HU5lkZZxQ5RbKmGU4rQAYiEM33Kt5HN74Xwh1fIB7piiKorwXF1RcAJDulu17F07lzk/P58cXT+e0Ktk7xtLSxZiYxI0Y83NcJCI5JIw4Qf0dAHTvVnr1tyjzleGyupiY4+Gv15xPkbsEq2ZNv1aeJ4OWbiuJYBX+nM30xDoRWgJD76Q7blGZZGXcUEGyMmaFfhcAIc11yJpkM9QOwNqdDZimSVcwNqwjeUVRFGX8OaP4DACWly0HwKprLJ+Wx2cWl3Pb1XP5+UdnctXMU7li0hUATHQV8MPzlwKgWYKcU3ohAkFHtJmqQFV6u7NLMvjVGb/g5tNvTk8r9Mls9ZzAMiJmB1b/erkdWzeNQQMzHh6xf629EQxDfZcoHywVJCtjJlJdwLUbLjbt3Meq3YPZ4lAsQWcwxo49+wD47l9Xc+3965n30xVc/8gm4klj2LZ2tfTx8+e2kTho+mgi8SSvbG8d9QRpmuaIbSuKoihHx2V1sfqTq/mvOf81Yp7PYeUTC0qxWizcuOhGNn96M0u8S1heOTO9zBmli5mRPQOAyYHJw9Y/Keckzig5A5GqTJ5bUsC8sgA/OedKdKHjy5VDZiMSNCQFe5s7uObedfxtfQOxhMEbu9o55ecv86UH1hNNJN+nd0BRRlI1ycqYaUL+puoxXXR3tPL5O9/i5PIAF88q5N5V++noj3JbsgkEnFPp4baaFooDTp7c1ERRhpNvnTclva173tzHg6vrmJTn5WPzikd9vZ5QnB0tfTywej9PbmriC6dP4LsXTE3PD8eSfO4vazAM+Ou1i4avG47jc1iGdy2kKIqiHJLL6hrTcgPn1QxHBgF7gK5oF1Myp7C4cDFb2reke80YyqJZyHJm0R5uZ0puLo99aRIAEzImsKtrV3q5ToeV3v5+1kc6eWlbCze/sJ1QLEmm284LNS18//F3uPmKWYRjSXa19mG36PRH4/z8ue3sau3n11fMYvm0PHpCca57aAMZLhu/u2r2iO8CwzCp3tnKzKIMcrz2d/uWKSc4FSQrYzaQBZhQWoTPTHJ9eRUv1LTwgydrsOkaDquG3+wBAV85rZD86RO4eFYh33/iHe59cx9fOH0CTd0RusMxqre3AnDry7u4aFYh2zqSzIvE8W59mHhgInrZIr75t7d5cWsLAJPyPNzx2h4WTcji2S0HcNl0NtZ1s6VRln3Ud4bI8dp5fVc70wp9nPXram66ZDpXnlz64bxZiqIo/wIq/BUE24NU+Cu4eOLFbGnfwpzcOaMum+vKpT3cjs/mS0+bnjV9WJBsz3NT3hlh/deW8+rONh5dX088afLt86bw1KZGfvfPWkLxJG/t7qAjGEuvV5ThJNtj4/qHN/Kbj8/ilhW72NEiu6fTBbT2RSnwO1k8MYsnNjXS2BVmT3uQUyuzue/zC8aUUNnc0M3Oln4WlGditQief6eZy+YUkeGyHdV71hOOU9vaT67XTknm8B8mA/1Gt/RGyPbYhw/ipXzgVJCsjNlAJtnmzkDv2Mv1yybx1bOreKGmmQyXDa/DQsX/i0AE7GaET50iR3P68pkTefrtJr7x6Nus3tNJMJbAMOH8Gfn8451mLrt9JTVNER7c/TqvGD9kNTP4nv419neEuGR2ITOL/PzbKWWc/qtX+Majb9MRjKFrgnyfg2+fN4VfPr+dl7a10NYX5fbq3SyoyCSaMLj7jX18fH6JyiYriqK8T84tP5fKjEqsmpVSXyl/Wv6nQy6b68pla8dWvDZvetq0rGk8UfsEE/wT2NOzhx63g4zGBmh+mzOnzObMKbnpZb9ydhW1bf2s3dvJ9CI/nzi5hI5gjKbuMF88fSLBWIIr/riKa+/fgNumc++/L+DmF7bzxKYmZhT52NLQw2MbGijKcDIx18PMYj9Pbmri1F++gsOq8YkFpZRkutjcnODxhzeyancH5Vlu/vuCKdQ09fKjp2pIGiZOq06uz87+jhA/e3YbTptOWZaLSXleJuZ4qN7RSjxpsmxqLj3hOO39MWaXZLCrtY9QLMmzmw8QTcgywZPLA5w1JY/WvgjBaIJnNh/gzCm5PLflACeXZ3LxrELCsSQ1TT209Ucpy3IzIdtNrs9BW18Ul03H57CyvzNING4ws8jPmVNy0TVBQ1eIxzc04rJbaO4Jc9mcYooCTt46kGDjip1keWxcMLMAj92CELCloYeKbDcv1LRQluVi8cQstjT20NAVJs/nwGO3UJXrob0/yoa6Lh7f2Eim2855M/JZNCELm0XGCOFYEl0TWHWR/v4NRhMA3LNyLztb+rl6YSkTcjwjsvg9oTjBWAKHVaczGKMzGKM820UiaZLrtWPRR1YJ72zpo7a1n/Nn5L/LT/GhqSBZOWqmw5/u3UIIwXkzUn1vmibEu+TjWDC9/JR8H9cvq+L//llLltuG1aLRGYxx40XTKA44ufP1vczM1mmOJDET3ZBspzEZxu+08pNLZ+BzyFbRVy8s45aXdlKV6+Gp607FZtHQNcHf1tfzyNp69rbL11yztxObrrGjpY81eztZOCFrxDH0RxN47OrjryiK8l58cuonx7xsrjMXTWi4LIPZ02lZ0wCozKikM9JJU/5UaNwND38Srt8Cqa5HASy6xu1Xzzvk9v0uKytuOJ2H1tRzyoRMphf6mVHooysUozLXS08ozob6LhZPzMJu0YknDXa39WMYYJgmP312W3pbAVcbSyqz2bC/i6v+9BaxpMFZU3K5YfkkvvHo29S29vPLj81kX0eIUDTBnvYgK2vb+fuGRooynDisGr9+cSc2XcPjsPD4xka8dguaJvjISYWcPyOfPe393PHaHn75/HbsFo2kYTK7JINnNx/g1MpsNtR1sWZvJwCZbhslmS6e23KA7lD8sO9ztsdGRbabrU29BGOyhlsIeGB1HYZpEokbgMze3/hkDQA2i0YsMbx9j1UXxJPD2wLZLVo6wM/x2glGEzy0pg6vw8LMIj/NvRH2tA1+/9ssGlPzvexo6Uu9rpz21NtNCAFzSwP0hOMsqMhkY1032w70HvK4bLrGgopMZhT5KctyUdPUw7YDfWyq7yZpmFy9sJSz/Me2caeKEpQxGyi3MBz+0ftJjvZBMnX5a0iQDHD9skl8dE4xNotGbWs/a/Z1UuB38u3zprC4MptEYw2ewkqsDycpsAZ55WtLiSaMdIAM8MmFpfxtQz3fOm8KTtvgifOiWYX89qVdBFxWrl5Yxt0r9/KVsyu5Z+U+vvG3tzm1MhvThI/NK2ZSnpffvLiD+97az1fOquLfl1QQNwwyXTa01GWtSDzJqzvb6OiPccX8YqypX677O4LkeO24bOq/jaIoytG6rOoyirxFw67uTQ5Mxq7bKfeX09DfQGO0G5b9CB77PDRthOL5csFEDO46CxZ8EeZ+6pCv4bJZ+PypFennWR47WR6ZrfS7rJw5eTAzbdU1nr7uVIQQmKZJe3+M5p4Ib61dx2cvPhOrrnGgJ8y1963nlAlZfOu8Keia4O//uZiW3igV2e4Rr98TjuO26eiaIBI30tnUus4QpZmug8on8vi3U8roiyTI9tgJx5N47BYaukIUZTgJxpKEUllVj82S/o7qCsZo6YuQ63UQiSfpDsUpzHDgtltYsbWFl7a20NAd5rwZBVy/rAqnTSeRNPnWY5sp8Dmo0tv47MVnsu1AH6v3dhCKJekKyWz3zpY+Fk3Ipr4rxP6OEOVZLmYU+Wnrj9LeF6WmqZeyLBdTC3zMKwuQNExW1rbz/DvN7G7rpyzTxUfnyL9xLGHQH02wsa6LS2YVkeuzU5Ht5uwpeazZ18nmhm5e2dFKns/OI2vrmZLv5ZvnTibLbSMST+KyW8j22KjrCGG1aOxpkz9E/vzGHuJJE4dVY3ZJBp9bXI6mCR54az8zFx5d6cuRqG97ZcwGyi1Muw8SYdmXpWXIpZJU928AxEMj1i/NktmDfL+DU1P9blp0jTMn51J9YCuLCuXHsdQRwpo5sgFJjtfO6986a8T0r55dxdULy9KZ4Uy3lc8sLue0qhw+eedbPLFR/mJ9eG19ep2ZRX5ufXkXt74sf02XZDrJdNnojyY40BMhlPr1/cTGRs6YnMOrO9pYs6+T4oCTZVPz6AzGcNl0koZJTVMvpZku/rm9lYUTMllQnsm8sgDZXjvtfVEe2xnjTzvfwqILTir2M7c0wIqtLby5u4MZRT7OmZbPnrZ+QrEkk/K8NPWEsWgCq65h0TWsuqAvkqC9P4phmHgdVqKJJI3dMtvuc1qxaAJdCEoyXWR77LT0RugMxXBYdJw2HYdVw6brhONJgtEEwVgCXQjcdgseuwW33YLdohGKJQjHk2hCpDMgAoEQIJBfAN3hONF4kgk5HjqDMTbWxdnw4g6EEOiavOV47AiRGnjGhIDbRp7PTq7XgSagN5KgP5rAME0Mw2RDXRdWXaM44Ep/wVgtGpF4ktbeKL2ROFZdw6ZrWFLZjVjCIBRLkOWxURxw4XVYMAzoDsfIdNtIGiYd/THa+qIkDANNCLTUPhqmiZZ6vwYuA1pS+x5PmvidVible8bwv0JRlLGakT0j3QPGAIfFwYMXPkihu5C63jpqOmpgyVmAgNqXB4Pk7c9A8xao+fthg+SjNRCwCyHI8drJ8drpqNXTyZECv5Mnrzt12Doum4WK7NHDJ79zMLEzNJkzWkA9sK2BxMvAd1hxwJV+PtoVz4DbRsA9GAwWZjjTjy+YWcAFMwtGrAPw//59AQDV1dVYdI2ZxX5mFvtHXfZQrjjouVWHs6fmcfbUvKPazvJpeSyflsfXz5GNPGMJY1h5xuEkkgYHeiIE3LZh78/nlpSzY+Pqo9qPI1FBsjJmAx9e05FqdBHpAc/gr3JCnYOPY/1H/wKpvpetkU5ZujHafxbDAG14TdLAyW3AdWfJPjpnlWTw0tfPwGmVQVf1jjYausLMKvazaGIWa/d1sX5/F1Zd8OrONpKGSXHAxeKJ2Zw7PZ8DPWF++uw21uzrpCLbzfXLqnh28wEeW99AwG2jOxQjljSYVuBjZW0758/MZ2NdN6/vah++f8CskiTxiMGfXt1DwjBx23ROmZDF6zvbeW5LM5qQPxgOvtw1lMduQdcEfZE4Fl2jOMNJbyRBbzhO0jRJfoh9iGrbajGRf7YTRaHfwf8s0o+8oKIo78mkgOzposxXxov7XyRu92Itmgu1L8EZ35LfBevvkQvXrYZkAvSDwpdRvhuOqYGTm2rj8r4YqGceC4uujWjwCPIHzY5juVOoIFk5CgPlFqYj9csz3D08SA4OCQ5jIzPJRzQwQImRkDXPzsDI+bfMgI/dBZPOHdMmC/yDv7AvmlU4bN6CikwWVMhO7a85bcKo618+r5iecDzdevn6ZZPS8wzDJG4Y2C3DA6n+aIJVuzuIxJNkeWy01m7m0nOXALJRwsb6LuaVBfA6rETiSRq6wgRcVuxWndbeCKWZLkwgnjSIJ+RreOwWHNbUsOCmiWEyotWzYZjsaQ/SF4mT5ZYZkUg8SSSRJBI3iCaSOK16OnucNEyCUZnR7Y8miCUMXDYLTpuOkep/uicUT1+KNIEMlxW/04omBLvbZOvsLRvWcuGypWgCDBMShkFHf2zYvnUGY7T2RWnplcPNeh0WvA55+oklDE4ul3+H+q4wkXiSpCEzxXaLRp7fgc9hJWEMvh9WTcNm0XBadVr6IjT3ROiPJjBNCLisdIXi6Jq81JrjsWNL1fuZJiRNEwHEkgb1nSF8TiuagETSJGGYWHWNtr4owVgC+ncf9vOlKMqxU+YrwzANGvobqKhcBq/+En5ZDid9HPa+BgWz4cAmaH4bMifKkV0zJ8A7j8GzN8AFv4G+A3DSleA9uszmCOFucGbIx0YS7jgDCufAxf/3no9TOX6oIFkZs4FMsjHQMvngoamPUG4hp0fAiIPdO3Le0FH8gh0jg+SeRoj2Qt2qMQfJ75UQ4pDd+2iawK6NzDR67BaWTxs8QVfXD/5C9rusLB1SE+ew6lTmDl7W9+QMPrbqGozy0kII9FGSGZomhm0Lhl/uG43bbiH3sEscWp7PAUCDQxuWBbCh4cocfmoZ7Vf/aAZqB4+G32VlUt4on6cxONJ61dUqSFaUD0q5rxyA/b37qVh4rfye2PokrLkDJiyFi26FW2fBpodgzyvQUQsZZRBsg0QE/n6N3FB/C5z7M3jxBzJo/shvQbNA0wYoXSSzwmvugH2vQ9liOPk/wDJ4ss1uWwW/vAQWXgvn/FTuQ/MWeXNkyKumxfNh7qeHNSxUTjxjym8LIc4TQuwQQtQKIf57lPmfFUK0CSE2pW7XDJn3GSHErtTtM8dy55UPlpb6uKTLLQ5uvDeQSbb7D11u8fx/w/2Xjz5vaJAcah85P5zqOaNDBS6KcjhjOGefLoTYIIRICCEuP2ieOmcrH4pSn+zXfn/vfnBlwuL/gs8+B1fcC1c9BIFyGeSuvRN6m+CsH0DuVMiaCF98DRZ8QWZ7tz4lvy9W/xG2PAr3f1Rmmu85Hx64HFb/AZ7/tmwY+MJ34eZK+b20/i9gmpTtfxRsXrn+P74N1b+A7EngyYM3fwc7n4dnrof7Lh0sM4z0wN+/CGvulN+N/W0yA22a0LBeTo/0ymm1L8G2p6F1mywTORLDkFdnjQ9ptMF4GHoPfDiv/SE7YiZZCKEDtwHLgQZgrRDiKdM0tx606COmaV530LqZwA+B+cg2POtT63Ydk71XPlDpmmT7YTLJuh08OYcut+iohfZDVA0N3V6wbeR8FSQryhGN8ZxdB3wW+MZB66pztvKh8dv9BOwB9vXuG5xoscH0Sweff+oJ2PcGePMhf3gjQC64GTbeD09+Gf75U9nb0pLrYeVvoX41lJ0q1619CYrmw+dXwN5qWa5Rtxqe/io0rMPbv1tmrQ+8Dev+DLoNPvEQ+Irkd1vRXPk6z94AfzodciZD5x552/wwPJf6b+UMgLcQWmU3a7z5Oxno9jYO7nNWFSz8IjRukCUlhbPB4Ye86TDtUvjHt2DXCkhGweKE0oWQPRlqV4DuKarPAAAgAElEQVRpyOC9YJb8sVDzuAxmvfnQ3wr9zTLAvuBXkJEaWOvAZnJbamF7EHb/Ew5slmUlNo8Mhr15sieR1hq5jrdQ/tCI9cv3N38mePLl931G6cgrviDfh10rwF8CVeeAmZQNLw1DZuD9JfL7PNwpt+vJkxn6+tWQN2OwVKZrP7TtALtHXlUYiD12/EMed/mp8keKkUgtv/eYN4wZS7nFAqDWNM09AEKIh4FLgIOD5NGcC6wwTbMzte4K4DzgoXe3u8qHKR0ke3JBs8pLTyd9fHCB/jZZo2xzH7rcItQh/3Mk46Bbh88bVm5xmExy557RG2kYBjRvlieZvhaZKZj/71Bx+lEeqaIc1454zjZNc19q3sFpLHXOVj5UZb4yartq0yPPjWB1QNWyQ65vTDqPsG7DvfYuWa+87EeyJGLb0zLQbd0GL/0Izv+l/A6ZeJa8JWJwz3mw8T66/dPIOOlKmPlxWaYx7VIoXzL8heZ+Sm7/lf+R303uXDjvFzJoC7aC1SVLA3sa4cLfyMDw1V+BrwDO/R+ZFW/eAm/cIoNqi0PuR+s22YXqpgdkuYhpwMnXgL8I+pph14symK5cJoPG1u2yFxAzKbPf+TNlMsqTJ7PuLTWyz+khpgFsQ75m0TxZnhLdDVYnNKyRya6sifIHRTwsXyvYLn9EHKxkocycx/rlMXftHQxaQQbJrdugp37kuqNx58gfDi01EO058vIHsS36y1GvczhjCZKLgKFH1wAsHGW5jwkhTgd2Al8zTbP+EOsWjfYiQogvAF8AyMvLo7q6egy7Nqi/v/+o1zmejIfj29m3E4CV6zay1DcV69tPss52dnr+SfXbsRgOjFAcM9zA26Ps76LuA9iB7X/9McUNT7N+3q8xNSv9/f3UtbxDsdDRzCR7atZS1y/7unT372fqtt/QkTWfMoBEmFUvPkbUkTNs25N23EbhgRdZN+9/mV7zC5yRVhq6E9RWjeFy1vtoPPzt3k8n8vEdp8c21nP2WNd9X87ZcNy+v2NyIh8bvH/HlxvN5cXeF7nir1cwwT6Bt/rfwq7ZqbRX0hxvZoF7AYu8i0ZdtzPRyS3Nt9Bdms9H4h6u9p7Ps8/+ik2hbdjypqE9/VXmuefxtMPgtHVPsTd6Kye5TmKWaxYNsQY2Z86g2D+dCsdyvCtTXYm5LqSztoWaLT8hx5JDbaSWnmQPV2VdhS50qPjm4A40ARTIWxzIroJsIJi6Vf1ALtcGtHUDJYgZN2OLdZKwuElaXHJ1wN2/l4m7/0JbzhIOuM+BBOAEZp6HZkQxdNkmhGzQklHcwToijjziQ4b8BtB9YfK9LxG3+jGFTshVRCgUwuOwEHKVkLQ4ORRRKgctMTUrwojjz9yGngxjj3YSt/pwherJaXuLhMVF1DERPRkhVDSTuNVLW84iclvfYMKu+wk78tk184dE7QH8PduxxntIWLzErV4Smh17vAdbrIuws4CS+ifQ2uvpyj6VsLOAPm8lmhHDkghhSYTQjCg9/ul4+3al3jcvptABk7Azn+6oeUw/l8eq4d7TwEOmaUaFEF8E7gVGdmh7GKZp3gHcATB//nxz6dKlR7UD1dXVHO06x5PxcHyduzrhTVi0aBEB5xWw4gcsnVMlf+ECbEtCzkR5OSnUMXJ/TRNe6wNgSqIGgvs4Y3oR5E2jurqaUsMHnVkQDzMh18eEgfU33Afr9uMJDDaGWzQpRzbkGNDbBNUvAjDf1wGRVgCKiwop/pDft/Hwt3s/ncjHdyIf23v1Xs/ZcGK/vyfyscH7d3ynm6czb/s8btt0Gzt6drAwfyEW3cJbTW/hsXl4qPMh7IV2DvQfIGkmOaXgFDa2bqQqUMXqA6uJiigfmfARntnzDH3ZrbzW8Bo5rhxsmo22cBvrQuvQhMYjnY8AsCG8ge9M/A53bLyDrqi8WnmyFuT8wvNxW9y0hdu4dcOtxI3ho9zl5OVwUs5JhBIhLp90Ob6DgtOx6o500xfvQxMae7r3sLBgIZFkBJ9tKfA5/EaSvtaN7O7ejRCCqkBVuq9pq2alJ9rD642vk+VbzNysaaxrWUdnpJNyXzlbO7bSH+9nT8FJrGpaBcCiwmIidTodme3s7HqTQnsh07On0xXpojnYTHOwmenZ03Fb3XhtXoo8RQggGE/QEMnCb/eT5cgi05GJ15mF0x6gLdxGW6iN7V3baepv4vTi06nyluKzX86encvJKjqZYF8draFWmlhMljOLqZlTebz2ce5+526+MvcrlPvLiSQivNVTTDQRpaG/gc1tm4nGtzA3by6VGZVs69hG3IgzLStMrmsur9S/Qjjewbz8eeS78tGEhrPOeUw/l2MJkhuBkiHPi1PT0kzT7Bjy9C7gV0PWXXrQutVHu5PK+JDuAs405eWXFT+QtV0tNWBzyUtMRXNk2cRol1YiPYOXYRo3yPumDbDqNnZo5SwMd+F0+FPbahu+HshLNkKXl5U6dg8Pkt95bPDx/pWDjw8a+U9R/gUc8Zx9hHWXHrRu9THZK0UZA01ofHLqJ7lo4kU09TcxKTAJIQQJI0HciPPNV7/JvTX34ra6MUyDFftX4Lf7eWbPMwDcMO8GPjv9s2Q7s3lkxyNMzpzMvefdi8vqYn3Leu555x6un3s9bzS+wezc2fx8zc/5yVs/wa7beeKSJ3hy95Pc8849rF21Nr1PCwsW8t0F3+X1xtfxWD3Udtdy/7b7eXrP0wA8sPUB8j35lHpLmZUzi5NyTiLTkcmL+17kmT3P0BxspsRXQlekC6tmxWVx4bK66Ip2sbt7N4Y5eLXTollIGAlOLz6dgD3AG41v0BHpGPYeCQSa0JieNZ3tnduJGbLLTZtmSz8+WLmvHJtu49frfg2Atd3K9KzprGxaydN7nkYgyHHmkOXM4t6ae0ma766RoCY07tpy15iXz3fn87PVPxsx3W/3My93HhbNwqqmVTy751mKPEU4dAfV9dWYmDJYd2Zy+6bb0+v9rHjktt6LsQTJa4EqIUQF8gR6FTCswEUIUWCa5kDTx4uR1S4ALwD/I4QYqOw+B/jOe95r5UOR7gIOQzYSsPtkTdXO52UtUrBd1mUlE6MHp6Eh/9EHGumt/iPNbVv5fWkRmeRwhcMPQpO1VwcvG+uTtUo9DSMb7/W3yDoqTKhfI6e5siGugmTlX84Rz9mHoc7ZyrjgtXmZnDk5/dyiWbBoFn5/9u8JxUPomk5vtJf6vnrm5M6hM9LJ/t79zM6djRCCr8//Ol+e/WU0oWHTZfdu8/LmMS9vHgCVgUoAHrjgAV7Y9wIBR4CJGRO5Yd4NTO+ZzuyFswkmgsSTcSozKtE1nQkZg/3pXzvrWmLJGE3BJv6w6Q8kjASrmlalg/UBs3Nmc0bJGTT0NTAjawZJM0kwESQUD1HoLuTs0rPJceYQioco8ZWwrnkdVs3KozsfxabbmJ83n3PKz2Fu7lySZpIt7VvY3rmdSCLCupZ1fHzyxzm3/Fy2d8osboW/gmJvMY39jczJnUOGPYNoMkqOMwchBLu6dlG9upqPLf0YmY5MDNOgI9xBhiMDqybbCfXGerFqVroiXXSE5fe23WIn25lNT7SHjnAHnZFOOiLyPmAPUOQpIs+dR4G7gHUt62gONtMV6aLYW0x7uJ0yXxlTMqcgENT11rG3dy/FnmKWFC1hZeNKXFYXDt1BibcEt82NLvTBUX5Nk+5oNwGHPC31RHvoi/WR58rDqlsJJ8Lp/dy5bucx/RweMUg2TTMhhLgOefLUgbtN06wRQtwErDNN8yngK0KIi5FVM53IVtOYptkphPgJ8qQNcNNAgxDl+DMskyyEbHjQvlMGrXKObLgX6TlykDygeQsdNvkfszXRD45i8BXC9mcHR90b2tWcK0sOhd1RO3w7wQ5Z8G+xyYZ9No8sA3k3g5ooynFsLOdsIcTJwONAALhICPFj0zSnq3O2cjxwWWW/6zmuHHJcsm1KljOLLGfWsOUcFscRt2XRLFw44cJh0+yanTz34Qcj8dv96X344/I/AvK78UDwAG+3vU1frI/JmZOZlTNrbAeVcnapbOfztXlfG7XhYr47n+Vly0dMn507e9jzkzl51O1XBapodDSS6ZADOGlCS7+HAwZKR5weJ4We4YNwZToyqfBXjOkYDqXYW8ziosXp52eUnHHY5YUQ6QAZ5Hs/8P4DOC1Oir3FANSK2hHrvxdjqkk2TfM54LmDpt045PF3OES2wTTNu4G738M+KuPE0F91AGRWwM4XkD1FpbhzZPc2saBs8fvYNXDW92XflaP1WAH06LIz9vZkVHZ9kz8TNt4nO4H3FQ7vGs4ZkIF460Gdq4TawZ0lu5Hp3CO7prEeppcNRTmBjeGcvRZZSjHauuqcrSjvghCCQk/hiMDy3W5L+fC9jwOdKycqcyAoDlTIUY6G8uTKLG4yCq/9WtYs73xBzhvIJKcu6ZBqVdud6sqt3Yyl+odM9X3Z/I68H5ZJzoSsSujaB8k4T9Q+wa0bbpU1zO4c2c0OyCDZ5lI1yYqiKIqivCsqSFbGLF2TPNDIIFA+ciF3rqxPBjlaEcjOwGFwFL0sWQtGmbzcMhAkdwgDHL7BDuJbtsj7gzPJWZWyAWBHLT9Y+QPu2nIXvaEOWYPsTyXH/CWH769ZURRFURTlMFSQrIxZelhqhpRbgByNKFWKITPJqSBZaLJ0om0HvPA9WHW77Lx8ILieeQVYXfRklgHQrmuQUSazyZ48ePkmeOnHEO7GBFY6HRgO/2CQffsp6X1bmewF95AgeaDcQmWSFUVRFEV5F1SQrIxZesQ9c0i5BZAMlJHwFctg2eGX5RaAOf8a/p5fQU/nLlj1e9lFnN0rh60GmPFR+G4T3Z5sANp1HbMg1cghlWXmjf+FYCurnS6uzc9lRaJDjgSUkpfqpeZVhy6D5AxVbqEoiqIoynungmRlzHQhG9jd/vbthBNhvrz+l3wvJ5sLvQafybQRcufK3ihKFsKMj7Fv7pX8sGcT93mGjOgTbJNDfJ7yZdlLhRB067L9aFwIegOp8eUv+DWc9g35ONLDukA+AGsirbKHi5Se1Ki6bzgdJJ2ZULYElv1YDoVpdalyC0VRFEVR3hUVJCtjtqhwER+r+hgv7HuBe2vu5bXG13nK4yJpsfMOcX5cLvu0NDJK4PK72R+TtcSvupyyfAJk+UXl2XDe/6S32yMGe8foSPTLB+5suVzKRrcXgLXhAyAETR/9Iy2LryOiaUyyZ9Oj62wnCroVTr1eZpFtbtmw0Hh3naIriqIoivKvSwXJyph5bV6+f8r3set2nqx9EoDbzr6Np698hU9OvZoXg3t5cNuDnP7I6fTF+qjrrQNgu93GuvKTCX19O3zuHyO222MmsBsyIzzQITgg65OBOLA52YfL4mJvsJH2cDuf3vFnboztA+B8U2aq3wofYJiBBoQqm6woiqIoylFSQbJyVCyahcmByTT0N6AJjQX5C3BYHCwtWUrCSPDbDb+lJ9rD6gOrqeurwyJkKcXngpu5YfWPZU0yDBuGs9uIUhGXw1W3h2UPGKF4iG6bE3QbW+02ImaCK6dcCcATtU/QEmphQ7fsNaOyfT+VsRire2Qn4vFknO+8/h12m2H5AmpAEUVRFEVRjpIKkpWjNjVrKgBlvrL0iEZzcufgtDgJJ2Rg+kbjG9T31TM5czJfnftVzi8/n5WNK3l699PcUH0DFz1+UXrZnlg/Gd6TgMEg+fsrv881K74A/hKqXU50ND497dP47X7+UvMXACLJKACB/lZOCUfY0LWV1lArO7t28syeZ1gRlJlsYv0fyPuiKIqiKMqJQwXJylGbmimD5CmBKelpNt3GgvwF6flvNr3J/t79lHpLuWbmNfzs1J9R7ivnu298lxX7V1DXV8fjux4nYSToi/cRcFbgtDhp7G8kGA/yav2r7OjaQVdGMc+53ZySNZ1sZzZLCpfQE+0Ztj+ZSYMrIga6sPCVf36F7Z3bAdiTqolW5RaKoiiKohytMQ1LrShDDWSSJ2VOGjb9P076D+blzcNn8/GjVT8C4CMTPgKAVbdy/wX382bTm+S58vjtht9y55Y7CSVkAOvW3FRmVLKraxevNbxGzIgBcJ/dpMm0cF3pMgDOKD6D5/Y+hya0dMlGYPlP8eTP5gfJDr7z+ncwdsjpe6Op+mZVbqEoiqIoylFSmWTlqE3JnMJX536VSysvHTZ9Vs4sPjfjc1ww4QJcFtlorshTlJ7vt/s5v+J85ubN5Vsnfwu31S2HlAbcuptJgUns7NrJiv0rCNgDaELjnkgdLsPg7IrzAVhStASrZmVR4SIArJoV94JroWwRZ5aciS50tnVuA2BfuBUDIK76SlYURVEU5eioIFk5aprQuGbmNWQ7s0ed77Q4efSiRzm16NR0MHuwGdkzePrSp/nP2f8JQI4lh0mBSXRHu3ml/hXOKT+HqowqEhhcWX4hLm8BIAPthz/yMDctvgmAgCOQHuTEbXWnS0F0oRMx4jRZdJVJVhRFURTlqKkgWXlflPpK+cOyP5Dvzj/kMkIIvjTrS6y9ei1l9jImZ8p+lhNGgmVly5iTOwerZuXfFn5j2HqTApPIdeWS6cgk05E5bN68vHkAzM+fD8Aeq1XVJCuKoiiKctRUkKx86AZ6yKgKVAGQYc9gft58rptzHQ9d+BC5rtxR15ueNZ0KX8WwaQNB8vLS5QDstVpV7xaKoiiKohw11XBPGTd8Nh+TA5OZnz8fi2bBb/fjt/sPufxvlv4GgRg27bTi0/j+wu9zWdVl3Ln5DmrsQVVuoSiKoijKUVNBsjKuPHjhg2hibBc4nBbniGkWzZIedGR27ize7m1S5RaKoiiKohw1VW6hjCs23YZFOza/3WblzqHJaqE1NUCJoiiKoijKWKkgWTlhzcqZBcDb4QPvehtDh89WFEVRFOVfhwqSlRPW1Myp2Ey4pWM9d//jWtY2r+VXa3/FXVvuIpwI89q+FemhsYcyTIPeWC9/3fFXFj24iMd3PT5sfiwZI2EkDvm68WScF/e9yNrmtZimecjlTNPkidoneGT7I3RGOumJ9rCpddNht60oiqIoygdD1SQrJyyrbuVr0z/PP2ru45bWlfDCSuy6nWgyyl8230lPIkSO1UuGJ5+F+Qsp9BRimAb/2PsPajpqEAg8Vg83vnkj+3r3saRwCf+38f/Y3L4Zn81Hhb+CcCJMgbsAr83LrJxZ2HQbt226jeZgMyAHU0lGk9zyxC1cVnkZ61rWMTlzMnEjztb2raxuXg3ArRtuxabb6Ih04LF6mJgxkYkZE5ngn0CFvwKfzYcmNHSh0xProTvSTYY9A7/dj0WzYNEs6EJH13SsmhVd6Nh0G1bNSjQZJZKIEElG6I/1s6NrBxbNkt5vgUjXgQsh0FK/nXtjvXRFutCEhtfmxWvzpqcH7AGiRpRwPExtpJZAWyC9nhAivR3DNOiOdmNioqGhaZq8Fxq6piMQ6EJHE9qoN13oCHGIZdDojnbTFm7DqlnJcmZhmAZJM0nSSA6/N5MkjAQ23UbAHsCm2+iOdtMX68OiWbBqVhJGgrgRx2P14LP7sGrWD/ojqyiKoowjKkhWTmj/dvL1XJ2/hCcfuYQD+dP4rKuCZ3w+/lD/Il/t7maDTyeWlcmD2x9Ml1a4NTufsRXRl1nO18s/wm87N3D3O3dz9zt3k2UPcM3Ma6jvq6cl2EKOM4f63jo6g808tfspACozKrnt7NvoCHfwasOrNLU20RPr4Dfrf0OOM5tXG17FKizkOrP4xoSPckrFefx66910Rbr46tyvUtNRw+7u3VTXV/P3XX//MN++sXvuw96BY6/MV8Y3At848oKKoijKCUkFycoJTxTP51LfJKhdC/adXBHt4QqAWZ+Atx+C8o/SFKpBi/Sily7CtvVp/IldwCpY9RA/OP9mzp//PXqfvZ759OGfUQiLvwjJGFjssOo2zE0/pMGbQ/fsK5my+JtYnRkAXFZ1GW+seIaZO35ETbCVU0pnEutqx969B8EeqFkLrvu585OPQPH89DoDuiJd7OvdRygeSmdG3VY32c5semI99ER7SBgJEmaChJFIZ04TRoJoMkrciGPX7TgtzvR9VYbsj7o51ExfrA8TE0wwMDBNk4F/PquPDIc8jr5YH32xPgzTwGvz0h3txq7bcVldbNq0iekzp8vtQHobhmkgEGQ4MtCEzCoPvSXN5IhpR5yPgWHIeSYmPpuPbGc2sWSMrmjXYEY9lVU/+HE0GaU72k00GSVgD+Cz+UiYCeLJeDoL3xvrpT/Wj9vqhn0f1KdUURRFGW9UkKyc+ISAy++B3kYoXQydeyARhtxpEO2D139Dod0P5afC9n+ANx+uegjad8DG+xEvfp+Ts6vAsIG/GP7274Pb9hWBaSAKZlPiyqTk9d/D+ofAkye7nov0cGq4CxAsnrAUdjyLo2AWnPYNOd+VBS//BO5aBpVnQ9F8+Rq9TWCxEbC6CdhcYHODvwSsNuiug9a9kFEC3lIwTUjGwVcAVhcYSTANCLVDsB2cAfk6di/EwxDphkgPJf4qSAXzJGLQUy8HXrF7wZEBmkU+Nk0w4vK50OT7OURkR4TTCpfIZZJxeS90uS/RXtBtYHHIHxVW5+D+WWwf1CcAYkG579aR3QYeTvW+6vdnfxRFUZRxTwXJyr+GzAp5A8iuHJx+xb2w9k4oPw3yZ8hg0TTA6oC8aXL6o5+Ffa/D2TfCkuth29PQvgt0C7z5fxDqgAt/A1MuhPo1sOo2GSza3GD3sqcjxoQzPgElC6FxHRSfDJo+uA9Vy2Hl72D7M1D7MnDoxn7vjRi+baHJgNw0oa9ZBrcHs7oGA98BmgU0qzwGI8EZiRhUj7EXEJsXEhG5PasbXJkygI6HwJkJrgB018vg2khAMiHvjYQMcAtmy0C+vxWCrfJvNbA/ukU+Nk0ZFHty5TEno9DfIl/fGQBvoQz+E2G5Xk+9XEezyMA93AXxCOROgck3vds3W1EURTnOqSBZ+demW+CULw0+Pzi76c6Gzz4DHbshUAGaBtMvHZxfuQx2PA+TzpPPSxbI2xB11dVMKF8in5SeMnIfnAFY9kN5i/bLgM5fIgPDeEgGhbEgdO6VwWVGGdg8Mrjra04FibrMlCeiMvjVdHD4wZMvM8ehDgh3y8DdmQF2H7TtkFlpIWT2PHsy2D0yux7ulq/f1wy6FRw+mQE2EqmgOSGfazp1DU2UTaiS+6FbZebYSMiRDh1+mUGOh+V73dcsg127F0JdqYA0KI8n1Cmz3wWzZOZbt6aOLXULd8KBzfJvkjcd3DlymfT+pPYNwOaSWXSQ62aUyveltwn6DshjdPjk+1W1XAbLRlw+d/jTP3BQPQAqiqL8y1JBsqKMRdbE0afnz5S3Y8XukTcAbDLYc2fLp3nThy+bM+nYve57sLe6mrKlSz/s3Xh/VFd/2HugKIqifEhUP8mKoiiKoiiKchAVJCuKoiiKoijKQVSQrCiKoiiKoigHUUGyoiiKoiiKohxEBcmKoiiKoiiKcpAxBclCiPOEEDuEELVCiP8eZf4NQoitQojNQoiXhRBlQ+YlhRCbUrenjuXOK4qiKCON4ZxtF0I8kpq/WghRnppeLoQIDzln//GD3ndFUZTx4ohdwAkhdOA2YDnQAKwVQjxlmubWIYttBOabphkSQnwJ+BVwZWpe2DTN2cd4vxVFUZRRjPGc/XmgyzTNSiHEVcAvGTxn71bnbEVRlLFlkhcAtaZp7jFNMwY8DFwydAHTNF8xTTOUevoWUHxsd1NRFEUZoyOes1PP7009/htwthAHjTeuKIryL06Y5uGHwBVCXA6cZ5rmNannnwIWmqZ53SGW/z3QbJrmT1PPE8AmIAH8wjTNJw6x3heALwDk5eXNe/jhh4/qQPr7+/F4PEde8Dilju/4dSIfG5zYx/duju3MM89cb5rm/Pdpl45oLOdsIcQ7qWUaUs93AwsBD1AD7AR6ge+bpvn6IV7nPZ2zQX12jmcn8vGdyMcGJ/bxHetz9jEdcU8I8W/AfOCMIZPLTNNsFEJMAP4phNhimubug9c1TfMO4A6A+fPnm0uPcgSv6upqjnad44k6vuPXiXxscGIf34l8bIdwACg1TbNDCDEPeEIIMd00zd6DF3yv52w4sd/fE/nY4MQ+vhP52ODEPr5jfWxjKbdoBEqGPC9OTRtGCLEM+B5wsWma0YHppmk2pu73ANXAnPewv4qiKMrhjeWcnV5GCGEB/ECHaZpR0zQ7AEzTXA/sBsbH+OeKoigfsLEEyWuBKiFEhRDCBlwFDOulQggxB/gTMkBuHTI9IISwpx5nA0uAoY1HFEVRlGPriOfs1PPPpB5fDvzTNE1TCJGTavhH6upfFbDnA9pvRVGUceWI5RamaSaEENcBLwA6cLdpmjVCiJuAdaZpPgXcjKxlezTV9qPONM2LganAn4QQBjIg/8VBLawVRVGUY2iM5+w/A/cJIWqBTmQgDXA6cJMQIg4YwLWmaXZ+8EehKIry4RtTTbJpms8Bzx007cYhj5cdYr03gZnvZQcVRVGUozOGc3YEuGKU9R4DHnvfd1BRFOU4oEbcUxRFURRFUZSDqCBZUf5/e3cXallZx3H8+2t8QVIsFUTSGk1vRiodJCTEi4JSu7CoUAmSECTRsovCCSEk8kKhF6YsUDLMJItKmwszTaWCypdiHGeU0ckGUsa3SmugTKd/F3sNbldnz9kzs8/ss575fmCz137W2mue/3nO+vOf9XIeSZKkHotkSZIkqcciWZIkSeqxSJYkSZJ6LJIlSZKkHotkSZIkqcciWZIkSeqxSJYkSZJ6LJIlSZKkHotkSZIkqcciWZIkSeqxSJYkSZJ6LJIlSZKkHotkSZIkqcciWZIkSeqxSJYkSZJ6LJIlSZKkHotkSZIkqcciWZIkSeqxSJYkSZJ6LJIlSZKkHotkSZIkqcciWZIkSeqxSJYkSUAFTQgAAAeWSURBVJJ6LJIlSZKkHotkSZIkqcciWZIkSeqxSJYkSZJ6LJIlSZKkHotkSZIkqWeqIjnJWUk2J9mSZM0C6w9O8sNu/f1JVo6t+0LXvjnJB2bXdUnSQszZkrT3Fi2Sk6wArgPOBlYBFyRZ1dvsIuDvVXUi8DXgmu67q4DzgZOBs4BvdfuTJC0Bc7YkzcY0Z5LfDWypqier6j/ArcC5vW3OBW7qln8MvC9JuvZbq+rlqvozsKXbnyRpaZizJWkGpimS3wL8ZezzU13bgttU1avAS8CRU35XkjQ75mxJmoED5t2BnZJcDFzcfdyeZPNu7uIo4IXZ9mpZMb7hajk2aDu+PYntbUvRkeVmBjkb/N0Zspbjazk2aDu+mebsaYrkp4Hjxj4f27UttM1TSQ4ADgf+OuV3Aaiq64Hrp+jPgpI8VFWn7en3lzvjG66WY4O24xtobIPI2TDYn+9UWo4N2o6v5dig7fhmHds0t1s8CJyU5PgkBzF6qGNdb5t1wIXd8keBe6uquvbzuyepjwdOAh6YTdclSQswZ0vSDCx6JrmqXk1yGfALYAVwY1VtSvIl4KGqWgd8B7g5yRbgb4ySMt12PwIeBV4FLq2qHUsUiyTt98zZkjQbU92TXFV3AHf02r44tvxv4GMTvns1cPVe9HFae3XZbwCMb7hajg3ajm+QsQ0kZ8NAf75Tajk2aDu+lmODtuObaWwZXWGTJEmStJPTUkuSJEk9TRTJi03BOjRJtiZ5JMn6JA91bUckuTvJE937m+fdz2kluTHJc0k2jrUtGE9G1nZjuSHJ6vn1fDoT4rsqydPdGK5Pcs7YusFM+5vkuCT3JXk0yaYkl3ftgx+/XcTWxNgtZ63lbGgrb5uzh3vct5yzYQ55u6oG/WL0YMqfgBOAg4CHgVXz7tdexrQVOKrXdi2wplteA1wz737uRjxnAquBjYvFA5wD/BwIcDpw/7z7v4fxXQV8boFtV3W/owcDx3e/uyvmHcMuYjsGWN0tHwY83sUw+PHbRWxNjN1yfbWYs7u4msnb5uzXbTuo477lnL1IfEsyfi2cSZ5mCtYWjE8jexPwoTn2ZbdU1a8ZPUE/blI85wLfq5HfA29Kcsy+6ememRDfJIOa9reqtlXVH7vlfwKPMZqBbfDjt4vYJhnU2C1j+0vOhoHmbXP26wzquG85Z8O+z9stFMktTqNawF1J/pDRrFYAR1fVtm75GeDo+XRtZibF09J4XtZdvrpx7DLrYONLshI4FbifxsavFxs0NnbLTKs/x9bzdlPH/ARNHfct52zYN3m7hSK5RWdU1WrgbODSJGeOr6zRNYRm/ixJa/F0vg28HTgF2AZ8Zb7d2TtJDgV+Any2qv4xvm7o47dAbE2NnfaZ/SZvtxTLmKaO+5ZzNuy7vN1CkTz1NKpDUVVPd+/PAbcxujTw7M5LIN37c/Pr4UxMiqeJ8ayqZ6tqR1X9F7iB1y7vDC6+JAcySka3VNVPu+Ymxm+h2Foau2WqyZ/jfpC3mzjmJ2npuG85Z8O+zdstFMnTTME6GEnemOSwncvA+4GNvH4a2QuBn82nhzMzKZ51wCe6J25PB14au0Q0GL17uj7MaAxhYNP+Jgmj2dkeq6qvjq0a/PhNiq2VsVvGmsrZsN/k7cEf87vSynHfcs6GOeTtPXm6cLm9GD2d+TijpxavnHd/9jKWExg9ifkwsGlnPMCRwD3AE8AvgSPm3dfdiOkHjC5/vMLofqCLJsXD6Anb67qxfAQ4bd7938P4bu76v6E7SI8Z2/7KLr7NwNnz7v8isZ3B6LLcBmB99zqnhfHbRWxNjN1yfrWUs7t4msrb5uzhHvct5+xF4luS8XPGPUmSJKmnhdstJEmSpJmySJYkSZJ6LJIlSZKkHotkSZIkqcciWZIkSeqxSNagJNmRZP3Ya80M970yycbFt5QkTcOcrSE7YN4dkHbTv6rqlHl3QpI0FXO2BsszyWpCkq1Jrk3ySJIHkpzYta9Mcm+SDUnuSfLWrv3oJLclebh7vafb1YokNyTZlOSuJId0238myaPdfm6dU5iS1ARztobAIllDc0jv0t15Y+teqqp3AN8Evt61fQO4qareCdwCrO3a1wK/qqp3AasZzZIFoykrr6uqk4EXgY907WuAU7v9fGqpgpOkxpizNVjOuKdBSbK9qg5doH0r8N6qejLJgcAzVXVkkhcYTU/5Ste+raqOSvI8cGxVvTy2j5XA3VV1Uvf5CuDAqvpykjuB7cDtwO1VtX2JQ5WkwTNna8g8k6yW1ITl3fHy2PIOXrtv/4OM5rdfDTyYxPv5JWnvmLO1rFkkqyXnjb3/rlv+LXB+t/xx4Dfd8j3AJQBJViQ5fNJOk7wBOK6q7gOuAA4H/u/MiCRpt5iztaz5PysNzSFJ1o99vrOqdv5JoTcn2cDozMIFXdunge8m+TzwPPDJrv1y4PokFzE6+3AJsG3Cv7kC+H6XlAOsraoXZxaRJLXLnK3B8p5kNaG7v+20qnph3n2RJO2aOVtD4O0WkiRJUo9nkiVJkqQezyRLkiRJPRbJkiRJUo9FsiRJktRjkSxJkiT1WCRLkiRJPRbJkiRJUs//ANuxMUVMvim/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}